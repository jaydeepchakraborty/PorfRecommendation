Privacy Preservation Services: Challenges and Solutions
Dijiang Huang

Arizona State University

dijiang@asu.edu

Vinayak Kandiah

Arizona State University

Mayank Verma

Arizona State University

vinayak.kandiah@asu.edu mayank.verma@asu.edu

ABSTRACT
The current Internet architecture was designed at a time
when many of the current network applications did not even
exist. As a result, it has become increasingly difficult to deploy new and secure services on the Internet. Hence, a new
Internet architecture is required to address the security and
usability issues that affect the current Internet. In this paper, we examine the current Internet architecture from various security and user perspectives using two privacy services
and propose some architectural guidelines and principles for
the future Internet Architecture. The two aforementioned
privacy services that we chose are: i) anonymous communication services and ii) identity management systems. We
examine the challenges in implementing anonymous communication services, and identity management systems and
identify the problems with existing solutions for these challenges. Based on the problems identified in the current Internet architecture, we propose a virtualization-motivated
set of architectural principles and design rules for the future
Internet.

Keywords
Privacy, Security, Virtualization, Anonymous Communication, Identity Management

1. INTRODUCTION
Data Communication has come a long way since its inception. The Internet is now being widely used for a variety of
activities that did not even exist when it was initially created. As a result, the Internet is struggling to cope with
the demands of the end users, in terms of support for the
services provided. Hence, there is widespread on-going research in an effort to realize a new Internet architecture that
can better serve next generation applications.
As the Internet based services proliferate, the number of
attacks also increase resulting in a need for improved security and privacy. Several privacy services have been pro-

posed for the Internet, but they are either too difficult to implement or the Internet architecture provides loopholes for
adversaries to exploit. In this paper, we examine two such
privacy services: Anonymous communication and Identity
Management (IDM) systems. We examine the challenges
of implementing a anonymous communication service (like
Mix Networks) and IDM on the current Internet architecture. We then propose the use of Virtual Service Domains
(VSDs) created using Virtualization techniques as the foundation for our architectural recommendations. Virtualization is a technique used to create a logically and physically
separated set of resources based on user needs. However,
creating VSDs alone will not solve all the problems we are
currently faced with. So we also provide a set of architectural characteristics for the Future Internet that must be followed to overcome the shortcomings of the current Internet
architecture. These architectural characteristics also satisfy
the challenges posed by the various privacy services. The
characteristics are derived through an analysis of the challenges presented by anonymous communication and IDM
systems and are presented in two sections. The first section
which describes the characteristics derived from the anonymous system also specifies a mapping of which challenges
are solved by the respective characteristics. The second section discusses more recommended characteristics obtained
through an IDM case study.
The rest of the paper is organized as follows. The research challenges presented by anonymous communication
and IDM systems are presented in Section 2. In section 3, we
describe the working of virtual service domain and the reason behind choosing Virtualization techniques. In addition,
the architectural design directions of anonymous communications and identity management solutions are presented.
Concluding remarks and open issues are given in Section 4.

2.

RESEARCH CHALLENGES

Research challenges of two inter-related research areas:
anonymous communication and identity management are
addressed in this section.

2.1 Anonymous Communication Systems
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SAC’08 March 16-20, 2008, Fortaleza, Ceará, Brazil
Copyright 2008 ACM 978-1-59593-753-7/08/0003 ...$5.00.

Over the past few years, solutions have been proposed for
achieving anonymity in communication networks. However
its implementation in the Internet is inhibited by some practical limitations. For example, TOR [6] is a working implementation of onion routing on the Internet that is supported
by the Free Haven Project [1]. However, there are various
constraints that have inhibited the wide spread use of TOR.

2110

Some of the challenges in implementing anonymous communication systems and the shortcomings of the Internet in
meeting these challenges are described below.

2.1.1

Scalability in Supporting More Users

The Internet is used by millions of users and as anonymity
services become more popular, the number of users participating in a Mix Network will increase significantly. Most
mix network implementations depend on the existence of
specialized servers that have the capability to perform mix
node functions. Simply providing specialized servers is not
an acceptable solution as this would merely build an overlay network and raise communication issues between mix
servers and conventional router. An alternative solution is
to integrate the mix node functionality with the underlying
network (i.e. routers); but as routers are busy handling the
conventional routing operations, it is difficult to configure
servers that perform both operations. Thus it is necessary
to provide a solution that does not affect other applications
hosted over the Internet [3]. Hence, it is required to design
an architecture which can support various services requested
by the user without conflicting with each other. Moreover,
integrating mix operations at network layers is desired.

2.1.2

Knowledge of Network Topology

In a mix network, the source node which sends the message must decide the complete route to the destination (i.e.
Strict Source Routing) or at least specify a part of the route
(i.e. Loose Source Routing). The bottom-line is that each
user node that needs to send a message must know the current network topology. This is not an easily achievable task
with the current IP routing scheme used in the Internet. As
mentioned previously, the mix nodes may be set up as specialized nodes forming an overlay network over the existing
Internet topology. Alternatively, the routers in the Internet themselves may be equipped to perform the additional
operations required for mix networks.
When using an overlay network, it is necessary for the
mix nodes to be appropriately labeled or addressed to be
uniquely identifiable in the overlay network. In this case, it
can be claimed that once the overlay network is set up the
topology does not change and hence it is easy to provide
all users with the initial topology enabling them to select
routes to the destination. However, the problem arises when
the overlay nodes in turn need to communicate with the
underlying Internet. At this time the mix nodes need to
know the topology of the Internet at least in its vicinity.
This issue contributes to greater overhead at the mix nodes.
An alternative way is to configure routers to perform mix
node operations. The addressing scheme for the routers
(i.e. IP addressing) maintains routing tables which are updated periodically through network protocols. In order to
use routers to perform mix operations, the users will have
to take part in the routing protocols and devote resources to
run the address update protocols irrespective of whether the
user is currently interested in communicating anonymously
or not.
Hence, to realize an ideal solution we need to combine the
two methods described above while eliminating their disadvantages. This ideal solution is to utilize the underlying network to perform the anonymous communication (i.e. avoid
overlay network) while at the same time to make the addressing scheme of this underlying network simple. Hence

we need to look into new addressing and routing schemes
that are simple. The current method of using a single name
space for routing purposes is not feasible when the number
of users/nodes connected to the network increases.

2.1.3

Overhead at Intermediate Nodes

Intermediate nodes in an anonymous communication perform routing as well cryptographic and reordering operations. Some of these operations are computationally intensive. For example, when the initial circuit is created in
Onion Routing [6], public key cryptography is used. Also,
there are some implementations of mix networks that work
on public key re-encryption for path discovery as opposed to
decryption (conventional mix network). Mix nodes also perform reordering in either batch or continuous mode. Usually continuous mode is not used due to the low level of
anonymity it provides. In batch mode, the mix node needs
to maintain a buffer to store the messages it has received
until they are flushed out. The messages are flushed out
when a certain flushing condition is met - the expiration of
a timer or the number of messages in the buffer exceeds a
value. It can be seen that these reordering operations utilize
resources as well.
In addition, when an overlay network is used to perform
anonymous communication it brings with it more overhead.
When the overlay network is initially set up, its configuration needs to be provided to the users and the nodes in the
overlay network need to identify the Internet routers in its
proximity. During normal operation, the overlay nodes will
send messages to the routers which need to be forwarded
to other overlay nodes. The forwarding router will need to
identify the next hop and the router it is associated with
and then transmit the message.
The issue of implementing anonymous nodes in the Internet is related to scalability. There are tradeoffs involved
in implementing mix networks either as overlay networks or
as router nodes with mix operation capability. Both these
cases are associated with their own overhead.

2.1.4

Vulnerability of Intermediate Nodes

Anonymous communication services are susceptible to several external active attacks. There are attacks which interfere with the normal functioning of the communication system (Active) and that do not compromise or involve physical
capture of intermediate nodes (External ). Attacks such as
denial of service and blending attack [11] merely involve interfering with the communication link. While it is very difficult to prevent such attacks, it is necessary to detect and
stop them [5]. Moreover, as mix nodes perform reordering
and cryptographic functions in a secure environment, these
operations should not be visible to other process running at
the same nodes. It is required to architecturally separate
secure tasks from other open and insecure tasks. Also, it
is required to ensure the authenticity of the intermediate
nodes as these nodes are located in various geographic locations and it is difficult for a user to have control over all
these intermediate nodes.
The above discussion points to an architecture where the
different services need to be isolated from each other if required. There exists a technique called virtualization which
achieves isolation and its use in the future Internet has been
proposed previously [10]. Section 3.1 discusses Virtual Service Domain (VSD) in detail.

2111

2.1.5

Support for Multiple Frameworks

different accountability levels. For example, in one case it
may be desirable that the level ni be accountable to only one
other level ni+1 (i.e. one level above i), while in another case
a level ni may be accountable to levels ni−2 and ni+3 , and so
on. Also the various stake holders can reside at any level. It
is not necessary for the user to sit at the lowest level. This
is because it may be required for a service provider to be
accountable to a user at all time. For example, how can a
user be assured that the anonymous communication service
provider does not disclose the operations of a mix node to a
malicious user? The details of these policies and the level of
accountability of all stake holders should be agreed during
the VSD creation.

Anonymous communication solutions are designed for several different frameworks. Different solutions (in different
frameworks) provide varying levels of anonymity depending
on the user’s requirements and the type of attack involved.
For example, synchronous mix cascades are more difficult to
break down using a traffic analysis attack when compared to
asynchronous onion routing networks [6]. It is important to
provide various choices to the user and not restrict his/her
options due to architectural shortcomings. The current Internet architecture is rigid. An anonymous communication
system can be setup in a particular framework. However,
it is difficult to quickly change the framework based on the
user needs and attacker activities. For example, running a
synchronous framework over the Internet requires a synchronization clock and the end-to-end transmission times of the
various messages should be fairly uniform. This is difficult
to achieve due to the vastness and geographic distribution
of the Internet. A user who wants to communicate anonymously with several parties spread out over the globe may
use the conventional asynchronous mode of operation due
to the difficulties associated with setting up a synchronized
clock over large distances. Also traffic analysis requires the
attacker to observe the traffic over a considerable period
of time. So a user who is interested in using the anonymous service briefly may not bother about the synchronous
framework. However, a user who plans to perform long term
anonymous communication with others who are located in
close geographical proximity is at a disadvantage if he/she
is not allowed to use synchronous mix cascades.
Also, re-encryption schemes are used when the source
needs to perform route discovery. To perform route discovery using a re-encryption network, it is necessary for the
return message to take the same path as the initial forward
path. It is possible that certain nodes may temporarily go off
line or change the network policy. The architecture should
be resilient enough to overcome these problems and provide
the required service to the user.

2.1.6

2.2 Identity Management Systems
Identity management systems involve the creation of credentials for users that contain proof of some personal information. These credentials are requested by the user and
provided by some central authority (i.e. a Certificate Authority (CA) or Trusted Authority (TA)). The CA or TA
verifies the information provided by the user and then issues
the credential to the user. The credential can be verified by
using the CA’s or TA’s signature. Several implementation
ideas have been proposed for IDM systems [2, 4, 7, 9] and
we pick out some of the design challenges posed by the implementation of these systems.

2.2.1

Storage of Credentials

Most Identity Management solutions provide multiple credentials for a single user. The user ideally stores these credentials along with other secure information like proof of
identity in a database. This type of system is vulnerable to
a single point of failure. It is safer for the user to store the
credentials over a distributed database. But in the case of
distributed nodes, who will guarantee security of the nodes?
Multiple users will store credentials over these distributed
nodes. How is access control implemented at these nodes?

2.2.2

Accountability

One important but unsolved issue of anonymous communication services over the Internet is the accountability of
anonymous users. A user may use an anonymous communication service to perform illegal activities without being
identified. In fact, this issue of accountability is a stumbling
block which has prevented the widespread use of anonymous
communication services over the current Internet. This is
because of the conflict of interest between individuals using
the Internet and the policy makers (like governments, service providers, etc.). It is necessary to allow genuine uses
to utilize anonymous communication while having a mechanism to ensure their accountability.
The solution for this problem lies partly in software and
partly in architecture. Virtualization which allows separation of services should not only span multiple nodes/resources
but should also allow various levels to be set up in each of
these resources. A multi-tiered accountability structure can
be realized using virtualization. Basically each VSD should
have several levels not conform to some rigid hierarchy. It
should not be assumed that higher levels are compromised
of governmental agencies and are more powerful while the
user resides at the lower levels of the multi-tiered structure.
The policies that govern the various levels should allow the

Usability vs Trust

TAs and CAs are powerful entities with verification and
revocation capabilities. Several schemes assume that these
entities cannot be compromised and they are above corruption. However, this assumption is too strong. It is desirable
to make these entities accountable and an ID management
solution should be resilient to compromised TAs or CAs.
Identity management services are required to perform complex cryptographic operations. Most common users are not
aware of the technical details of the ID management system.
As a result, the user is presented with a simple interface and
the operations are implemented at the lower layers. It is
necessary to ensure that the user can trust the operations
performed in the layers below the user layer. The current
architecture is restrictive because the common user can only
have control over the application layer.

2.2.3

Identity managers

As stated above, the assumption that the trusted authorities of a system cannot be compromised is very strong. As
these authorities sign the digital certificates for the users,
they become the prime targets for attackers. Moreover,
various solutions proposed for providing anonymity and using credentials highly rely on the trusted authorities, who
store and manage user identities as well as their pseudonyms

2112

used for anonymous purposes. Compromising such a trust
authority will reveal the real identity and its associated
pseudonyms to the attackers. Thus, all the transactions
performed by the user will be disclosed.

2.2.4

Dynamically Generated Credentials

Generation of credentials takes time. A trusted authority
issues the credentials, verifies user information, and then
creates a credential in the required format. In addition, a
user should have multiple credentials each containing some
but not all of his/her information. It is difficult for the user
to know in advance how many such certificates that contain
partial information need to be created. Thus, on-demand
creation of credentials is not supported in current solutions.

3. RESEARCH DIRECTIONS
To address the previously presented research challenges,
we first discuss the basic properties of VSDs for service isolation. Then, we will discuss architectural designs for anonymous communications and identity management solutions.

3.1
3.1.1

Virtual Service Domain
Physical and Logical Separation of Services

Logical separation of services can be achieved in the current Internet through the use of overlay networks. The data
transmissions are taken care of in the lower layers of the
protocol stack. All messages are then conveyed to higher
levels where the different applications process their respective messages. Hence logical separation only takes place in
the higher layers of the protocol stack. As a result, there is
no way to ensure the security of services at the lower layers.
In addition, if a particular service is attacked in the lower
layers, it affects the normal functioning of the other services
sharing the same resources.
The possible solution would be to use virtualization techniques to create VSDs for each service. These VSDs provide
a self sufficient framework within which the service can operate uninterrupted by other services. These VSDs should be
created such that they can be distinguished both physically
and logically. A VSD spans multiple nodes and communication links in the network. Virtualization will reduce the
vulnerability of the intermediate mix nodes as they will be
separated from other services and users controlling those services. Creating VSDs is also a precondition for the Internet
to support multiple frameworks. A particular framework
and its associated protocols can be set up to operate within
a VSD. However, it is possible that different services operating in their own VSDs may require communicating with
each other. In order for these logically and physically separated services to communicate with each other, each VSD
should specify an interface which will be used to communicate with other VSDs. At this interface, security policies,
translation capabilities (like address translation) and other
required inter-operability optimizations can be performed.

3.1.2

that it does not contain services and infrastructure providers
(IPs) which are not required by the user. Thus, a VSD is
not a separate segment of the complete architecture. Instead
it is a virtually created architecture that satisfies users’ requirements. VSDs provide the user access to various services
offered by different service providers along with complete
user management capability.
Different services, Service Providers (SPs) and IPs can be
added or removed from a VSD on the user’s request. Addition or deletion of the services or providers from a VSD will
also depend upon the duration of the lease they are issued
for. To append a service, a request is generated from a user;
on receiving the user’s request, the SPs or the IPs leases
a segment of their services or infrastructure to the VSD.
This allocated segment is then appended to the user’s VSD.
Aggregation can be done for each SP or IP for maximally
utilizing their resources. Deallocation can be carried out by
following a similar procedure. SPs and IPs from different
domains can also be added to the VSD by running a similar
procedure. It is evident that VSDs are also a step forward in
creating a user-centric network. In this way, we can enable
the service accountability at the user level.

VSDs are Customizable

The current Internet architecture does not provide a customizable architecture for the user. By customizable architecture, we mean an architecture containing various components customized to user requirements. A customizable
architecture is a virtually created architecture that has the
same properties as a complete architecture. The difference is

3.1.3

Solving Anonymous Communication Challenges
with VSDs

Virtualization is useful in solving the challenges specified
in sections 2.1.3 - 2.1.6. When VSDs are created for individual services, all operations for a particular service will
be performed only within the corresponding VSD (i.e. utilizing the reserved resources). As a result, the overhead in
performing operations related to the anonymous service can
be reduced by reserving the appropriate resources needed.
In short, physical resources are reserved exclusively for the
operation of the mix nodes as opposed to sharing resources
with other services. Also, as each VSD is logically and physically separated, the intermediate nodes are not vulnerable
to attacks from users participating in other services. If any
attacks take place it will affect only the targeted VSD and
hence can be shut down without affecting other services using the Internet. Virtualization is also a requisite for supporting multiple frameworks and to ensure accountability as
explained in sections 3.2.2, 3.2.3.

3.1.4

Solving Identity Management Challenges with
VSDs

A VSD can be created in the real name or for the pseudonym
of the user. When the user wishes to add a SP or wishes to
incorporate some services into his/her VSD, the user has to
provide the required credentials to the SP. In order to append the segment, the user has to obtain a credential from
the organization under which the user is registered. These
credentials can be static or generated dynamically depending upon the user request. A credential is unique for every
SP and satisfies SP specific requirements. The credential is
signed by the user’s organization making it easy for the SP
to perform authentication. Once authenticated the segment
of the service or SP is appended to the user’s VSD. Hence the
user can have access to multiple services from different SPs
by using the same VSD, thus making identity management
easier for the user. In section 3.3 we illustrate through a case
study how the various implementation challenges specified
in section 2.2 are met by VSDs in detail.

2113

3.2
3.2.1

Architectural Design for Anonymous Communications
Addressing Schemes

In the current Internet architecture, the IP addressing
scheme has limitations related to scalability. While IP addressing is effective in uniquely identifying a node connected
to the Internet, all services providers should not be forced to
follow the same addressing scheme. For example, an anonymous communication service may prefer to use its own addressing scheme as opposed to using public known IP addresses. However, allowing each service to arbitrarily follow its own addressing scheme will cause inter-operability
issues. For example, a user may need to use multiple services to accomplish a task and these services may need to
interact with each other. These services may be using different addressing schemes and inhibit the possibility of effective interaction. One possible solution is to have a standard
addressing scheme Addrstd that can be understood by all
services and in addition each service may define their own
addressing schemes. This standard addressing scheme will
serve as a basis of reference. For example, mix networks
could use their own addressing scheme Addrmix that makes
it easier to share the knowledge of the mix network topology and perform anonymous routing. Hence a user who uses
the mix network will use the addressing scheme that works
efficiently within that VSD. However if another service using addressing scheme Addrx needs to interact with the mix
networks, address translation must be performed to translate Addrx to the Addrstd format. The mix network can then
translate the Addrstd format in to Addrmix . Also, an anonymous communication service can design its own addressing
scheme that is scalable. Identifying each person uniquely
mounts to a scalability issue. Using the addressing scheme
described services domains can create their own addressing
scheme that suits the number of users they support. This
flexibility in choosing an addressing scheme will help solve
the network topology and scalability issues of anonymous
communication mentioned in sections 2.1.1 and 2.1.2.
The addressing scheme proposed is also in keeping with
the user centric [8] trend in network addressing. In a user
centric scheme, addressing will be easier for the user to identify the nodes and devices that he/she controls. Each user
will refer to these physical resources by common names that
he/she is familiar with. The user will also connect to devices
owned by others using a simple name (for example, Bob’s
PDA). However, it is up to the addressing scheme to ensure
that such common names used by each user are bound to
a unique identifier. The addressing principles described in
this section can support such user centric schemes. Let’s
say a user u1 has his/her own way of addressing and naming devices denoted as Addru1 and another user u2 follows
the scheme Addru2 . These two users can communicate with
each other using the translation services and Addrstd as the
intermediate addressing scheme.

3.2.2

Flexible and Customizable Architecture

As specified in section 2.1.5 users must be given the ability
to choose the type of framework. In order for a user to have
a flexible and customizable architecture, a VSD with various components that are arranged and configured as desired
by the user is required. By components, we mean physical
resources, protocols and other network related policies.

3.2.3

Multi-tiered Architecture without a rigid Hierarchy

The accountability should be provided by anonymous communication services. Similarly, the service provider must be
able to ensure that the services they claim to provide are
verifiable. This relates to the accountability issue we discussed in section 2.1.6. To realize such a system, a multitier architecture can be used within each VSD. Each such
tier is a logical level created in the VSD. This multi-tier architecture spans several physical resources. However, this
multi-tier architecture must not follow a rigid hierarchy. It
is not necessary for a higher level to be more powerful or to
be at a higher level of abstraction than a lower level. For example, a user of anonymous services and the service provider
may reside in their own tiers. The user can invoke certain
operations on the service provider’s tier if certain conditions
are satisfied and vice versa. These conditions for invoking
operations and the actual operations themselves are decided
by policies agreed upon by all the stake holders. Basically,
these policies are designed such that the user and the service
provider are accountable for their actions and in case one of
the parties suspects foul play, operations can be invoked on
the other’s tier.

3.3 Architectural Design for IDM
We have various domains (like .edu, .com, .org etc) in
our present Internet architecture which we will classify as
different domains. Every domain has various subdomains
(universities registered under the domain .edu). As the user
in the Internet will always be accessing the services offered
by a SP registered under a certain service domain (for example, a user willing to access e-commerce services would be
utilizing the services of a SP, like e-bay, Amazon, etc., registered under .com domain), the user will always be a part
of that domain. However, current Internet being network
centric requires the user to create a new profile not only for
every domain but also for every SP registered under those
domains. The user often provides unnecessary information
along with his/her complete identity to the SP in order to a
create profile and gain access control. This leads to various
privacy related issues like profiling attack and more serious
problem of identity management.
In following section, we discuss how VSD can be used to
solve problems in IDM discussed in section 2.2. Let’s assume
that a user who wishes to create a VSD is a member of the
Arizona State University (ASU) domain which is an educational institute registered under the .edu domain. Also we
assume that the user has provided his/her identity details to
ASU at the time of system initialization. As the probability
of ASU being compromised can be assumed to be low, the
user’s trust on the system is high. Using virtualization, the
SPs allocate a segment of their services to the VSD once the
mandatory policies are satisfied by means of user’s credentials. Policies specific to the SP are referred to as the details
or the part of information that the SP would need in order
to authenticate the user.

3.3.1

Storage of Credentials

Credentials are required by the user to add different services to his/her VSD. Once the services are added using
the credentials, depending upon the credential type (oneshow or multi-show), determining the credential storage is
the next logical step. Storing of all user credentials at a sin-

2114

gle place will lead to the single point of failure problem. Distributed storage is more efficient but the security provided at
the nodes comes under question. Hence our proposed solution is to have a semi-distributed system. A semi-distributed
system shares most features of a full-fledged distributed system except that the information is stored in a distributed
fashion only among the nodes within a restricted subdomain
like ASU. In addition, the information is only accessible by
the users of the associated VSD and not by any party belonging to a different VSD. Thus, the user is not vulnerable
to the single point of failure as his/her details are distributed
but still the information is secure among the members of the
domain. Even when a single node is compromised, most of
the information is preserved from the outside world.

3.3.2

credential that contains the information required by the SP.
The issued credential will prove the authenticity of the user
and satisfy the SP’s policies.

4.

Usability Vs Trust

Most of the users accessing the Internet do not understand complex cryptography protocols that are running at
the back-end. A user friendly interface running at an organization of a VSD can be used to aid the construction of the
VSD for the user. Due to involvement of credentials for appending and removing the services and providers, the user’s
efforts for extending or reducing VSD segments are minimal
due to the requests (appending and removing requests), thus
making the VSD usable. As the user is registered under a
sub-domain, the user can easily rely on the certificates for
the credentials issued by the organization.

3.3.3

5.

Identity managers

As discussed in section 2.2.3, current Internet architecture assumes that the trusted authorities cannot be compromised. Moreover, all the anonymous communication systems proposed provide anonymity by means of pseudonyms.
Most of the systems rely heavily on trusted authorities, who
know user’s real identity and pseudonyms. Although the
user is anonymous to the SPs or other users, the user’s
pseudonyms are known to the trusted authority. Thus, subverted authorities can easily profile the user and reveal his/her
information to the attacker. To solve this problem, we propose a solution to separate the responsibility of managing
real identity and pseudonyms among different trusted authorities in the system. One authority will only manage
user real identity and will not contain any information with
respect to the user’s pseudonyms. On the other hand, another authority will be responsible for managing the user’s
pseudonyms and will not contain any information about
the user’s real identity. Thus the user’s real identity and
pseudonyms are managed by different trusted authorities.
In this way,to link user’s real identity and all associated
pseudonyms, an adversary will have to compromise both
the trusted authorities. This can be safely assumed to be a
difficult task to accomplish in the real world.

3.3.4

Dynamic Generation of Credentials

If a user accesses the service of a certain SP more frequently than others, having static credentials is useful. However, if the user wants to add new segments from a new SP to
the VSD, credentials can be generated dynamically as per
the requirements that satisfy the SP’s policies. Dynamic
generation of credentials only requires submission of the request from the user which specifies the policies (or policies
can already be known to organization) of the SP. On receiving this request, the organization creates and signs the

CONCLUSION

In this paper, we discussed various architectural issues
that make it difficult to implement privacy and security services on the current Internet. One of the main causes for
these problems is the fact that the Internet was not designed
with privacy protection as one of its driving factors. Also,
the flexibility of the current Internet architecture is limited. As a result, it has been difficult to incorporate services
with special requirements into the Internet. We examined
the challenges in implementing anonymous communication
and identity management systems in the Internet. From the
analysis of these challenges we propose virtualization techniques to build an architecture using VSDs. All other recommendations for a future architecture made in this paper
are related to creation and manipulation of VSDs.
However there are still some issues that need to be resolved. The most important of these concerns is inter-VSD
communication through the provision of interfaces. It is
also important to provide an integration of ID management
solutions and anonymous communication systems to achieve
both privacy and accountability.

REFERENCES

[1] Free Haven Project http://freehaven.net/index.html.
[2] J. Camenisch. Design and implementation of the
idemix anonymous credential system. Proceedings of
the 9th ACM conference on Computer and
communications security, pages 21–30, 2002.
[3] D. Clark, J. Wroclawski, K. Sollins, and R. Braden.
Tussle in cyberspace: defining tomorrow’s internet.
IEEE/ACM Transactions on Networking (TON),
13(3):462–475, 2005.
[4] S. Clauß and M. Köhntopp. Identity management and
its support of multilateral security. Computer
Networks, 37(2):205–219, 2001.
[5] G. Danezis and L. Sassaman. Heartbeat traffic to
counter (n-1) attacks. Proceedings of the Workshop on
Privacy in the Electronic Society (WPES 2003),
Washington, DC, USA, October, pages 89 – 93.
[6] R. Dingledine, N. Mathewson, and P. Syverson. Tor:
The second-generation onion router. Proceedings of the
13th USENIX Security Symposium, 2, 2004.
[7] M. Koch. Global Identity Management to Boost
Personalization. Schubert, Petra und Uwe Leimstoll
(Herausgeber): Proceedings of the Ninth Research
Symposium on Emerging Electronic Markets, pages
137–147, 2002.
[8] R. Morris and F. Kaashoek. User Information
Architecture. NSF NeTS FIND Initiative, 2006.
[9] T. Olzak. Unified identity management.
InfosecWriters, 2006.
[10] L. Peterson and J. E. Wroclawski. Overview of the
GENI Architecture. GENI Design Document, 2006.
[11] A. Serjantov, R. Dingledine, and P. Syverson. From a
trickle to a flood: Active attacks on several mix types.
Proceedings of Information Hiding Workshop (IH
2002), 2578/2003:36–52, 2002.

2115

Mobile Netw Appl (2015) 20:297–307
DOI 10.1007/s11036-015-0617-0

Establishing A Personal On-Demand Execution
Environment for Mobile Cloud Applications
Huijun Wu1 · Dijiang Huang1 · Yan Zhu2

Published online: 21 May 2015
© Springer Science+Business Media New York 2015

Abstract A distributed mobile cloud service model called
“POEM” is presented to manage the mobile cloud resource
and compose mobile cloud applications. POEM provides
the following salient features: (a) it considers resource management not only between mobile devices and clouds, but
also among mobile devices; (b) it utilizes the entire mobile
cloud system as the mobile application running platform,
and as a result, the mobile cloud application development is significantly simplified and enriched; and (c) it
addresses the interoperability issues among mobile devices
and cloud resource providers to allow mobile cloud applications running cross various cloud virtual machines and
mobile devices. The proposed POEM solution is demonstrated by using OSGi and XMPP techniques. Our performance evaluations demonstrate that POEM provides a true
elastic application running environment for mobile cloud
computing.

 Huijun Wu

Huijun.Wu@asu.edu
Dijiang Huang
Dijiang.Huang@asu.edu
Yan Zhu
zhuyan@ustb.edu.cn
1

School of Computing, Informatics, and Decision Systems
Engineering, Arizona State University, 699 S Mill Ave,
Tempe, AZ 85281, USA

2

School of Computer and Communication Engineering,
University of Science and Technology Beijing,
Beijing 100083, China

Keywords Mobile application · Cloud computing ·
Offloading · Service oriented architecture · OSGi · XMPP

1 Introduction
In mobile clouds, mobile devices and cloud resources compose a distributed mobile application running environment,
where a mobile application may consume resources from
both local and remote resource providers who provide computing, networking, sensing, and storage resource provisioning. Mobile devices can serve as either service consumers
or service providers in the mobile cloud, in which the
cloud boundaries are extended into the mobile domain [1].
Mobile applications may require a mobile device to interact with other mobile devices and cloud resource providers
to achieve desired computing, storing, collaboration, or
sensing features.
An ideal mobile cloud application running system
should enable mobile devices to easily discover and compose cloud resources for its applications. From mobile
resource providers’ perspectives, they may not even know
what applications are using their resources and who may
call their provisioned functions beforehand. In this way,
the mobile application design should not be applicationoriented; instead, it should be functionality-oriented (or
service-oriented). For example, the video function of a
mobile device should provide general interfaces that can
be called by multiple local or remote functions in the
runtime. To achieve this feature, we can consider these Provisioning Functions (PFs) as the fundamental application
components in the mobile cloud, which can be composed by
mobile cloud service requesters in the runtime. As a result,
mobile cloud can significantly reduce the mobile application development overhead and greatly improve the agility

298

and flexibility to build a personalized mobile cloud computing system that can be customized for each mobile user.
A simple vehicular video sensing example is used to
illustrate the above described mobile cloud features. Alice is
driving on the road and her smartphone, which is mounted
on the front dashboard for navigation, has the basic video
capture PF. Bob is driving next to Alice and is running an
image processing PF in his phone and wants to utilize more
video clips from the neighboring vehicles in order to reconstruct the road situations around his vicinity. Then Bob can
consume Alice’s video PF to reconstruct the view of the
entire road segment captured by their video cameras. Moreover, Bob wants to share his captured video clips to his
friend Carol who is managing a traffic monitoring website
that posts videos from smartphone users for the public to
access the realtime road traffic information. As the result,
Bob can share his augmented traffic view to Alice, i.e.,
through Carol’s website. In this mobile application scenario,
all participants have them basic PFs: (a) Alice: video capture, (b) Bob: video augment, and (c) Carol: video display.
Note that a PF can be called by multiple other PFs for different application purposes, and they altogether can build
several mobile cloud applications.
There are several challenges invoked by the above
described application scenario. The first challenge is that
knowing the status of mobile devices, e.g., online/offline
and runtime information (such as battery, computing power,
connectivity, etc.), is difficult due to the mobility of mobile
users. The second challenge is that knowing the available
PFs on each mobile device is not a trivial task. Currently,
there is no such a common framework allowing mobile
devices for exchanging the available PFs information and
running such a system in a distributed environment. The
third challenge is to compose PFs crossing various hardware
and software platforms, which demands a universal programming and application running environment with little
compatibility issues.
To address these challenges, we present a new
mobile cloud application running system, which is called
POEM (Personal On-demand execution Environment for
Mobilecloud computing), as shown in Fig. 1. POEM treats
each mobile device as a PF provider. In addition, POEM
is designed based on the mobile cloud framework, where a
dedicated Virtual Machine (VM) is assigned to each mobile
device providing computing and storage support. Moreover,
PFs can be offloaded/migrated from a mobile device to
its assigned VM. Thus, the VM can not only run mobile
devices’ PFs (i.e., as shadows), but also can run extended
PFs that mobile devices may not have the capacity to execute. Thus, we also call the VM in the POEM framework
as ESSI (Extended Semi-Shadow Image). Collectively, the
PFs provided by a mobile device X and its corresponding
ESSIX is denoted as {P F }X . POEM regards both mobile

Mobile Netw Appl (2015) 20:297–307

Fig. 1 Overview of POEM system

devices and their dedicated ESSIs as PF providers. As a
result, the mobile user’s applications can be composed by
PFs from local PFs (may be offloaded/migrated to its dedicated ESSI) and/or remote PFs (may run on remote mobile
devices or their dedicated ESSIs).
To demonstrate the proposed POEM solutions, we implemented a pilot POEM system based on OSGi [2] and
XMPP [3] techniques. In summary, the contributions of the
presented research is highlighted as follows:
•

•

Social mobile cloud computing: POEM solution
enables mobile cloud application to utilize social network power, i.e., in addition to the discovered PFs
through the mobile cloud system, mobile user can establish mobile cloud applications through their trusted
social connections. In this way, POEM applications
not only can use the resource in cloud by offloading
resource intensive components but also can use services
provided from their social connections.
Versatile and personalized application offloading,
migration, and composition: POEM maintains available mobile cloud resource and allows users choosing a
mobile cloud application by using different approaches
(offloading, migration, and composition) based on the
available system resources and their personalized application requirements.

The paper is organized as follows. Section 2 introduces
related work and compares POEM to them. Section 3
describes systems and models. Section 4 discusses POEM
design and implementation, respectively. Section 5 presents
evaluation results. Section 6 discusses the application of
POEM platform in vehicle cloud scenario. Finally, Section 7
concludes the paper.

Mobile Netw Appl (2015) 20:297–307

2 Related work
Most of the research focuses either on mobile task partition
and composition or on offloading techniques. μCloud [4]
describes a framework for mobile cloud application composition from heterogeneous software components. μCloud
presents mobile cloud application as a directed graph whose
nodes are categorized as mobile, cloud, and hybrid. μCloud
is a static mobile cloud application model, which requires
a lot of work for programmers to partition application
and decides which partition runs on which part of the
cloud. eXCloud [5] focuses on offloading and migration:
it migrates Java Virtual Machine (JVM) runtime to cloud.
However it migrates only the top portion of runtime stack,
rather than the whole virtual machine, to cloud using Stack
On Demand (SOD) [6] migration technique. eXCloud triggers offloading processes according to local resource availability by capturing resource exception. So performance and
energy gain are not optimized. CloneCloud [7] maintains a
clone of mobile device in the cloud. The mobile device and
its clone in cloud is synchronized. The process running on
phone can be set to sleep state and transfer the execution
state to its clone. When finishing execution on clone, the
process states are transferred back to mobile device and integrated into the original process. CloneCloud can deal with
dynamic offloading, however it requires synchronization
between mobile device and cloud, which is not always satisfied in mobile cloud application scenario due to unstable
mobile connection to cloud.
Some frameworks generate two versions of application
for mobile device and cloud separately. MAUI [8] and
ThinkAir [9] use similar offloading technique and both have
their own decision making algorithms. They require the programmer to mark the offloadable method and they generate
two versions of an application: one is for mobile execution
and the other is for cloud. The offloading decision is made
according to execution history and energy consumption.
ThinkAir in addition considers high availability in unstable connection scenario. Cuckoo [10] focuses on offloading
technique. Cuckoo generates local and remote version of
an Android Service component, which is similar to MAUI
and ThinkAir. Cuckoo requires programmer support to build
the final application and it’s offloading decision making
algorithm is static.
Some frameworks apply loose couple between mobile
devices and clouds. Zhang et al. [11] proposed a web based
mobile cloud application model. It defines weblet as independent compute unit that provides web service. Weblet can
be migrated based on the decision of its cost model. Zhang
et al. model restricts application structure to User Interface
(UI), weblet and manifest, which force application components to communicate through web service. Satyanarayanan
et al. [12] proposed cloudlet solution for offloading. The

299

cloudlet is virtual machine that is near the mobile phone and
that is usually connected to WiFi access point. The offloading is achieved through virtual machine migration, which
increases migration load and leads to high latency. Besides
the above work, [13–17] discussed the mobile cloud system
in specific areas.

3 Systems and models
This section presents application and execution model of the
presented POEM system.
3.1 Application model
POEM is implemented based on OSGi framework [2] that
is a general purpose, secure, and managed Java framework
that supports the deployment of extensible and downloadable applications [2]. Due to the popularity of Java, OSGi
framework is compatible with major operating systems for
both desktop and mobile device systems. The framework
is stacked in layers: from bottom-up, module layer, life
cycle layer, and service layer. The framework defines a
unit of modularization, called a bundle, i.e., “PF” in the
POEM. In the later descriptions, we do not differentiate
the terms bundle and PF. In POEM, a PF is comprised of
Java classes and other resources, and is deployed as a Java
ARchive (JAR) file. PF sits on the top of stacked layers
and interacts with them through PF context. Module layer
and life cycle layer handle PF installation and activation.
PF can be installed/uninstalled and started/stopped. Service
layer has a service registry and handles service publication and discovery. A service is a normal Java object that is
registered under one or more Java interfaces with the service registry. PFs can register services, search for them, or
receive notifications when services’ states change. When
PF is installed, the framework must cache the PF JAR file.
A SERVICE RANKING property may be specified when
a service is being registered. The service with the highest
ranking is returned when the framework receives service
query. Before the service is consumed, it may become a
stale reference. Service tracker is usually used for service
consumer to prevent stale reference by obtaining reference
when consumption happens. Besides local service activities,
a distribution provider can export service to another framework by creating end point or import service from another
framework by creating proxy for service composition, and
then registering the proxy as an imported service.
POEM models a mobile cloud application as a set of
PFs. The PF may provide class definitions and host services that implements PFs. POEM does not differentiate PFs
on mobile devices and PFs on their ESSIs as the PFs may
be migrated from mobile side to cloud side or vice versa

300

without any modification. The uniform PF format make
PFs reusable and reduces develops’ workload by avoiding
developing separate PFs for specific platform. The application may use services provided by local or remote PFs. The
application can migrate PFs between mobile devices and
ESSIs without disrupting the other active PFs.
POEM achieves social feature through an implemented
XMPP [3] system within the MobiCloud system [18].
The availability information of the system resources and
mobile devices is maintained through a decentralized clientserver architecture, where every mobile cloud entity needs
an address called a JabberID (JID). JID is presented in
the form of user@domain/resource. Domain represents the
XMPP service provider, user represents virtual identity in
the domain, and resource identifies connection to an XMPP
server. Three basic status services are achieved through
XMPP: message, presence, and info/query(or iq). POEM’s
service discovery protocol provides two discovery methods: one enables discovering information about an entity;
and the other enables to discover the items associated with
an entity.
In POEM, each entity, i.e., a mobile device or an ESSI,
runs an OSGi framework, which is identified uniquely by
its JID. One POEM entity discovers services hosted by
his/her friends through XMPP service discovery protocol
and XMPP publish-subscribe protocol. Mobile applications
offload PFs to ESSIs through XMPP file transfer protocol,
and the data exchange with remote application in POEM is
through XMPP iq communication.
3.2 Execution model
According to previous application scenario, there are three
fundamental execution patterns in POEM, as shown in
Fig. 2. The first pattern describes how one PF discovers
remote available PFs, which is shown in Fig. 2a. PF b hosts a
service and it publishes the service through local POEM for
remote PF to discover. Then PF a can discover the published
service on remote side with local POEM PF’s help. One prerequisite for a to discover and use service of b is that they
are mutual friends, in other words they in each other’s contact list. PF a does not know that PF b is running on remote
side because POEM pretends that b is running locally. Thus,
a programmer does not need special treatments in coding
when developing PF a.
The second pattern presents how an application recruit a
service provided by a remote PF, which is shown in Fig. 2b.
The PF c sends method invocation parameters, which are
transferred by the POEM on local side and then on remote
side, to the destination PF d. Then, the service result returns
along the reverse route from d back to c. PF c also regards it
is calling a local target d due to POEM transparent transfer,
and d also thinks local c is calling it.

Mobile Netw Appl (2015) 20:297–307

Fig. 2 Execution patterns in POEM

The third pattern presents how one PF migrates to a
remote entity. A POEM PF initializes the migration process. There are two types of migrations: pull and push. In
pull migration, the POEM PF on the right side sends request
to left side POEM PF, and then the later fetches and transfers the target PF e to the right side. In push migration, the
POEM PF on the left side transfers PF e to the remote side.
The source keeps the PF e active during transfer to provide
the failsafe when the transferring is not successful.

4 POEM design and implementation
Figure 3 illustrates the overall design of POEM system.
The POEM Manager monitors local services, tracks service
state change, maintains local PF repository and responds
to remote service queries. Its networking component also
maintains XMPP connections to XMPP peers that provides
the communication and signaling infrastructure among
mobile devices and their ESSIs. The POEM composition
component creates local proxy for remote service provider
that responds to service request by transferring the request
to the remote PF, and then getting the result to the local
PFs. Based on a systematic decision model, POEM initiates

Mobile Netw Appl (2015) 20:297–307

Fig. 3 POEM design and components

301

operations will not be flooded to end mobile devices. The ESSI
POEM Manager also maintains the mobile device availability information and provides its reachability information to
its trusted POEM peers. When the ESSI POEM Manager
receives the service discovery message, it replies with its
available PFs with the available remote service interfaces.
POEM Manager also monitors local service changes and
notifies its friends. This is done through a publishing procedure. POEM Manager first registers a publish node (i.e., a
virtual node in the XMPP server) under its JID. Thus, when
local service status changes, POEM Manager can post the
notice on its publish node and its friends get notified and
update their PFs availability database.
4.1.2 POEM service composition

the migration operations for PF offloading. In the following sections, we describe each component within the POEM
framework.
4.1 Distributed POEM service platform
POEM’s networking and signaling system is deployed based
on XMPP approaches. The communication between POEM
entities (i.e., mobile devices and ESSIs) is full duplex compared to half duplex HTTP approach deployed by many
web-based service frameworks. In a distributed execution
environment, any entity can be both a client and a server
at the same time, which is different from web-based service models where clients and servers are explicitly defined.
Moreover, POEM inherits the XMPP trust and identity management framework, where every POEM entity is authenticated when joining the system and data transferred are also
protected through cryptographic approaches. As a result, the
PF offloading and PF compositions can utilize the XMPP
trust management framework with fine-grained access control capabilities. Furthermore, POEM entities need to provide their presence information to indicate its availability
information in real-time, which is as well used to indicate
their service status. Finally, POEM must provide the support for secure file transfer, service discovery, and service
composition, in which the XMPP provides the fundamental
support to realize these features.
4.1.1 POEM service discovery and publishing
POEM service discovery is designed based on XMPP
service discovery protocol and XMPP publish-subscribe
extension. A PF may reside on a mobile device or its
corresponding ESSI. The ESSI takes the responsibility to
represent the mobile user for any PF related operations and
the mobile device POEM Manager can frequently update
its available PFs information to the ESSI. In this way, the
main POEM service discovery, migration, and composition

When POEM discovers service provided by remote POEM
entities, it tries to create a proxy for that service so that
remote PF can be used locally. POEM uses Java dynamic
proxy technique to create proxy. Dynamic proxy requires
that the target interface’s Class instance must exist. To
have remote service interface’s Class instance in local
OSGi framework instance, POEM fetches PF JAR file
corresponding to the target service from remote POEM
framework. POEM Manager installs the PF, and then the
target Class instance is available and proxy generation is
done.
POEM uses JavaScript Object Notation (JSON) over
XMPP for service composition because JSON is lightweight
and has abundant expression ability. The service proxy generated by POEM Manager captures local service requests
that are then converted into JSON requests. Then the
JSON request is sent to XMPP channel to the destination. The destination POEM Manager receives the JSON
request and translates it to method invocation on service provider’s object. It then returns the result in form
of JSON back to the source POEM Manager. Then
the JSON response is decoded and returned to calling
object.
4.2 PF offloading
When application decides to offload a service provider
object and migrate it to cloud, POEM Manager chooses to
send the object’s byte code to cloud and start the object
from byte code. How to choose POEM PFs to be migration is based on several conditions described as follows:
First, thread migration solution is not adopted because some
objects that exist in the same thread have to run on mobile
device, such as user interfaces and sensors. Second, an
application usually wants to migrate only the compute intensive operations rather than the whole thread. Third, object
state is not maintained because the insight private details of

302

the object to be migrated cannot be fetched due to Java security management. Our recent practice suggests that service
implementation should be stateless, so that the object states
will not bother POEM like Representational State Transfer
(REST) does [19].
4.2.1 Migration
The service provider object offloading process follows a
three-step approach: First, the target PF JAR file is transferred to ESSI and started. Then, a proxy object is created
to intercept and capture service request to remote target
service. Finally, the PF containing target service provider
object is stopped.
The migration happens according to the migration decision module command. POEM constructs the migration
decision module as plug-in framework. The previous work
[20–22] on decisions can be applied. User can develop his
own migration decision strategy plug-ins and install the
strategy bundle into POEM, which not only provides the
flexibility for user customized migration strategy but also
scales the POEM intelligence.
4.2.2 PF isolation
The migrated PFs are running in the surrogate POEM
framework for providing service for its origination. These
PFs may interact with the POEM framework and interrupt the PFs that belong to surrogate host. The PF isolation is required to protect the surrogate POEM framework and cease the potential attack from the migrated
PF.
The POEM manager initializes a separate PF container
for each friend who wants to offload his PF. The PF container is duplication of the surrogate host POEM framework.
The only difference is that this nested PF container is
empty and dedicate for the corresponding friend. The friend
identity is stored and managed by identity manager. The
surrogate host defines the accepted PF policies that are
enforced by policy manager.

Mobile Netw Appl (2015) 20:297–307

4.3 POEM manager implementation
POEM Manager consists of several objects as shown in
Fig. 4. They are categorized as three sets - XMPP connection and related listeners, PF context and related listeners,
and proxy and migration management. The three object sets
represent three POEM functional sets: XMPP connection
set represents remote POEM framework; PF context set represents local POEM framework; and proxy and migration
management represent core POEM logic and operation that
connect the other two parts.
4.4 Seamless offloading
POEM Manager registers a service with an Java interface
that contains a method to do service migration. Service
migration involves two framework instances that are source
framework and destination framework. The offloading process can be illustrated using the following application scenario. The source is device 1 and the destination is an ESSI.
The migration method is called on device 1. Service name
and destination XMPP identity are passed to the migration
method. The migration process consists of five steps as follow. First, a migration notice is sent by device 1 to the
ESSI. Along with the migration notice, the PF JAR file that
owns the indicated service is transferred from device 1 to
the ESSI. Second, POEM Manager in the ESSI starts the PF.
When PF is running, services including the indicated service

4.2.3 Connection failsafe
The connection between mobile device and cloud is usually
not stable as mobile device moves. When the connection is
lost, POEM Manager restarts the PF that has been stopped in
offloading process. The recovery process has the following
two steps: First, the target PF is started. Then, the proxy service is unregistered and the proxy object is destroyed. The
first step prepares for receiving service request. The second
step destroys proxy, which makes the target service provider
object be the first in the ranking order to receive service
request.

Fig. 4 POEM manager details

Mobile Netw Appl (2015) 20:297–307

303

are registered. Third, POEM Manager in the ESSI is notified with service changes in last step. it unregister existing
proxy under the same service name. Then it publishes the
new services to the ESSI’s publish node. At this point, both
sides have the running PF that provides services to local
PFs. Fourth, POEM Manager on device 1 is notified due to
the publishing in last step. it creates the proxy for the published services with a higher ranking. Then it stops the local
PF. At this point, the PFs on device 1 are consuming services
provided by the ESSI. The sequence diagram of migration
process is shown in Fig. 5.
Besides device 1 and the ESSI, a third framework
instance on device 2 is using the service being migrated.
When POEM Manager in the ESSI signals the new service,
POEM Manager on device 2 creates proxy for the new service with a higher ranking as device 1 does. When POEM
Manager in the ESSI signals the service recycling, POEM
Manager on device 2 recycles the proxy for that service.
Other PFs on device 2 are not disturbed during the process.

contains a Felix OSGi framework instance that hosts POEM
Manager runs on Android Motorola phone A855. The
phone’s parameters are 600MHz CPU and 256M memory.
The Android version is 2.2.3. The virtual machine is with
1GHZ CPU and 512M memory, which runs Ubuntu 11.10.
Four applications are used to evaluate the POEM performance. They are Fibonacci sequence generator, NQueens puzzle, nested loop and permutation generator. The
Fibonacci application generates Fibonacci sequence in a
recursive manner. Its time complexity is O(2n ) and its stack
usage is high due to recursive algorithm. The N-Queens
application calculates all solutions for input chessboard size.
Its time complexity is O(n2 ) and its stack usage is also high
due to recursive algorithm. The nested loop application contains a six layer loop which leads to time complexity O(n6 ).
The permutation application’s time complexity is O(n!) and
uses little memory. Experiment result is obtained by running
the application 50 times for every scenario and averaged.
Between two consecutive executions there is a pause of 1
second.
The experiments are run under two scenarios:

5 Performance evaluation

•
•

This section describes POEM performance evaluation
through both macro-benchmarks and micro-benchmarks.
Then migration evaluation is then followed.
5.1 Methodology
The POEM Manager is implemented on Felix [23] OSGi
implementation version 4.0.3. Mobile application that

Phone: Applications are run only in phone.
WiFi: Phone is connected to the ESSI through WiFi.

The WiFi connection has averaged latency of 70 ms, download bandwidth of 7 Mbps, and upload bandwidth of 0.9
Mbps. Ping is used to report the average latency from the
phone to the ESSI, and Xtremelabs Speedtest, downloaded
from Android market, is used to measure download and
upload bandwidth.
5.2 Macro-benchmarks

Fig. 5 PF migration sequence

For typical input parameter values, four applications are run
on phone and in the ESSI separately. The application running time is recorded in Table 1. By subtracting time on
phone and in the ESSI, the max speed up is put in the last
column of the table. However, the max speed up is seldom
achieved due to cost of communication and proxy. This cost
changes little while offloading benefit changes much, so
there should be some point when the benefit of offloading
surpasses its cost giving application net gain.
Fibonacci application takes a sequence index number
and calculates the corresponding number in the Fibonacci
sequence. Figure 6a shows execution time of Fibonacci
application. The intersection of execution time on phone
and WiFi offloading is the Boundary input value (BIV) [9]
that shows the offloading benefit starting point. N-Queens
application takes chess board size and calculates all solutions and return solution number. Figure 6b shows execution
time of N-Queens application. The execution time on phone
rises dramatically as the chessboard size increases one scale.
Offloading offers benefit after chess size is larger than 10.

304

Mobile Netw Appl (2015) 20:297–307

Table 1 Execution time for phone and cloud, and the potential max
speed up by offloading
Case

Input

Phone
(ms)

Cloud
(ms)

Max speed
up (ms)

Fibonacci

26
27
28
29
30
8
9
10
11
12
14
15
16
17
18
5
6
7
8
9

59.25
99.5
156.75
251
408.25
11
39.75
222.75
1593.5
9630.25
157
332
276.75
392.5
560.25
1.25
1
6.5
49.25
1124.75

2
3.05
5
7.65
12
1.1
3.05
12.2
64.4
377.2
15.05
21.55
28.6
39.85
54.35
0.25
0.25
0.4
2.05
12.1

57.25
96.45
151.75
243.35
396.25
9.9
36.7
210.55
1529.1
9253.05
141.95
310.45
248.15
352.65
505.9
1
0.75
6.1
47.2
1114.65

N-Queens

Nested loop

Permutation

Nested loop application takes loop times and execute loop
without memory operation. The execution time on phone
is convex, which means it is less than exponential increase

compared to the above two applications that requires both
computing and storage. The execution time of offloading
increases slowly. The Permutation application takes a max
number N and returns count of prime number within the
range (1,N). The prime number searching algorithm used
is Permutation algorithm. The execution time increases on
phone, however the execution time for offloading approach
almost remains same.
The offloading line of four applications is increasing
slowly compared to phone line. As the phone line starts
from a low point, which indicates the application runs fast
when input is small, the offloading line and phone line
intersects finally. Comparing offloading line and the ESSI
execution time column in Table 1, the slow increase is reasonable due to execution time increase slowing in the ESSI
as well. Besides, the starting point of offloading line is
higher than phone line, so there must be cost for remote
method invocation.
5.3 Micro-benchmarks
This experiment measures service invocation time. This
time is measured on phone where is service consumer side.
The remote service consuming time consists of three parts:
marshaling time of both consumer and provider sides, network transfer time and actual execution time. The result is
shown in Figure 7.
Figure 7 shows time against different input parameters.
From the table, the actual execution time is similar to the
execution in the ESSI of column the ESSI in Table 1. At

Fig. 6 Execution time of four applications for both offloading and local execution scenarios

Mobile Netw Appl (2015) 20:297–307

305

Fig. 7 Time cost of each steps in remote service invocation process

the beginning, execution time is nearly zero. The execution
time increases along with input parameter value increases.
Figure 7 shows that marshaling time is relatively small compared to network delay. Figure 7 also shows that the main
cost for remote method invocation is network delay around
BIV point. And marshaling time and network time against
different input parameters are approximately identical. The
marshaling and network cost decides the start points of
offloading line in Fig. 6a–d. And execution time decides the
trend of those offloading line. If the network delay or the
marshaling is reduced in some situation, the offloading line
will drop and then BIV point will go to left, which means
the range of benefit increase and application components are
supposed to be offloaded to the ESSI. In another perspective, if component’s ratio of computation cost to network
cost increases, it is better to offload that component to the
ESSI.
Besides service invocation time, the proxy generation
time is also measured. The proxy generation time indicates
POEM initialization time, which is paid once at starting
POEM Manager.
5.4 PF migration
This experiment measures PF migration time. PF migration time period starts when service migration command is
issued and ends when proxy for migrated service is available. The result is in Table 2 which shows that the migration
time is nearly same for the tested four applications. This is

reasonable because the migration time is mainly the time of
transferring PF bundles on the network and these four PF
bundle sizes are similar.

6 Case study
The POEM framework is used in the MIDAS [24] project,
which develops the system that proactively manages the
interacting traffic demand and the available transportation
supply. This project demonstrates the synergistic use of
a cyber-physical infrastructure consisting of smart-phone
devices; cloud computing, wireless communication, and
intelligent transportation systems to manage vehicles in the
complex urban network – through the use of traffic controls, route advisories and road pricing – to jointly optimize
drivers’ mobility and the sustainability goals of reducing
energy usage and improving air quality. A key element of
MIDAS is the data collection and display device PICT that
collects each participating driver’s vehicle position, forward
Table 2 PF migration time cost
Cases

Migration time (ms)

Fibonacci
N-Queens
Nested loop
Permutation

272
335
290
304

306

Mobile Netw Appl (2015) 20:297–307

images from the vehicle’s dashboard, and communication
time stamps, and then displays visualizations of predicted
queues ahead, relevant road prices, and route advisories.
6.1 Setup
The same smartphone Motorola A855 in previous evaluation is used as PICT device. The smartphone captures
the road image which is processed by calling the image
process PF exposed by one VM in the cloud as shown
in Fig. 8. The smartphone communicates with the cloud
through WiFi while the other network configuration is the
same as previous evaluation.
The image process part is implemented based on
OpenCV [25] library. We used the bilateral filter as the
example PF for image processing. Bilateral filter can reduce
unwanted noise very well while keeping edges fairly sharp.
One of the parameters to the bilateral filter is the filter size
that is the diameter of each pixel neighborhood that is used
during filtering. We run the application against different filter size and try to find the BIV for this application. The test
image size is around 45 KB and it is with 800 × 600 pixels.
6.2 Evaluation
We measure the time cost of three indicators in this scenario
as shown in Fig. 9. The ‘phone’ series indicates the time cost
without remote service composition, which means all the
computation happens on the smartphone locally. The Fig. 9
shows the ‘phone’ series grows drastically from 509 milliseconds to 17,847 milliseconds on average along with the
filter size increases from 2 to 20. Since the VM in the cloud
is much more powerful than the smartphone, the time cost

Fig. 9 Execution time of image process application for local, cloud
and offloading execution scenarios

on the same filter size parameter is much less than the time
spent for phone local execution. The ‘cloud’ series shows
the time spend for the image process in the VM, which
grow from 5 milliseconds to 183 milliseconds while the filter size is from 2 to 20. Compared to the ‘phone’ series,
the ‘cloud’ series is almost a horizontal line. The ‘offload’
series measures the total time spent for calling remote image
process PF, including the time indicated by ‘cloud’. The area
between the ‘offload’ series and the ‘cloud’ series presents
the time spent on the network, which is around 7.8 seconds in the evaluation configuration for the test image. The
‘offload’ series actually adds the image transfer time on to
the ‘cloud’ series and the major time spent for the image
process application is for image transfer. The Fig. 9 shows
the BIV point is around 13. If the application requires more
obvious filter result by altering the filter size greater than the
BIV, the application had better offload the image process to
the cloud to gain time benefit.
6.3 Potential improvement
The above evaluation incorporates one mobile device, however there are thousands of vehicles in the urban area. If the
image process PF is hosted on one POEM framework in one
VM, the remote PF composition requests may quickly consume all the resources on the VM. Possible solution is to
separate the data collection task to multiple VMs and define
the limit for each POEM framework. In this way, the work
load is distributed to a bunch of VMs and the system can
scale up by adding more VMs.

7 Conclusion

Fig. 8 Image process application case scenario

This paper proposes a novel application running platform
for mobile cloud computing that allow mobile users to
offload and compose mobile cloud application with little management overhead. The implementation is based on

Mobile Netw Appl (2015) 20:297–307

OSGi platform and XMPP protocols. The proposed service platform handles service migration, service discovery
and service composition seamlessly in a transparent fashion. The evaluation shows the proposed service platform
is flexible and efficient. The future work on POEM is to
improve security and privacy control of the POEM system.
Moreover, the service discover should incorporate more
social network features to make the discovery scalable and
customizable.
Acknowledgment The authors would like to thank NSF CPS
#1239396 grant to support the research on the MIDAS project.

References
1. Huang D, Xing T, Wu H (2013) Mobile cloud computing service
models: a user-centric approach. IEEE Netw 27(5):6–11
2. OSGi Alliance. OSGi Core Release 5, March 2012. http://www.
osgi.org/Release5/HomePage
3. Extensible Messaging and Presence Protocol (XMPP), available
at http://xmpp.org/. Open Source
4. March V, Gu Y, Leonardi E, Goh G, Kirchberg M, Lee BS (2011)
ucloud: Towards a new paradigm of rich mobile applications. In:
8th international conference on mobile web information systems
(MobiWIS)
5. Ma RKK, Lam KT, Wang CL (2011) excloud: Transparent
runtime support for scaling mobile applications in cloud. In: International conference on cloud and service computing (CSC). IEEE,
pp 103–110
6. Ma RKK, Lam KT, Wang CL, Zhang C (2010) A stack-ondemand execution model for elastic computing. In: Proceedings
of the 39th International Conference on Parallel Processing (ICPP
2010), pp 208–217
7. Chun BG, Ihm S, Maniatis P, Naik M, Patti A (2011) Clonecloud:
Elastic execution between mobile device and cloud. In:
Proceedings of the 6th conference on computer systems. ACM,
pp 301–314
8. Cuervo E, Balasubramanian A, Cho D, Wolman A, Saroiu S,
Chandra R, Bahl P (2010) Maui: making smartphones last longer
with code offload. In: Proceedings of the 8th international conference on Mobile systems, applications, and services. ACM,
pp 49–62
9. Kosta S, Aucinas A, Hui P, Mortier R, Zhang X (2012) Thinkair:
Dynamic resource allocation and parallel execution in the cloud
for mobile code offloading. In: 2012 Proceedings IEEE INFOCOM, pp 945–953

307
10. Kemp R, Palmer N, Kielmann T, Bal H (2012) Cuckoo: a
computation offloading framework for smartphones. In: Mobile
Computing, Applications, and Services, pp 59–79
11. Zhang X, Jeong S, Kunjithapatham A, Gibbs S (2010) Towards an
elastic application model for augmenting computing capabilities
of mobile platforms. In: Mobile wireless middleware, operating
systems, and applications, pp 161–174
12. Satyanarayanan M, Bahl P, Caceres R, Davies N (2009) The
case for vm-based cloudlets in mobile computing. IEEE Pervasive
Comput 8(4):14–23
13. Chen M, Zhang Y, Li Y, Mao S, Leung V (2015) Emc:
Emotion-aware mobile cloud computing in 5g. IEEE Netw 29(2):
32–38
14. Chakareski J (2013) Adaptive multiview video streaming:
challenges and opportunities. IEEE Commun Mag 51(5):
94–100
15. Corradi A, Fanelli M, Foschini L (2014) Vm consolidation: a real
case based on openstack cloud. Futur Gener Comput Syst 32:
118–127
16. Gerla M (2012) Vehicular cloud computing. In: 2012 The 11th
annual mediterranean ad hoc networking workshop (Med-HocNet), pp 152–155
17. Hsu C-Y, Yang C-S, Yu L-C, Lin C-F, Yao H-H, Chen D-Y,
Robert Lai K, Chang P-C (2014) Development of a cloud-based
service framework for energy conservation in a sustainable intelligent transportation system. Int J Prod Econ 164:454–461
18. Huang D, Zhang X, Kang M, Luo J (2010) Mobicloud: Building
secure cloud framework for mobile computing and communication. In: 5th IEEE international symposium on service oriented
system engineering (SOSE), pp 27–34
19. Fielding RT, Taylor RN (2002) Principled design of the modern
web architecture. ACM Trans Internet Technol (TOIT) 2(2):115–
150
20. Wu H, Huang D, Bouzefrane S (2013) Making offloading
decisions resistant to network unavailability for mobile cloud
collaboration. In: 9th international conference on collaborative
computing: networking, applications and worksharing (Collaboratecom). IEEE, pp 168–177
21. Wu H, Huang D (2014) Modeling multi-factor multi-site
risk-based offloading for mobile cloud computing. In: 10th
international conference on network and service management
(CNSM). IEEE, pp 230–235
22. Wu H, Huang D (2015) Mosec: Mobile-cloud service composition. In: 3rd international conference on mobile cloud computing,
services, and engineering (MobileCloud). IEEE
23. Apache Felix. http://felix.apache.org/index.html
24. A cyber physical system for proactive traffic management to
enhance mobility and sustainability. https://mobile.mobicloud.
asu.edu/poem/midas-cps
25. OpenCV library. http://opencv.org/

2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications

Geographic-based Service Request Scheduling
Model for Mobile Cloud Computing
Tianyi Xing1 , Hongbin Liang2 ,Dijiang Huang1 , Lin X. Cai3
1

School of Computing Informatics and Decision Systems Engineering, Arizona State University, {tianyi.xing,dijiang}@asu.edu
2
School of Information Science and Technology, Southwest Jiaotong University, {liang.hongbin}@gmail.com
3
Department of Electrical Engineering, Princeton University, {lincai}@princeton.edu

service satisfaction, which is usually referred as Quality of
Experience (QoE) of the mobile user. Here, we must note
that VM migration is an important virtualization techniques
to help Cloud service providers manage their Cloud resource
and to improve the QoE of mobile users as well. In the above
described scenario, VM migration consumes system resource
to monitor and maintain the VM states such as data processing
and networking state, etc. Thus, comprehensive considerations
of the Cloud system expense and QoE must be taken for
deciding Cloud VM migrations.
Much research work has been produced recently to address
the resource allocation for geographic-based Cloud system.
For examples, research work in [4], [5], [6], [7], [8] investigated the network architecture and protocol designs in
the Cloud computing environment to make the network is
optimized for Cloud services. Research in [9], [10], [11]
investigated the scheduling problem in the Cloud system
that is built on centralized infrastructure. In [12], [13], [14],
[15] researchers proposed methods to optimize the resource
management in a distributed Cloud system. However, to the
best of our knowledge, no previous research work look into
the resource allocation in a geo-distributed mobile Cloud
computing environment by considering the expenses and gains
from both the Cloud system and mobile devices, which is the
research focus of this work. Due to the resource restrictions of
mobile devices (e.g., energy, communication capacity, storage,
etc.), this research is of important for future mobile applications based on Cloud computing techniques.
In this paper, we present a novel service request scheduling
scheme for geographically distributed mobile Cloud system.
This scheme introduces a reward model considering both
Cloud and mobile device’s cost and gain (e.g., mobile device
energy, transfer charge, access&transfer latency, computation
time, mobile access manners and etc.). We simulate the
presented scheduling scheme and produce optimal scheduling
resource management schemes. The evaluation results show
that our proposed resource scheduling scheme is able to
gain more system reward comparing with traditional overprovisioning approaches for centralized Cloud.
The rest of this paper is organized as follows: Section
II presents related work; Section II introduces the proposed
geographically distributed mobile Cloud system; In Section
IV, we discuss the service request scheduling model applied
to proposed MobiCloud; The performance evaluations of the
presented scheduling scheme is shown in Section V; Finally,
Section VI concludes this paper and points out the future work.

Abstract—With Internet environment is getting optimized
and users preferring mobile communications, Cloud Service
Providers (CSP) aim to provide services to users depending
on their geographic locations with higher service availability
and faster access speed. Mobile Cloud computing falls into this
category, where mobile users can move around and request
Cloud services at any given geographic locations. To build such
a geographic-based mobile Cloud services, an effective mobile
Cloud resource allocation and service request scheduling scheme
is highly desired. To this end, the presented service request
scheduling scheme takes a comprehensive approach by considering system parameters from both CSP and mobile users such
as computation, energy, connectivity, service payment, mobile
users’ satisfaction, etc. Finally, the performance evaluation of
the proposed scheduling scheme is evaluated through simulations
where the results show that the presented scheme achieves better
system overall gain compared to traditional over-provisioning
approaches.

I. I NTRODUCTION
Cloud computing is growing rapidly in last few years due to
the increasing bandwidth, more diverse available services and
lower cost. and it has been envisioned as the future services
provisioning architecture over Internet. Besides the traditional
service models of Cloud computer such as IaaS, PaaS and
SaaS [1], new Cloud computing concepts are proposed to
provide new capabilities of Cloud services. Among these new
Clouds, mobile Cloud computing has attracted more attentions
by shifting the service models from ﬁxed-user oriented to
dynamic mobile-user oriented, and from local centralized to
geographically distributed Cloud service architecture [2].
One of main research challenges of mobile Cloud computing is that the Cloud’s resource provisioning must take
mobile users’ geographic locations into the considerations. As
presented in the recent mobile Cloud computing solutions [3],
one or multiple dedicated Virtual Machine (VM) is allocated
for each mobile device to assist it in data-related processes
such as computing, storing, communicating, etc. Ideally, the
allocated VMs should be located closely to the geographic
location of each mobile device. To this end, VM can be
migrated from its Home-Location Host (HLH, i.e., a physical
Cloud server at the registered location that usually the mobile
device accesses the Cloud services more frequently than in
other locations) to a Visiting-Location Host (VLH). During
the migration, the VM related computing is both logically
and physically moved to the VLH. The VM migration helps
to reduce the communication delay for the mobile device
frequently exchanging data with its VM in its home location
and it is usually motivated by improving the mobile users’
978-0-7695-4745-9/12 $26.00 © 2012 IEEE
DOI 10.1109/TrustCom.2012.6

1446

II. R ELATED W ORK

puting framework for mobile devices and then extend it to
geographically distributed manner. As shown in Fig. 1, the
MobiCloud is a multi-cluster based geographically distributed
Cloud system especially designed for mobile devices. In this
section, we are going to describe the framework in terms of
framework architecture and implementation ﬂow.

As we discussed before, the focus on Cloud computing have
been evolving from the centralized infrastructure for providing service for ﬁxed users to geo-distributed infrastructure
for mobile users. Cloud computing for mobile devices has
a major beneﬁt in that it enables running applications between resource-constrained devices and Internet-based Clouds.
Moreover, resource-constrained devices can outsource computation/communication/resource intensive operations to the
Cloud. CloneCloud [16] focused on execution augmentation
with less consideration on user preference or device status.
Elastic applications for mobile devices via Cloud computing
was presented in [17]. Oberheide et al. [18] presented a
framework that outsources the anti-virus services from mobile
devices to a Cloud. Goayl and Carter proposed a secure cyber
foraging mechanism for resource-constrained devices [19].
Existing mobile Cloud solutions are limited and are solely
focused on the enhancement of the individual mobile device’s
capability. Additionally, one of the most essential concerns
about necessary procedures in Cloud computing system is the
request scheduling and VM placement. Especially for those
Cloud computing system which have large number of Cloud
hosts in the cluster where the newly created VM is going to be
placed, it has something closely to do with the performance
and cost of the Cloud system. Meng et al. [20] have designed
a two-tier approximation to deal with the VM placement issue
in the large size data centers. Seung et al. proposed a system
called CLoudFlex [11], which can tap the Cloud resources
to serve application requests that exceed the current capacity
of internal infrastructure. They developed the prototype based
on the Amazon EC2 instances. Rosy Aoun et al. [9] deﬁned
services corresponding to distributed data storage and to
multicast data transfer and considered the possibility of each
service to increase the request accept rate. In paper[12], author
proposed an autonomous scheme for admission control in
Cloud services aiming at preventing overloading, guaranteeing
target response time and dynamically adapting the admitted
workload to compensate for changes in system capacity.
Existing solutions listed above are all limited to centralized
Cloud infrastructure. Only few works deal with the resource
management issue in the distributed data centers. Boloor et al.
[13] presented an approach of data-oriented dynamic servicerequest allocation with gi-FIFO scheduling, in each of the
geographically distributed data centers. However the target
of this research work is to increase the proﬁt of the CSP,
without considering the user side. Another resource management related work [14] combined the scheduling, bandwidth
considerations and storage capacity constraints to optimize the
schedule. It focuses on the content distribution over the web,
where large VM needs to be transferred to the target compute
farms. Volley [15] is proposed as a system addressing data
placement in geo-distributed Cloud system. Cloud services
make use of Volley by submitting logs of requests.

A. Framework Architecture
1) Components: We have built up a prototype of our proposed framework where several servers serving for different
purposes. Our virtualization is based on XEN [21] which
has an impressive scalability, availability and ﬂexibility. With
virtualization technology enabled, Cloud system can provide
more logically separate resource for mobile users. File system
is another major concern for geographically distributed Cloud
system since resource will be prepared from repository where
the resource template stores. We did not use the local storage
on the Cloud system and chose to establish a Network File
System (NFS) [22] instead to manage the storage of VMs
in our Cloud system. Once VMs are successfully created for
mobile users, DHCP server assigns an IP address for each
VM, and the DNSSEC server then pairs up the IP address and
domain name which is uniquely assigned based on the user’s
ID. Sometimes, when mobile users move out of their HLH,
their resources (i.e., VMs) need to be transferred to the VLH.
DHCP and DNSSEC server at different clusters will coordinate
with each other and keep the same access identity for mobile
users. For example, Users can access their VMs with the same
domain name but different IP address in another domain. The
request scheduling server handles both the incoming request
from mobile device and transfer-in request from adjacent
domain. It runs some algorithm and scheme to schedule the
request with appropriate resource. We also have Extensible
Messaging and Presence Protocol (XMPP) [23] server for
building a platform for users to communicate with each other.
It also can be used as a signaling control center when servers
at different cluster want to synchronize or coordinate.
2) Network Architecture: Mobile devices are able to access
to the IP networks via either WLAN or 3G manner to request
the resource through our gateways (GWs). In our MobiCloud
system, we isolate the data plane and control plane of the
network. Management network (Control Plane) is for management and control trafﬁc (i.e., the trafﬁc of service request,
downloading applications in our repository and etc.). On the
other hand, the data network is for data trafﬁc among different
VMs, or different mobile devices via VMs. Not only VM-toVM communication in one physical cluster is considered, but
also the VMs located in different clusters which may probably
across the ocean is considered.
For brand new users requesting the resource, when the home
domain can hardly handle the request, then the request needs to
be transferred to another domain through the control network.
Meanwhile, not all users access to the resource which need to
be newly created. For users want to access resource at VLH,
what we should do is that we can just migrate the proﬁle
of uses’ VM to a corresponding VM in the VLH since the
migrating proﬁle rather than the whole VM damage can greatly
enhance the QoE.

III. M OBI C LOUD : G EOGRAPHICALLY D ISTRIBUTED
C LOUD S YSTEM FOR M OBILE U SERS
After thoroughly investigating the mobile Cloud computing
related research issue, we ﬁrst propose a new Cloud com-

1447

Cluster n@Location n

Service Request
Arrived

Service Request
Processed

Service Request
Analysis

Access Preparation

Resource
Scheduling

Database
Update

Cluster 2@Location 2
Data Network

Cluster 1@Location 1

Cloud

Servers
Control
Network

DNSSEC

Reqt Scheduling

XMPP

VM Operation

NFS Repository DHCP Server

Create

Clone

IP

GW

Suspend

Destroy

VLAN

Mac Addr

Inter-Domain
Router
Node B

Network Configuration

XENServer API

Internet

Fig. 2.

Service
reuqesting GW

MD

Service request processing ﬂow.

WLAN
AP

Fig. 1.

have limited resources (such as computing capability or energy
supply) comparing to the Cloud hardware farm, they need
to outsource its computation and storage, and migrate all or
part of running code of an application service onto the Cloud
system. When Cloud system is a single cluster managing one
region, after the request passing the admission control, the
Cloud only needs to check the status of the Cloud and dispatch
the request to the servers which have available resources
based on some simple scheduling algorithms. The traditional
Cloud computing system then decides the number of virtual
machines in its hardware pool to be allocated to respond the
service request from the mobile device. If there is no available
resource in the Cloud, or assigning any available resource will
violate the availability or workload balancing policy, the Cloud
system just simply reject the request.
However, unlike the centralized Cloud system, the geographically distributed mobile Cloud system needs to determine the location and the number of the virtual machines to
be allocated for the arriving service request from the mobile
device. Since the servers which handle the services (i.e.,
especially those services which needs collaborative operation)
in the mobile Cloud are geographically isolated, when there
is no sufﬁcient resource, to maximize the system reward (a
parameter reﬂecting gain of both CSP and mobile users),
some service requests need to be transferred to other clusters
with available resource at the different location. Base on this
scenario, we propose a service request scheduling model for
geo-distributed mobile Cloud system. The service requesting
scheduling model is presented in Fig. 3.

MobiCloud framework.

B. Service Request Processing Flow
Service provisioning is the one of the most concerning issue
in Cloud computing. MobiCloud is a service provisioning
platform which allows users to claim services and resource
in their own deﬁned manner. Fig. 2 shows the service request
processing ﬂow from service request arriving to request being
processed. Basically, when the service request arrives at our
system, the request analyzer parses the request into several
speciﬁc classiﬁed items. After analyzing service request and
real time situation of the Cloud resource, the scheduling
scheme will be run to direct the service request to the right
cluster ﬁrst and then available server(s). By default, the HLH
is considered to provide the resource to handle the request. If
the HLH does not have sufﬁcient resource, then request will
be transferred to resource scheduler in adjacent domain to be
processed.
When the raw Cloud resource is done being assigned, then
the system starts preparing network resources ﬁrst, such as
reserving VLANs for network user deﬁnes. Meanwhile the
VM is created for users based on the multiple parsed attributes
(i.e., CPU, Memory, storage capacity, etc.). There are two
kinds of interfaces to be conﬁgured, the management interface
and user deﬁned data interface since the data plane and control
plane are isolated as we described before. Once the resources
are fully done preparation, then the database is updated again
to make the stored information complete. Thus, the service
request is done responding and users are free to experience
any Cloud service available in the Cloud.

A. Service Request Scheduling Model
Generally, resource scheduling can be classiﬁed into two
categories due to the architecture of the Cloud system, namely,
centralized and distributed. In a centralized resource allocation
scheme, the scheduler allocates system resources, i.e., bandwidth, spectrum, power, etc., based on the status of current
Cloud system and user information [24], [25], such as the
number of active users, trafﬁc demands and quality of service
(QoS) requirements of users.

IV. D ISTRIBUTED S ERVICE R EQUEST S CHEDULING
S CHEME
The Cloud computing system usually contains two major
parts, the Cloud system and the mobile devices. The Cloud
system contains multiple VMs, which are used to handle
requests from mobile devices. Since mobile devices usually

1448

Algorithm 1 Distributed Service Request Scheduling Algorithm: Scheduling(Nreqi , Ki )
for all Nreqi such that NReqi ≤ R do
if Nreqi ≤ Ri then
R ← R − NReqi
Ri ← Ri − NReqi
else
Ri ← 0
Scheduling(Nreqi − Ri , Ri+1 )
end if
end for
return R Ri

Cluster2
VM Pool

Cluster1
VM Pool

Request Transfer

System Resource Scheduler
Request Analyzer

System Resource Scheduler
Request responce

Admission Control

request

Admission Control

accept
or reject

available
MD

Fig. 3.

Request Analyzer

being
assigned

busy

Reference mobile Cloud service request model.

some mobile paid communication services such as the cost
for mobile device using telecommunications connection and
additional transmission delay.
In the following sections, we also assume the arrival rate of
the new arrival service request and the across-domain transfer
service request follow Poisson distribution with mean rate of
λn and λt , respectively. The departure rate of both service
requests follows exponential distribution with mean rate of μ
when only one VM is allocated to arrival service. Thus the
mean departure rate of arrival service which are allocated c
VMs in the mobile Cloud computing system is μc.
1) System States: According to the assumption, there are
total K VMs in the whole Cloud service provisioning domains,
and C allocation schemes for the VM distribution responding
to the service request, which is from 1 to C, where C ≤ K. On
the other hand, the arrival of new service request and transferin service request, and the departure of the ﬁnished service in
the different allocation schemes are distinct events. Thus the
system states can be described by the number of the services
with every allocation scheme and the events (including both
arrival and departure events) in the mobile Cloud computing
system. Here, the allocation scheme c means that the number of VMs allocated to the service is c, c ∈ {1, 2, ...C}.
Therefore, the number of being served service with allocation
scheme c in one mobile Cloud service provisioning domain
can be denoted as sc .
We also consider the connection type between the mobile
device and the Cloud system since mobile devices can have
multiple ways to access to the Internet, which deﬁnitely causes
different performance and QoE. There are two major ways
for mobile device to access to the IP network in wireless
manner, which are WLAN and 3/4G communication. When
we use the WiFi to access to the internet, it ﬁrstly can be
assumed to be free of charge and then relatively higher speed
connection. However the connection speed will decrease a lot
comparing with the WiFi when using the UMTS connection.
In addition, the telecommunications will charge the mobile
user based on the data amount user transfers. Consequently,
with considering the access communication method beside
computation ability, energy saving issue, etc., we deﬁne ﬁve
types of service events: 1) a new service request arrives
via WiFi connection from the mobile device, denoted by
Anw ; 2) a new service request arrives via telecommunications
connection from the mobile device, denoted by Antele ; 3) a

While in the distributed resource allocation scheme, the
scheduler allocates those system resources based on not only
user’s preference and available system resources locally [26],
[27], but also available resource in all other Cloud clusters in
the system. Therefore, distributed resource allocation scheme
that characterizes the distributed Cloud system can achieve
better user experience and system utilization compared to
centralized resource allocation scheme.
Thus, the distributed resource allocation scheme is adopted
in the MobiCloud system. We provide multiple provisioning
domains with a total number resources of K virtual machines.
Let’s say the number of the provisioning domains
n is n. The
number of the VMs in ith domain is Ki . So, i=1 Ki = K.
The number of VMs to be allocated for one service is denoted
as c, where c ∈ {1, 2, .., C}, C ≤ K. Meanwhile, if the Cloud
resource is not sufﬁcient to handle more service requests when
a service request arrives, the Cloud needs to decide either
transferring the service request to another Cloud provisioning
domain or rejecting the request. That is based on the consideration of the maximizing whole mobile Cloud computing
system reward. However things are more complicated when
service requests arriving from adjacent mobile Cloud service
provisioning domain.
Let’s make R denote the available resource of whole system
in terms of the number of the VMs, Ri denotes the number
of available VMs in domain i. Nreqi denotes the number of
VMs being requested in domain i. We introduce the distributed
scheduling function Scheduling(Nreqi , Ri ), which means,
service request claiming Nreqi VMs arrives at or is transferred
to the ith domain with Ri available resource in terms of VMs.
If Nreqi ≤ Ri , the Cloud host that request arrives at has
sufﬁcient resource and is possible to handle the request locally.
If not, the excessive requesting resource that local Cloud host
does not have needs to be claimed at an adjacent provisioning
domain. The algorithm is shown in Algorithm 1. After any
single request is handled, both the R and Ri are updated.
Besides, when the mobile Cloud computing system considers the whole system reward, it should not only consider
the reward of the mobile Cloud and the mobile device itself
(i.e., saved battery energy and saved time of mobile device
if the service is processed in the mobile Cloud), but also the
mobile communication carrier if the mobile devices are using

1449

w(s, a) =

⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩

0,
(αs − αd ) En + γ d Ud − ψ t − δ t − β s ,
(αs − αd ) En + γ d Ud − ψ t − δ t − β s − δ tele − αtele Etele ,
−γ d Ud − β d ,
−γ d Ud − β d − δ tele − αtele Etele ,
0,
(αs − αd )En + γ d Ud −β s /c,
(αs − αd )En + γ d Ud −β s /c − δ tele − αtele Etele ,
ψ t −β s /c,

transfer-in service request arrives from an adjacent mobile
Cloud service provisioning domain, denoted by At ; 4) the
departure of a ﬁnished service with allocation scheme c in
the current Cloud provisioning domain, denoted by Fnc ; 5)
the departure of a ﬁnished transfer-in service in the current
Cloud provisioning domain, denoted by Ft . Thus, the event
e in the MobiCloud computing system can be described as
e ∈ {Anw , Antele , At , Fn1 , Fn2 , ..., FnC , Ft }. Therefore, the
system state in each domain can be expressed as
S = {s|s = s1 , s2 , ..., sC , e},
where

C

c=1

(1)

(sc ∗ c) ≤ Ki .

2) Actions: For a system state with event Anw , Antele or
At , if the decision of home mobile Cloud service provisioning
domain is acceptance and then the c allocation scheme is
assigned to the arrival service request, then the action to assign
the c allocation scheme can be denoted as a(s) = c. While
if the decision of home mobile Cloud service provisioning
domain to a new or a transfer-in mobile code service request
is rejection, which means no VM will be assigned to the new
or transfer-in mobile code service request, then the action to
reject the new or transfer-in mobile code service request can
be denoted as a(s) = 0.
Generally, for the new service request from mobile device,
with either WiFi or telecommunications connection, the current mobile Cloud service provisioning domain need transfer
the new service request to an adjacent mobile Cloud service
provisioning domain to process this service request instead of
rejection in order to decrease the number of rejection, due
to the lack of the resource of current mobile Cloud service
provisioning domain. We denote this action as a(s) = −2.
On the other hand, for the departure of a ﬁnished new
service in the mobile Cloud (i.e., e = Fnc ), or the departure
of a transferred service in the mobile Cloud (i.e., e = Ft ), the
action for this event can be considered as “continue” and it
is denoted as a(s) = −1. Therefore, the action space can be
deﬁned as a(s) ⊆ Acts , where
⎧
⎨ {0, 1, ...C}, e ∈ {Anw , Antele , At }
−1,
e ∈ {Fn1 , Fn2 , ..., FnC , Ft }
(2)
a(s) =
⎩ −2,
e ∈ {Anw , Antele }.
3) Reward Model: Based on the system state and its corresponding action, one can evaluate the entire MobiCloud system (including Cloud system, mobile device and the telecommunications operator reward (denoted by r(s, a)) based on the

a(s) = −1, e ∈ {Fn1 , Fn2 , ..., FnC , Ft }
a(s) = −2, e = Anw
a(s) = −2, e = Antele
a(s) = 0, e = Anw
a(s) = 0, e = Atele
a(s) = 0,e = At
a(s) = c, e = Anw
a(s) = c, e = Antele
a(s) = c, e = At .

(4)

income and the cost as follows:
r(s, a) = w(s, a) − g(s, a),

(3)

where w(s, a) is the net lump sum income for the Cloud, a
mobile device and the telecommunications operator.
The net lump sum income should not only consider the
income of the mobile Cloud computing system but also the
income of mobile device. Thus the net lump sum income
w(s, a) is computed as equation (4). Here, αs and αd are
weight factors for Cloud and mobile device, respectively. They
satisfy 0 ≤ αs , αd ≤ 1 and αs + αd = 1. En is the income of
the Cloud when it accepts a new service request from a mobile
device. At the boundary cases, the impact factors αs and αd
are used to adjust the considerations either from system side
or mobile device side.
For instance, if αs = 1, αd = 0, then the Cloud only
considers the system income, while if αs = 0, αd = 1, then
the Cloud only considers the income of mobile device. Ud
represents the income measured by the saved battery energy of
the mobile device when the Cloud accepts the service request,
which has the same measurement unit as the income. γ d is
the weight factor that satisﬁes 0 ≤ γ d ≤ 1. ψ t represents the
charge for transferring a service request from one domain to
another domain based on the agreement between two domains.
Here, we assume that all the domains have the same
agreement, which means the transfer charge ψ t between all
domains are the same. δ t denotes the payout measured by
the time delay because of congestion during transferring the
service request from one mobile Cloud service provisioning
domain to an adjacent mobile Cloud service provisioning
domain, which has the same measurement unit as the income.
β s denotes the payout measured by the computation time to
process the service using one VM in the mobile Cloud service
provisioning domain. Therefore β s /c denotes the expense
measured by the computation time to process the service using
c VMs in the mobile Cloud service provisioning domain, and
β d represented the payout measured by the computation time
to process the service using the CPU of Mobile device.
In addition to the measurement considering the computation,
payment and transmission time delay between mobile device
and the Cloud system, the telecommunications connection also
introduces some factors such as payment and time delay over
the WiFi connection. δ tele denotes the payout measured by
the time delay because using telecommunications connection
may cause additional time delay when migrate the service
from the mobile device to the remote Cloud. Also, if the user

1450

chooses to use the telecommunication connection, additional
payment should be taken into account. αtele is the weight
factor for the telecommunications operator, which satisﬁes that
0 ≤ αtele ≤ 1. Etele is the income of the telecommunications
operator when it send out the mobile code via the telecommunication network rather than WLAN network.
In equation (4), g(s, a) denotes the system cost and it is
given by:

1

<sn1,sn2,st1,Ft>

a=-

…

<sn1,sn21,st,Fn2>

……

……

…

…

a=0
…

(4)

…

<sn11,sn2+1,st,F
n1>

<sn1+1,
sn2-1,st,Fn2>

…

<sn1,sn2,st,
Anw>

a=0

<sn1,sn2,st,
Ang>

………

a=2
a=
1

a=
1

V. E VALUATION
A. System Rewards
The state transition for our model is shown in Fig. 4. We
assume that there are two allocation schemes. The quantities
in each bracket’s in circle denote one state of our model, and
the variable a denotes the action from one state to another
state. Then, from the Fig. 4, the state transition probability
q(j|s, a) can be obtained, where q(j|s, a) denotes the state
transition probability from the current state s to the next state j
when action a is chosen. Thus, based on the discounted SMDP
reward model deﬁned in [28] and [29], the expected maximum
long-term discounted reward of new service of whole mobile
Cloud computing system can be achieved as well, which can
be denoted as ν(s).
Our purpose is to obtain the expected long-term reward of
each action for one state, thus to choose the optimal action that
has the maximal expected long-term reward for each state. In
this subsection, we evaluate the whole system performance of
new service of our service activity model compared to using
greedy methods, using the event driven simulator written by
Matlab.

<sn1+1,sn2,st
,Anw>

<sn1+1,sn2,s
t,Ang>

Fig. 4.

2
a=

a=1

a=2

(5)

c=1

<sn1,sn2,st,
At>
………

a=2

a=1

(sc ∗c).

<sn1,sn2,st,F
t>

a=2

C


……

<sn11,sn2,st,
Fn1>

In equation (4), τ (s, a) is the average expected service time
when the system state transfers from current state s to the
next potential state j and the decision a is made; o(s, a) is
the cost rate of the service time, it is deﬁned as the number
of all occupied VMs, thus it can be computed as:
o(s, a) =

<sn1,sn2,st,F
n2>

a=0

g(s, a) =τ (s, a)o(s, a), a(s) ∈ Acts .

<sn1,sn2,st,F
n1>

<sn1,sn2+1,s
t,Anw>

<sn1,sn2+1,s
t,Ang>

<sn1,sn2,st+
1,At>

State transitions of MobiCloud service model.
TABLE I
PARAMETER USED IN THE SIMULATION

P arameter N ame
αs
αd
En
γd
Ud
ψt
δt
βs
δ tele
αtele
Etele
βd

P arameterV alue
0.8
0.2
50
1
10
8
16
1
1
0.5
2
19

transferring service request from the current mobile Cloud
service provisioning domain is about 50%. To assure reward
computation convergence, the continuous-time discounting
factor α is set to be 0.1. The simulation results are collected
with each experiment of 18000s, and each experiment is run
1000 times. The other parameters used in this simulation are
listed in Table I.

B. Simulation Environments
In our simulation, there are total three VMs allocation
schemes which means C = 3 and c1 = 1, c2 = 2,
c3 = 3, respectively. The total resource capability of the
mobile Cloud service provisioning domain is up to K = 10
VMs. Unless otherwise speciﬁed, the arrival rates of the new
and transferring service request are λn = 7.2 and λt = 2.4,
respectively; and the departure rate of ﬁnished service using
one VM is μ = 6.6. Then the departure rate of ﬁnished service
using multi-VMs is cμ which is described in section IV. Thus,
the departure rates of ﬁnished service using one, two and three
VMs are μc1 = 6.6, μc2 = 13.2 and μc3 = 19.8, respectively.
Let p denote the probability of the adjacent mobile Cloud
service provisioning domain accepting the transferring service
request from the HLH. In this simulation, we set p = 0.5 by
default, which means the probability of the adjacent mobile
Cloud service provisioning domain accepting/rejecting the

C. Simulation Results
To evaluate the performance of our proposed dynamic
resource allocation model, we compare the long-term reward
and blocking probabilities of the new service between our
model and greedy method in Figure 5 and 6, respectively.
In Figure 5, the reward of new service of our model
increases at the beginning, then falls down with the increase of
the arrival rate of new service (λn ), while the reward of new
service of the greedy method declines always. It can be seen in
the ﬁgure that the reward of the new service of our proposed
model performs much better than that of greedy method. This

1451

with the greedy method under the scenario of different number
of VMs (K). In Figure 7, the rewards of both our model and
greedy method increase with the increase of the number of
total VMs in the current mobile Cloud service provisioning
domain. When the number of VMs (K) is less than 2, the
rewards of both our model and greedy method are negative.
This is because the absolute values of rejection cost (−70)
and transferring cost (−63) are much higher than the net
lump rewards of acceptance (8, 14 and 16 for c1 , c2 and c3 ,
respectively). When the number of VMs is low (1 and 2),
both the rejection probability and transferring probability of
new services are as high as 30% shown in Figure 8, implying
that total 60% of new services are rejected and transferred,
and only 40% of new services are allocated to c1 allocation
scheme, which results in the negative rewards of both our
model and the greedy method.
We also observed that when K is less than 3, the reward
of a new service of our model is lower than that of the
greedy method. The reason is our model does not only
consider the instant and future long-term reward, but also
the cost of resource occupation of new migration service in
the current mobile Cloud service provisioning domain when
deciding to allocate the resource to the new service, while
the greedy method only considers the current reward of new
migration service of current mobile Cloud service provisioning
domain. When the resource of current mobile Cloud service
provisioning domain is less than 3 VMs, our model is more
conservative than the greedy method to allocate resource to
the new service, thus the reward of new service of our model
is lower than that of the greedy method in this case.
In Figure 7, we can also see that the reward of new
service increase rapidly with the increase of the value of K
when the number of VMs (K) is less than 7. Meanwhile,
when K is greater than 7, the reward of new migration
service of our model increase slowly with the increase of
the value of K, which implies that for the given arrival rate
and departure rate, the impact to increase the reward of new
migration service through increasing the resource of current
mobile Cloud service provisioning domain is limited when the
resource of current mobile Cloud service provisioning domain
exceeds the threshold. Compare the rewards of new service
between our model and the greedy method in Figure 7, it can
be seen that our model outperforms over 50% averagely than
the greedy method.

is because with the increase of the arrival rate of the new
service, our model is more conservative to allocate available
VMs to the new service than the greedy model in order to
reduce the increase rate of dropping probability.
In Figure 6, with the increase of the arrival rate of the
new service, our model would rather allocate more c1 and
c2 allocation schemes to the new service other than the c3
allocation scheme, thus the dropping probability of our model
is lower than that of the greedy method. As the rejection
has more impact on the system lump reward compared with
acceptance (in our simulation, the lump reward w(s, a) or
ﬁne of rejection is −70, while the corresponding lump reward
w(s, a) for c1 , c2 and c3 are 8, 14 and 16), thus, the lower
dropping probability of our model gains more rewards of
new service than the greedy method. When the arrival rate
of the new service is over 7, the probabilities to allocate
c1 and c2 allocation schemes (especially the probability of
c1 allocation scheme) exceed the probability to allocate c3
allocation scheme, which explains the reason why the reward
of new service falls down when the arrival rate of new service
exceeds 7 shown in Figure 5. In other words, our model can
achieve higher reward of new service than that of the greedy
method while keeping low dropping probability, which are
shown in Figure 5 and Figure 6, respectively. Thus our model
outperforms the greedy method with the increase of arrival
rate of new service.
Reward of new arrival service per minute

350

300

250

200

150

100

50

0

SMDP
Greedy
1

2

3
4
5
6
7
8
New service arrival rate per minute(n)

9

10

The probabilities of each action for new service using SMDP

Fig. 5. System reward of new service compared between SMDP model
and Greedy method, varying with the arrival rate of new service (λt = 2.4,
μ = 6.6, K = 6, p = 0.5)
0.7
Dropping
Class 1
Class 2
Class 3
Transfer

0.6

0.5

VI. C ONCLUSION
0.4

In this paper, we have proposed and implemented MobiCloud, a geographically distributed Cloud service provisioning
framework for mobile devices. The MobiCloud framework
allows users to experience the Cloud service with more ﬂexible
manner and more degree of freedom through wireless connection. Furthermore, we have deﬁned and proposed a service
request scheduling reward model which considers metrics
from CSP, mobile users and ISP in terms of computation,
energy, payment and etc. The simulation results show that
our proposed services request scheduling reward model has
better performance than greedy scheme with different input
parameters under the geo-distributed topology.

0.3

0.2

0.1

0

1

2

3
4
5
6
7
8
New service arrival rate per minute( )

9

10

n

Fig. 6. Probabilities for each action of new service using SMDP model,
varying with the arrival rate of new service (λt = 2.4, μ = 6.6, K = 6,
p = 0.5)

To further illustrate the performance of our model, we
compare the reward of new service and blocking probability

1452

!"#"$%%$&'$









*+,
-#/
 













	






Fig. 7. System reward of new service compared between SMDP model and
Greedy method, varying with the number of VMs(K)(λn = 7.2, λt = 2.4,
μ = 6.6, p = 0.5)
The probabilities of some actions for new service using SMDP

0.9
Dropping
Class 1

0.8

Class 3
0.7

Transfer

0.6
0.5
0.4
0.3
0.2
0.1
0
1

2

3

4
5
6
7
The number of the total VMs (K)

8

9

10

Fig. 8. Probabilities for each action of new service using SMDP model,
varying with the number of VMs(K)(λn = 7.2, λt = 2.4, μ = 6.6, p = 0.5)

ACKNOWLEDGEMENT
This research is sponsored by ONR YIP. Some of the work
is also partially sponsored by NSF CNS-1029546 and DUE0942453. The research outcomes do not necessarily reﬂect the
views of sponsors.
R EFERENCES
[1] M. Armbrust, A. Fox, R. Grifﬁth, A. D., Joseph, R. K. andAndy Konwinski, G. Lee, D. Patterson, A. Rabkin, I. Stoica, and M. Zaharia, “Above
The Clouds:A Berkeley View of Cloud Computing,” in Technical Report,
2009.
[2] D. Huang, “MobiCloud: A Secure Mobile Cloud Computing Platform,”
E-Letter of Multimedia Communications Technical Committee (MMTC),
IEEE Communications Society (invited paper), 2011.
[3] D. Huang, X. Zhang, M. Kang, and J. Luo, “Mobicloud: A secure mobile
cloud framework for pervasive mobile computing and communication,”
in Proceedings of 5th IEEE International Symposium on ServiceOriented System Engineering, 2010.
[4] H. Ballani, P. Costa, T. Karagiannis, and A. Rowstron, “Towards
Predictable Datacenter Networks,” in SIGCOMM, 2011.
[5] P. Costa, T. Zahn, A. Rowstron, G. OShea, and S. Schubert, “Why
Should We Integrate Services, Servers, and Networking in a Data
Center? ,” in WREN, 2009.
[6] D. Li, C. Guo, H. Wu, K. Tan, Y. Zhang, and S. Lu, “FiConn: Using
Backup Port for Server Interconnection in Data Centers,” in The 28th
Conference on Computer Communications, Infocom, 2009.
[7] J. Mudigonda, P. Yalagandula, and J. Mogul, “NetLord: A Scalable
Multi-Tenant Network Architecture for Virtualized Datacenters,” in
SIGCOMM, 2011.
[8] P. Gill, P. Gill, and P. Gill, “Understanding Network Failures in Data
Centers: Measurement, Analysis, and Implications,” in SIGCOMM,
2011.

[9] R. Aoun, E. A. Doumith, and M. Gagnaire, “Resource Provisioning for
Enriched Services in Cloud Environment,” in 2nd IEEE International
Conference on Cloud Computing Technology and Science, CLoudCom,
2010.
[10] C. Courcoubetiso and R. R. Weber, “Economic Issues in Shared Infrastructures,” in VISA, 2009.
[11] Y. Seung, T. Lam, L. E. Li, and T. Woo, “CloudFlex: Seamless Scaling
of Enterprise Applications into the Cloud,” in The 30th Conference on
Computer Communications,Mini-Conference at Infocom, 2011.
[12] N. Leontio, D. Dechouniotis, and S. Denazis, “Adaptive admission
control of distributed cloud services,” in 2010 International Conference
on Network and Service Management (CNSM), 2010.
[13] K. Boloor, R. Chirkova, Y. Viniotis, and T. Salo, “Dynamic Request
Allocation and Scheduling for Context Aware Applications Subject to a
Percentile Response Time SLA in a Distributed Cloud ,” in 2010 IEEE
Second International Conference on Cloud Computing Technology and
Science (CloudCom), 2010.
[14] Amir, E. D. H., L. Ezra, and S. I. Shapira, “Virtual Appliance Content
Distribution for a Global Infrastructure Cloud Service ,” in The 29th
Conference on Computer Communications, Infocom, 2010.
[15] S. Agarwal, J. Dunagan, N. Jain, S. Saroiu, and A. Wolman, “Volley:
Automated Data Placement for Geo-Distributed Cloud Services,” in
NSDI, 2011.
[16] B. Chun and P. Maniatis, “Augmented Smartphone Applications
Through Clone Cloud Execution,” in Proceedings of USENIX HotOS
XII, 2009.
[17] X. Zhang, J. Schiffman, S. Gibbs, A. Kunjithapatham, and S. Jeong,
“Securing elastic applications on mobile devices for cloud computing,”
in Proceedings of the 2009 ACM workshop on Cloud computing security,
2009, pp. 127–134.
[18] J. Oberheide, K. Veeraraghavan, E. Cooke, J. Flinn, and F. Jahanian,
“Virtualized in-cloud security services for mobile devices,” in Proceedings of the First Workshop on Virtualization in Mobile Computing, 2008,
pp. 31–35.
[19] S. Goyal and J. Carter, “A lightweight secure cyber foraging infrastructure for resource-constrained devices,” in Proceedings of the 6th IEEE
Workshop on Mobile Computing Systems and Applications, 2004, pp.
186–195.
[20] X. Meng, V. Pappas, and L. Zhang, “Improving the Scalability of Data
Center Networks with Trafﬁc-aware Virtual Machine Placement,” in The
29th Conference on Computer Communications, Infocom, 2010.
[21] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neugebauer, I. Pratt, and A. Warﬁeld, “Xen and the Art of Virtualization,” in
SOSP, 2003.
[22] RFC1094, available at http://tools.ietf.org/html/rfc1094/, 1989.
[23] RFC3920, available at http://www.ietf.org/rfc/rfc3920.txt, 2004.
[24] L. X. Cai, L. Cai, X. Shen, and J. W. Mark, “REX: a randomized
exclusive region based scheduling scheme for mmWave WPANs with
directional antenna,” IEEE Transactions on Wireless Communications,
vol. 9, no. 1, pp. 113–121, 2010.
[25] F. Hou, L. X. Cai, P. H. Ho, X. Shen, and J. Zhang, “A cooperative
multicast scheduling scheme for multimedia services in IEEE 802.16
networks,” IEEE Transactions on Wireless Communications, vol. 8,
no. 3, pp. 1508–1519, 2009.
[26] L. Cai, X. Shen, J. W. Mark, and L. Cai, “Supporting voice and video
applications over IEEE 802.11n WLANs,” ACM/Wireless Networks,
vol. 15, no. 4, pp. 443–454, 2009.
[27] J. Xu, X. Shen, J. Mark, and J. Cai, “Adaptive transmission of multilayered video over wireless fading channels,” IEEE Transactions on
Wireless Communications, vol. 6, no. 6, pp. 2305–2314, 2007.
[28] M. Puterman, Markov decision processes: Discrete stochastic dynamic
programming. John Wiley & Sons, Inc. New York, NY, USA, 2005.
[29] H. Mine, S. Osaki, and M. L. Puterman, Markovian decision process.
Elsevier, Amsterdam, 1970.

1453

Modeling Multi-factor Multi-site Risk-based
Offloading for Mobile Cloud Computing
Huijun Wu, Dijiang Huang
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University
Email: {Huijun.Wu, Dijiang.Huang}@asu.edu
Abstract-Offtoading decisions for computation-intensive ap­

In addition to the privacy-breach risk, another offloading risk is

plications in mobile cloud computing may involve many decision

the reliability of offloading targets. For example, the surrogates

factors.

may be unavailable due to unstable communication link or

Important

decision factors

such as offtoading node

reliability and privacy protection have not been well studied.
Moreover, existing offtoading models mainly focus on the one-to­
one offtoading relation. To address the multi-factor and multi-site
offtoading mobile cloud application scenarios, we present a multi­
factor multi-site risk-based offtoading model that abstracts the
offtoading impact factors as for offtoading benefit and offtoading
risk. The offtoading decision is made based on a comprehensive
offtoading risk evaluation. This presented model is generic and
extendible. Four offtoading impact factors are presented to show
the construction and operation of the presented offtoading model,
which can be easily extended to incorporate more factors to make

software crash, etc. In this case, offloading effort has to include
offloading recovery strategies. Thus, both privacy breach and
reliability risks should be considered in the offloading model
in addition to the performance offloading factors described

previously.
The presented multi-factor multi-site risk-based offload­
ing model abstracts the offloading impact factors into two
categories: offloading benefit and offloading risk. The final
offloading decision is made based on the aggregated and

offtoading decision more comprehensive. The overall offtoading

normalized benefit and risk evaluations. This presented model

benefits and risks are aggregated based on the mobile cloud users'

is generic and extendible in that the number of factors that

preference. The performance evaluation presents the practicality

are considered in the offloading decision processes varies.

of the presented solution.

Specifically, we present four offloading impact factors to show

how the model works, and it can cover more factors to
I.

make offloading decision more comprehensive. The offloading

INTRODU CTION

benefits include delay reduction and energy saving, and of­

In mobile cloud computing, offloading is an important

floading risks factors include privacy breach and reliability of

approach to overcome the resources and functionalities con­
strains of mobile devices. In a mobile cloud offloading model,
applications deploy their components on multiple application
processing nodes such as mobile smart phones and virtual

the offloading targeting nodes. The overall offloading benefits

machines in a cloud. A mobile device can rely on an offloading

and risks are aggregated based on the mobile cloud users'
preference. Finally, we design an ant-based algorithm to com­
pute the optimal application partition strategy. In summary, the
contributions of presented research are highlighted as follows:

decision model based on multiple factors such as offloading

computational-intensive, time- or energy-consuming applica­
tion functions.

•

proach takes two risk factors into offloading decision

making process. The privacy risk and reliability risks
have not been studied in previous work, however they
are common issues in mobile cloud computing appli­

Many existing mobile cloud offloading models focus on a
one-to-one directional offloading model (e.g.,

[1][2][3]): i.e.,

offloading from a mobile device to a cloud server (e.g., a VM).
Study in

cation scenarios. The offloading decision is made by

[4] had shown the benefits of using one-to-many (i.e.,

comparing the aggregated risk and potential offloading

multi-site) offloading models to improve the performance of

benefit. The proposed decision approach is not limited

mobile devices, where a mobile device can offload multiple

to only two types of risk or benefits. The solution

application functions to multiple computing nodes. However,

can be easily extended to many factors as long as the

existing offloading models only consider one offloading factor

such as computation overhead, networking delay, or energy
consumption. Moreover, they do not consider other important
offloading factors such privacy, reliability, etc.

One of important focuses of this work is to model the
offloading risks that have not been addressed by previous

research. Particularly, we focus on two main sources of risks
in mobile cloud computing: privacy breach and offloading
reliability. Mobile application components can be offloaded

to malicious nodes that can potentially compromise the ap­

Risk-based multi-factor decision: The proposed ap­

factors result in either benefits or risks.
•

Multi-site offloading:

The proposed offloading ap­

proach picks one or multiple surrogates from a set
of candidate sites (here we use node and site inter­
changeably), i.e., there could be multiple offloading

destinations, where both cloud V Ms and mobile nodes
can serve as a destination.
The remainder of this paper is organized as follows: Section
II discusses recent related work. Section III presents models

plication's privacy, e.g., the offloaded data and functions may

of mobile cloud applications, and formulates the offloading

contain private data or expose the purpose of the application.

partition problem, and presents the ant system based algorithm.

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

230

CNSM Mini-Conference Paper

Section IV provides some experiment results illustrating the
performance of our proposed algorithm as well as algorithm
tuning guides. The conclusions are given in section V finally.

II.
Cuckoo

[5]

1

REL AT ED WORK

proposed a static offloading framework that

is build on Android and requires a separate compile process
to generate mobile device and cloud versions of the same
application. This framework does not have offloading decision

intelligence. Zhang et at. proposed a web service based elastic
offloading framework

[3].

an effective method to obtain optimal offloading decision.

[2]

and MAUl

[1]

are energy saving frameworks.

They profiles the hardware components and make offloading

to optimize energy usage of mobile device. These two frame­
works only consider the energy issue of offloading and ignore

[6]

[7]

other aspects. Clonecloud
and eXCloud
are virtual
machine related frameworks. Clonecloud mirrors the mobile
device application in the cloud. eXCloud migrates Java virtual
machine stack to cloud. These two frameworks record the
application state on mobile devices and resume the application
from the stored state in cloud.
Besides offloading framework, some research work focus

[8]

et at.
models application
as a dependency graph. 'All step' and 'K step' algorithms were
proposed to solve application partition problem. Memory and
transferred data size were taken into the consideration. Ou et
on offloading algorithms. Giurgiu

at.

[9]

A.

Offloading Benefits

1) Execution Time: The component c is labeled with com­
putation load Wc and vector w is computation load of all
vertexes; the edge e
(C1' C2) from C1 to C2 is labeled with
data transfer load fCIC and matrix Fmxm is data exchange
2
load of all edges. Meanwhile, candidate site 8 is labeled as
a vertex weight Us and vector u is weights of all sites; link
l
(81,82) from 81 to 82 is labeled as link weight dS1 S2 and
matrix Dnxn is weights of all links.
=

=

In this article, we define the operator .* as array inner
multiplication that multiplies arrays or matrices in element-by­
element way, which is different from matrix multiplication. Let
U be the vector that satisfies u. * U
1 where 1 is the vector
whose elements are all 's. Then the upper bound of total time
spent for computation load is sum of workload on every site
over its processing capability:
=

1

(1)

discussed system failure in offloading systems. They

analyzed system execution time considering system failure
and recovery. They did not consider how to make offloading

[10]

decisions. Wolski et at.
considered offloading decision
problem based on network bandwidth constraints. They as­
sumed that the network reliability is not an issue. However,
the network may even not be connected in real mobile cloud
computing scenario due to mobility or other reasons. Sinha et
at.

=

=

This framework uses a cost model

to make offloading decision. The author did not provide

ThinkAir

The multi-site offloading problem can be modeled to find

a mapping from the application graph G app to the candidate
network Gs ur to achieve a given optimization objective func­
tion. Let matrix X present this mapping, whose element Xij
is set to either when component i is assigned to site j or 0
otherwise. Based on X, four more mappings can be defined.
Mapping fc-+s maps component i to site j, and fs-+c is the
reverse mapping. Mapping fE-+L maps edge e
(i1,i2) to
link l
(fc-+s(id,fc-+s(i2)); and h-+E maps a link to a
vector of edges. These four mappings can easily be expended
to accept vector as well.

[4] proposed offloading scenarios involving multiple sites.

Similarly, let Dnxn be the matrix that satisfies D. * D
Inxn where Inxn is the matrix whose elements are all Is. The
transformation XT F X redistributes the communication load
of Fmxm into a "!: x n matrix where element positions are
corresponding to Dnxn. The upper bound of total time spent
on networks for data exchange load is the sum of workload
on every link over its throughput:
=

However, their approaches do not consider the privacy and

(2)

reliability issues during the mobile cloud offloading process.
Although the above researches provided different offload­

ing frameworks and decision models, they mostly focused
on a one-to-one mobile devices to cloud servers offloading

model, and none of existing solutions consider the privacy and
reliability issues during the offloading procedure.

III.

SY STEM AND MODELS

In our framework, a mobile application is programmed
based on component-based design, where components provide
functionality via interfaces and may, conversely, consume func­
tionality provided by other components via their interfaces.
The application can be presented as a graph G app
(C, E)
where a vertex is a component and an edge represents the
interaction between components. Let m
Ic!. In a multi-site
=

where the

n
2:= aii'
i =l

trO

function calculates matrix trace

tr(Anxn)

So the upper bound of total time is the sum of the

computation time and the communication time:

t

=

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

231

tc + tn.

[11][12][13][14].
[15][16].

[14][13][17][11]:

(3)

offloading scenario, some computation workload is offloaded

=

=

2) Energy Consumption: Energy consumption on mobile
devices can be categorized according to hardware modules.
The major categories are CPU, radio module including Wi­
Fi and Cellular, display, audio device, GPS module and vi­
bration motor
Both CPU and radio power
can be modeled as a linear model that consists of two parts:
dynamic consumption when hardware module is active and
base consumption
The dynamic part of CPU power
is proportional to utilized processing capability according to

=

from an original mobile device and distributed onto candidate
surrogate sites. The original site and its candidate surrogate
sites form an egocentric network Gsur
(S, L), where a node
is a site and a link represents a network connection between
two sites. Let n
l SI .

=

where cCPu is the coefficient vector for all sites. Let's code
E as e, then the dynamic part of radio module power is
proportional to the outgoing packet rate

[14][13]:

D'

=

D. * (lnxn

-

1). * (cradio e ),

(4)

CNSM Mini-Conference Paper

pradio

(5)

=

i

where crad o is coefficient vector for all sites, I is identity
matrix and d; is the element of D' corresponding to link l.
i
Let Pi�I� U be the static part of CPU power and /;:::e O be
static power of radio module. Then the total power IS the sum
pcpu+piCPU+pradio+pradio .
of the above J'lour parts: p
base
de

:

=

l

Fig.

B. Offloading Risks

1.

and Trust: Information leakage may happen
in transportation process in network and/or in computation
process on sites. Let's code C as c and E as e, then combine
fc--+s (c ) and fE--+de) as a vector v of elements that may leak
information. Corresponding to this vector, two state vectors s
and s' are defined of one unique surrogate network state. Vector
s records what elements leak information and vector s' records
links on which data is exposed. Both sand s' are constructed
initially as all O's and then adjusted according to:

Si

For s, if Vi leaks information, then

•

For s', two situations are considered. First, if a link
Vi E fE--+de) leaks information, then s � 1. Second,
if a site is compromised, then all data transferred on
incident links are exposed. Let Vi E fE--+de) and
Vi
(Vj ,Vk), and either Vj or Vk leaks information,
then s �
1.
=

=

Let function PI (Vi ) be the probability of leakage occurring
for element Vi. The probability of state s is the probability
product of all independent leakage events:
=

II PI(Vi) II

Ifsi=l

Ifsi=O

(6)

(1 - PI(Vi)).

=

C.

(10)

=

L

(11)

P2sQ2s' ,

User Preference
We classify benefits from each source into several levels,

such as none, low, medium, and high, so that each type of ben­
efits can be processed together. To obtain the overall offloading
benefit, user preference is used to aggregate time benefit and
overall benefit can be calculated by fuzzy inference in three
steps: fuzzification, inference and defuzzification.
1)

t%
(torig - t )/torig where torig is execution time when
no offloading is done. The membership degree of t%
The time benefit is firstly normalized by

=

ship function. For example, the membership degrees
of t%
0.28 are: mf�:� (0.28)
0.0 983 (none),
time
where mf none is member function of time benefit
for level 'none', and similarly 0.9193 (low), 0.0120
(medium), and 0 (high) according to membership
functions shown in Fig. 1. Similarly, the energy

2:= PIs

=

PlsQls'·

(8)

=

=

sEH

S(S')EH

benefit is fuzzified as well.

2)

The firing degree of a rule is calculated based on

the chosen conjunction operation and membership
degrees of both time and energy benefit. For example,

2) Reliability: The surrogates may be unavailable due to
device mobility or failures in network or on sites. Similarly,
vector v is defined of elements that may be unavailable and
state vectors sand s' are defined as well. Vector srecords what
elements are unavailable and vector s' records nodes on which
workload is lost. Analogically to the section III-B I, we can
calculate the risk T'2 introduced by surrogates' unavailability:

IfSi=1

L {We},

=

=

1. The risk can be computed based on the expected data loss:

II P2(Vi) II

medium

to a specific benefit level is determined by member­

All valid s(s') vectors form a state space Hand

P2s

medium

where P2 (Vi ) be probability of unavailability occurring for
element Vi ; We are values picked from w corresponding to
components in c
fs--+o(Vi ), and {We} is a set of computa­
tion loss of all unavailability events.

=

=

low

S(S')EH

(7)

L {te},

L

0.85

\fs� =1

where fe are values picked from F corresponding to edges
in e
h--+E (Vi ) ; and {Ie} is set of data loss in all unique
leakage events.

T'1

Final benefit

Q2s'

1f8;=1

=

Energy benefit

energy benefit. We use a fuzzy-based approach [18], where the

The amount of exposed data is considered as the informa­
tion leakage consequence. The impact of state s' is data sum
of all unique leakage events:

qls'

Time benefit

T'2

=

PIs

Weight

1.

=

BENEFIT INFERENCE RULES

TABLE 1.

1) Privacy

•

Time benefit member functions.

(1 - P2 (Vi )),

(9)

1f8i=0

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

the chosen operation is product t-norm

ab ...,

=

for 'medium' is 0.5642. Then, the firing degree is cal­
culated by Tp (0.9193,0.5642)
0.9193 x 0.5642
0.5187 for the rule shown in TABLE I.
=

=

The final benefit of a rule is estimated based on the
conjunction of its member function, its firing degree,
and its weight. For instance, the final benefit for the

�

Tp (0.5187,0.85,mf �;: m )
0.5187 x 0.85 x mf �;�lum
0.4409 x mf rr:,;:ilum

rule in TABLE I is:

=

232

Tp (a,b,...)

and the membership degree of energy benefit

=

CNSM Mini-Conference Paper

where

mf�;:ilum

benefit for

3)

is member function of the final

'medium'.

Algorithm 2
1:

The aggregation of final benefit is calculated based

on the chosen disjunction operation and all outputs of
rules. For example, the chosen operation is minimum
t-norm Tmin (a, b,
)
{a, b, ...}. Then, the final
.

.

.

mf�;:ilum '" .) .

of

rf (x): b

=

Set X according to predefined assignment, and put un­
movable component index into set I

2: while
3:

=

benefit result function is

rf (x)

=

The final benefit

f.rf(X)XdX.
j rf(x)dx

Tmin (

.

.

.

, 0 4409 X
.

4:

bvalue is the center
5:
6:

Similarly to benefit aggregation, fuzzy inference is also

Algorithm: solution construction.

III :::::

m

do

Choose i uniformly at random,
where 1 ::::: i ::::: m and i � I
Choose j randomly with probability in (14),
where 1 ::::: j ::::: n
Xij +- 1
I +- I U {i}

7: end while

applied to aggregate offloading risks and the final risk is

denoted as

r.

Both band

r

are within range

[0,1].

D. Risk-Based Decision
The final benefit aggregated by user preference depends on

mapping matrix X and the final risk. Thus band r in previous
section are actually b(X) and r(X). The offloading problem
is to find mapping X to maximize the aggregate benefit, and
meanwhile, the constraint is satisfied that the aggregate risk is
smaller than the benefit:

max b(X),
S.t. b(X) > r(X) .

(12)
(13)

The ant algorithm is based on the following philosophy:
high pheromone accumulated on the edge indicates this as­
signment is a potential good assignment; the ant chooses a
potential good edge intentionally. However, the ant does not
give up the choices of other edges.
Algorithm 3

Algorithm: local search.

I +-0
2: for 1 to a do
3:
Choose i uniformly at random,
where 1 ::::: i ::::: m and i � I
4:
J +-0
1:

5:

while

IJI :::::

ndo

motivation or benefit overwhelms the offloading risk. To solve

7:

Choose j uniformly at random,
where 1 ::::: j ::::: nand j � J
X' +- X, and change assignment from

the above problem, we design an ant-algorithm based approach
in Alg. 1.

8:

if

The offloading decision considers trade off of benefit and

6:

risk. The offloading is allowed only when the offloading

Algorithm 1
1:

Algorithm overview.

Initialization

2: repeat

10:

end if

11:

J +- JU {j}

12:

end while

13:

I +- I U

and

b(X')

>

r(X')

i

to

j

in

X'

then

{i}

14: end for

3:

Solution construction
Local search
5:
Pheromone update
6: until stopping criteria is reached
4:

The previous problem can be represented by graph G
where 8
{C, S}. Edges A connect components to
sites. An ant at component vertex chooses site vertex as next
vertex to go and leaves pheromone on the trail.
=

(8, A)

9:

b(X) < b(X')
X +- X'

=

The algorithm maintains a counter 'Y and a pheromone
matrix T . At the beginning, 'Y is set to 0, and Tij is set to
1 where 1 ::::: i ::::: m and 1 ::::: j ::::: n. Then, three steps are
executed in a loop until the result is reached. 'Y increases by 1
each round in loop. T is used to guide the transition in solution
construction step, and is updated in pheromone update step.
Two stopping criteria are: the counter reaches 'Ym ax, and the
result stagnates. When either criterion is met, the algorithm
stops.

1) Solution Construction: The solution construction is
shown in Alg. 2. The ant goes from component i to site j
with the probability:
(14)

2) Improvement Procedure: The neighborhood X' is ob­
tained by changing one assignment in the solution X. The
improvement procedure searches the neighborhood area and
finds the valid local optimal solution as shown in Alg. 3. The
local search improves X through iterations. The parameter a
controls the iteration times. The high a means the local search
algorithm will try to explore more neighbors. The value range
of a is [1,m].
3) Pheromone Update: The elements of pheromone matrix
are updated as:
(15)
where

Xij
Xij
if Xij

if

=

if

=

=

1 in current X"Y
1 in best Xbest
1 in X"Y and Xbest

.

(16)

otherwise
*

Two parameters 'f} and 'f} control the search scheduling. 'f}
is set to 1 at the beginning and varies in the run, while 'f}* is
fixed in the whole process. In two cases, pheromone updates

in alternative way that is different from (16):

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

233

CNSM Mini-Conference Paper

1)

2)

When the best result ever found Xbest has been
improved by current solution X"!, the ry is reset to
1 and all Tij are reset to 1. The resetting remove
historical information and intensify the search around
new direction Xbest.
When current solution X,,! reaches Xbest, which
means the focus on Xbest is to too high, ry is increased
by 1 and all Tij are reset to new ry to diversify the
search.

The risk constraint in the problem is treated by parameter
A. When the solution X does not obey risk constraints, the
positive feedback on pheromone is removed by paying penalty:

*

in iteration range [25,50]. When ry raises, more cases that
are solved originally in higher iteration numbers [25,50] will
be solved in less iterations, which leads to the case number
*
increases in range [1,20]. When ry increases, more pheromone
will accumulate on the links that belong to the best solution
Xbest' This accumulated pheromone guides the ant to pick
those links more often than other links, so that the ant goes to
*
the direction of the Xbest. The higher ry is, the better sense
of direction the ant has, which avoid ant's heading in random
direction and save iterations.
By comparing figures of the same
=

if

b(X"!)

<

r(X"!)

(17)

otherwise

=

EVALUATIONS

We evaluate our ant based algorithm by simulation in
MATLAB. We generate 50 test cases for evaluation. In each
case, parameters for time, energy, privacy and reliability factors
are generated. For time factor, one application graph and
one surrogate graph are generated. The application component
number is set to 5 and the candidate surrogate site number
is set to 3. The workload wand site processing ability u
are generated uniformly at random in range [1,100] and
[1,10] separately. The data exchange amount F and network
throughput D are uniformly random distributed in range [1,10]
and [1,100] separately. This parameters are set in order to meet
the assumption that the application is computation intensive
as the average time spent on computation is much greater
than data exchange. For energy factor, the coefficients of
mobile devices are similar to [15]. The CPU coefficients of

dynamic and static parts are random in range

[4,6] and [1, l.5]

separately. The RF coefficients of dynamic and static parts are

random in range [2,3] and [1, l.5] separately. For privacy and
reliability factors, the event probabilities are random in range
[0,0.2]. These events are assumed to happen in low probability
in real situations.
A. ry

*

impact
*

In the proposed algorithm, there are two parameters ry
*
and a for performance tuning. The parameter ry indicates the
search direction in the whole solution space. In every iteration
of searching, the best solution ever found is always assigned
more pheromone, which guides the ant to go to that direction
in high probability in following iterations. The performance
*
impact of ry is shown in Fig. 2, which shows the algorithm
performance when a values are fixed at 1, 3 and 5. In the
figure, the y axis represents the average case number and

the x axis represents the iteration sequence number when the
solution X is found. Every point ( x, y) in the figure represents
th iteration. The lines
x cases reach their final solutions in the y
in the figure represent the case numbers distributed in iteration

number range [1,50]. Since the total case number is 50, the
area below each line should be 50.
*

In all three situations of a
1,3,5, the line ry
*
higher than ry
3 and the line ry* 3 is higher than ry*
*
in iteration range [1,20]. And meanwhile, the line ry
*
*
lower than ry
3 and the line ry
3 is lower than ry*
=

=

=

=

=

=

=

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

5 is
1
5 is
1
=

=

234

values, we also find
=

=

B.

a

=

=

=

=

IV.

a

that the more cases reach solutions in small iteration from line
*
ry
1 to line ry* 3 than from line ry* 3 to line ry* 5.
This is obvious in range [1,10]: the incremental case number
*
between line ry
1 and line ry* 3 is larger than that between
*
line ry
3 and line ry*
5. The incremental case number
*
decreases when the ry increases, which will finally lead to
*
the limit situation when increasing ry does not make iteration
*
number smaller. When ry is too high, the algorithm will always
search around the point Xbest in solution space and often hit it
again. When algorithm hits the Xbest again, the relative high
*
value of ry is decreased by the way of increasing ry in case 2
of pheromone update step in algorithm to guarantee the search
diversity.
impact
*

While parameter ry guides the global search, the parameter
a controls the local search. In Fig. 2a,2b and 2c, the case
3
number from line a
1 to a
3 and from line a
to a
5 increases in range [1,12] and decreases in range
[23,50], which means some cases that are solved originally
in high iteration numbers are solved in less iterations. This is
obvious in iteration range [1,12] where the line a
3 is above
a
l. Similar phenomenon is also seen in Fig. 2d,2e,2f and
Fig. 2g,2h,2i. When a increases, the algorithm searches the
near solution around the picked X. The near solution is the
solution that has only one different assignment of component
to site. Since the component number is limited, the largest a
value is bounded by component number. The higher the a is,
the more neighbors the algorithm explores in each iteration,
=

=

=

=

=

=

and the earlier the algorithm finds the best solution in the

dedicated area, which leads to improvement of performance
from iteration number aspect. However, the local search costs
more time when we increase local search quality. Although the
iteration number is decreased, the time spent for each iteration
is increased because high a requires more attempts to explore
neighbors.
V.

CONCLUSIONS

In this paper, we proposed a multi-factor multi-site risk­
based offloading decision model that is generic and extendible.
The offloading decision is made based on a comprehensive
offloading risk evaluation. To show how the model works,
we used four offloading impact factors, including two benefit

factors and two risk factors. We used fuzzy inference to
aggregate the overall offloading benefits and risks based on the

mobile cloud users preference, and used ant-based algorithm
to calculate the assignment from application components to
surrogate sites. The performance evaluation presents the prac­
ticality of the presented solution.

CNSM Mini-Conference Paper

l�- - l95%
1'�I,a�1

�2

�I�--10 20
(a) 71*

_

01-

'+-

_ _
-

--

_ __ _ _

30

40

Iterations
=

prediction bounds

01

1, C\'

=

OL-__�____�
�__�____��___

10

1

20

(b) 71*

30

40

Iterations
=

1, C\'

=

3

.....
<..>

o
'It

'It

OL-__��--��--��--�
�---

20

(d) 71

2
01
�

-

30

Iterations
=

3, C\'

=

1

40

__
__
o �__��__
��
��

10

20

*
(e) 71

��

30

Iterations

=

3,

C\' =

40

___

prediction bounds

<..>

10

30

20

*
(g) 71

o �__�____�____�____

10

Iterations
=

5,

C\' =

1

20

*
(h) 71

=

5,

C\' =

[10]

=

1,

C\' =

5

- "-'-'-

10

20

*
(f) 71

30

40

Iterations

=

3,

C\' =

5

�11'�
- - 95%5,a�5

�

prediction bounds

40

__�

o

��__�����a

10

3

*
(i) 71

20

30

40

Iterations

=

5,

C\' =

5

R. Wolski, S. Gurun, C. Krintz, and D. Nurmi, "Using bandwidth
data to make computation offioading decisions," in IEEE International
Symposium on Parallel and Distributed Processing (IPDPS).
IEEE,

2008, pp. 1-8.
[11]

code offload," in Proceedings of the 8th international conference on
Mobile systems, applications, and services. ACM, 2010, pp. 49-62.

D. Shin, K. Kim, N. Chang, W. Lee, Y. Wang, Q. Xie, and M. Pedram,
"Online estimation of the remaining energy capacity in mobile systems
considering system-wide power consumption and battery characteris­
tics," in 18th Asia and South Pacific Design Automation Conference
(A SP-DAC). IEEE, 2013, pp. 59-64.

[12]

S. Kosta, A. Aucinas, P. Hui, R. Mortier, and X. Zhang, "Thinkair:
Dynamic resource allocation and parallel execution in the cloud for
mobile code offloading," in Proceedings of IEEE INFOCOM, 2012, pp.
945-953.

c. Yoon, D. Kim, W. Jung, C. Kang, and H. Cha, "Appscope: Applica­
tion energy metering framework for android smartphone using kernel
activity monitoring," in USENIX ATC, 2012.

[13]

L. Zhang, B. Tiwana, Z. Qian, Z. Wang, R. P. Dick, Z. M. Mao,
and L. Yang, "Accurate online power estimation and automatic battery
behavior based power model generation for smartphones," in Pro­

REFEREN C ES
E. Cuervo, A. Balasubramanian, D.-k. Cho, A. Wolman, S. Saroiu,
R. Chandra, and P. Bahl, "Maui: making smartphones last longer with

X. Zhang, A. Kunjithapatham, S. Jeong, and S. Gibbs, "Towards an
elastic application model for augmenting the computing capabilities of
mobile devices with cloud computing," Mobile Networks and Applica­
tions, vol. 16, no. 3, pp. 270-284, 2011.
K. Sinha and

M. Kulkarni, "Techniques for fine-grained, multi-site

ceedings of the eighth IEEEIACMIIFIP international conference on
Hardware/software codesign and system synthesis.
ACM, 2010, pp.

105-114.

[14]

computation offloading," in 1 lth IEEEIACM International Symposium

on Cluster, Cloud and Grid Computing (CCGrid).

184-194.
[5]

40

Performance tuning.

The authors would like to thank NSF #1239396 grant to
support the research on the MIDAS project.

[4]

�

30

Iterations

ACKNOW LEDGMENT

[3]

(c) 71*

30

Iterations

'It

o �__�____�____�____�__�

[2]

2
'EI

20

<..>

'It

[I]

2
1
0

3

�11'�
- - 95%5,a�3

_ _ _ _ _

.....

Fig. 2.

10
�

*

prediction bounds

<..>

_ _ _
_

10

�11'�
- - 95%I,a�5

_

.....

- - -'- -

� 2 = �==

'It

OL.
__�____�
�--��--��---

�2

1�- - 11'�
95%I,a�3

prediction bounds

IEEE, 2011, pp.

R. Kemp, N. Palmer, T. Kielmann, and H. Bal, "Cuckoo: a compu­
tation offioading framework for smartphones," in Mobile Computing,

Applications, and Services.

W. Jung, C. Kang, C. Yoon, D. Kim, and H. Cha, "Devscope: a
nonintrusive and online power analysis tool for smartphone hardware
components," in Proceedings of the eighth IEEEIACMIIFlP interna­
tional conference on Hardware/software codesign and system synthesis.

ACM, 2012, pp. 353-362.

[IS]

Y. Wang, X. Lin, and M. Pedram, "A nested two stage game-based
optimization framework in mobile cloud computing system." in SOSE,
2013, pp. 494-502.

Springer, 2012, pp. 59-79.

[6]

B.-G. Chun, S. Ihm, P. Maniatis, M. Nail<, and A. Patti, "Clonecloud:
elastic execution between mobile device and cloud," in Proceedings of
the sixth conference on Computer systems. ACM, 2011, pp. 301-314.

[16]

[7]

R. K. Ma, K. T. Lam, and c.-L. Wang, "excloud: Transparent runtime
support for scaling mobile applications in cloud," in International
Conference on Cloud and Service Computing (CSC).
IEEE, 2011,
pp. 103-110.

J. C. McCullough, Y. Agarwal, J. Chandrashekar, S. Kuppuswamy, A. C.
Snoeren, and R. K. Gupta, "Evaluating the effectiveness of model-based
power characterization," in USENIX Annual Technical Conf, 20II.

[17]

[8]

1. Giurgiu, O. Riva, D. Juric, 1. Krivulev, and G. Alonso, "Calling the
cloud: enabling mobile phones as interfaces to cloud applications," in
Middleware. Springer, 2009, pp. 83-102.

R. Mittal, A. Kansal, and R. Chandra, "Empowering developers to
estimate app energy consumption," in Proceedings of the 18th annual
international conference on Mobile computing and networking. ACM,
2012, pp. 317-328.

[18]

[9]

S. Ou, Y. Wu, K. Yang, and B. Zhou, "Performance analysis of fault­

Q. Ni, E. Bertino, and J. Lobo, "Risk-based access control systems
built on fuzzy inferences," in Proceedings of the 5th ACM Symposium
on Information, Computer and Communications Security. ACM, 2010,
pp. 250-260.

tolerant offioading systems for pervasive services in mobile wireless

environments," in IEEE International Conference on Communications
(ICC). IEEE, 2008, pp. 1856-1860.

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

235

CNSM Mini-Conference Paper

2016 IEEE Conference on Communications and Network Security (CNS)

Security Policy Checking in Distributed SDN based
Clouds
Sandeep Pisharody, Ankur Chowdhary and Dijiang Huang
School of Computing, Informatics and Decision Systems Engineering
Arizona State University, Tempe, AZ 85281
{spishar1, achaud16, dhuang8}@asu.edu
Abstract—Separation of network control from devices in
Software Defined Network (SDN) allows for centralized implementation and management of security policies in a cloud
computing environment. The ease of programmability also makes
SDN a great platform implementation of various initiatives that
involve application deployment, dynamic topology changes, and
decentralized network management in a multi-tenant data center
environment. Dynamic change of network topology, or host
reconfiguration in such networks might require corresponding
changes to the flow rules in the SDN based cloud environment.
Verifying adherence of these new flow policies in the environment
to the organizational security policies and ensuring a conflict free
environment is especially challenging. In this paper, we extend the
work on rule conflicts from a traditional environment to an SDN
environment, introducing a new classification to describe conflicts
stemming from cross-layer conflicts. Our framework ensures that
in any SDN based cloud, flow rules do not have conflicts at
any layer; thereby ensuring that changes to the environment
do not lead to unintended consequences. We demonstrate the
correctness, feasibility and scalability of our framework through
a proof-of-concept prototype.

I.

I NTRODUCTION

Software Defined Networking (SDN) is a transformative
approach to network design and implementation based on the
premise that separating control of network functions from the
network devices themselves (switches, routers, firewalls, etc.)
grants network administrators granular control over traffic flow.
Using the OpenFlow protocol, SDN switches can leverage the
flexibility afforded by the ability to access header information
from several layers of the Open Systems Interconnection (OSI)
stack. The programmability of SDN can be utilized to respond
rapidly to changing user and security requirements by enabling
dynamic network reconfiguration. However, this flexibility and
programmability also brings to light complex issues with
regards to implementing a holistic security infrastructure for
an SDN based cloud computing environment. Amongst these
are issues caused by flow rule chaining, cross-layer policy
conflicts, partial matches, and challenges due to set-field
actions; all of which are unique to SDN environments. Further,
abstracting the data plane from the control plane means that
multiple tenants of the cloud could share the same physical
network. The users on these cloud environments would control
and secure their logical infrastructure by implementing flow
rules without any knowledge of the system as a whole. While
these flow rules are implementing perceivably private security
policies, their presence on a shared control plane means

978-1-5090-3065-1/16/$31.00 ©2016 IEEE

it could lead to potential flow rule conflicts in the overall
environment.
Just as firewall conflicts in a traditional network limits the
effectiveness of a security infrastructure [1], conflicts between
flow rules on the controller limits the effectiveness and impact
of a security infrastructure in an SDN based cloud. Unlike a
traditional network where new rules can get added only by
an administrator, in an SDN based cloud environment, any
module running on the controller could introduce new flow
rules without having an understanding of existing flow rules or
the desired security policy, which could also result in conflicts.
To complicate matters further, a dynamically changing network
topology adds its own wrinkles.
Substantial research has attempted to address the problems
brought forth above, significant amongst which are FortNOX
[2] and Flowguard [3] (Section II discusses these further).
While these solutions deal effectively with direct policy conflicts and flow violations, they do not tackle a problem that is
heightened in an SDN environment - cross-layer policy conflicts. In several multi-tenant clouds implemented using SDN,
tenants use flat layer-2 topologies due to latency concerns and
the ability to conduct inline promiscuous monitoring using
layer-2 devices [4]. A natural extension would be to implement
layer-2 flow rule policies. The data center itself might operate
in a more traditional fashion with flow rules based on layer3 addresses. Further, in a traditional environment, a firewall
can satisfactorily enforce security policies by having an endto-end view based on layer-3 addresses. But in an SDN based
cloud, policies could be based on layer-2 tunnels over multihop networks. If different policy enforcement points enforce
policies based on different layers, inconsistent actions could
result. Cross-layer conflicts become exacerbated in an SDN
based cloud where each SDN switch, both physical and virtual,
can be considered to be a distributed firewall instance, with a
different local view of the environment and policies.
In our work, we present a formalism for reasoning about
conflicts in OpenFlow rules, motivated by the use case of
a dynamically changing cloud environment. We begin by
classifying all potential conflicts in an SDN environment and
introduce a new class of conflicts, imbrication, that accounts
for indirect cross-layer policy conflicts. Using this formalism,
we develop a methodology to conduct temporal mapping
between the address ranges of the policies thereby accurately
detecting cross-layer conflicts. We develop a controller-based
algorithm for detecting conflicts in a flow tables. We further

2016 IEEE Conference on Communications and Network Security (CNS)

address automatic and assisted conflict resolution mechanisms.
This work is implemented in a framework that effectively
scrubs the flow table, highlighting and resolving all potential
conflicts. Moreover, we account for the possibility that in a
multi-tenant cloud environment, not all parties would play fair,
with some attempting to prioritize their security policy - a
problem our framework effectively addresses. To summarize,
in this work we classify, detect and resolve flow rule conflicts
in an SDN based distributed cloud environment including
cross-layer policy conflicts. Correctness was verified on a test
network with 100 rules in its flow table and scalability was
tested on the Stanford backbone rule set [5], extrapolated upto
100, 000 rules. Performance impact of running our module on
the controller was also evaluated, and found to be within an
acceptable 5% overhead.
This paper is organized as follows. We discuss related work
in Section II. In Section III we lay out some background
information about flow rule conflicts, produce a real-world
motivating scenario for our framework along with formalizing
and classifying flow rule conflicts. In Section IV we discuss
our system design and implementation details. Evaluation
information is discussed in Section V. Finally, we conclude
and comment on our future research tasks in Section VI.
II.

R ELATED W ORK

There have been several attempts at a security solution
in SDN. The most basic SDN firewall is introduced as part
of Floodlight [6], where each new packet in a flow is sent
to the controller, where it is matched against a set of rules.
The resulting action set is then sent to the OpenFlow switch
for implementation for the current and future matching flows.
In case of dynamic security policy updates to the controller,
the OpenFlow switches could be left implementing a dated
action set. Javid et al. [7] built a layer-2 firewall for an SDN
environment using a tree topology for a small network using
a POX controller and restricted traffic flow as desired. Suh et
al. [8] illustrated a proof-of-concept version of a traditional
firewall over an SDN controller. But neither of these works
addressed the problem of conflicting flow rules.
Pyretic [9] deals effectively with direct policy conflicts,
by placing them in a prioritized rule set much like the
OpenFlow flow table. However, indirect security violations or
inconsistencies in a distributed SDN environment cannot be
handled by Pyretic without a flow tracking mechanism such
as the one discussed by Fayazbakhsh et al. [10]. FRESCO
[11] allows for the implementation of security services in
an OpenFlow environment by providing reusable modules
accessible through a Python API. To address conflicts that
might arise in an OpenFlow environment, FRESCO introduces
a Security Enforcement Kernel (SEK) that prioritizes rules to
assist in conflict resolution.
FortNOX [2] is an extension to the NOX controller that
implements role-based and signature based enforcement to
ensure modules do not circumvent the existing security policy.
In FortNOX, reusable modules are used to protect the flow installation mechanism against adversaries, but conflict analysis
is conducted only between a new flow rule and existing rules,
without considering dependencies within flow tables. Thus,

implementing FortNOX in a distributed environment would be
challenging. Decision making in FortNOX seems to follow a
least permissive strategy instead of making a decision keeping
the holistic nature of the environment in mind. Moreover, it
uses only IP and port information for conflict detection, which
we believe is incomplete since SDN flow rules could use purely
layer-2 addresses for decision making. In addition FortNOX
would not be able to handle partial flow rule conflicts.
Flowguard [3] is a security tool specifically designed to
resolve security policy violations in an OpenFlow network.
Flowguard examines incoming policy updates and determines
flow violations in addition to performing stateful monitoring.
It uses several strategies to refine anomalous policies, most of
which include rejecting a violating flow.
VeriFlow [12] is a proposed layer between the controller
and switches which conducts real time verification of rules
being inserted. It verifies that flow rules being implemented
have no errors due to faulty switch firmware, control plane
communication, reachability issues, configuration updates on
the network, routing loops, etc. However, none of the solutions
discussed tackle what we believe is a problem that is heightened in an SDN environment - cross-layer policy conflicts in
distributed environments. To that end, we propose a tool that
will consider cross-layer dependencies while ensuring conflictfree policies in a SDN based distributed cloud environment.
III.

BACKGROUND & M ODEL

A. Motivating Scenario
Implementing a management system that only specifies security policies without tackling topological interaction amongst
constituent members has always been a recipe for conflicts
[13]. With the SDN controller having visibility into the entire
system topology along with the policies being implemented,
several of the conflict causing scenarios in traditional networks
were handled. However, there are several instances where
conflicts can creep into the flow table such as a) service chain
processing where multiple flow tables that handle the same
flow might have conflicting actions; b) VPN implementations
that modify header content could result in flow rules being
inadvertently being applied to a certain flow; c) flow rule injection by different modules (using the northbound API provided
by the controller) could have conflicting actions for the same
flow; d) matching on different OSI layer addresses resulting
in different actions; and e) administrator error. This list, while
incomplete, goes to show how prevalent policy conflicts in
SDN environments could be. We illustrate a L2VPN based
scenario to serve as a real life motivating example.
In a multi-tenant hosted data center cloud, the provider
could have layer-3 rules in place to prevent certain tenants
from sending traffic to one another for monetization, compliance or regulatory reasons. Hosts in two different tenant
environments, Tenant A and Tenant B, can establish a layer-2
tunnel (either as a host-to-host tunnel or a site-to-site tunnel)
between themselves to do single hop computation or to encrypt
communication between them as shown in Figure 1. To accommodate this VPN, flow rules will be inserted on the controller
that permit traffic between the layer-2 addresses of servers on
Tenant A and Tenant B; which clearly conflict with the earlier

2016 IEEE Conference on Communications and Network Security (CNS)

host C in Figure 5. This flow would clearly match rule 8 in
Table I based off a layer-2 address match; and rule 1 based
off a layer-3 address match. A flawed approach to tackle this
problem would be to expand the header space and determine
rule conflicts as in a traditional environment since there exists
an indirect dependency between the layer-2 and layer-3 addresses. Moreover, flow rules could exist that do not include
all the header fields making an apples-to-apples comparison
impossible. We take a different approach to detecting and
solving indirect conflicts (discussed in Section III-C). Since
these conflicts arise as a result of addressing across different
OSI layers, we categorize them accordingly and tackle it as
such.
C. Conflict Classification
We first formally define the set operations on address
spaces. Let ξ be a 2-tuple address space (ξs , ξd ), with subscript
s denoting the source address set and d denoting the destination
address set. Then the following definitions apply.
Fig. 1.

Motivating scenario for cross-layer conflicts.

policy of not allowing traffic between the layer-3 addresses of
Tenant A and Tenant B. Further, if a policy is inserted into the
controller to implement Deep Packet Inspection (DPI) on all
packets exiting Tenant A, all traffic from Tenant A to Tenant
B will be dropped, since they are encrypted and fail the DPI
standards. Clearly there is an inherent conflict between flow
rules inserted by different modules that are running on the
SDN controller, leading to a shoddy user experience.

Definition 1. An address space ξi ⊆ ξj if and only if they
refer to the same OSI layer, and ξs i ⊆ ξs j ∧ ξd i ⊆ ξd j .
Definition 2. An address space ξi 6⊆ ξj if and only if they
refer to the same OSI layer, and ξs i 6⊆ ξs j ∨ ξd i 6⊆ ξd j .
Definition 3. An address space ξi ⊂ ξj if and only if they refer
to the same OSI layer, and (ξs i ⊂ ξs j ∧ ξd i ⊆ ξd j ) ∨ (ξs i ⊆
ξs j ∧ ξd i ⊂ ξd j ).

B. Flow Rule Management Challenges

Definition 4. Address space intersection ξi ∩ ξj produces a
tuple (ξs i ∩ ξs j , ξd i ∩ ξd j ) if and only if ξi and ξj refer to the
same OSI layer. When ξi and ξj are not addresses in the same
OSI layer, the ∩ operation is invalid.

Security implementations using SDN leverage the ability
to make dynamic changes to the network and system configurations to have a lean, agile and secure environment. Since this
usually results in environments that are constantly in flux, any
kind of a security infrastructure has to detect these changes in
real time, and update flow rules on the (distributed) controllers
to keep it in line with the security policy of the organization.
Since flow rules have the ability to match more than just
layer-3 and layer-4 headers as in a traditional network, they
are inherently more complex by virtue of having additional
variables to consider for a match. The actions that can be
applied on a match include forwarding to specific ports on
the switch, flooding the packet, changing its QoS levels,
dropping the packet, encapsulating, encrypting, rate limiting or
even customizable actions using various set-field actions.
Since cross-layer interaction is bolstered in SDN by virtue
of having flow rules that permit set-field actions, several
packet headers can be dynamically changed. And lastly, since
wildcard rules are allowed, a partial conflict of a flow policy
could occur, thereby adding complexity to the resolution of
conflicting flow rules.
As opposed to a traditional network, flow rules in SDN,
could have the same priorities as well as matches on multiple
header fields, thereby resulting in indirect dependencies. For
example, consider traffic originating from host A destined to

Rules present in a flow table consist of a) rule priority;
b) match fields consisting of header information and ingress
port that is used to match flows; c) packet counters; d) the
action set; and e) timeouts. Of these fields, we focus on just
priority, match fields and actions to handle flow rule conflicts.
Table I shows sample flow table rules with the relevant fields
present. Ingress port and VLAN fields have been ignored in
this example.
Since flow table rules in an SDN environment closely
match firewall rules, we extend the work done on firewall rule
conflicts. Although there have been several attempts to classify
firewall rule conflicts [13], [14], [15], [16], the seminal work
by Al-Shaer and Hamed [17] is often used to classify firewall
rule conflicts in a single firewall environment. We build on
that work to formally classify flow rule conflicts.
In a flow table F containing rule set {r1 , r2 , ..., rn }; we
can represent ri = (pi , λi , i , ζi , ηi , ϕi , ρi , ai ), where a) p is
the priority of the rule and is defined in the range [1, 65535];
b) λ is the ingress port; c)  is a 2-tuple (s , d ) OSI layer-2
address space, with subscript s denoting source and d denoting
destination address; d) ζ is a 2-tuple (ζs , ζd ) OSI layer-3
address space, with subscript s denoting source and d denoting
destination address; e) η is a 2-tuple (ηs , ηd ) OSI layer-4
address space, with subscript s denoting source and d denoting
destination address; f) ρ is the layer-4 protocol; and g) action

2016 IEEE Conference on Communications and Network Security (CNS)

Rule #

Priority

Source
MAC

Dest
MAC

Source
IP

Dest
IP

Protocol

Source
Port

Dest
Port

Action

1
2
3
4
5
6
7
8
9

51
50
52
53
54
51
55
57
58

*
*
*
*
*
*
*
11:11:11:11:11:ab
*

*
*
*
*
*
*
*
11:11:aa:aa:11:11
*

10.5.50.0/24
10.5.50.5
10.5.50.5
10.5.50.0/24
10.5.50.5
10.5.50.0/16
10.5.50.5
*
*

10.211.1.63
10.211.1.63
10.211.1.0/24
10.211.1.63
10.211.1.63
10.211.1.63
10.211.1.0/24
*
*

tcp
tcp
tcp
tcp
tcp
tcp
tcp
*
tcp

*
*
*
*
*
*
*
*
*

*
80
*
*
*
*
80-90
*
80

permit
permit
permit
deny
deny
deny
deny
permit
deny

TABLE I.

F LOW TABLE EXAMPLE .

a is the action set for the rule.
Knowing that OpenFlow specifications clarify that if a
packet matches two flow rules, only the flow rule with the
highest priority is invoked, the different flow rule conflicts are
categorized as below:
• Redundancy: A rule ri is redundant to rule rj iff
a) address space i ⊆ j ∧ ζi ⊆ ζj ∧ ηi ⊆ ηj ; b) protocol
ρi = ρj ; and c) action ai = aj . For example, rule
2 in Table I has a packet space that is a subset to
the packet space of rule 1, with matching protocol and
actions. Hence, rule 2 is redundant to rule 1. Redundancy
does not pose a serious issue, but instead is more of an
optimization and efficiency problem.
• Shadowing: A rule ri is shadowed by rule rj iff a) priority pi < pj ; b) address space i ⊆ j ∧ ζi ⊆ ζj ∧ ηi ⊆ ηj ;
c) protocol ρi = ρj ; and d) action ai 6= aj . In such a
situation, rule ri is never invoked since incoming packets
always get processed using rule rj , given its higher
priority. Shadowing is a potentially serious issue since
it shows a conflicted security policy implementation [17].
For example, rule 4 in Table I has the same packet space
as rule 1, with the same protocol, but conflicting actions.
Hence, rule 1 is shadowed by rule 4.
• Generalization: A rule ri is a generalization of rule rj
iff a) priority pi < pj ; b) address space (i ⊃ j ∧ ζi ⊇
ζj ∧ ηi ⊇ ηj ) ∨ (i ⊇ j ∧ ζi ⊃ ζj ∧ ηi ⊇ ηj ) ∨ (i ⊇
j ∧ ζi ⊇ ζj ∧ ηi ⊃ ηj ); c) protocol ρi = ρj ; and d) action
ai 6= aj . In this case, the entire packet space of rule rj is
matched by rule ri [17]. As shown in Table I, rule 1 is a
generalization of rule 5, since the packet space of rule 5
is a subset of the packet space of rule 1, and the actions
are different. Note that if the priorities of the rules are
swapped, it will result in a shadowing conflict.
• Correlation: Classically, a rule ri is correlated to rule
rj iff a) priority pi < pj ; b) address space i 6⊆ j ∧ ζi 6⊆
ζj ∧ ηi 6⊆ ηj ∧ i 6⊇ j ∧ ζi 6⊇ ζj ∧ ηi 6⊇ ηj ∧ (i ∩ j 6=
∅ ∨ ζi ∩ ζj 6= ∅ ∨ ηi ∩ ηj 6= ∅); c) protocol ρi = ρj ; and
d) action ai 6= aj [17]. As shown in Table I, rule 3 is
correlated to rule 4. Since multiple SDN flow rules can
have the same priority, we make the following addition to
the correlation conflict: A rule ri is correlated to rule rj iff
a) priority pi = pj ; b) address space i ∩j 6= ∅∨ζi ∩ζj 6=

∅∨ηi ∩ηj 6= ∅; c) protocol ρi = ρj ; and d) action ai 6= aj .
Thus the correlation conflict now encompasses all policies
that have the different actions, overlapping address spaces
and the same priority. For example, in Table I, rule 6 is
correlated to rule 1.
• Overlap: A rule ri overlaps rule rj iff a) priority pi ≤
pj ; b) address space i 6⊆ j ∧ζi 6⊆ ζj ∧ηi 6⊆ ηj ∧i 6⊇ j ∧
ζi 6⊇ ζj ∧ηi 6⊇ ηj ∧(i ∩j 6= ∅∨ζi ∩ζj 6= ∅∨ηi ∩ηj 6= ∅);
c) protocol ρi = ρj ; and d) action ai = aj . An overlap
rule is essentially a correlation; but with the same action
set. This overlap can be seen between rule 6 and rule 7
in Table I.
• Imbrication: The criteria discussed above does not cover
all potential conflicts. Consider the case of flow rules,
a) only layer-3 header is used as a condition (rule 1-7);
b) only layer-2 header is used as a condition for decision
(rule 8); and c) only layer-4 header is used as a condition
(rule 9). Even though using our definition there is no
overlap in packet space, and hence there should be no
conflict, a packet could match more than one of these
rules. We classify such policy conflicts as imbricates, and
address them by introducing the concept of reconciliation
(described in Section IV) which maps all headers to the
same layer. Using the topology shown in Figure 5 and
the flow rules in Table I, we can see flow rule 4, which
denies traffic from host A to host D and flow rule 8, which
permits traffic from host A to any other host are clearly
imbricates.
IV.

S YSTEM D ETAILS

A. System Modules
Our framework as shown in Figure 3 is an intuitive model
to help resolve conflicts in flow rules in a distributed SDN
environment. It consists of several inter-related modules that
together achieve a conflict free flow table. It runs as an
application on the controller that listens for new/modified flow
rules from different applications running on the controllers.
The processing is compartmentalized to sanitization, conflict
detection and conflict resolution. The modules that accomplish
these tasks are:
• Flow rule monitor: The flow rule monitor intercepts any

2016 IEEE Conference on Communications and Network Security (CNS)

Fig. 2.

Venn diagram showing address space overlap and rule conflicts.

new or updated flow rule that is to be added to the flow
table. These rules, which we call candidate flow rules, can
be generated by any module running on the controller
or by the administrator. A candidate flow rule is not
completely processed and vetted, and hence is not eligible
to be sent to any of the devices. In a distributed controller
scenario, candidate flow rules into every controller is
obtained, in an effort to have complete knowledge of all
possible flow rules that are present in the environment.
The priority of the rules from the controller are modified
to a global priority, based on the decentralization strategy
that has been employed. Thus, the priority assigned by the
flow rule monitor may differ from the priority of the flow
rule present in the flow table. In a redundant controller
setup, only candidate rules from the master controller are
obtained, and in a truly distributed environment, candidate
flow rules are aggregated from all the controllers before
processing.
• Atomization engine: Since OpenFlow permits chained
flow rules by having an action for a match redirect to a
different flow table, in order to correctly identify conflicts
between flow rules, we atomize the flow rules by processing the chains and ensuring that only the atomic actions

of permit and deny remain. The atomization process itself
follows along the lines of ipchain processing in Unix.
There are two important considerations we make here.
◦ While the actions for a flow rule can include any drop,
forward, flood, set QoS parameters, change several
header fields, or redirect to a different flow table; we
process the actions and generically classify them into
two categories; permit and deny. For example, implementing an IP mapping rule in OpenFlow would change
the IP address headers and forward onto a different flow
table that forwards the traffic. We process such a chain
to include the address translation information and set
the final atomic action to be permit.
◦ For rules which have multiple actions, we duplicate the
rules to generate rules with identical priority and match
conditions with a single action.
• Conflict detection module: This module identifies conflicts based on the categories described in Section III-C.
Special attention is given to rules which have only layer2 match conditions by mapping them to their layer-3
addresses using a process we call reconciliation. The
mapping information is obtained using a temporal 1-to1 mapping by doing a table lookup. In cases where a

2016 IEEE Conference on Communications and Network Security (CNS)

mapping is found, we tag the rule indicating a reconciled address to identify flow rules which fall into the
imbrication conflict. Rules that have only layer-4 match
conditions are also tagged as such.
• Conflict resolution module: Once the flow rule conflicts have been detected, the conflict resolution module
is invoked. Most conflicts are resolved automatically.
However, in case of interpretative conflicts (Generalization, Correlation and Imbrication) which cannot be
resolved automatically, resolution strategies discussed in
Section IV-C are used.

Fig. 3.

System overview representing different constituent modules.

B. Conflict Detection Mechanism
The default OpenFlow rule specifications do not provide
us all the information we need to detect and resolve flow
rule conflicts. Thus we add a data structure to accompany the
existing OpenFlow rule using four additional fields over 32
bits of information as shown in Figure 4. These fields are:
a) One bit identifying if the rule in question has been tagged
as a reconciled rule (required for imbricate detection); b) seven
bits identifying the SDN controller to which the rule is going
to be inserted; c) sixteen bits for a global priority of the flow
rule (to be used for flow rule conflict resolution); and d) eight
bit Conflict Resolution Criteria (CRC) metric (discussed in
Section IV-C). Armed with these additional bits of information,
we can now detect flow rule conflicts using the methodology
shown in Algorithm 1.
During environment ramp up, the flow table on the

Fig. 4.

Data structure format.

controller is parsed, and atomized by the atomization engine.
As a result of this process, every flow rule that has an action
which leads to execution of a different flow table is modified
into one or more rules that have terminal actions of permit,
deny, QoS and packet count. Since QoS and packet counting
can be processed along with the permit and deny actions, these
rules are removed from further processing.
The conflict detection module reconciles all the layer-2

only rules by doing an address mapping to layer-3, and marks
them as a reconciled rule. Since we formally describe any
overlaps involving reconciled rules as imbricates, we process
those rules separately from non-reconciled rules and classify
them as such. The conflict detection module then employs a
Patricia trie [18] lookup to detect address space overlap.
The Patricia trie is an efficient search structure for finding
matching IP strings [19] with a good balance between running
time (lookup and update) and memory space requirement, and
has been used previously with great success [20], [21]. Since
we know that the layer-3 addresses are fixed length, we can
follow along a path from the root to a matching node to obtain
flow entries that match the address space of the flow being
processed. In cases of wildcard matches, all child nodes of
the matching node will represent flow entries conflicting with
the input flow. We do an octet wise Patricia trie lookup [19]
to look for IP address range overlap between the new rules
being inserted and existing rules in the flow table in a fast
and efficient manner. All detected conflicts are classified as
shown in Figure 2. Next, the conflict resolution module is
invoked. Details on the resolution strategies are provided in
Section IV-C.
C. Conflict Resolution Strategies
Once the conflicts between different flow rules have been
detected, the conflict resolution module attempts to resolve
these. The different conflict types can be broadly categorized
into Intelligible and Interpretative conflicts. The resolution
strategies for each of these two categories are markedly
different, as seen in Algorithm 2.
1) Intelligible Conflicts: Since flow rules that conflict with
each other in the Redundancy, Shadowing and Overlap classifications all have the same action they can be resolved without
the loss of any information. In other words, any packet that is
permitted by the controller prior to resolving the conflict will
continue to be permitted after conflict resolution.
Intelligible conflicts are resolved fairly easily by eliminating the rules that are not applied, or by combining and
optimizing the address spaces in the rules so as to avoid the
conflict. It could be argued that creative design of rules by
administrators result in flow rules that deliberately conflict so
as to optimize the number of rules in the flow table, especially
when it comes to traffic shaping policies. However, such optimization strategies stem out of legacy network management
techniques, and do not hold true in dynamic, large-scale cloud
environments where the flow table enforcing the policies in
the environment could have millions of rules.
2) Interpretative Conflicts: Conflicts that fall into the Generalization, Correlation and Imbrication classifications can not
be intuitively resolved without loss of some information, and
are interpretative in nature. As opposed to intelligible conflicts,
it is not guaranteed that any packet permitted by the controller
prior to resolving the conflict will be permitted after conflict
resolution. Since interpretative conflict resolution is lossy in
nature, the resolution strategies are not a one size fits all and
need to be adapted according to the cloud environment in
question. We discuss a few resolution strategies that could

2016 IEEE Conference on Communications and Network Security (CNS)

Algorithm 1 Conflict Detection Module
1: procedure F LOW C ONFLICTS (F lowT able f )
2: Input: Rule r, F lowT able f
3: Output: Conflict-free F lowT able f 0
4:
ATOMIZE(r)
5:
if r is layer-2 rule || layer-4 rule then
6:
R ECONCILE(r)
7:
if r doesn’t have Reconciled tag then
8:
γ ← SearchP atricia(L3Addr(r))
9:
if P rotocol(r)! = P rotocol(γ) then
10:
f 0 ← InsertF low(f, r) return f 0
11:
if Addr(r) ⊆ Addr(γ) then
12:
if Action(r) = Action(γ) then
13:
Conf lictResolve(r, γ, Redundancy)
14:
else
15:
if P riority(r) == P riority(γ) then
16:
Conf lictResolve(r, γ, Correlation)
17:
else
18:
Conf lictResolve(r, γ, Generalization)
19:
if Addr(γ) ⊆ Addr(r) then
20:
if Action(r) = Action(γ) then
21:
Conf lictResolve(r, γ, Redundancy)
22:
else
23:
if P riority(r) == P riority(γ) then
24:
Conf lictResolve(r, γ, Correlation)
25:
else
26:
Conf lictResolve(r, γ, Shadowing)
27:
if Addr(r) ∩ Addr(γ)! = ∅ then
28:
if Action(r) = Action(γ) then
29:
Conf lictResolve(r, γ, Overlap)
30:
else
31:
Conf lictResolve(r, γ, Correlation)
32:
Insert r to the PatriciaTrie and flow table
33:
else
34:
// Rules with Reconciled tag
35:
for Rule γ in f do
36:
if P rotocol(r) == P rotocol(γ) then
37:
if Addr(r) ∩ Addr(γ)! = ∅ then
38:
Conf lictResolve(r, γ, Imbrication)
39:
Insert r to the PatriciaTrie and flow table
be applied. Algorithm 2 makes a generic reference to a
Conflict Resolution Criteria (CRC) which is dependent on the
resolution criteria in use. The data structure we suggested as a
concomitant to the flow rules also refers to this CRC metric.
• Least privilege - In case of any conflict, flow rules that
have a deny action are prioritized over a QoS or a forward
action. If conflicts exist between a higher and lower
bandwidth QoS policy, the lower QoS policy is enforced.
The least privilege strategy is traditionally one of the most
popular strategies in conflict resolution [22].
• Module security precedence - Since flow rules in an SDN
based cloud environment can be generated by any number
of modules that run on the controller, an effective strategy
that can be put in place is to have a security precedence
for the origin of the flow rule [2]. Thus a flow rule
originating from a security module is prioritized over flow

Algorithm 2 Conflict Resolution Module
1: procedure C ONFLICT R ESOLVE (Rule r, Rule γ, ConflictType)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:

if ConflictType == Shadowing || ConflictType ==
Redundancy then
// No need to add these rules to the table
if ConflictType == Correlation then
if CRC(γ) > CRC(r) then
Addr(r) ← Addr(r) − Addr(r ∪ γ)
Insert r to the PatriciaTrie and flow table
else
Remove γ from PatriciaTrie and flow table
Addr(γ) ← Addr(γ) − Addr(r ∪ γ)
Insert γ, r to the PatriciaTrie and flow table
if ConflictType == Generalization then
if CRC(γ) > CRC(r) then
Addr(r) ← Addr(r) − Addr(r ∪ γ)
Insert r to the PatriciaTrie and flow table
else
Remove γ from PatriciaTrie and flow table
Insert r to the PatriciaTrie and flow table
if ConflictType == Overlap then
Addr(r) ← Addr(r ∪ γ)
Remove γ from PatriciaTrie and flow table
Insert r to the PatriciaTrie and flow table
if ConflictType == Imbrication then
if CRC(γ) > CRC(r) then
// No need to add these rules to the table
else
Insert r to the PatriciaTrie and flow table

rule from an traffic management or optimization module.
• Environment calibrated - This strategy incorporates learning strategies in the environment to make an educated
decision on which conflicting flow rule really needs to be
prioritized. Over time, if a picture can be formed about the
type of data that a certain tenant usually creates/retrieves,
or of the applications and vulnerabilities that exist in
the tenant environment, or the reliability of the software
modules inserting the flow rule; the conflict resolution
module may be able to prioritize certain flow rules over
others. However, these techniques falter while dealing
with a dynamic cloud, especially with Moving Target
Defense (MTD) based defensive strategies.
• Administrator assistance - Administrators that are willing
to give up automatic conflict resolution have the option to
be able to use their infinite wisdom to resolve conflicts.
This technique assumes that the administrator knows what
is best for the cloud environment. In addition to requiring
manual intervention to resolve conflicts, this method is
also susceptible to insider poisoning.
V.

E VALUATION

The modules described in Section IV were implemented in
JAVA, using a command line interface in its current iteration.
OpenDaylight (ODL) [23] Lithium was used as the OpenFlow controller and the L2Switch project was employed

Total Running Time (ms)

2016 IEEE Conference on Communications and Network Security (CNS)

101

Test network topology.

105

to connect to the Open vSwitch (OVS) switches. OVS and
ODL Lithium support both OpenFlow 1.0 and OpenFlow 1.3.
Our implementation correctly identifies flow rule conflicts
and classifies them, including temporal cross-layer conflicts.
Both intelligible and interpretative conflicts are automatically
resolved using the least privilege resolution strategy.
A simple network with topology shown in Figure 5 was
implemented on Mininet to instantiate Open vSwitch switches
and virtual hosts using a python script. The flow table rules
shown in Table I were used to constrain traffic in the network.
Since the flow rules in the table were implemented explicitly
with different priorities, traffic flow was as expected. When we
processed the flow rules using our framework, it was correctly
able to identify several flow rule conflicts, and correct them.
Here, we compared our framework with closest related works
such as FortNox [2] and FlowGuard [3], and determined that
20% of the conflicts we detected were imbrication conflicts,
which would not have been detected by earlier works.
In the next phase of our evaluation, we tested the scalability
of system. Here, we performed experiments based on a realworld network topology derived from the Stanford network as
obtained by Kazemian et al. [5]. Both the conflict detection and
resolution algorithms grow in a linear fashion, except for the
Patricia trie lookup and insertion time. The time complexity
of a lookup on a Patricia trie depends on the length of the
string (constant in our case) and the number of flow rules; for
a total runtime of O(n) [18], where n is the number of entries
in the flow table. This result was verified experimentally using
a 2.5 GHz Intel Core i7 machine with 16 GB DDR3 memory.
With an input file containing about 10, 000 atomic flow rules,
the processing time was about 6.45 ms. Rules were further
replicated and inserted into the system to observe growth of
computation time. Figure 6 shows results from our experiment
runs using different input flow table sizes. Ten different test
runs were conducted on flow tables of size varying from
10, 000 to 100, 000 rules, and the resulting running times were
averaged to get the results in the plot. The results clearly
show that our system effectively identifies flow rule conflicts
and takes corrective action in spite of the large data sets. The
results also clearly show a O(n) running time. Comparative
running times for Flowguard are obtained from [3]. Run times
for FortNox are not available and the algorithm complexity is
not discussed, but evaluation appears to suggest linear growth;
albeit considerably slower (approximately 7 ms per 1, 000 flow
rules, as opposed to 0.56 ms per 1, 000 flow rules for our
system).

Our work
FlowGuard
104

Fig. 5.

101.5

Number of Flow Rules
Fig. 6.

Running time evaluation.

Once correctness of our work was verified and validated,
we analyzed the performance overhead of conducting inline
rule conflict analysis. Once again, the topology shown in
Figure 5 was used for the experiment. The different link
bandwidth were enforced using the tc command on Linux.
This setup allows us a fine control on the network. A very
large file (1 GB) was sent from host A to host D, with
a script attempting to add flow rules into the environment.
Figure 7 shows the time taken to transfer the file in cases where
the rules being inserted were a) conflict free; b) rules had
conflicts that could be automatically resolved; and c) conflicts
needed administrator assistance for resolution. As expected,
when administrator assistance was required, the transfer took
longer, due to system resources on the VM being diverted
for I/O purposes. Further granular introspection into the data
showed that shadowing and redundancy conflicts had the least
impact on latency, only because they were the first to be
identified in the chained processing. Implementing our system
caused about 5% increase in transfer time (average of 100
test runs). We contend that this tradeoff is acceptable in an
SDN environment since having a conflict free flow table will
not only ensure greater confidence in security, but also more
optimal packet forwarding processing times.
VI.

F UTURE W ORK & C ONCLUSION

Traditional approaches to addressing security issues in a
dynamic, distributed cloud environment concerned themselves
with implementing security on individual components, and
not considering security holistically. With the growing size
of such environments and its increasingly distributed nature;
implementing consistent and conflict-free security policies is
progressively challenging. A complete security solution for
an SDN based cloud computing environment is incomplete
without a set of conflict free flow rules implementing the
security policy in the cloud.
In this work, we introduce a framework, that monitors
and maintains a conflict free environment. We first present
a formalism for the classification of the different types of

2016 IEEE Conference on Communications and Network Security (CNS)

50

[3]

Transfer Time (ms)

40

[4]

30

[5]

20
[6]

10

[7]

0

[8]

Native
(without
conflict
detection)

No conflicts

Intelligible
conflicts

Interpretative
conflicts
[9]

File transfer test.
[10]

Fig. 7.

Network performance impact.

conflicts in SDN, and develop ways to resolve them automatically. When a new flow is added, our system helps maintain
conflict-free consistent flow rules among multiple distributed
controllers. The run time complexity for the framework is
linear, and hence scalable to large data center environments.
As part of out next steps, we plan to study using multiple
analyzers to share the work load in an effort to parallelize
processing. Including role-based and attribute-based policy
conflicts is a natural extension of this work. Further, we are
looking into flow rule optimization based on rule positioning
and examine adaptive prioritization of rules. Incorporating
stateful functionality into the current framework is also being
studied. Since a one-size fits all solution rarely works, we are
also looking into flavors of our framework tailored for host
based SDN firewalls and a mobile (lightweight) SDN based
cloud. Finally, we plan on expanding the framework to work
in an environment with diverse controllers.

[11]

[12]

[13]

[14]
[15]

[16]

[17]

ACKNOWLEDGEMENT
This research is supported by NSF Secure and Resilient
Networking (SRN) Project (1528099) and NATO Science for
Peace & Security Multi-Year Project (MD.SFPP 984425).
S. Pisharody is supported by a scholarship from the NSF
CyberCorps program (NSF-SFS-1129561).

[18]

[19]

[20]

R EFERENCES
[1]

[2]

E. Al-Shaer, H. Hamed, R. Boutaba, and M. Hasan, “Conflict classification and analysis of distributed firewall policies,” Selected Areas in
Communications, IEEE Journal on, vol. 23, no. 10, pp. 2069–2084,
2005.
P. Porras, S. Shin, V. Yegneswaran, M. Fong, M. Tyson, and G. Gu, “A
security enforcement kernel for openflow networks,” in Proceedings of
the first workshop on Hot topics in software defined networks. ACM,
2012, pp. 121–126.

[21]
[22]
[23]

H. Hu, W. Han, G.-J. Ahn, and Z. Zhao, “FLOWGUARD: Building
robust firewalls for software-defined networks,” in Proceedings of the
third workshop on Hot topics in software defined networking. ACM,
2014, pp. 97–102.
Y. Bartal, A. Mayer, K. Nissim, and A. Wool, “Firmato: A novel firewall
management toolkit,” in Security and Privacy, 1999. Proceedings of the
1999 IEEE Symposium on. IEEE, 1999, pp. 17–31.
P. Kazemian, G. Varghese, and N. McKeown, “Header space analysis:
Static checking for networks,” in Presented as part of the 9th USENIX
Symposium on Networked Systems Design and Implementation (NSDI
12), 2012, pp. 113–126.
“Floodlight,”
2015.
[Online].
Available:
http://www.projectfloodlight.org/floodlight/
T. Javid, T. Riaz, and A. Rasheed, “A layer2 firewall for software defined
network,” in Information Assurance and Cyber Security (CIACS), 2014
Conference on. IEEE, 2014, pp. 39–42.
M. Suh, S. H. Park, B. Lee, and S. Yang, “Building firewall over
the software-defined network controller,” in Advanced Communication
Technology (ICACT), 2014 16th International Conference on. IEEE,
2014, pp. 744–748.
C. Monsanto, J. Reich, N. Foster, J. Rexford, D. Walker et al.,
“Composing software defined networks.” in NSDI, 2013, pp. 1–13.
S. K. Fayazbakhsh, L. Chiang, V. Sekar, M. Yu, and J. C. Mogul, “Enforcing network-wide policies in the presence of dynamic middlebox
actions using flowtags,” in Proc. USENIX NSDI, 2014.
S. Shin, P. A. Porras, V. Yegneswaran, M. W. Fong, G. Gu, and
M. Tyson, “Fresco: Modular composable security services for softwaredefined networks.” 2013.
A. Khurshid, X. Zou, W. Zhou, M. Caesar, and P. B. Godfrey, “Veriflow:
Verifying network-wide invariants in real time,” in Presented as part
of the 10th USENIX Symposium on Networked Systems Design and
Implementation (NSDI 13), 2013, pp. 15–27.
Z. Fu, S. F. Wu, H. Huang, K. Loh, F. Gong, I. Baldine, and
C. Xu, “IPSec/VPN security policy: Correctness, conflict detection, and
resolution,” in Policies for Distributed Systems and Networks. Springer,
2001, pp. 39–56.
E. Lupu and M. Sloman, “Conflict analysis for management policies,”
in Integrated Network Management V. Springer, 1997, pp. 430–443.
E. C. Lupu and M. Sloman, “Conflicts in policy-based distributed
systems management,” Software Engineering, IEEE Transactions on,
vol. 25, no. 6, pp. 852–869, 1999.
D. Eppstein and S. Muthukrishnan, “Internet packet filter management
and rectangle geometry,” in Proceedings of the twelfth annual ACMSIAM symposium on Discrete algorithms. Society for Industrial and
Applied Mathematics, 2001, pp. 827–835.
E. S. Al-Shaer and H. H. Hamed, “Firewall policy advisor for anomaly
discovery and rule editing,” in Integrated Network Management, 2003.
IFIP/IEEE Eighth International Symposium on. IEEE, 2003, pp. 17–
30.
D. R. Morrison, “Patricia - Practical algorithm to retrieve information
coded in alphanumeric,” Journal of the ACM (JACM), vol. 15, no. 4,
pp. 514–534, 1968.
K. Poornaselvan, S. Suresh, C. D. Preya, and C. Gayathri, “Efficient IP
lookup algorithm,” Strengthening the Role of ICT in Development, p.
111, 2007.
S. Natarajan, X. Huang, and T. Wolf, “Efficient conflict detection
in flow-based virtualized networks,” in Computing, Networking and
Communications (ICNC), 2012 International Conference on. IEEE,
2012, pp. 690–696.
P. Gupta and N. McKeown, “Algorithms for packet classification,”
Network, iEEE, vol. 15, no. 2, pp. 24–32, 2001.
F. B. Schneider, “Least privilege and more,” in Computer Systems.
Springer, 2004, pp. 253–258.
“OpenDaylight,”
2010.
[Online].
Available:
https://www.opendaylight.org/

Globecom 2014 - Ad Hoc and Sensor Networking Symposium

QoS-Constrained Sensing Task Assignment for
Mobile Crowd Sensing
Zhijie Wang1 , Dijiang Huang1 , Huijun Wu1 , Yuli Deng1 , Ailixier Aikebaier2 and Yuuichi Teranishi2
1

2

Arizona State University, Tempe, AZ, USA
National Institute of Information and Communications Technology, Tokyo, Japan
{wangzj, dijiang, huijun.wu, yuli.deng}@asu.edu, {alisher, teranisi}@nict.go.jp

Abstract—The ubiquitous sensing-capable mobile devices have
been fuelling the new paradigm of Mobile Crowd Sensing (MCS)
to collect data about their surrounding environment. To ensure
the timeliness and quality of the data samples in MCS, it is critical
to select qualified participants to maintain sensing coverage
ratios over important spatial areas (i.e., hotspots) during time
periods of interest and meet various Quality of Service (QoS)
requirements of sensing applications. In this paper, we examine
the problems of sensing task assignment to minimize the overall
cost and maximize the total utility in MCS while adhering to
the QoS constraints and prove that they are NP-hard problems.
Consequently, we present heuristic greedy approaches as the
baseline solutions and further propose new hybrid approaches
with the greedy algorithm and bees algorithm combined to
address them. We demonstrate that the hybrid approaches
significantly outperform the greedy approaches through extensive
simulation and the analysis is given in the end.

I. I NTRODUCTION
The advancements in microelectromechanical systems technology and high-speed wireless communications are driving
the proliferation of mobile devices, such as smartphones,
wearable devices and in-vehicle sensors. Many mobile devices
come with Internet connectivity and embedded sensors (e.g.,
accelerometers, gyroscope, camera and GPS), thereby turning
themselves into well-functioned sensor boxes to probe personal activities and environmental phenomena in the vicinity.
As a result, these trends have been driving the new term
Mobile Crowd Sensing (MCS) [1] from concept into reality.
MCS presents a new paradigm to harness the potential of
the widespread sensing-capable mobile devices to gather data
about personal context and surrounding environment (e.g.,
location, traffic conditions, noise levels) without static sensing
network infrastructures. As such, useful knowledge acquired
from MCS data collection can be used across a wide variety of
domains (e.g., public safety, weather prediction) while heavy
expenses resulting from the deployment and maintenance of
static sensor networks can be avoided. For example, the
smartphone application Waze [2] provides real-time trafficrelated information for geographical navigation based on the
the crowdsourced data submitted by its worldwide users.
The timeliness and quality of the collected data become
major concerns in MCS due to its infrastructureless and
distributed nature, and thus it is critical to select appropriate
participants carried with mobile devices to provide sufficient
data about the target spatial areas during the time periods

978-1-4799-3512-3/14/$31.00 ©2014 IEEE

of interest and meet the application needs at various levels. Generally, we can classify the participating candidates
into two major categories, namely regular participants
and opportunistic participants. The regular participants
follow repetitive traces with a regular spatiotemporal moving pattern during a time period (e.g., a day), and their
locations at a specific time slot can be determined a priori.
Examples of regular participants include city buses, school
buses, trams, street sweepers, and so on. In contrast, the
opportunistic participants have opportunistic daily traits
due to their uncontrolled mobility (e.g., pedestrians, taxis), and
their locations at a specific time cannot predicted. To maintain
a stable spatiotemporal coverage, we only consider regular
participants and hereafter use the term participants to refer
to regular participants in this paper.
There have been some work on the sensing coverage
problems in mobile sensing. Reddy et al. [3] proposed a
recruitment framework to maximize the utility associated with
spatiotemporal coverage with constrained budget in persuasive
sensing, but it only provides a greedy approach as the best
solution, and it does not consider how to minimize the
cost or maximize the utility with the constraints of different
spatiotemperal coverage ratios over different regions. Riahi et
al. [4] presented efficient algorithms to deal with queries of
different types and maximize the total utility in participatory
sensing. As the spatiotemporal coverage has direct impact
on the sensing data quality, we consider the sensing task
assignment problem from the perspective of spatiotemporal
coverage ratio and define it as the Quality of Service (QoS)
in our MCS scenario. Different sensing applications have
different QoS requirements. The event-driven sensing applications (e.g., continuous surveillance in public places in case of
emergency) usually require high spatiotemporal coverage ratio
or even a full spatiotemporal coverage, while low spatiotemporal coverage ratio would suffice some data-driven sensing
applications(e.g., the pattern extraction of long-term variations
in air quality in a city), because segmentation and sampling
algorithms can be leveraged to infer the measurements in
uncovered spatiotemporal space to reduce costs [5].
Consequently, we study the strategies of sensing task assignment in MCS with QoS constraints in this paper. As
illustrated in Figure 1, the sensing campaign organizer investigates the empirical data sets with respect to the candidates’
historical mobility traces and transportation modes, estimates

311

Globecom 2014 - Ad Hoc and Sensor Networking Symposium

WĂƌƚŝĐŝƉĂŶƚƐ

ŚŝƐƚŽƌŝĐĂůĚĂƚĂƌĞƉŽƌƚƐ
ƐĞŶƐŝŶŐƚĂƐŬĂƐƐŝŐŶŵĞŶƚ
ƐĞŶƐĞĚĚĂƚĂ

^ĞŶƐŝŶŐĂŵƉĂŝŐŶKƌŐĂŶŝǌĞƌ
ƐƐĞƐƐŵĞŶƚďĂƐĞĚŽŶƚŚĞĞŵƉŝƌŝĐĂůĚĂƚĂ
ƐĞƚƐ;ůŽĐĂƚŝŽŶ͕ƚŝŵĞ͕ƚƌĂŶƐƉŽƌƚĂƚŝŽŶŵŽĚĞͿ

Fig. 1. Sensing Task Assignment in MCS

their stability in the behavioral space, and accordingly select
well-suited participants to meet various QoS requirements.
As the execution of sensing tasks inevitably incur costs due
to sensor installation, battery consumption, data storage and
transmission, etc., we formulate the QoS-Constrained Sensing
Cost Minimization Problem (QSCM) with the objective of
minimizing the sensing cost while adhering to the QoS constraints. On the other hand, the spatiotemporal coverage yields
benefits for the sensing campaign organizers. We hereby define
the sensing utility as the difference between the benefits and
the costs. The benefits are proportional to the spatotemporal
coverage and the costs increase with the number of selected
participants. Hence, more selected participants does not necessarily result in higher utility, as the costs grow with number
of participants while the spatotemporal coverage derived from
different paticipants’ mobility traces may overlap with each
other. Consequently, we formulate the QoS-Constrained Sensing Utility Maximization Problem (QSUM) with the objective
of maximizing the sensing utility while adhering to the QoS
constraints. Our contributions in this paper are three-fold: i)
we formulate the problems of cost minimization and utility
maximization with QoS constraints in terms of spatiotemporal
coverage ratio and prove that they are NP-hard problems; ii)
we present greedy approaches to address them, and propose
new heuristic hybrid approaches combining the bees algorithm
and greedy algorithm to provide better performance; iii) we
conduct extensive simulation and the numerical results prove
that the hybrid approaches outperform the greedy approaches
with lower cost and higher utility.
The remainder of this paper is organized as follows. Section
II gives problem formulations and offers preliminary analysis.
Section III presents greedy approaches and Section IV describes the hybrid approaches in detail. Section V evaluates
their performance and provides analysis. Section VI discusses
the related work, and Section VII concludes this paper.
II. P ROBLEM F ORMULATION AND A NALYSIS
The spatiotemporal coverage is an important metric in MCS,
since the location and time are crucial context in analyzing
the semantics of sensing data and exploring the phenomena
of interest. As each sensing device can only cover a spacial
range at a time, the regions of interest can be partitioned into
many smaller subregions which fit the sensing range. Also, the
time span of interest can be discretized into many fine-grained
time units of equal length, e.g., 5 minutes. Consequently, the
sensing space is composed of spatiotemporal blocks along the
spacial dimension and the temporal dimension. As such, the
mobility trace of each participant can be modelled as a series
of spatiotemporal blocks in the sensing space. Consider an ur-

ban area in Figure 2 where m hotspot regions Sj (1 ≤ j ≤ m)
need to be monitored within different time intervals of interest
during a time period T (e.g., a day), which is sliced into time
units with equal duration. Accordingly, each hotspot region
Sj corresponds to a spatiotemporal domain STj of which
the projection on the temporal axis span across |Tj | time
units, which could be discontinuous. There exists a participant
pool {p1 , p2 , . . . , pn } consisting of n participants, and each
participant pi moves along statistically equivalent trace tri
consisting of spatiotemporal units during time period T .
As illustrated in Figure 2, there exist three hotspot regions
Sj (1 ≤ j ≤ 3) in the urban area corresponding to the interested time intervals Tj (1 ≤ j ≤ 3) respectively. Assume the
sensing campaign organizer selects participants p1 and p2 , and
each participant moves at a speed of one spatial unit per time
unit. The participant p1 ’s trace tr1 has 3 overlapped spatiotemporal blocks with S1 and 2 overlapped spatiotemporal blocks
with S2 , while tr2 has 3 overlapped spatiotemporal blocks
with S2 and 3 overlapped spatiotemporal blocks with S3 . The
resulting spatiotemporal coverage ratio of ST1 , ST2 and ST3
can be computed as 3/|ST1 | = 12.5%, (3+2)/|ST2 | = 10.2%
and 3/|ST3 | = 20% where | · | denotes the cardinality of a set.
^
^ϯ͕ϱ

Ɖϭ

^ϯ͕ϰ

^ϯ

^dϯ

^ϯ͕ϯ

ƉϮ

^ϯ͕Ϯ

^dϮ

^ϯ͕ϭ
^Ϯ͕ϳ
^Ϯ͕ϲ
^Ϯ͕ϱ

^Ϯ

^Ϯ͕ϰ

^Ϯ ^Ϯ͕Ϯ
^Ϯ͕ϭ ^Ϯ͕ϯ ^Ϯ͕ϱ
^Ϯ͕ϰ ^Ϯ͕ϲ ^Ϯ͕ϳ

^ϯ

^ϭ

^ϯ͕ϭ ^ϯ͕Ϯ ^ϯ͕ϰ
^ϯ͕ϯ ^ϯ͕ϱ

^Ϯ͕ϯ
^Ϯ͕Ϯ
^Ϯ͕ϭ

^dϭ

^ϭ͕ϭ ^ϭ͕ϯ ^ϭ͕ϱ
^ϭ͕Ϯ ^ϭ͕ϰ ^ϭ͕ϲ

^ϭ͕ϲ
^ϭ͕ϱ

^ϭ

^ϭ͕ϰ
^ϭ͕ϯ
^ϭ͕Ϯ
^ϭ͕ϭ
dϭ͕ϭdϭ͕Ϯdϭ͕ϯdϭ͕ϰdϮ͕ϭdϮ͕ϮdϮ͕ϯdϮ͕ϰdϮ͕ϱdϮ͕ϲdϮ͕ϳ

dϭ

dϮ

dϯ͕ϭdϯ͕Ϯdϯ͕ϯ

d

dϯ

Fig. 2. Illustration of Spatiotemperal Coverage in MCS

A. QSCM: The QoS-Constrained Sensing Cost Minimization
Problem
The engagement of a new participant pn in the sensing
campaign can help increase the spatiotemporal coverage ratios
of the hotspot regions, whereas it also raises the cost cn
stemmed from mobile sensor installation, battery consumption,
etc. As more participants with various traces join the sensing
campaign, the actual spatiotemporal coverage ratios could
exceed the QoS requirements of the sensing applications with
unnecessary cost. The goal of QSCM is to find a subset of
participants that minimize the overall cost while fulfilling the
QoS requirement.PWe define the
P total sensing cost as follows:
C(~x) = i∈N (di + j∈M |tri,j |bi )xi ,
where ~x = (x1 , x2 , · · · , xn ) is a n-dimensional (0, 1)
vector, M := {1, . . . , m} is the set of hotspot indexes and

312

Globecom 2014 - Ad Hoc and Sensor Networking Symposium

N := {1, . . . , n} is the collection of participant indexes. The
participant selection vector ~x represents the participant selection results (i.e., xi = 1 iff participant pi is selected otherwise
0). For each participant pi , di denotes the corresponding sensor
installation and maintenance cost, bi denotes the sum of the
battery consumption cost and data transmission cost per each
spatiotemporal block, and tri represents pi ’s mobility trace
consisting of spatiotemporal blocks. We use tri,j = tri ∩ STj
to represent the set of the overlapped spatiotemporal blocks
between tri and STj . Hence, we define the QoS criterion of
STj as its spatiotemporal coverage ratio as follows:





 [


tr
i,j 


xi =1,i∈N
, j∈M
QoSj (~x) =
|STj |
and the QSCM problem can be formulated as follows:
s.t.

min C(~x)
QoSj (~x) ≥ rj , ∀j ∈ M

where the constraints indicate that the QoS of STj should
be no less than the designated threshold rj for all j ∈ M .
Furthermore, the QSCM problem is an NP-hard problem,
which can be proved with Theorem 1 below:
THEOREM 1: The QSCM is an NP-hard optimization
problem.
Proof of Theorem 1: This can be proved by reduction
from k-partial set cover [6]. The k-partial set cover is a
generalization of the well-known set cover problem. It strives
to select a minimum number of sets to cover at least k
elements and it is NP-hard. Given an instance of the kpartial set cover problem (U, S, k) where U is a set of
all elements and S is the set of subsets with elements
from U , we can construct a corresponding QSCM problem ({STj , rj }j∈M , {tri,j }i∈N,j∈M , {bi , di }i∈N ) with M :=
{1}, U = ST1 , r1 = k/|U |, S = {tri,1 }i∈N . Furthermore, we
have bi = 0 and di = 1 for every i ∈ N . This construction
can be done in linear time that is the same size of the kpartial set cover instance. On the other hand, if we have a
QSCM in the constructed problem with M := {1}, we can
choose the subsets corresponding to the selected participants.
Consequently, the k-partial set cover can be reduced to QSCM
with M := {1} in polynomial time, which is a subproblem of
QSCM. Therefore, the QSCM problem is an NP-hard problem.
B. QSUM: The QoS-Constrained Sensing Utility Maximization Problem
In QSUM, the utility is defined as the difference between the
benefits attributed to the spatiotemporal coverage of hotspot
regions and the total cost resulting from the sensing campaign.
Different hotspots are at different levels of interest, and their
spatiotemporal coverage ratios should be assigned with different weights. Hence, the sensing utility is defined as follows:
X
[
X
X
U (~x) =
wj |
tri,j | −
(di +
|tri,j |bi )xi ,
j∈M

xi =1,i∈N

i∈N

condition (xi =S1, i ∈ M ) denotes the index of selected participant pi , and is the disjoint set union of all the overlapped
spatiotemporal blocks between tri and STj . The QoS criteria
are defined in the same manner as with QSCM. The objective
of QSUM is to find a subset of participants to maximize
the utility while ensuring the spatiotemporal coverage ratio
associated with each hotspot is above the corresponding QoSdesignated threshold, and it can be formulated as below:
max U (~x)
s.t. QoSj (~x) ≥ rj , ∀j ∈ M
It can be seen that QSUM considers the utility of sensing
coverage by computing the difference between the total benefits and total costs in the objective function with the same QoS
constraints as in QSCM, and it can be proved QSUM is also
an NP-hard problem in the same manner as in Theorem 1.
III. T HE Q O S-C ONSTRAINED G REEDY A PPROACHES
This section presents greedy approaches to minimize sensing cost or maximize sensing utility while satisfying the QoS
constraints. The algorithms are analyzed accordingly.
A. The QoS-Constrained Greedy Algorithm for Cost Minimization
In order to achieve the minimal cost with QoS constraints, a
greedy approach detailed in Algorithm 1 is proposed hereby
to carry out the process of participant recruitment. It is meant
to select the participant with the maximum ratio of marginal
benefit to the cost from the pool of remaining unselected
participants in each iteration of selection. For each participant
pi , its total number
of spatiotemporal
blocks overlapped with
P
T
hotspots isP j∈M |STT
tri |, and the associated cost is
j
ci = di + j∈M |STj tri |bi . As a result, its unit cost can
ci T
be expressed as uci = P
tri | . In addition, we define
j∈M |STj
a function ψ : I → ~x to map the collection of participant
indexes to a n-dimensional (0, 1) vector ~x, such that the q-th
element xq in ~x is set as 1 if q ∈ I, and 0 otherwise.
Algorithm 1: The QoS-Constrained Greedy Algorithm for
Cost Minimization (QGA-CM)
1

2

3
4
5

6
7
8
9
10
11

where wj denotes the utility weight associated with STj , the

313

[

STj

j∈M

and ST ∗ ← ST ;

12

j∈M

I ∗ ← ∅, tr∗ ← ∅, I ← N = {1, 2, · · · , n}, ST ←
S

tri,j |
< rj then
|STj |
// the pool of participants cannot satisfy
the QoS constraint
I ∗ ← ∅;
else
while |I| > 0 and there exists a hotspot Sj such that
|STj ∩ tr∗ |
< rj do
|STj |
S
d +|
tr |b
T i,j i ;
i∗ ← arg mini∈I i |STi∈N
∗
tri |
S
∗
I ← I \ {iS
}, I ∗ ← I ∗ {i∗ };
tr∗ ← tr∗ tri∗ , ST ∗ ← ST ∗ \ {tr∗ };
end
end
~xbest ← ψ(I ∗ ) ;
return ~xbest
if there exists a hotspot Sj such that

|

i∈N

Globecom 2014 - Ad Hoc and Sensor Networking Symposium

B. The Greedy QoS-Constrained Utility Maximization Algorithm
A similar greedy approach is proposed to achieve the maximum utility with QoS constraint in the process of participant
recruitment. It is meant to choose the participant with the
maximum ratio of marginal benefit to the cost from the pool of
remaining unselected participants in each iteration of selection.
The algorithm is detailed in Algorithm 2. As both the two
algorithms iterate through all the remaining participants in
each round for no more than n iterations, their time complexity
are both O(n2 ). The bound of the greedy algorithms can
achieve H(∆) approximation as shown in [6], [7] where ∆ is
the largest size of tri and H(∆) is the ∆-th Harmonic number.

apply the random global search in the solution space to select
no more than E −1 food positions for the employed bees with
no more than nε attempts to avoid infinite searching loops,
where ε is an adjustable parameter. Next, the algorithm starts
Algorithm 3: The QoS-Constrained Greedy Bees Algorithm for Cost Minimization (QGBA-CM)
1
2
3
4
5
6
7
8

Algorithm 2: The QoS-Constrained Greedy Algorithm for
Utility Maximization (QGA-UM)
1

I ∗ ← ∅, tr∗ ← ∅, I ← N = {1, 2, · · · , n}, ST ←

3
4
5

6
7
8
9
10
11
12
13

11

STj

j∈M

and ST ∗ ← ST ;
2

[

9
10

12
13

S

tri,j |
< rj then
|STj |
// the pool of participants cannot satisfy
the QoS constraint
I ∗ ← ∅;
else
while |I| > 0 and there exists a hotspot Sj such that
|STj ∩ tr∗ |
< rj do
|STj |
0
STj ← STj \ tr∗ P
;
0T
tri | − ci
j∈M wj |STj
∗
T
;
i ← arg maxi∈I
∗
|ST
tri |
∗
∗
∗S ∗
I ← I \ {iS}, I ← I
{i };
tr∗ ← tr∗ tri∗ , ST ∗ ← ST ∗ \ tr∗ ;
end
end
~xbest ← ψ(I ∗ ) ;
return ~xbest
if there exists a hotspot Sj such that

|

i∈N

14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33

IV. T HE Q O S-C ONSTRAINED H YBRID A PPROACHES

34

In this section, we present hybrid approaches to fulfil
the QoS requirements for task assignment. They apply bees
algorithm [8], [9], [10] on top of the participant selection
results derived from previous greedy approaches.
A. The QoS-Constrained Greedy Bees Algorithm for Cost
Minimization (QGBA-CM)
In this subsection, we propose a QoS-Contrained Greedy
Bees Algorithm to minimize the cost for sensing task assignment. In this algorithm, the employed bees, onlooker bees
and scout bees cooperatively forage the optimal solution in
the solution space of ~x within an acceptable time period. In
the first step, the algorithm initiates a randomly distributed
population of food source positions (i.e., possible solutions)
~xα (1 ≤ α ≤ E} in the solution space, where ~xα is a
n-dimensional vector and E is the maximum number of
employed bees. Specifically, we initiate one of the positions
with the resulting vector derived from QGACM, and then

Apply QGA-CM and derive corresponding result ~xbest ;
cycle ← 1, ~xe ← {~xbest }, ~x∗ ← ~xe , α ← 2, k1 ← 1 ;
while α ≤ E and k1 ≤ nε do // the employed bees’
global search
randomly generates a n-dimensional (0, 1) vector ~xα ;
if ~xα ∈
/ ~x∗ and QoSj (~xα ) ≥ rj , ∀j ∈ M then
α←α+1 ;
end
S
S
~x∗ ← ~x∗ {~xα },~xe ← ~xe {~xα }, k1 ← k1 + 1 ;
end
repeat
foreach employed bee ~xα ∈ ~xe do
C −1 (~xα )
Lα ←
·L ;
Σ1≤α0 ≤E C −1 (~xα0 )
β ← 1, k2 ← 1 ;
while β ≤ Lα and k2 ≤ nε do // the onlooker
bees’ local search
~xα,β ← Ff lip (~xα , );
if ~xα,β ∈
/ ~x∗ and QoSj (~xα,β ) ≥ rj , ∀j ∈ M then
β ←β+1 ;
~xα ← arg min~x {C(~xα,β ), C(~xα )} ;
end
S
~x∗ ← ~x∗ {~xα,β }, k2 ← k2 + 1 ;
end
end
Generate aSscout bee ~x0 as in the global search;
~x∗ ← ~x∗ {~x0 } ;
if max{{C(~xα )}~xα ∈~xe } > C(~x0 ) then
~xα−max ← arg max{{C(~xα )}~xα ∈~xe } ;
~xα−max ← ~x0 ;
end
if C(~xbest ) > min{{C(~xα )}~xα ∈~xe } then
~xbest ← arg min~x {{C(~xα )}~xα ∈~xe } ;
end
cycle ← cycle + 1 ;
until the stopping conditions are satisfied;
return ~xbest

a repeated cycle as follows: each employed bee first makes
modifications on the its assigned position (i.e., solution), and
their memory are shared with the onlooker bees. Accordingly,
the L(L > E) onlooker bees explore the neighbourhood of
the food source positions where each food position is selected
with probabilities proportional to the corresponding nectar
amount (i.e., the reciprocal of cost), and they look for new
positions that can meet QoS requirements using the local
search algorithm. The local search algorithm uses Ff lip (~x, )
as shown below to derive new vectors (i.e., food positions) in
the neighbourhood of ~x:
~xf ← Ff lip (~x, ): the onlooker bee randomly selects 0 elements in (0, 1) vector ~x and flips them
where 0 ≤ 0 ≤ .
To avoid infinite search loops, all visited positions are recorded
in the tabu list ~x∗ ,and the number of attempts is limited to nε .

314

Globecom 2014 - Ad Hoc and Sensor Networking Symposium

After the local search, if the new positions bring more nectar
amount (i.e.,less cost), then the employed bees’ memory will
be updated with the new positions of onlooker bees. Next,
a scout bee randomly selects a new food source position to
replace one of the previous positions which brings the highest
cost. The search loops stop if two conditions are satisfied: i)
the number of iterations has reached Maximum Number of
Cycles (MNC); ii) the resulting cost remains unchanged for
nstable iterations. The algorithm is detailed in Algorithm 3.
B. The QoS-Constrained Greedy Bees Algorithm for Utility
Maximization (QGBA-UM)
Similarly, we apply the QoS-constrained Bees Algorithm to
achieve maximum utility, which is detailed in Algorithm 4.
QGBA-UM differs from QGBA-CM in that the food positions
of the employed bees are selected with probabilities proportional to the corresponding utilities rather than the reciprocal
of cost, and the employed bees update their memory when
the new positions bring higher utility rather than lower cost.
In addition, the scout bee updates one of the employed bees’
position with the lowest utility rather than the highest cost.
The major parts of QGBA-CM and QGBA-UM are the
same, and they both need to conduct the greedy approaches
to derive a food position of which the time complexity
is O(n2 ). In addition, as there exist no more than M N C
iterations and each employed bee searches no more than O(nε )
iterations, the time complexity of the hybrid approaches are
O(n2 + M N C · E · nε ).
Algorithm 4: The QoS-Constrained Greedy Bees Algorithm for Utility Maximization (QGBA-UM)
1
2
3
4
5
6
7

8
9
10
11
12
13
14
15
16
17
18
19
20

Apply QGA-UM and get corresponding result ~xbest ;
cycle ← 1, ~xe ← {~xbest }, ~x∗ ← ~xe ;
the employed bees conduct the same global search and update
~x∗ , ~xe as in QGBA-CM;
repeat
foreach employed bee ~xα ∈ ~xe do
U (~xα )
Lα ←
·L ;
Σ1≤α0 ≤E U (~xα0 )
the onlooker bees conduct the same local search and
update ~xα using ~xα,β with higher utility as in
QGBA-CM;
end
Generate aSscout bee ~x0 as in the global search;
~x∗ ← ~x∗ {~x0 } ;
if min{{U (~xα )}~xα ∈~xe } < U (~x0 ) then
~xα−min ← arg min{{U (~xα )}~xα ∈~xe } ;
~xα−min ← ~x0 ;
end
if U (~xbest ) < max{{U (~xα )}~xα ∈~xe } then
~xbest ← arg max~x {{U (~xα )}~xα ∈~xe } ;
end
cycle ← cycle + 1 ;
until the stopping conditions are satisfied;
return ~xbest

ated their performance using metrics including sensing cost,
sensing utility, spatiotemporal coverage ratio and the number
of participants. All the simulations ran on a Windows machine
with Intel(R) Xeon(R) CPU and 4 GB memory.
We assume the whole region of size 1000m × 1000m
is griditized into spatial blocks of size 20m × 20m. Three
hotspots are distributed in the whole region, and their projections in the spatiotemperal space consist of 60×4, 60×5, 60×6
spatiotemporal blocks similar to Figure 2. The spatiotemporal
coverage ratio of each participant’s trace tri over each hotspot
STj is uniformly distributed over [0, 16%]. The number of
participants n varies from 10 to 30 with the increment of
10. We also assume the participant pi ’s static cost di is
uniformly distributed over [1, 5] and its unit cost per block bi
is uniformly distributed over [1, 3], while the utility weight wj
is uniformly distributed over [4, 10]. In the hybrid algorithm
QGBA-CM and QGBA-UM, we set  = 3,ε = 3,nstable = 3,
M CN = 6,E = 10, and L = 50. For simplicity, it is assumed
that the sensing applications have the same QoS requirement r
for different hotspots where r ranges from 10% to 100% with
the increment of 10%. Based on the parameter setup stated
above, we randomly generate 50 instances for each set of r
and n and derive the graphs with error bars.
From Figure 3 we can learn that the hybrid approaches
can derive better results than greedy approaches with respect
to both cost and utility. Specifically, the hybrid approaches
achieve the same results as the optimal solution when n = 10
in Figure 3(a) and Figure 3(d). It can be seen that the results
of hybrid approaches and greedy approaches are getting closer
to the optimal results as r approaches 100% in each subfigure,
because the solution space shrinks with the increase of r.
In addition, the gaps between the greedy approaches’ results
and the optimal results become larger due to the growing
solution space as n increases from 10 to 30, while the hybrid
approaches’ results keep close to the optimal results.
VI. R ELATED W ORK

V. P ERFORMANCE E VALUATION
In this section, we implemented both the greedy approaches
and the hybrid approaches in QSCM and QSUM, and evalu-

Substantial research has been done for resource allocation
and task assignment in traditional sensor networks. An efficient near-optimal algorithm is provided in [11] to achieve
a complete spatial coverage of the sensing field in wireless
sensor networks. Koulali [12] et al. presented an optimal
distributed relay selection policy to optimize duty-cycling
sensor’s energy consumption with QoS constraints on transmission delay. Kallitsis et al. [13] constructed a resource
allocation model based on pricing scheme to maximize the
provider’s utility with QoS requirements in network delay.
Bagaria et al. [14] proposed a polynomial-time approximation
algorithm to maximize the lifetime of coverage of targets
in a wireless sensor network with battery-limited sensors.
Chen et al. [15] offered a novel algorithm maxL-minE to
find a landmark placement pattern to minimize the maximum
localization error and demonstrated its improved performance
using Wifi and Zigbee networks in real building environment.
Some work have been done for mobile sensing. Reddy et
al. [3] proposed a recruitment framework to maximize utility

315

Globecom 2014 - Ad Hoc and Sensor Networking Symposium

0
0

50%

0
0

100%

(a) r (n=10)

3000

4000

Optimal
QGA−UM
QGBA−UM

2000
1000
0

50%

2000

0
0

100%

(b) r (n=20)

Utility

Utility

4000

50%

Cost

2000

4000

Optimal
QGA−CM
QGBA−CM

100%

3000
2000

(d) r (n=10)

50%

50%

100%

4000

Optimal
QGA−UM
QGBA−UM

1000
0

Optimal
QGA−CM
QGBA−CM

(c) r (n=30)

Utility

2000

4000

Optimal
QGA−CM
QGBA−CM

Cost

Cost

4000

100%

(e) r (n=20)

3000
2000
1000
0

Optimal
QGA−UM
QGBA−UM

50%

100%

(f) r (n=30)

Fig. 3. Evaluation Results of Different Approaches

with budget constraint. Yang et al. [16] designed incentive
mechanisms in platform-centric and user-centric models for
mobile phone sensing. OptiMoS [5] devised a two-tier mobile
sensing model to balance sensor coverage and energy cost.
Unlike previous work, we identify the task assignment problems with QoS constraints in terms of spatiotemporal coverage
and propose efficient hybrid methods on top of the greedy
algorithm and bees algorithm to provide better performance.
VII. C ONCLUSIONS AND F UTURE W ORK
The spatiotemporal coverage of the mobile sensing devices
over the target areas during time periods of interest has direct
impact on the data quality and quantity in MCS. We identify
the problems of sensing cost minimization and utility maximization with QoS constraints to fulfil different requirements
of sensing applications, and propose greedy approaches as
well as heuristic hybrid approaches with greedy algorithm
and Bees algorithms to address them. Our evaluation results
show that our hybrid approaches approximate the optimal
solutions when the solution space is small, and the results
of hybrid approaches are more close to the optimal solutions
than the greedy approaches when the size of solution space
grows large. To gather more sensing data and enlarge the spatiotemporal coverage in mobile crowd sensing, we will extend
our participant selection framework to cover both regular
participants and opportunistic participants as our next
step. Accordingly, our future participant selection framework
is anticipated to achieve better performance and better fit
into real life, as the mobility traces of most participants in
real world are inconsistent and their submissions can also
contribute to the sensing campaign.
R EFERENCES
[1] R. K. Ganti, F. Ye, and H. Lei, “Mobile crowdsensing: Current state and
future challenges,” Communications Magazine, IEEE, vol. 49, no. 11,
pp. 32–39, 2011.
[2] “Waze.” [Online]. Available: https://www.waze.com/

[3] S. Reddy, D. Estrin, and M. Srivastava, “Recruitment framework for participatory sensing data collections,” in Pervasive Computing. Springer,
2010, pp. 138–155.
[4] M. Riahi, T. G. Papaioannou, I. Trummer, and K. Aberer, “Utility-driven
data acquisition in participatory sensing,” in Proceedings of the 16th
International Conference on Extending Database Technology. ACM,
2013, pp. 251–262.
[5] Z. Yan, J. Eberle, and K. Aberer, “Optimos: Optimal sensing for
mobile sensors,” in Mobile Data Management (MDM), 2012 IEEE 13th
International Conference on. IEEE, 2012, pp. 105–114.
[6] R. Gandhi, S. Khuller, and A. Srinivasan, “Approximation algorithms
for partial covering problems,” Journal of Algorithms, vol. 53, no. 1,
pp. 55–84, 2004.
[7] P. Slavı́k, “Improved performance of the greedy algorithm for partial
cover,” Information Processing Letters, vol. 64, no. 5, pp. 251–254,
1997.
[8] D. Karaboga and B. Akay, “A comparative study of artificial bee colony
algorithm,” Applied Mathematics and Computation, vol. 214, no. 1, pp.
108–132, 2009.
[9] D. Pham, A. Ghanbarzadeh, E. Koc, S. Otri, S. Rahim, and M. Zaidi,
“The bees algorithm-a novel tool for complex optimisation problems,” in
Proceedings of the 2nd Virtual International Conference on Intelligent
Production Machines and Systems (IPROMS 2006), 2006, pp. 454–459.
[10] B. Basturk and D. Karaboga, “An artificial bee colony (abc) algorithm
for numeric function optimization,” in IEEE swarm intelligence symposium, 2006, pp. 12–14.
[11] S. S. Dhillon and K. Chakrabarty, Sensor placement for effective
coverage and surveillance in distributed sensor networks. IEEE, 2003,
vol. 3.
[12] M.-A. Koulali, A. Kobbane, M. El Koutbi, and J. Ben-Othman, “Optimal
distributed relay selection for duty-cycling wireless sensor networks,” in
Global Communications Conference (GLOBECOM), 2012 IEEE. IEEE,
2012, pp. 145–150.
[13] M. G. Kallitsis, G. Michailidis, and M. Devetsikiotis, “Measurementbased optimal resource allocation for network services with pricing
differentiation,” Performance Evaluation, vol. 66, no. 9, pp. 505–523,
2009.
[14] V. K. Bagaria, A. Pananjady, and R. Vaze, “Optimally approximating the
lifetime of wireless sensor networks,” arXiv preprint arXiv:1307.5230,
2013.
[15] Y. Chen, J.-A. Francisco, W. Trappe, and R. P. Martin, “A practical
approach to landmark deployment for indoor localization,” in Sensor
and Ad Hoc Communications and Networks. SECON’06., vol. 1, 2006,
pp. 365–373.
[16] D. Yang, G. Xue, X. Fang, and J. Tang, “Crowdsourcing to smartphones:
incentive mechanism design for mobile phone sensing,” in Proceedings
of the 18th annual international conference on Mobile computing and
networking. ACM, 2012, pp. 173–184.

316

198

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 10,

NO. 4, JULY/AUGUST 2013

NICE: Network Intrusion Detection
and Countermeasure Selection
in Virtual Network Systems
Chun-Jen Chung, Student Member, IEEE, Pankaj Khatkar, Student Member, IEEE,
Tianyi Xing, Student Member, IEEE, Jeongkeun Lee, Member, IEEE, and
Dijiang Huang, Senior Member, IEEE
Abstract—Cloud security is one of most important issues that has attracted a lot of research and development effort in past few years.
Particularly, attackers can explore vulnerabilities of a cloud system and compromise virtual machines to deploy further large-scale
Distributed Denial-of-Service (DDoS). DDoS attacks usually involve early stage actions such as multistep exploitation, low-frequency
vulnerability scanning, and compromising identified vulnerable virtual machines as zombies, and finally DDoS attacks through the
compromised zombies. Within the cloud system, especially the Infrastructure-as-a-Service (IaaS) clouds, the detection of zombie
exploration attacks is extremely difficult. This is because cloud users may install vulnerable applications on their virtual machines. To
prevent vulnerable virtual machines from being compromised in the cloud, we propose a multiphase distributed vulnerability detection,
measurement, and countermeasure selection mechanism called NICE, which is built on attack graph-based analytical models and
reconfigurable virtual network-based countermeasures. The proposed framework leverages OpenFlow network programming APIs to
build a monitor and control plane over distributed programmable virtual switches to significantly improve attack detection and mitigate
attack consequences. The system and security evaluations demonstrate the efficiency and effectiveness of the proposed solution.
Index Terms—Network security, cloud computing, intrusion detection, attack graph, zombie detection

Ç
1

INTRODUCTION

R

ECENT studies have shown that users migrating to the
cloud consider security as the most important factor. A
recent Cloud Security Alliance (CSA) survey shows that
among all security issues, abuse and nefarious use of cloud
computing is considered as the top security threat [1], in
which attackers can exploit vulnerabilities in clouds and
utilize cloud system resources to deploy attacks. In
traditional data centers, where system administrators have
full control over the host machines, vulnerabilities can be
detected and patched by the system administrator in a
centralized manner. However, patching known security
holes in cloud data centers, where cloud users usually have
the privilege to control software installed on their managed
VMs, may not work effectively and can violate the servicelevel agreement (SLA). Furthermore, cloud users can install
vulnerable software on their VMs, which essentially
contributes to loopholes in cloud security. The challenge
is to establish an effective vulnerability/attack detection

. C-J. Chung, P. Khatkar, T. Xing, and D. Huang are with the
Department of Computer Science, Arizona State University, Brickyard
Suite 470, 699 S. Mill Ave., Tempe, AZ 85281.
E-mail: {chun-jen.chung, pkhatkar, tianyi.xing, dijiang}@asu.edu.
. J. Lee is with Hewlett-Packard Laboratories, 1501 Page Mill Road, M/S
1184, Palo Alto, CA 94304. E-mail: jklee@hp.com.
Manuscript received 20 July 2012; revised 21 Nov. 2012; accepted 2 Jan. 2013;
published online 22 Jan. 2013.
Recommended for acceptance by S. Distefano, A. Puliafito, and K.S. Trivedi.
For information on obtaining reprints of this article, please send e-mail to:
tdsc@computer.org, and reference IEEECS Log Number
TDSCSI-2012-07-0183.
Digital Object Identifier no. 10.1109/TDSC.2013.8.
1545-5971/13/$31.00 ß 2013 IEEE

and response system for accurately identifying attacks and
minimizing the impact of security breach to cloud users.
In [2], Armbrust et al. addressed that protecting “Business
continuity and services availability” from service outages is
one of the top concerns in cloud computing systems. In a
cloud system, where the infrastructure is shared by potentially millions of users, abuse and nefarious use of the shared
infrastructure benefits attackers to exploit vulnerabilities of
the cloud and use its resource to deploy attacks in more
efficient ways [3]. Such attacks are more effective in the cloud
environment because cloud users usually share computing
resources, e.g., being connected through the same switch,
sharing with the same data storage and file systems, even
with potential attackers [4]. The similar setup for VMs in the
cloud, e.g., virtualization techniques, VM OS, installed
vulnerable software, networking, and so on, attracts attackers to compromise multiple VMs.
In this paper, we propose Network Intrusion detection
and Countermeasure sElection in virtual network systems
(NICE) to establish a defense-in-depth intrusion detection
framework. For better attack detection, NICE incorporates
attack graph analytical procedures into the intrusion
detection processes. We must note that the design of NICE
does not intend to improve any of the existing intrusion
detection algorithms; indeed, NICE employs a reconfigurable virtual networking approach to detect and counter the
attempts to compromise VMs, thus preventing zombie VMs.
In general, NICE includes two main phases: 1) deploy a
lightweight mirroring-based network intrusion detection
agent (NICE-A) on each cloud server to capture and
analyze cloud traffic. A NICE-A periodically scans the
virtual system vulnerabilities within a cloud server to
Published by the IEEE Computer Society

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

establish Scenario Attack Graph (SAGs), and then based on
the severity of identified vulnerability toward the collaborative attack goals, NICE will decide whether or not to
put a VM in network inspection state. 2) Once a VM enters
inspection state, Deep Packet Inspection (DPI) is applied,
and/or virtual network reconfigurations can be deployed to
the inspecting VM to make the potential attack behaviors
prominent.
NICE significantly advances the current network IDS/
IPS solutions by employing programmable virtual networking approach that allows the system to construct a dynamic
reconfigurable IDS system. By using software switching
techniques [5], NICE constructs a mirroring-based traffic
capturing framework to minimize the interference on users’
traffic compared to traditional bump-in-the-wire (i.e.,
proxy-based) IDS/IPS. The programmable virtual networking architecture of NICE enables the cloud to establish
inspection and quarantine modes for suspicious VMs
according to their current vulnerability state in the current
SAG. Based on the collective behavior of VMs in the SAG,
NICE can decide appropriate actions, for example, DPI or
traffic filtering, on the suspicious VMs. Using this approach,
NICE does not need to block traffic flows of a suspicious
VM in its early attack stage. The contributions of NICE are
presented as follows:
We devise NICE, a new multiphase distributed
network intrusion detection and prevention framework in a virtual networking environment that
captures and inspects suspicious cloud traffic without
interrupting users’ applications and cloud services.
. NICE incorporates a software switching solution to
quarantine and inspect suspicious VMs for further
investigation and protection. Through programmable network approaches, NICE can improve the
attack detection probability and improve the resiliency to VM exploitation attack without interrupting existing normal cloud services.
. NICE employs a novel attack graph approach for
attack detection and prevention by correlating
attack behavior and also suggests effective countermeasures.
. NICE optimizes the implementation on cloud
servers to minimize resource consumption. Our
study shows that NICE consumes less computational overhead compared to proxy-based network
intrusion detection solutions.
The rest of paper is organized as follows: Section 2
presents the related work. System models are described in
Section 3, Section 4 describes system design and implementation. The proposed security measurement, mitigation,
and countermeasures are presented in Section 5 and
Section 6 evaluates NICE in terms of network performance
and security. Finally, Section 7 describes future work and
concludes this paper.
.

2

RELATED WORK

In this section, we present literatures of several highly
related research areas to NICE, including: Zombie detection and prevention, attack graph construction and
security analysis, and software defined networks for
attack countermeasures.

199

The area of detecting malicious behavior has been well
explored. The work by Duan et al. [6] focuses on the
detection of compromised machines that have been
recruited to serve as spam zombies. Their approach, SPOT,
is based on sequentially scanning outgoing messages while
employing a statistical method Sequential Probability Ratio
Test (SPRT), to quickly determine whether a host has been
compromised. BotHunter [7] detects compromised machines based on the fact that a thorough malware infection
process has a number of well-defined stages that allow
correlating the intrusion alarms triggered by inbound traffic
with resulting outgoing communication patterns. BotSniffer
[8] exploits uniform spatial-temporal behavior characteristics of compromised machines to detect zombies by
grouping flows according to server connections and
searching for similar behavior in the flow.
An attack graph is able to represent a series of exploits,
called atomic attacks, that lead to an undesirable state, for
example, a state where an attacker has obtained administrative access to a machine. There are many automation
tools to construct attack graph. Sheyner et al. [9] proposed a
technique based on a modified symbolic model checking
NuSMV [10] and Binary Decision Diagrams (BDDs) to
construct attack graph. Their model can generate all
possible attack paths, however, the scalability is a big issue
for this solution. P. Amman et al. [11] introduced the
assumption of monotonicity, which states that the precondition of a given exploit is never invalidated by the
successful application of another exploit. In other words,
attackers never need to backtrack. With this assumption,
they can obtain a concise, scalable graph representation for
encoding attack tree. Ou et al. [12] proposed an attack graph
tool called MulVAL, which adopts a logic programming
approach and uses Datalog language to model and analyze
network system. The attack graph in the MulVAL is
constructed by accumulating true facts of the monitored
network system. The attack graph construction process will
terminate efficiently because the number of facts is
polynomial in system. To provide the security assessment
and alert correlation features, in this paper, we modified
and extended MulVAL’s attack graph structure.
Intrusion Detection System (IDS) and firewall are widely
used to monitor and detect suspicious events in the
network. However, the false alarms and the large volume
of raw alerts from IDS are two major problems for any IDS
implementations. To identify the source or target of the
intrusion in the network, especially to detect multistep
attack, the alert correction is a must-have tool. The primary
goal of alert correlation is to provide system support for a
global and condensed view of network attacks by analyzing
raw alerts [13].
Many attack graph-based alert correlation techniques
have been proposed recently. Wang et al. [14] devised an inmemory structure, called queue graph (QG), to trace alerts
matching each exploit in the attack graph. However, the
implicit correlations in this design make it difficult to use
the correlated alerts in the graph for analysis of similar
attack scenarios. Roschke et al. [15] proposed a modified
attack-graph-based correlation algorithm to create explicit
correlations only by matching alerts to specific exploitation

200

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

nodes in the attack graph with multiple mapping functions,
and devised an alert dependencies graph (DG) to group
related alerts with multiple correlation criteria. Each path in
DG represents a subset of alerts that might be part of an
attack scenario. However, their algorithm involved all pairs
shortest path searching and sorting in DG, which consumes
considerable computing power.
After knowing the possible attack scenarios, applying
countermeasure is the next important task. Several solutions have been proposed to select optimal countermeasures based on the likelihood of the attack path and cost
benefit analysis. Roy et al. [16] proposed an attack countermeasure tree (ACT) to consider attacks and countermeasures
together in an attack tree structure. They devised several
objective functions based on greedy and branch and bound
techniques to minimize the number of countermeasure,
reduce investment cost, and maximize the benefit from
implementing a certain countermeasure set. In their design,
each countermeasure optimization problem could be
solved with and without probability assignments to the
model. However, their solution focuses on a static attack
scenario and predefined countermeasure for each attack.
Poolsappasit et al. [17] proposed a Bayesian attack graph
(BAG) to address dynamic security risk management
problem and applied a genetic algorithm to solve countermeasure optimization problem.
Our solution utilizes a new network control approach
called SDN [18], where networking functions can be
programmed through software switch and OpenFlow
protocol [19], plays a major role in this research. Flowbased switches, such as OVS [5] and OpenFlow Switch
(OFS) [19], support fine-grained and flow-level control for
packet switching [20]. With the help of the central
controller, all OpenFlow-based switches can be monitored
and configured. We take advantage of flow-based switching
(OVS) and network controller to apply the selected network
countermeasures in our solution.

3.2 Attack Graph Model
An attack graph is a modeling tool to illustrate all possible
multistage, multihost attack paths that are crucial to
understand threats and then to decide appropriate countermeasures [22]. In an attack graph, each node represents
either precondition or consequence of an exploit. The
actions are not necessarily an active attack because normal
protocol interactions can also be used for attacks. Attack
graph is helpful in identifying potential threats, possible
attacks, and known vulnerabilities in a cloud system.
Since the attack graph provides details of all known
vulnerabilities in the system and the connectivity information, we get a whole picture of current security situation of
the system, where we can predict the possible threats and
attacks by correlating detected events or activities. If an
event is recognized as a potential attack, we can apply
specific countermeasures to mitigate its impact or take
actions to prevent it from contaminating the cloud system.
To represent the attack and the result of such actions, we
extend the notation of MulVAL logic attack graph as
presented by Ou et al. [12] and define as Scenario Attack
Graph (SAG).
Definition 1 (SAG). An SAG is a tuple SAG ¼ ðV ; EÞ, where
1.

NICE MODELS

In this section, we describe how to utilize attack graphs to
model security threats and vulnerabilities in a virtual
networked system, and propose a VM protection model
based on virtual network reconfiguration approaches to
prevent VMs from being exploited.

3.1 Threat Model
In our attack model, we assume that an attacker can be
located either outside or inside of the virtual networking
system. The attacker’s primary goal is to exploit vulnerable
VMs and compromise them as zombies. Our protection
model focuses on virtual-network-based attack detection
and reconfiguration solutions to improve the resiliency to
zombie explorations. Our work does not involve host-based
IDS and does not address how to handle encrypted traffic
for attack detections.
Our proposed solution can be deployed in an Infrastructure-as-a-Service (IaaS) cloud networking system, and
we assume that the Cloud Service Provider (CSP) is benign.
We also assume that cloud service users are free to install
whatever operating systems or applications they want, even

NO. 4, JULY/AUGUST 2013

if such action may introduce vulnerabilities to their
controlled VMs. Physical security of cloud server is out of
scope of this paper. We assume that the hypervisor is secure
and free of any vulnerabilities. The issue of a malicious
tenant breaking out of DomU and gaining access to physical
server have been studied in recent work [21] and are out of
scope of this paper.

2.

3

VOL. 10,

V ¼ NC [ ND [ NR denotes a set of vertices that
include three types namely conjunction node NC to
represent exploit, disjunction node ND to denote result
of exploit, and root node NR for showing initial step of
an attack scenario.
E ¼ Epre [ Epost denotes the set of directed edges. An
edge e 2 Epre  ND  NC represents that ND must be
satisfied to achieve NC . An edge e 2 Epost  NC  ND
means that the consequence shown by ND can be
obtained if NC is satisfied.

Node vc 2 NC is defined as a three tuple ðHosts; vul;
alertÞ representing a set of IP addresses, vulnerability
information such as CVE [23], and alerts related to vc ,
respectively. ND behaves like a logical OR operation and
contains details of the results of actions. NR represents the
root node of the SAG.
For correlating the alerts, we refer to the approach
described in [15] and define a new Alert Correlation Graph
(ACG) to map alerts in ACG to their respective nodes in
SAG. To keep track of attack progress, we track the source
and destination IP addresses for attack activities.
Definition 2 (ACG). An ACG is a three tuple ACG ¼
ðA; E; P Þ, where
1.

A is a set of aggregated alerts. An alert a 2 A is a data
structure ðsrc; dst; cls; tsÞ representing source IP
address, destination IP address, type of the alert, and
time stamp of the alert respectively.

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

2.

3.

Each alert a maps to a pair of vertices ðvc ; vd Þ in SAG
using mapðaÞ function, i.e., mapðaÞ : a 7! fðvc ; vd Þj
ða:src 2 vc :HostsÞ ^ ða:dst 2 vd :HostsÞ ^ ða:cls ¼
vc :vulÞg.
E is a set of directed edges representing correlation
between two alerts ða; a0 Þ if criteria below satisfied:
ða:ts < a0 :tsÞ ^ ða0 :ts  a:ts < thresholdÞ.
9ðvd ; vc Þ 2 Epre : ða:dst 2 vd :Hosts ^ a0 :src 2
vc :HostsÞ.
P is set of paths in ACG. A path Si  P is a set of
related alerts in chronological order.
a.
b.

4.

We assume that A contains aggregated alerts rather than
raw alerts. Raw alerts having same source and destination
IP addresses, attack type, and time stamp within a specified
window are aggregated as Meta Alerts. Each ordered pair
ða; a0 Þ in ACG maps to two neighbor vertices in SAG with
time stamp difference of two alerts within a predefined
threshold. ACG shows dependency of alerts in chronological
order and we can find related alerts in the same attack
scenario by searching the alert path in ACG. A set P is used
to store all paths from root alert to the target alert in the
SAG, and each path Si  P represents alerts that belong to
the same attack scenario.
We explain a method for utilizing SAG and ACG together
so as to predict an attacker’s behavior. Alert Correlation
algorithm is followed for every alert detected and returns
one or more paths Si . For every alert ac that is received from
the IDS, it is added to ACG if it does not exist. For this new
alert ac , the corresponding vertex in the SAG is found by
using function mapðac Þ (line 3). For this vertex in SAG, alert
related to its parent vertex of type NC is then correlated with
the current alert ac (line 5). This creates a new set of alerts
that belong to a path Si in ACG (line 8) or splits out a new
path Siþ1 from Si with subset of Si before the alert a and
appends ac to Siþ1 (line 10). In the end of this algorithm, the
ID of ac will be added to alert attribute of the vertex in SAG.
Algorithm 1 returns a set of attack paths S in ACG.
Algorithm 1. Alert_Correlation
Require: alert ac , SAG, ACG
1: if (ac is a new alert) then
2:
create node ac in ACG
vc 2 mapðac Þ
3:
n1
4:
for all n2 2 parentðn1 Þ do
5:
create edge (n2 :alert; ac )
6:
for all Si containing a do
7:
if a is the last element in Si then
8:
append ac to Si
9:
else
10:
create path Siþ1 ¼ fsubsetðSi ; aÞ; ac g
11:
end if
12:
end for
13:
add ac to n1 :alert
14:
end for
15: end if
16: return S

3.3 VM Protection Model
The VM protection model of NICE consists of a VM
profiler, a security indexer, and a state monitor. We specify

201

security index for all the VMs in the network depending
upon various factors like connectivity, the number of
vulnerabilities present and their impact scores. The impact
score of a vulnerability, as defined by the CVSS guide [24],
helps to judge the confidentiality, integrity, and availability
impact of the vulnerability being exploited. Connectivity
metric of a VM is decided by evaluating incoming and
outgoing connections.
Definition 3 (VM State). Based on the information gathered
from the network controller, VM states can be defined as
following:
1.
2.
3.
4.

4

Stable. There does not exist any known vulnerability
on the VM.
Vulnerable. Presence of one or more vulnerabilities
on a VM, which remains unexploited.
Exploited. At least one vulnerability has been
exploited and the VM is compromised.
Zombie. VM is under control of attacker.

NICE SYSTEM DESIGN

In this section, we first present the system design overview
of NICE and then detailed descriptions of its components.

4.1 System Design Overview
The proposed NICE framework is illustrated in Fig. 1. It
shows the NICE framework within one cloud server
cluster. Major components in this framework are distributed and light-weighted NICE-A on each physical
cloud server, a network controller, a VM profiling server,
and an attack analyzer. The latter three components are
located in a centralized control center connected to
software switches on each cloud server (i.e., virtual
switches built on one or multiple Linux software bridges).
NICE-A is a software agent implemented in each cloud
server connected to the control center through a dedicated
and isolated secure channel, which is separated from the
normal data packets using OpenFlow tunneling or VLAN
approaches. The network controller is responsible for
deploying attack countermeasures based on decisions
made by the attack analyzer.
In the following description, our terminologies are based
on the XEN virtualization technology. NICE-A is a network
intrusion detection engine that can be installed in either
Dom0 or DomU of a XEN cloud server to capture and filter
malicious traffic. Intrusion detection alerts are sent to
control center when suspicious or anomalous traffic is
detected. After receiving an alert, attack analyzer evaluates
the severity of the alert based on the attack graph, decides
what countermeasure strategies to take, and then initiates it
through the network controller. An attack graph is established according to the vulnerability information derived
from both offline and real-time vulnerability scans. Offline
scanning can be done by running penetration tests and
online real-time vulnerability scanning can be triggered by
the network controller (e.g., when new ports are opened
and identified by OFSs) or when new alerts are generated
by the NICE-A. Once new vulnerabilities are discovered or
countermeasures are deployed, the attack graph will be
reconstructed. Countermeasures are initiated by the attack

202

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 10,

NO. 4, JULY/AUGUST 2013

Fig. 1. NICE architecture within one cloud server cluster.

analyzer based on the evaluation results from the costbenefit analysis of the effectiveness of countermeasures.
Then, the network controller initiates countermeasure
actions by reconfiguring virtual or physical OFSs.

4.2 System Components
In this section, we explain each component of NICE.
4.2.1 NICE-A
The NICE-A is a Network-based Intrusion Detection System
(NIDS) agent installed in either Dom0 or DomU in each
cloud server. It scans the traffic going through Linux
bridges that control all the traffic among VMs and in/out
from the physical cloud servers. In our experiment, Snort is
used to implement NICE-A in Dom0. It will sniff a
mirroring port on each virtual bridge in the Open vSwitch
(OVS). Each bridge forms an isolated subnet in the virtual
network and connects to all related VMs. The traffic
generated from the VMs on the mirrored software bridge
will be mirrored to a specific port on a specific bridge using
SPAN, RSPAN, or ERSPAN methods. The NICE-A sniffing
rules have been custom defined to suite our needs. Dom0 in
the Xen environment is a privilege domain, that includes a
virtual switch for traffic switching among VMs and network
drivers for physical network interface of the cloud server. It
is more efficient to scan the traffic in Dom0 because all
traffic in the cloud server needs go through it; however, our
design is independent to the installed VM. In the
performance evaluation section, we will demonstrate the
tradeoffs of installing NICE-A in Dom0 and DomU.
We must note that the alert detection quality of NICE-A
depends on the implementation of NICE-A, which uses
Snort. We do not focus on the detection accuracy of Snort in
this paper. Thus, the individual alert detection’s false alarm
rate does not change. However, the false alarm rate could be
reduced through our architecture design. We will discuss
more about this issue in the later section.
4.2.2 VM Profiling
Virtual machines in the cloud can be profiled to get precise
information about their state, services running, open ports,
and so on. One major factor that counts toward a VM profile
is its connectivity with other VMs. Any VM that is
connected to more number of machines is more crucial

than the one connected to fewer VMs because the effect of
compromise of a highly connected VM can cause more
damage. Also required is the knowledge of services running
on a VM so as to verify the authenticity of alerts pertaining
to that VM. An attacker can use port-scanning program to
perform an intense examination of the network to look for
open ports on any VM. So information about any open ports
on a VM and the history of opened ports plays a significant
role in determining how vulnerable the VM is. All these
factors combined will form the VM profile.
VM profiles are maintained in a database and contain
comprehensive information about vulnerabilities, alert, and
traffic. The data comes from:
.

.
.

Attack graph generator. While generating the attack
graph, every detected vulnerability is added to its
corresponding VM entry in the database.
NICE-A. The alert involving the VM will be recorded
in the VM profile database.
Network controller. The traffic patterns involving the
VM are based on five tuples (source MAC address,
destination MAC address, source IP address, destination IP address, protocol). We can have traffic
pattern, where packets emanate from a single IP and
are delivered to multiple destination IP addresses,
and vice versa.

4.2.3 Attack Analyzer
The major functions of NICE system are performed by
attack analyzer, which includes procedures such as attack
graph construction and update, alert correlation, and
countermeasure selection.
The process of constructing and utilizing the SAG
consists of three phases: Information gathering, attack
graph construction, and potential exploit path analysis.
With this information, attack paths can be modeled using
SAG. Each node in the attack graph represents an exploit by
the attacker. Each path from an initial node to a goal node
represents a successful attack.
In summary, NICE attack graph is constructed based on
the following information:
.

Cloud system information is collected from the node
controller (i.e., Dom0 in XenServer). The information

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

Fig. 2. Workflow of attack analyzer.

includes the number of VMs in the cloud server,
running services on each VM, and VM’s Virtual
Interface (VIF) information.
. Virtual network topology and configuration information is
collected from the network controller, which includes
virtual network topology, host connectivity, VM
connectivity, every VM’s IP address, MAC address,
port information, and traffic flow information.
. Vulnerability information is generated by both ondemand vulnerability scanning (i.e., initiated by the
network controller and NICE-A) and regular penetration testing using the well-known vulnerability
databases, such as Open Source Vulnerability Database (OSVDB) [25], Common Vulnerabilities and
Exposures List (CVE) [23], and NIST National
Vulnerability Database (NVD) [26].
The attack analyzer also handles alert correlation and
analysis operations. This component has two major functions: 1) constructs ACG, and 2) provides threat information
and appropriate countermeasures to network controller for
virtual network reconfiguration.
Fig. 2 shows the workflow in the attack analyzer
component. After receiving an alert from NICE-A, alert
analyzer matches the alert in the ACG. If the alert already
exists in the graph and it is a known attack (i.e., matching
the attack signature), the attack analyzer performs countermeasure selection procedure according to the algorithm
described in Section 5.3. and then notifies network controller immediately to deploy countermeasure or mitigation
actions. If the alert is new, attack analyzer will perform alert
correlation and analysis according to Algorithm 1, and
updates ACG and SAG. This algorithm correlates each new
alert to a matching alert correlation set (i.e., in the same
attack scenario). A selected countermeasure is applied by
the network controller based on the severity of evaluation
results. If the alert is a new vulnerability and is not present
in the NICE attack graph, the attack analyzer adds it to
attack graph and then reconstructs it.

4.2.4 Network Controller
The network controller is a key component to support the
programmable networking capability to realize the virtual
network reconfiguration feature based on OpenFlow

203

protocol [20]. In NICE, within each cloud server there is a
software switch, for example, OVS [5], which is used as the
edge switch for VMs to handle traffic in and out from VMs.
The communication between cloud servers (i.e., physical
servers) is handled by physical OpenFlow-capable Switch
(OFS). In NICE, we integrated the control functions for both
OVS and OFS into the network controller that allows the
cloud system to set security/filtering rules in an integrated
and comprehensive manner.
The network controller is responsible for collecting
network information of current OpenFlow network and
provides input to the attack analyzer to construct attack
graphs. Through the cloud internal discovery modules
that use DNS, DHCP, LLDP, and flow initiations [27],
network controller is able to discover the network
connectivity information from OVS and OFS. This information includes current data paths on each switch and
detailed flow information associated with these paths,
such as TCP/IP and MAC header. The network flow and
topology change information will be automatically sent to
the controller and then delivered to attack analyzer to
reconstruct attack graphs.
Another important function of the network controller is
to assist the attack analyzer module. According to the
OpenFlow protocol [20], when the controller receives the
first packet of a flow, it holds the packet and checks the flow
table for complying traffic policies. In NICE, the network
control also consults with the attack analyzer for the flow
access control by setting up the filtering rules on the
corresponding OVS and OFS. Once a traffic flow is
admitted, the following packets of the flow are not handled
by the network controller, but monitored by the NICE-A.
Network controller is also responsible for applying the
countermeasure from attack analyzer. Based on VM Security
Index (VSI) and severity of an alert, countermeasures are
selected by NICE and executed by the network controller. If
a severe alert is triggered and identifies some known
attacks, or a VM is detected as a zombie, the network
controller will block the VM immediately. An alert with
medium threat level is triggered by a suspicious compromised VM. Countermeasure in such case is to put the
suspicious VM with exploited state into quarantine mode
and redirect all its flows to NICE-A DPI mode. An alert
with a minor threat level can be generated due to the
presence of a vulnerable VM. For this case, to intercept the
VM’s normal traffic, suspicious traffic to/from the VM will
be put into inspection mode, in which actions such as
restricting its flow bandwidth and changing network
configurations will be taken to force the attack exploration
behavior to stand out.

5

NICE SECURITY MEASUREMENT, ATTACK
MITIGATION, AND COUNTERMEASURES

In this section, we present the methods for selecting the
countermeasures for a given attack scenario. When
vulnerabilities are discovered or some VMs are identified
as suspicious, several countermeasures can be taken to
restrict attackers’ capabilities and it is important to
differentiate between compromised and suspicious VMs.
The countermeasure serves the purpose of: 1) protecting

204

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

P rðnjW Þ ¼ GM ½n 

the target VMs from being compromised, and 2) making
attack behavior stand prominent so that the attackers’
actions can be identified.

5.1 Security Measurement Metrics
The issue of security metrics has attracted much attention
and there has been significant effort in the development of
quantitative security metrics in recent years. Among
different approaches, using attack graph as the security
metric model for the evaluation of security risks [28] is a
good choice. To assess the network security risk condition
for the current network configuration, security metrics are
needed in the attack graph to measure risk likelihood. After
an attack graph is constructed, vulnerability information is
included in the graph. For the initial node or external node
(i.e., the root of the graph, NR  ND ), the priori probability is
assigned on the likelihood of a threat source becoming
active and the difficulty of the vulnerability to be exploited.
We use GV to denote the priori risk probability for the root
node of the graph and usually the value of GV is assigned to
a high probability, e.g., from 0.7 to 1.
For the internal exploitation node, each attack-step node
e 2 NC will have a probability of vulnerability exploitation
denoted as GM ½e. GM ½e is assigned according to the Base
Score (BS) from Common Vulnerability Scoring System
(CVSS). The BS as shown in (1) [24] is calculated by the
impact and exploitability factor of the vulnerability. BS can
be directly obtained from National Vulnerability Database
[26] by searching for the vulnerability CVE id
BS ¼ ð0:6  IV þ 0:4  E  1:5Þ  fðIV Þ;

ð1Þ

where
IV ¼ 10:41  ð1  ð1  CÞ  ð1  IÞ  ð1  AÞÞ;

and


0
if IV ¼ 0;
1:176 otherwise:

ð2Þ

In the attack graph, the relations between exploits can
be disjunctive or conjunctive according to how they are
related through their dependency conditions [29]. Such
relationships can be represented as conditional probability,
where the risk probability of current node is determined
by the relationship with its predecessors and their risk
probabilities. We propose the following probability
derivation relations:
.

Y

P rðsjW Þ;

ð3Þ

s2W

.

for any privilege node n 2 ND with immediate
predecessors set W ¼ parentðnÞ, and then
Y
ð1  P rðsjW ÞÞ:
ð4Þ
P rðnjW Þ ¼ 1 
s2W

Once conditional probabilities have been assigned to all
internal nodes in SAG, we can merge risk values from all
predecessors to obtain the cumulative risk probability or
absolute risk probability for each node according to (5) and (6).
Based on derived conditional probability assignments on
each node, we can then derive an effective security
hardening plan or a mitigation strategy:
.

for any attack-step node n 2 NC with immediate
predecessor set W ¼ parentðnÞ,
Y
P rðsÞ;
ð5Þ
P rðnÞ ¼ P rðnjW Þ 
s2W

.

for any privilege node n 2 ND with immediate
predecessor set W ¼ parentðnÞ,
Y
ð1  P rðsÞÞ:
ð6Þ
P rðnÞ ¼ 1 
s2W

5.2 Mitigation Strategies
Based on the security metrics defined in the previous
subsection, NICE is able to construct the mitigation
strategies in response to detected alerts. First, we define
the term countermeasure pool as follows:

cost is the unit that describes the expenses required to
apply the countermeasure in terms of resources and
operational complexity, and it is defined in a range from 1
to 5, and higher metric means higher cost;
2. intrusiveness is the negative effect that a countermeasure
brings to the SLA and its value ranges from the least
intrusive (1) to the most intrusive (5), and the value of
intrusiveness is 0 if the countermeasure has no impacts on
the SLA;
3. condition is the requirement for the corresponding
countermeasure;
4. effectiveness is the percentage of probability changes of
the node, for which this countermeasure is applied.
In general, there are many countermeasures that can be
applied to the cloud virtual networking system depending
on available countermeasure techniques that can be
applied. Without losing the generality, several common
virtual-networking-based countermeasures are listed in
Table 1. The optimal countermeasure selection is a multiobjective optimization problem, to calculate MIN(impact,
cost) and MAX(benefit).
1.

The impact value (IV ) is computed from three basic
parameters of security namely confidentiality (C), integrity
(I), and availability (A). The exploitability (E) score consists
of access vector (AV ), access complexity (AC), and
authentication instances (AU). The value of BS ranges from
0 to 10. In our attack graph, we assign each internal node
with its BS value divided by 10, as shown in
GM ½e ¼ P rðe ¼ T Þ ¼ BSðeÞ=10; 8e 2 NC :

NO. 4, JULY/AUGUST 2013

Definition 4 (Countermeasure Pool). A countermeasure pool
CM ¼ fcm1 ; cm2 ; . . . ; cmn g is a set of countermeasures. Each
cm 2 CM is a tuple cm = (cost, intrusiveness, condition,
effectiveness), where

E ¼ 20  AC  AU  AV ;

fðIV Þ ¼

VOL. 10,

for any attack-step node n 2 NC with immediate
predecessors set W ¼ parentðnÞ,

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

TABLE 1
Possible Countermeasure Types

In NICE, the network reconfiguration strategies mainly
involve two levels of action: Layer-2 and layer-3. At layer-2,
virtual bridges (including tunnels that can be established
between two bridges) and VLANs are main component in
cloud’s virtual networking system to connect two VMs
directly. A virtual bridge is an entity that attaches VIFs.
Virtual machines on different bridges are isolated at layer 2.
VIFs on the same virtual bridge but with different VLAN
tags cannot communicate to each other directly. Based on
this layer-2 isolation, NICE can deploy layer-2 network
reconfiguration to isolate suspicious VMs. For example,
vulnerabilities due to Arpspoofing [30] attacks are not
possible when the suspicious VM is isolated to a different
bridge. As a result, this countermeasure disconnects an
attack path in the attack graph causing the attacker to
explore an alternate attack path. Layer-3 reconfiguration is
another way to disconnect an attack path. Through the
network controller, the flow table on each OVS or OFS can
be modified to change the network topology.
We must note that using the virtual network reconfiguration approach at lower layer has the advantage in that
upper layer applications will experience minimal impact.
Especially, this approach is only possible when using
software-switching approach to automate the reconfiguration in a highly dynamic networking environment. Countermeasures such as traffic isolation can be implemented by
utilizing the traffic engineering capabilities of OVS and OFS
to restrict the capacity and reconfigure the virtual network
for a suspicious flow. When a suspicious activity such as
network and port scanning is detected in the cloud system,
it is important to determine whether the detected activity is
indeed malicious or not. For example, attackers can
purposely hide their scanning behavior to prevent the
NIDS from identifying their actions. In such situation,
changing the network configuration will force the attacker
to perform more explorations, and in turn will make their
attacking behavior stand out.

5.3 Countermeasure Selection
Algorithm 2 presents how to select the optimal countermeasure for a given attack scenario. Input to the algorithm is
an alert, attack graph G, and a pool of countermeasures CM.
The algorithm starts by selecting the node vAlert that
corresponds to the alert generated by a NICE-A. Before
selecting the countermeasure, we count the distance of vAlert
to the target node. If the distance is greater than a threshold

205

value, we do not perform countermeasure selection but
update the ACG to keep track of alerts in the system (line 3).
For the source node vAlert , all the reachable nodes (including
the source node) are collected into a set T (line 6). Because the
alert is generated only after the attacker has performed the
action, we set the probability of vAlert to 1 and calculate
the new probabilities for all of its child (downstream) nodes
in the set T (lines 7 and 8). Now, for all t 2 T the applicable
countermeasures in CM are selected and new probabilities
are calculated according to the effectiveness of the selected
countermeasures (lines 13 and 14). The change in probability
of target node gives the benefit for the applied countermeasure using (7). In the next double for-loop, we compute
the Return of Investment (ROI) for each benefit of the applied
countermeasure based on (8). The countermeasure which
when applied on a node gives the least value of ROI, is
regarded as the optimal countermeasure. Finally, SAG and
ACG are also updated before terminating the algorithm. The
complexity of Algorithm 2 is OðjV j  jCMjÞ, where jV j is the
number of vulnerabilities and jCMj represents the number
of countermeasures.
Algorithm 2. Countermeasure_Selection
Require: Alert; GðE; V Þ; CM
1: Let vAlert ¼ Source node of the Alert
2: if Distance to TargetðvAlert Þ > threshold then
3:
Update ACG
4:
return
5: end if
6: Let T ¼ DescendantðvAlert Þ [ vAlert
7: Set P rðvAlert Þ ¼ 1
8: Calculate_Risk_Prob(T )
9: Let benefit½jT j; jCMj ¼ ;
10: for each t 2 T do
11:
for each cm 2 CM do
12:
if cm:conditionðtÞ then
13:
P rðtÞ ¼ P rðtÞ  ð1  cm:effectivenessÞ
14:
Calculate_Risk_Prob(DescendantðtÞ)
15:
benefit½t; cm ¼ P rðtarget nodeÞ.
16:
end if
17:
end for
18: end for
19: Let ROI½jT j; jCMj ¼ ;
20: for each t 2 T do
21:
for each cm 2 CM do

(7)

benefit½t;cm
.
22:
ROI½t; cm ¼ cost:cmþintrusiveness:cm
23:
end for
24: end for
25: Update SAG and Update ACG
26: return Select Optimal CMðROIÞ

(8)

6

PERFORMANCE EVALUATION

In this section, we present the performance evaluation of
NICE. Our evaluation is conducted in two directions: The
security performance, and the system computing and
network reconfiguration overhead due to introduced
security mechanism.

206

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 10,

NO. 4, JULY/AUGUST 2013

TABLE 2
Vulnerabilities in the Virtual Networked System

Fig. 3. Virtual network topology for security evaluation.

6.1 Security Performance Analysis
To demonstrate the security performance of NICE, we
created a virtual network testing environment consisting of
all the presented components of NICE.
6.1.1 Environment and Configuration
To evaluate the security performance, a demonstrative
virtual cloud system consisting of public (public virtual
servers) and private (VMs) virtual domains is established as
shown in Fig. 3. Cloud Servers 1 and 2 are connected to
Internet through the external firewall. In the Demilitarized
Zone (DMZ) on Server 1, there is one Mail server, one DNS
server and one web server. Public network on Server 2
houses SQL server and NAT Gateway Server. Remote
access to VMs in the private network is controlled through
SSHD (i.e., SSH Daemon) from the NAT Gateway Server.
Table 2 shows the vulnerabilities present in this network
and Table 3 shows the corresponding network connectivity
that can be explored based on the identified vulnerabilities.
6.1.2 Attack Graph and Alert Correlation
The attack graph can be generated by utilizing network
topology and the vulnerability information, and it is
shown in Fig. 4. As the attack progresses, the system
generates various alerts that can be related to the nodes in
the attack graph.
Creating an attack graph requires knowledge of network
connectivity, running services, and their vulnerability
information. This information is provided to the attack
graph generator as the input. Whenever a new vulnerability
is discovered or there are changes in the network connectivity and services running through them, the updated
information is provided to attack graph generator and old
attack graph is updated to a new one. SAG provides
information about the possible paths that an attacker can
follow. ACG serves the purpose of confirming attackers’
behavior, and helps in determining false positive and false
negative. ACG can also be helpful in predicting attackers’
next steps.
6.1.3 Countermeasure Selection
To illustrate how NICE works, let us consider, for example,
an alert is generated for node 16 (vAlert ¼ 16) when the
system detects LICQ Buffer overflow. After the alert is
generated, the cumulative probability of node 16 becomes 1

because that attacker has already compromised that node.
This triggers a change in cumulative probabilities of child
nodes of node 16. Now, the next step is to select the
countermeasures from the pool of countermeasures CM. If
the countermeasure CM4: Create filtering rules is applied to
node 5 and we assume that this countermeasure has
effectiveness of 85 percent, the probability of node 5 will
change to 0.1164, which causes change in probability values
of all child nodes of node 5 thereby accumulating to a
decrease of 28.5 percent for the target node 1. Following the
same approach for all possible countermeasures that can be
applied, the percentage change in the cumulative probability of node 1, i.e., benefit computed using (7) are shown
in Fig. 5.
Apart from calculating the benefit measurements, we also
present the evaluation based on ROI using (8) and represent
a comprehensive evaluation considering benefit, cost, and
intrusiveness of countermeasure. Fig. 6 shows the ROI
evaluations for presented countermeasures. Results show
that countermeasures CM2 and CM8 on node 5 have the
maximum benefit evaluation; however, their cost and
intrusiveness scores indicate that they might not be good
candidates for the optimal countermeasure and ROI
evaluation results confirm this. The ROI evaluations
demonstrate that CM4 on node 5 is the optimal solution.

6.1.4 Experiment in Private Cloud Environment
Previously, we presented an example where the attackers
target is VM in the private network. For performance
analysis and capacity test, we extended the configuration in
Table 3 to create another test environment, which includes
14 VMs across three cloud servers and configured each VM
as a target node to create a dedicated SAG for each VM.
TABLE 3
Virtual Network Connectivity

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

207

Fig. 4. Attack graph for the test network.

These VMs consist of Windows (W) and Linux (L) machines
in the private network 172.16.11.0/24, and contains more
number of vulnerabilities related to their OSes and
applications. We created penetration testing scripts with
Metasploit framework [31] and Armitage [32] as attackers in
our test environment. These scripts emulate attackers from
different places in the internal and external sources, and
launch diversity of attacks based on the vulnerabilities in
each VM.
To evaluate security level of a VM, we define a VSI to
represent the security level of each VM in the current virtual
network environment. This VSI refers to the VEA-bility
metric [33] and utilizes two parameters that include

Vulnerability and Exploitability as security metrics for a
VM. The VSI value ranges from 0 to 10, where lower value
means better security. We now define VSI:

Fig. 5. Benefit evaluation chart.

Fig. 6. ROI evaluation chart.

Definition 5 (VSI). VSI for a virtual machine k is defined as
V SIk ¼ ðVk þ Ek Þ=2, where
1.

2.

Vk is vulnerability score for VM k. The score is the
exponential average of BS from each vulnerability in
thePVM or a maximum 10, i.e., Vk ¼ minf10;
ln eBaseScoreðvÞ g.
Ek is exploitability score for VM k. It is the
exponential average of exploitability score for all

208

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

Fig. 7. VM security index.

vulnerabilities or a maximum 10 multiplied by the
ratio of network
services on the VM, i.e., Ek ¼
P
Sk
Þ. Sk repreðminf10; ln eExploitabilityScoreðvÞ gÞ  ðNS
k
sents the number of services provided by VM k. NSk
represents the number of network services the VM k
can connect to.
Basically, vulnerability score considers the BSs of all the
vulnerabilities on a VM. The BS depicts how easy it is for an
attacker to exploit the vulnerability and how much damage
it may incur. The exponential addition of BSs allows the
vulnerability score to incline toward higher BS values and
increases in logarithm-scale based on the number of
vulnerabilities. The exploitability score on the other hand
shows the accessibility of a target VM, and depends on the
ratio of the number of services to the number of network
services as defined in [33]. Higher exploitability score
means that there are many possible paths for that attacker to
reach the target.
VSI can be used to measure the security level of each VM
in the virtual network in the cloud system. It can be also
used as an indicator to demonstrate the security status of a
VM, i.e., a VM with higher value of VSI means is easier to be
attacked. To prevent attackers from exploiting other
vulnerable VMs, the VMs with higher VSI values need to
be monitored closely by the system (e.g., using DPI) and
mitigation strategies may be needed to reduce the VSI value
when necessary.
Fig. 7 shows the plotting of VSI for these virtual
machines before countermeasure selection and application.
Fig. 8 compares VSI values before and after applying the
countermeasure CM4, i.e., creating filtering rules. It shows
the percentage change in VSI after applying countermeasure on all of the VMs. Applying CM4 avoids
vulnerabilities and causes VSI to drop without blocking
normal services and ports.

6.1.5 False Alarms
A cloud system with hundreds of nodes will have huge
amount of alerts raised by Snort. Not all of these alerts can
be relied upon, and an effective mechanism is needed to
verify if such alerts need to be addressed. Since Snort can be
programmed to generate alerts with CVE id, one approach
that our work provides is to match if the alert is actually
related to some vulnerability being exploited. If so, the
existence of that vulnerability in SAG means that the alert is
more likely to be a real attack. Thus, the false positive rate
will be the joint probability of the correlated alerts, which

VOL. 10,

NO. 4, JULY/AUGUST 2013

Fig. 8. Change in VSI.

will not increase the false positive rate compared to each
individual false positive rate.
Moreover, we cannot keep aside the case of zero-day
attack, where the vulnerability is discovered by the attacker
but is not detected by vulnerability scanner. In such case,
the alert being real will be regarded as false, given that there
does not exist corresponding node in SAG. Thus, current
research does not address how to reduce the false negative
rate. It is important to note that vulnerability scanner
should be able to detect most recent vulnerabilities and sync
with the latest vulnerability database to reduce the chance
of Zero-day attacks.

6.2 NICE System Performance
We evaluate system performance to provide guidance on
how much traffic NICE can handle for one cloud server and
use the evaluation metric to scale up to a large cloud
system. In a real cloud system, traffic planning is needed to
run NICE, which is beyond the scope of this paper. Due to
the space limitation, we will investigate the research
involving multiple cloud clusters in the future.
To demonstrate the feasibility of our solution, comparative studies were conducted on several virtualization
approaches. We evaluated NICE based on Dom0 and
DomU implementations with mirroring-based and proxybased attack detection agents (i.e., NICE-A). In mirrorbased IDS scenario, we established two virtual networks in
each cloud server: Normal network and monitoring network. NICE-A is connected to the monitoring network.
Traffic on the normal network is mirrored to the monitoring network using Switched Port Analyzer (SPAN)
approach. In the proxy-based IDS solution, NICE-A
interfaces two VMs and the traffic goes through NICE-A.
Additionally, we have deployed the NICE-A in Dom0 and
it removes the traffic duplication function in mirroring and
proxy-based solutions.
NICE-A running in Dom0 is more efficient because it
can sniff the traffic directly on the virtual bridge. However,
in DomU, the traffic need to be duplicated on the VM’s
VIF, causing overhead. When the IDS is running in
Intrusion Prevention System (IPS) mode, it needs to
intercept all the traffic and perform packet checking,
which consumes more system resources as compared to
IDS mode. To demonstrate performance evaluations, we
used four metrics namely CPU utilization, network
capacity, agent processing capacity, and communication
delay. We performed the evaluation on cloud servers with
Intel quad-core Xeon 2.4-GHz CPU and 32-G memory.

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

209

Fig. 9. CPU utilization of NICE-A.
Fig. 11. Network communication delay of NICE-A.

We used packet generator to mimic real traffic in the
cloud system. As shown in Fig. 9, the traffic load, in the
form of packet sending speed, increases from 1 to
3,000 packets per second. The performance at Dom0
consumes less CPU and the IPS mode consumes the
maximum CPU resources. It can be observed that when
the packet rate reaches to 3,000 packets per second, the CPU
utilization of IPS at DomU reaches its limitation, while the
IDS mode at DomU only occupies about 68 percent.
Fig. 10, represents the performance of NICE-A in terms
of percentage of successfully analyzed packets, i.e., the
number of the analyzed packets divided by the total
number of packets received. The higher this value is, more
packets this agent can handle. It can be observed from the
result that IPS agent demonstrates 100 percent performance
because every packet captured by the IPS is cached in
the detection agent buffer. However, 100 percent success
analyzing rate of IPS is at the cost of the analyzing delay.
For other two types of agents, the detection agent does not
store the captured packets and, thus, no delay is
introduced. However, they all experience packet drop
when traffic load is huge.
In Fig. 11, the communication delay with the system
under different NICE-A is presented. We generated
100 consecutive normal packets with the speed of 1 packet
per second to test the end-to-end delay of two VMs
compared by using NICE-A running in mirroring and
proxy modes in DomU and NICE running in Dom0. We
record the minimal, average, and maximum communication delay in the comparative study. Results show that the
delay of proxy-based NICE-A is the highest because every
packet has to pass through it. Mirror-based NICE-A at
DomU and NICE-A at Dom0 do not have noticeable
differences in the delay. In summary, the NICE-A at
Dom0 and Mirror-based NICE-A at DomU have better
performance in terms of delay.

From this test, we expected to prove the proposed
solution, thus achieving our goal “establish a dynamic
defensive mechanism-based software defined networking
approach that involves multiphase intrusion detections.”
The experiments prove that for a small-scale cloud system,
our approach works well. The performance evaluation
includes two parts. First, security performance evaluation.
It shows that the our approach achieves the design security
goals: To prevent vulnerable VMs from being compromised
and to do so in less intrusive and cost effective manner.
Second, CPU and throughput performance evaluation. It
shows the limits of using the proposed solution in terms of
networking throughputs based on software switches and
CPU usage when running detection engines on Dom 0 and
Dom U. The performance results provide us a benchmark
for the given hardware setup and shows how much traffic
can be handled by using a single detection domain. To scale
up to a data center-level IDS, a decentralized approach
must be devised, which is scheduled in our future research.

7

CONCLUSION AND FUTURE WORK

In this paper, we presented NICE, which is proposed to
detect and mitigate collaborative attacks in the cloud virtual
networking environment. NICE utilizes the attack graph
model to conduct attack detection and prediction. The
proposed solution investigates how to use the programmability of software switches-based solutions to improve
the detection accuracy and defeat victim exploitation phases
of collaborative attacks. The system performance evaluation
demonstrates the feasibility of NICE and shows that the
proposed solution can significantly reduce the risk of the
cloud system from being exploited and abused by internal
and external attackers.
NICE only investigates the network IDS approach to
counter zombie explorative attacks. To improve the detection accuracy, host-based IDS solutions are needed to be
incorporated and to cover the whole spectrum of IDS in the
cloud system. This should be investigated in the future
work. Additionally, as indicated in the paper, we will
investigate the scalability of the proposed NICE solution by
investigating the decentralized network control and attack
analysis model based on current study.

ACKNOWLEDGMENTS

Fig. 10. NICE-A success analyzing rate.

This work is supported by Hewlett-Packard Lab’s Innovation Research Program Grant and the Office of Naval
Research Young Investigator Program Award.

210

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

REFERENCES
[1]
[2]

[3]
[4]
[5]
[6]

[7]

[8]

[9]
[10]
[11]
[12]
[13]

[14]
[15]

[16]

[17]
[18]
[19]
[20]

[21]

[22]
[23]
[24]
[25]

Coud Sercurity Alliance, “Top Threats to Cloud Computing v1.0,”
https://cloudsecurityalliance.org/topthreats/csathreats. v1.0.pdf,
Mar. 2010.
M. Armbrust, A. Fox, R. Griffith, A.D. Joseph, R. Katz, A.
Konwinski, G. Lee, D. Patterson, A. Rabkin, I. Stoica, and M.
Zaharia, “A View of Cloud Computing,” ACM Comm., vol. 53,
no. 4, pp. 50-58, Apr. 2010.
B. Joshi, A. Vijayan, and B. Joshi, “Securing Cloud Computing
Environment Against DDoS Attacks,” Proc. IEEE Int’l Conf.
Computer Comm. and Informatics (ICCCI ’12), Jan. 2012.
H. Takabi, J.B. Joshi, and G. Ahn, “Security and Privacy
Challenges in Cloud Computing Environments,” IEEE Security
and Privacy, vol. 8, no. 6, pp. 24-31, Dec. 2010.
“Open vSwitch Project,” http://openvswitch.org, May 2012.
Z. Duan, P. Chen, F. Sanchez, Y. Dong, M. Stephenson, and J.
Barker, “Detecting Spam Zombies by Monitoring Outgoing
Messages,” IEEE Trans. Dependable and Secure Computing, vol. 9,
no. 2, pp. 198-210, Apr. 2012.
G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee,
“BotHunter: Detecting Malware Infection through IDS-driven
Dialog Correlation,” Proc. 16th USENIX Security Symp. (SS ’07),
pp. 12:1-12:16, Aug. 2007.
G. Gu, J. Zhang, and W. Lee, “BotSniffer: Detecting Botnet
Command and Control Channels in Network Traffic,” Proc. 15th
Ann. Network and Distributed Sytem Security Symp. (NDSS ’08), Feb.
2008.
O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J.M. Wing,
“Automated Generation and Analysis of Attack Graphs,” Proc.
IEEE Symp. Security and Privacy, pp. 273-284, 2002,
“NuSMV: A New Symbolic Model Checker,” http://afrodite.itc.
it:1024/nusmv. Aug. 2012.
P. Ammann, D. Wijesekera, and S. Kaushik, “Scalable, graphbased network vulnerability analysis,” Proc. 9th ACM Conf.
Computer and Comm. Security (CCS ’02), pp. 217-224, 2002.
X. Ou, S. Govindavajhala, and A.W. Appel, “MulVAL: A LogicBased Network Security Analyzer,” Proc. 14th USENIX Security
Symp., pp. 113-128, 2005.
R. Sadoddin and A. Ghorbani, “Alert Correlation Survey: Framework and Techniques,” Proc. ACM Int’l Conf. Privacy, Security and
Trust: Bridge the Gap between PST Technologies and Business Services
(PST ’06), pp. 37:1-37:10, 2006.
L. Wang, A. Liu, and S. Jajodia, “Using Attack Graphs for
Correlating, Hypothesizing, and Predicting Intrusion Alerts,”
Computer Comm., vol. 29, no. 15, pp. 2917-2933, Sept. 2006.
S. Roschke, F. Cheng, and C. Meinel, “A New Alert Correlation
Algorithm Based on Attack Graph,” Proc. Fourth Int’l Conf.
Computational Intelligence in Security for Information Systems,
pp. 58-67, 2011.
A. Roy, D.S. Kim, and K. Trivedi, “Scalable Optimal Countermeasure Selection Using Implicit Enumeration on Attack Countermeasure Trees,” Proc. IEEE Int’l Conf. Dependable Systems Networks
(DSN ’12), June 2012.
N. Poolsappasit, R. Dewri, and I. Ray, “Dynamic Security Risk
Management Using Bayesian Attack Graphs,” IEEE Trans.
Dependable and Secure Computing, vol. 9, no. 1, pp. 61-74, Feb. 2012.
Open Networking Fundation, “Software-Defined Networking:
The New Norm for Networks,” ONF White Paper, Apr. 2012.
“Openflow,” http://www.openflow.org/wp/learnmore/, 2012.
N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L.
Peterson, J. Rexford, S. Shenker, and J. Turner, “OpenFlow:
Enabling Innovation in Campus Networks,” SIGCOMM Computer
Comm. Rev., vol. 38, no. 2, pp. 69-74, Mar. 2008.
E. Keller, J. Szefer, J. Rexford, and R.B. Lee, “NoHype:
Virtualized Cloud Infrastructure without the Virtualization,”
Proc. 37th ACM Ann. Int’l Symp. Computer Architecture (ISCA ’10),
pp. 350-361, June 2010.
X. Ou, W.F. Boyer, and M.A. McQueen, “ A Scalable Approach to
Attack Graph Generation,” Proc. 13th ACM Conf. Computer and
Comm. Security (CCS ’06), pp. 336-345, 2006.
Mitre Corporation, “Common Vulnerabilities and Exposures,
CVE,” http://cve.mitre.org/, 2012.
P. Mell, K. Scarfone, and S. Romanosky, “Common Vulnerability
Scoring System (CVSS),” http://www.first.org/cvss/cvss-guide.
html, May 2010.
O. Database, “Open Source Vulnerability Database (OVSDB),”
http://osvdb.org/, 2012.

VOL. 10,

NO. 4, JULY/AUGUST 2013

[26] National Institute of Standards and Technology, “National
Vulnerability Database, NVD,” http://nvd.nist. gov, 2012.
[27] N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown,
and S. Shenker, “NOX: Towards an Operating System for
Networks,” SIGCOMM Computer Comm. Rev., vol. 38, no. 3,
pp. 105-110, July 2008.
[28] X. Ou and A. Singhal, Quantitative Security Risk Assessment of
Enterprise Networks. Springer, Nov. 2011.
[29] M. Frigault and L. Wang, “Measuring Network Security Using
Bayesian Network-Based Attack Graphs,” Proc. IEEE 32nd Ann.
Int’l Conf. Computer Software and Applications (COMPSAC ’08),
pp. 698-703, Aug. 2008.
[30] K. Kwon, S. Ahn, and J. Chung, “Network Security Management
Using ARP Spoofing,” Proc. Int’l Conf. Computational Science and Its
Applications (ICCSA ’04), pp. 142-149, 2004.
[31] “Metasploit,” http://www.metasploit.com, 2012.
[32] “Armitage,” http://www.fastandeasyhacking.com, 2012.
[33] M. Tupper and A. Zincir-Heywood, “VEA-bility Security Metric:
A Network Security Analysis Tool,” Proc. IEEE Third Int’l Conf.
Availability, Reliability and Security (ARES ’08), pp. 950-957, Mar.
2008.
Chun-Jen Chung received the MS degree in
computer science from New York University.
He is currently working toward the PhD degree
in the School of Computing Informatics and
Decision Systems Engineering at Arizona State
University. Previously, he was a software
developer in Microsoft and Oracle for several
years. His current research interests include
computer and network security, security in
software-defined networking, and trusted computing in mobile devices and cloud computing. He is a student member
of the IEEE.
Pankaj Khatkar received the BE degree in
computer engineering in 2010 from the University of Mumbai, India, and is currently working
toward the PhD degree and is a research
associate in the School of Computing Informatics
and Decision Systems Engineering at Arizona
State University. His research interests lie in the
area of computer and network security and
mobile cloud computing with emphasis on cloud
security. He is a student member of the IEEE.
Tianyi Xing received the BE degree in telecommunications engineering from Xidian University and the ME degree in electronic
engineering from the Beijing University of Posts
& Telecommunications in 2007 and 2010,
respectively. He is currently working toward the
PhD degree in the School of Computing Informatics and Decision Systems Engineering at
Arizona State University. From July 2009 to
December 2009, he worked at Microsoft Research Asia as a research intern. His research interests are in secure
networking design and implementation, software-defined networking,
and cloud computing. He is a student member of the IEEE.

CHUNG ET AL.: NICE: NETWORK INTRUSION DETECTION AND COUNTERMEASURE SELECTION IN VIRTUAL NETWORK SYSTEMS

Jeongkeun Lee received the PhD degree in
computer science and engineering from Seoul
National University. He is a senior researcher in
the Networking and Communications Lab, HP
Labs. His research interest include cloud networking, software-defined networking, and mobile and wireless communication systems. He is
a member of the IEEE.

211

Dijiang Huang received the BS degree from the
Beijing University of Posts and Telecommunications, China 1995, and the MS and PhD degrees
from the University of Missouri, Kansas City, in
2001 and 2004, respectively. He is currently an
associate professor in the School of Computing
Informatics and Decision System Engineering at
the Arizona State University. His current research interests include computer network security, mobile computing, and cloud computing.
He is an associate editor of the Journal of Network and System
Management. He served as an organizer for many international
conferences and workshops. His research is supported by the National
Science Foundation, the Office of Naval Research, the US Navy, and
Hewlett-Packard. He received the ONR Young Investigator Award 2010.
He is a senior member of the IEEE.

. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

IEEE TRANSACTIONS ON SERVICES COMPUTING,

VOL. 8, NO. 4,

JULY/AUGUST 2015

601

From RBAC to ABAC: Constructing Flexible Data
Access Control for Cloud Storage Services
Yan Zhu, Member, IEEE, Dijiang Huang, Senior Member, IEEE, Chang-Jyun Hu, and Xin Wang
Abstract—This paper addresses how to construct an RBAC-compatible secure cloud storage service with a user-friendly and
easy-to-manage attribute-based access control (ABAC) mechanism. Similar to role hierarchies in RBAC, attribute hierarchies
(considered as partial ordering relations) are introduced into attribute-based encryption (ABE) in order to define a seniority relation
among all values of an attribute, whereby a user holding senior attribute values acquires permissions of his/her juniors. Based on these
notations, we present a new ABE scheme called attribute-based encryption with attribute hierarchies (ABE-AH) to provide an efficient
approach to implement comparison operations between attribute values on a poset derived from an attribute lattice. By using bilinear
groups of a composite order, we present a practical construction of ABE-AH based on forward and backward derivation functions.
Compared with prior solutions, our scheme offers a compact policy representation approach that can significantly reduce the size of
private-keys and ciphertexts. To demonstrate how to use the presented solution, we illustrate how to provide richer expressive access
policies to facilitate flexible access control for data access services in clouds.
Index Terms—Security, secure cloud storage, role-based access control, attribute-based encryption, data migration

Ç
1

INTRODUCTION

I

NCREASINGLY, more and more enterprises and individuals
have moved their data, such as personal data and large
archive system, into cloud-based storage services because
they provide various attractive services such as infinite
capacity on on-demand, no upfront cost, long-term archiving, etc. Furthermore, consumers can access applications
and data without location constraints. However, several
recent surveys [1], [2] showed that 88 percent potential
cloud consumers worry about the privacy of their data, and
security is often cited as the top concern for adopting cloudbased storage solutions.
Using cloud-based storage services, it is common to centrally store customers’ data. Security issues arose due to the
fact that cloud-based storage is outsourcing-service and there
may incur untrusted or honest-but-curious attacks. In order
to protect the privacy of consumers’ data, attribute-based
encryption (ABE) [3], [4], [5] has been proposed to provide
data access control for cloud storage services. ABE is a powerful and flexible approach, which implements attributebased access control (ABAC) by encrypting data with a
specified access policy over attributes [6]. By matching
attributes of access policy on the stored data, only authorized users who own these attributes and corresponding
private keys can access and decrypt the data. For example,
we use ABE to encrypt a file by enforcing the following



Y. Zhu, C.-J. Hu, and X. Wang are with the School of Computer and
Communication Engineering, University of Science and Technology
Beijing, Beijing 100083, China.
E-mail: {zhuyan, Wangxin}@ustb.edu.cn, chjyhu@163.com.
 D. Huang is with the School of Computing, Informatics, and Decision
Systems Engineering, Arizona State University, Tempe, AZ 85287.
E-mail: dijiang@asu.edu.
Manuscript received 3 Feb. 2014; revised 9 Aug. 2014; accepted 25 Sept. 2014.
Date of publication 15 Oct. 2014; date of current version 7 Aug. 2015.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identifier below.
Digital Object Identifier no. 10.1109/TSC.2014.2363474

data access policy:
ðððFaculty ¼ Prof:Þ or ðFaculty ¼ Associate Prof:Þ
or ðFaculty ¼ Assistant Prof:ÞÞ and ðDep: ¼ CSÞÞ:
Using ABE solution, this data access policy is used as a public constraint to encrypt a data encrypting key (DEK), and
then the data is encrypted by the DEK. If a user owns
the private key with the corresponding attributes: i.e.,
fFaculty
Prof:; Dep:
CSg, he can obtain the DEK and
then decrypt this encrypted data.
ABE has been proved to be a powerful data access control solution that meets a variety of application requirements for cloud-based storage services. However, ABE also
has some implementation issues when using attributes to
construct the data access policies. First, data migration from
existing IT systems to a cloud storage environment is not
easy to be transferred because these systems are usually not
designed for ABAC. Second, ABE as a fine-grained data
access control requires that “objects receive their attributes
either directly from the data creator or as a result of automated
scanning tools” according to NIST’s ABAC definition [7]. In
the former case, the data creator needs to know the data
access policies in advance, which may require substantial
background knowledge on how to construct the data access
policies. In the latter case, the deployment of effective scanning tools is usually difficult when the data access policies
are required to keep consistent with diverse interpretations
of access policies from various data creators and users.
These restrictions hinder the applicability of using ABE for
cloud storage services.
To address the above-described issues and provide a
smooth transition for using ABAC in cloud storage service,
we first investigate into the role-based access control
(RBAC) that has been widely adopted by various information systems (such as Windows/Active Directory RBAC,
HP-UX, AIX, Oracle). Compared to ABAC, advantages of

1939-1374 ß 2014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

602

IEEE TRANSACTIONS ON SERVICES COMPUTING,

Fig. 1. The architecture for user-friendly security cloud storage in existing RBAC system.

using RBAC include simplicity, easy-to-use, and automatic
running without user’s intervention. To see an example of
this in an RBAC-based system, a role’s responsibilities and
relationships to other roles are usually specified by an
administrator or using a system default setup, and the role
assignment is usually transparent to end users. Typically,
users do not need to develop access policies for their own
resources; but if necessary, they can customize their own
policies. Based on this fact, our goal is to establish a userfriendly, secure, flexible, and easy-to-manage access control
service by transferring the easy-use features of RBAC model
into the ABAC model by applying ABE schemes. As a
result, cloud storage services can be naturally implemented
based on this kind of ABAC model.
To illustrate the presented solution, an example of cloud
storage service is shown in Fig. 1, where conversion mechanism from RBAC to ABAC (realized by Migration Proxy) is
introduced as a bridge that migrates automatically data from
existing RBAC systems to cloud-based ABAC system. In this
system, public cloud could be used to store actual data in the
ABE-encrypted form. Users who wish to share or access the
data only need to interact with the existing RBAC systems
(such as Windows NT and Linux); and the migration proxy
should make automatically and routinely data transmission
between two systems. At the meantime, the cloud storage
service can also provide ABAC-based security policy
enforcement directly to more advanced users.
To achieve the described system, there are many technical challenges to overcome. One of the most challenging
issues is to implement the hierarchy structure used by
RBAC as well as cryptographic partial ordering relation in
ABE. This means that we must provide an efficient
approach to support attribute hierarchy with arbitrary partial ordering relations, including the comparative operations (ai  aj ) for a poset H ¼ ðA; Þ on a set of attributes
A ¼ fa1 ; . . . ; an g. Such a partial ordering relation is very
helpful to reduce the computation overhead of using ABE,
as well as to keep the compatibility with the RBAC model.
For instance, in the previously presented example, we can
define a set of attribute values as
Faculty ¼ fLecture; Assistant Prof:; Associate Prof:; Prof:g
and a partial ordering relation (called attribute hierarchy)
Lecture  Assistant Prof:  Associate Prof:  Prof: Then,
we can define a policy as
ððFaculty  Associate Prof:Þ and ðDep: ¼ CSÞÞ:

VOL. 8,

NO. 4,

JULY/AUGUST 2015

It is easy to find that this approach simplifies the complexity
of deploying access policies from this instance, however
none of ABE schemes support the partial ordering relation.
Fortunately, there have been some cryptographic work [8],
[9] has been proposed to realize the hierarchical key in terms
of RBAC. The main drawback of these solutions is that they
cannot be directly utilized by ABE schemes. On the other
side, some ABE solutions support the tree-hierarchy (i.e.,
called hierarchical ABE) [10], [11], [12]. However they cannot support full RBAC-type hierarchy [13] (i.e., a lattice with
tree, inverted tree, or general hierarchies) on all attribute values. We address the described challenges by constructing an
effective RBAC-compatible ABE for secure cloud storage
services. Our solution takes advantages of both RBAC and
ABAC, and it is compatible with existing RBAC systems. In
summary, our contributions are presented as follows:


We present a practical solution to convert RBACbased rules into ABAC-based policies. This conversion can help migrate the data from existing RBAC
systems into ABE-based secure cloud storage. This
solution fully utilizes the highly automated feature
of existing RBAC system, so it provides the following advantages:
- including good properties of both RBAC and
ABAC;
- making it compatible to existing RBAC;
- realizing more flexible policy enforcement for
cloud data storage due to policy expended from
RBAC to ABAC.
 We present an effective cryptographic method to
realize partial ordering relation (derived from hierarchy structure in RBAC) used by existing ABE solutions. In our approach, a hierarchical hash function
(HHF) is introduced for realizing the cryptographic
order-preserving mapping from a partial-order hierarchy. Based on this function, we present a new ABE
scheme, called ABE with Attribute Hierarchy (ABEAH), for our RBAC-compatible data access control
for secure cloud storage services.
 We prove that our ABE-AH scheme is semantic
secure and unforgeable under the Computational
Diffie-Hellman (CDH) and extended Decisional Diffie-Hellman (eDDH) assumptions.
 Compared with prior ABE solutions, ABE-AH
scheme provides more succinct and richer policy
representations with more flexible access control
capabilities.
Organization. Section 2 overviews some basic notations and
frameworks. In Section 3, we present our solution from
RBAC to ABAC. Sections 4 and 5 provide the definitions of
ABE-AH, security models, and cryptographic partial ordering
relations. We present the construction of ABE-AH and its
security analysis in Sections 6 and 7, respectively. We evaluate
the performance of the ABE-AH scheme in Section 8. Finally,
We conclude the solution in Section 10.

2

NOTATIONS AND DEFINITIONS

In this section, we provide the definitions of RBAC and
ABAC models, as well as some notations used in this paper.

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

Furthermore, the relationships between them are discussed
and analysed, and ABE over ABAC is introduced in the
end. These discussions lay a foundation for our solution.

2.1 RBAC Model
In an information system, a hierarchy or lattice is used to
denote the relationships and arrangements of the objects,
users, elements, values, and so on. Especially, in many access
control systems the users are organized in a hierarchy constructed with a number of classes, called security classes or
roles, according to their competencies and responsibilities.
This hierarchy arises from the fact that some users have
more access rights than others. In order to manage largescale systems, the hierarchy in RBAC becomes more complex
than other systems. Especially, role hierarchy (RH) is a natural means for structuring roles to reflect an organization’s
lines of authority and responsibility. We adopt the definitions from RBAC models proposed by Sandu et al. [14]:
Definition 1 [Hierarchical RBAC model]. The RBAC model
has the following components:







U, R, P , and S denote users, roles, permissions and
sessions respectively;
PA  P  R is a many-to-many permission to role
assignment relation;
UA  U  R is a many-to-many user to role assignment relation;
RH  R  R is a partial order on R called the role
hierarchy or role dominance relation, written as ;
user : S ! U is a function mapping each session si to
the single user userðsi Þ; and
roles : S ! 2R is a function mapping each session si
to a set of roles: rolesðsi Þ  fr 2 R j 9r0 2 R; r  r0 :
0
ðuserðs
i Þ; r Þ 2 UAg and si has the permissions:
S
00
00
00
r2rolesðsi Þ fp 2 P j 9r 2 R; r  r : ðp; r Þ 2 PAg.

The last component states that the system can automatically run the RBAC without user’s intervention. When a
user performs an operation, first of all, the system uses the
function userðsi Þ, taking as input the session si , to get the
single user. Next, the set of the user’s roles rolesðsi Þ is
known by using the user to role assignment relation UA.
Then, the user’s permissions are found by using the role
hierarchy RH and permission to role assignment relation
PA. Finally, the system determines whether the user’s operation is legitimate according to the permissions. We present
some terminologies in partial order. Let C ¼ hP; i be a
(finite) partially ordered set with partial order relation  on
a (finite) set P . Two distinct elements x and y in C are said
to be comparable if x  y or y  x. Otherwise, they are
incomparable, denoted by xky and ?x denotes the independent set fy 2 P j xjjyg.

2.2 ABAC Model
Similar to role hierarchy in RBAC, the hierarchy is also
extremely useful for ABE to introduce attribute hierarchy or
attribute lattice (AH or AL), which defines a seniority relation among all values of an attribute, whereby a user holding the senior attribute values acquires the permissions of

603

TABLE 1
Grammar for ABAC Addresses and Policies
Name

Symbol

Attribute
Attribute value
Delivery Policy
Condition
Literal
Relation

Ai
ai;j
p
%
x


Description
2
2
::¼¼
::¼¼
::¼¼
::¼¼

a set of attributes A
Numerals j Strings
%
xjð% or %Þjð% and %Þ
ðAi  ai;j Þ
j	j¼jj

their juniors. In fact, this kind of attribute lattice has been
introduced in ABAC model [6].
Table 1 describes the language according to [15]. We
call an access control system as an ABAC system if this
system satisfies the above specifications. Here, access
policy can be expressed as a logical function on some
attribute values. For the sake of clarity, we propose a definition of policy matching (or relation matching) of attributebased access control as follows:
Definition 2 (ABAC Model). The ABAC model has the following components:








Let A ¼ fA1 ; . . . ; An g be a (finite) set of attributes. Let
Ai ¼ fai;1 ; . . . ; ai;m g be a set of values correspond to
an attribute Ai 2 A. Ai is called as a hierarchy, if all
elements in ai have a partial ordering relation . That
is, Hi ¼ ðAi ; Þ.
Let x :¼ Ai  ai;j denote a literal in terms of the relation between Ai and ai;j in a poset Hi . For an assignment of attribute value Ai
ai;l , the relation
Ai  ai;j returns “true” if ai;l  ai;j ; otherwise, it
returns “false”.
Let p :¼ ]xk denote an access policy function based on
the Boolean function, where ] denotes either and or or
logical operation. For the assignment of attribute valða1;j1 ; . . . ; an;jn Þ, the policy
ues r :¼ ðA1 ; . . . ; An Þ
matching between hp; ri (which is denoted as
Matchðp; rÞ) returns “true” if the Boolean function is
satisfied according to the results of literals, otherwise,
it returns “false”.
User has the access permission specified by p iff
W
r2S Matchðp; rÞ ¼ true for a set of attribute assignments S ¼ frg.

In Fig. 2, we show some simple examples of university
information system to describe the above definition. These
examples includes three attribute lattices: Departments,
faculty, and Clearance. For example, there exists the seniority relation among four basic levels of clearance: ðunclassified
 confidential  secret  topsecretÞ. Similarly, there also exists
the relation among three levels of faculty: ðlecture 
assistant prof:  associate prof:  prof:Þ. If the above definition is implemented in ABE, we can define a policy of
“Read” permission as
p :¼ ðfaculty  assistant prof: or clear: 
secretÞ and Depart:  School of Engineering:
Next, given a set of attribute assignments

604

IEEE TRANSACTIONS ON SERVICES COMPUTING,

VOL. 8,

NO. 4,

JULY/AUGUST 2015

Fig. 2. Some examples for attribute lattice in a management information system.

r :¼ ðDepartments; Faculty; ClearanceÞ
ðElectrical Depart:; associate prof:; topsecretÞ;



it is easy to compute the result of matchðp; rÞ. Hence, the
attribute lattice can simplify the access policy, reduce the
computational overheads, and decrease the size of ciphertexts and private-keys in ABE. Note that, the ABE with AH
must have the ability to support full RBAC model with tree,
inverted tree, and general hierarchies on them, as shown
Fig. 2.
In short, ABAC provides a more scalable and flexible
access management based on powerful policy specification.
Moreover, ABAC supports some new features, for example,
dynamically changing attributes, such as time of day and
location, can be accommodated in access control decisions.

2.3 RBAC versus ABAC
In this section we discuss the relationships between
RBAC and ABAC, which will be used to implement the
conversion from RBAC to ABAC below. First of all, it is
easy to find that there exist some similarities between
them. For example, both RBAC and ABAC are able to
map each user to a set of identities (roles or attributes).
When the number of users is far greater than the number
of identities, such a mapping can help simplify authority
management for a large organization. Similarly, both
adopted hierarchical structure (which be used to realize
comparison operators) to further simplify authority management. Although there are these similarities between, it
is obvious to find many differences (see Table 2), which
be summarized as follows:


User’s authority. in RBAC we use a simple binary
relation between users and roles, and in most cases
only one role is assigned in current session; but a set
of attribute assignments included in the attribute





space A1  A2  
 
 
  An is used to express the characteristics of a user in ABAC;
Hierarchical structure. in RBAC all roles are usually
included in a role hierarchy, but in ABAC each attribute has a hierarchical structure. This does not mean
that the expression ability of RH is weaker than that
of AH because we are able to integrate multiple hierarchies into a hierarchy, but these attribute hierarchies are simpler and easier to use and understand
than role hierarchy.
Resource’s constrain specification. in both models they
are stored together with the resources. Given a certain resource, in RBAC they are represented as a
binary relation between roles and permissions, but
in ABAC they are as an access policy on Boolean
function. Obviously, the expression ability of the latter is stronger than that of the former;
Permission criterion. RBAC relies on the following
search of permissions:
[

fp 2 P j9r00 2 R; r00  r : ðp; r00 Þ 2 PAg;

r2rolesðsi Þ

the result of which is a set of permissions authorized
to access the particular resource for the current session. In ABAC it relies on policy matching between
policy function p and attribute assignments S ¼ frg
as follows:

_
true accept
Matchðp; rÞ ¼
false reject:
r2S

Observing the above comparison, it is not difficult to find
that ABAC model has stronger ability to express complex
access policies than RBAC model, moreover RBAC-based
rule can be converted and integrated into ABAC-based policy.

TABLE 2
Comparison between RBAC and ABAC
RBAC
User’s authority
Hierarchical structure
Resource’s constrain specification
Permission criterion

UA: a binary relation between U  R
RH: one role hierarchy
PA: a binary relation between P  R
Relation search between user and permission

ABAC
r: multiple attribute assignments
Hi : multiple attribute hierarchies
p: an access policy function
Match: policy matching between p and r

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

605

Fig. 3. The framework of RBAC-Compatible ABE for secure cloud storage.

Benefited from this kind of conversion, ABAC-based cloud
storage service will provide a more secure, flexible, scalable
way to share data than existing RBAC-based IT systems.

(as an example of line ordering relation) based on CP-ABE
scheme, it is not efficient enough for general partial ordering
relations.

2.4 ABE over ABAC
Attribute-based encryption is a cryptosystem built on
ABAC model [3], [4], [16], [17]. In ABE, attributes are used
to encrypt data, such as key-policy ABE (KP-ABE) [3] or
used as credentials to decrypt data, such as ciphertext-policy ABE (CP-ABE) [17], [18]. We adopt the construction,
proposed by the BSW’s CP-ABE scheme [17], to realize the
logical operations and string matching. In CP-ABE, access
policy function is used to constraint the decryption permission, that is, the decryption is authorized iff Matchðp;
rÞ ¼ true, where the policy function p is hidden into ciphertext and r is assigned to the user’s private key.
In order to realize the policy matching Matchð
Þ, one of
main techniques, cryptographic logical operations, have
been developed in recent years. In CP-ABE, cryptographic
logical operations is implemented by using an extension of
general threshold secret sharing (SS):

3

Definition 3 (Threshold Secret Sharing). Let t; n be positive
integers, t  n, A ðt; nÞ—threshold scheme is a method of
sharing a secret s among a set of n participants, in such a way
that any t participants can compute the value of s, but no
group of t  1 participants can do so.
It is easy to note that AND and OR logics can be realized
by the threshold secret sharing scheme, as follows:
 AND gates. considered as ðn; nÞ-threshold schemes;
 OR gates. considered as ð1; nÞ-threshold schemes.
Therefore, t-of-n AND gates can be constructed as
ðt; nÞ-threshold schemes. The common scheme introduced
by Shamir is based upon Lagrange interpolation, namely, it
takes t points to define a polynomial of degree t  1 and the
secret s is represented as the free coefficient of polynomial.
Further, hierarchical secret sharing is also suitable for Boolean formulas: given a logical hierarchy over AND/OR operations, a logical tree can be constructed to express this
hierarchy and the secret is set as the value of root of this
tree, such that the values of lower nodes can be calculated
recursively by sharing the value of upper nodes in terms of
ðt; nÞ-threshold schemes.
However, there has been little work on studying cryptographic comparison mechanisms to support partial ordering
relations. Even though Bethencourt et al. [17] presented a bitwise comparison method to implement integer comparison

SOLUTION FROM RBAC TO ABAC

In this section we propose a practical solution for moving
the data from RBAC system into ABE-based secure cloud
storage. We first introduce the framework of this solution.
Then we propose an effective method that converts RBAC
rules into ABAC policies. Finally, a RBAC-compatible ABE
is defined to meet the needs of construction of this solution.

3.1 System Framework
In this paper we focus on the solution of migrating and
sharing the data in existing RBAC systems into cloud. We
try to resolve two problems: 1) how to remain access constraints of data on RBAC to implement data sharing in
cloud; and 2) how to ensure the security of data in public
cloud, especially for “honest and curious” cloud [19].
ABAC model is considered as a suitable solution for
secure information sharing in large-scale organizations,
especially for cloud computing environments. However,
facing with a variety of existing enterprise RBAC systems,
re-establishment of such a ABAC system is not realistic.
Therefore, we desire to develop a new “transparent” migration solution that existing RBAC systems are integrated into
the cloud to implement better data sharing. In our solution,
a ABAC-based system is deployed in the cloud, existing
RBAC systems are unified into this cloud ABAC system.
The openness of cloud computing means that more authorized users have quick and easy access to the cloud data
they need. Furthermore, the ABE cryptosystem must be
used for data security in cloud ABAC system. Hence, our
goal is to improve ABE for implementing cloud data
encryption in the existing RBAC systems.
In order to achieve this goal, we expect to provide an
effective method that transforms the RBAC mechanism into
an ABE-based instance. Based on this instance, data can be
encrypted by using ABE and then stored into cloud. In
Fig. 3 we describe the framework of our solution, where
a user can use the existing system with RBAC (such as
Windows, Linux) to access cloud resources. The accessing
process is completely transparent to the user, at the same
time, data can be stored and shared by using ABE encryption. In this figure, an existing RBAC system is connected to
cloud storage service on ABAC model. To migrate RBAC
data to cloud, a new module, called migration proxy, need

606

IEEE TRANSACTIONS ON SERVICES COMPUTING,

to append into RBAC system. The proxy can perform the
following functions: rule conversion between RBAC and
ABAC, encryption/decryption processes, and key management. The process of proxy is described as follows:

3.2 Rule Conversion from RBAC to ABAC
Recall the analysis in Section 2.3, it is easy to find that
ABAC’s expression ability is stronger than that of RBAC.
This means that we might convert access constraints from
RBAC model into ABAC model. Given a RBAC system that
is constructed on standard RBAC model in Definition 1. We
present a simple conversion method based on “one-to-one”
mapping from role to attribute as follows:




Map the set of roles R and its hierarchy RH to a
poset ðA; Þ ¼ ðR; RHÞ, where each roles ri 2 R
becomes the attribute values ai 2 A and A ¼ R. This
mapping is direct and obvious.
Map each permission p 2 P to a policy function p
with Boolean function
p :¼

_

ðr  AÞ:

(1)

9r;ðp;rÞ2PA



Map user’s assignments (for a certain u 2 U) to an
attribute assignment r as
r :¼ A

fr 2 R j ðu; rÞ 2 UAg:

(2)

However, this conversion does not show the advantage
of ABAC model. In the respect of granularity, the role in
RBAC (coarse grain) can be considered as “multi-attribute”
composite. For example, “School Leader of Business (SLB)”
in RBAC is able to denote the composite of two attributes:
“School of Business” and “Leader”. Therefore, the abovementioned conversion can be performed in a more flexible
way. So, we present a more effective multi-attribute

NO. 4,

JULY/AUGUST 2015

conversion method based on “one-to-many” mapping from
role to attribute as follows:




When a “create” requestor asks to store a new data to
cloud, the proxy converts the role of roles corresponding to permission p1 ¼ “write”, p2 ¼ “create”,
and p3 ¼ “read” into policy functions fp1 ; p2 ; p3 g
according to Section 3.2; and then, the proxy obtains
the ABE keys escrowed by key management unit,
and uses the keys and fp1 ; p2 ; p3 g to encrypt the data
as ABE-ciphertext; finally, the ciphertext and its policy fp1 ; p2 ; p3 g is sent to the cloud.
 When a “write” requestor asks to write the existing
data to cloud, the proxy does not need to rewrite the
policy function fp1 ; p2 ; p3 g, but re-encrypts the modificated parts into the cloud.
 When a “read” requestor asks to read data stored in
the cloud, the proxy first downloads the policy function p3 corresponding to permission “read” and performs the access authorization decision (see Section
3.2); if it permits, the proxy obtains the ABE keys
escrowed by key management unit, and then downloads and decrypts the data.
We will highlight the rule conversion from RBAC to
ABAC, as well as RBAC-compatible ABE system below.

VOL. 8,



The role set R is divided into n groups of set of
attributes, that is, R ¼ A1  A2  
 
 
  An . For each
Ai , we build a hierarchy ðAi ; Þ.
Map each permission p 2 P to a policy function p,
but Equation (1) also need to become
!
^
_
ðai  Ai Þ :
p :¼
8r¼ða1 ;...;an Þ;ðp;rÞ2PA



ai 2r

Similarly, Equation (2) becomes
r :¼ ðA1 ; . . . ; An Þ

fða1 ; . . . ; an Þj

¼ ða1 ; . . . ; an Þ 2 R : ðu; rÞ 2 UAg:
We define the partial ordering relation on the Cartesian
product of ordered sets as follows: ða1 ; . . . ; an Þ  ða01 ; . . . ; a0n Þ
if and only if a1  a01 ^ 
 
 
 ^ an  a0n . This is a partial order.
Next, we describe the process of accessing cloud resources. If the user wishes to access the data in the cloud, the
system first obtains the access policy of the resource, then
calculates rolesðsÞ to get the set of authorized roles, where
rolesðsÞ  fr 2 R j 9r0 2 R; r  r0 : ðuserðsÞ; r0 Þ 2 UAg. Using
the set of authorized roles, the system can check whether
there is an effective subset of roles in rolesðsÞ which meets
the above access policy, that is, Matchðp; rÞ ¼ true. If the
subset exists, the system downloads the data and decrypts
it locally.
We give a simple approach to implement “Access Authorization Decision”, which adopts the roles in RBAC to verify
the ABAC policy function p. In the case of simple “one-toone” conversion, the verification can be checked by using

_
true accept
Matchðp; ðA
aÞÞ ¼
false reject;
a¼r;r2rolesðsÞ

W
where p :¼ 9r00 ;ðp;r00 Þ2PA ðr00  RÞ. This means that there
exists at least one r 2 rolesðsÞ and r00 2 R for r00  r to make
ðp; r00 Þ 2 PA if the above verificaiton is accepted. This is consistent
of permissions in RBAC, that
S with the statement
00
fp
2
P
j
9r
2
R;
r00  r : ðp; r00 Þ 2 PAg. Furtheris,
r2rolesðsÞ
more, in the case of “multi-attribute” composite, the above
equation turns into
_
Matchðp; ðA1 ; . . . ; An Þ
ða1 ; . . . ; an ÞÞ
8r¼ða1 ;...;an Þ;
rrolesðsÞ


¼

true accept
false reject:

Similarly, it is obvious that this conversion is also consistent
with the statement of permissions RBAC. In short, the
above-mentioned conversions will be used to construct our
RBAC-compatible ABE system.
In practical applications, we highlight two extra attentions: 1) we must clearly understand the relationship among
roles and role hierarchy in RBAC system because we found
that the definition of role hierarchy is not clear in some
existing RBAC systems; and 2) In the multi-attribute

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

607

The proxy writes these two policies ðpwrite ; pread Þ into
the header of Doc1 and uses pread :¼ ðSB  AÞ encrypts the
file by using the Encrypt algorithm in ABE. Finally, the
encrypted file Doc1 is migrated into the cloud.
When the user Vincent expects to access this file by using
the Migration proxy, the proxy first obtains the session s (by
using command in the operation system) from RBAC system, and then invokes the function usersðsÞ ! ðVincentÞ to
get the user’s name (see Equation (3)). Based on it, the proxy
computes all possible roles by using the following function:
rolesðsÞ  fr 2 R j 9r0 2 R; r  r0 : ðuserðsi Þ; r0 Þ 2 UAg
Fig. 4. Attribute lattice used in our example.

conversion, we emphasize that the mapping from roles
to attributes must be strictly satisfy the partial ordering
relation on the Cartesian product of ordered sets. It is also
a good alternative for “one-to-one” mapping from role to
attribute if the above-mentioned attentions are not met.

3.3 An Example of Our Solution
We assume we have a simple RBAC-based University system, in which the set of roles R and role hierarchy RH are
showed in Fig. 4 (it is the same as the Department in Fig. 2).
We assume that there exist two users Vincent and Crown
in this system, that is, U :¼ ðVincent; CrownÞ. Moreover, we
assume that Vincent works at EconomicsDepartment (EcD)
and Crown is a SchoolLeaderofBusiness, namely,
UA :¼ ððVincent; EcDÞ; ðCrown; SLBÞÞ;

(3)

where EcD and SLB are two acronyms for name of department. According to Equation (1) in our convention method,
the system manager designates the attribute assignments
rVincent :¼ A
rCrown :¼ A

fr 2 R j ðVincent; rÞ 2 UAg ¼ A
fr 2 R j ðCrown; rÞ 2 UAg ¼ A

EcD;
SLB

into the ABE’s private key of Vincent and Crown,
respectively.
Next, we assume that a document (called Doc1 ) in this
system has the Read and Write permissions, P :¼ ðRead;
WriteÞ, and the permission-to-role assignment is
PA :¼ ððRead; SBÞ; ðWrite; SLBÞÞ;

(4)

where SB and SLB denotes SchoolofBusiness and
SchoolLeaderofBusiness. According to Equation (2) in our
convention method, the migration proxy can generate two
policy functions
_
ðr  AÞ
pwrite :¼
9r;ðWrite;rÞ2PA

_

¼

ðSLB  AÞ ¼ ðSLB  AÞ

9SLB;ðWrite;SLBÞ2PA

pread :¼

_

ðr  AÞ

9r;ðRead;rÞ2PA

¼

_

9SB;ðRead;SBÞ2PA

ðSB  AÞ ¼ ðSB  AÞ:

¼ fr 2 R j 9r0 2 R; r  r0 : ðVincent; r0 Þ 2 UAg
¼ fr 2 R j r  EcD : ðVincent; EcDÞ 2 UAg
¼ fEcD; SB; Ung:
Next, the proxy downloads the permission assignment PA
of Doc1 from the cloud and checks the permission:
[r2rolesðsÞ fp 2 P j 9r00 2 R; r00  r : ðp; r00 Þ 2 PAg
¼ [r2fEcD;SB;Ung fp 2 P j 9r00 2 R; r00  r : ðp; r00 Þ 2 PAg
¼ fp 2 P j 9r00 2 R; r00  EcD : ðp; r00 Þ 2 PAg
[ fp 2 P j 9r00 2 R; r00  SB : ðp; r00 Þ 2 PAg
[ fp 2 P j 9r00 2 R; r00  Un : ðp; r00 Þ 2 PAg
¼ fRead 2 P j 9SB 2 R; SB  EcD : ðRead; SBÞ 2 PAg
[ fRead 2 P j 9SB 2 R; SB  SB : ðRead; SBÞ 2 PAg
¼ fReadg:
Hence, the proxy allows to download the encrypted file
Doc1 with an encryption policy pread :¼ ðSB  AÞ for
Vincent. Vincent is able to decrypt this file by using his priEcD
vate key with attribute assignment rVincent ¼ A
because the policy matching between the ciphertext’s policy
function and the user’s attribute assignment,
Matchðpread ; rVincent Þ
¼ MatchðSB  A; A

EcDÞ ¼ true

is satisfied in terms of the relation SB  EcD in RH.
The “write” (or “create”) operation also executes the similar process as above besides the process of file encrypting
and migrating to cloud is accomplished by the migration
proxy. In this process, the proxy only needs to verify the
matching between the file’s policy and the user’s attribute
assignment. For example, the user Crown tries to write the
file Doc1 , the proxy invokes userðsÞ ! ðCrownÞ and rolesðsÞ
 fr 2 R j r  SLB : ðCrown; SLBÞ 2 UAg ¼ fSLB; EcD;
AcD; SB; Ung.
is comS Based on these values, the permission
00
00
puted as
r2fSLB;EcD;AcD;SB;Ung fp 2 P j 9r 2 R; r  r : ðp;
r00 Þ 2 PAg ¼ fRead; Writeg in terms of the policy PA in
Equation (4). Hence, Crown have the authority to write the
document Doc1 , and the proxy re-encrypts the modification
parts submitted by Crown into cloud by using the escrowed
ABE encryption key.
We have the ability to achieve multi-attribute conversion
at the same process as above if the roles are “one-to-many”
mapped to several different set of attributes. This kind
conversion is very intuitive and can help to simplify the
role hierarchy.

608

IEEE TRANSACTIONS ON SERVICES COMPUTING,

It is obvious that our conversion methods are complete
and sound from the above examples, only if ABE can support partial ordering relation over one or more attribute
sets, as well as the matching operation Matchðp; rÞ in
decryption. However, the existing schemes do not support
this relation. For this purpose, we will put forward such an
effective ABE construction in next section.

4

RBAC-COMPATIBLE ABE

In the previous section, the attribute hierarchy (partial
ordering relation on ðA; Þ) have been introduced to RBACCompatible ABE. This means that comparison operation 
on attribute hierarchies would be executed in the ABE.
However, existing ABE schemes do not support comparison
operation on attribute hierarchies at present.1 In light of
the fact that the comparison operation can enhance the
capacity of constraint expressions, decrease the computational overheads of encryption and decryption, and reduce
the size of ciphertexts and private-keys, in this section we
design an efficient cryptographic comparison operations for
arbitrary partial orders to support the expressions of attribute lattices in ABE.

4.1 ABE with Attribute Hierarchies
An attribute-based encryption with attribute lattice (ABEAH) consists of the following five algorithms:
Setup(A; S). Takes in the parameters of cryptosystem S and
the attribute universe description A. It outputs a master
key msk, the public parameter pp and a encryption-key
ek;
GenKey(msk; r). Takes in the manager key msk and a user’s
attribute assignments r for a certain user. It outputs a
user’s private-key usk.
Encrypt (ek; p; M). Takes in the encryption key ek, the access
policy p over A, and the plaintext M 2 f0; 1g
 . It outputs a ciphertext C such that only users whose private
keys satisfy the access policy p are able to exact M.
Decrypt (pp; usk; C). Takes in the public parameters pp, a
ciphertext C and a private key usk. If the set of attributes of usk satisfies the access policy of the ciphertext, it
outputs the plaintext M.
In this framework, the scheme must obey this rule as
follows: Given the above-mentioned ðr; pÞ, we can compute
ðmsk; pp; ekÞ
SetupðA; SÞ and gsk
GenKeyðmsk; rÞ.
Such that, we hold
2
3
Decryptðpp; usk; CÞ ¼ Mj
Pr4 C
Encryptðek; p; MÞ; 5 ¼ 1;
Matchðp; rÞ ¼ true
if and only if the access is granted over hp; ri according to
the policy matching criterion.

4.2 Security Definition of ABE-AH
To analyze the security of ABE-AH scheme, we first consider a new kind of security, called indistinguishability
1. Note that this kind of hierarchy on posets is different from that on
the hierarchy IBE (HIBE) schemes because the latter only supports a
tree structure.

VOL. 8,

NO. 4,

JULY/AUGUST 2015

against chosen plaintext attacks with adaptive attribute lattice (IND-AH-CPA), which can be transformed into the
security against chosen ciphertext attacks (IND-CCA) by
applying a random oracle technique based on Fujisaki-Okamoto transformation. In this kind of security, we consider
that the adversary can query arbitrary partial ordering relations (attribute hierarchies) to construct a key hierarchy.
Given an ABE-AH scheme ES, the IND-AH-CPA security is
evaluated by the following game:
Setup. The challenger B runs Setup algorithm, gives the
adversary A the public parameters pp, and keeps the
master key msk and the encryption key ek secret;
Query. The adversary A gives the challenger B an attribute
identity-poset pair ðAi ; Hi Þ, where Hi ¼ hVi ; i is an
arbitrary partial ordering relation. The challenger B
assist A to construct the cooperatively attribute lattice.
After all queries are realized, the adversary can require
the challenger B to generate a valid ciphertext for an
arbitrary policy p and message M.
Challenge. The adversary A submits two equal length messages M0 and M1 . In addition, the adversary gives a
challenge policy p in terms of A. The challenger B flips
a random coin b 2 f0; 1g, and encrypts Mb under a policy p. The correspondent ciphertext Cb is given to the
adversary A.
Guess. The adversary outputs a guess b0 2 f0; 1g of b.
In this game, the advantage of the adversary A attacking
INDALCPA
ðAÞ ¼
the ABE-AH scheme is defined as AdvES


1
0
0
Pr½b0 ¼ b  1; where the probaj
Pr½b
¼
b

Pr½b
¼
6
b
j
¼
2
2
bility is taken over the random coins of A and all probabilistic algorithms in the scheme.
Definition 4. A ciphertext-policy attribute-based encryption with
attribute lattice scheme is ðt; "Þ-adaptive attribute lattice
against chosen plaintext attacks (IND-AH-CPA), if for any
polynomial time adversary with time-complexity t, there is at
most a negligible advantage " in the above game.

5

CRYPTOGRAPHIC PARTIAL ORDERING
RELATIONS

In this section, we propose a novel construction for integer
comparison to overcome the limitations of BSW’s CP-ABE
scheme. We first give the background on compositing order
bilinear groups. Then, we present two key constructions:
forward and backward derivation functions. Finally,
we present the construction of our ABE scheme based on
those techniques.

5.1 Our Approach
From the discussions above, an efficient secure comparison
mechanism is needed to express complex access policy and
realize attribute hierarchy. This motivates us to investigate
a new approach for partial ordering relation, which can be
used to construct encryption schemes based on various
comparison relations. In the following, we present our idea
of a new approach for cryptographic comparison built on
the mathematical principles of comparison relation.
In mathematics, the comparison relation on a partially
ordered set (or poset) is a binary relation denoted by infix ,

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

609

property. This process can be expressed to build two functions: Mapping function cð
Þ converts a partial ordering set
to a new set of random numbers; and Ordering function fð
Þ
sets up a new ordering relation in the new set of random
numbers. Typically, the mapping function is confidential,
but the ordering function is publicly verifiable. So, we redefine these two functions with private/public key, as
follows:
Fig. 5. The order preserving mapping for general poset.

e.g.,  ða; bÞ or a  b, where a binary relation on a set H is a
collection of ordered pairs of elements in H. Strictly speaking, the comparison on integer is a total order or a linear
order which is a binary relation with the following properties: for any a; b 2 U, we have
 Reflexivity. a  a;
 Antisymmetric. If a  b and b  a then a ¼ b;
 Transitivity. If a  b and b  c then a  c.
For a and b are two elements of a partially ordered set H,
if a  b or b  a, then a and b are comparable. Otherwise
they are incomparable, denoted by ajjb.
Our objective is to develop an effective method for cryptographic comparison relation. That is, let H ¼ fa1 ;
a2 ; . . . ; am g be a countable set with partial ordering, we
expect to define a set of cryptographic random numbers
V ¼ fv1 ; v2 ; . . . ; vm g in a large space F, which can preserve
the order of elements in H. To do so, we can make use of a
cryptographic map c : H ! V to convert H to V: 2 It is obvious that c must be an order-preserving mapping such that if
ai  aj in H, it implies there exists a partial-order relation 
to ensure vi  vj in V , where vi ¼ cðai Þ and vj ¼ cðaj Þ. In
Fig. 5, we describe this kind of order preserving mapping c
from U to V , where  is used to represent the order relation
between vi and vj . Here, vi  vj does not means the value of
vj is greater than that of vi .
In order to ensure the security of cryptosystem, V ¼
fv1 ; v2 ; . . . ; vm g is required to be a set of random values.
Here it comes the question: how to define the partial ordering
relation  over a set of random values in a secure manner? By
“secure”, we mean if ai  aj , then it is easy to verify the
relation vi  vj ; otherwise, vi  vj is not provable.
To answer this question, we turn our attention to use
cryptographic “one-way” property to represent the partial
ordering relation in set V . The one-way property means
that given the integer relation ai  aj and two corresponding value vi ; vj , there exists an efficient algorithm
fð
Þ to obtain vj from vi , but it is hard to compute vi from
vj . So we have
ai  aj , Pr½fðvi Þ ¼ vj  ¼ 1;
where, , denotes the equivalence relation. In fact, this
means that the decision problem of ai  aj converted into
computing function problem of vj ¼ fðvi Þ.
In summary, our idea for cryptographic comparison relation on hH; i is to create a mapping from a partial ordering
set to a new set of random numbers, and then define a new
ordering relation on the new set based on “one-way”



Mapping function c : SK  H 7! V , which converts a
poset H into V , where SK is a set of private keys.
 Ordering function f : PK  V 7! V , which can publicly compute the value of other element in V from a
element, only if these two elements satisfies ordering
relation, where PK is a set of public parameters.
We illustrate this process and the two functions in Fig. 6.
Note that, the randomness property of elements in V is necessary to ensure the security of comparison relation, in particular, to prevent forgery.
A related technique called order-preserving encryption
(OPE) was introduced in database community by Agrawal
et al. [20]. We say that the encryption scheme ðK; E; DÞ is an
OPE scheme if E K ð
Þ is an order-preserving function in integer. That is, E K ðiÞ > E K ðjÞ iff i > j. Note that, the comparison
operation > between two ciphertexts is straightforward
numerical comparison, which is a tough hypothesis for
designing an OPE scheme. Such that, as far as we know, “the
first formal cryptographic treatment of OPE did not appear
until recently” [21]. Moreover, the OPE scheme is not suitable for general partially ordered relation because the
numerical comparison just meet the totally ordered relation.
Hence, our proposed approach cannot be replaced by OPE.

5.2 Hierarchial Hash Functions
As the above-mentioned approach, we give the cryptographic definitions of order-preserving mapping, called
hierarchical hash function (HHF, represented as fpk; ð
Þ) in
this section. Such a function implement the comparison
operation  on a poset ðH; Þ.
At first, we setup the  relation over V by using a random mapping function. Given a cryptographic map c :
SK  H ! V , where V ¼ fv1 ; v2 ; . . . ; vm g is a set of cryptographic values and vi ¼ csk ðai Þ for all i 2 ½1; m and ai is
any attribute string in f0; 1g
 . We require that vi is random
and hard-to-guess if sk is unknown.
Next, it is obvious that csk ð
Þ must be an order-preserving mapping, that is a map such that if ai  aj in H implies
there exists a partial-order relation  to ensure vi  vj in V .
Therefore, in order to setup this kind of relation over V , we
consider the partial-order relation in V as the “one-way”
property in cryptography. Therefore, we provide a definition of hierarchy hash function that is used to construct public ordering function, as follows:
Definition 5 (Hierarchial Hash Function). Given a function
f : PK  V ! V based on a set ðH; Þ, it is called a forward
derivation function if it satisfies the conditions:


2. In fact, V is a small subset of set of cryptographic values.

Easy to compute. The function fð
Þ can be computed in
fpk;ai aj ðvi Þ;
a polynomial-time, if ai  aj , i.e., vj

610

IEEE TRANSACTIONS ON SERVICES COMPUTING,

VOL. 8,

NO. 4,

JULY/AUGUST 2015

Fig. 6. Our solution for cryptographic comparison relation.




Pre-image resistance. It is infeasible for any probabilistic polynomial time (PPT) algorithm to compute vj
from vi if aj  ai .
Second pre-image resistance. Given an input vi 2 V , it
is infeasible for any PPT algorithm to find vj 2 V ,
ai jjaj and fpk;ai ak ðvi Þ ¼ fpk;aj ak ðvj Þ.

The above definition follows the definition of general
hash function, but from a viewpoint of practical use, we
did not require collision resistance, that is, it is infeasible
for any PPT algorithm to find two elements vi and vj 2 V
and fpk;ai ak ðvi Þ ¼ fpk;ai ak ðvj Þ. In addition, the transitivity
property can be satisfied because fpk;ai ak ðvi Þ ¼ fpk;aj ak
ðfpk;ai aj ðvi ÞÞ.
We show a simple example to explain HHF in Fig. 7.
This example assume that we have a poset H ¼ ðA; Þ,
where A ¼ fa1 ; a2 ; . . . ; a7 g. Given v7 , the HHF ensures
that the value of v3 ; v4 ; v1 can be obtained by using
fpk; ðv7 Þ. Inversely, given v3 , it is hard to guess v6 and v7
according to pre-image resistance property. As the same
reason, v4 cannot be guessed because v4 jjv3 . More importantly, in the hierarchy it is easy to find the collision of
HHF. For example, v1 ¼ fpk;v3 v1 ðv3 Þ ¼ fpk;v4 v1 ðv4 Þ, however, it is still hard to guess v4 from v3 according to
second pre-image resistance property. These security
properties should be used to guarantee the security of
our ABE scheme.

5.3 Cryptographic Construction of HHF
In this section, we will present a cryptography construction
of HHF, which will be used in our ABE scheme. This construction is built on a general multiplicative group G. In
addition, we make use of a hash function H : f0; 1g
 7! G,
which can map any string into a random element in G.
First, given a attribute hierarchy with a poset ðAi ; Þ and
Ai ¼ ðai1 ; . . . ; aimi Þ, we assume that Ai and all aij can be represented as f0; 1g
 . Let wi0 ¼ HðAi Þ and wij ¼ HðAi jjaij Þ.
Next, we pick a random integer r 2 G as the private key
sk ¼ r. We define that wi0 ¼ wri0 ¼ HðAi Þr and wij ¼ wrij ¼

Fig. 7. An example of hierarchy hash function.

HðAi jjaij Þr for all aij 2 Ai . And then, we define the random
mapping function csk ð
Þ as follows:
Y
vij
csk ðai;j Þ ¼ vrij ¼ wi0 

wik
r

¼ HðAi Þ 


Y

aij 6aik

HðAi jjaij Þr

2 G;

aij 6ak

Q
where vij ¼ wi0 
 aij 6aik wik . Note that, everyone can compute HðAi Þ and HðAi jjaij Þ, but vi;j cannot be computed if
the secret r is unknown. So we build the public parameter
(or the part of ciphertext) as
pk ¼ ðG; Hð
Þ; fwik g8aik ;aij aik Þ:
Finally, we define the HHF fpk ð
Þ as
Y
vik
fpk;aij aik ðvij Þ ¼ vij 

0
¼ @wi0 


Y

1

¼ wi0 


Y

Y

wil A 


aij 6ail

wil

ail 2Gðaik ;aij Þ

wil

[aik 6ail fail gn[aij 6ail fail g

wil ¼ vik

2 G;

aik 6ail

where Gðaik ; aij Þ denotes [aik 6ail fail g n [aij 6ail fail g and
ail 2 Gðaik ; aij Þ  f8ail ; aij  ail g. For example, let see the
example of Fig. 7. In this example we list all elements of vi
according to partial ordering relation in Table 3. It is easy to
find that [aik 6ail fail g  [aij 6ail fail g if aik  aij . Hence, vij
can be computed according to such a containment relationship. For example, given v5 and w1 ; w2 ; w4 ; w5 , we can compute its seniors v1 ; v2 ; v4 , that is, v4 ¼ v5 
 w5 , v1 ¼ v4 
 w2 
 w4 ,
and v2 ¼ v4 
 w1 
 w4 .
In this construction it is intractable to obtain vik from vij for
aik  aij because [aik 6ail fail g  [aij 6ail fail g, aik 2 [aij 6ail
TABLE 3
Examples for HHF Construction
vi

[ai 6aj wj

[ai aj wj

v1
v2
v3
v4
v5
v6
v7

w2 ; w3 ; w4 ; w5 ; w6 ; w7
w1 ; w3 ; w4 ; w5 ; w6 ; w7
w2 ; w4 ; w5 ; w6 ; w7
w3 ; w5 ; w6 ; w7
w3 ; w6 ; w7
w2 ; w4 ; w5 ; w7
w5 ; w6

w1
w2
w1 ; w3
w1 ; w2 ; w4
w1 ; w2 ; w4 ; w5
w1 ; w3 ; w6
w1 ; w2 ; w3 ; w4 ; w7

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

611

Fig. 8. Our construction of ABE-AH scheme.

fail g, and aik 62 [aik 6ail fail g. This means that vik can be
obtained unless vij =wik is computed. So, vik cannot not be
computed because wik is not in pk. For example, it is
hard to compute v6 ¼ v3 =w6 from v3 and w1 ; w3 because
w6 is unknown for a6  a3 . Also, v4 ¼ v3 =w4 cannot be
computed from v3 and w1 ; w3 because w4 is unknown
for a4 jja3 . This ensures pre-image resistance and second
pre-image resistance.

6

CONSTRUCTION OF ABE-AH

In this section we propose a novel construction with attribute hierarchies based on BSW’s CP-ABE scheme. This
construction enjoys the lower computation and communication/storage costs. Moreover, we can generate a private key
with range controls, and then can implement comparisons
between two range controls from ciphertext and private
key, respectively.
We set up our systems using bilinear pairings proposed
by Boneh and Franklin [22]. Let G1 , G2 and GT be three
cyclic groups of large prime order p using pairing-friendly
curves, and e be a computable bilinear map e : G1 
G2 ! GT 3 with the following properties. For any G 2 G1 ,
H 2 G2 and all a; b 2 Zp , we have
1) Bilinearity. eðGa ; H b Þ ¼ eðG; HÞab .
2) Non-degeneracy. eðG; HÞ 6¼ 1 unless G or H ¼ 1.
3) Computability. eðG; HÞ is efficiently computable.
Where, ½aP denotes the multiplication of a point P in
elliptic curve by a scalar a 2 Zp . A bilinear map group
3. We require that no efficient isomorphism G2 ! G1 or G1 ! G2 is
known, or G2 ! G1 is unknown but its inverted G1 ! G2 is known.

system S is a tuple S ¼ hp; G1 ; G2 ; GT ; ei composed of the
objects as described above. S may also include group generators in its description. In addition, there is a hash function
H : f0; 1g
 ! G.
Our ABE-AH scheme is described in Fig. 8. Our scheme
is constructed on BSW’s CP-ABE scheme, which makes use
of the hierarchy secret sharing scheme (HSSS) to realize
AND and OR operations for a access policy which be represented by Boolean function. In the description of our
scheme, we omit these details. Our ABE-AH scheme has an
optimum performance of storage and computation. For
example, the length of the user’s private key usk is directly
proportional to the number of attributes in AðiÞ , that is,
Oð#AðiÞ Þ, where # denotes the number of elements in a set.
Similarly, the length of ciphertexts is directly proportional
to the number of literals in an access tree T corresponding
to p, that is, Oð#T Þ. More importantly, the length of ciphertexts is unrelated to the size of candidate attribute values
for a certain policy, by which we usually measure the length
of a ciphertext in the trivial equal matching way. Therefore,
the shorter ciphertext commonly means the lower overheads of computation, so that the ABE-AH scheme also
involves low computational overhead in the process of
encryption and decryption.
Next, we prove that if the decryptor’s attribute values
satisfy the policy p, and the decryptor can obtain the correct
message M from a ciphertext C using our ABE-AH scheme.
The analysis process is listed as follows:
First, if a decryptor’s attribute value aij satisfies the literal
aik  Aj in the ciphertext (that is aik  aij ), the decryptor
s
computes fE00 ;aik aij ðviki Þ since the value vsiji ¼ fE00 ;aik aij ðvsiki Þ ¼
i

i

612

IEEE TRANSACTIONS ON SERVICES COMPUTING,

vsiki 


Q
ail 2Gðaij ;aik Þ

wsili ¼ wsi0i 

Ei00

Q
aij 6ail

wsili 2 G can be efficiently

s
fwili gaik ail

¼
and ail 2 Gðaij ; aik Þ 
computed from
f8ail ; aik  ail g if the condition aik  aij holds.
s
s
Second, given the correct value viji ¼ fE00 ;aik aij ðviki Þ, we
i
can computes the value Sj in terms of Equation (5) as follows:
eðgt 
 viji ; hsi Þ
eðDi ; Ei Þ
 s 


Si ¼  0
¼
e Di ; fE00 ;aik aij ðEi0 Þ
e hri ; fE00 ;aik aij viki
r

i

VOL. 8,

NO. 4,

JULY/AUGUST 2015

a; b 2 Zp , it is computationally intractable to compute the
value gab 2 G. More exactly, we define a game to measure
the difficulty of computing csk ðaj Þ from csk ðai Þ for aj  ai .
That is, for any t-time PPT algorithm A and a negligible ", if
2

3
8H; H 2 pk; vi
csk ðai Þ;
Ahð
Þ ðpk; vi Þ;
ða
j ; v
j Þ
Pr4
: a
j  ai 5  ":



9aj 2R V; aj ¼ aj ^ cpk ðaj Þ ¼ vj

i

eðgt 
 viji ; hsi Þ
¼  r si  ¼ eðg; hÞt
si :
e h i ; vij
r

Finally, according to the aggregate algorithm in [17], the
decryptor can obtain S ¼ eðg; hÞts only if the decryptor’s
attribute set is matching the policy tree T ; otherwise, the
decryptor cannot get S. When the decryptor gets S, she can
compute the correct message M in terms of the equation
M 0 ¼ C1 
 S=eðD; C2 Þ ¼

M 
 eðg; hÞas 
 eðg; hÞts
¼ M:

 aþt
e g b ; hbs

Combining these two conditions, we know that if the
decryptor can get the message M if and only if the
decryptor’s attribute set is matching the policy tree T and
the decryptor’s attribute values follow the comparison constraints in the access policy p. Hence, if the decryptor can
get the message M if and only if the decryptor’s attribute
sets satisfy the access policy of the attribute lattices.

7

SECURITY ANALYSIS

7.1 Security Analysis of HHF
First, before proving the security of our HHF construction,
we consider the security of the random values obtained
from HðAjjai Þ in HHF for all ai 2 A. Usually, we call collision if two group of random values are equal,
i.e., for any
Q
two different subsets W1 and W2 of A, al 2W1 HðAjjal Þ ¼
Q
al 2W2 HðAjjal Þ. Due to the reason that all vi must be chosen
at random, this scheme do not permit the collision among
the vi (or vi 6¼ vj ) for i 6¼ j. The following theorem tells us
that this collision probability is negligible only if the security parameter k is large enough. Moreover, the fast sort
algorithm can help us to find the collision.
Theorem 1. The collision probability of getting any sum among
m random integers, which are chosen in Z
p from a uniform dis2

tribution, is less than ðmþ1Þ
4p , where p is a large prime number.
Since the total number of roles is far less than the size of
space of keys, this theorem means that the collision probability is neglectable for a large number of attributes m, e.g.,
given m ¼ 1; 000 and m  p  2160 , the collision probability
20
is less than 22162 ¼ 2142 . This means that the security of HHF
is not related to the combination of the attributes.
Next, we prove that our HHF is secure with pre-image
resistance under the Computational Diffie-Hellman (CDH)
assumption: consider a cyclic group G of order p and a randomly chosen generator g, given ðga ; gb Þ for two random

We call that this problem is hard to resist the pre-image
attack of HHF. Hence, we have the following theorem.
Theorem 2. Assuming that the CDH assumption holds, any
probabilistic polynomial-time PPT algorithm is hard to break
the pre-image resistance property.
Proof. Assume that there exists a PPT adversary A to compute v
j from ðpk; vi Þ for ai 6 aj with a non-negligible
probability. By using A, we construct an algorithm B to
solve the computational DH problem as follows:
1)

2)

given ai , let sk ¼ a and set B sets vi ¼ ðga Þr and
fwk ¼ ðga Þrk g8ak ;ai ak , where r and rk are some
random integers.
for a hash query HðAjjal Þ in al 2 Gðai ; aj Þ, the ranb kl
dom Oracle returns HðAjja
P l Þ ¼ ðg Þ for al 6¼ aj ,
kl

3)

and HðAjjaj Þ ¼ gr =ðgb Þ al 2Gðai ;aj Þ , where kl is a
random integer in Zp .

we revoke Aðpk; vi ; fwk g8akP
;ai ak Þ. If A returns vj ,
1=

kl

al 2Gðai ;aj Þ
B outputs gab ¼ ððga Þr =v
j Þ
.
According
to
the
definition
of
v
,
we
have
vi ¼ vj 

i
Q
Q
ð al 2Gðai ;aj Þ wl Þ ¼ vj 
 w0ij ¼ gar , where w0ij ¼ al 2Gðai ;aj Þ wl .

Also, in terms of the definition of P
random Oracle, we
Q
kl
have w00ij ¼ al 2Gðai ;aj Þ HðAjjal Þ ¼ ðgb Þ al 2Gðai ;aj Þ . Further,
P

since sk ¼ a, this means that w0ij ¼ w00ij a ¼ ðgab Þ
P

k
al 2Gðai ;aj Þ l

.

kl

ab
al 2Gðai ;aj Þ
¼ gar and gab ¼
Therefore,
P we have vi ¼ vj 
 ðg ÞP
1=
k
1=
k
al 2Gðai ;aj Þ l
al 2Gðai ;aj Þ l
ðw0ij Þ
¼ ððga Þr =v
j Þ
. This contradicts to the CDH assumption, thus the theorem holds.
u
t

Finally, we prove that our HHF is secure with second
pre-image resistance under the CDH assumption. we also
define a game to measure the difficulty of computing
csk ðaj Þ from csk ðai Þ for aj jjai and fpk;ai ak ðvi Þ ¼ fpk;aj ak ðvj Þ.
That is, for any t-time PPT algorithm A and a negligible ", if
2

3
csk ðai Þ;
8H; H 2 pk; vi
hð
Þ


6
7
A ðpk; vi Þ;
ðaj ; vj Þ

7
Pr6
4 9aj ; ak 2R V; a
j ¼ aj ^ cpk ða
j Þ ¼ v
j ; : aj jjai 5  ":
fpk;ai ak ðvi Þ ¼ fpk;a
j ak ðv
j Þ
We call that this problem is hard to resist the second preimage attack of HHF. Hence, we have the following
theorem.
Theorem 3. Assuming that the CDH assumption holds, any
probabilistic polynomial-time PPT algorithm is hard to break
the second pre-image resistance property.

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

Proof. Assume that there exists a PPT adversary A to compute vj from ðpk; vi Þ for ai jjaj and fpk;ai ak ðvi Þ ¼ fpk;aj ak ðvj Þ
with a non-negligible probability. By using A, we build
an algorithm B0 to solve the CDH problem as follows:
1)

2)

given ai ; ak 2 H, let sk ¼ a, B0 sets vi ¼ ðga Þr and
fwl ¼ ðga Þrk g8ak ;ai al , where r and rk are some random integers, and vk ¼ fpk;ai ak ðvi Þ.
for a hash query HðAÞ and HðAjjal Þ in al 6¼ aj , the
random Oracle returns HðAÞ ¼ ðgbP
Þk0 and HðAjj
P

kl

k0 þ

ai 6al ;al 6¼aj
al Þ ¼ ðgb Þkl , but HðAjjaj Þ ¼ gr =ðgb Þ
,
where kl is a random integer in Zp .
3) we revoke Aðpk; vi ; fwk g8ak ;ai ak Þ. If A returns
v
j for ai jjaj and aj  ak , B outputs gab ¼
P
1=ðk0 þ
kÞ
aj 6al Þ l
.
ðv
j Þ
According to the definition of vi and ai jjaj , we have

0

0

vi ¼ @HðAÞ 
 @

Y

11a
HðAjjal ÞAA

ai 6al

0
b k0 þ

¼ @ðg Þ

1a

P

k
ai 6al ;al 6¼aj l




k0 þ

ðgb Þ
¼ gar ;

gr
P

k
ai 6al ;al 6¼aj l

A

P

P
kl
k0 þ
ai 6al ;al 6¼aj
where HðAjjaj Þ ¼ g =ðg Þ
. Also, in terms
a,
we
have vj ¼ ðH
of the definition of vj and sk ¼
P
Q
a
b k0 þ ai 6al kl a
ðAÞ 
 ð aj 6al HðAjjal ÞÞÞ ¼ ððg Þ
Þ . This means
P
k þ
k
ai 6al l . Therefore, if A returns v
 , we
that vj ¼ ðgab Þ 0
j
P
kÞ
ab

 1=ðk0 þ
aj 6al Þ l
. This contradicts to compuhave g ¼ ðvj Þ
tational CDH assumption, thus the theorem holds.
u
t
r

b

In summary, two above-mentioned cases means that it is
hard to compute the values of all elements fvj g8aj ;ai 6aj for a
given vi because we have the partial ordering ai 6
aj ¼ ðaj  ri Þ _ ðai jjaj Þ. Therefore, our construction of HHF
is a secure hierarchial hash functions.

7.2 Security Analysis of ABE-AH Scheme
The analysis of HHF has showed the security of partial
ordering relation in our ABE scheme. Now, we focus on the
security of ciphertexts in this scheme. Since semantic security is a widely used definition for security in an asymmetric
key encryption algorithm, we will also prove the semantic
security of our scheme. The semantic security of our ABE
scheme enjoys the same security as the extension of BSW’s
CP-ABE scheme [17] because our scheme is built on their
scheme in addition to our partial ordering relation on HHF.
Our scheme is secure under extended Decision DiffieHellman problem assumption, which is defined as follows:
Suppose S ¼ ðp; G; GT ; eð
; ÞÞ be a cryptosystem on bilinear
pairing. Given ðG; Gt Þ; ðH; H t Þ; ðeðG; HÞ& ; T Þ for two random t; & 2 Zn , it is hard to decide whether or not
T ¼ eðG; HÞ&t , where g; h are two generators in G and G; GT
with order p. It is easy to see that an eDDH problem can be
transferred into a DDH problem in GT , that is, given
ðeðG; HÞ; eðG; HÞt ; eðG; HÞ& ; T Þ in GT to decide whether

613

T ¼ eðG; HÞ&t . This means that if DDH problem is hard in
GT then eDDH problem is also hard in G and GT even if the
bilinear pairing exists here.
More precisely, we have the following theorem according to the intractability of distinguishing the two distributions involved in the General Decision Diffie-Hellman
Exponent (GDDHE) problem [23]:
Theorem 4 (Lower Bound of eDDH, [23]). Given an eDDH
problem on S ¼ ðp; G; GT ; eð
; ÞÞ, for any PPT algorithm A
that makes a total of at most q queries to the oracle computing
the group operations in G; GT and the bilinear pairing
2

.
e : G  G ! GT , we have AdveDDH ðAÞ  2ðqþ10Þ
p
We prove the semantic security of our scheme under the
assumption of extended DDH problem. Since this kind of
security is concerned with the plaintext, which be confidentiality-protected rather than the validity of constraints
as described above, we need only to consider the adaptive
attribute lattice against chosen plaintext attacks. Hence, we
prove the Theorem
5, in which the advantage of adversary
2
according to Theorem 4 and "0 > 2".
is at most 4ðqþ10Þ
p
Theorem 5 (Semantic Security). Assume that extended Decision Diffie-Hellman problem on S ¼ ðp; G; GT ; eð
; ÞÞ with
order p is ðt0 ; "0 Þ-hard, the ABE-AH construction is
ðt; "Þ-adaptive attribute lattice against chosen plaintext attacks
(IND-AL-CPA), such that for any PPT algorithm A ¼ ðA1 ;
A2 Þ, the success probability of A satisfies
2

3
8ðpk; mskÞ
SetupðkÞ;
OðH Þ
6
A1 i ðpkÞ; 7
ðM0 ; M1 Þ
0
7  ";
Pr6
4b ¼ b :
5
b R f0; 1g;
0
A2 ðEncryptðpk; p; Mb ÞÞ
b
where "0 > 2", t0  t þ qA tA þ qh th , and tA ; th denotes the time
of attribute query and hash query.

8

PERFORMANCE EVALUATION

8.1 Performance Analysis of ABE Cryptosystem
Our ABE scheme is constructed on bilinear map system
from from elliptic curve pairings. For simplification, we
give several notations to denote the time for various operations in our ABE scheme. EðGÞ and EðGT Þ are used to
denote the exponentiation in G and GT , respectively. B is
used to denote the paring e : G  G ! GT . We neglect the
operations in Zp , the hash function H : f0; 1g
 ! G and the
multiplication in G and GT , since they are much more efficient than exponentiation and paring operation. We analyse
the computation and communication complexity for each
phase, where jT j denotes the number of the leaf nodes in
the tree, jAj denotes the set of attributes of encryptor and
decryptor, and lZp ; lG ; lGT denote the length of elements in
Z
p ; G; GT , respectively. The security of comparison operations is based on two mathematical assumptions: the hardness of CDH and eDDH problem, so we define k ¼ 80 bit
and p ¼ 160 bit to build a sufficiently secure system.
In Tables 4 and 5, we analyse the performance of our
ABE scheme from two aspects: computation and communication/storage costs. In Setup, the computation and storage
costs are constant. In KeyGen, it is easy find that the

614

IEEE TRANSACTIONS ON SERVICES COMPUTING,

TABLE 4
Complexity Analysis of Our ABE Scheme
Computation Complexity
Setup
KeyGen
Encrypt
Decrypt

2 
 EðGÞ þ 1 
 EðGT Þ þ 1 
 B
ð1 þ 3jAjÞ 
 EðGÞ
ð2 þ 3jAjÞ 
 EðGÞ þ 1 
 EðGT Þ
ð1 þ 2jAjÞ 
 B þ jAj 
 EðGÞ þ jT j 
 EðGT Þ

computation and storage of generating user’s private key is
bound up with the size of A, but for each attribute Ai the
user only needs two elements in G stored by himself. In
Encrypt, the computation and storage costs of ciphertexts is
related to the size of A and T . Finally, in Decrypt, the computation of decryption is also related to the size of A and T ,
but the bilinear map operations will consume a large
amount of time and memory. From the above analysis, the
computation and storage of our scheme is bound up with
the size of A and T , but the storage size of user’s private
key is shorter than general scheme.

8.2 Performance Analysis of Rule Conversion
Our solution for migrating from RBAC to ABAC enjoys an
optimum performance. When the “one-to-one” conversion
method is used in our solution, the generation of access policy only requires one-time search for PA, and the mapping
process of user’s attribute assignment also requires onetime scanning for UA. The access authorization decision
based on Match requires one-time function invoking of
rokesðsi Þ, one-time searching for RH, as well as at most
jRHj time searching for PA, where jRHj denotes the number of roles in RH. When the multi-attribute conversion
method is introduced, that is, R ¼ A1  A2  
 
 
  An , the
complexities of three above-mentioned processes are
increased to n ¼ jAj times, but the searching processes for
RA, RH, and PA are the same as before.
In Table 6 we show some comparison results of conversion between our scheme and BSW’s ABE scheme [17] from
a RBAC-based university management system with around
40 roles, which is used for maintenance of large volumes of
information, including student, faculty, inventory, transport, library, facility management. Our scheme divided 40
roles into six groups where each group has seven attribute
values, but the BEW’s ABE without attribute hierarchy only
achieved the same number of attributes by one-to-one mapping. We found that these conversions entail a substantial
attribute engineering effort: our scheme reduced the length
of private keys and ciphertexts to less than 60 percent at
average case, where lG ¼ lGT ¼ 320 bits and lZp ¼ 160 bits.
This means that the computational costs were reduced

VOL. 8,

NO. 4,

JULY/AUGUST 2015

TABLE 6
The Results of Conversion from RBAC to ABAC
Our Scheme BSW’s Scheme [17]
Number of roles
Number of set of attributes n
Average size of attribute sets v
Length of private key
13lG
Length of ciphertext
20lG

40
6
7
 0:5 KB
 0:8 KB

40
40
1
41lG  1:6 KB
62lG  2:5 KB

enormously. Benefited from these possible rule conversions,
our scheme provides a secure and efficient solution to cloud
storage in a more flexible manner.

8.3 Performance Evaluation of System
We have implemented our scheme in Qt/C++ and experiments were run on a small cloud based on Openstack platform with six servers. All disk operations were performed
on a 1.82TB RAID five disk array. Using GMP and PBC
libraries, we have implemented a cryptosystem based on
our solution in this paper. This C library contains approximately 8,000 lines of code and has been tested on a virtual
network platform based on VMware workstation, in which
consists of a simple medical RBAC system, a cloud storage
service, and a virtual network.
Our experiments employed 6 sets of attributes, that is,
A ¼ fA1 ; . . . ; A6 g. In every experiment we randomly built an
attribute hierarchy for each Ai 2 A, where the size of hierarchies (the number of nodes) can be specified in accordance
with our requirements. In Fig. 9 we show the practical computational costs of different algorithms in our ABE scheme
under the different sizes of attribute hierarchy (from 5 to 55).
From the trends of these curves, the change of computational
costs is not significant for different hierarchies.
In Table 7 the detail data are listed for the above experiments. In these experiments, the performance of Setup algorithm does not changed for all cases, but the performance of
other three algorithms are increased along with the size
ascending. However, the increasing is not significant. In
addition, the decryption is the most expensive algorithm
because a great amount of bilinear map operations are executed. In our experiments we ignores the execution time of
the other modules because their changes were not evident
for the different hierarchies.

TABLE 5
Communication/Storage Analysis of Our ABE Scheme
Communication/Storage Complexity
Public parameter (pp)
Encryption key (ek)
Master key (msk)
Private key (usk)
Ciphertext (C)
Plaintext (M)

1 
 lZp
3 
 lG þ 1 
 lGT
1 
 lG þ 1 
 lZp
ð1 þ 2jAjÞ 
 lG
ð1 þ 3jT jÞ 
 lG þ 1 
 lGT
1 
 lGT

Fig. 9. Computational costs of our scheme under the different sizes of
attribute hierarchy (from 5 to 55).

ZHU ET AL.: FROM RBAC TO ABAC: CONSTRUCTING FLEXIBLE DATA ACCESS CONTROL FOR CLOUD STORAGE SERVICES

TABLE 7
Computational Consts of Our Scheme for Different Hierarchies
Heirarchy size
5
10
15
20
25
30
35
40
45
50
55

9

Setup

GenKey

Encrypt

Decrypt

3.38521
3.38521
3.38521
3.44761
3.43201
3.38521
3.40081
3.40081
3.43201
3.44761
3.47881

5.97481
5.97481
5.97481
5.97481
5.89681
5.91241
5.89681
6.00601
6.06841
6.08401
6.38041

7.56601
7.56601
7.56601
7.56601
7.59721
7.62841
7.64401
7.76881
7.90921
7.92481
8.42402

12.99482
12.99482
12.99482
12.99482
13.02602
13.05722
13.07282
13.16642
13.21322
13.33802
13.55642

RELATED WORK

While the concept of ABAC has been around (introduced as
early as 1996 in ISO 10181-3 and X.509 ACs), it has gained
prominence in research literature with its use in trust negotiation and credential-based access control in a distributed
system with multiple administrative domains [6], [15].
Goyal et al. [3] first defined the two complimentary forms of
ABE, namely, key-policy ABE and Ciphertext-Policy ABE
(CP-ABE), and provided a construction for KP-ABE. Then,
Bethencourt et al. [17] gave the first construction for a CPABE scheme (short for BSW) in the generic group model.
These schemes supported monotonic Boolean encryption
policies. Many ABE schemes with varying properties have
been proposed since then, for example, schemes that supported non-monotonic boolean encryption policies (e.g.,
[4]), schemes that supported multiple attribute authorities
(e.g., [24]), and so on. Recently, Lewko and Waters [25] proposed a multi-authority ABE system, in which any party
can become an authority and there is no requirement for
any global manager. Also, Waters [26] presented a new
methodology for realizing CP-ABE under concrete and noninteractive cryptographic assumptions in the standard
model. Lewko et al. [27] presented a fully secure ABE
scheme and attribute-hiding predicate encryption (PE)
scheme for inner-product predicates by using dual system
encryption methodology.

10

CONCLUSION

In this paper, we addressed the effective method to simplify
the policy-specified burden of cloud users in the process of
using ABE. Our method is to improve ABE to support RBAC
model, the existing RBAC users, without alterations, can
access their ABE-encrypted data in the cloud. Compared with
trivial equal and bit matching in prior solutions, our scheme
enhances the expressive capacity of access policies, decreases
the computational overheads, and reduces the size of ciphertexts and private-keys for attribute-based encryption.

615

REFERENCES
[1]

[2]
[3]

[4]
[5]
[6]

[7]

[8]

[9]

[10]

[11]
[12]
[13]

[14]
[15]

[16]
[17]
[18]
[19]
[20]

ACKNOWLEDGMENTS

[21]

The authors are indebted to anonymous reviewers for their
valuable suggestions. This work was supported by the
National 973 Program (Grant No. 2013CB329605) and the
National Natural Science Foundation of China (Grant Nos.
61170264 and 61472032).

[22]

F. R. Institute. (2010). Personal data in the cloud: A global survey
of consumer attitudes [Online]. Available: http://www.fujitsu.
com/downloads/SOL/fai/reports/fujitsu/personal-data-in-thecloud.pdf
K. Ren, C. Wang, and Q. Wang, “Security challenges for the public
cloud,” IEEE Internet Comput., vol. 16, no. 1, pp. 69–73, Jan./Feb.
2012.
V. Goyal, O. Pandey, A. Sahai, and B. Waters, “Attributebased encryption for fine-grained access control of encrypted
data,” in Proc. 13th ACM Conf. Comput. Commun. Security,
2006, pp. 89–98.
R. Ostrovsky, A. Sahai, and B. Waters, “Attribute-based encryption with non-monotonic access structures,” in Proc. 14th ACM
Conf. Comput. Commun. Security, 2007, pp. 195–203.
S. Yu, C. Wang, K. Ren, and W. Lou, “Achieving secure, scalable,
and fine-grained data access control in cloud computing,” in Proc.
IEEE Conf. Comput. Commun., 2010, pp. 534–542.
R. Bobba, O. Fatemieh, F. Khan, A. Khan, C. A. Gunter, H. Khurana, and M. Prabhakaran, “Attribute-based messaging: Access
control and confidentiality,” ACM Trans. Inf. Syst. Secur., vol. 13,
no. 4, p. 31, 2010.
V. C. Hu, D. Ferraiolo, R. Kuhn, A. Schnitzer, K. Sandlin, R. Miller,
and K. Scarfone, “Guide to attribute based access control (ABAC)
definition and considerations,” NIST Special Publ., vol. 800, p. 162,
2014.
M. J. Atallah, K. B. Frikken, and M. Blanton, “Dynamic and efficient key management for access hierarchies,” in Proc. 12th ACM
Conf. Comput. Commun. Security, Alexandria, VA, USA, 2005,
pp. 190–202.
S. D. C. di Vimercati, S. Foresti, S. Jajodia, S. Paraboschi, and
P. Samarati, “Over-encryption: Management of access control evolution on outsourced data,” in Proc. 33rd Int. Conf. Very Large Data
Bases, 2007, pp. 123–134.
R. Bobba, H. Khurana, and M. Prabhakaran, “Attribute-sets: A
practically
motivated
enhancement
to
attribute-based
encryption,” in Proc. 15th Eur. Symp. Res. Comput. Security, 2009,
pp. 587–604.
G. Wang, Q. Liu, and J. Wu, “Hierarchical attribute-based encryption for fine-grained access control in cloud storage services,”
in Proc. ACM Conf. Comput. Commun. Secur., 2010, pp. 735–737.
J. Li, Q. Wang, C. Wang, and K. Ren, “Enhancing attribute-based
encryption with attribute hierarchy,” in Proc. ACM Mobile Netw.
Appl., vol. 16, no. 5, pp. 553–561, 2011.
Y. Zhu, G.-J. Ahn, H. Hu, D. Ma, and S. Wang, “Role-based cryptosystem: A new cryptographic RBAC system based on role-key
hierarchy,” IEEE Trans. Inf. Forensics Secur., vol. 8, no. 12,
pp. 2138–2153, Dec. 2013.
R. Sandhu, E. Coyne, H. Fenstein, and C. Youman, “Role-based
access control models,” IEEE Comput., vol. 29, no. 2, pp. 38–47,
Feb. 1996.
R. Bobba, O. Fatemieh, F. Khan, C. A. Gunter, and H. Khurana,
“Using attribute-based access control to enable attribute-based
messaging,” in Proc. 22nd Annu. Comput. Security Appl. Conf., 2006,
pp. 403–413.
A. Sahai and B. Waters, “Fuzzy identity-based encryption,”
in Proc. EUROCRYPT, 2005, pp. 457–473.
J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-policy attribute-based encryption,” in Proc. IEEE Symp. Secur. Privacy, 2007,
pp. 321–334.
V. Goyal, A. Jain, O. Pandey, and A. Sahai, “Bounded ciphertext
policy attribute based encryption,” in Proc. Int. Colloq. Automata,
Lang. Program., 2008, pp. 579–591.
Y. Zhu, G.-J. Ahn, H. Hu, S. Yau, H. An, and C.-J. Hu, “Dynamic
audit services for outsourced storages in clouds,” IEEE Trans.
Serv. Comput., vol. 6, no. 2, pp. 227–238, Apr.-Jun. 2013.
R. Agrawal, J. Kiernan, R. Srikant, and Y. Xu, “Order preserving
encryption for numeric data,” in Proc. ACM SIGMOD Int. Conf.
Manage. Data, 2004, pp. 563–574.
A. Boldyreva, N. Chenette, and A. O’Neill, “Order-preserving
encryption revisited: Improved security analysis and alternative
solutions,” in Proc. Annu. Int. Cryptol. Conf. Adv. Cryptol., 2011,
pp. 578–595.
D. Boneh and M. Franklin, “Identity-based encryption from the
weil pairing,” in Proc. 21st Annu. Int. Cryptol. Conf. Adv. Cryptol.,
2001, pp. 213–229.

616

IEEE TRANSACTIONS ON SERVICES COMPUTING,

[23] D. Boneh, X. Boyen, and E.-J. Goh, “Hierarchical identity based
encryption with constant size ciphertext,” in Proc. 24th Annu. Int.
Conf. Theory Appl. Cryptographic Tech., 2005, pp. 440–456.
[24] M. Chase and S. S. M. Chow, “Improving privacy and security in
multi-authority attribute-based encryption,” in Proc. ACM Conf.
Comput. Commun. Secur., 2009, pp. 121–130.
[25] A. B. Lewko and B. Waters, “Decentralizing attribute-based
encryption,” in Proc. Annu. Int. Conf. Theory Appl. Cryptographic
Tech., 2011, pp. 568–588.
[26] B. Waters, “Ciphertext-policy attribute-based encryption: An
expressive, efficient, and provably secure realization,” in Public
Key Cryptography, New York, NY, USA: Springer, 2011, pp. 53–70.
[27] A. B. Lewko, T. Okamoto, A. Sahai, K. Takashima, and B. Waters,
“Fully secure functional encryption: Attribute-based encryption
and (hierarchical) inner product encryption,” in Proc. Annu. Int.
Conf. Theory Appl. Cryptographic Tech., 2010, pp. 62–91.
Yan Zhu received the PhD degree in computer
science from Harbin Engineering University,
China, in 2005. He is currently a professor at the
University of Science and Technology, Beijing,
China. He was an associate professor at Peking
University, China, from 2007 to 2012. He was a
visiting associate professor at the Arizona State
University, from 2008 to 2009, and a visiting
research investigator of the University of Michigan-Dearborn in 2012. His research interests
include cryptography, secure computation, and
network security. He is a member of the IEEE.
Dijiang Huang received the BS degree from the
Beijing University of Posts and Telecommunications, China, in 1995, and the MS and PhD
degrees from the University of Missouri-Kansas
City, in 2001 and 2004, respectively. He is an
associate professor at the School of Computing
Informatics and Decision System Engineering,
Arizona State University. His current research
interests include computer networking, security,
and privacy. He is an associate editor of the Journal of Network and System Management and an
editor of the IEEE Communications Surveys and Tutorials. He was an
organizer for many international conferences and workshops. His
research is supported by the United States National Science Foundation
(NSF), the US Office of Naval Research (ONR), the US Army Research
Office, NATO, and the Consortium of Embedded Systems. He received
the ONR Young Investigator Program Award. He is a senior member of
the IEEE.

VOL. 8,

NO. 4,

JULY/AUGUST 2015

ChangJyun Hu received the PhD degree from
Peking University, Beijing, China, in 2001. He is
currently a professor at the School of Computer
and Communication Engineering, University of
Science and Technology, Beijing, China. His
main research interests include parallel computing, parallel compilation technology, parallel software engineering, network storage system, data
engineering, and software engineering.

Xin Wang received the BS degree from the
Hubei University of Technology, China, in 2012.
She is working toward master’s degree at the
School of Computer and Communication Engineering, University of Science and Technology
Beijing, China from 2013. Her research interests
include cryptography, cloud computing, and network security.

BY DIJIANG HUANG, QING CAO, AMIT SINHA, MARC J. SCHNIEDERJANS,
CORY BEARD, LEIN HARN, AND DEEP MEDHI

New Architecture for
Intra-Domain Network
Developing an effective platform for deterring network attacks.
The pervasive nature of information infrastructure coupled with threats for cyber terrorism
makes network infrastructure security a critical
area of interest for computer/network security
practitioners and researchers. While there has
been a significant amount of research on securing information content or software, securing
network infrastructure has drawn attention
sporadically over the years [1, 2, 5, 12].
One of the most critical infrastructure
security issues involves securing routing
infrastructure. Bellovin [1] in 1989 commented that “Abuse of the routing mechanism
and protocols is probably the simplest protocol-based attack available.” More recently, the
following excerpts from the Computer Emergency Response Team (CERT) highlight the
importance and imminent need for securing
the routing infrastructure: “One of the most
recent and disturbing trends we have seen is an
increase in intruder compromise and use of
ILLUSTRATION BY
ROBERT NEUBECKER

64

November 2006/Vol. 49, No. 11 COMMUNICATIONS OF THE ACM

routers. … Reports indicate routers are being
used by intruders as platforms for scanning
activity. … Routers make attractive targets for
intruders…routers are often less protected by
security
policy
and
monitoring
technology…attacks based on direct attacks
against the routing protocols that interconnect
the networks comprising the Internet. We
believe this to be an imminent and real threat
with a potentially high impact” [5].
In order to understand routing infrastructure
protection, we provide a brief overview of the
Internet routing infrastructure. For routing purpose, the infrastructure is divided into two
domains: intra-domain and inter-domain. The
entire routing infrastructure is a collection of
intra-domain routing “regions” connected
through an inter-domain functionality (see Figure 1). A particular intra-domain routing environment, also referred to as an Autonomous
System (AS), is administered by a specific

Security Issues
administrative authority; usually, this authority
owns the routers in its domain, but not necessarily all the links that connect the intra-domain
routers (since bandwidth is commonly leased
from telecommunications carriers). Most commonly deployed routing protocols within an
Autonomous System are Open Shortest Path
First (OSPF) and Intermediate-System-toIntermediate-System (IS-IS) routing protocols;
they are both based on the concept of link-state
routing (see the sidebar “Link-State Routing”).
Neighboring Autonomous Systems exchange
routing reachability information through an
inter-domain functionality; in the Internet
routing infrastructure, this functionality is
accomplished through Border Gateway Protocol (BGP, currently, version 4). An intradomain may be connected to multiple other
intra-domains through inter-domain links and
peering arrangement.
Routing attacks are attacks targeting routing

protocols or attacks that rely on routers as
weapons. A router is a network device that performs two main functions: it uses routing protocols to build up routing tables and secondly, it
forwards data packets. The consequences of
routing attacks can be noticeable and catastrophic as they can also bring down a network infrastructure without causing any
perceived physical damage to the network entities [7, 12]. In other words, since
routers are network-layer devices, faulty routers
or routing protocols can cause malfunctions of
the entire routing domain regardless of what services are running within the routing domain.
Thus, routing attacks can have broad scale
effects since these can deny or reduce communication capabilities of end systems. In this article,
our scope is on categorizing various threats when
link-state routing is employed in an intradomain environment, followed by proposing
preventative countermeasures to these threats,

COMMUNICATIONS OF THE ACM November 2006/Vol. 49, No. 11

65

and finally to describe an architectural framework for Internet. Finally, since the links between routers in a
geographically dispersed autonomous system are
robustness of an intra-domain environment.
There are several reasons to consider the protection often leased, they are vulnerable to tapping by outFigure 1. Internet infrastructure connecting intra-domains
of an intra-domain routing
infrastructure. If siders for information (including routing information
through inter-domain links.
routers in a particular autonomous system (especially exchange).
In link-state routing, a router receives LSAs from
critical ones in the entire Internet routing infrastrucdifferent routers; it may
ture) are compromised,
combine them into a
then it can affect transit
Inter-domain BGP links
link-state update (LSU)
traffic between different
OSPF
or
Tier-1 Internet
private peer-to-peer links
packet (see the figure in
domains that are using
service providers
the sidebar “Link-State
this AS for reachability. If
IS-IS
OSPF
Routing”) for flooding
an autonomous system is
downstream. It is assumed
decommissioned momenthat this router does not
tarily due to routing
change the content of the
attacks, it can cause casTier-2,3
Internet
LSAs received, but merely
cading effects on other
service
providers
OSPF
IS-IS
OSPF
puts them together for
Autonomous
Systems
forwarding purposes. For
through BGP, possibly
IS-IS
OSPF
now, we assume that all
leading to route flapping
routing information is
and delayed convergence
and while such behavior Figure 1. Internet infrastructure generated in a clear-text format (how to protect it will
connecting intra-domains
has been identified earlier
through inter-domain links. be discussed later).
for routing CPU overload
[9], it is similarly possible in the case of routing TAXONOMY OF NETWORK ROUTING THREATS
attacks. Another important considerationHuang
is thatfig There
are several sources of threat to a network rout1 (11/06)
while routers in an intra-domain environment are ing infrastructure. In the context of routing infraowned by a particular administrative authority, they structure protection, it is immaterial what motivates
are “public” in the view of the Internet environ- these sources; what matters instead is whether these
ment—that is, they are possible points of attacks sources present a risk of security breaches to the
much like end hosts or Web servers connected to the infrastructure and to what level or extent. In an

LINK-STATE ROUTING
A router sends information about its outgoing links (“link-states”) to all its neighboring routers either periodically or when an event (for examSidebar: Figure 1. Routing information encapsulation and illustrations
ple, a failure) triggers such an advertisement; this advertisement is called link-state advertisement (LSA). A typical LSA contains link metrics
of Packet Level (PL) and Information Level (IL).
that may be based on information such as hop count, bandwidth, delay, and so on; furthermore, an LSA for a link can contain multiple link
metrics. Upon receiving an LSA from its neighbor, a router is required to make certain decisions: if this router has already received the same
LSA (via another router), it will drop it; otherwise, this router will forward the LSA to all its neighbors except to the sending router. Thus, the
forwarding takes place in a point-to-point manner, this forwarding procedure is called flooding and it continues until every router in the network receives the most recent LSA. In
order to allow a receiving router to deterInformation Level (IL):
mine if it has the most recent LSA for a
(Link State Advertisements are
particular link, each LSA is stamped with
encapsulated within an LSU packet)
a sequence number before it is disseminated by the originating router; if a router
LSU
LSA1 LSA2
LSAn
IP Header LSU1 LSU2
LSUn
needs to generate a new LSA for any of its
Header
outgoing links, it increments the
sequence number and starts the new
advertisement that includes the newly
Packet Level (PL): routing
packet (LSU) or IP packet
stamped sequence number. Upon receiving LSAs of different links, each router
builds a link-state database that also
serves as topological information; using the metric contained in the LSA, each router can compute shortest
path routing to all destination routers in its domain using Dijkstra’s algorithm, and builds a packet forHuang
sidebar
warding table (“next-hop”). This forwarding table is used in determining how to handle
an incoming
datafig
packet which is not meant for itself. c

66

November 2006/Vol. 49, No. 11 COMMUNICATIONS OF THE ACM

Routing information
encapsulation and illustrations
of Packet Level (PL) and
1 (11/06)
Information Level (IL).

Insider

Outsider

intra-domain routing infrastructure, there are legiti1. Sniffing: An outsider monitors and/or records
mate users who have unlimited access to routers (for routing exchanges between authorized routers to sniff
example, password-based access) and other legiti- for routing information; this cannot be ruled out,
mate users who have limited access; while clearly the especially in a networking environment where links
former have more privilege than the latter, we clas- are leased.
sify both of them as ‘insiders’ in our taxonomy. In
2. Traffic analysis: An outsider gains routing inforaddition, there is another group of users who have mation by analyzing the characteristics of the data trafexternal access to the infrastructure:
1) since routers fic on a subverted link. Network tomography is a
Table 1. Taxonomy of network routing attacks.
in an intra-domain environment are still ‘public’ technique that can be attackers to derive network topolentities as far as the Internet is concerned, any users ogy and network traffic allocation pattern by measuring
who are not legitimate
end-to-end performance
Acquiring routing Denial of service
Routing-path
users of the intra-domain
of the network (such as
information (ARI) (DoS)
manipulation (RPM)
infrastructure can concounts of the sent/received
1. Sniffing
1. Interference
1. Can manipulate
ceivably try to “attack”
packets, the time delays
2. Traffic analysis –
a. Add noise
Network
b. Inject dummy
such routers, much like
between
sent/received
tomography
routing/data traffic
c. Replay old packets
the way Web servers have
packets, and so forth).
All capabilities of
All capabilities of
been attacked for denial of
Denial of Service (DoS)
outsiders
outsiders
service, 2) since a large
1. Interference: An
1. Routing analysis
1. Interference
1. Impersonation
geographically dispersed
outsider
blocks routing
2. Deliberate
a. Not forwarding packets 2. Falsification
exposure
b. Delay responses
a. Claim non-exist links
intra-domain environexchanges between authoc. Inject wrong
b. Misclaim exist links
ment consists of leased
rized routers to disrupt
routing packets
c. Modify, insert, or
2.
Overload
substitute
routing
links (often, from telecomrouting operations. The
a. Overload CPU
message
b. Overload link-state
munications carriers), the
outsider can add noises to
database
possibility of a link being
prevent the legitimate
tapped for (and manipularouters from receiving the
Table 1. Taxonomy of network routing information correctly, inject dummy data or
tion of) information canrouting attacks.
Huang table
1 (11/06)
not be completely ruled
routing
packets to saturate the communication link, or
out. Thus, we can see that
replay old routing packets to cause the routing to malthere is a second group of users (not legitimate users) function.
who can do harm to an intra-domain routing infraRouting-path manipulation (RPM)
structure: we classify them as ‘outsiders’ in our tax1. An outsider can manipulate the routing paths by
onomy.
disseminating forged routing information.
It is important to recognize that an adversary can
Threat possibilities from an insider include:
be either an insider or an outsider; regardless, the priCompared to an outsider, an insider not only posmary goal of an adversary is to cause network routing sesses all the capabilities of an outsider but also has the
to malfunction somehow. We base our classification following additional capabilities.
by insiders and outsiders, rather then whether a user is
Acquiring routing information (ARI)
being adversarial or not, since our classification allows
1. Routing analysis: The routing information
us to consider goals and techniques of attacks more (LSA) is flooded within the link-state routing domain.
succinctly. We categorize threat possibilities for link- All routers maintain the same network topology. As
state routing into three types: acquiring routing infor- such, it is easier for an insider to derive network topolmation (ARI), denial of service (DoS), and ogy, network routing and network resource allocation
routing-path manipulation (RPM). It may be noted patterns (bandwidth of each link or traffic load on
that the first two are rather goals of an attacker links).
(whether insider or outsider) while the third one is a
2. Deliberate exposure: An insider intentionally
technique to force routing and the network to mal- releases routing information to others, such as outfunction—this technique is important to consider as siders or those who are not authorized to receive the
a separate type due to the role of a link-state routing exposed information.
protocol in an intra-domain environment. In Table 1,
Denial of Service (DoS)
we present our taxonomy of threats based on our user
1. Interference: Since an insider is a legitimate parclassification, and on identification of goals and tech- ticipant who has control over network routers, it can
niques into three types; we elaborate on this here.
take actions to drop received routing packets
(LSUs/LSAs), delay the responses of the received routThreat possibilities from an outsider include:
ing packets (which can prolong the routing converAcquiring routing information (ARI)
COMMUNICATIONS OF THE ACM November 2006/Vol. 49, No. 11

67

Table 2. Preventive cryptographic countermeasures.

gence time and cause Methods Level
LINK-STATE ROUTING
Label Description
Examples
instability of the system),
SECURITY MECHANISMS
PLA P2P Packet level, point-toOSPFv2 ([10]) and
point authentication
OSPFv3 ([4])
or inject wrong routing
The challenges imposed
Packet Level
PLA E2E Packet level, end-to-end N/A
information to prevent
by the enormity and diverauthentication
other routers from build- Authentication
sity of network routing
ILA
Information
level,
pointN/A
P2P
ing correct routing tables.
threats for an intrato-point authentication
Information
2. Overload: An
domain routing environLevel
ILA E2E Information level, end- OSPF with digital
insider can place excess
ment have prompted the
to-end authentication
signature ([11])
burden on legitimate
need to develop a variety
Packet Level C PL
Confidentiality for the OSPFv3 ([4])
whole packet
routers. For example, the
of preventive techniques.
Confidentiality
insider can create an
In order to properly disInformation C IL
Confidentiality for the N/A
Level
information within the
excessive amount of linkcuss how to prevent or
packet
state packets that other
minimize attacks, we first
Table
2.
Preventive
cryptographic
routers within the netdiscuss preventive cryptographic countermeasures. It
countermeasures.
work are not able to hanmay be noted that preventive cryptographic counterHuang
2 (11/06)
dle. In addition, the insider can overload the
routingtable
measures,
by themselves, can do little to prevent DoS
database to prevent other routers from building up attacks. Most of the current solutions to DoS attacks
the routing table.
are reactive solutions, that is, solutions that depend
on intrusion detection systems (IDS), which is
Routing-path manipulation (RPM)
1. Impersonation: this refers to an insider claim- beyond the scope of this research. However, we will
ing to be another legitimate “router” and performs discuss later how to create multiple trusted routing
routing functions. Impersonation enables the domains to mitigate the consequence of DoS attacks.
insider to successfully carry out other threats (such
Preventive Cryptographic Countermeasures. It
as falsification) causing additional threat conse- may be noted that the confidentiality ensures that no
quences. For example, by impersonating a legiti- unauthorized entities can decipher the routing informate router, the insider can successfully convince a mation on its way to a destination. Integrity refers to
receiver to accept forged routing packets if all the trustworthiness of data or resources, and it is usurouters use the same shared key to verify the rout- ally phrased in terms of preventing improper or unauing packets. In this way, the insider can create a thorized change. Integrity includes data integrity (the
shorter path to attract data traffic or create a longer content of the information) and origin integrity (the
path to expel data traffic. Thus, the insider can source of the data, often called authentication). The
manipulate the routing paths more efficiently by interpretations of integrity and authentication vary, as
impersonating multiple routers rather than chang- do the contexts in which they arise. In the
ing its own link weights.
context/setting of a link-state routing environment,
2. Falsification: A router held hostage by an insider authentication is generally considered as both data
can send false routing information. It can also send integrity and origin integrity.
non-existing or wrong LSAs of itself. The insider can
In recent link-state routing protocol standards,
also alter/drop the forwarded LSAs originated from RFC 2328 [10] for OSPFv2 (OSPF version 2),
other routers. By impersonating a legitimate router, packet level authentication capability is now available.
the insider can forge LSAs for non-existent/existing Note that this refers to a routing packet such as a linkcommunication links in any part of the link-state state update (LSU) packet which usually contains
routing domain. Another goal of the insider is to cre- multiple LSAs; that is, the authentication is provided
ate shorter or longer paths between communication only at the LSU level, not at the LSA level. By using
peers, and thus deviates the data traffic to a host con- a keyed cryptographic hash (a message authentication
troller by the attacker.
code), a shared secret key is configured in all routers
In summary, network routing security rests on attached to a common network/subnet and each LSU
confidentiality, integrity, and availability. These three is authenticated. An example of authentication techaspects are closely related to threat possibilities that niques is keyed hashing for message authentication
we have discussed thus far: acquiring routing infor- (HMAC). We note that the operation of HMAC also
mation (ARI), denial of service (DoS), and routing- provides data integrity checking; only authorized
path manipulation (RPM), respectively. That is, ARI users (possessor of a shared key) can generate and veris related to confidentiality of a router, DoS related to ify HMAC. Similarly, digital signature for OSPF (see
the availability of a router, and RPM primarily relates RFC 2154 [11]) also provides both data integrity and
to the integrity of a router.
origin integrity. In this work, we consider authentica68

November 2006/Vol. 49, No. 11 COMMUNICATIONS OF THE ACM

Our approach focuses on the following two preventive cryptographic
countermeasures: CONFIDENTIALITY AND AUTHENTICATION.

tion as providing both data integrity and origin
integrity.
Our approach focuses on the following two preventive cryptographic countermeasures: confidentiality and authentication. These two countermeasures
can provide protection at either the packet level (PL)
or the information level (IL), shown in the figure in
the sidebar “Link-State Routing.” If we assume a routing packet to be a bus filled with a group of passengers, PL and IL represent the cryptographic
countermeasures being provided for the bus and each
individual passenger, respectively. Besides authentication and confidentiality, there are two other important concepts we need to introduce; they are
point-to-point (P2P) and end-to-end (E2E). In terms
of authentication, P2P means that the generation and
verification of an authentication code are performed
by every forwarding router; while E2E means that the
generation of an authentication code is performed
only at the originating router, all the forwarding
routers and termination routers are part of the end
system, and they only perform verification. In Table
2, we summarize two main preventive cryptographic
countermeasures needed for link-state routing protocols; the table also includes labeling currently available
approaches.
As one can see, only some of cryptographic countermeasures presented in Table 2 have been
addressed in the existing literature, namely, PLAP2P
and ILAE2E. Researchers in our team (see [6, 7] for
details) have addressed additional measures such as
the double authentication (DA) scheme to set up an
authentication chain from the source to destination.
In this scheme, each router generates two authentication codes for the LSA: one is used for verification
by all its neighbors; the other is used for verification
by all routers except its neighbors (see the sidebar
“Double Authentication Scheme” for a discussion of
the DA scheme). Generally speaking, digital signatures use asymmetric (public/private key) encryption
algorithms and digital signatures operate roughly
100 to 1,000 times slower (depend on which cryp-

tographic algorithm is used) than symmetric encryption algorithms, such as HMAC, under same hardware constraints. The DA scheme (basically lies
between ILAE2E and ILAP2P) is aimed to provide similar security features of digital signatures, and at the
same time, it has less computational overhead as
compared to using a digital signature scheme. Note
that ILAP2P does not provide protection from insider
attacks, moreover, it involves more computational
overhead than PLAP2P schemes. To date, no ILAP2P
authentication schemes have been proposed.
Regardless, based on the preceding analysis, using
both PLAP2P and ILAE2E, it is possible to design a
secure intra-domain routing environment that can
provide strong cryptographic countermeasures to
prevent insider attacks (such as impersonation and
falsification by claiming/misclaiming other routers’
links and modifying/inserting/substituting the forwarded LSAs).
To date, there has been no CIL proposed for linkstate routing. Our proposed approach is to use CILand
ILAE2E for link-state routing as the foundation to
build a new secure link-state routing framework for
intra-domain routing. To deploy CIL, routing information is categorized by multiple groups. By carefully
assigning group keys to routers, we can partition network resource into multiple routing domains. For
example, consider a router with several outgoing links;
it can encrypt LSAs for some links using one key and
encrypt LSAs for other links using another key. Thus,
only routers that have the correct key can decrypt the
routing information. This strategy can also be applied
to a single link, that is, a router can partition the
bandwidth of a link into multiple portions and create/encrypt an LSA for each portion. This approach
has several benefits:
• It prevents outsiders’ sniffing attacks (we assume
the crypto key length is long enough to prevent
brutal force attack within a maintenance cycle—
periodically update the crypto keys).
• It mitigates outsiders’ traffic-analysis attacks: Since
COMMUNICATIONS OF THE ACM November 2006/Vol. 49, No. 11

69

Figure 2. Secure framework for link state routing.

called secrets) and the
linear derivative relations
of one-way function
Trusted Routing Domains (TRDs)
chains, each group member can self-derive any
desired subgroup key.
Thus, during the group
Key
Network Resource
communication phase,
Management
Management (NRM)
each group member
(KM)
(router) can self-generate
any possible subgroup
key at anytime without
Intrusion
Detection
depending on a trusted
Traffic
System (IDS)
Management
third party (such as KM)
(TM)
or negotiating first
among group members
for any verification; that
is, communication overhead due to such set-up can
Figure 2. Secure framework for
link-state routing.
be avoided. Note that a subgroup key is a shared key
that is known only to the corresponding subgroup
members.
Huang fig 2 (11/06)
To implement CIL, an efficient secure group key
Other Security Supporting Mechanisms. To build
management scheme, which supports many-to-many a highly secure routing system, several supporting
secure group communication, is needed. Many-to- mechanisms are also needed. For example, DoS
many secure group communication requires that each attacks are difficult to prevent. The most efficient
group member (router in our case) with a group pop- countering technique is to identify the DoS attack
ulation of size n can communicate with any subgroup and respond to it quickly. An IDS (intrusion detecof members securely; this means a group member tion system) is a system that collects information
would need to possess 2n-1-1 keys. When n is large, it from a variety of systems and network sources, and
is not possible for a group member to store 2n-1-1 then analyzes the information for signs of intrusion
number of keys. To solve this problem, a centralized and misuse. Chang et al. [3] proposed a real-time IDS
key server can be in charge of the group key manage- for link-state routing protocols. This IDS is based on
ment functionality. However, the centralized key simple network management protocol (SNMPv3),
server is vulnerable to single point failure. In addition, which can be used to collect system status and intrulong key setup delay and communication overhead sion alerts from the network. To respond to attacks,
due to key setup prevent the centralized scheme from we need a network resource management system to
being used for secure many-to-many group commu- manage routers, such as isolating subverted routers,
nication needed between a subgroup of routers. To changing link weights, informing a key management
solve the preceding problems, a novel key-chain based system to redistribute keys, and so on. This will be
many-to-many secure group communication scheme addressed in the next section.
and a key agreement protocol have been proposed [8].
The proposed group Key Management (KM) scheme AN ARCHITECTURAL FRAMEWORK FOR SECURE
involves two phases: the key predistribution phase LINK-STATE ROUTING
and the group communication phase. During the key Now that we have covered various components and
predistribution phase, a set of secrets is preinstalled in proposed approaches, we are ready to present our
each group member (a router) via offline methods, entire secure routing architectural framework, which
such as manual installation or online dedicate secure is based on security techniques (authentication and
channels. In order to construct the secure group key- confidentiality) for the link-state routing protocol.
ing scheme, this scheme utilizes the linear hierarchical In our proposed routing framework shown in Figure
structure of one-way function chain (such as hash 2, there are five components: trust routing domains
chain). A unique value from each one-way function (TRDs), network resource management (NRM),
chain is distributed (however, multiple one-way func- key management (KM), traffic management (TM),
tion chains need to be constructed in advance). Based and intrusion detection system (IDS). Arrows
on the predistributed one-way function values (also within Figure 2 represent the communication relalink-states are encrypted
and a router may or may
not possess the decrypting key, routers can
maintain different network topology and
shortest path tree. Thus,
the data flow may not
follow the same shortest
path, which can prevent
attackers from deriving
correct network topology
or traffic allocation
pattern.
• An insider has limited
information of the network, which can mitigate
routing analysis and
deliberate exposure
attacks.

70

November 2006/Vol. 49, No. 11 COMMUNICATIONS OF THE ACM

overhead such as key setup delay and communication
tions among different components.
The entire routing domain can be divided into overhead due to key setup. Creating TRDs in a routmultiple routing sub-domains. We refer to such a sub- ing domain and providing ILAE2E and CIL to the routdomain as a TRD. The framework may not ing information require an efficient symmetric keying
need/imply the division of the administrative domain scheme. The keying scheme would be deemed suitable
into TRDs. Every router that belongs to a particular for this purpose if it displays the following features:
TRD will have complete routing information of its
own TRD, but not others. We use the cryptographic • Shared key scheme is preferred in order to minitechniques ILAE2E and CIL to build the TRD
mize computational overhead.
framework. We also assume each router has the capa- • Each TRD is formed by using the same shared
bility of link bandwidth control. For example, the
key and this shared key is only shared among
bandwidth of a communication link of each router
those TRD members (a subgroup of routers).
would need to be divided by using different encrypKM needs to be flexible in order to support
tion/decryption/authentication keys. While bandgroup/subgroup communication to reduce overwidth partitioning is not directly available in today’s
head caused by subgroup formation processes.
routers, this can be accomplished through the concept
The secure many-to-many group communication
of multiple virtual links due to availability of virtual
scheme presented in [8] (and briefly described
link concept in the current generation of routers; nevearlier) is such a candidate for KM.
ertheless, the actual bandwidth control mechanism
would need to be a new functionality. Thus, a subset
To build TRDs, the proposed framework ensures
of network resources, which is composed by multiple the independence among all TRDs that provide a
network links by using the same encryption/decryp- degree of survivability when a router is compromised.
tion/authentication key, will build a TRD.
That is, any single router failure of a TRD would not
The network resource management (NRM) plays affect other TRDs.
an important role in our framework to provide surFramework Evaluation. We have conducted an inivivability. It serves as a coordinating center to create or tial evaluation of the robustness of the proposed
withdraw a TRD. The traffic management (TM) framework. The evaluation results show the following
reports the network resources allocation information benefits:
to NRM and intrusion detection system (IDS)
reports the network security events to NRM. Based • Proposed framework mitigates the effect of neton the reported information, NRM makes the deciwork tomography. It can mitigate the DoS attacks
sion on creating or withdrawing a particular TRD.
caused by both outsiders and insiders; it can mitiAn efficient key management (KM) Sidebar:
needs an Figure
effi- 2.gate
the routing analysis and deliberate exposure
Feature of different preventative schemes.
cient keying scheme that can reduce the management
attacks by insiders; and finally its use of ILAP2P
THE DOUBLE
AUTHENTICATION SCHEME

j

i

The double authentication (DA) scheme

k

l

presented in [6, 7] is designed to prevent
impersonation attacks. In the DA scheme,
the flooded LSAs are individually authenticated twice by two different keys, that is,

LSAn An

LSA1 A1

LSA1

LSAn

LSU

LSU

OSPF with digital signatures RFC 2154

OSPF v2 RFC 2328

A

LSA Aik Aij

LSA Ajl Aik Ajk

Double Authentication Scheme
[6, 7]

each LSA is signed twice by every router
when it floods the LSA to its neighbor(s). Authentication codes are then appended to each individual LSA.
Shown in the figure here, node i originates an LSA. It then generates two authentication codes Aik and Aij

Features of different preventive
schemes.

by using shared key between pairs (i,k) and (i,j), respectively. After a neighbor node j receives the LSA, it authenticates the LSA based on the
second code Aij. Once the authentication is passed, node j generates two new authentication codes Ajl and Ajk by using shared key between
pairs (j,l) and (j,k). Note that the authentication code Aik is also attached with the forwarded LSA and Aik can be used to verify that node j

Huang sidebar fig 2 (11/06)

does not compromise the LSA. The presented forwarding and authenticating procedures will continue until all nodes in the network receive
the LSA. Choosing the DA scheme over other authentication schemes, such as packet-level (such as specified in RFC 2328) and information
level (such as specified in RFC 2154), is the trade-off between the consideration of security strength and computation overhead. The DA
scheme provides stronger authentication than packet-level authentication scheme but less computation overhead than the information-level
authentication scheme.

c

COMMUNICATIONS OF THE ACM November 2006/Vol. 49, No. 11

71

provides integrity and origin authentication to
prevent insiders from impersonating and forging
routing information of other legitimate routers.
• Proposed security features are added-on components and hence do not change operational functionalities of current link-state routing protocols.
For example, security extensions can be implemented using opaque option in OSPF protocol.
• The router CPU usage is usually dominated by
the length of time it takes to run the shortest
path calculation. Our comparison study shows
that the additional processing overhead for processing link-state advertisements is minimal to
shortest path calculation; furthermore, LSA processing is done at a different time than shortest
path calculations.
• Routers have the ability to handle the extra processing required for the proposed framework,
with some increase in memory requirement.
We are currently doing further work on understanding the best ways to accomplish division of
TRDs, overall network performance issues, and more
detailed robustness analysis of the overall architecture.
CONCLUSION
Network survivability has been studied extensively
from the view of node and link failures. The domain
of survivability goes beyond just the physical failures
and one needs to address this issue when faced with
security threats that can render the network logically
dysfunctional without causing any physical damage.
An intra-domain routing environment may
encounter several security threats that can eventually
make network routing susceptible to a number of
attacks. We discuss potential attacks and propose a
new secure routing framework based on security
techniques (authentication and confidentiality) for a
link-state routing protocol, applicable in an intradomain routing environment. The proposed framework emphasizes the use of efficient cryptographic
countermeasures for network survivability against
security threats to link-state routing protocols. The
framework relies on providing information-level
authentication and information-level confidentiality
that can be imbedded in link-state routing protocols
with assistance of a key management system that
uses secure group communication. Our proposed
secure network routing framework is a major step
toward providing security professionals with an
effective platform as deterrence to network attacks.
It will be worthwhile to look into the balance
between network security/performance and cost
issues (such as the cost of routers and routing proto72

November 2006/Vol. 49, No. 11 COMMUNICATIONS OF THE ACM

cols); furthermore, it will also be important to see
the results of the implementation of the proposed
framework. We leave these issues to be addressed in
future research. c
References
1. Bellovin, S.M. Security problems in the TCP/IP protocol suite. Computer Communication Review 19, 2 (1989), 32–48.
2. Chakrabarti, A. and Manimaran, G. Internet infrastructure security: A
taxonomy. IEEE Network 16, 6 (Nov. 2002), 13–21.
3. Chang, H.Y., Wu, S.F., and Jou, Y.F. Real-time protocol analysis for
detecting link-state routing protocol attacks. ACM Transactions on
Information and System Security 4, (Feb. 2001), 1–36.
4. Gupta, M. and Melam, N.S. Authentication/confidentiality for
OSPFv3. IETF Internet draft, (Dec. 2004).
5. Houle, K.J., Weaver, G.M., Long, N, and Thomas, R. Trends in
denial of service attack technology. CERT Coordination Center document, 2001.
6. Huang, D., Sinha, A., and Medhi, D. A double authentication scheme
to detect impersonation attacks in link-state routing protocols. In Proceedings of the IEEE International Conference on Communications (May
2003), 1723–1727.
7. Huang, D., Sinha, A., and Medhi, D. A key distribution scheme for
double authentication in link-state routing protocols In Proceedings of
the 24th IEEE International Performance Computing and Communications Conference (Apr. 2005).
8. Huang, D. and Medhi, D. A Key-chain based keying scheme for manyto-many secure group communication. ACM Transactions on Information and System Security 7, 4 (Nov. 2004), 523–552.
9. Labovitz, C., Malan, G.R., and Jahanian, F. Internet routing instability. IEEE/ACM Transactions on Networking 6 (1998), 515–528.
10. Moy, J. OSPF Version 2, IETF RFC 2328, (Apr. 1998).
11. Murphy, S., Badger, M., and Wellington, B. OSPF with digital signatures. IETF RFC 2154, (June 1997).
12. Papadimitratos, P., and Haas, Z.J. Securing the Internet routing infrastructure. IEEE Communications 40, 10 (Oct. 2002), 60–68.

Dijiang Huang (dijiang.huang@asu.edu) is an assistant professor
in the Computer Science and Engineering Department at Arizona
State University, Tempe, AZ.
Qing Cao (caoq@umkc.edu) is an assistant professor in the H.W.
Bloch School of Business and Public Administration at the University
of Missouri-Kansas City, Kansas City, MO.
Amit Sinha (amit.sinha@umkc.edu) is a doctoral candidate in the
Computer Science and Electrical Engineering Department at the
University of Missouri-Kansas City, Kansas City, MO.
Marc J. Schniederjans (Mschniederjans1@unl.edu) is the C.
Wheaton Battey Distinguished Professor of Business in the College of
Business Administration at the University of Nebraska-Lincoln,
Lincoln, NE.
Cory Beard (beardc@umkc.edu) is an associate professor in the
Computer Science and Electrical Engineering Department at the
University of Missouri-Kansas City, Kansas City, MO.
Lein Harn (harnl@umkc.edu) is a professor in the Computer
Science and Electrical Engineering Department at the University of
Missouri-Kansas City, Kansas City, MO.
Deep Medhi (dmedhi@umkc.edu) is a professor in the Computer
Science and Electrical Engineering Department at the University of
Missouri-Kansas City, Kansas City, MO.
Dijiang Huang’s research is supported in part by a University of Missouri Research
Board grant. Cory Beard’s research is supported in part by NSF CAREER award grant
CNS-0133605.

© 2006 ACM 0001-0782/06/1100 $5.00

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

Anonymous Certification Services
Dijiang Huang
School of Computer Informatics and Decision Systems Engineering
Arizona State University

Abstract—We present a new Anonymous Communication Service (ACS). ACS is a PKI certificate service that anonymizing
users’ identity. ACS achieves end user anonymity by using
pseudonym certificates issued to a user. The user can obtain
multiple pseudonym certificates and use them for different
transactions. A service provider, e.g., a web server, is not able to
determine the user’s real identity or profile the user based on the
user’s online transactions. We also present a revocation scheme
to identity and revoke malicious users.

way, the adversary will be unable to link different pseudonyms
to the same user based on monitoring WSP’s transactions. This
is because a user can use a new pseudonym certificate for
each transaction. ACS also provides a revocation solution to
revoke an anonymous user when he/she is identified to perform
illegal transactions. Thus ACS satisfies both the anonymity and
manageability requirements [5], [8], [9], which are essential
for any anonymous communication system.

I. I NTRODUCTION
In this paper, we construct an Anonymous Communication
Service (ACS) through an anonymized PKI approach. Using
ACS, a user needs to obtain a pseudonym certificate issued
by a CA for his/her generated pseudonym. The pseudonym
certificates are issued based on the ACS ticket obtained from a
Trusted Authority (TA). Thus, the presented solution includes
two authorities: CA and TA, and we call this trust model as a
Dual trusted architecture, which is shown in Fig. 1. The TA
is responsible for maintaining user real identity information
and issuing ACS ticket for a user to derive its pseudonym
certificate. CA is responsible for issuing digital certificates
for pseudonyms. Once the user has successfully obtained a
pseudonym certificate, he/she can establish an anonymous
communication session with a Web Service Provider (WSP) to
access the web services anonymously. In this paper, we define
a WSP transaction as a communication session initiated by a
user. For example, one purchasing action in an online store can
be a transaction. Thus, the anonymity discussed in this paper is
scaled at the transaction level, i.e., the attacker cannot identity
two purchasing actions from the same user. Apart from generating pseudonym certificates, dual trust architecture provides
one major advantage over the current PKI system, i.e., the real
identity and pseudonyms of the user are managed by different
authorities, thus compromising any single authority will not
linking the a user’s identity to its anonymized actions.
As described by Pfitzmann and Kohntopp, in [8], there
are three types of anonymity: sender anonymity, receiver
anonymity, and unlinkability of a sender and its receiver.
Sender anonymity means that the identity of the party who
sends a message is hidden, however the receiver identity may
not be hidden. In ACS, we achieve the sender anonymity with
the primary goal of restricting the WSP from profiling a user.
Since a web server is usually public know, thus ACS is not
designed for achieving the receiver anonymity. Unlinkability
of a sender and its receiver is achieved based on the following
assumption: ACS is deployed on a large scale, in which the
system involves a large number of anonymous users. In this

1. Identity is known to TA
2. Pseudonym is unknown to TA
3. Pseudonym is known to CA.
4. Identity is unknown to CA.

TA

(1)

(2)

(3)

CA

User
Anonymous
Communication

Fig. 1.

(4)

Trust model of ACS.

We must note that the anonymity provided by ACS is
subjected to few constraints similar to those discussed by
Reiter in Crowds [10]. For example, under the scenario when
the content of web transaction involves exchange of user
identity details (i.e., if the user submitted his real name, credit
card details to the WSP during an e-commerce), then the
sender anonymity cannot be achieved by ACS. Also in the
scenario when the user downloaded some executable web
content such as an ActiveX control or a Java applet, which
establishes a direct connection from the end user to a web
server, anonymity may not be provided by ACS. Moreover,
if a user performs all transactions through the same machine
using a static IP address, the WSP can profile the user based
on the peer computer’s IP address even if the user change its
pseudonym certificates for each transaction. This problem can
be mitigated if we use Tor [6] or other Mix networks [3], [7],
[4] to establish an anonymous network layer.
The rest of this paper is arranged as follows: Section II
presents an overview of ACS system and its design goals. In
Section III, we describe the ACS protocols; the performance
assessments and security analysis are given in Section IV.
Finally, we conclude our work in Section V with future
research issues.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

II. S YSTEM AND M ODELS
Following notations will be used throughout this paper:
• IDa or a, the real identity of the user.
th
• Ci , the i
certificate authority in the system.
• TA, the trusted authority in the system.
1
• ((PT , ST ), (PCi , SCi ) and (Pa , Sa ))
are the public/private key pairs of TA, Ci , and user a, respectively.
• H, a hash function.
• r, a random variable generated by the TA.
• , concatenation operator.
• P Na , a pseudonym generated by user a
c
• Npc , Npc , the maximum number of pseudonym certificates and the number of remaining pseudonym certificates.
• Cert(Ci )→P Na , the certificate issued by the CA Ci to the
pseudonym P Na .
• T icketa , the ACS ticket issued by TA to the user a.
• Ta , TT , and TCi , the time stamp of originated by the user,
trusted authority (TA), and ci , respectively.
A. Trust Models

TA

Ticket Request

Ticket

Pseudonym
Certificate
request

Pseudonym
Certificate
request

CA1

Usera
Cert(CA2 ->PN1)

CA2
Cert(CA2 ->PN1)

Transactions using
pseudonym certificates

WSPs

Fig. 2.

Trusted Authority (TA): is responsible for authenticating
the user based on the real certificates. TA also issues
a ticket to the user that is later used for generation of
pseudonym certificates.
• Certificate Authorities (CAs): are the trusted authorities
responsible for issuing pseudonym certificates to the users
for their chosen pseudonyms based on the primary ticket
issued by the TA.
• Web Service Providers (WSPs): provide general web
services. A WSP can be malicious and is interested in
disclosing users’ transaction history.
A user in ACS system is assumed to have a identity (or
original) certificate. By identity certificate we refer to a digital
certificate issued in the real name of the user by the TA. For
a user to obtain a pseudonym certificate, the user has to use
his identity certificate to obtain a ticket from the TA. A ticket
is defined as a document signed by the TA for the user. The
ticket also specifies the number of pseudonym certificates that
a user can obtain. Thus a user can obtain multiple pseudonym
certificates based on a single ticket. However, the ticket does
not contain any information that will reveal the users’ real
identity to the CA.
Once the user obtains a ticket, the user generates a
pseudonym and a public/private key pair. The user sends the
ticket and the pseudonym with the public key to the CA.
CA verifies the ticket details with the TA and then issues the
pseudonym certificate to the user if the verification is passed.
Note that, during the verification procedure, the user does not
have to provide any identity details or private information to
the CA. However, the user has to perform a challenge-response
with the TA to prove that the ticket being used belongs to
the user and not to any another user. This challenge-response
prevents impersonation attacks that will be discussed later.
Another important property provided by ACS is that the real
identity and related pseudonyms of the user are managed by
separate trusted authorities. Thus, compromising the TA or
a CA will not breach the pseudonymity of the user. This
means that the attacker cannot link a transaction to the user’s
real identity. Additionally, each of the pseudonym certificates
issued to the user has a validity period (or expiration date).
•

System Model.

ACS provides sender anonymity to users using pseudonym
certificates. ACS system comprises of four main parties: users,
certificate authority (CA), trusted authority (TA), and web
service provider (WSP). The relationship between different
participants in ACS system is presented in Fig 2. In an large
ACS system, there can be multiple TAs and CAs. Without
loss of generality, we only assume that there exists one TA
and multiple CAs in the system to simplify the presentation.
The definition and functionality of each participant can be
described as:
• Users: who wish to access services of an WSP or
communicate with another user anonymously.
1 where public/private key equals to (g T modN, T ), (g Ci modN, C ) and
i
(g x modN, x) for TA, CA and User.

B. Attack Model
The attacks can be a WSP, eavesdroppers, and the curious
TA or CAs. The primary goal of malicious users is to link
the user pseudonyms to the user’s real identity based on the
user’s web transactions with the WSP. We assume that the TA
and CAs do not collude to mapping users’ actions to their
identities. Both TA and CAs are curious in that they perform
normally as specified by the ACS protocols, but curious about
linking web transactions to a user. An attacker can also launch
a replay attack to waste user resources (i.e., ticket). Finally
an attacker may attempt to impersonate a user to obtain a
pseudonym certificate and perform illegal web transactions.
III. ACS P ROTOCOLS
The ACS includes 3 sub-protocols. They are:

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

Certificate
Authority (C k)

Trust Authority
(TA)

User ‘a’
M1
M2

5) TA creates an ACS ticket for the user a. The content of
ticket are as follows:
T icketa = [T A, H Npc (IDa r), Npc , TT , SigT A ]

M3
M4

where

M5b
M5c
M5a/M5d
M6

Fig. 3.

Ticket and certificate issuing protocols.

Protocol 1: Ticket issuing protocol.
Protocol 2: ACS pseudonym certificate issuing protocol.
• Protocol 3: Revocation Protocol.
The presented protocols are summarized in Fig. 3. In the
following sections, we describe each of these protocols in
detail.
•
•

A. Ticket issuing protocol
The purpose of the ticket issuing protocol is to issue an
ACS ticket to the user. In Table I, the ticket issuing protocol
is presented from S1 to S2.
TABLE I
M ESSAGES EXCHANGED IN ACS.
S1.
S2.
S3.
S4.
S5a.

S5b.

a → TA :
TA → a :
a → Ck :
Ck → T A :
c
If Npc
=0
T A → Ck :
c
If Npc
!=0
TA → a :

M1
M2
M3
M4

=
=
=
=

[reqa , CertID ]
[T icketa ]
[P N1 , PP N1 , T icketa , Ta ]
[Npc , H Npc (IDa r), TCk ]

M 5a = [H Npc (IDa r), 0, TCk + 1]
then Request is denied

M 5b = [Npc , EPa (H Npc −1 (IDr)), TT +
1]
a → T A:
M 5c = [EPT (H Npc −1 (IDr)), TT +
1]
S6.
T A → Ck :
M 5d = [H Npc (IDa r), 1, TCk + 1]
CAk → a :
M 6 = [Cert(Ck )→P N1 , Ta + 2]
S7.

If the request is denied, the TA will inform both CA and the user.
∗
Ta , Tt , and TCk are the time stamps of user a, TA, and the CA, respectively.

The ticket issuing protocols is described as follows:
Protocol 1: Ticket Issuing Protocol
1) User a sends M1 = [reqa , CertID ] to the TA, where
reqa is a specification on certificate service requested by
the user and CertID is the real (or original) certificate
of the user a.
2) On receiving M1, TA checks the user certificate using
the public key of the trusted authority who issued this
certificate to the user.
3) On successful verification, TA generates a random
number r; determines Npc (the maximum number of
pseudonym certificates) and calculates H(IDa r).
4) TA recursively calculate the hash value H(IDa r), Npc
times and stores the mapping mapT A = H(IDa r),
c
 in TA’s database.
H Npc (IDa r), CertID , Npc , Npc

SigT A = HEST [T A, H Npc (IDa r), Npc , TT ]
is the signature signed by TA, TT is the TA time stamp.
6) TA creates a message M2 = T icketa and sends to the
user a.
Again to specify here we assume that every user already has
a real certificate CertID . When a user sends message M1
to TA, the TA verifies the certificate and establishes a secure
channel with a user using a shared key. One basic method
for authenticating the user is that the TA can encrypt the
shared key with users public key (obtained from CertID ) and
send it to the user. If user is the real owner of the certificate,
then the user can successfully decrypt the shared key and can
establish the secure channel with the TA. Once this channel
is established, all the messages exchanged between user and
TA takes place on this secure channel. Thus we can safely
assume that no eavesdropper can listen to this channel and
obtain messages exchanged between the user and TA.
The ticket is signed with TA’s private key to ensure that
the user himself cannot modify the ticket. The maximum
number of pseudonym certificates for which this ticket is valid
is Npc . TA assigns the Npc to the user. TA also maintains
c
as the number of remaining pseudonym certificates
the Npc
of the user. For a ticket that hasn’t been used once for
c
equal
generating pseudonym certificate, will have value of Npc
to Npc . With every pseudonym certificate issued to the user
c
c
is reduced by one. When Npc
for T icketa , the value of Npc
reaches zero, the T icketa becomes invalid and a new T icketa
has to be issued to the user a. Note that the T icketa and all
the pseudonym certificates issued for T icketa have the same
validity time stamp as of the real certificate of the user.
B. ACS Certificate Issuing Protocol
In Table I, the pseudonym certificate issuing protocol is
presented from S3 to S8. After deriving the T icketa using
protocol 1, the user can now obtain the pseudonym certificate
by executing protocol 2.
Protocol 2: Request ACS Certificate
1) Generates a pseudonym P N1 .
2) Generates public/private key pair as (PP N1 , SP N1 ) =
(g xγ1 Npc , xγ1 Npc ) where γ1 is the random number
generated by the user for pseudonym P N1 .
3) Creates the request message M3 and send it to CA, Ck
M 3 = [P N1 , PP N1 , T icketa , Ta ]
Ck on receiving M3, collaborates with user a and TA to
execute protocol 3.
Protocol 3: Certificate Issuing Protocol
1) On receiving M3, Ck extracts Ta and the T icketa .
2) Ck verifies the T icketa using TA’s public key.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

3) After T icketa verification, Ck extracts the Npc ,
H Npc (ID| r) and creates M4
M 4 = [Npc , H Npc (IDa r), TCk ]
CA sends M4 to TA over a secure channel2 where TCk
is the time stamp of Ck .
4) On receiving M4, TA verifies H Npc (IDa r) in the
c
asmapT A . If verified, TA checks the value of Npc
sociated with mapT A and performs one of the two
operations:
c
• If Npc = ’0’, then TA sends
M 5a = [H Npc (IDa r), 0, TCk + 1]

•

to Ck which implies that the T icketa has expired
and no more pseudonym certificates should be issued.
c
If Npc
!= ’0’, TA calculate H Npc −1 (IDr), encrypts it using public key (Pa )of the user and send
message M5b to the user.
M 5b = [Npc , EPa (H Npc −1 (IDr)), TT + 1]

5) On receiving M5b from the TA, the user decrypts the
hash value using his/her private key Sa ; encrypt it again
using TA public key Pt ; creates and send message M5c
back to the TA.
M 5c = [EPT (H Npc −1 (IDr)), TT + 1]
6) TA on receiving M5c, decrypts the message and compares the hash value with the value in message M5c. If
c
by one and sends message
it matches, TA reduces Npc
M5d to CA Ck .
M 5d = [H Npc (IDa r), 1, TCk + 1],
Which informs the CA that the ticketa is valid and that
the pseudonym certificate can be issued to the user.
7) When Ck receives M5d, Ck signs the pseudonym certificate for the pseudonym P N1 and sends it back to the
user in message M6
M 6 = [Cert(Ck )→P N1 , Ta + 2]
8) Ck
stores
the
mapping
mapCA
=
T icketa , Cert(Ck )→P N1  into its database.
By performing protocols 2 and 3, the user can obtain a
pseudonym certificate for his/her self generated pseudonym.
Once the user has obtained the pseudonym certificate, the
user can perform anonymous communication with any WSP
in the system. Every service provider accepts the pseudonym
certificate as they are issued by the trusted authority of the
system. To exchange data with the anonymous user, the WSP
can use the public key (available on the pseudonym certificate)
to encrypt the data and sent it to anonymous user. Only the
user with correct private key can decrypt the data received
2 As TA and CA knows each other public key, the can setup a secure channel
using any key sharing scheme

from the WSP. Using above protocol, the user can obtain the
c
Npc pseudonym certificates using T icketa . The value of Npc
is reduced every time the user obtains a pseudonym certificate.
In above protocol (step 4), the TA recursively calculates the
H(IDr), Npc − 1 times. TA can also store these values with
the mapping mapT A as the Npc value will not be very high
or can generate them on the fly. Every time the user requests
a pseudonym certificate, the TA sends one lesser hash value
to authenticate the user. The user cannot self generate these
hash values as the value r is unknown to the user. Thus we
can conclude that a user cannot self generate the ticket.
From all the protocol discussed above, Protocol 1 is only
required when a user enters the ACS system for the first time
or when the T icketa has expired. Table I summarizes the
messages transferred during protocol 1, 2 & 3. Next we discuss
the revocation procedure.
C. Revocation Protocol
Revocation is absolutely mandatory to provide manageability property to the trusted authorities of the system. When a
user performs an illegal operation using any one pseudonym,
it becomes absolutely necessary to revoke the user. When a
user is revoked, all other pseudonyms associate with the user
should also be revoked. Revocation of all pseudonyms prevent
user from accessing the system resources and performing
anonymous communication with the WSP’s of the system.
For example, if a user has ten pseudonyms and performs any
illegal activity with pseudonym P N1 , then all ten pseudonyms
of the user must be revoked to prevent the user from further
communicating with other participants in the system. Also
revoking the real identity is necessary to prevent the user from
obtaining new ACS tickets from the TA. If the user’s real
identity is not revoked, the user can obtain a new ACS tickets
for the TA and can obtain new pseudonym certificates from
CAs.
Our proposed ACS revocation protocol utilizes a revocation
list RL. It is required that before performing communications
with any anonymous user in the system, every WSP checks
the revocation list for the revoked pseudonym and pseudonym
certificate. If the peer’s pseudonym is found in the revocation
list, the communication should be abandoned. Also the revocation list is consulted by TA’s and CA’s periodically in case any
user’s real identity or other pseudonym certificates have to be
revoked. When a illegal transaction is performed, the victim
authority notifies the revocation authority RA of the security
breach. RA is responsible for maintaining the revocation list
RL and monitoring that the revocation protocol is followed
correctly by all the involved parties. It is the responsibility
of the RA to ensure that a genuine user is not revoked and
the information provided by all parties during the revocation
procedure is authentic. The revocation protocol is as follows:
Protocol 4: Revocation Protocol
1) When user ’a’ has to be revoked, the victim notifies the
RA of the security breach.
2) RA obtains the pseudonym certificate from the victim
and publishes it on the RL.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

3) Following step 2, RA queries the CA who issued the
pseudonym certificate.
4) CA looks-up the mapping mapCA and provides RA
with T icketa that was used for generating pseudonym
certificate.
5) RA publishes T icketa on the revocation list RL and
approaches the TA.
6) All the CAs consult the RL periodically and if any CA
has issued the pseudonym certificate to the user, it adds
the pseudonym certificate to the RL. This procedure
results in revocation of all pseudonym certificate of the
user.
7) TA also consults the revocation list and looks-up the
mapping mapT A to extract the user’s real certificate
whose T icketa has been revoked. The real identity
certificate of the user is appended to the RL, thus
leading to revocation of user real identity as well.
Using revocation protocol an WSP can prevent an anonymous
user from performing illegal operations. We assume that before
the communication starts, the WSP has verified the pseudonym
certificate of the user and has already established a secure
channel. Thus the WSP knows that a user is accessing the
services but cannot link the activities to the real identity of
the user. Moreover, as the user can use different pseudonyms
with the same WSP, profiling of the user is not a trivial task.
IV. P ERFORMANCE A SSESSMENTS
In this section we describe the anonymity provided to the
user in an ACS system. We also present the security analysis
and evaluate the performance of the protocols used in ACS.
A. Anonymity
As discussed above, ACS provides anonymity to the user
on the basis of pseudonym certificates. The user initiates a
service request from the service providers. Thus the user can
be considered as the sender and the service provider as the
receiver. ACS provides anonymity to the user against the
following:
• Service Providers (WSP) seeking to profile user based on
the users transactions and link multiple transaction to the
same user.
• Adversaries are the attackers aiming to compromise user
real identity by compromising trusted authorities or the
databases storing user information. An adversary also
seeks to waste user resources (ticket) and/or impersonate
the user, to perform malicious activities on the users’
behalf.
It is assumed that every attacker works at full capability
and utilizes all the resources available to compromise user
anonymity. ACS can provide the flexibility to the user using
different pseudonyms and pseudonym certificates for different
transactions. For example, suppose a user wish to store some
document with W SP1 . The user approaches W SP1 with the
pseudonym certificate. W SP1 authenticate the user by performing a challenge-response with the user. W SP1 encrypts
the challenge using public key (present in the pseudonym

certificate) and send it to the user. If user can successfully
decrypt the challenge (using private key corresponding to the
public key) and reply W SP1 with the correct response, the
user is authenticated. The user can then store the document
with W SP1 without losing his/her anonymity. Thus during
the authentication procedure, as the user did not provide any
private information to the service provider, it is very difficult
for the WSP to profile the user. If at later time, the same
user wishes to read the contents of the documents stored with
W SP1 , the user can again approach W SP1 with a different
pseudonym and pseudonym certificate. Although W SP1 will
be able to authenticate the user and provide access to the
document, W SP1 will fail to determine that this is the same
user who stored the document. An WSP can only profile a user
pseudonym if and only if the user uses the same pseudonym
and pseudonym certificate for multiple transactions. Based on
this discussion, we can state following lemma without proof.
Lemma 1: A service provider or an adversary cannot profile and link multiple transactions performed by the same user,
thus achieving sender-receiver unlinkability.

For an adversary to compromise user’s real identity and
link pseudonyms to the real identity, the adversary has to
compromise both the trusted authorities - TA and CA simultaneously. For a practical communication system it can be safely
assumed that both trusted authorities cannot be compromised
simultaneously. This can be easily proved using Lemma 3.
B. Security Analysis
In this section, we discuss possible attacks that can be
launched against the participants of the ACS and the resilience
offered by ACS protocols under these attacks. As addressed
in Lemma 1, ACS prevents the adversaries from linking user
activities together. The dual trust architecture3 provided by
ACS, splits the users’ real and anonymous identity among
two different trusted parties (TA and CA) whose simultaneous
compromise can be considered difficult in a real world scenario. Now we discuss possible attacks that can be launched
against different participants of the system.
Replay attack on the user: A user obtains a ticket from the
TA by providing his/her real identity information. The ticket
specifies the maximum number of pseudonym certificates the
user can obtain from the different CAs. In ACS, all the
messages contain a time stamp denoted by Ta , TT , and TC that
are initiated by the user a, TA, and CA, respectively. The timestamp restricts the adversaries from launching replay attacks
by replaying the user ticket.
Profiling attack on user: Profiling attack cannot be launched
against the user as discussed in Lemma 1
Impersonation attack: An adversary can attempt to impersonate any participant of the system. However, an adversary
cannot impersonate the TA or CA as they are publicly known
authorities. An adversary can attempt to impersonate a user
and obtain a pseudonym certificate for the user ticket. However, such an attack will not be successful. Reason being that
3 where the real identity of a user is maintained by the TA and the
pseudonyms by the CA’s

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

before any authority issues a ticket or pseudonym certificate, a
challenge-response is performed with the participant claiming
the certificate or the ticket. Thus even if an adversary can
successfully obtain a ticket, the adversary cannot impersonate
as the user to obtain the pseudonym certificate. Hence we state
the following lemma.
Lemma 2: Any adversary cannot impersonate the user to
obtain a pseudonym certificate. (Proof sketch is in Appendix)

C. Protocol Assessment
Based on the presented protocols, we state the following
lemmas:
Lemma 3: ACS system cannot fulfill anonymity requirements if and only if both TA and CA are compromised
simultaneously.(Proof sketch is in Appendix)

Apart from anonymity requirement, the manageability requirements are satisfied by the revocation protocol discussed
in section III-C.
V. C ONCLUSION
In this paper we proposed a new Anonymous Communication Services (ACS) system with several advantages over
existing systems. We introduced a dual trust architecture that
allows ACS users’ identities and pseudonyms to be managed
by separate trusted authorities. A user in ACS can obtain
multiple pseudonym certificates for a single ticket and can use
different certificates for different anonymous communication
sessions. To compromise the users’ identity or to link multiple
transactions to an anonymous user, the adversaries must compromise two trusted parties simultaneously which is assumed
to be as a non-trivial task in real world scenario. ACS also
provides a revocation mechanism which allows trusted authorities to collaboratively revoke misbehaving users’ pseudonyms
and real identity. This property is important to provide admissibility and manageability which are critical issues for
an anonymous communication system. There are still several
research issues that require further investigation:
• How to extend the single TA ACS to multi-TA ACS?
• It is interesting to consider integrating our solution with
the anonymous certificate chain solutions proposed by
Zhang and Shi [11].
• During the revocation procedure, we can identify which
CA has provided ACS certificates to the user. However,
we cannot identify if the malicious CA has provided a
genuine user pseudonym from the revocation.
R EFERENCES
[1] www.trustcenter.de/en/.
[2] www.verisign.com.
[3] D.L. Chaum. Untraceable electronic mail, return addresses, and digital
pseudonyms. Communications of the ACM, 24(2):84–88, 1981.
[4] C. Diaz and B. Preneel. Taxonomy of mixes and dummy traffic.
Accepted submission at I-NetSec04: 3rd Working Conference on Privacy
and Anonymity in Networked and Distributed Systems. Kluwer academic
publishers, August, 2004.
[5] C. Dıaz, S. Seys, J. Claessens, and B. Preneel. Towards measuring
anonymity. Privacy Enhacing Technologies (PET 2002). SpringerVerlag, LNCS, 2482, 2002.

[6] Roger Dingledine, Nick Mathewson, and Paul Syverson. Tor: The
Second-Generation Onion Router. In Proceedings of the 13th USENIX
Security Symposium, August 2004.
[7] D.M. Goldschlag, M.G. Reed, and P.F. Syverson. Hiding Routing
Information. Information Hiding, R. Anderson, ed., LNCS, 1174:137–
150.
[8] A. Pfitzmann and M. Kohntopp. Anonymity, Unobservability, and
Pseudonymity-A Proposal for Terminology. DIAU00, Lecture Notes in
Computer Science, pages 1–9, 2009.
[9] Andreas Pfitzmann and Marit Hansen. Anonymity, unlinkability, unobservability, pseudonymity, and identity management - a consolidated
proposal for terminology. Working draft, avaliable at http:// dud.inf.
tu-dresden.de/ literatur/ Anon Terminology v0.26.doc, September 2005.
[10] M.K. Reiter and A.D. Rubin. Crowds: anonymity for Web transactions.
ACM Transactions on Information and System Security, 1(1):66–92,
1998.
[11] N. Zhang and Q. Shi. Anonymous public-key certificates for anonymous
and fair document exchange. Proc-Commun, 147(6), 2000.

APPENDIX
Proof Sketch: (Lemma 2) Suppose an adversary was successful in obtaining the T icketa of the user. To obtain a
pseudonym certificate, the adversary generates an pseudonym
P Ni and the associate public/private key pair (PP Ni , SP Ni ).
Following that, the adversary sends message M3 (protocol 1,
step 3) to Ck for generation of the pseudonym certificate.
Ck after verifying the T icketa using TA public key Pt ,
sends message M4 to TA. TA lookup its mapping table and
c
> 0, TA sends M5b to the user. If the genuine
if Npc
user receives M5b, the user can simply deny any pseudonym
certificate generation request. Even if the adversary was able to
bypass the message M5b before it was received by the user, the
adversary will be unable to decrypt the message. As message
decryption require users’ private key Sa which is not available
to the adversary, the adversary will be unable to generate M5c
which satisfies the verification at step 6, protocol 3. Similarly,
if the adversary simply replays the ticketa , it cannot do any
harm to the user as no new pseudonym certificate will be
issued without verification. Thus lemma 2 is proved.

Proof Sketch: (Lemma 3) The anonymity properties i.e.,
unidentifiable and non-profiling cannot be achieved only under
the scenario when both TA and CA are compromised. We can
safely assume that both TA and CA cannot be simultaneously
compromised in real world scenario. The reason for such
assumption is that in the real communication system, the
trusted authorities are big organizations and it is difficult for
an adversary to compromise them. For example, assume that a
user already have a digital certificate issued from VeriSign [2].
User also approach VeriSign to obtain ACS ticket. Thereafter,
the user approaches TrustCenter [1], another certificate issuing
authority to obtain pseudonym certificate. As these two are
big organizations it is extremely hard for an adversary to
compromise them and obtain user identity information. Even
if we assume that VeriSign is attacked and the database
containing user information is compromised (although any
such instance has not been reported yet), it is not possible for
an attacker to compromise TrustCenter as well. Thus we can
prove the Lemma by assuming that the anonymity property
will only be lost if both VeriSign and TrustCenter (in this
example) are compromised simultaneously.


978-1-4244-5638-3/10/$26.00 ©2010 IEEE

2013 IEEE Wireless Communications and Networking Conference (WCNC): SERVICES & APPLICATIONS

A Cloud based Dual-Root Trust Model for Secure
Mobile Online Transactions
Li Li1 , Dijiang Huang2, Zhidong Shen1, Samia Bouzefrane3,
Wuhan University, P. R. China, Email: {lli, shenzd}@whu.edu.cn
2 Arizona State University, U.S.A., Email: dijiang@asu.edu
Conservatoire National des Arts et Métiers, France, Email: samia.bouzefrane@cnam.fr
1

3

Abstract—With rapid growth of mobile devices and the emergency of mobile cloud services, it is a trend to use mobile
devices for mobile-centric applications, and expand the mobile
capabilities and provide needed security by mobile cloud services.
However, due to the mobility of the device and the semitrust of the mobile cloud, how to build trust in the mobile
applications is a big concern. In this paper, we propose a
dual-root trust online transaction model that provides a dualroot trust model including both the user’s mobile device and a
delegation mobile cloud. We design a dual-root trust protocol
by leveraging a modified CP-ABE cryptography and the trust
execution environment embedded in a mobile device to provide
device-specific transaction confirmations for online transactions
initiated by the mobile user. The performance evaluation of the
protocol demonstrates that it is a lightweight scheme for mobile
devices since most cryptographic functions are delegated from
users to the mobile cloud.

I. I NTRODUCTION

is not a simply two-factor authentication solution and it is
different from traditional two-factor authentication approaches,
e.g., using SMS as a second authentication approach [6] and
security RSA ID tokens [7], in that DRT natively incorporates
policy-enforcement by using attribute-based cryptography [8],
in which transaction contents and users’ roles can be verified
during the online transaction verification procedure. Thus,
DRT provides a more flexible policy-based dual-root verification model. Moreover, DRT may rely on recent developed
Trusted Executive Environment (TEE) approaches, such as
[14], [9], [10], to develop the trust root functions on mobile
devices to deal with compromised mobile OS. This requires
the mobile trust root functions must be efficient due to limited
hardware support of TEE components such as a smartcard. In
summary, the presented DRT scheme achieves the following
contributions: 1) a new dual-root trust model considering both
mobile devices and clouds as trust roots; 2) a policy based
online transaction verification procedure; and 3) an ABE-based
computing delegation model that allocates minimal computing
overhead on mobile devices.
The presented performance evaluation study demonstrates
the security strength against untrusted participants impersonating system participating entities (i.e., mobile devices,
clouds, and service providers), and the presented computation
overhead analysis shows the practicality of the DRT scheme
considering the execution on resource constrained mobile
devices.
The rest of the paper is organized as follows. Section II
describes the related work. Section III outlines the system and
assumptions for the proposed scheme. Section IV presents
detailed Dual-Root Trust Scheme. Section V analyzes the
proposed DRT scheme. We conclude the paper in Section VI.

As the world becomes more interconnected, integrated and
intelligent, mobile devices are playing ever-increasing roles in
changing the ways that people live, work and communicate.
Then mobile devices become an ideal platform for carrying
identity credentials and using them for logical access and
online transactions [1]. Unfortunately, mobile devices are
prone to loss and theft due to their small size and highportability [2]. Attackers may compromise data stored on a
mobile device or launch transactions using credentials stored
in mobile devices.
With the emergency of cloud-based service models, e.g.,
[3], [4], building the credential platform for mobile devices in
the cloud has become a natural choice for mobile applications,
e.g., Google Wallet [5] that considers the cloud is fully trusted.
However, it is necessary to address critical security issues
of mobile applications that rely on both mobile devices and
clouds, such as how to make sure the cloud will not launch
II. R ELATED W ORK
transactions on behalf of users without users’ acknowledgements and how to assure that it is the right user using the
Filyanov A. et al. [11] designed a secure transaction conright device to launch transactions when online transactions firmation architecture called UTP that provides assurance to
a remote server that the user of a client system has indeed
fully trust mobile devices or clouds.
To address the above-described issues, we present a Dual- confirmed a proposed action. The ”just one device” transaction
Root Trust (DRT) scheme to secure mobile online transactions confirmation is similar to our device-specific confirmation, but
by considering both mobile devices and clouds as semi-trusted, UTP provides more assurance to service providers than to
and they need to work together as the verification parties of client users since the feedback available to client users remains
mobile online transactions. DRT requires secure actions from susceptible to manipulated by malwares. E-EMV [12] is a
both mobile devices and the cloud, i.e., none of parties can software-based credit card application to secure transaction
individually process and confirm an online transaction. DRT confirmation. TruWalletM [13] uses M-Shield [14] on a mobile
978-1-4673-5939-9/13/$31.00 ©2013 IEEE
4404

2

phone to protect login credentials of a user and invoked only
during login. Nokia’s onBoard Credentials project explores an
open credential platform and using ARM TrustZone [9] as a
platform for the prototype [15], but there is no transactions
considered based on the platform. M. Nauman et. [16] proposed extensions to the OAuth protocol to provide ”devicespecific” authorization for native applications on TPM based
smartphone platforms, and also did not consider transaction
confirmations. There is no mobile cloud involved in these
schemes that limits the computation ability of the resource
constrained device.
Tassanaviboon and Gong [17] proposed an authorization
scheme named AAuth using a modified CP-ABE to provide
end-to-end encryption and tokens to enable authorization by
both authorities and owners. Compared to our scheme, AAuth
can only provide authorization for tokens and the computations
is much heavier if the client is a resource constrained mobile
device.
Krautheim [18] proposed the Private Virtual Infrastructures
that represents a new cloud management model, and shares
the responsibility of security in cloud computing between the
service provider and the client. This dual root infrastructure
assumed changes to the IaaS, while we focus on building
trusts between parties involved in an online transaction in the
application level.
III. DRT S YSTEM

etc. Keeping these private information on mobile devices is
insecure and executing cryptography operations on credentials
in the mobile device is power consuming.
To solve the problem, we propose a mobile transaction
system model as shown in Fig. 1. Mobile users delegate data
and credentials to the mobile cloud but make device-specific
confirmations to all mobile online transactions launched in the
device. This requirement needs mobile users to be involved
as a human-in-the-loop solution to prevent adversaries from
deploying mobile online fraud transactions. As a result, the
DRT requires two trusted roots: (a) a security element on each
mobile device, and (b) a cloud-based supporting system.
To achieve the described DRT design requirements, we
have the following assumptions: 1) Each mobile device used
in the scheme is equipped with a hardware-based trusted
execution environment (TEE) that provides: (a) isolated and
integrity protected execution of trusted codes, and (b) secure
storage for secrets. We assume that attackers cannot bypass the
security mechanism of the TEE to get the user’s credential to
perform the user-in-the-loop security operations described in
the DRT protocol; 2) There is a dedicated virtual machine
providing storage, networking, and computing resources for
mobile devices in the mobile cloud; 3) Service providers and
the Mobile Cloud set up SSL/TLS security channels to protect
inter-communications. All secrets preinstalled in the system
from the TA are protected through a secure channel.

M ODELS FOR M OBILE O NLINE
T RANSACTIONS

AND

B. DRT System Components
ĂĂ

Service Provider
( Medical
Institution )

There are five following major system components in the
presented DRT system model as shown in Figure 1:

Service Provider
( Software
Dissemination
Server )

•
•

Services Provider
( Financial Service
Center )

Uersÿattributes and
credentials ( email, addresses,
credit/debit card accounts, etc.)
for different applications.
Hosts VMs for SMDs
Mobile Cloud

DTA
Credential Issuing
& revocation

Trusted Authority
(TA)

Fig. 1.

DTA

Services Provider
Transactions

User

•

Smart Mobile Device
( SMD )

System models for DRT.

A. DRT System Design Requirements and Assumptions
In the presented DRT protocol running environment, a
smart device may be used for different device-specific online
transactions. For example, users request to download software
from a software dissemination server, remotely log into servers
to access business files, or launch an online payment. In
the private-business mixed transactions environment, mobile
users may have many credentials such as online IDs, billing
and delivery addresses, credit card information, secret keys,
4405

•

•

Trusted Authority (TA): A TA is a trusted party to generate
secrets key for DRT participants.
Samrt Mobile Device (SMD): Each SMD used in DRT
is equipped with a hardware-based TEE. Secret keys
should be preinstalled in the TEE and only if with
correct password, can the TEE authorization procedure
be initiated and corresponding secret keys be used. There
is a unique device identity (e.g., International Mobile
Equipment Identity – IMEI) that is stored in the ROM
of each mobile device.
Mobile User: A user is the owner of a SMD. The
user authenticates himself to a SMD with traditional
username/password and launches transactions through
applications in the SMD. There is a binding between the
user and her SMD. If the user lost her SMD, the binding
can be broken.
Mobile Cloud (MC): The MC provides secure storage
and computational services to users, and provides management of credentials stored in the cloud. Data in the
MC should be managed under an access control policy.
Due to page limits, we do not discuss the details in this
paper on how to implement secure storage and access
control scheme in the MC.
Service Provider (SP): An SP provides services to mobile users. SPs can be authenticated through traditional
certificates, e.g., using SSL certificates by the MC.

3

TABLE I
C RYPTOGRAPHIC NOTATIONS USED IN THE DRT.

C. Adversary Model
Adversaries attacking the DRT system can be both external
and internal attackers. Attackers have complete control over
the network among DRT participants. No entities in DRT
trusts the others but trusts the protocol. Internal attackers who
are working for services providers or the MC can get access
to mobile users’ private data (although data in ciphertext
or protected). They are interested in launching fraudulent
transactions illegitimately on behalf of users. Mobile device
may be lost. Users may launch transactions using others’
device.

Notation
auI

Description
An attribute specific to the device, e.g., IMEI.
Au = {auI } ∩ {aui |i = 1, ..., j},
where aui are attributes to describe the user that stored in the MC.
As = {asi |i = 1, ..., k} includes attributes to describe the SP,
and there is one attribute denoted as asI ∈ As
that will be discussed later.
ru ∈ Zp , a random number generated by the TA for each user.
rs ∈ Zp , a random number generated by the TA for each SP.
SKu = hDu = g(α+ru )/β ;
∀aj ∈ Au : Dj = gru × H(aj )rj , Dj′ = grj i,
where Du is stored in the SMD,
and Dj and Dj′ are stored in the MC.
SKs = hDs = g(α+rs )/β ;
′
∀ak ∈ As : Dk = grs × H(ak )rk , Dk
= grk i,
and SKs is stored in the SP itself .
a ∈ Zp is a random number generated by the TA for each device,
and stored in the SMD.

Au
As
ru
rs
SKu

SKs

D. Attribute-Based DRT Cryptography System

a

The DRT’s crypto system is designed based on the Ciphertext Policy Attributed-Based Encryption (CP-ABE) [8]
scheme. CP-ABE uses the bilinear pairing that is a bilinear
map function e : G0 × G0 → G1 , where G0 is an addition
group and G1 is a multiplicative cyclic group. The Discrete
Logarithm Problem (DLP) on both G0 and G1 are hard.
Pairing has the Bilinearity property:
e(P a , Qb ) = e(P, Q)ab ,

SMD
TEE

4. n1, transinfo

3. n1, transinfo, REQ-userinfo

Request token
token
5. token, transinfo
6. user attributes, nM
8. Partial decrypted {n2+1, nM, sk}

Requests
decryption

ġ

7. Encrypted {n2+1, nM, sk}

9. {transinfo, n2, aaI}sk, nM+1
10. {transinfo, n2, aaI}sk

ġ

as2

...

...auI

ġ

asI
An attribute that
is specific to an
SP.

au1

au2

...

An attribute
that is specific
to the device.

the userÿs attributes
(b) attributes tree Tu of a user
binded to an SMD

(a) attributes tree Ts of an SP

Fig. 2.

SP

2. Encrypted REQ-trans, userID

{n2+1, , nM, sk}

TSP-r

as1

MC
1. REQ-trans

∀P, Q ∈ G0 , ∀a, b ∈ Z∗p .

ġ

App

Attributes tree in the DRT.

.
An attribute tree in our DRT model is composed by leaf
nodes and internal nodes. Each leaf nodes represents an
attribute, and each internal node is a logical gate, such as
”AND”, ”OR”, ”n-of-m”, as shown in Fig. 2.
The following functions and terms that will be used in next
section are defined as follows:
• att(x) returns the attribute associated with the leaf node
x.
• parent(x): return the parent node of node x;
• numx is the number of children of a node x. A child
y of node x is uniquely identified by an index integer
index(y) from 1 to numx .
• The threshold value kx = numx −1 when x is an ”AND”,
and kx = 0 when x is an ”OR” gate or a leaf node. kx
is used as the polynomial degree for node x using the
threshold secret sharing scheme.
IV. D ESCRIPTION

OF

DRT T RANSACTION S CHEME

A. System Parameters Setup

Fig. 3.

DRT protocol.

DRT Setup(k): Chooses a security parameter k and outputs
a bilinear group map between two cyclic groups G0 and G1 .
The G0 is a bilinear group of prime order p with generator
g. H : {0, 1}∗ → G0 is a hash function. The TA chooses
two random values α, β ∈ Zp . The TA keeps the master key
M K = (β, g α ) secret, and published the following public
parameters:
P K = hG0 , g, h = g β , e(g, g)α i.

(1)

B. DRT Key Generation and Registration
The key generation algorithm takes attributes in Au of the
user and attributes in As of the SP as shown in Table I as input
and outputs secret keys for a user and an SP separately. The detailed DRT key generation function DRT Genkey(M K, Au )
for users’ attributes is presented as follows:
1) Chooses random numbers ru , a ∈ Zp , and calculates
g ru , g a , where a acts as a private key of the device.
2) Chooses random numbers rj ∈ Zp for each attribute
aj ∈ Au .
3) Computes the secret keys as follows:
SKu =hDu = g (α+ru )/β ;
∀aj ∈ Au : Dj = g ru × H(aj )rj , Dj′ = g rj i.

The TA runs DRT Setup(k) procedure to generate a set of
4) Registers the user in the MC by sending g a , Au and
public parameters that are shared by all participants as follows:
h∀aj ∈ Au : Dj = g ru × H(aj )rj , Dj′ = g rj i to the
4406

4

MC through a secure channel and binding the user with
the device attribute auI in Au .
5) Stores Du and a in the TEE of the SMD.
The TA performs DRT Genkey(MK,As ) to generate secret
keys for a SP as follows:
1) Chooses a random number rs ∈ Zp , and calculates g rs .
2) Chooses random numbers rk ∈ Zp for each attribute
ak ∈ As .
SKs =hDs = g (α+rs )/β ;
∀ak ∈ As : Dk = g rs × H(ak )rk , Dk′ = g rk i.
3) Delivers SKs to the SP through a secure channel.
C. Duel-Root Trust Protocol
We assume that the user opens an online application in the
SMD. To use DRT, the user should first connect to MC using
his device through a secure channel, e.g., a VPN. Then the
following protocol takes steps as shown in Figure 3.
1) First, the user initiates a request of transaction through
the application (hereafter, it is referred as ”App”) in
his SMD to request an online transaction from the SP.
To do this, the App uses attributes for the expected
SP, for example, the DNS name, IP address etc., to
generate an attributes tree TSP as shown in Fig 2(a),
which has only one attribute in the right subtree. To be
simple and minimum the communication, we assumed
attributes trees discussed later are all AND gates trees.
The attribute in the right subtree is denoted as asI
which is one of the SP’s attribute will be handled in
SMD. Then the App generates randomly an 1-degree
polynomial qR (x) [8] where R is the root node of TSP ,
and sets s = qR (0), s1 = qR (1), and s2 = qR (2),
and then generates two random nonces n1 , n2 ∈ Zp
and performs SemiEncrypt(P K, Mu , asI ) as follows,
where Mu = {n1 , n2 , auI }:
a) Calculates C0 = hg s2 , H(asI )s2 i
fu = Mu e(g, g)αs , and Cu = hs .
b) Computes C
c) Sends REQ − trans to the MC, where REQ −
eu , Cu , s1 } :
trans = {TSP , C0 , C
REQ−trans

SM D −−−−−−−−→ M C.
2) The MC retrieves the required attributes according
TSP −r and performs Encrypt(TSP , s1 ) as follows:
a) ∀x ∈ TSP −r , randomly chooses a polynomial
qx with degree dx = kx − 1, where kx is the
secret sharing threshold value[8]: For the root
node RSP −r of TSP −r , chooses a dRSP −r -degree
polynomial with qRSP −r (0) = s1 . ∀x ∈ TSP −r \
RSP −r sets dx -degree polynomial with qx (0) =
qparent(x) (index(x)).
b) Calculates the following ciphertext:
{∀y ∈ YSP −r : Cy = g

qy (0)

, Cy′

qy (0)

= H(att(y))

},

.
d) Sends CTSP to the SP.
{CT

,userID}

SP
M C −−−−
−−−−−−→ SP.

gs
3) The SP retrieves secret keys SK
⊆ SKs
that are related to attributes in TSP , and invokes
g s , CTSP )[8] as follows :
Decrypt(SK
For each leaf node y that contains an attribute in TSP ,
g s , y)[8]
the SP runs a function DecryptNode(CTSP , SK
as follows:
g s , y)
DecryptNode(CTSP , SK
e(Di , Cy )
e(g rs · H(i)ri , g qy (0) )
=
=
e(Di′ , Cy′ )
e(g ri , H(i)qy (0) )
=

e(g, g)rs qy (0) = Fy .

(2)

For each non-leaf node x in in TSP , the recursion is
processed as follows: ∀y is the child of x, it calls
g s , y) and stores the output as
DecryptNode(CTSP , SK
Fy . Let Sx be a kx -sized set of children nodes of x, the
SP computes:
Y
Y ∆i,S′ (0)
Fx =
Fy x =
(e(g, g)rs ·qy (0) )∆i,Sx′ (0)
y∈Sx

=

Y

y∈Sx
′ (0)
rs ·qparent(y)(index(y)) ∆i,Sx

(e(g, g)

)

y∈Sx

=

Y

(e(g, g)rs ·qx(i)·∆i,Sx′ (0)

y∈Sx

= e(g, g)rs qx (0) ,

(3)

where i = index(z) and Sx′ = {index(z) :
z ∈ Sx }, ∆i,Sx′ (0) is the Lagrange coefficient. If
the tree satisfied by attributes, the recursive function
g s , root), where root is the root
DecryptNode(CTSP , SK
of TSP , returns A = e(g, g)rs s . Then computes:
eu /(e(Cu , Ds )/A)
C
= Mu e(g, g)αs /(e(hs , g (α+rs )/β )/e(g, g)rs s ) = Mu
to get the plaintext Mu = {n1 , n2 , auI } generated by the
SMD. The SP checks the freshness of nonces. If the request is valid, the SP replies to the MC with transinf o,
where transinf o includes sessionID, userID and
SP ID that uniquely denotes the transaction between
the user and the SP, to request attributes of the user for
the following transactions. The SP sends the request to
the MC.
{n1 ,transinf o,REQ−userinf o}

SP −−−−−−−−−−−−−−−−−−−−−→ M C.
4) The MC transfers the request to the App in the SMD.
n1 +1,transinf o

M C −−−−−−−−−−→ SM D.

where YSP −r is the set of leaf nodes in TSP −r .
c) Gets all the following ciphertexts:
eu = Mu e(g, g)αs ; Cu = hs ;
CTSP =hTSP ; C
∀y ∈ YSP : Cy = g qy (0) ,

Cy′ = H(att(y))qy (0) i.

4407

5) The App checks n1 + 1 and transinf o so that it can
confirm the response to setp 1 is correct, and then sends
the request to the TEE embedded in the device. The TEE
first calculates D0 = (H(auI ⊕n1 ))a , and then generates
e = Du t . After
a random number t ∈ Zp , calculates D

5

e to the App. The
that, the TEE sends the token {D0 , D}
App sends the token to the MC:
e
{D0 ,D,transinf
o}

SM D −−−−−−−−−−−−→ M C.
This token is to provide evidence to the MC that the
SMD confirms the first challenge-response with the SP
and agrees to provide attributes.
6) The MC retrieves the user’s attributes and gets au I
and g a , and checks whether e(H(auI ⊕ n1 ), g a ) equals
e((H(auI ⊕ n1 ))a , g). If they are equal, the MC authenticates the user’s attempt for the device-specific
transaction and retrieves required attributes and builds
the attribute tree TU . As shown in Figure 2 (b), TU is
an all AND-gate tree and the root has at least two subtrees. Attributes on the left subtree include descriptive
attributes of the user, while attributes on the right subtree
is an attribute specific to the SMD, e.g. au I. The MC
generates a random nonce nM ∈ Zp and sends to the
SP.
{Tu ,nM }

M C −−−−−−→ SP.
7) The SP checks whether attributes in Tu meets
the REQ − userinf o, and then performs Encrypt(P K, Ms , Tu ) as follows, where Ms = {n2 +
1, nM , sk} and sk ∈ Zp is a session key for later use:
a) ∀x ∈ Tu , randomly chooses a polynomial qx with
degree dx = kx − 1, where kx is the secret sharing
threshold value[8]. Chooses a random s′ ∈ Zp and
sets s′ = qRu (0), where Ru is the root node of Tu ;
b) Generates a ciphertext from top to down:

Till now, the SMD gets the second response to the
challenge n2 sent in the step 1. The TEE returns Ms
to the App. After validating the n2 , the App encrypts
transinf o, n2 , auI using sk and sends them to the MC
as follows :
{{transinf o,n2 ,auI }sk ,nM +1}

SM D −−−−−−−−−−−−−−−−−−−−→ M C.
10) The MC checks nM , and then sends to the SP.
{transinf o,n2 ,auI }sk

M C −−−−−−−−−−−−−−→ SP.
The SP decrypts the ciphertext using the session key it
generated in step 7 and checks the plaintext. The SP
confirms that the transaction is valid and launched by
the user from the expected device after validating the
message.
V. P ERFORMANCE E VALUATION
In this section, we first provide security assessment of DRT,
and then we evaluate the cost of DRT in terms of computation
cost.
A. Security Assessment

In DRT, all entities in the system are considered semitrusted. Entities only trust knowledges that they get from the
protocol to set up trusts. In the follows we analyze knowledges
entities can get and their potential misbehaviors to show the
strength of DRT protocol. Due to the limits of space, the
security analysis on the modified CP-ABE used in DRT can
be refer to [19].
{∀y ∈ Yu : Cy = g qy (0) , Cy′ = H(att(y))qy (0) },
The user can confirm the transaction between her and
the
expected SP through two rounds of response-challenges.
where Yu is the set of leaf nodes
in Tu .
αs′
s′
e
The
user generates two nonce n1 , n2 encrypted by the SP’s
c) Computes CSP = Ms e(g, g)
and CSP = h .
d) Sends
attributes in step 1, and then get one response to n1 in step 4
and the other response to n2 in step 8. There is no way for
eSP , CSP , ∀y ∈ Yu : Cy , C ′ },
CTu = {C
y
others to fake responses except using secret keys related to
to the cloud.
the SP’s attributes which we assume they are hosted in the SP
{CTU }
securely.
SP −−−−→ M C.
Although a user is unlikely to cheat or counterfeit the tokens
8) The MC retrieves:
in the transaction she initiated, she may use other people’s
mobile device to launch transactions or pretends to be someone
g u = h∀j ∈ Yu : Dj = g ru × H(j)rj ; D′ = g rj i,
SK
j
else using her own devices. In these cases, first, the MC can
g u , CTu ) and gets easily detect the misbehaviors since each user has registered
and runs the algorithm Decrypt(SK
′
e received in the and been bounded with a mobile device in the MC, second, we
A = e(g, g)ru s . The MC retrieves D
step (5), and computes
assume that the access to devices’ TEE cannot bypass without
′
s
t(α+r
)/β
a password.
u
e = e(h , g
B = e(CSP , D)
)
The potential misbehaviors for the MC is that it may im′
′
= e(g, g)tαs · e(g, g)tru s .
personate the user to launch transactions with the SP without
users’ consent. The MC may launch step 2 and 6, then gets
eSP } to the SMD:
The MC sends {A, B, C
messages from step 3 to 7 even without users’ involvement,
eSP }
{A,B,C
but it cannot fake the token in step 5 since it has no private key
M C −−−−−−−→ SM D.
eSP } to the TEE. The TEE a and the device-specific secret key D. Even if the MC has
9) The SMD sends {A, B, C
e = g t(α+r)/β , it cannot deduce
the old blinded secret key D
finalized the last step for the decryption to get Ms =
D, since the blinded factor t is the exponent of the generator
{transinf o, n2 , sk} as follows:
g,
deriving it can be reduced to a Discrete Logarithm Problem
′
eSP
C
Ms e(g, g)αs
that is considered to be hard. Without the token, the MC cannot
.
Ms =
=
(e(g, g)αs′ · e(g, g)ru s′ )/e(g, g)ru s′ decrypt the ciphertext in step 7.
((B t−1 )/A)
4408

6

The SP only communicates with the MC who is on behalf
of the user, but it can confirm that it is the expected user on
the specific device after the SP decrypts the ciphertext in step
10. The session key sk acts as a challenge to the user, only
the user who has the associated secret keys can decrypt the
ciphertext in step 7 to get sk. {transinf o, n2 , auI }sk is the
user’s confirmation to the online transaction.
To eavesdropping attacks, keys or credentials are never
exposed in plaintext and nonces are used randomly only for
one session in order to prevent attackers replaying the captured
messages. The MC is authenticated by the TA through common authentication procedures without described in the DRT
protocol, which is our assumption in that the communication
between participating entities can be protected by SSL/TLS
channels that can resist the man-in-middle attack.
B. Computational Performance Evaluation
In the setup procedure, the TA needs to generate secret
keys that causes 2|Au | + 3 exponentiations on G0 for each
SMD, and 2|As |+2 exponentiations on G0 for each SP. These
computations are only calculated for once in a period time and
not a burden to the TA since we assume that the TA usually
has powerful computational capability.
TABLE II
O NLINE CRYPTOGRAPHIC OPERATION COSTS .
Exp G0 /G1
Pairing
SMD
5/2
0
MC
2a1 /a2
2a2 + 3
SP
2a2 + 1/a1 + 2
2a1 + 3
a1 is the number of attributes in Ts , a2 is

Mul G1
Hash
3
2
2a2 − 1
a1
2a1 + 3
a2
the number of attributes in Tu .

Expensive cryptographic operations over G0 and G0 performed by entities in the DRT is shown in Table II. From
Table II, we can see that the computation overhead is linear
for the MC and the SP, who are considered have sufficient
resources to process these operations. Pairing and exponentiation operations are considered the most computationally
intensive among all computations. using DRT only a constant
number of cryptographic operations are required, which is
efficient and feasible for resource-constrained devices. The
most expensive operations such as pairings are outsourced
into the MC. Since the order of the computation overhead
on smartcards is constant, the presented DRT scheme shows
significant performance gain when the attribute tree is large,
i.e., all the attribute-related operations are outsourced to the
cloud side.

VII. ACKNOWLEDGMENT
This work was supported by National Natural Science
Foundation of China ( Grant No. 61003185 ). The research
of Dijiang Huang is sponsored by ONR YIP award.
R EFERENCES
[1] S. C. Alliance, “Mobile devices and identity applications,” September
2012.
[2] A. Felt, M. Finifter, E. Chin, S. Hanna, and D. Wagner, “A survey of
mobile malware in the wild,” in Proceedings of the 1st ACM workshop
on Security and privacy in smartphones and mobile devices, 2011, pp.
3–14.
[3] D. Huang, “Mobile cloud computing,” in Proccedings of the sixth
conference on computer systems. ACM, 2011, pp. 301–314.
[4] P. M. M. N. B. G. Chun, S. Ihm and A. Patti, “Clonecloud: Elastic
execution between mobile device and cloud,” in IEEE COMSOC Multimedia Communicatoins Technical Committee (MMTC) E-letter, vol.
6(10), Octorber 2011, pp. 27–31.
[5] Google Inc., “Google Wallet,” in available at http://www.google.com/
wallet/.
[6] M. Wu, G. S., and R. Miller, “Secure web authentication with mobile
phones,” in DIMACS workshop on usable privacy and security software,
2004, pp. 9–10.
[7] EMC, “Rsa secureid,” in available at http://www.emc.com/security/
rsa-securid.htm.
[8] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-policy attributebased encryption,” in Proceedings of the 2007 IEEE Symposium on
Security and Privacy, ser. SP ’07.
Washington, DC, USA: IEEE
Computer Society, 2007, pp. 321–334.
[9] ARM, “Trustzone technology overview,” 2009.
[10] D. Davenport, “Nexus S Enables the NFC Secure Element,”
in
available
at
http://thinkd2c.wordpress.com/2011/ 07/ 07/
nexus-s-enables-the-nfc-secure-element/ , 2011.
[11] A. Filyanov, J. M. McCuney, A. Sadeghiz, and M. Winandy, “Unidirectional trusted path: Transaction confirmation on just one device,”
in Proceedings of the 2011 IEEE/IFIP 41st International Conference on
Dependable Systems&Networks, ser. DSN ’11. Washington, DC, USA:
IEEE Computer Society, 2011, pp. 1–12.
[12] S. Balfe and K. G. Paterson, “e-emv: emulating emv for internet
payments with trusted computing technologies,” in Proceedings of the
3rd ACM workshop on Scalable trusted computing, ser. STC ’08. New
York, NY, USA: ACM, 2008, pp. 81–92.
[13] S. Bugiel, A. Dmitrienko, K. Kostiainen, A. R. Sadeghi, and
M. Winandy, “Truwalletm: Secure web authentication on mobile platforms,” in Proceedings of 2nd International Conference on Trusted
Systems (INTRUST), 2011, pp. 219–236.
[14] J. Azema and G. Fayad, “M-shield mobile security technology: making
wireless secure,” 2008.
[15] K. Kostiainen, J. Ekberg, N. Asokan, and A. Rantala, “On-board credentials with open provisioning,” in Proceedings of the 4th International
Symposium on Information, Computer, and Communications Security,
ser. ASIACCS ’09. New York, NY, USA: ACM, 2009, pp. 104–115.
[16] M. Nauman, S. Khan, A. T. Othman, S. U. Rehman, and N. U. Rehman,
“Poauth: privacy-aware open authorization for native apps on smartphone platforms,” in Proceedings of the 6th International Conference on
Ubiquitous Information Management and Communication, ser. ICUIMC
’12. New York, NY, USA: ACM, 2012, pp. 60:1–60:8.
[17] A. Tassanaviboon and G. Gong, “Oauth and abe based authorization
in semi-trusted cloud computing: aauth,” in Proceedings of the second
international workshop on Data intensive computing in the clouds, ser.
DataCloud-SC ’11. New York, NY, USA: ACM, 2011, pp. 41–50.
[18] F. J. Krautheim, “Building trust into utility cloud computing,” Ph.D.
dissertation, University of Maryland, 2010.
[19] Z. Zhou and D. Huang, “Efficient and secure data storage operations
for mobile cloud computing,” in Proceedings of 8th International
Conference on Network and Service Management, 2012.

VI. C ONCLUSION
It becomes a global trend to use mobile devices as a
platform for secure transactions in different domains. The dual
root trust model proposed in this paper provides confirmation
for both users and SPs in each transaction between users and
SPs, and it provides trust from both mobile devices and the
mobile cloud. In the future, we will work on extending our
work to provide a detailed performance evaluation using the
TrustZone embedded mobile devices and enhance dual-root
trust level relying on the trusted execution environment and
the mobile cloud.
4409

Secure, Selective Group Broadcast in Vehicular
Networks using Dynamic Attribute Based
Encryption
Nanxi Chen and Mario Gerla

Dijiang Huang

Xiaoyan Hong

Department of Computer Science Department of Computer Science and Engineering Department of Computer Science
University of Alabama
Arizona State University
University of California, Los Angeles
hxy@cs.ua.edu
dijiang@asu.edu
chnx, gerla@cs.ucla.edu

Abstract—Ciphertext-policy attribute-based encryption (CPABE) provides an encrypted access control mechanism for
broadcasting messages. Basically, a sender encrypts a message
with an access control policy tree which is logically composed
of attributes; receivers are able to decrypt the message when
their attributes satisfy the policy tree. A user’s attributes stand
for the properties that he currently owns. A user should keep
his attributes up-to-date. However, this is not easy in CP-ABE
because whenever one attribute changes, the entire private key,
which is based on all the attributes, must be changed. In this
paper, we introduce fading function, which renders attributes
“dynamic” and allows users to update each attribute separately.
We study how choosing fading rate for fading function affects the
efficiency and security. We also compare our design with CP-ABE
and find our scheme performs significantly better under certain
circumstance.

I. I NTRODUCTION
Cautious landlords replace house locks after tenants leave
because they worry that tenants might keep copies of the
keys. The same concept applies to protecting confidential
information. Whenever a user leaves a communication group
with which has been exchanging and sharing confidential
information, the remaining group members will replace the key
used to encrypt the messages. However, given the high cost
of key redistribution, this can impact performance especially
when the group is made of thousands of users and the group
members are likely to move in and out frequently.
Sahai et al. [2], [3]’s recent Attribute-Based Encryption
(ABE) scheme makes it possible to dynamically reassign
group keys when requirements and conditions change. To
introduce the concept of ABE, consider the following example:
sometimes there are several restrictions to redeem a discount
coupon, say, California resident, UC or CSU students, plus
AAA or UHaul membership, etc. One must show resident
ID, student ID and AAA or UHaul ID to use the coupon.
In the ABE context, the coupon is the object or information
that we must protect, and the IDs are so-called attributes.
The secret message (the coupon) is encrypted with an access
control policy tree that contains the logical combination of
the different attributes. The policy tree for the above coupon
example would be “CA resident AND (UC student OR CSU

student) AND (AAA membership OR UHaul member)”. Any
qualified user can apply and obtain a private key from certifying authority (Key Master). The key is associated with the
various qualifications (i.e., attributes) of the applicant. The user
can decrypt only if his attributes satisfy the policy tree.
Attributes can be expanded to represent all kinds of properties related to applicants, e.g., skin color, car brand, size,
occupation and time window when these properties are valid,
etc. A policy tree defines a target multicast group to which a
secret must be delivered - for example, a group key to be used
for future communications. ABE saves the trouble to issue a
group key in advance to each foreseen multicast group (thus
avoiding combinatorial explosion). Or, conversely, ABE avoids
the problem (and latency) of finding and certifying all the
qualified members on the spot whenever the need arises. ABE
requires customers to pre-qualify (off line) for the attributes
that may correspond to multicast groups they will be asked to
join. Thus, the work is done ahead of time; and, it does not
require combinatorial complexity.
To prevent users holding certain attributes forever, ABE
adds expiration timers to revoke private keys. The problem
with this revocation scheme is that the entire private key
expires after a period of time. It works well in some scenarios
but significantly reduces the performance in applications such
as Situation Aware Trust (SAT), proposed by Xiaoyan Hong
et al. in [5], where attributes can change frequently. Just as
an example, in SAT, locations are encoded into attributes.
Considering that the location attribute can be as specific as
a street or a neighborhood, a mobile user’s location attribute
is expected to change in a matter of minutes or less. Each time
the location attribute changes, the entire private key which may
be associated with hundreds of attributes must be changed.
This is not efficient since the cost of generating a new private
key is proportional to the number of attributes associated with
that private key [1]. If there are 100 attributes associated with
a key and even only one changes, the authority must generate
a new key with 100 attributes at considerable expense of CPU
resources. In fact, the bigger the key, the longer transmission
time - not a welcome proposition in applications like vehicular
networks with short road-side unit to vehicle contact time.

978-1-4244-8435-5/10/$26.00 ©2010 IEEE

To save CPU resources, bandwidth and time, we avoid
updating those attributes that stay unchanged. To achieve this,
we introduce in this paper the concept of attribute fading
function, making attributes “independent” and “dynamic”.
Being dynamic, an attribute associated with a private key has
its own expiration time. When an underlying property changes,
the user requests a new attribute from the authority to represent
his new property and the out-of-date attribute expires after
a certain period of time. By this mean, a user can update
partial attributes, rather than all of them, in one update. Our
simulation results show that this approach significantly reduces
the overhead comparing with traditional ABE especially when
there are a number of “active” attributes associated with a
user’s private key.
The rest of paper is organized as follows: Section II gives
the essential background on ABE and SAT. Section III identifies the potential inefficiencies of the current ABE system.
Section IV introduces the design of “dynamic” Attribute-Based
Encryption. Section V describes simulation experiments and
results. Section VI concludes the paper.
II. BACKGROUND
A. Attribute Based Encryption
Sahai and Waters et al. [2], [3] introduced Attribute Based
Encryption (ABE) as a new mechanism for encrypted access
control. There are several versions of ABE; the one discussed
in this paper is the so-called Cipher-Policy Attribute-Based
Encryption (CP-ABE) [1].
CP-ABE utilizes identity based encryption [7], [8] and
threshold secret sharing scheme [6]. To some extent, CP-ABE
is an extension of conventional PKI to groups: an authority
generates public and private keys; public key is for encryption
while users keep their own private keys to decrypt. In CP-ABE,
public and private keys are not a one-to-one pair; instead, there
is only one public key and a potentially very large number of
private keys, one for each user in the target group.
A user’s private key is associated with an arbitrary number
of attributes. A user acquires a private key from the authority
based on his properties. One attribute corresponds to one
property. Properties such as name, age and employer are different from person to person, so users have different attributes
associated with their private keys. The publisher uses a policy
tree, i.e., the logical combination of various attributes, and the
public key to encrypt a message. Only clients whose attributes
associated with their private keys satisfy the policy tree can
decrypt the message.
In Fig. 1, the policy tree is logically composed of five different attributes. Two users try to decrypt. Kevin has attributes
CA resident, UC student and AAA member so that he can
decrypt the cipher while Sarah cannot.
B. Situation Aware Trust
Xiaoyan Hong et al. developed Situation Aware Trust (SAT)
to provide adaptive and proactive security in mobile scenarios
like VANET. Attributes in SAT identify a group of entities
(e.g., taxicabs associated with a company, police cars in a city),

And

Encryption

Policy Tree
Public Key

CA resident

And

Or

UC
student

Message

Or

CSU
student

AAA
UHaul
member member

Cipher

Decryption
Private KeyKevin:

Private KeySarah:
“CA resident”
“High school student”
“AAA member”
“Hispanic”
“06/18/2010”…



“CA resident”
“UC student”
“AAA member”
“Asian”
“03/19/2012”…



Fig. 1. An example of Policy Tree and Private Keys associated with attributes

a type of events (e.g., accidents, congestions), or the property
of events (location-based services, road traffic updates). They
can be further classified as dynamic attributes and static attributes, depending on whether the attributes change frequently
or not [5].
In SAT, vehicles fulfilling a common set of attributes
form a “policy group”. The policy group is specified by the
information originator and is automatically established without
relying on a trust party to manage the group [5]. For example,
a company A’s taxi driver can broadcast a message encrypted
with policy tree “company A AND Westwood Blvd. AND 1011am” to tell his colleagues that conventioneers will be waiting
for pickup at hotels on Westwood Blvd. The message may be
broadcasted to a very large area of the city. However, only
company A’s taxicabs that have been “certified” to be near
Westwood Blvd. in the time window 10-11am can decrypt the
message. Thus competitive advantage is ensured. At the same
time, company A’s taxi drivers likely to work the morning shift
in remote areas will not be notified and will not waste time
and gas unnecessarily.
III. M OTIVATION
As we have learned in the previous section, attributes are
the most vital concept in ABE. Let us briefly review the
relationship between properties and corresponding attributes:
• Attributes associated with a user’s private key reflect the
user’s CURRENT state or properties.
• A user is not expected to hold an attribute (corresponding
to specific state or property) for which he is no longer
(or not yet) certified.
A key revocation mechanism is necessary to prevent a user
from keeping a private key with expired attributes. In [4], the
authors suggest adding expiration timestamp attributes into
a user’s private key when it is issued. The access control
policy tree is also expected to include a subtree which defines
the range of acceptable expiration times [1]. Users whose

expiration timestamp attributes satisfy the subtree can continue
to decrypt. When one’s private key expires, a new key must
be required from the authority.
CP-ABE is also protected against collusion attacks. A user
cannot give his attributes to others; neither can he borrow
attributes from his expired private keys. From the mathematical
construction of ABE (which is attached as an appendix), we
know that this is achieved by using a random number when
generating private keys. Each private key uses a unique random
number. All the attributes associated with the same private
key are bonded by this random number. So, they cannot be
transferred to other users.
The above two features ensure the security of CP-ABE,
but also bring unexpected problems. Since no attribute level
operation is allowed in CP-ABE, the only way to update an
attribute (when the underlying property changes) is to update
the entire private key. However, this may spell disaster in some
scenarios, as SAT a case in point. As we have mentioned in
the previous section, locations are encoded into attributes in
SAT. Location attributes tend to change super frequently since
cars are moving around all the time. That requires a moving
car to update its private key time to time. On the other hand,
attributes such as the color of cars, car owners and so on
seldom change regardless of car speed. In conventional CPABE, each time a location attribute changes, these attributes
must also be updated since the entire private key must be
reissued.
This is equivalent of a landlord to change all the locks/keys
in the entire apartment building whenever a single tenant
moves out, which would be ridiculously expensive. By the
same token, we would like to update only the attribute that
changes rather than updating the entire private key.
IV. DYNAMIC ATTRIBUTES
A. Key Insight
Here is another story from our acquaintance, the landlord. A
landlord owns a house with 5 rooms. At first, he advertises the
house for rent on Craigslist. Five people (they are all friends of
each other) come together and rent the house. They sign a oneyear contract with the landlord and each of them has a copy.
A month later, one tenant leaves and another friend of theirs
moves in. The landlord renews the rental contract with them
to incorporate the new tenant’s name. Unfortunately, the same
thing happens several times in the following months. Every
time when a new tenant moves in, the landlord has to meet all
the tenants and update their contracts, which him crazy. So he
decides to adapt a new strategy - he advertises each room for
rent and signs room rental contract with each tenant. In this
way, he saves the trouble of meeting all the tenants each time
a new tenant moves in.
This life story inspires us. Why do we need expiration
timestamp attributes (a house rental contract) for the private
key (house)? Why not allow each attribute (room) to have
its own expiration time (room rental contract)? If that works,
whenever we need to update an attribute, we expire the old

attribute, then request a new attribute from authority and add
it into the private key.
Technically speaking, the second step (i.e., adding a new
attribute to the user’s private key) is so not difficult. But it
is a real challenge to remove (or revoke) an attribute that
is already associated with a private key. This is because the
party encrypting the message does not obtain the receiver’s
certificate (attribute) online, and he is not able to check
whether it is expired or not [1]. In other words, the old attribute
(the receiver no longer owns the corresponding property) looks
the same as the rest of the attributes (the receiver has the
corresponding properties) so that no one except for the receiver
himself knows whether an old attribute is used or not when
decrypting a meesage. We can always assume that a tamperproof hardware forces a user to discard his old attributes, but
it is such a strong assumption that it may be unrealistic or
economically inefficient for civil usage. Since we can do little
on the receiver’s side, we consider the problem on the sender’s
side - as long as an attribute is never posted again in policy tree
after it is expired, it becomes useless. Our scheme is designed
under this direction and we will focus on how to expire an
attribute in the following sections.
B. Assumptions and Concepts
The Key Master is the authority in our system. It is responsible
to formalize and maintain the set of attributes that can be
used in the system (both in policy trees and private keys).
It publishes all the available attributes, their values, and the
corresponding descriptions. The Key Master is also in charge
of generating keys, including public and private keys, as well
as the attributes associated with private keys. Usually, for a
given application, there is only one public key. The Key Master
generates private keys and attributes for users according to
their requests. It verifies each request for compliance before
issuing the key to the user.
A sender is an individual that encrypts a message and sends it
to others. Before encrypting, the sender looks up the desired
attributes in the Key Master’s attribute list and downloads the
corresponding attributes. He downloads the public key as well.
Then he encrypts a message as instructed in Section II-A and
sends out the cipher.
A receiver receives ciphers and tries to decrypt. A receiver can
get a private key before or after receiving ciphers. Generally,
to enable “proactive trust” [5], a receiver is supposed to obtain
a private key at the start of the day (or mission) and keep his
private key up-to-date proactively.
The Lifetime of an attribute is a fixed time window during
which the attribute’s value remains unchanged.
We assume that all the parties in the system, including the
Key Master, senders and receivers, have coarsely synchronized
time clocks using, for example, GPS or equivalent techniques.
C. Design
In the following parts, we give a high level description
about the design. Readers may refer to the appendix for the
underlying mathematical constructions.

1) Setup: To make each attribute have an expiration time,
AND Policy Tree
we introduce a fading function for each attribute. The elapsed
time is the input of a fading function. A fading function can be
Attribute 1 Attribute 2
Attribute 2 Lifetime for
Sender:
of any form as long as it outputs different values for different
Attribute 2
Sarah
inputs. For example,
t − Base T ime
c
Att Current V alue = Att Base V alue×b
60min
Attribute 1
is a fading function with its Lifetime equals to 60 minutes.
time
The Key Master assigns a fading function to each attribute and
t1
t2
t3
publishes the fading functions together with the corresponding
Private Key Kevin:
“Attribute 1”
attribute descriptions and attribute base values.
“Attribute 2”
2) Encryption: The objective of the fading function is
Receiver:
AND “Attribute 3”
Kevin
…
to produce a time changing attribute. When a sender wants
Attribute
2
Attribute
1
to encrypt, he downloads the attribute base values and corresponding fading functions at first. From fading functions
he computes attributes’ current values, taking attribute base
values and current time as inputs. Then the sender uses the
Fig. 2. How does “dynamic” attribute work
current attribute values to compose a “policy tree”. Finally, a
message is encrypted with the policy tree and broadcast to all
the receivers.
with is different from the value based on which a receiver’s
3) Key Generation: The Key Master creates a record (a old attribute is generated. Fig. 2 explains this process. The
profile) in its memory for each new coming receiver. Records sender encrypts a message with two attributes at time t2 . The
are distinct from receiver to receiver. In addition, the Key receiver has both attributes. He obtains Attribute 1 at time
Master keeps this information secret and no receiver will ever t1 and Attribute 2 at time t3 respectively. Between t2 and
know his or others’ record. The Key Master utilizes records to t3 , Attribute 2’s value stays unchanged, which means the
generate private keys and attributes for receivers. Due to the Key Master uses the same value as the sender does, and the
uniqueness of each record, receivers cannot exchange their receiver can match the sender on Attribute 2. However, from
attributes with each other (preventing collusion).
t1 to t2 , Attribute 1’s value has changed. Due to some reason,
4) Decryption: A receiver requests a private key from the the receiver has failed to update Attribute 1, meaning this
Key Master at the beginning of the day/mission, and keeps attribute has been expired. So the receiver’s Attribute 1 value
his attributes, which are associated with his private key, up- does not match the sender’s, resulting in his failure to decrypt
to-date. Only if the receiver’s attributes satisfy the policy tree the message.
with which a message is encrypted, the receiver can decrypt
We name our scheme with Dynamic Attribute Based Enthe message. We emphasize that attribute A matches attribute cryption, DABE for short. This name has two-fold meaning:
B if and only if they have the same attribute value.
attributes’ values are dynamic and change by time; and this
5) Attribute Update: Suppose a receiver’s underlying prop- scheme is designed to work more efficiently in presence of
erty changes at 3:15PM (for example, he has moved from dynamic attributes.
arrondissement 4 to 5 in Paris); he requests an attribute
update. When the Key Master receives the request, it computes
D. Discussion
the current attribute value for arrondissement 5 using the
1) Fading Rate: Attribute values do not, and should not
appropriate fading function (3 < t < 4). Then it looks up the
receiver’s record, uses the record to generate an attribute based continuously change. Ideally, an attribute value should be
on the attribute’s current value, and issues the newly generated stable for a while, jump to another value, stay at that point for
attribute to the receiver who requested it. The receiver adds another fixed time, jump to a third value, stay stable and go
the new attribute to his private key. The new attribute is on. The fixed time span that an attribute value stay unchanged
only for that receiver because it is built on his record. And is called the Lifetime for that attribute. As showed in Fig. 2 the
this “magic” record also guarantees that the attribute has no Lifetime controls the fading rate of an attribute, which is how
problem of associating with that user’s private key because all fast an attribute becomes invalid. If the Lifetime is too small,
the attributes associated with his private key are generated an attribute in the private key set expires very soon after it is
based on the same record. Note: if the receiver knows its issued so that receiver needs to update it frequently. Too large
time/space trajectory, it can request a set of attributes, one Lifetime is not desirable either since “fading” is very important
for each segment. The Key Master will issue the attributes for security consideration: a receiver can use an unexpired
ONLY upon verification that the request is valid (for example, attribute to decrypt even after he loses the corresponding property. Therefore, choosing an appropriate Lifetime is desired.
a bus going on a predefined route).
Update is not finished until the old attribute expires. Expi- The general question about the best Lifetime for a particular
ration happens when the attribute value that a sender encrypts attribute is out of the scope of this paper. We will analyze







the Lifetime affect on system security and efficiency in a later
section (Section V).
Attributes may have different Lifetimes because they use
different fading functions. Basically, an attribute that tends
to change frequently, e.g., local location attributes (street,
neighborhood), should have relatively smaller Lifetime to
make the old attributes expired as soon as possible. In contrast,
an attribute supposed to change less frequently or not change
at all, such as high level locations (state, country), may have
a bigger value to avoid unnecessary updates.
2) Security: Collisions may be caused by introducing fading functions. It is possible that attribute A’s value at time t1 ,
say attA,t1 , is exactly the same as attribute B’s value at t2 , say
attB,t2 , if fading functions are not carefully designed. This is
never allowed to happen since a receiver can use attB,t2 to
decrypt cipher encrypted by attA,t1 , which totally screws up
ABE.
The Key Master is the one responsible for designing and
publishing fading functions. By carefully choosing fading
function for each attribute, collision can be avoided. Replacing
old fading functions after a period of time is recommended for
security consideration.
Another security concern is that a sender may choose outof-date attribute value, other than the “latest”, to encrypt a
message. This is allowed, and sometimes even desired, i.e.,
a sender broadcasts a message to the receivers who were on
Westwood Blvd. 5 minutes ago. It is the sender’s responsibility
to choose which value to use and who can see his message. In
most cases, the sender uses the latest attribute value to ensure
the real-time constraint.
Besides fading, DABE is identical to CP-ABE. Thus it is
as secure as CP-ABE.
3) Overhead: DABE causes unnecessary updates if a receiver still owns the property when the corresponding attribute
expires. In that case, he should request an attribute from
the Key Master to replace the expired attribute. This is not
only DABE’s concern. CP-ABE also suffers from similar
problem because the Key Master cannot predict the correct
expiration time for a private key. By allowing attribute updates
individually, DABE avoids CP-ABE much more cumbersome
private key update. When attributes change fast, the overhead
produced by private key updates far outweighs the unnecessary
updates in DABE. Our simulation results in Section V confirm
this claim.
Fading functions do not bring much overhead. The set of
available attributes is maintained by the Key Master. So, before
encrypting, a sender has to check available attributes with the
Key Master at least once. He can download fading functions
at that time. The sender does not need to check with the Key
Master anymore as long as the fading function is not replaced,
if he wants to reuse the same attribute later.
V. S IMULATION
We evaluate the performance of DABE in a scenario similar
to SAT. Locations are encoded into attributes. Instead of using

Fig. 3.

Quadrant Location System

road names [5], we use Quadrant Location System to represent
a car’s location.
In a real system, vehicles have several other attributes
besides location. However, to test DABE we need to concern ourselves with the dynamic attributes. And, instead of
considering various types of dynamic attributes (e.g., fuel
level, remaining ammunitions, remaining food, customers on
board, etc.), we just assume for simplicity and without loss of
generality that ALL dynamic attributes are location related,
and differ from each other due to differing granularity or
reference coordinates.
A. Quadrant Location System
In Quadrant Location System (QLS), an area is divided
into 4 squares. Each square is a quadrant, labeled counterclockwise from 1 to 4. Each quadrant is recursively subdivided into 4 smaller quadrants until granularity requirement
is reached. Quadrants having the same size are in the same
layer. As Fig. 3 shows, there are 4 layer 1 quadrants and 16
in layer 2. An object’s Quadrant location is a series of digits.
Each digit represents the object’s location (quadrant label) in
one layer. Digits on the left represent lower layer (with bigger
size) and digits on the right stand for the higher layer quadrant
locations. In Fig. 3, A is in the 3rd quadrant in layer 1 and
the 1st quadrant in layer 2, so A has quadrant location “3,1”.
More precisely, each quadrant represents an attribute. In the
above example, A uses two attributes to indicate his current
location, one for layer 1 and the other for layer 2. Ideally,
when a car enters a new quadrant, it gets an attribute for
the new quadrant and the attribute for the quadrant that it
previously stays expires.
B. Impact of Fading Rate
1) Efficiency and Security: It takes longer time to traverse
a lower layer quadrant (i.e., smaller layer number and bigger
size) than a higher layer quadrant, meaning a lower layer
attribute is updated less frequently than a higher layer one.
Accordingly, a higher layer attribute is supposed to have
smaller Lifetime. In the experiment, we evaluate the impact
of fading rate on security and efficiency. More specifically, to
measure efficiency and security, we define two metrics.

(a)
Fig. 5.

Fig. 4.

(b)

A deeper look at the impact of Lifetime on Multiple Keys and Update Frequency (Cumulative Distributions)

Impact of Lifetime on Multiple Keys and Update Frequency

Multiple Keys: In one Lifetime, a car may traverse several
quadrants in the same layer and get an attribute for each.
Attribute value does not change during one Lifetime interval,
so all these attributes are simultaneously valid. We claim this
is a security violation: a user should not have valid attributes
for locations other than the location that he is currently
occupying. The number of illegal attributes, which is equal to
the number of quadrants that a car traverses in one Lifetime
minus one, is defined as Multiple Keys.
Update Frequency: If a car resides in one quadrant for a
long time, it will get a new attribute for the same quadrant
for each Lifetime expiration. For example, if a car takes 60s
to traverse a quadrant and the Lifetime for that quadrant
attribute is 15s, it will carry out 4 updates as undesirable
waste. Update Frequency reflects efficiency.
2) Setup: Our simulation uses VanetMobiSim [12]. Ten
nodes move in a 2400m × 2400m area. Each simulation
run lasts for 3600 seconds. We put 10 nodes (cars) in the
simulation. The cars have maximum speed of 30m/s and
minimum speed of 14m/s. For realism, we use TIGER maps
[9] and Intelligent Driving Model [10], [11]. Two TIGER maps
are used, one is Los Angeles(+34063690, −118445289), and
the other is Washington D.C.(+38890000, −77020000). We
define a 3-layer QLS (Quadrant Location System). That is,
every car uses 3 attributes to identify its location. Layer 1
quadrant has edge length of 1200m, layer 2 600m and layer

3 300m respectively. We run each experiment 10 times to
get average statistics. A different random seed (which affects
initial location, path selection and speed) is chosen for each
run. Figures below are just from one node running on the
Washington D.C. map.
3) Variable Lifetime experiment: We change Lifetime from
80s to 300s, 30s to 200s and 15s to 150s for layer 1, layer 2
and layer 3 respectively. Fig. 4 shows that the Multiple Keys
behavior grows linearly with Lifetime while Update Frequency
decreases. These results are expected since when Lifetime
gets bigger, in most cases, a car travels longer distance thus
passing more quadrants in one Lifetime and updating less in
one quadrant. At the same time the car will pick up multiple
“illegal” keys for quadrants it is not residing in.
However, the above curves only reflect the average behavior.
Fig. 5(a) shows the cumulative distributions1 . The lower curve
is Lifetime = 200s, and the upper one is for Lifetime = 30s.
As Lifetime decreases, most users pick up fewer Multiple
(illegal) Keys. Small Lifetime also improves worst case, e.g.,
users have 1 or 0 Multiple Keys during most time when
Lifetime is 60s while they have more than 1 Multiple Keys
for nearly half of the simulation time when Lifetime is 200s.
Update Frequency is the opposite. Fig. 5(b) indicates that
the Lifetime increase improves worst case situation. Some
users end up updating 10 times or more in one quadrant if
Lifetime is 30s; with Lifetime = 200s, the worst we can get
is updating twice in one quadrant. It is quite obvious that
a tradeoff exists between Multiple Keys (leading to security
violation) and Update Frequency (leading to extra line and
processing overhead). This is expected. It reflects the usual
tradeoffs between security and efficiency.
C. Scalability
1) Setup: We next analyze the scalability of DABE and
compare the results with CP-ABE. Instead of using a single
QLS, we use a set of 3-layer QLSs to create an environment
with a large number of dynamic attributes. To make these
attributes different, each QLS has a vertical and/or horizontal
shift from the original QLS. That is, if A has location of
“1, 1, 4” in one QLS, it may have location of “1, 2, 4” in
another QLS. A car has up to 3n attributes with n QLSs.
1 CDF

stands for Cumulative Distribution Function

TABLE I
N OTATIONS U SED IN THE COMPUTATION
AU
KU
Na
QC
UF

times of attribute updates
times of private key updates
number of attributes in one private key
times of entering a new quadrant
update frequency

We use 40s, 75s and 160s as Lifetime for layer 3 to 1. From
layer 1 results in Fig 4 we recall that for Lifetime = 160s, the
Multiple Keys probability is 0.5 and the Update Frequency is 2
per Lifetime. So are layer 2 and layer 3 attributes. This is an
acceptable security/efficiency tradeoff leading to meaningful
scalability results.
We increase the size of the private key from 1 attribute to
50 (proportionally to the QLS domains used) and measure
how many attributes are transmitted from the Key Master
to cars when updating (attribute updates). For example, if a
private key is associated with 15 attributes, in CP-ABE, there
are 15 attributes transmitted in one update. Instead, only 1
attribute is transmitted each time in DABE. The more attribute
updates, the more network load, and the more CPU resources.
So attribute updates can be viewed as an index for system
performance. Attributes are randomly picked from 50 QLSs
(i.e., 150 attributes in total); we assume each QLS contributes
one attribute at most to the private key. That whether an
attribute is from layer 1, layer 2 or layer 3 is random (1/3
chance for each layer). The rest of settings are the same as
the previous experiment.
2) Comparison with CP-ABE: We first calculate the amount
of attribute updates in CP-ABE case. As we know, CP-ABE
uses the expiration timestamp attributes to revoke private keys.
Assume this approach works perfectly (while it might not
in reality), a car updates its ENTIRE private key only when
necessary (when it enters a new quadrant). So
ECP −ABE (AU ) = N a × E(KU ) = N a × E(QC)
X
= N a(
EQLSi (QC))
1≤i≤N a

= N a(

X

((p(layerj ) × N a) × Elayerj (QC)))

1≤j≤3

= N a(

X N a × Elayerj (QC)
)
3

1≤j≤3

(N a)2 X
=
(
Elayerj (QC))
3
1≤j≤3

On the other hand, DABE has extra cost (Update Frequency)
in addition to updates happened on the edge of quadrants, but
it never updates the entire key. So
EDABE (AU ) = E(KU ) + E(KU ) × E(U F )
= E(QC)(1 + E(U F ))
N a(1 + E(U F )) X
=
(
Elayerj (QC))
3
1≤j≤3

Fig. 6.

Scalability improvement over CP-ABE

Given E(UF) is 2 here, CP-ABE’s update cost is O(N a2 ), far
more than that of DABE, which is only O(N a).
Simulation results showed in Fig. 6 coincide with our
calculation (E(QC) are 17.9, 22.7 and 43.1 times for layer
1, 2 and 3 with our settings). Attribute updates significantly
increase when the number of dynamic attributes in a private
key grows. As for DABE, we note that it suffers more overhead
than CP-ABE when the number of attributes in a private key
is very small. It does shine, however, when the number of
attributes associated with the private key grows. In fact, DABE
scales enormously better than CP-ABE, with one order of
magnitude improvement for 50 dynamic attributes. This result
supports our previous claim that “the overhead produced by
private key updates far outweighs the unnecessary updates in
DABE”. It is worthwhile to point out that we assume CP-ABE
updates only when necessary, so its performance is a little
overestimated leading to a CONSERVATIVE comparison.
The above results illustrate that the private key refresh
approach in CP-ABE is not scalable with the increase in
dynamic attributes. By saving updates of the unchanged attributes in the private key, DABE achieves a better efficiency
in a scenario where attributes tend to change frequently.
DABE allows administrators to tune the balance between
security and efficiency and build a system optimized for a
specific application based on the average key size, security
requirements, etc., and shows more flexibility than CP-ABE.
VI. C ONCLUSIONS
This work is a follow-up of the previous research on Situation Aware Trust. SAT uses descriptive attributes to efficiently
perform security policy control. ABE is used as the basis to
integrate the policy control and security services for SAT. One
of SAT’s main contributions is to divide attributes into two
categories, static and dynamic, in order to improve efficiency.
However, this does not help much since updating is still in
terms of (private) keys, instead of attributes. In this paper,
we introduce the concept of fading function to CP-ABE in
order to allow attribute level update. Fading functions allow
treating attributes in accordance with their rate of change
so that attributes can be updated independently from entire
private keys. We find the fading rate of fading functions is the

key to balance the tradeoff between security and efficiency
of the system. By choosing an appropriate fading rate for
each attribute, we are able to build an efficient system with
acceptable security level. We also show that the benefits of
avoiding key update far overweigh the overhead the new
scheme may bring, thus making our scheme much more
efficient and scalable than the traditional CP-ABE system in
presence of dynamic attributes.
R EFERENCES
[1] J. Bethencourt, A. Sahai, and B. Waters. Ciphertext-Policy AttributeBased Encryption. In the 28th IEEE Symposium on Security and Privacy,
Oakland, 2007.
[2] A. Sahai and B. Waters. Fuzzy Identity Based Encryption. In Advances
in Cryptology - Eurocrypt, volume 3494 of LNCS, pages 457-473,
Springer, 2005.
[3] V. Goyal, O. Pandey, A. Sahai, and B. Waters. Attribute Based
Encryption for Fine-Grained Access Conrol of Encrypted Data. In ACM
conference on Computer and Communications Security (ACM CCS),
2006.
[4] M. Pirretti, P. Traynor, P. McDaniel, and B. Waters. Secure AtrributeBased Systems. In ACM conference on Computer and Communications
Security (ACM CCS), 2006.
[5] Xiaoyan Hong, Dijiang Huang, Mario Gerla and Zhen Cao. SAT:
Building New Trust Architecture for Vehicular Networks. In the 3rd
International Workshop on Mobility in the Evolving Internet Architecture
(MobiArch’08), ACM SIGCOMM workshop, Seattle, 2008.
[6] A. Shamir. How to share a secret. Commun. ACM, 22(11):612C613,
1979.
[7] A. Shamir. Identity Based Cryptosystems and Signature Schemes. In
Advances in Cryptology - CRYPTO, volume 196 of LNCS, pages 37-53,
Springer, 1984.
[8] D. Boneh and M. Franklin. Identity Based Encryption from the Weil
Pairing. In Advances in Cryptology - CRYPTO, volume 2139 of LNCS,
pages 213-229, Springer, 2001.
[9] http://www.census.gov/geo/www/tiger/index.html
[10] M. Treiber, A. Hennecke, and D. Helbing. Congested Traffic States in
Empirical Observations and Microscopic Simulations. Physical Review,
E62, 1805-1824, 2000.
[11] J. Haerri, M. Fiore, F. Filali, and C. Bonnet. VanetMobiSim: Generating Realistic Mobility Patterns for VANETs. In ACM International
Workshop on Vehicular Ad Hoc Networks (VANET), 2006.
[12] http://vanet.eurecom.fr/

A PPENDIX
M ATHEMATICAL C ONSTRUCTION
The mathematical construction of DABE is based on
Bethencourt et al. [1] ’s CP-ABE construction. Most parts are
exactly the same. Readers should pay attention to the places
where fading functions are used.
Definition: G0 is a bilinear group of prime order p. g
is the generator of G0 . e : G0 × G0 → G1 denotes a bilinear
∗
map. Define a hash function H : {0, 1} → G0Qas a random
oracle. Define Lagrange coefficient ∆i,S (x) = j∈S,j6=i x−j
i−j
where i ∈ Zp and S is a set of elements in Zp .
att(j) represents the base value of attribute j. An attribute
value is time-dependent and depicted by Fj (att(j), t), where
Fj is a fading function for attribute j.
Setup: the Key Master chooses a bilinear group G0 of
prime order p with generator g and two random exponents
α, β ∈ G0 . The public key P K = G0 , g, h = g β , e(g, g)α is
published. The Key Master keeps the master key M K = β, α.

Encryption(P K, M, T): A sender first chooses a polynomial
qx for each node x in the policy tree T. Set the degree dx of
the polynomial qx to be one less than the threshold value of
that node (for OR, threshold is 1; for AND, threshold is the
number of children). Starting with the root node R, choose a
random s ∈ Zp and set qR (0) = s. Then randomly choose dR
other points of the polynomial qR to define qR completely.
For any other node x, set qx (0) = qparent(x) (index(x)) (In
T, every children node are numbered. Index(x) returns such a
number associated with node x), and choose dx other points
randomly to completely define qx . The ciphertext is:
CT = (T, C̃ = M e(g, g)αs , C = hs ;
∀j ∈ S : Cj = g qj (0) , Cj0 = H(Fj (att(j), t))

qj (0)

)

Key Generation(M K, S): The Key Master chooses a random
r ∈ Zp and random rj ∈ Zp for each attribute j ∈ S. Compute
private key as
SK = (D = g

α+r
β

,

∀j ∈ S : Dj = g r H(Fj (att(j), ti ))rj , Dj0 = g rj )
The Key Master stores r as the user’s profile and uses it to
generate attributes for that user in the future:
AT T = (∀j ∈ S : Dj = g r H(Fj (att(j), ti ))rj , Dj0 = g rj )
Decryption(CT, SK): DecryptNode(CT, SK, x) is a recursive algorithm used to decrypt a cipher. x is a leaf node in
the policy tree. When attribute x is not in a receiver’s private
key, DecryptNode(CT, SK, x) = N U LL. If a receiver has
attribute x, then:
e(Dx , Cx )
DecryptN ode(CT, SK, x) =
e(Dx0 , Cx0 )
e(g r H(Fx (att(x), tt ))rx , g qy (0) )
=
e(g rx , H(Fx (att(x), t))qy (0) )
= e(g, g)rqx (0)
When x is a non-leaf node, for all nodes z that are children
of x, call DecryptNode(CT, SK, z) and store the output as Fz .
If all the children have valid returns (not NULL), compute
Y
Fx =
Fz ∆i,Sx0 (0) (i = index(z), Sx0 = {index(z) : z ∈ Sx })
z∈Sx

=

Y

(e(g, g)

0 (0)
r·qz (0) ∆i,Sx

)

z∈Sx

=

Y

(e(g, g)

0 (0)
r·qparent(z) (index(z) ∆i,Sx

)

z∈Sx
rqx (0)

= e(g, g)

(using polynomial interpolation)

If a receiver has all the attributes to satisfy the policy tree, he
can successfully obtain A = DecryptN ode(CT, SK, R) =
rq (0)
rs
e(g, g) R = e(g, g) by recursively calling DecryptNode
from leaf nodes to the root. Finally, decrypt message by
rs

C̃/(e(C, D)/A) = C̃/(e(hs , g (α+r)/β /e(g, g) ) = M

Enabling Secure Location-based Services
in Mobile Cloud Computing
Di Ma

Yan Zhu

Computer and Communication Engineering
University of Science and Technology Beijing
30 Xueyuan Rd, Beijing 100083, China

Computer and Information Science
University of Michigan-Dearborn
4901 Evergreen Rd, Dearborn, MI 48128

zhuyan@ustb.edu.cn

dmadma@umd.umich.edu
Changjun Hu

Dijiang Huang

Computing Informatics & Decision Systems Eng.
Arizona State University
699 S. Mill Avenue, Tempe, AZ 85281

Computer and Communication Engineering
University of Science and Technology Beijing
30 Xueyuan Rd, Beijing 100083, China

dijiang.huang@asu.cn

huchangjun@ies.ustb.edu.cn

ABSTRACT

store data and perform computation in the cloud. Examples
of such applications include document sharing, media players and map browsers. In this paper we particularly focus on
location-based services (LBSs) in mobile cloud, which have
experienced explosive growth in recent years, particularly
leveraging fast development of mobile technology and the
wide use of mobile devices. In LBSs, the location of a device,
representing one of most important contextual information
about the device and its owner, is exploited to develop innovative and value-added services to the user’s personal context. Many individual, commercial and enterprise-oriented
LBSs are already available and have gained popularity. Analysts project revenues for LBSs to grow from $2.8 billion in
2010 to hit a $10.3 billion by 2015 [1].
The increasing popularity of LBSs has led to a renewed
research interest in location-based security, where one important problem is to enforce ﬁne-grained spatio-temporal
access control on a large number of users to prevent the
unauthorized access of services and the disclosure of valuable LBS data [2, 3]. Moreover, the possibility to identify
the user who requests a given service and her/his location information at the time of the request has raised much concern
on potential privacy violation [4]. Therefore, we are facing
the secure challenge of utilizing LBSs: on one hand, the user
needs to be identiﬁed by LBS server to get personalized location service as precise as possible; on the other hand, s/he
wants to maintain the privacy of her/his location information from the LBS server. Hence, it is critical to explore a
systematic mechanism to address above challenging issues.
Using location information for access control, i.e., locationbased access control (LBAC), is not a new concept [5]. However, one major challenge in geo-spatial computing is identiﬁed as “ﬁne-grained access control mechanisms permitting
the precise release of location information to just the right
parties under the right circumstances” [6]. To better illustrate the requirement of ﬁne-grained spatio-temporal access control in LBSs, we present a typical example, which
employs a payment-based subscription model where a 3dimensional spatio-temporal authorization is deﬁned as follows [7]: A paying user u subscribes to a LBS for a spatial
region (xf , yf , xe , ye ) and a time interval (ta , tb ); the user u
is allowed to read a broadcast from the LBS about a spatial

The increasing spread of location-based services (LBSs) has
led to a renewed research interest in the security of services.
To ensure the credibility and availability of LBSs, there is a
pressing requirement for addressing access control, authentication and privacy issues of LBSs in a synergistic way. In this
paper, we propose an innovative location-based ﬁne-grained
access control mechanism for LBSs, enabling eﬀective ﬁnegrained access control, location-based authentication and
privacy protection. Our proposed approach is based on the
construction of a spatio-temporal predicate-based encryption by means of eﬃcient secure integer comparison. Our
experimental results not only validate the eﬀectiveness of
our scheme, but also demonstrate that the proposed integer
comparison scheme performs better than previous bitwise
comparison scheme.

Categories and Subject Descriptors
D.4.6 [Security and Protection]: Cryptographic controls;
E.3 [Data Encryption]: Public key cryptosystems

General Terms
Security

Keywords
Location-based Service; Mobile Cloud; Access Control; Comparison Mechanism; Attribute-based encryption

1.

INTRODUCTION

Today, many mobile applications are constructed as client/
server applications, and make use of the 3G connection to
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
MCC’13, August 12, 2013, Hong Kong, China.
Copyright 2013 ACM 978-1-4503-2180-8/13/08 ...$15.00.

27

Table 1: Attribute lists for data user’s service certiﬁcate (access privileges).
ServiceName
Wireless

Period-of-Validity
2010/01/10 -2012/06/15

RealPlay

2011/04/01-2011/12/31

IFriends

2011/04/25-2012/06/13

Transport

2011/01/08-2011/12/22

RealTraﬃc

2010/08/28-2011/12/03

ServiceArea
[(33◦ 08’,111◦ 36’),(33◦ 50’, 112◦ 25’)] (Phoenix)
[(39◦ 12’,71◦ 11’),(40◦ 12’, 73◦ 58’)] (New York),
[(38◦ 44’, 74’15’),(39◦ 06’,75◦ 30’)] (Vineland)
[(38◦ 44’, 74◦ 15’), (39◦ 06’,75◦ 30’)] (Vineland)
[(33◦ 22’,111◦ 45’),(33◦ 27’, 111◦ 54’)] (Tempe),
[(33◦ 22’, 111◦ 38’),(33◦ 28’,111◦ 45’)] (Misa)
[(31◦ 20’, 108◦ 25’),(37◦ 00’,115◦ 00’)] (Arizona)

coordinate (x, y) at time t if and only if xf ≤ x ≤ xe and
yf ≤ y ≤ ye and ta ≤ t ≤ tb . In reality, spatio-temporal
authorization can be more complex and subject to multidimensional restrictions. Table 1 lists several example service certiﬁcates stored on a user’s mobile device. Each certiﬁcate consists of ﬁve attributes: ServiceName is a string
attribute used to distinguish diﬀerent services; Period-ofValidity is a time attribute on year/month/day basis; ServiceArea is a location attribute on geometric and symbolic
representations, respectively; and Category and QoS are two
integers which can be speciﬁed by the service providers.
Attribute based encryption (ABE) schemes [8, 9] have
been recently introduced for ﬁne-grained access control. However, there has been little work on studying integer comparison mechanisms to support spatio-temporal control in
the context of ABE. Even though Bethencourt et al. [10]
presented a bitwise comparison method to implement integer comparison based on CP-ABE scheme, it is not eﬃcient
enough for practical applications. For example,
Suppose a global-oriented LBS needs to make approximate
1 mile precision to express geographical coordinates. In accordance with general latitude and longitude expressions
(degrees, minutes), we must implement the integer representation in the range [1; 21,600] and the eﬃcient integer
comparison function in it, where 21,600=360*60.

Category
≥ 3(IndividualPlan)

QoS
≤ 3(HighBandwidth)

= 2(FamilyPlan)

≥ 2(LowRate)

≥ 10(MobileClient)

= 4(CertiﬁedMembers)

= 1(PrepaidClient)

= 1(Category)

≤ 5(VIPmember)

= 4(Frequency)

Contributions. In this paper, we address the afore-mentioned
security and privacy issues in LBSs by constructing a locationbased ﬁne-grained access control (LFAC) framework to provide spatio-temporal access control as well as user privacy
protection. Our primary goal is to design a new cryptosystem which can support ﬂexible access control over various
types of comparison-based constraints, including:
• Control over independent values, such as, service name,
device ID. For example, (ServiceName = “RealTraﬃc”)
and (Category = “FamilyPlan”);
• One dimensional attribute control, such as, time, level, or
salary. For example, (3 ≤ Category ≤ 5) and (2, 000 ≤
Salary ≤ 5, 000));
• Complex control on multi-attributes, such as, two dimension coordinate, periodic control on Week and Hour. For
example, ((3 ≤ Week ≤ 5) AND (8:00PM ≤ Hour ≤
10:00PM)) and ((33◦ 08’≤ X ≤ 111◦ 36’) AND (33◦ 50’
≤ Y ≤ 112◦ 25’)).
To achieve our goal, we make the following contributions:
1. Our LFAC framework is built upon a novel construction
of a spatio-temporal predicate-based encryption scheme
(ST-PBE). In LFAC, access policies are enforced entirely
by spatio-temporal attribute matches between ciphertexts
and private keys on the user side, and no user identiﬁcation information is required.

Hence, lacking an eﬃcient secure comparison mechanism
makes existing ABE schemes diﬃcult to realize various predicates required by ﬁne-grained access control. Furthermore,
since a user’s service certiﬁcate could contain complicated
relationships among various attributes (see Table 1), it is
necessary to explore a comprehensive cryptographic technique to express those relationships.
In addition to access control in LBSs, potential privacy
violation of LBS users has also raised a lot of concern. Although LBS services introduce problematic issues for privacy leakage due to the nature of the service, some locationprivacy preserving approaches have been proposed in recent
years, such as,

2. To achieve ﬁne-grained access control under the framework of ST-PBE, we propose a secure cryptographic integer comparison scheme to support various spatio-temporal
comparison-based predicts required by ﬁne-grained access
control. It is a new cryptographic scheme which can realize the capability of supporting range attributes allows
a user to employ coarse-grained spatio-temporal information in service query to achieve the obfuscation feature.

Unlinkability of LBS Transactions: diﬀerent transactions
of the same customer are unlinkable [11];

Organization. This paper is organized as follows. Section 2 discusses the system and security models of our approach. Section 3 overviews our proposed scheme. In Section 4, we analyze the performance of our scheme. Finally,
we conclude this paper in Section 5.

Anonymity Set of User Identity: many users hold the
same identifying information [12];

2. SYSTEM AND SECURITY MODELS

Obfuscation of Location Query: the coarse-grained spatiotemporal information is used to query LBS service [13].

2.1 System Model

In general, it is an eﬀective way for developing a practical
framework covering spatio-temporal access control model,
various cryptographic methods, and location-privacy approaches
to realize the secure LBS. Therefore, further research is
needed to eﬀectively defend against the risk of privacy leakage and unauthorized LBS access.

28

We consider a LBS system on mobile cloud involving three
diﬀerent entities [14] as illustrated in Figure 1. We assume
that Certiﬁcation Center is a trusted third party (TTP), in
which the user ID is omitted from the location query and
the network address of the query message is anonymized
through sender anonymity mechanisms such as Crowds or
Onion Routing.

Location Measurement

2.2 Security Model

Location
Providers
And
Access Point

......

Within the three entities involved, the certiﬁcate center
is a trusted entity. Hence, we are concerned with security
risks with respect to LBS servers and data users:

Internet

• LBS servers: Similar to [15, 16], we consider “Honest but
Curious” servers. That is, servers are assumed to follow
the proposed protocol in general, but try to ﬁnd out as
much “privacy” information as possible based on the users’
inputs. In particular, we assume the servers are more
interested in learning user’s private information, such as
access habits, history of past movements, and access privileges, rather than user’s secret information such as private
keys.

Data Provider
Service Request
Data
Encrypted Data
Location-based
Sever

Mobile Users

The User’s
Acc
ess P
Public key
(the ermiss
ion
user
&
's pr
ivate License
keys
)

Cloud Computing

Certification Center

• Data users: A dishonest user would try to access data outside the scope of her/his access privileges. To do so, unauthorized users may attempt to change the spatio-temporal
constraints in her/his service certiﬁcate independently or
cooperatively (called collusion attacks). Each party is
preloaded with a private key and the public key can be
easily obtained when necessary.

Figure 1: Location-based service architecture.
Mobile User is an entity who wants to access LBS data. It
is issued with a service certiﬁcate with certain access privileges. A user can access its current location information
either by a equipped GPS device or through a location
information provider.
Location-based Service Provider is an entity that provides customized location-based services according to the
user’s request with her/his location information.

3. OVERVIEW OF PROPOSED SCHEME

Certiﬁcation Center is a trusted third party (TTP) which
issues user certiﬁcates (containing user private keys) and
provides necessary public parameter information to realize
secure LBSs.

Let A denote a set of attributes. A user’s access privilege
P is deﬁned as an arbitrary Boolean function on AND/OR
logical gates and various comparison predicates, such as
Equal, Contain, Cross, over A. For example,

3.1 Notations

P = (Equal(A, x) AND (Contain(B, [v1 , v2 ]) OR Smaller(C, y))),

To ensure data access compliant with the assigned policy,
the ﬁne-grained access control are introduced into LBSs, in
which we make use of the ABE’s “privilege-constraint” attribute matching mechanism to transfer the service authentication into the client side, such that this minimum guarantee that the user’s information cannot be obtained by the
LBS providers. The system operates as follows:

where [v1 , v2 ] denotes the integer range between v1 and
v2 . Similarly, the access constraint L can also be deﬁned as
the combination of a set of attribute constraints over these
comparison predicates. For example, Contain(A, [x1 , x2 ]),
Equal(B, v), Greater(C, y)). Other notations are summarized
in Table 2.

• A user obtains her/his service certiﬁcate (the private key
with access privilege P) from the certiﬁcate center;

Table 2: Notations

• Upon receiving a request, which contains the objective
requested and location information Lc , from an authorized
user, the LBS provider

Name
P KA
SKP
MK
HL
ED
C
ek

– Authenticates the user’s access privilege by means
of anonymous authentication, and receives the user’s
LBS query in a secure way;
– Processes the related data from content/data provider
with respect to location Lc ; and

Description
the public key over A;
the private key over P: SKP = (SK1 , SK2 );
the master key held by the system manager;
the header of ciphertext over L;
the body of ciphertext, or the encrypted service data;
the ciphertext consists of HL and ED ;
the session key used to encrypt the data.

3.2 Spatio-Temporal Predicate-based
Encryption

– Employs an encryption method to convert the result
data into a ciphertext C that embeds the necessary
access constraint L, and sends the ciphertext to the
user.

A spatio-temporal predicate-based encryption (ST-PBE)
scheme, constructed on Key-Policy ABE model, consists of
four algorithms as follows:

• The authorized user can decrypt C and obtain the requested data by using her/his certiﬁcate (private-key) with
access privilege P.

• Setup(1κ , A): Takes a security parameter κ and a set of
attributes A as input, outputs the master key M K and
the public-key P KA ;

Through interactions with other entities in the system,
an authorized user can enjoy the services provided by LBSs
only if her/his access privilege P satisﬁes the location-based
access constraint L and Lc belongs to the area deﬁned in P.

• GenKey(M K, uk , P): Takes a user’s ID number uk , the
user’s associated access privilege P and M K as input,
outputs the user’s private key SKP over P;

29

• Encrypt(P KA , L): Takes an access constraint L and P K
as input, outputs the ciphertext header HL and a random
session key ek; and

access. Due to the dual purposes, we represent SKP as
SKP = (SK1 , SK2 ) where SK1 is used for service authentication while SK2 is used to regulate service data access.
As shown in Figure 2, SK1 is used to implement a simple service-aware authentication protocol. SK1 is generated over partial of the user’s access privileges denoted as
P1 : SK1 = GenKey(M K, uk , P1 ). P1 only consists of a
determination of “ServiceID” (SrvID) and “period-of-valid”
(PoV), that is,

• Decrypt(SKP , HL ): Takes a user’s private key SKP and
a ciphertext header HL as input, outputs a session key
ek.
Given a cryptographic system based on our ST-PBE definition, we must guarantee that this cryptosystem can follow the principle in range-based access control: Let Ak ∈
A be a range-based attribute and (P, L) be a privilegeconstraint pair with Ak , where Contain(Ak , [xi , xj ]) ∈ P
and Contain(Ak , [xa , xb ]) ∈ L. Secure comparison problem
requires that the access is granted if and only if [xi , xj ] ∩
[xa , xb ] = ∅. That is, given the above-mentioned (P, L),
we can compute (M K, P KA ) ← Setup(1κ , A) and SKP ←
GenKey(M K, uk , P), such that the following equation holds
if and only if the access is granted over (P, L) according to
a ﬁne-grained access control model:
⎡
⎢
Pr ⎣

P1 = (Equal(SrvID, “s”) AND Contain(PoV, [v1 , v2 ])).
Let c be the current time. Given an access constraint L1 =
(Equal(ServiceID, “s ”), Equal(PoV, c)), the LBS server sends
a ciphertext header HL1 which hides a random session key
ek1 : (HL1 , ek1 ) ← Encrypt(P KA , L1 ). The user can be authenticated if s/he can retrieve ek1 by using the operation
ek1 = Decrypt(SK1 , HL1 ), which implies “s” = “s ” and
c ∈ [v1 , v2 ]. SK2 also makes use of the same way to support
the predicate-based privilege P2 . We integrate the two keys
into a private-key by using “OR” operation.
Note that, the user can hold multiple private keys {SKP }
which correspond to diﬀerent services which the user has
subscribed to. However, these keys are not inter-operable.
This is because that even if these services share the same
attribute set A, these attributes may have diﬀerent values
according to diﬀerent access privileges.
Based on ST-PBE, the workﬂow of LFAC is described in
Figure 3. We illustrate the workﬂow as follows:

⎤
(HL , ek) ← Encrypt(P KA , L),
:
Decrypt(SKP , HL ) = ek
⎥
⎦=1
∀Ak , Contain(Ak , [xi , xj ]) ∈ P,
Contain(Ak , [xa , xb ]) ∈ L, [xi , xj ] ∩ [xa , xb ] = ∅

The practical ST-PBE scheme can be constructed on the
comparison-based encryption (CBE) [17] by using forward/
backward derivation functions (FDF/BDF).
The session key ek generated by Decrypt(SKP , HL ) is
used for data encryption. Operations on data are not shown
in the framework since the data sender could easily employ
a symmetric key cipher (ED ← Eek (D), D ← Dek (ED )) for
data encryption/decryption with ek. Note that the key ek
can only be obtained through the decryption algorithm.

Lightweight Service Authentication: When a mobile user
sends a simple “hello” service request, the location-based
server invokes the algorithm (HP1 , ek1 ) ← Encrypt
(P KA , P1 ) and sends HP1 to the mobile user. If the mobile user can obtain the valid ek1 ← Decrypt(SK1 , HP1 )
in a given time, s/he can move to the next step. Note
that, the temporary session key ek1 should be changed in
each request.

3.3 Location-based Fine-grained Access
Control
Access Policy in Private Key SK

Obfuscation and Query: The mobile user makes use of
obfuscation methods to get a coarse-grained spatio-temporal
query L, and then employs a symmetrical encryption scheme
to encrypt the query by using the key ek1 obtained in
the Lightweight Service Authentication phase, that is,
Q ← Eek1 (L). After receiving and decrypting the ciphertext (L ← Dek1 (Q)), the server checks whether the query
is valid. If the query is not valid, it will be stopped. Otherwise, the user queries the desired data from data providers
and moves to the next step.

OR

AND

AND

...
Equal(ServerID,...)

...
Contain(PoV,...)

Contain(Level,...)

OR

Subkey SK1 on policy P1

...

Contain(ServerArea,...)

Subkey SK2 on policy P2

LBS Information Transmission: The server ﬁrst encrypts
the spatio-temporal query L to generate a header of ciphertext HL and a new session key ek2 by (HL , ek2 ) ←
Encrypt(P KA , L). And then it encrypts the data to generate the real ciphertext body ED by using a symmetrical encryption with the help of ek2 , ED ← Eek2 (D).
Next, the ciphertext C2 = HL ||ED is sent to the mobile user. The mobile user can decrypt the header to
get ek2 ← Decrypt(SK2 , HL ) and then decrypt the body
to get the desired data by using the key ek2 , that is,
D ← Dek2 (ED ).

Figure 2: Illustration of Access Policy for Locationbased Service.
In this section, we describe how to build LFAC system
for LBSs from ST-PBE presented in the previous section.
Note that the user’s private-key SKP is constructed over a
spatio-temporal predicate-based privilege P with AN D, OR
and comparison operations. In LFAC, we use SKP for two
diﬀerent purposes, service authentication 1 and service data
1
The goal of such a design is to prevent abusive service requests targeting a DoS attack: the LBS provider only responds to users who have subscribed to the requested services and thus are able to pass the authentication process.

It is easy to ﬁnd that the LBS query condition L is speciﬁed
by the mobile user and it is a valid query if and only if L

30

Simple Sever Query

Server

Location-based Server

Service ID
Current Time
ST-PBE Encryption

ek1

Decryption for
Coarse Location

C1
SK1

Subscriber

Data

Coarse Location
Coarse
Location

ST-PBE Encryption

Encrypted
LBS Query

ST-PBE Decryption

ek1

Encryption for
Coarse Location

ST-PBE Decryption

(b) Obfuscation and Query

(a) Service Authentication

HP

Location

SK2

ek2

C2={HP||ED}
ek2

Symmetry-based
Encryption

ED
Symmetry-based
Decryption

(c) LBS Information Transmission

Data

Client

Figure 3: Illustration of LFAC workﬂow for location-based service.
can satisfy the access control policy P in the mobile user’s
private-key SKP .
The storage structure of LBS information transmission is
shown in Figure 4. According to diﬀerent attribute-values
and access constraints, the query results can be stored separately in diﬀerent blocks, e.g., a certain hotel information
can be encrypted by using its precise location (e.g., Equal
(ServiceArea, P os)) and the service level (e.g., Equal
(ServiceLevel, 4)). Of course, we can also encrypt the result data into one block by using a large constraint, e.g.,
(Constain(ServiceArea, Range)), in order to reduce computation cost.
D ata Block 1

H L1

G reater(Level,3)
Equal(ServiceA rea,Pos1)

ED1

D ata Block 2

H L2

ED2

Equal(Level,2)
Equal(ServiceA rea,Pos2)

allows a user to use a coarse-grained spatio-temporal information in location to achieve obfuscation. That is, a “location” in our system can be a region as opposed to a point and
it serves as a “cloak” to the user’s actual position. For example, the user can query the desired information in a relatively
large zone instead of his exact position. Cloaking also adds
noise to the spatio-temporal information of service queries.
In our LBS architecture, obfuscation is achieved through desired query scope or perturbation algorithms [18, 13]. It is
true that obfuscation methods may result in inaccuracy or
imprecision of the location/time. Thus, some location-based
applications may not work well if they get updates only on
a scale of hours and kilometers, as opposed to seconds and
meters. In this case, we need to carefully select the proper
granularity to balance the need for privacy protection and
service usability.

D ata Block n

......

H Ln

EDn

Equal(Level,1)
Equal(ServiceA rea,Posn)

4. PERFORMANCE EVALUATION

Figure 4: The storage structure of LBS information
transmission.
In LFAC, user privacy is protected through several ways.
First, access policies are enforced by “privilege-constraint”
attribute matching between ciphertexts and private-keys on
the client-side with the help of the KP-ABE model. In the
procedures of authorization and encryption, the LBS server
does not need any user identiﬁcation information to enforce
access policies. Hence, this ensures that user’s information,
including user identity and access privileges in the user’s private key, will not be disclosed to the LBS servers. Furthermore, this mechanism signiﬁcantly increases the diﬃculty
of identifying diﬀerent LBS requests sent by the same mobile user from a mass of user requests, which is called as
unlinkability of LBS transactions.
Moreover, the proposed LBS architecture provides a privacypreserving mechanism by separating users’ location information from users’ identities, in which the LBS server cannot
link a certain location with the speciﬁc user even if the server
obtains user’s location information in a LBS service query.
Users holding the same license (access privileges) may consist of a large “k-anonymity set” 2 . The larger the size of
the anonymity set, the greater the level of anonymity can
be oﬀered.
Furthermore, since interval or range predicates are introduced into our location-based access control mechanism, it
2
The anonymity set is deﬁned as the group of people who
hold the same access privileges.

31

We have implemented our ST-PBE scheme in Qt/C++
and experiments were run on an Intel Core 2 processor with
2.16 GHz and 500M of RAM on Windows Server 2003. All
disk operations were performed on a 1.82TB RAID 5 disk
array. Using GMP and PBC libraries, we have implemented
a cryptographic library (called as PKUSMC) upon which
temporal attribute systems can be constructed. This C library contains approximately 5,200 lines of code and has
been tested on Windows and Linux platforms.

Figure 5: Computational costs of our scheme under
diﬀerent comparison range (the eﬀective calculation
length is L = 2048-bits).
We show the practical computational costs of algorithms
for our scheme in Figure 5 under the eﬀective calculation
length is L = 2048-bits. In this example, for a certain comparison range [1, Z], we generate a secret-key with licence

[t1 , t2 ], where t1 ∈R [1, Z/4] and t2 ∈R [3Z/4, Z]; and a
message is encrypted by the time t ∈R [Z/4, 3Z/4]. So, we
ensure that max(t − t1 , t2 − t) ≥ Z/4. As the value of Z is
changed from 4 to 65, 536, the computational costs should
keep pace with the growth of comparison ranges. However,
we not this growth is not signiﬁcant by comparing with bilinear operations.
Computational overheads of main cryptographic operations of ST-PBE scheme were shown in Figure 6. The experiments involve 23 independent LBS requests, where we
choose randomly some policies and location queries over a
set of 7 attributes. These attributes include string, integer,
and location expressions. We found that it takes much more
time on the additional operations, such as, the policy-tree
construction and the access constrain generation. Therefore, the overhead of decryption in service authentication is
smaller than those in LBS data transmission because the
coordinate expressions are larger in LBS data transmission.
Overall, diﬀerent numbers and scales of attributes and constrains have aﬀected the system performance to some extent,
but not very seriously.

[3]

[4]

[5]

[6]

[7]

[8]
[9]

[10]

[11]

[12]

Figure 6: The computational overheads of cryptographic operations in our LBS system.
[13]

5.

CONCLUSIONS

In this paper, we have proposed a novel cryptographic
access control framework for LBSs on mobile cloud. This
framework facilitates ﬁne-grained access control, locationbased authentication, and privacy protection. Our framework is based on a spatio-temporal predicate-based encryption (ST-PBE) scheme which implemented a novel secure
cryptographic integer comparison mechanism to support various predicates required in LBSs. In addition, the implementation of a proof-of-concept prototype and corresponding
evaluation demonstrate the feasibility of our methodology.

6.

[14]

[15]

[16]

ACKNOWLEDGMENTS
[17]

The work of Y. Zhu and C.-J. Hu was supported by the
National Natural Science Foundation of China (Project No.
61170264 and No. 10990011) and the National 973 Program
(Project No. 2013CB329606).

7.

[18]

REFERENCES

[1] Jan Ten Sythoﬀ. Location-based services, market forecast,
2011-2015. Technical report, Pyramid Research, 2010.
[2] Heechang Shin and Vijayalakshmi Atluri. Spatio-temporal
access control enforcement under uncertain location
estimates. In Proceedings of the 23rd Annual IFIP WG

32

11.3 Working Conference on Data and Applications
Security XXIII, pages 159–174, Berlin, Heidelberg, 2009.
Springer-Verlag.
Maria Luisa Damiani, Elisa Bertino, and Claudio Silvestri.
The probe framework for the personalized cloaking of
private locations. Trans. Data Privacy, 3:123–148, August
2010.
Reza Shokri, George Theodorakopoulos, Jean-Yves Le
Boudec, and Jean-Pierre Hubaux. Quantifying location
privacy. In IEEE Symposium on Security and Privacy,
pages 247–262. IEEE Computer Society, 2011.
Mohamed F. Mokbel and Walid G. Aref. Gpac: generic and
progressive processing of mobile queries over mobile data.
In Panos K. Chrysanthis and George Samaras, editors,
Mobile Data Management, pages 155–163. ACM, 2005.
Muntz et al. It roadmap to a geospatial future. Technical
report, Committee on Intersections Between Geospatial
Information and Information Technology, National
Research Council, 2003.
Mudhakar Srivatsa, Arun Iyengar, Jian Yin, and Ling Liu.
A scalable method for access control in location-based
broadcast services. In INFOCOM, pages 256–260. IEEE,
2008.
Amit Sahai and Brent Waters. Fuzzy identity-based
encryption. In EUROCRYPT, pages 457–473, 2005.
Vipul Goyal, Omkant Pandey, Amit Sahai, and Brent
Waters. Attribute-based encryption for ﬁne-grained access
control of encrypted data. In ACM Conference on
Computer and Communications Security, CCS, pages
89–98, 2006.
John Bethencourt, Amit Sahai, and Brent Waters.
Ciphertext-policy attribute-based encryption. In IEEE
Symposium on Security and Privacy, pages 321–334, 2007.
ZP Jin, J. Xu, M. Xu, and N. Zheng. A location privacy
preserving algorithm based on linkage protection. In
Information Theory and Information Security (ICITIS),
2010 IEEE International Conference on, pages 190–194.
IEEE, 2010.
Byoungyoung Lee, Jinoh Oh, Hwanjo Yu, and Jong Kim.
Protecting location privacy using location semantics. In
Proceedings of the 17th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining
(KDD), pages 1289–1297, 2011.
John Krumm. Inference attacks on location tracks. In
Anthony LaMarca, Marc Langheinrich, and Khai N.
Truong, editors, 5th International Conference of Pervasive
Computing, PERVASIVE, volume 4480 of Lecture Notes in
Computer Science, pages 127–143. Springer, 2007.
Claudio Agostino Ardagna, Marco Cremonini, Sabrina
De Capitani di Vimercati, and Pierangela Samarati. A
privacy-aware access control system. Journal of Computer
Security, 16(4):369–397, 2008.
Sabrina De Capitani di Vimercati, Sara Foresti, Sushil
Jajodia, Stefano Paraboschi, and Pierangela Samarati.
Over-encryption: Management of access control evolution
on outsourced data. In VLDB, pages 123–134, 2007.
Shucheng Yu, Cong Wang, Kui Ren, and Wenjing Lou.
Achieving secure, scalable, and ﬁne-grained data access
control in cloud computing. In INFOCOM, pages 534–542.
IEEE, 2010.
Yan Zhu, Hongxin Hu, Gail-Joon Ahn, Mengyang Yu, and
Hong-Jia Zhao. Comparison-based encryption for
ﬁne-grained access control in clouds. In Elisa Bertino and
Ravi S. Sandhu, editors, CODASPY, pages 105–116. ACM,
2012.
Matt Duckham and Lars Kulik. A formal model of
obfuscation and negotiation for location privacy. In 3th
International Conference of Pervasive Computing,
PERVASIVE, pages 152–170, 2005.

Location-aware Key Management Scheme for Wireless
Sensor Networks
Dijiang Huang, Manish Mehta, Deep Medhi, Lein Harn
{dh7ee,mmmef7,dmedhi,harnl}@umkc.edu
University of Missouri-Kansas City

ABSTRACT

General Terms

Sensor networks are composed of a large number of low
power sensor devices. For secure communication among
sensors, secret keys must be established between them. Recently, several pairwise key schemes have been proposed for
large distributed sensor networks. These schemes randomly
select a set of keys from a key pool and install the keys in
the memory of each sensor. After deployment, the sensors
can set up keys by using the preinstalled keys. Due to lack
of tamper-resistant hardware, the sensor networks are vulnerable to node capture attacks. The information gained
from captured nodes can be used to compromise communication among uncompromised sensors. Du et al. [1], Liu and
Ning [2] proposed to use the known deployment information
to reduce the memory requirements and mitigate the consequences of node capture attack. Our analysis shows that the
assumption of random capture of sensors is too weak. An intelligent attacker can selectively capture sensors to get more
information with less eﬀorts. In addition to selective node
capture attack, all recent proposals are vulnerable to node
fabrication attack, in which an attacker can fabricate new
sensors by manipulating the compromised secret keys and
then deploy the fabricated sensors into the sensor system.
To counter these attacks, we propose a grid-group scheme
which uses known deployment information. Unlike the pairwise key scheme using deployment information proposed by
Du et al., we uniformly deploy sensors in a large area; instead of randomly distributing keys from a large key pool
to each sensor, we systematically distribute secret keys to
each sensor from a structured key pool. Our performance
analysis shows that our scheme requires less number of keys
preinstalled for each sensor and is resilient to selective node
capture attack and node fabrication attack.

Design, Security

Keywords
key management, sensor networks, probabilistic key sharing

1.

INTRODUCTION

Sensor networks are composed of a large number of lowpower sensor devices. Typically, these networks are installed
to collect sensed data from sensors deployed in a large area.
SmartDust [3] and WINS [4] are examples of sensor network
projects. Within the networks, sensors communicate among
themselves to exchange data and routing information. Since
the sensor networks are usually deployed in unattended or
even hostile environments (such as battle ﬁelds), the sensor
networks are vulnerable to various kinds of active and passive attacks on the communication protocols. This demands
secure communication among sensors.
We deﬁne a secure channel or link as as a channel through
which two nodes can communicate with each other using a
secret key. The secure channel is said to be compromised
if an attacker can compromise the secret key. Since the
low-power sensor devices have very limited computational
power, the symmetric-key systems are preferred to establish
secure channels. As speciﬁed in [5], the number of sensor
nodes deployed in studying a phenomenon may be on the
order of hundreds of thousands. Depending on the application, the number may reach an extreme value of millions.
Due to inherent storage constraints, it is infeasible for a sensor device to store a unique shared key value for every other
sensor in the system. One naı̈ve solution to use a common
key between every pair of sensors can overcome the storage
constraints, but it oﬀers weak security. Since, if one node is
compromised, the entire system is compromised. Recently,
Random Key Predistribution (RKP) schemes have been proposed [6, 7, 8, 9, 10] for large-scale distributed sensor networks. These schemes randomly select a set of keys from a
large key pool and install the keys in the memory of each
sensor. After deployment, the sensors can set up keys by
using the preinstalled keys. Since the RKP schemes require
limited number of keys preinstalled in the sensors, a sensor
may not share a key with all of its neighbors. In this case,
a Pairwise Key Establishment (PKE) scheme is required to
set up a shared key with every neighbor.
In current RKP schemes, the analyses of the security
strength are done on the basis of number of communication
links that can be compromised due to compromised sen-

Categories and Subject Descriptors
C.2.0 [Computer-communication networks]: General—
Security and protection

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SASN’04, October 25, 2004, Washington, DC, USA.
Copyright 2004 ACM 1-58113-972-1/04/0010 ...$5.00.

29

2.

sors in the network. In other words, the schemes consider
probable use of the keys, exposed due to captured sensors,
in non-compromised parts of the network. This attack is
called node capture attack. Also, the current schemes consider random capture of nodes in the deployment region.
To mitigate the random node capture attack, Du et al. [1]
and Liu and Ning [2] proposed using deployment information (sensor location information) to improve the resilience
to node capture attack. However, in practice, the open or
hostile deployment environment of sensor networks makes it
easier for attackers to locate and selectively capture sensors
which can provide more information for attackers to attack
the sensor networks. In addition, due to lack of node authentication, attackers can easily fabricate nodes by using
the secrets preinstalled in the captured node.
In this paper, we propose a new scheme, called Grid-group
deployment scheme. This scheme utilizes merits from both
[1] and [2]. Similar to [1, 2], a sensor deployment area is
partitioned into multiple small square areas (zones) and the
sensors deployed in each zone form a group. In the key
predistribution phase, using the unconditionally secure and
λ-collusion resistant properties of the group keying scheme
proposed in [11], we utilize the key predistribution scheme
proposed in [8, 9] to distribute keys for the sensors in each
zone; for each sensor, we select a sensor in each of its adjacent zones and assign a unique key to them (the selection
of the pair of sensors is based on the mapping between the
unique node IDs assigned to the sensors; the technical details are presented in Section 4.2.2). After the deployment
of sensors, each sensor ﬁrst sets up pairwise keys with all
its neighbors within its zone; then it sets up pairwise key
with its neighbors located in adjacent zones. Comparing
with previously proposed schemes, our approach is resilient
to selective node capture attack and node fabrication attack.
Our main contributions in this paper are as follows:

BACKGROUND OF RANDOM KEY PREDISTRIBUTION SCHEMES

In this section, we review Purely Random Key Predistribution (P-RKP) schemes [6, 7] and Structured Key-pool
Random Key Predistribution (SK-RKP) schemes [8, 9].

2.1

The Phases in Random Key Predistribution Schemes

We present the main phases for random key predistribution schemes [6, 7, 8, 9] as follows:
1. Key predistribution phase: A centralized key server
generates a large key pool oﬄine. The procedure for
oﬄine key distribution is as follows: 1. Assign a unique
node identiﬁer or key ring identifer to each sensor, 2.
Select m diﬀerent keys for each sensor from the key
pool to form a key ring, 3. Load the key ring into the
memory of the sensor.
2. Sensor deployment phase: The sensors are randomly
picked and uniformly distributed in a large area. Typically, the number of neighbors of a sensor (n ) is much
smaller than the total number of deployed sensors (N ).
3. Key discovery phase: During the key discovery phase,
each sensor broadcasts its key identiﬁers in clear-text
or uses private share-key discovery scheme1 to discover
the keys shared with its neighbors. By comparing the
possessed keys, a sensor can build the list of reachable
nodes with which share keys and then broadcast its
list. Using the lists received from neighbors, a sensor
can build a key graph (see Deﬁnition 1) based on the
key-share relations among neighbors.
4. Pairwise key establishment phase: If a sensor shares
key(s) with a given neighbor, the shared key(s) can
be used as their pairwise key(s). If a sensor does not
share key(s) with a given neighbor, the sensor uses the
key graph built during key discovery phase to ﬁnd a
key path (see Deﬁnition 2) to set up the pairwise key.

• We point out the weak assumption of random capture
of nodes in current RKP schemes and introduce selective attack on RKP schemes. In particular, we show
the importance of selective attack in RKP schemes
that use deployment information.

The set of all neighbors of sensor i is represented by Wi .
The deﬁnition of key graph is given as follows:

• We point out the node fabrication attack on current
RKP schemes and countermeasures for the same.

Definition 1 (key graph). A key graph maintained by
node i is defined as Gi = (Vi , Ei ) where, the vertices set Vi =
{j|j ∈ Wi ∨ j = i}, the edges set Ei = {ejk |j, k ∈ Wi ∧ jRk},
R is a relation defined between any pair of nodes j and k if
they share required number of key(s) after the key discovery
phase.

• We propose a new RKP scheme called Grid-group deployment scheme which is based on current schemes
and deployment information. Further, this scheme is
resilient against the introduced selective attack and
node fabrication attack.
• Our proposed scheme reduces the number of keys preinstalled in each sensor.

The deﬁnition of key path is given as follows:
Definition 2 (key path). A key path between node A
and B is defined as a sequence of nodes A, N1 , N2 ,. . .,
Ni , B, such that, each pair of nodes (A, N1 ), (N1 , N2 ), . . .,
(Ni−1 , Ni ), (Ni , B) has required number of shared key(s) after the key discovery phase. The length of the key path is
the number of pairs of nodes in it.

The rest of the paper is organized as follows: In section 2,
we provide the background of RKP schemes in sensor networks. We introduce attacks on current schemes in section 3.
Section 4 describes our proposed scheme. The sensor area
coverage analysis for the proposed scheme is given in section 5. In section 6, we analyze the key graph connectivity
based on our proposed scheme. The Pairwise Key Establishment protocol is presented in section 7. A performance
analysis addressing storage requirements, security, communication overhead, and computation overhead is given in section 8. Section 9 provides summary and future work.

1
Speciﬁed in [6], using private share-key discovery, for every
key on a key ring, each node could broadcast of list α,
EKi (α), i = 1, . . . , k, where α is a challenge. The decryption of EKi (α) with the proper key by a recipient would
reveal the challenge α and establish a shared key with the
broadcasting node.

30

2.2 Purely Random Key Predistribution (PRKP) Schemes

3.

ATTACKS ON RANDOM KEY PREDISTRIBUTION SCHEMES

For current P-RKP schemes, the phases presented in Section 2.1 can be applied without any change. There are two
characteristics of P-RKP schemes. First, the m keys preinstalled in a sensor can also be installed in other sensors.
That is, a key can be shared by more than one pair of sensors. Second, in most of current schemes, there is no relation between the set of preloaded keys and the sensor id.
A recent solution proposed by Pietro et al. [12] attempts to
deﬁne this relation. However, the scheme is not scalable in
that the size of the network is restricted by a function of
number of preinstalled keys.

The proposed P-RKP schemes and SK-RKP schemes have
several limitations which make them vulnerable to attacks.
Since sensors are low-cost devices and operate in unattended
environment for many applications, they cannot be considered tamper-resistant. We make following assumptions
about capabilities of the attacker.

2.3 Structured Key-pool Random Key Predistribution (SK-RKP) Scheme

• The attacker can listen and record all the traﬃc in the
network.

Unlike in P-RKP schemes, in SK-RKP scheme, each sensor is preloaded with a unique set of keys in its memory.
The key discovery is not simply ﬁnding a shared key with
the neighboring sensor, but using a set of polynomial variables (constructed by the keys possessed by the sensor) to
derive the shared key. In addition, the key id can serve
as the sensor id which is linked to the set of preinstalled
keys. This link can prevent the attackers from misusing the
sensors’ ids. In the following paragraphs, we give a brief
description of structured key pool scheme.
The SK-RKP scheme uses the key predistribution scheme
proposed by Blom [13]. This scheme allows any pair of nodes
in a network to ﬁnd a pairwise key in a secure way as long
as no more than λ nodes are compromised. The scheme is
built on two matrices: a publicly known matrix G of size
(λ + 1) × N ; a secret matrix D of size (λ + 1) × (λ + 1)
created by key distribution center. The matrix A of size
N × (λ + 1) is then created as A = (D · G)T . Each row of
A is the keys distributed to a group member and the row
number can serve as a sensor’s id. Since K = A · G is a
symmetric matrix, nodes i and j can generate a shared key
(Kij or Kji ) from their predistributed secrets, where Kij is
the element in K located in the ith row and jth column.
A key pool is constructed by many key spaces, represented
by A(t) , where t = 1, . . . , ω. Each sensor randomly selects
τ key spaces out of ω key spaces, where τ < ω. If sensor k
selects key space A(t) , the kth row of A(t) and kth column
of G are preinstalled in the sensor (note that the G matrix
is unique). The SK-RKP scheme has following properties:

• The attacker has ability to physically locate a given
sensor by listening to the traﬃc.

• The attacker has unlimited energy and computing power.
• The attacker knows all the information stored in a sensor once the sensor is captured.

• The attacker has ability to fabricate similar nodes and
deploy them.

3.1

Selective Node Capture Attack

In all current RKP proposals, the sensors are assumed to
be captured randomly. But in practice, the random capture
assumption is too weak. The attacker can purposely attack
certain area or a group of sensors possibly located closer
to each other. Thus, an attacker can purposely locate a
sensor and compromise the sensors which can give him more
information about the sensor network. For example, in PRKP scheme, each sensor broadcasts its key ring id (the
key list). An attacker can selectively compromise a sensor
that possesses the most number of keys that are not already
compromised.
We model the selective attack by using the heuristic technique. In the following presentations, x is the number of
compromised sensors, Cx is the cardinality of the set of compromised keys when x nodes are compromised, P is the size
of the key pool, m is the number of keys preinstalled in
each sensor, N is the total number of sensors deployed in
the network, and k is a variable. We use B to represent the
threshold that an attacker is to inspect and then to decide
which sensors to capture next. The mathematical model of
selective attack is presented as follows:



P −Cx
Cx

• Once two nodes i and j have keys presinstalled from
the same key space A(t) , they can derive a shared key
(t)
(t)
Kij = Kji .

B

m−k

=





k

(N − x)

(k = 0, . . . , m) (1)

( Ckx )
is the probability that there exist un( )
compromised nodes and each of them has m − k keys not
already compromised; N − x is the total number of uncompromised nodes in the system.
The heuristic method is described as follows. Initially,
when k = 0, an attacker can arbitrarily capture a sensor
and derive m keys preinstalled in the captured sensor and
Cx = m. Then, he inspects the B: if B ≥ 1, he continuously captures the nodes with m − k keys that are not
already compromised, and for each capture, Cx is increased
by m − k; if B < 1, he increases k by 1 until B ≥ 1. He then
captures the sensors with m − k keys that are not already
compromised. The attacker continues this process until the
where

• If x rows of a key space A(t) are predistributed to x
sensors and x ≤ λ, any subset of the x sensors cannot
collude to derive the secrets in other sensors.
• The id of a sensor is represented by the row number
of the key matrix A. No other sensor can impersonate
this sensor, since the row of A is uniquely distributed
to this sensor.
The technical details refer to [8, 9].

31

P −Cx
m−k
P
m

P
m

Fraction of compromised links among uncompromised nodes

Fraction of compromised links among uncompromised nodes

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

SA q−composite q=3
SA q−composite q=2
SA Basic scheme
RA q−composite q=3
RA q−composite q=2
RA Basic scheme

0.2

0.1

0

50

100

150

200

250

300

1

0.9

0.8

SA−ST ω=71,τ=6
SA−ST ω=32,τ=4
SA−ST ω=8,τ=2
RA−ST ω=71,τ=6
RA−ST ω=32,τ=4
RA−ST ω=8,τ=2

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

1725

50

100

150

200

250

300

Number of compromised nodes

Number of compromised nodes

(a) Selective attack on P-RKP schemes (m = 100, p1 = 0.423,
N =10000; basic scheme P = 28140; q-composite scheme,
when q = 2, P = 9120, when q = 3, P = 5220)

(b) Selective attack on SK-RKP schemes (m = 100, p1 =
0.423, N =10000)

Figure 1: Selective attack on RKP schemes.

compromises only few sensors and uses the captured keys to
fabricate sensors with identities of uncompromised sensors
or fabricate sensors with new identities. Then, the attacker
can deploy the fabricated nodes in the parts of the network
where the original node is not present. The uncompromised
sensors in the network cannot detect the fabricated nodes
as anomalous nodes as long as they can have standard communication with them. This attack is severer as compared
to passive listening attacks as the attacker may have enough
information to fabricate many sensors with many diﬀerent
identities and possibly outnumber the original set of sensors.
The attacker can launch the node fabrication attack on
P-RKP schemes [6, 7] by capturing only two sensors. Since
there is no id authentication by using P-RKP scheme, by
capturing
two nodes, the attacker can fabricate and deploy

2m
new
nodes without being detected. These fabricated
m
nodes are apparently good nodes, since they all have valid
keys. Thus, the fabricated nodes can quickly outnumber the
uncompromised nodes.
SK-RKP scheme is also vulnerable to node fabrication attack. However, there are few restrictions for the attacker.
First, an attack requires to capture more than λ sensors in
order to compromise a key space. Second, an attacker cannot arbitrarily generate new ids for the fabricated sensors,
since the ids indicate the rows of the secret matrix A possessed by the sensors. A wrong id will not guarantee that
a fabricated sensor can set up a pairwise key with uncompromised sensors. Thus, by restricting the distribution of
the number of rows of a secret matrix A to λ, we can prevent the node fabrication attack. Our scheme described in
the next section uses this technique. The previous proposals [8, 9] cannot fulﬁl this requirement with relatively small
λ to support a large sensor system with typically 1,000 to
10,000 sensors. Since in our scheme, we restrict the size of
deployment region by partitioning it into multiple zones, the
required network size for each zone becomes smaller and we
can prevent node fabrication attacks by using the technique

condition m = k is fulﬁlled or the entire key pool is compromised. The condition B > 1 means there exists uncompromised sensor that has m − k keys that are not already compromised. Figure 1(a) shows the comparison between the
selective-node-capture attack (SA) and random-node-capture
attack (RA) on the P-RKP schemes. It might be note that,
in this ﬁgure, the size of key pool P is computed based
on the key graph connectivity probability presented in [14]
and p1 is the probability that two sensors share at least one
key during the key discovery phase. Our studies show that
the selective node capture attack can gain more information
than random node capture attack with the same number of
captured sensors.
In SK-RKP scheme, the attacker can selectively capture
the sensors that possess keys within the same key space.
Once λ + 1 sensors with preinstalled keys from the same key
space are compromised, all the keys allocated from the same
key space are compromised. Thus, an attacker can incrementally compromise the sensors that use same key space.
In this way, the attacker can compromise all the key spaces
one-by-one. Since sensors have keys from more than one key
space preinstalled, the number of sensors required to be captured to compromise the subsequent key spaces is smaller.
Figure 1(b) shows the SK-RKP scheme [8, 9] under SA and
RA, with m = 100, p1 = 0.432. This ﬁgure shows that under selective attack, the robustness (threshold) of SK-RKP
scheme against node capture attack decreases dramatically.
In the example, the threshold values under SA are: 17 with
ω = 71, τ = 6; 25 with ω = 32, τ = 4; 50 with ω = 8, τ = 2.
The relation between the τ and the threshold is: the smaller
the τ , the higher the initial threshold. That is, with τ = 2,
we can maximize the initial threshold.

3.2 Active Attack: Node Fabrication Attack
The proposed P-RKP and SK-RKP schemes are all vulnerable to node fabrication attack. We describe the node
fabrication attack as follows: in this attack, the attacker

32

4.2

450

ω=9, τ=2, p =0.4167
1
ω=8, τ=2, p =0.4643
1
ω=7, τ=2, p =0.5238
1
ω=6, τ=2, p =0.6
1

400

z

Number of sensors in a zone (n )

350

300

250

200

4.2.1

150

I-Scheme: key predistribution within a given
zone

We use the scheme speciﬁed in Section 2.3 for our IScheme. To achieve the non-colluding 3 property. We set
the following restrictions:

100

50

0

Key Predistribution Schemes

The value (i, j) is used to identify a group or zone. We
use the superscripts + and − with i and j to denote the
neighboring groups or zones. For example, G(i+ , j) = G(i +
1, j) is a neighboring group of G(i, j). We propose two key
predistribution schemes according to the group relations.
The key predistribution scheme used within a group is called
I-Scheme and the key predistribution scheme used between
two neighboring groups is called E-Scheme.

0

10

20

30

40

50

60

70

80

90

• τ = 2, this maximizes the initial node capture threshold (refer to Figure 1(b)).

100

λ

Figure 2: Relation between λ and the number of
sensors deployed in a zone (nz ), and m = 100

• No more than λ sensors are allowed to choose a given
key space.

discussed above. Figure 2 shows the relation between the
value of λ and supported size of network for each zone (nz ).

• As a result of the ﬁrst two restrictions, we restrict the
number of sensors in each group, nz , to |G(i, j)| ≤
λω/τ .
As shown in Figure 1(b), for a ﬁxed value of m=100, the
number of keys preinstalled in each sensor, the smaller the
τ , the higher the initial node capture threshold. The initial
threshold is computed as m/τ . For example, for τ = 2,
ω = 8, and m = 100, the initial threshold is 50. Since τ = 2
gives the highest initial threshold. In this paper, we consider
τ = 2 for our analysis.
For each key space, the secret matrix A = (D · G)T is a
N × (λ + 1) matrix. If an attacker has knowledge of more
than λ rows, the entire matrix A can be derived. Thus, to
improve the survivability of the sensor system, we restrict
the number of rows of matrix A distributed to sensors to λ.
As a consequence of the previous restrictions, the number
of sensors deployed in each zone is restricted to |G(i, j)| ≤
λω/τ . Figure 2 shows the relation between |G(i, j)| and λ.
Based on above discussion, we propose the following key
predistribution scheme (I-Scheme) for the sensors located
within the same zone as follows:

4. GRID-GROUP DEPLOYMENT SCHEME
In this section, we present our grid-group deployment
scheme and the key predistribution schemes used for the
same.
For our scheme, we assume that the target deployment
area is a two-dimensional rectangular region with the size
(i · a) × (j · a) square meters. The rectangular region can be
further divided into (i·j) deployment areas, each of size a×a
square meters. In this paper, we denote each small deployment area as zone Z(i, j), where Area(Z(i, j)) = a2 . An
example of deployment region is shown in Figure 3, where
i = j = 6. We use G(i, j) to denote the group of sensors
deployed in zone Z(i, j). We assume that the sensors are
uniformly distributed over the deployment region and for
each group, the number of sensors in the group is nz . We
denote the total number of sensors in the whole deployment
region by N . Thus, we have N = nz · i · j. A sensor is
identiﬁed by [(i, j), b], where (i, j) is the group id, and b is
the unique node id of a sensor (b = 1, . . . , N ).

1. The key pool P is composed by P = L × M sub-key
pools (a sub-key pool is represented as P(i, j) where
i = 1, . . . , L, j = 1, . . . , M ). Each sub-key pool is
divided into ω sub-key spaces. A sub-key space is a
N × (λ + 1) key matrix A. Each element of A is a
unique key.

4.1 Sensor Deployment Method
The sensor deployment method is given as follows:
• Partition N sensors into i · j groups with nz sensors in
each group.

2. Divide the N sensors in L × M groups (a group is represented by G(i, j), where i = 1, . . . , L, j = 1, . . . , M ).

• Assign the identiﬁer [(i, j), b] to each sensor in the
G(i, j), where b = 1, . . . N .

3. Assign unique identiﬁers to the sensors. For each sensor, assign the id = [(i, j), b], where (i, j) is the group
id, and b = 1, . . . , N .

• Assign m keys to each sensor in group G(i, j).2

3
The non-colluding feature of the proposed pairwise key
scheme is described as follows: for all pairwise key Kij ∈ P,
where Kij is the pairwise key that can be derived from the
secrets possessed by sensors si , sj ∈ S, all sensors in the set
S \ {si , sj } cannot derive the pairwise key Kij , S is the set
of all sensors deployed in the system.

• Uniformly distribute the sensors for the group G(i, j)
in zone Z(i, j).
2

The key-assignment is presented in Section 4.2.

33

i

Z(i−1,j−1)

Z(i−1,j)

100

3

4

5

6

1

(1,1)

(1,2)

(1,3)

(1,4)

(1,5)

(1,6)

a

2

(2,1) (2,2)

(2,3)

(2,4)

(2,5)

(2,6)

a

3

(3,1) (3,2)

(3,3)

(3,4)

(3,5)

(3,6)

a

15

25

20

Z(i−1,j+1)
30

20

90
35

30

35

45

(5,5)

(5,6)

a

30

30

(5,3) (5,4)

40

5 (5,1) (5,2)

40

45

45

35

20

40

40

30

35

35

6 (6,1) (6,2)

(6,3) (6,4)

(6,5)

(6,6)

15

0

a

a

a

a

a

Z(i+1,j−1)

a

0

10

30

25

20

20

20

30

40

50

60

70

80

Z(i+1,j)

90

15
100

Z(i+1,j+1)

Figure 4: Contour curves for average number of
neighbors within the same zone (n = 50, nz = 100)

Figure 3: Sensor deployment in a grid structure
4. For sensor [(i, j), b], randomly select τ sub-key spaces
from ω sub-key spaces in P(i, j) while making sure
that the selected sub-key space is not already selected
λ times. Load the sensor with the bth row of matrix A
for each sub-key space selected.

4.2.2

30

10

a

Z(i,j+1)

50

50

45

a

50

25

(4,6)

35

j
(4,5)

50

50
30

Z(i,j−1)

(4,4)

40

60

(4,3)

30

45

40

25

70

35

40

80

4 (4,1) (4,2)

15

25

25

2

25

1

sensor is n . The density of the deployed sensors is
n
ρ = πR
2.
According to the assumption presented above, the  number
£
2 
of deployed sensors within each zone is nz = a2 ρ ≈ aπRn2 .

E-Scheme: keys predistribution for two adjacent zones

5.1

Sensor Coverage – within the Same Zone

We present the coverage of sensor [(i, j), b] in its zone
Z(i, j) in this section. Given a position (x, y) for sensor
[(i, j), b], the sensor coverage is given as follows:
 1
p
Cb (i, j)|(x,y) , 0 ≤ x2 + y 2 ≤ R
p
Cb (i, j)|(x,y) =
Cb2 (i, j)|(x,y) , R < x2 + y 2 ≤ a/2

As shown in Figure 3, a zone can have the maximum of
8 neighboring zones; e.g., the bidirectional arrows shown
around zone Z(3, 3). Our key predistribution scheme (EScheme) for sensors in two adjacent zones is given as follows:
1. For a sensor i in group G(i1 , j1 ), randomly select one
sensor, say j, from one of its neighboring groups, say
G(i2 , j2 ). Groups G(i1 , j1 ) and G(i2 , j2 ) are neighbors
if |i1 − i2 | ≤ 1 or |j1 − j2 | ≤ 1.

The expressions for Cb1 (i, j) and Cb2 (i, j), along with the
proofs are given in Appendix A. From the above results,
the number of neighbors of sensor [(i, j), b] within the zone
Z(i, j) is given as:

2. Install duple < kij , idj > in i and duple < kij , idi > in
j, where key kij is unique and idi , idj are the identiﬁers
of node i, j respectively. Once node i select a peer node
j in group G(i2 , j2 ), it cannot select another node in
the same group.

Nb (i, j) = ρ · Cb (i, j)

(2)

Where Nb (i, j) is the number of neighbors of sensor [(i, j), b]
within the zone Z(i, j). In Figure 4, we show the contour
curves of the average number of neighbors of sensor [(i, j), b]
within the zone Z(i, j).

3. If all sensors have selected a node in each of its neighboring groups, stop; otherwise goto step 1.

5. AREA COVERAGE ANALYSIS

5.2

In this section, we study the area coverage of a sensor
within the same zone and in the neighboring zones. Our
analysis is based on the following assumptions:

In Figure 4, we show that there are 8 possible zones surrounding zone Z(i, j). We use superscripts + and − to represent the area coverage and sensor coverage between two
neighboring zones. For example Cb (i+ , j − ) and Nb (i+ , j − )
represent the area coverage and sensor coverage of sensor
[(i, j), b] in zone Z(i + 1, j − 1). Similarly, Cb (i, j − ) and
Nb (i, j − ) represent the area coverage and sensor coverage of
sensor [(i, j), b] in zone Z(i, j − 1).
The representations and proofs of neighboring zone coverage Cb (i, j − )|(x,y) , Cb (i+ , j − )|(x,y) , and Cb (i+ , j)|(x,y) are
given in Appendix B. In summary, the number of neighbors
that node [(i, j), b] covers in a neighboring zone is given as:

• All our analysis is based on a two-dimensional Cartesian plane. A zone is represented by an area x ∈
[0, a], y ∈ [0, a], where (x, y) is a point in the twodimensional Cartesian plane.
• All sensors have equal communication radius, R, and
hence cover the same size of area, where R ≤ a/2.
In our analysis, we assume R = 40 meters, a = 100
meters

Sensor Coverage – in Different Zone

Nb (i∗ , j ∗ ) = ρ · Cb (i∗ , j ∗ )

• The sensors are uniformly distributed in a deployment
region and the average number of neighbors for each

where * represents -, +, or none.

34

(3)

6. KEY GRAPH CONNECTIVITY

6.2

In this section, we present the Key Graph connectivity
analysis for sensors located within the same zone and in
adjacent zones.

The node [(i, j), b] may be located close to the boundary
of two neighboring zones, Z(i, j) and Z(i∗ , j ∗ ). The number
of neighbors of node [(i, j), b] located within these two zones
can be represented by Nb (i, j) and Nb (i∗ , j ∗ ). Node [(i, j), b]
is considered to be connected to the neighboring zone as long
as it can ﬁnd at least one neighbor, b , located in Cb (i, j)
who shares a key with at least one of nodes, b , located in
Cb (i∗ , j ∗ ). The pairwise key establishment protocol between
two adjacent zones is described in Section 7.2. Thus, using
(2) and (3), we can derive the probability p(i∗ , j ∗ ) that sensor [(i, j), b] can connect to the neighboring zone with the
help of all its neighbors.



nz − Nb (i, j)
nz − Nb (i∗ , j ∗ )
Nb (i, j)
Nb (i∗ , j ∗ )



(5)
p(i∗ , j ∗ ) = 1 −
nz
nz
Nb (i, j)
Nb (i∗ , j ∗ )

6.1 Key Graph Connectivity within the Same
Zone
The number of keys preinstalled in each sensor is represented by m. According to the deployment pattern shown
in Figure 3, we select a unique key pool for each zone, i.e.,
P(i, j) for Z(i, j).
To determine the size of key pool, |P(i, j)|, and the number of keys selected, m, from the key pool for sensor [(i, j), b],
we use the equations of P-RKP scheme proposed by Eschenauer and Gligor [6] and further modiﬁed for SK-RKP
scheme by Du et al. [9].
p1 = 1 −

ω
τ



ω−τ
τ

ω 2
τ


=1−

((ω − τ )!)2
(ω − 2τ )!ω!

Key Graph Connectivity between Two Adjacent Zones

(4)

Note that (2) and (3) are derived from Cb (i, j) and Cb (i∗ , j ∗ ),
which are the functions of two-dimensional Cartesian coordinates with the position (x, y). Thus p(i∗ , j ∗ ) is the
function of (x, y). Using the (5), we draw the probability contour curves that a node in Z(i, j) can connect to its
neighboring zones Z(i, j − ) and Z(i+ , j − ) with parameters
a = 100m, R = 40m, n = 50, nz = 100 in Figure 5(a).

Here, p1 is the probability that given two sensors share at
least one key. Eschenauer and Gligor [6] proposed an approximate method to compute key graph connectivity. Our
preliminary studies show that this approach does not work
well when the neighborhood size of a sensor is small. We
derive the key graph connectivity by using binomial probability distribution and modiﬁed binomial probability distribution in a heuristic hop-by-hop fashion. The key graph
connectivity probability is presented in [14].
Since we assume that the sensors are uniformly distributed
within a zone, the closer the sensor to the center of the zone,
the more the neighbors within the same zone for the sensor.
Thus, the key graph connectivity will only be considered
as the key graph created by the sensors within the same
zone. For sensor [(i, j), b] in zone Z(i, j), the number of
neighbors within its zone is Cb (i, j). As shown in Figure 4,
if the average number of neighbors of a sensor, n , is 50,
the zone has total of nz = (n a2 )/(πR2 ) sensors and there
are approximately 11 nodes in the zone with less than 25
neighbors from the same zone.
If we assume the number of neighbors of a sensor is 25, using the key graph 4 connectivity presented in [14], we derive
the probability p1 = 0.5. When p1 ≥ 0.5, the key graph is
connected with probability greater than 0.996 within three
hops. In the worst case, the sensor is located at the corner of the square area, and has approximately 12 neighbors
within the same zone. In this case, the probability that
the key graph is connected within ﬁve hops is 0.8736 and
on average there are only 0.1483 neighbors that can not be
reached within ﬁve hops. If there exist unreachable nodes,
a sensor can just simply send requests to is neighbors which
have more than 25 neighbors to set up the pairwise keys.
A neighbor with more than 25 neighbors can be identiﬁed
from the neighbor-list broadcasted during the key discovery
phase. Since we know that a sensor with 25 or more neighbors can set pairwise keys with all its neighbors, it can help
to set up the pairwise key when they all within each other’s
communication range. In Section 7.1, we will discuss how
a sensor sends requests to its neighbors for pairwise key set
up within the same zone.

7.

PAIRWISE KEY ESTABLISHMENT PROTOCOL

Our key establishment protocol5 consists of two phases:
1. the key establishment within a given zone, 2. the key
establishment between adjacent zones.

7.1

Key Establishment within the Same Zone

The key establishment within the same zone is the ﬁrst
phase after deployment of the sensors. In this phase, each
sensor attempts to establish pairwise keys with all its neighbors within the same zone.
In our scheme, each sensor, say [(i, j), b], initiates this
phase by broadcasting its identiﬁer [(i, j), b] and its key space
identiﬁers [τ1 , τ2 ]. Based on the received ids and corresponding key spaces, a sensor builds a key graph with ids of all
the neighbors as vertices. For each of the neighbors, say
[(i, j), u], the sensor checks if they share the same key space.
If they do share a key space, they can derive the pairwise
key Kbu using the key agreement method presented in Section 2.3. The node [(i, j), b] will then add a link between
itself and node [(i, j), u] in its key graph.
After receiving the identiﬁers from all neighbors and adding
links in the key graph for the neighbors with shared key
space, the sensor broadcasts a list of neighbors who share
key space with it. After receiving the same type of list from
the neighbors, each sensor updates its key graph by adding
edges between vertices according to the received neighborlist. Finally, based on the derived key graph, the sensor can
use source routing, by explicitly specifying the key path (in
hop-by-hop fashion), to send request and establish pairwise
keys with all its remaining neighbors.
5
Due to page limits, in this paper, we only present an outline
of the key establishment protocol. The detailed protocol will
be covered in our following papers.

4

Here, the key graph is composed by only the sensors within
the same zone.

35

0.7

40

0.1

40

2
0.3 0.2

0.1

25

R

0.7

0.9

0.4

0.

0.9

5

0.8

3

1

2

10

0.
8
10

15

20

25

0.1

5

5

0.4
0.3

7
0.

0.1

Z(i,j−)

5

2

0.7

6

0.2

0.

1

2
0.

0.9

+ −

Z(i ,j )

20

15

0.

0.6
0.5

15

10

1

3

0.5
0.6

0.8

R

Z(i+,j)

30

0.4

25

0
0

+ −

Z(i ,j )

35

0.5
0.6
0.7

20

0.1

1

0.3

0.4
30

0.2

0.8

35

0.4
0.3

0.1

3

2

2
1

3
30

35

0
0

40

R

5

10

15

20

25

30

35

40

R

(a) Probability contour curves to zone Z(i+ , j − )
and zone Z(i, j − ) with q=1

(b) Connectivity contour curves to the neighboring zone Z(i+ , j − ) and zone Z(i, j − ) with q=1,
2, 3. pq̂ (i∗ , j ∗ ) = 0.8

Figure 5: Connectivity between two adjacent zones (a = 100m, R = 40m, n = 50, nz = 100)

There may be a few nodes that may not be able to set up
pairwise keys to all its neighbors within a given zone (e.g.,
the node are located outside of 25 curve line in Figure 4).
In Section 6.1, we present the analysis that this probability is small. Even if there exist nodes that cannot set up
pairwise keys with its neighbors, they can refer to the nodes
who have already set up the pairwise keys with all its neighbors within the same zone. These nodes are usually located
around the high numbered contour curves. For example, if
our selected thresholds ω and τ can fulﬁl the requirement
that a node with 25 or more neighbors can set pairwise keys
with all its neighbors, the nodes locate around 25 curve line
can set up links to every node within its communication
range which includes the nodes located outside the 25 curve
line. Now, these node can serve as the intermediate nodes
(or proxy) to set up the pairwise keys. A node can send requests to its neighbors with more than 25 neighbors within
the same zone. If the node has a link to the requested destination, it selects a pairwise key and encrypts it using the
already set up pairwise keys with the source and destination. The source (a requestor) can send multiple requests
to its neighbors and it may receive multiple responses. In
this case, the source and destination node can exclusive-or
all received keys and use the result as their pairwise key.
This arrangement improves security. A neighbor with more
than 25 neighbors can be identiﬁed from the neighbor-list
broadcasting during the key discovery phase.

wants to set up keys with its neighbors in the adjacent zones,
it broadcasts the desired node list. A neighbor of the requestor within the same zone who already shares a key with
the nodes in the requestor’s list acts as a proxy and does the
following: 1. selects a pairwise key for the pair, 2. encrypts
the selected pairwise key using the pairwise key already set
up between itself and the requestor and the pairwise key
already shared between itself and the destination node, 3.
sends the two encrypted messages to the requestor. Upon
receiving the response, the requestor will forward the encrypted pairwise key to the destination. Figure 5(a) shows
the contour curves of the probabilities that a node in Z(i, j)
can connect to its neighboring zones Z(i, j − ) and Z(i+ , j − ).
Since during the ﬁrst phase, nodes have already set up pairwise keys to all their neighbors within the same zone, during
the second phase, as long as there exists one node with a link
to the neighboring zone, it can be used as a bridge to set up
pairwise keys to the neighboring zone for all its neighbors.
The probability that a node can connect to neighboring
zones with the help of exactly k neighbors is given as follows:
pk (i∗ , j ∗ )
  n − N (i, j)  n − N (i∗ , j ∗ ) 
z
nz
b
z
b
k
Nb (i, j) − k
Nb (i∗ , j ∗ ) − k



=
nz
nz
∗ ∗
Nb (i, j)
Nb (i , j )
The probability that a node can connect to neighboring
zones with the help of at least q neighbors is denoted by
pq̂ (i∗ , j ∗ ) and is given as follows:

7.2 Key Establishment between Adjacent
Zones

pq̂ (i∗ , j ∗ ) = 1 − [p0 (i∗ , j ∗ ) + · · · + pq−1 (i∗ , j ∗ )]

After the ﬁrst phase of key establishment, a sensor sets up
pairwise keys with all its neighbors within the same zone.
Then, the system goes into the second phase of key establishment to set up pairwise keys with nodes located in the
adjacent zones.
We described the key predistribution scheme for two adjacent zones (E-Scheme) in Section 4.2.2. When a sensor

(6)

Figure 5(b) shows the range in which a sensor can connect to
its neighboring zones with at least q links via its neighbors,
where q = 1, 2, 3 and the connectivity probability is 0.8.
Thus, a sensor can randomly select q neighbors who respond
to the requests and send the responses to the destination
nodes. The selected q destination nodes can help the sensor

36

set up q paths to any of the neighbors in the adjacent zone.
If there are q keys generated, the pairwise key is given as:
k = k1 ⊕ · · · ⊕ kq

restricted for implementation due to large number of sensors. In our grid-group deployment scheme, we assume a
group of sensors (100 sensors in our performance analysis)
are uniformly deployed within a given square area, which reduces the deployment complexity. Our scheme employs two
stage pairwise key establishment scheme which uses two set
of preinstalled keys. This method also reduces the number
of keys preinstalled in each sensor.
In [1], Du et al. showed that using known deployment
information, the performance of P-RKP schemes can be improved signiﬁcantly. Especially, the proposed scheme reduces the consequences of random node capture attack. The
main contribution of this scheme is to restrict the shared
key information locally (within a small range, e.g., 100m ×
100m). The P-RKP and SK-RKP schemes proposed in [6,
7, 10, 8, 9] assume that each sensor has an equal probability
to have a given key installed in its memory. Instead of distributing the keys uniformly within a given sensor system,
Du et al. [1] proposed to restrict the key distribution locally by geographically dividing the deployment region into
N × M small areas. A small key pool is constructed for each
small area acco‘rding to its neighboring-area relation. The
sensors located within each small area (which form a group)
use the P-RKP scheme to predistribute the keys. They call
this deployment method as group-based deployment model.
However, the scheme proposed by Du et al. has several deﬁciencies. The sensor density of of an area is uneven in that
the density around the center of group deployment point is
much higher than that at the edge of the small area. The
deployment pattern can be modeled by normal distribution.
Thus, in order to make sure that a sensor deployed at the
edge of an area has enough preinstalled keys to set up pairwise keys with all its neighbors, the group-based deployment
model requires more sensors deployed around the group deployment point. In addition, the uneven distribution of sensors within a given area may be undesirable from the application and the security point view. For example, the sensed
data may be unevenly distributed within the deployed area
which can introduce additional complexity for the applications analyzing the sensed data; moreover, an attacker can
capture more sensors around the group deployment point.

(7)

where ⊕ is the exclusive-or operator.
Comparing Figure 4 and Figure 5(b), almost all sensors
that have less than 20 neighbors and some of sensors that
have less than 25 neighbors can set up at three connections
to the diagonal neighboring zones. The sensors that have
less than 35 neighbors within the same zone may set up at
three connections to the horizontal and vertical neighboring
zones.
Similar to the key establishment scheme within the same
zone, for a sensor who cannot set up a key path to a neighboring zone, a sensor can send requests to its neighbors with
15 ∼ 30 neighbors within the same zone. If the nodes has
a link to the requested destination, it selects a pairwise key
and encrypts it using the already established pairwise keys
with the source and destination. The pair of nodes that
may want to set up a pairwise key can utilize the function
presented in (7) to exclusive-or all received keys and use the
result as their pairwise key.

8. PERFORMANCE ANALYSIS
In this section, we present the performance analysis based
on storage, security, communication overhead, and computation overhead due to the proposed scheme. We also provide comparison studies of our scheme with the sensor deployment scheme proposed in [1].

8.1 Other Location-aware Schemes
Two schemes have been proposed in [2] by using known
sensor location information. The ﬁrst scheme is called closest pairwise keys scheme (CPKS). This scheme assumes the
deployment point of each sensor is known in advance, which
is too strict for implementation. The second scheme is called
location-based key predistribution (LBKP). This scheme partitions a deployment area in multiple square areas (zones);
using the same key predistribution schemes proposed in [11],
each area is associated with two polynomials; a key server
is responsible for predistributing keys based on known network topology and sensors’ location points within a square
area. Once a sensor’s location point is determined, the key
server installs a set of polynomial variables associated with
the square area in the sensor. Using this scheme, within
a square area, if λ + 1 or more sensors are captured, all
communications between this area and its adjacent area are
compromised. Our analysis in Section 3.1 shows this scheme
is vulnerable to selective node capture attack. To overcome
this problem, instead of using two polynomial settings for
each zone, we use a unique structured key pool (proposed
in [8, 9]) for each zone and restrict at most λ polynomial
variables that are distributed from each polynomial. Another vulnerability of the scheme in [2] is that, if attackers
capture more than λ sensors, they can fabricate nodes without being detected. We overcome this problem by assign a
unique number (from 1 to N ) to N deployed sensors. This
number also identify the column number of G matrix. Since
this number is unique for a sensor and no attacker can compromise more than λ rows of a key matrix A. Thus, the
attacker cannot fabricate new sensors by installing new row
elements to a fabricated sensor. The LBKP scheme also requires the location of each sensor is preknown, which is too

8.2

System Configuration

In order to compare with the P-RKP location scheme, we
use the similar system conﬁguration proposed in [1].
• The number of sensor nodes in the sensor network is
10,000.
• The deployment area is 1000m × 1000m.
• The area is divided into a grid of size 100, with each
square (a zone) of size 100m × 100m.
• The number of sensors deployed within each zone is
nz = 100.
• The communication radius R is 40m and the average
number of neighbors of a sensor is n = 50.
• The parameters used for key predistribution scheme
within a zone are τ = 2 and ω = 7. Therefore, the
probability that two neighboring sensors share a key
is p1 = 0.5238.

37

8.3 Storage Overhead Analysis

1

Fraction of compromised links among uncompromised nodes

A sensor is required to store m = (λ + 1)τ keys that
are used to set up pairwise key within its zone, where λ is
restricted by nz = λω/τ . For example, if τ = 2, ω = 7, and
nz = 100, then λ = 29. In addition to the keys selected from
the key matrix A, each sensor is required to install at least
one key for each of its neighboring zones. The maximum
number of neighboring zones is 8. Thus, the total number
of keys that are needed to be preinstalled in a sensor is give
as:
  n τ £

z
+ 1 τ + γα
m=
ω
where the γ is the number of neighboring zones and α is
the number of keys preinstalled for each pair of neighboring
zones for a sensor. For all our analysis, we use the following parameter setting: γ = 8, α = 1. Thus, the storage
requirement for a sensor is m = 68.
Unlike the P-RKP scheme proposed in [6] which requires
m = 272 to fulﬁl p1 = 0.5238, our scheme requires m = 68
which is much lesser. For the scheme speciﬁed in [1], to
achieve the p1 = 0.5238, it requires 72 keys preinstalled for
each sensor, which is a marginally higher than our scheme.

0.7

P−RKP location scheme with selective attack
P−RKP location scheme with random attack
Our scheme

0.6

0.5

0.4

0.3

0.2

0

10

20

30

40

50

60

70

80

90

100

Number of compromised nodes

Figure 6: Random/Selective node capture attack:
P-RKP location scheme vs. Our Scheme
since no attacker can derive the secrets preinstalled in the
uncompromised sensors. Thus, our scheme is perfectly secure against the random node capture attack during the ﬁrst
phase of key establishment procedure. During the second
phase of key establishment procedure, a unique key is assigned to each node for each of its neighboring zones. Thus,
the attacker cannot derive more information from the captured information. Hence, for the second phase of our key
establishment procedure, our proposed scheme is perfectly
secure against random node capture attack. In summary,
using our scheme, the attacker can not derive the secret information used among uncompromised nodes from the captured nodes. Overall, our scheme is resilient to random node
capture attack. Figure 6 compares our scheme with the PRKP location scheme proposed in [1] against selective attack.

Our security analysis presents a new way to analyze the
security of pairwise key establishment for large distributed
sensor system. Particularly, selective attack and node fabrication attack have not been addressed thoroughly in current
literatures. All our analysis is based on the attacker’s capabilities presented in Section 3 and the two phases of key
establishment procedure presented in Section 7.

Security evaluation metrics

Sensor networks have many characteristics that make them
more vulnerable to attacks as compared to conventional
computing environment. We present several criteria that
represent desirable characteristics in a pairwise key establishment scheme for sensor networks.
Resilience against node capture attack : to evaluate the
random node capture attack and selective node capture attack: we evaluate the fraction of compromised links among
uncompromised nodes due to captured nodes.
Resilience against node fabrication: we evaluate a the
resilience of scheme against node fabrication by evaluating
the capability of the attacker to successfully deploy the fabricated sensors into the deployment area.

8.4.2

0.8

0.1

8.4 Security Analysis

8.4.1

0.9

8.4.3

Selective node capture attack

The selective node capture attack is described in Section 3.1. In this attack, the attacker can listen to the broadcast communications and selectively capture sensors to maximize the attack eﬀects. Using selective node capture attack,
the attacker only needs to attack certain area or a group of
sensors. By doing this, with little eﬀorts, a particular zone
can be compromised.
The analysis of the fraction of compromised link among
uncompromised nodes under selective attack on our scheme
is the same that presented in previous section – the attacker
cannot derive the keys used among uncompromised nodes
from the captured nodes. But for P-RKP location scheme
[1], if the attacker just concentrates on a particular area,
he can compromise the system by capturing less number of
nodes. As speciﬁed in [1], if the number of keys preinstalled
for each sensor is m = 50 and the average number of neighbors for a node is n = 50, the key pool size used by a
particular zone is 1770. Note that the 1770 keys contain not
only the keys for its own zone, but also keys in the neighboring zones (for details refer to [1]). Thus, by utilizing the
(1) and attack techniques described in Section 3.1, we draw
the Figure 6 to compare our scheme with P-RKP location
scheme.

Random node capture attack

Random node capture attack assumes that an attacker
randomly captures the deployed sensors. If the attacker can
gain the information which is not already known to him, the
attack is considered successful. To evaluate the resilience to
against the random node capture attack, we use the fraction of compromised communication links among uncompromised nodes to evaluate the proposed schemes.
Our pairwise key establishment scheme includes two phases.
The ﬁrst phase uses the SK-RKP scheme proposed in [8, 9].
In addition, we restrict the number of rows of secret matrix
A (A = (D · G)T ) distributed to sensors to λ. The side eﬀect
of this restriction is that the number of sensors deployed in
each zone is restricted by λω/τ , where τ is the number of
key spaces selected for each sensor. This restriction gains
the maximum security to guard against node capture attack

38

# of neighbors
50
40
30
25
20
15

Figure 6 shows that under selective attack for P-RKP
scheme, capturing 20 nodes will cause roughly 60% (1062
keys) of the total keys (1770) compromised. On the contrary, for our scheme, the fraction of compromised links between uncompromised nodes remains zero.

8.4.4

Node fabrication attack

Using node fabrication attack, the attacker can fabricate
new nodes by manipulating the information from the captured nodes, such as the secret keys preinstalled in the captured sensors. This attack can cause severe security problems for P-RKP location scheme, since there is no connections between a sensor’s id and the keys it possesses. For
example, if an
 attacker only captures two nodes, he can
new nodes and deploy them back into the
fabricate 2m
m
sensor network without being detected. Thus, the attacker
can quickly outnumber the uncompromised sensors.
We use the secure group key schemes proposed by Blom [13]
and further developed by Blundo et al [11], in which the
key id is used to identify the row of the secret matrix A
(A = (D · G)T )) distributed to the sensor (the key id can
also serve as user id). Since we restrict the number of rows
of the key matrix A distributed to sensors to λ, the attacker
cannot derive the rows of key matrix A other than the ones
he has already captured. Consequently, the attacker cannot
fabricate new nodes using the information from the captured
nodes.

8.4.5

# of hops
2
2
3
3
3
4

key graph connectivity
0.9957
0.9806
0.9996
0.9980
0.9893
0.9583

average, only 0.044 neighbors cannot set up pairwise keys
within 4 hops. This is almost negligible.
During the second phase of key establishment, between
two adjacent zones, as Figure 5(b) shows, a sensor can set
up q paths to the neighboring zones with the probability of
0.9. Each path is a 2-hop path. The nodes who cannot ﬁnd
a path to the neighboring zone can use the method described
in Section 7.2, which is the same as that in used in the ﬁrst
phase. In this scenario, a sensor sends requests (r requests)
to its neighbors, if q neighbors reply to the requests with the
keys k1 , . . . , kq , the pairwise key is k = k1 ⊕. . .⊕kq . Since the
sensors within the curve lines (the area of the zone Z(i, j) is
split by the curve that close to the neighboring zone) shown
in Figure 5(b) has already set up the pairwise keys with
all the neighbors in the neighboring zones, we only consider
the nodes who can help the sensor to set up path with 2
hops. We note that the farther the sensor from the zone
boundary, the smaller the probability that a sensor can ﬁnd
a path to the neighboring zone; at the same time, the farther
the sensor from the boundary, the smaller the number of
neighbors within the neighboring zone.

Other security considerations

In other security attacks, such as node replication attack,
cloned nodes can be deployed in the system. Our scheme’s
behavior is the same as that of existing proposals under this
attack. Further, we notice that the attacker can compromise
the pairwise keys by capturing sensors and then use the captured sensors to help the uncompromised sensors to setup
the pairwise keys. This attack can be mitigated by increasing the probability that two sensors share a key p1 and use
multiple key paths to set up pairwise keys. The analysis of
these countermeasures will be given in our following papers.

8.6

Computation Overhead Analysis

The computation overhead is mainly from the secure group
key scheme introduced by SK-RKP scheme. In our schemes,
we reduced the computation overhead signiﬁcantly as compared to the SK-RKP scheme proposed in [8, 9] that does
not use the location information. For example, by using
the SK-RKP scheme without using location information, for
m = 200, τ = 2, and λ = 100, to derive a pairwise key, the
total number of required modular multiplication operations
is 200 (for the detail description of pairwise key establishment scheme refer to [8, 9]). Note that this requirement is
to fulﬁl the connectivity of whole sensor network. In our
scheme, we only need to guarantee the local connectivity
within a zone. We reduce the number of keys preinstalled
in a sensor (see the analysis presented in Section 8.3). If
we restrict the number of sensor within a zone to nz = 100,
for ω = 7, τ = 2, the λ = nz τ /ω = 29. Thus, the number of required modular multiplication operations to derive
a pairwise key is only 58.

8.5 Communication Overhead Analysis
We derive the mathematical expressions for the probability that a sensor can set up key paths with all its neighbors
within h hops in [14]. Due to page limits, we simply put the
mathematical expressions, simulation results, and comparison studies in [14]. This mathematical model is used for our
communication overhead analysis. Since our key establishment procedure includes two phases: the key establishment
within a zone and the key establishment between two adjacent zones, we analyze the communication overhead for each
phase separately.
During the ﬁrst phase of key establishment, the closer the
sensor to the center of a zone, the smaller the communication
overhead due to key establishment. For example, for τ = 2,
ω = 7, the following table shows the number of hops and
the corresponding key graph connectivity probabilities: As
shown in Figure 4, most pairwise keys can be set up within 3
hops. If a sensor cannot set up pairwise keys with its neighbors within 3 hops, as presented in Section 7.1, the sensor
sends requests (r requests) to its neighbors, if q neighbors
reply to the requests with the keys k1 , . . . , kq , where q ≤ r,
the pairwise key is k = k1 ⊕ . . . ⊕ kq . We show that for
ω = 7 and τ = 2, and if a sensor has 15 neighbors, then on

9.

CONCLUSION

We described SK-RKP schemes [8, 9] used in our proposed grid-group scheme. Using this scheme, we signiﬁcantly decrease the requirement for number of keys to be
installed in each sensor (approximately 3 times less than
the schemes without using deployment information). Moreover, our scheme is resilient to selective node capture attack
and node fabrication attack which have not been completely
addressed and analyzed in the current literatures. Our comparison studies with the recent P-RKP location scheme [1]
show that our scheme exhibits better performance from both
storage and security perspectives.

39

We notice that the attacker can compromise the pairwise
keys by capturing sensors and then use the captured sensors
to help (act as a proxy) the uncompromised sensors to setup
the pairwise keys. In this way, the attacker can capture the
pairwise keys used between uncompromised sensors. In our
future work, we will study the security of various proposals
under such attack and corresponding countermeasures.

[12] R. D. Pietro, L. V. Mancini, and A. Mei, “Eﬃcient
and resilient key discovery based on pseudo-random
key pre-deployment,” in 18th International Parallel
and Distributed Processing Symposium (IPDPS’04),
April 2004.
[13] R. Blom, “An optimal class of symmetric key
generation systems,” in EUROCRYPT’84, ser.
Lecture Notes in Computer Science, vol. 209. Paris,
France: Springer-Verlag, 1985, pp. 335–338.
[14] D. Huang, M. Mehta, D. Medhi, and L. Harn,
“Modeling pairwise key establishment for random key
predistribution in large-scale sensor networks,”
University of Missouri – Kansas City, Tech. Rep., July
2004. [Online]. Available:
http://conrel.sice.umkc.edu/dhuang/modeling.pdf

ACKNOWLEDGEMENT
The authors would like to thank the anonymous reviewers
for their valuable comments.

10. REFERENCES
[1] W. Du, J. Deng, Y. S. Han, S. Chen, and P. K.
Varshney, “A key management scheme for wireless
sensor networks using deployment knowledge,” in
IEEE INFOCOM, March 2004.
[2] D. Liu and P. Ning, “Location-based pairwise key
establishments for static sensor networks,” in
Proceedings of the 1st ACM workshop on Security of
ad hoc and sensor networks (CCS’03), 2003, pp. 72 –
82.
[3] J. M. Kahn, R. H. Katz, and K. S. J. Pister, “Next
century challenges: Mobile networking for ”smart
dust”,” in International Conference on Mobile
Computing and Networking (MOBICOM), 1999, pp.
271–278.
[4] “Wireless integrated network sensors,” University of
California.
[5] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and
E. Cayirci, “A survey on sensor networks,” IEEE
Communications Magazine, vol. 40, pp. 102 – 114,
August 2002.
[6] L. Eschenauer and V. D. Gligor, “A key-management
scheme for distributed sensor networks,” in
Proceedings of 9th ACM Conference on Computer and
Communication Security (CCS-02), November 2002,
pp. 41–47.
[7] H. Chan, A. Perrig, and D. Song, “Random key
predistribution schemes for sensor networks,” in
Proceedings of 2003 Symposium on Security and
Privacy. Los Alamitos, CA: IEEE Computer Society,
May 11–14 2003, pp. 197–215.
[8] D. Liu and P. Ning, “Establishing pairwise keys in
distributed sensor networks,” in Proceedings of 10th
ACM Conference on Computer and Communications
Security (CCS’03), October 2003, pp. 52–61.
[9] W. Du, J. Deng, Y. S. Han, and P. K. Varshney, “A
pairwise key pre-distribution scheme for wireless
sensor networks,” in Proceedings of 10th ACM
Conference on Computer and Communications
Security (CCS’03), October 2003, pp. 42–51.
[10] S. Zhu, S. Xu, S. Setia, and S. Jajodia, “Establishing
pair-wise keys for secure communication in ad hoc
networks: A probabilistic approach,” in Proceedings of
11th IEEE International Conference on Network
Protocols (ICNP’03), November 2003.
[11] C. Blundo, A. D. Santis, A. Herzberg, S. Kutten,
U. Vaccaro, and M. Yung, “Perfectly-secure key
distribution for dynamic conferences,” Information
and Computation, vol. 146, no. 1, pp. 1–23, 1998.

APPENDIX
A.

SENSOR COVERAGE – WITHIN THE
SAME ZONE

The covering area of sensor [(i, j), b] in its zone Z(i, j) is
shown in Figure 7. We can further divide the zone into 4
areas. The sensor coverage in these 4 areas are horizontally
and vertically mapping to each other. Within a small area,
there are two scenarios that shown in the Figure 7.
In the ﬁrst scenario (shown the sensor is located at the
position p
(x1 , y1 )), the distance between the origin and the
sensor is x21 + y12 ≤ R. The coverage is composed by a sector with the angle θ1 plus two triangles (the shaded areas).
The θ1 is given as follows:
θ1 =

B1 − x1
A1 − y1
3
π − sin−1
− sin−1
2
R
R

where,
A1 − y1 =

È
R2 − x21 ,

B1 − x1 =

È

R2 − y12

The coverage (the shade area) of sensor [(i, j), b] in zone
Z(i, j) is represented as Cb1 (i, j) and it is computed as follows:
1
Cb1 (i, j)|(x1 ,y1 ) = x1 y1 + [x1 (A1 − y1 )
2
θ1
+y1 (B1 − x1 )] + R2
2
In the second scenario (shown the sensor is located at the
positionp(x2 , y2 )), the distance between the origin and the
x22 + y22 > R. The coverage is composed by two
sensor
triangles (A2 A3 o, B2 B3 o) and two sectors with angles
θ2 and θ3 . The θ3 is given as follows:
B2 − x2
A2 − y2
3
π − sin−1
− sin−1
2
R
R
The θ2 is given as follows:
θ3 =

x2 − B3
y2 − A3
π
− sin−1
− sin−1
2
R
R
The θ4 is given as follows:
θ2 =

θ4 = 2 sin−1

A2 − y2
R

The θ5 is given as follows:
θ5 = 2 sin−1

40

B2 − x2
R

;;
;;
;;
;;;;;;
;;;;;;

triangle A3 A1 b as follows:
p
R2 − x2
|A1 A2 | =
x
xR
|A3 b| =
= p
cos(∠A3 bA2 )
R2 − y 2
xy
|A2 A3 | = p
R2 − y 2
È
|A2 b| =
|A3 b|2 − |A2 A3 |2

y

zone (i,j-1)

a

zone (i,j)

A2

A1

(x2,y2)
4

R

2

3

A3 A1 b

5

(x1,y1)

R

a

B1 B2

B3

|B1 A3 | =
|A3 o| =

x

|B1 o| =

zone (i+1,j)

zone (i+1,j-1)

B1 A3 o =

Figure 7: Occupied zone

We note that,

È

R2 − x22
È
x2 − B3 = B2 − x2 = R2 − y22

Cb (i, j − )|(x,y)
=
=

, x ≤ R, y
, x ≤ R, y
, x > R, y
, x > R, y

≤R
>R
≤R
>R

To summarize, given a position (x, y) for sensor [(i, j), b],
the area coverage is given as follows:


Cb (i, j)|(x,y) =

Cb1 (i, j)|(x,y)
Cb2 (i, j)|(x,y)

1
|B1 o||A3 o|
2

Thus, the shade area C(i, j − ) is given as;

The coverage (the shade area) of sensor [(i, j), b] in zone
(i, j) is represented as Cb2 (i, j) and it is computed as follows:
Cb2 (i, j)|(x2 ,y2 ) =
8
1
[x2 (A2 − A3 ) + y2 (B2 − B3 )]
>
2
>
θ +θ
2
>
+
< 22 3R
1
4
x (A2 − A3 ) + 2π−θ
R2
2 2
2
>
2π−θ5 2
1
>
y2 (B2 − B3 ) + 2 R
>
:2 2
πR

R − |A3 b|
y − |A2 A3 |
È
|B1 A3 |2 − |A3 o|2

ú
The area of sector B
1 bA1 is given as follows:
y
∠A2 bA3 = sin−1
R
x
−1
∠A2 A1 b = sin
R
π
∠A1 bA2 =
− ∠A2 A1 b
2
∠A1 bB1 = ∠A1 bA2 + ∠A2 bA3
∠A1 bB1
∠A1 bB1 2
ú
B
=
πR2 =
R
1 bA1
2π
2

(x1,y1)

y2 − A3 = A2 − y2 =

1
(|A1 A2 | + |A2 A3 |)|A2 b|
2

The area of triangle A3 oB1 is given as follows:

1

0

=

p
, 0 ≤ x2 + y 2 ≤ R
p
, R < x2 + y 2 ≤ a/2

B.2

ú
B
1 bA1 + B1 A3 o − A3 A1 b
y
 x 
R2  π
− sin−1
+ sin−1
2 2
R
R

x p 2
xy
R − x2 + p
−
2
R2 − y 2


1
xy
+
y− p
2
R2 − y 2
Ê
 

xR
xy
×
R− p
− y− p
R2 − y 2
R2 − y 2

Zone Coverage C(i+ , j − )

Shown in Figure 8 (b), we ﬁrst compute the area of sector
ú
B
4 bA4 :

In Figure 4 shows the average number of neighbors of a
sensor that is located in diﬀerent position of a given zone.

ú
B
4 bA4

=

πR2
4

ú
The area of sector B
1 bA4 is given as follows:
y
∠B1 bA4 = sin−1
R
∠B1 bA4 2
ú
B1 bA4 =
R
2

B. SENSOR COVERAGE – IN DIFFERENT
ZONE
B.1 Zone Coverage C(i, j − )
Shown in Figure 8 (a), we ﬁrst compute the area of the

41

;;;; ;;
;;
;;
;;
;;
;;
;;
;;;
;;
;;
;;
;;
;;
;;
;;;
;;
;;
;;
y

y

Zone (i,j-1)

Zone (i,j)

y

Zone (i,j-1)

Zone (i,j)

Zone (i,j-1)

Zone (i,j)

A1

R

R

A2
A3

R

x

o

B1

A1

A4

b(x,y)

B1

b(x,y)
A2
o B B
2 3

A2

x

b (x,y)

R

o B B
3 2

x

B1

R

Zone
(i+1,j)

Zone
(i+1,j-1)

Zone
(i+1,j-1) A3

(a)

B4

Zone
(i+1,j)

Zone
(i+1,j)

Zone
(i+1,j-1) A1

(b)

(c)

Figure 8: Zone Coverage Proof

The area of triangle B3 oA1 is given as follows:

The area of triangle bB1 B3 is given as follows:
p
|B1 B3 | =
R2 − y 2
1
bB1 B3 =
|B1 B3 |y
2

|A1 B3 | =

x − |B2 B3 |
È
|A1 o| =
|A1 B3 |2 − |B3 o|2

ú
The area of sector B
4 bA3 is given as follows:
x
∠B4 bA3 = sin−1
R
∠B4 bA3 2
ú
B4 bA3 =
R
2

A1 B3 o =

Thus, the shade area C(i+ , j − ) is given as;

Thus, the shade area C(i+ , j) is given as follows;

Cb (i+ , j − )|(x,y)

Cb (i+ , j)|(x,y)

ú
ú
ú
= B
4 bA4 − B
1 bA4 − bB1 B3 − B
4 bA3
−bA1 A3 + xy
 x 
πR2
R2  −1  y 
sin
+ sin−1
=
−
4
2
R
R

p
1 p 2
2
2
2
−
x R − x + y R − y + xy
2

ú
= A
1 bB1 + A1 B3 o − B3 B1 b
x
 y 
R2  π
− sin−1
=
+ sin−1
2 2
R
R
y p 2
xy
−
R − y2 + √
2
R2 − x2


1
xy
+
x− √
2
R2 − x2
r
 

yR
xy
×
R− √
− x− √
R2 − x2
R2 − x2

B.3 Zone Coverage C(i+ , j)
Shown in Figure 8 (c), we ﬁrst compute the area of triangle
A3 A1 b as follows:
p
|B1 B2 | =
R2 − y 2
y
yR
|B3 b| =
= √
cos(∠B3 bB2 )
R2 − x2
xy
|B2 B3 | = √
R2 − x2
È
|B3 b|2 − |B2 B3 |2
|B2 b| =
=

1
|A1 o||B3 o|
2

ú
The area of sector A
1 bB1 is given as follows:
x
∠B2 bB3 = sin−1
R
y
∠B2 B1 b = sin−1
R
π
∠B1 bB2 =
− ∠B2 B1 b
2
∠B1 bA1 = ∠B1 bB2 + ∠B2 bB3
∠B1 bA1
∠B1 bA1 2
ú
A
=
πR2 =
R
1 bB1
2π
2

The area of triangle bA1 A3 is given as follows:
p
R2 − x2
|A1 A3 | =
1
bA1 A3 =
|A1 A3 |x
2

B3 B1 b

R − |B3 b|

|B3 o| =

1
(|B1 B2 | + |B2 B3 |)|B2 b|
2

42

1204

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 15, NO. 5, OCTOBER 2007

Modeling Pairwise Key Establishment for Random
Key Predistribution in Large-Scale Sensor Networks
Dijiang Huang, Member, IEEE, Manish Mehta, Member, IEEE, Appie van de Liefvoort, Member, IEEE, and
Deep Medhi, Senior Member, IEEE

Abstract—Sensor networks are composed of a large number of
low power sensor devices. For secure communication among sensors, secret keys are required to be established between them. Considering the storage limitations and the lack of post-deployment
configuration information of sensors, Random Key Predistribution
schemes have been proposed. Due to limited number of keys, sensors can only share keys with a subset of the neighboring sensors.
Sensors then use these neighbors to establish pairwise keys with the
remaining neighbors. In order to study the communication overhead incurred due to pairwise key establishment, we derive probability models to design and analyze pairwise key establishment
schemes for large-scale sensor networks. Our model applies the binomial distribution and a modified binomial distribution and analyzes the key path length in a hop-by-hop fashion. We also validate
our models through a systematic validation procedure. We then
show the robustness of our results and illustrate how our models
can be used for addressing sensor network design problems.
Index Terms—Random key distributions, security, sensor networks.

I. INTRODUCTION
ARGE-SCALE sensor networks are composed of a large
number of low-powered sensor devices. According to [1],
the number of sensor nodes deployed to study a phenomenon
may be on the order of hundreds or thousands; depending on the
application, the number may reach an extreme value of millions.
Typically, these networks are installed to collect sensed data
from sensors deployed in a large area. Within a network, sensors
communicate among themselves to exchange data and routing
information. Because of the wireless nature of the communication among sensors, these networks are vulnerable to various
active and passive attacks on the communication protocols and
devices. This demands secure communication among sensors.
Due to inherent storage constraints, it is infeasible for a sensor
device to store a shared key value for every other sensor in the
system. Moreover, because of the lack of postdeployment geographic configuration information of sensors, keys cannot be
selectively stored in sensor devices. Although a naïve solution
would be to use a common key between every pair of sensors to
overcome the storage constraints, it offers weak security.
Random key predistribution (RKP) schemes [6], [8], [10],
and [15] have been proposed to provide flexibility for the designers of sensor networks to tailor the network deployment to

L

Manuscript received March 4, 2005; revised May 6, 2006; approved by
IEEE/ACM TRANSACTIONS ON NETWORKING Editor R. Caceres.
D. Huang is with the Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287 USA (e-mail: dijiang@asu.edu).
M. Mehta is with the Tumbleweed Communications, Redwood City, CA
94063 USA (e-mail: manish.mehta@tumbleweed.com).
A. van de Liefvoort and D. Medhi are with the Department of Computer Science and Electrical Engineering, University of Missouri—Kansas City, Kansas
City, MO 64110 USA (e-mail: appie@umkc.edu; dmedhi@umkc.edu).
Digital Object Identifier 10.1109/TNET.2007.896259

the available storage and the security requirements. The RKP
schemes propose to randomly select a small number of keys
from a fixed key pool for each sensor. Sensors then share keys
with each other with a probability proportional to the number
of keys stored in each sensor. Since the RKP schemes necessitate only limited number of keys to be preinstalled in sensors, a
sensor may not share keys with all of its neighbor nodes. In this
case, a pairwise key establishment (PKE) scheme is required to
set up shared keys with required fraction of neighbor nodes.
The PKE schemes require sensors to set up pairwise keys via
the nodes that share keys with either or both the sensors. This
PKE phase involves communication overhead for finding the
shortest path to a neighbor node and for setting up the pairwise
key through that path. The lesser the number of keys preinstalled
in each sensor, the lower the probability that a sensor shares
a key with a given neighbor node. Consequently, the sensor
requires more overhead in the PKE phase with the remaining
neighbor nodes. Studies in [5] show that the energy consumption due to communication in sensors is several orders higher
than that due to computation overhead. The constraints such as
scarce battery power and limited storage necessitate a reference
model to study the tradeoff between storage and communication
overhead involved during the PKE phase in RKP schemes.
It may be noted that the memory limitation of sensors restricts
the number of keys that can be preinstalled in each sensor to a
small number. For example, the capabilities of sensor nodes for
large-scale sensor networks can be as limited as those of Smart
Dust sensors [11], [12], that have only 8 Kb of program and
512 bytes for data memory. Moreover, studies in [6] and [8]
show that a small key pool size increases security vulnerabilities. Thus, for large-scale sensor networks, a small number of
keys preinstalled in each sensor and a large key pool size result
in a small value of probability
that two sensors share keys
(see (1) in Section II-B-1)). Our studies show that the smaller
the value of , the higher the number of hops required to set
up pairwise keys. (A detailed analysis is given in Section V.)
Analyses presented in [6] and [8] provide communication overhead in the PKE phase for up to 3 hops. Due to the restrictions
mentioned above, a general mathematical model to study the
communication overhead for the PKE phase is required.
In this paper, we propose a probability model to analyze communication overhead requirements for the PKE phase in RKP
schemes. Unlike the PKE scheme proposed in [8], our model
is based on the PKE scheme where sensors set up pairwise keys
using only their neighbor nodes. This design significantly reduces
the communication overhead involved in the PKE phase. Similar
to the recent schemes in [6], [8], [10], [14], [15], and [22], our
model is based on networks with uniformly distributed sensors.

1063-6692/$25.00 © 2007 IEEE

HUANG et al.: MODELING PAIRWISE KEY ESTABLISHMENT FOR RKP IN LARGE-SCALE SENSOR NETWORKS

Our model applies the binomial probability distribution
and a modified binomial probability distribution (presented
in Section III-B) in a hop-by-hop fashion. There are three
input parameters to our model: 1) probability of two sensors
sharing keys, 2) average number of neighbors of a sensor, and
3) probability that two neighbors of a node share keys and
are located within each other’s communication range. Our
model can be used for evaluating the fraction of neighbors of a
sensor to which it can communicate securely. Furthermore, the
model derives the probability that for a given sensor network
configuration, every sensor can securely communicate with all
its neighbors. We then validate our model through our proposed
validation procedure. Finally, we use our model to analyze the
communication overhead in the PKE phase.
The rest of the paper is organized as follows. In Section II,
we provide necessary background and related work in the area
of RKP schemes. Section III describes the proposed probability
model for pairwise key establishment and key-graph connectivity. Section IV presents the validation methodology and results of our proposed probability model. Communication overhead analysis of using our proposed model is given is Section V.
Section VI summarizes the work.
II. BACKGROUND OF RANDOM KEY
PREDISTRIBUTION SCHEMES
The goal [10] of RKP schemes is to reduce the number of
preinstalled keys in each sensor considering unknown postdeployment geographic configuration. The preinstalled keys can
help the sensor to set up pairwise keys with its neighbors. Sensors located within a sensor’s communication range are called
neighbors of that sensor. In this paper, we use terms sensor and
node interchangeably.
In this section, we first list phases for pairwise key setup in RKP
schemes. We then provide general mathematical background of
RKP schemes in literature. Finally, we present related work.
A. Phases in Random Key Predistribution Schemes
Four main phases for key setup in RKP schemes are presented
as follows.
1. Key predistribution phase: A centralized key server generates a large key pool offline. The key server is assumed to
be protected and no adversary can break into the server to
reveal the keys. The procedure for offline key distribution
is as follows:
• generate a large key pool of size ;
• randomly select
different keys for each sensor from
the key pool to form a key ring;
• load the key ring into the memory of the sensor.
• assign a unique node identifier or key ring identifier to
each sensor.
2. Sensor deployment phase: Sensors are randomly picked
and uniformly distributed in a large area. Typically, the average number of neighbors of a sensor
is much smaller
than the total number of deployed sensors
.
3. Key discovery phase: Two steps are involved in the key
discovery phase. In the first step, each sensor attempts to
discover shared key(s) with each of its neighbors. To accomplish this, the sensor can broadcast its key ring iden-

1205

tifier to its neighbors. The sensor can also use the secret
discovery protocol specified in [7], [10], and [17] to discover the shared key without using clear-text broadcast.
After the first step of the key discovery phase, the sensor
knows all its neighbors. The set of all neighbors of sensor
is represented by
and
. The set of neighbors
of sensor who share at least one key with the sensor is
represented by . The set of neighbors of sensor who
do not share any key with sensor is represented by .
Thus, we have
and
. In
the second step, every sensor broadcasts its set . Using
the sets received from neighbors, a sensor can build a key
graph (see Definition 1) based on the key-share relations
among neighbors.
4. Pairwise key establishment phase: If sensor shares at least
one key with a given neighbor (a neighbor in set ), the
shared key(s) can be used as their pairwise key(s). For each
of the neighbors in set
, sensor uses the key graph
built during key discovery phase to find a key path (see
Definition 2) via the neighbors in set to set up a pairwise
key. Once a pairwise key is set up with a neighbor in set
, the neighbor is included in set
and deleted from
set . The above PKE procedure can be achieve by using
source-routing-based pairwise key PKE protocol [13]. The
goal of the PKE phase for sensor is to set up pairwise
and satisfy
,
keys with its neighbors in set
where is the fraction of the total number of neighbors of
sensor that are required to be reached.
Definition 1 (Key Graph): A key graph maintained by node
is defined as
, where
is
a relation defined between two nodes if they share at least one
key after the key discovery phase.
Definition 2 (Key Path): A key path between node and
is defined as a sequence of nodes
, such
that each pair of nodes
,
has at least one shared key after the key discovery
phase. The length of the key path is the number of pairs of
nodes in it.
B. Mathematical Foundations of Random Key
Predistribution Scheme
An important probability
is the probability that two
nodes share at least one key after the key predistribution phase
[10]. We first state this result here for completeness. We then
give two approaches proposed in the literature that are used for
computing the key-graph connectivity.
:
1) Probability That Two Nodes Share at Least One Key
Given a key pool of size and that each sensor is loaded with
randomly selected different keys from the key pool, the probability that two sensors share at least one key is given as (for
proof, see [10])

where

(1)

1206

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 15, NO. 5, OCTOBER 2007

TABLE I
COMPARISON OF EXISTING RKP SCHEMES

2) Random Graph Approach (RGA): An approximation
method to compute key-graph connectivity is proposed by
Eschenauer and Gligor [10]. Their method utilizes the random
graph theory [20]. Given a desired probability of the graph
is the global two-node connectivity
connectivity
probability that a link exists between any two nodes, as follows:

where is the total number of sensors in the system. Using ,
we can derive the local two-node connectivity probability
by amplifying with factor
. Here, is the estimated
probability that a node shares a key with any of its neighbors,
where is the average size of its neighborhood

Note that in [8], the authors define the
as the probability
for global key-graph connectivity and the
as the probability
for the local key-graph connectivity. The RGA uses the probability of global key-graph connectivity to estimate the local
key-graph connectivity. This approach does not provide the key
path length information of a key graph that can be useful in design of pairwise key establishment schemes. Moreover, it estimates the key-graph connectivity and produces inconsistent results when the neighborhood size is relatively small (see our
validation results in Section IV-E).
3) Area Covering Approach: Du et al. [8] uses the area covering approach to analyze the probability that a node can set
up pairwise keys with any of its neighbors. They calculate the
two-node connectivity probability as a function of the overlapped range shared by a sensor with its neighbors. During
the PKE phase, the intermediate nodes may not necessarily be
located within the source node’s communication range. Thus,
the sensor cannot determine key paths to set up pairwise keys
with its neighbors. In other words, the key setup requests must
be flooded instead of using chosen paths. Consequently, the
communication overhead invoked by the pairwise key requests
is prohibitively high. Moreover, the area covering approach is
based on the analysis of geographical locations of nodes on
all possible key paths. For the path length greater than 3, the
analyses of the node locations and the graphical representations are very complicated. In their work in [8], the authors only
present the analyses for key paths with lengths 2 and 3.
C. Related Work
The first RKP scheme was proposed by Eschenauer and Gligor
[10], and we call it the basic scheme. The proposals that followed

are all based on the basic scheme and they propose improvements
in terms of security. The proposed improvements focus on three
aspects: key pool structure [8], [15]; key selection threshold [6];
and path-key establishment protocol [6], [22].
Table I shows five recent proposals and the basic scheme.
Chan et al. [6] proposed the -composite scheme. In this
scheme, the key selection threshold is set to . To form a secure
link, the scheme requires at least shared keys between two
nodes. The structured key pool scheme (sk-RKP) [8] proposed
by Du et al. and Grid-based scheme [15] proposed by Liu and
Ning change the unstructured key pool to a structured key pool.
The structured key pool is formed by multiple key spaces.
Within each key space, the key space structure uses the group
key scheme proposed by Blom [2] and further developed by
Blundo et al. [3]. Both the -composite scheme and the -path
to set up the pairwise
scheme [22] use key paths
key. The -path scheme uses the secret-sharing scheme1 to
set up the pairwise key. In all presented schemes, during the
key discovery phase, both the clear-text broadcast discovery
and the private share-key discovery scheme2 are specified.
Clearly, the private share-key discovery approach involves
more communication overhead.
It may be noted that the key-graph connectivity problem we
have considered here has some similarity to global network connectivity problems, i.e., the connectivity of an entire network;
a comprehensive study on graph connectivity can be found in
[18]. The recent work by Xue and Kumar [21] addresses the
connectivity of wireless networks by inspecting the minimal
number of neighbors in order to achieve global connectivity.
Note that both these works achieve network connectivity of the
entire graph. In our case, the key-graph connectivity is from
the point of view of each individual sensor (node) when global
knowledge/connectivity is not known/possible due to limited
storage and communication ability at each sensor. In our sensor
network model, two neighboring sensors must be physically visible via a direct wireless link in order to set up a direct key in
their key graphs; in other words, the wireless links outside of a
sensor’s communication range are considered to be invisible for
that sensor. Consequently, given the storage and communication
restrictions, we study the following problem: the probability that
a node can establish a key with one or all of neighbors within
-hop visible key path(s).
1In their proposed scheme, a pairwise key can be derived by k exclusive-OR
operations on k secret shares received from k paths.
2Specified in [10], using private share-key discovery, for every key on a key
ring, each node could broadcast of list ; E (); i = 1; . . . ; k;, where  is a
challenge. The encryption of E () with the proper key by a recipient would
reveal the challenge  and establish a shared key with the broadcasting node.

HUANG et al.: MODELING PAIRWISE KEY ESTABLISHMENT FOR RKP IN LARGE-SCALE SENSOR NETWORKS

1207

TABLE II
NOTATIONS

Fig. 2. Node selection for computing
h 2.



p (h). (a) h

= 1, (b)

h

= 2, and (c)

The expected area of the overlapped region is given by [6]

Fig. 1. Overlapped region between two sensor nodes.

As shown in Fig. 1, a node must be located within the
shaded region
in order to be in node ’s and node ’s range
simultaneously. On an average, is the ratio of the shaded area
, we can
to the whole area of the circle. Using the result for
as
then determine
(2)

III. PROBABILITY MODEL FOR PAIRWISE KEY ESTABLISHMENT
In this section, we analyze the PKE phase of RKP scheme
for a large number of sensors uniformly distributed within a
vast two-dimensional area. The uniform distribution of sensors was introduced in [10] and extensively utilized in many
proposals, such as [6], [8], and [15]. We derive here the probability that a node can reach any of its neighbors with exactly
hops and the probability that a node can reach all of its
hops. Notations used for this work are
neighbors within
summarized in Table II.
A. Computing

and

In order to model the probability that a sensor can set up a
pairwise key with any of its neighbors with exactly hops, we
first determine the probability that any two neighbors, say and
, of a sensor, say , are within each other’s range—this probability is denoted by . Our analytical approach requires a result
, given in [6]. In order
on expected area of overlap region
to review this result, consider Fig. 1; we can draw two circles
with centers as sensor node and and each with communication radius resembling the range of sensors. The distance
between and is . The cumulative distribution function for
the distance between a node and one of its neighbors is given
distance
. Thus, the probability
by
. The area of the
density function is
is
overlapped region

Furthermore, given a node and its range, the probability that
any two nodes within the range of node share a key and are in
each other’ range is given as
(3)
In our case,
due to (2). It may be noted that
is computed based on the assumption that every sensor has
a circular communication range with equal radius. Other mechfor different configurations.
anisms can be devised to find
However, any different mechanism will not affect our probability model introduced in Sections III-B and III-C.
B. Computing
The basic idea behind our approach is the probability of node
selection on each hop. The selection follows the binomial distribution or a modified binomial distribution. The binomial probability mass function for given and is represented as

The modified binomial probability mass function is represented
as follows:
(4)
where probabilities

and

need not be the same.

1208

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 15, NO. 5, OCTOBER 2007

Fig. 2 gives a graphical view of our approach. Node is a
sensor that wants to set up a pairwise key with one of its neighbors, say node . ’s range contains nodes, including the node
.
is the probability that node can set up pairwise key
with a given neighbor with exactly hops. As shown in Fig. 2,
our equation is derived in three stages. Stage always represents the final stage that node can reach node ; stage represents all the intermediate hops when
; and stage rep.
resents the first hop when
, as shown in Fig. 2(a), there is no intermediate
For
node. Therefore, is the probability that node shares at least
one key with node . If node and node share key(s), the
same key(s) can be used as pairwise key(s) and no additional
key setup is required. Otherwise, they cannot set up pairwise
key(s) directly and must go through the PKE phase to set up
pairwise key(s). Thus, we have

(
each of the
one of the

. All
the nodes selected for this hop are eligible to connect to node
. The expression of stage is
, which means that at
nodes shares a key with node . Using the
least one of the
expressions of all the stages, we derive the following equation
for

(7)

(5)
is shown in Fig. 2(b). In stage , we select
The case for
nodes from
nodes as the first hop nodes who share at
. Since our
least one key with node , where
goal is to derive the probability that node is reachable with exactly two hops, once node is fixed, we can only select at most
nodes as the first hop nodes. We now have the equation
for stage A. This equanodes are setion can be interpreted as follows: out of
lected for the first hop; the probability that nodes share keys
; the probability that
nodes
with node is
; also, in each sedo not share keys with node is
lection, we have the condition that node does not share keys
). Following stage ,
with node (represented by
is the stage in the second hop. Any selected node in stage
may share keys with node . Thus, the probability that at least
one of the selected nodes in stage shares key with node is
, in which
means that all selected nodes
given as
in stage A do not share a key with node . It may be noted that
the probability that a node selected in stage shares keys with
node is , as derived in Section III-A. Thus, we have

nodes) after the selection for the first hop and
nodes shares at least one key with at least
nodes. The expression for stage B is given as

, there exists three stages [see Fig. 2(c)]. The
For
is the same as that for
. We have
analysis of stage
the expression

for

stage A. There are two substages in stage , we denote them as
and
. The expression of substage
represents the formulas from hop 2 to hop
. It represents a iterative process
nodes
that is used on each hop. In other words, on hop
hops.
are selected from the leftover nodes of previous
nodes from
For example, on hop 2, we select
nodes. We now show induction as follows: on hop , we can
nodes. Following (4),
select nodes from
shows the probability of selection of a node
nodes in
that shares at least one key with at least one of the
the hop
and this selected node does not share key(s) with
represents the probability that a node
node ;
nodes in the hop
. For each
does not share any key with
hop , the value of has to be less than
to
guarantee that at least one node is available at each of the hops
to . The substage
represents the hop
. As
from
, the nodes selected for hop
discussed in the analysis of
are all eligible to share a key with node . The analysis
. Thus, we
of stage is the same as that of stage for
arrive at

(6)
For
, as shown in Fig. 2(c), there exists three stages. In
stage , the mathematical expression is similar to the expres. One difference is that equation
sion we presented for
is a cumulative modi(using (4),
fied binomial distribution function multiplied by
,
). The expression
stands
nodes selected for the
for the condition that none of the
first hop share keys with node and node simultaneously.
Since there must be at least one node available on hop 2, the
maximum number of nodes that can be selected from
candidate nodes is
. In stage (only substage
exist
), the formula is a cumulative binomial distribution
when
function that
nodes are selected from the remaining nodes

(8)

HUANG et al.: MODELING PAIRWISE KEY ESTABLISHMENT FOR RKP IN LARGE-SCALE SENSOR NETWORKS

Fig. 3. Node selection for computing
(c) h 3.



p

(h). (a)

h

=

1, (b)

h = 2,

The probability that a node can reach any of its neighbors
. The formula is then
within hops is represented as
given as

1209

. There are
hops in the stage B. For hop
as that for
nodes from
nodes that share keys with
2, we select
nodes in hop 1. Now, we can do induction as follows: in hop ,
we can select nodes from
nodes; it is a binomial
that
probability mass function with the probability
each of hop nodes shares at least one key with at least one
hop nodes and
nodes do not share
of the
key(s) with
hop nodes. Then, we conclude that the stage
B is a sequence of cumulative binomial distribution functions
and each successive function depends on the previous hop nodes
.
selection. The analysis of stage C is the same as that for
Then, we have the following expression for
:

(9)
where
is as derived for different values of earlier in this
section. Note that (9) is not dependent on radius nor on the
total number of sensors ; it is dependent on
and .
C. Key Graph Connectivity
In this subsection, we study the key-graph connectivity of a
given sensor network.
A graph is said to be connected if any two of its vertices can be
joined by a path, disconnected otherwise [4]. We say that a key
, is h-hop-connected at vertex if vertex can reach
graph,
any other vertex of the key graph with a path no more than
hops in length. We now derive the probability that a key graph,
, maintained by node is h-hop-connected. Our equation
derivation includes three stages as shown in Fig. 3. There are
nodes within ’s range.
is the probability that the
key graph
is h-hop-connected. Stage always represents
the final hop in which node can reach all its neighbors; stage
represents all the intermediate hops when
; and stage
represents the first hop when
.
We first present the formula for
[see Fig. 3(a)]. It is
is
easy to see that
(10)
For
first stage

, as shown in Fig. 3(b), there are two stages: the
and the final stage . In stage
out of nodes
are selected for the first hop. This is a binomial
probability mass function with probability . Thus, we have

the binomial probability distribution
to represent the first hop. Unlike in expressions for
, the
for
can be . In stage C, the probability
value of
that each of
nodes shares at least one key with at least
. Then, the probability
one of the nodes is given by
nodes on hop 2 is
.
of connecting to all
is given as follows:
The
(11)
For
, as shown in Fig. 3(c), there are three stages. The
analysis and mathematical expression of stage A are the same

(12)
In order to deploy a sensor system using RKP schemes, we
first select different values of and plug them into (10)–(12) to
find out suitable value of to achieve the required value of connectivity probability
. Once
is found, we can apply
(1) to select the proper (key pool size) and (the number of
keys to be preinstalled in a sensor).
IV. VALIDATION METHODOLOGY AND RESULTS
In (3)–(12), we have the following assumptions: 1) each
neighbors, where
sensor can communicate directly with
is the average number of neighbors of a sensor, 2) each
is a
sensor has the same communication radius , and 3)
fixed value. Here, through a systematic approach, we show that
our mathematical derivations based on above assumptions are
sound approximations.
We consider following two parameters in our validation: the
number of neighbors of a sensor, and the communication radius of a sensor. We also consider two different distributions:
1) sensors are uniformly distributed within a vast area, and 2) a
sensor’s communication radius follows normal distribution with
mean and standard deviation or uniform distribution within
.
the interval
A. Number of Neighbors of a Sensor
We consider to be a large sensor deployment area, i.e.,
, where is the average transmission range of a sensor
. We define
as the sensor deployment
and
is
density. The probability that a node is placed within area
. The probability
that of nodes are placed in
is
the area
(13)

1210

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 15, NO. 5, OCTOBER 2007

Fig. 4. Cumulative Poisson Distribution, r = 10. The average number of
neighbors of a sensor is n = r = 50.

Fig. 5. Cumulative normal distribution r = 10.  = 0:05r = 0:5; and
2 = 1 .

When
and
, we can approximate this solution
with a Poisson distribution [19]:

Fig. 6. Coverage area with different communication radius.

(14)
The cumulative poisson distribution function

is:
(15)

The average number of neighbors of a sensor is
(16)
In order to assign a number of neighbors of a sensor, we can
simply map uniform distribution in the range of
to the
cumulative Poisson distribution. For example, for each sensor,
( axis in
we randomly select a number within the range
Fig. 4); based on the histogram shown Fig. 4, we can find its
corresponding -coordinate, which is the number of neighbors
assigned to the sensor.
B. Generating
We assume that sensors have average communication radius
when they are shipped out of factories. We consider both
normal distribution and uniform distribution to model the communication radius of a sensor. We use mean and standard de. We can easily derive the proportion of a
viation
distribution that is below a given number of standard deviations

from the mean. It can be shown that only 2.3% of the population will be less than or equal to a value two standard deviations
below the mean. Similarly, the same portion that is above the
mean. Using the similar mapping technique, we can draw the
cumulative normal distribution function for sensor’s communication radius. For example, shown in Fig. 5, we can randomly
select value from the axis (within the interval of dashed lines);
then we can assign the radius of a sensor from the axis to a
sensor. Note that the value selected for a sensor is within
from the mean . In the case of uniform distribution, we ranfor each
domly select a radius within the range
sensor.
In real world, the communication radii of sensors are of
varying length. Fig. 6 shows the coverage area of sensors in
three different scenarios. Sensor (with communication radius
) has two neighbors and with communication radii
and , respectively: where 1)
, 2)
(the analysis of the scenario
is the same),
. In all our following analysis, we assume
and 3)
. In order to set up pairwise keys, two sensors must be
located within each other’s communication range. In Fig. 6,
the shaded area is the intersected coverage area between two
sensors with smaller communication radii. It is easy to prove
that, in all three scenarios, the intersected coverage area used
is the intersected area of two sensors with less
to compute
communication radii. We note that, in the scenario
shown in Fig. 6, if is located in the area between the dashed

HUANG et al.: MODELING PAIRWISE KEY ESTABLISHMENT FOR RKP IN LARGE-SCALE SENSOR NETWORKS

circle (centered by node with radius ) and the circle centered
by (with radius ), node will not consider as its neighbor.
Thus, node must be located within the shaded area.
The area abcd shown in Fig. 6 is

(17)
where
and represent two of the less
and (we assume
).
communication radii of
In Section III-A, we presented the cumulative distribution
function for the distance between the node and one of its neighdistance
, where we
bors with
assume each node has the same communication radius . The
. For
probability density function is
the sensor network with different communication radii, we have
.
the probability density function
Thus, the expected coverage area abcd is given by
(18)
Then, we can compute

as follows:
(19)

and,

is computed using (3).

C. Validation Procedure
Our aim here is to validate the soundness of probability
and
derived earlier in Section III. We
models
use the following procedure to estimate
and
to
compare against the models presented in Section III.
1. Select to be average number of neighbors for a sensor.
2. For the average communication radius of sensors, , use
the exponential mapping method presented in Section IV-A
to find the number of neighbors of a sensor.
3. Select a distribution for each neighbor, and use the method
presented in Section IV-B to assign a radius for each
sensor.
for each pair of neighbors
4. Use (17)–(19) to compute
for the same.
and then use (3) to derive the probability
Based on the derived value of , assign pairwise keys for
each pair of neighbors.
and
based on the steps 2 to 4 de5. Compute
scribed above.
The above procedure is run 300 000 times for each distribuand
tion selected in step 3 and then the average value for
is obtained over the 300 000 runs; note that we consider
uniform and normal distribution separately for this step.
D. Validation Results
In Fig. 7, we plot computed average value from the validation procedure and the theoretical result derived from our pro[see Fig. 7(a)–(f)] and
posed probability models
[see Fig. 7(g)–(l)]. In Fig. 7, each subfigure shows three scenarios with
for different values of

1211

and , where each plot considers three values or radius
at 10, 30, and 50 to compare against the theoretical result. We
assume that a sensor’s communication radius follows either a
, or normal
uniform distribution with the range
distribution with mean and standard deviation in our validation process. Our results show that the proposed probability
models fit the method used for validation. Readers might notice
the gaps between the simulation results and theoretical results
in Fig. 7(g)–(l). Note, however, that the evaluated probabilities
(see the axis) are very small; thus, this difference has less practical significance, and our analytical model can be considered to
be very accurate.
E. Comparison of Key Graph Connectivity Methods
Next, we compare key-graph connectivity. We can find the
key-graph connectivity probability by using any of the following
three methods.
• Using the probability that a node connects to any of its
neighbors within hops [see (9)], we can derive the fraction of neighbors of a node for which the pairwise keys can
be set up within hops. This approach only provides the
) that
number of neighbors (can be derived by
, a node
connect to a node within hops. When
can set up pairwise keys with practically all its neighbors;
then, we can say the key graph is connected.
• The second method is as described in Section III-C [see
(10)–(12)]. To start with, this method only considers directly reachable nodes and pairwise-key sharing relations
among sensors without considering the geographical location of each sensor, which significantly reduces the analytical complexity. In addition, it provides the key path
length information, which is valuable for sensor network
designers to evaluate or design a sensor system.
• The third evaluation method, RGA, is as described in
Section II-B-2), which is by [10].
In Table III, we compare the three approaches. Note that the
while our
RGA method requires the total number of sensors
approach does not. We find that the RGA method may produce
inconsistent result, especially when the neighborhood size is relwhen
. In addition,
atively small, for example,
compared to the
method, the RGA method requires higher
value when
and lower value when
. Since
our model has been validated via simulation [see Section IV-D],
our comparative results in Table III show that the RGA method
will result in inaccurate parameter settings in sensors.
F. Using Connectivity Probability
Deploy Sensor Networks

or

to

Our model allows to answer questions such as “Can our proposed analytical model help sensor network designers to deploy
sensor networks and evaluate a RKP scheme with given storage
constraints and network configurations?” We briefly illustrate
this aspect.
For instance, we might have the following requirements: “Deploy a uniformly-deployed sensor network such that each node
can establish pairwise keys, within 5 hops, to 99.999% of all
its neighboring sensors.” This requirement can be translated to
the following parameters used in our model, i.e.,

1212

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 15, NO. 5, OCTOBER 2007

Fig. 7. n = 10; 30; 50; p = 0:1; 0:2; 0:3; radius = 10; 20; 30. (a)–(f): validate p (h); (g)–(l): validate p (h). (a) n = 10, (b) n = 30, (c) n = 50,
(d) n = 10, (e) n = 30, (f) n = 50, (g) n = 10, (h) n = 30, (i) n = 50, (j) n = 10, (k) n = 30, and (l) n = 50.

and
. Once
is fixed, we need to determine the important RKP parameter, . Recall that the selecis determined by evaluating (12). Since
and
tion of

are known, there are three variables in (12); they are
and . From (3), we know that
is a function of . Thus,
the problem translates to solving (12) in order to determine un-

HUANG et al.: MODELING PAIRWISE KEY ESTABLISHMENT FOR RKP IN LARGE-SCALE SENSOR NETWORKS

TABLE III
CONNECTIVITY PROBABILITY FOR KEY GRAPH: p ( h) METHOD VERSUS
p (h) METHOD VERSUS RGA METHOD



knowns and . Relations between different values of and
so determined can be found in Table III. For example, if we
choose
, then
. In fact, we can create multiple similar tables with different connectivity requirements.
The next step is to determine RPK scheme parameters. We
choose three RKP schemes for our analysis. They are basic
scheme, -composite scheme, and sk-RKP scheme (see Table I).
for each RKP scheme
The mathematical representations of
are given in Section II-B-1) and in Appendix Sections A and
B. For additional information about these schemes, refer to the
publications [6], [8], [10], and [15]. Thus, we can use (1), (20),
and (21) to determine the number of keys to be installed in each
sensor and the size of the key pool.
Based on the above discussion, it is easy to see that our analytical model provides a nice mathematical representation for
key-graph connectivity for a given number of hops. This model
can help network designers to evaluate the communication overhead (restricted by the number of hops, i.e., ) with the considerations of storage capability of sensors (i.e., the value of ).
V. COMMUNICATION OVERHEAD ANALYSIS
In this section, we use our proposed probability model to analyze the communication overhead involved in the PKE phase.
We analyze the required number of hops to set up a pairwise key
and the communication overhead for PKE distributed on each
hop.
Since sensors establish pairwise keys via only the neighbors
nodes in our model, our analysis is based on the average number
and is independent of the size of the sensor
of neighbors
. The number of neighbors
of a sensor is usually
network
,
less than 100. For our computations, when
we assume that a sensor can set up pairwise keys with all its
neighbors within hops. We refer to the condition
as -fraction h-connected condition. A special case when
is referred to as the strong h-connected condition. In Table IV, we show probability
under the conditions strong 4-connected and 0.5-fraction 8-connected. It may
be noted that the communication overhead during pairwise key
establishment for strong h-connected sensor networks is mainly

1213

distributed within first three hops. As shown in Fig. 8, with increases in the neighborhood size, the pairwise key establishment
communication overhead shifts from hop 1 to hop 2 and drops
dramatically on hop 3.
On the other hand, the pairwise key establishment communication overhead for 0.5-fraction h-connected sensor network is
distributed in more than three hops. Fig. 9 shows that the probability curves become flatter with increase in the neighborhood
size and the probability peaks shift to higher hop numbers. We
.
define the communication weight on hop as
We notice that the highest communication weight for each curve
also shifts to a higher hop number with increase in the neighborhood size.
Thus, we summarize our findings as follows.
:
1) For strong h-connected
a) the pairwise key establishment communication overhead is mainly distributed within first three hops;
b) the pairwise key establishment communication overhead shifts from the first hop to the second hop when
increases
.
:
2) For -fraction h-connected
a) for given and maximum number of hops , when
decreases, the pairwise key establishment
communication overhead shifts from lower number
hops to higher number hops, the value of the peak
probability decreases and shifts to a higher number
hop, the probability curve becomes flatter, and
decreases (see the changes from Figs. 8 to 9);
and the maximum
b) for a given
increases, the pairwise
number of hops , when
key establishment communication overhead shifts
from lower number hops to higher number hops, the
value of the peak probability decreases, the probability curve becomes flatter, and the
decreases (see Fig. 9).
3) From findings 1) and 2), we make the following observaand the maximum number of hop ,
tions: for a fixed
cause a decrease in ; for a fixed
the decreases of
, the increases in causes a decrease in ;
given
the increase in the maximum number of allowed hops
also causes a decrease in . These observations for the
PKE phase lead us to the study of tradeoff between the
communication overhead, which is restricted by , and the
storage overhead of a sensor, which is restricted by . It
may be noted from (1) that for a fixed , the smaller the
, the smaller the . On the other hand, the smaller the
maximum number of hops , the lesser the communication overhead involved. The exact tradeoff study between
and for different scenarios requires additional analysis, which is out of scope of this paper.
VI. SUMMARY
In this paper, we have derived two analytical probability
models for large-scale sensor networks to analyze the PKE
phase for RKP schemes. Through a validation procedure,
we show the robustness of our mdoels. Our models can help
designers to analyze the PKE phase for RKP schemes in following ways: 1) to study the key-graph connectivity, which, in

1214

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 15, NO. 5, OCTOBER 2007

TABLE IV
COMMUNICATION OVERHEAD ANALYSIS FOR p ( 4)

  0 99999 AND
:

p

(

 8)  0 5
:

turn, helps to determine the number of keys to be preinstalled
in each sensor and the range of a sensor, and 2) the pairwise
key establishment path length can help in determining the
communication overhead during pairwise key establishment
and then evaluate if a designed the PKE scheme fulfils the
energy consumption requirements for a sensor.
The software for the analytical models and the validation
process are available at http://www.csee.umkc.edu/~dmedhi/
software/.
APPENDIX
We briefly review here the mathematical background for two
RKP schemes: -composite scheme [6] and sk-RKP scheme
[15], [16], [8], [9].
A. Q-Composite Scheme
Fig. 8. Sensor network key establishment communication overhead distribu0:99999.
tion for p ( 4)





According to [6], the probability to set up a secure link requires at least keys. The probability that two nodes can set up
keys is denote as
. Thus,
is given as

The probability that two nodes can set up a secure link is
(20)
B. Sk-RKP Scheme

Fig. 9. Sensor network key establishment communication overhead distribu0 :5 .
tion for p ( 8)





The sk-RKP scheme has been independently proposed by Du
at al. [8], and Liu and Ning [15]. In this scheme, the key pool
of RKP schemes is constructed by key spaces, and each key
sub-key-space
space (i.e., a key matrix) is the structure of
. For
(i.e., an array of keys); the size of each key space is
the structured key pool, we can determine that the number of
preinstalled in a sensor is given by
,
keys
where is the number of key spaces selected for each sensor
, and
is number of keys installed in each
with

HUANG et al.: MODELING PAIRWISE KEY ESTABLISHMENT FOR RKP IN LARGE-SCALE SENSOR NETWORKS

sensor from each of selected key spaces. The probability
two sensor nodes share at lease one key is

that

(21)

REFERENCES
[1] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci,
“A survey on sensor networks,” IEEE Commun. Mag., vol. 40, pp.
102–114, Aug. 2002.
[2] R. Blom, “An optimal class of symmetric key generation systems,”
in EUROCRYPT’84, ser. Lecture Notes in Computer Science. Paris,
France: Springer-Verlag, 1985, vol. 209, pp. 335–338.
[3] C. Blundo, A. D. Santis, A. Herzberg, S. Kutten, U. Vaccaro, and M.
Yung, “Perfectly-secure key distribution for dynamic conferences,” Inf.
Comput., vol. 146, no. 1, pp. 1–23, 1998.
[4] B. Bollobás, Modern Graph Theory. New York: Springer-Verlag,
1998.
[5] D. W. Carman, P. S. Kruus, and B. J. Matt, “Constraints and approaches
for distributed sensor network security,” NAI Laboratory, Tech. Rep.,
Sep. 2000.
[6] H. Chan, A. Perrig, and D. Song, “Random key predistribution
schemes for sensor networks,” in Proc. 2003 Symp. Security Privacy.
Alamitos, CA: IEEE Computer Society, 2003, pp. 197–215.
[7] R. Di Pietro, L. V. Mancini, and A. Mei, “Efficient and resilient key
discovery based on pseudo-random key pre-deployment,” in Proc. 18th
Int. Parallel Distributed Processing Symp. (IPDPS’04), Apr. 2004, p.
217.
[8] W. Du, J. Deng, Y. S. Han, and P. K. Varshney, “A pairwise key predistribution scheme for wireless sensor networks,” in Proc. 10th ACM
Conf. Computer Communications Security (CCS’03), Oct. 2003, pp.
42–51.
[9] W. Du, J. Deng, Y. S. Han, P. Varshney, J. Katz, and A. Khalili, “A pairwise key pre-distribution scheme for wireless sensor networks,” ACM
Trans. Inf. Syst. Secur., 2005, accepted for publication.
[10] L. Eschenauer and V. D. Gligor, “A key-management scheme for distributed sensor networks,” in Proc. 9th ACM Conf. Computer Communication Security (CCS-02), Nov. 2002, pp. 41–47.
[11] V. D. Gligor and P. Donescu, “Fast encryption and authentication:
XCBC encryption and XECB authentication modes,” in Proc. 2nd NIST
Workshop AES Modes of Operation, Aug. 2001, pp. 92–108.
[12] J. Hill, R. Szewczyk, A. Woo, S. Hollar, D. E. Culler, and K. S. J. Pister,
“System architecture directions for networked sensors,” in Proc. Architectural Support for Programming Languages Operating Systems,
2000, pp. 93–104.
[13] D. Huang, M. Mehta, and D. Medhi, “Source routing based pairwise key establishment protocol for sensor networks,” in Proc. 24th
IEEE Int. Performance Computing Communications Conf., 2005, pp.
177–183.
[14] D. Huang, M. Mehta, D. Medhi, and H. Lein, “Location-aware key
management scheme for wireless sensor networks,” in Proc. ACM
Workshop Security of Ad Hoc Sensor Networks (SASN’04), Oct. 2004,
pp. 29–42.
[15] D. Liu and P. Ning, “Establishing pairwise keys in distributed sensor
networks,” in Proc. 10th ACM Conf. Computer Communications Security (CCS’03), Oct. 2003, pp. 52–61.
[16] D. Liu, P. Ning, and R. Li, “Establishing pairwise keys in distributed
sensor networks,” ACM Trans. Information System Security, vol. 8, no.
1, pp. 41–77, 2005.
[17] M. Mehta, D. Huang, and L. Harn, “RINK-RKP: A scheme for key
predistribution and shared-key discovery in sensor networks,” in Proc.
24th IEEE Int. Performance Computing Communications Conf., 2005,
pp. 193–197.
[18] M. D. Penrose, “On k-connectivity for a geometric random graph,”
Random Struct. Algorithms, vol. 15, no. 2, pp. 145–164, Sep. 1999.
[19] P. E. Pfeiffer and D. A. Schum, Introduction to Applied Probability.
New York: Academic, 1973.
[20] J. H. Spencer, The Strange Logic of Random Graphs (Algorithms and
Combinatorics, ser. 22. New York: Springer-Verlag, 2001.

1215

[21] F. Xue and P. R. Kumar, “The number of neighbors needed for connectivity of wireless networks,” Wireless Netw., vol. 10, pp. 169–181,
2004.
[22] S. Zhu, S. Xu, S. Setia, and S. Jajodia, “Establishing pair-wise keys for
secure communication in ad hoc networks: A probabilistic approach,”
in Proc. 11th IEEE Int. Conf. Network Protocols (ICNP), Nov. 2003,
pp. 326–335.

Dijiang Huang (M’00) received the B.S. degree from
Beijing University of Posts & Telecommunications,
Beijing, China, in 1995 and the M.S. and Ph.D. degrees from the University of Missouri—Kansas City,
in 2001 and 2004, respectively.
He is an Assistant Professor in the Computer Science and Engineering Department at Arizona State
University, Tempe. His current research interests are
computer networking, security, and privacy.
Dr. Huang has been a member of the Association
for Computing Machinery (ACM) since 2000.

Manish Mehta (S’03–M’04) received the B.E.
degree in computer engineering from Mumbai
University, India, in 1999 and the M.S. and Ph.D.
degrees, both in computer science, from the University of Missouri—Kansas City (UMKC) in 2002 and
2006, respectively.
He is currently a Senior Software Engineer at Tumbleweed Communications, Redwood City, CA. His
research interests are in cryptography, network security, and sensor networks.

Appie van de Liefvoort (M’01) received graduate
degrees in computer science and mathematics from
the University of Nebraska—Lincoln and from the
Katholieke Universiteit, Nijmegen, The Netherlands.
Previously, he was a faculty member at the University of Kansas, Lawrence. He is currently a Professor and Chair of the Department of Computer Science Electrical Engineering at the University of Missouri—Kansas City, where he has been since 1987.
His research interests include queueing theory and
performance modeling of computer and communication networks, specializing in linear algebraic queueing theory, the matrix-exponential distribution, and correlated matrix-exponential sequences.

Deep Medhi (M’89–SM’97) received the B.Sc.
(Hons.) degree in mathematics from Cotton College/Gauhati University, India, the M.Sc. degree in
mathematics from the University of Delhi, India,
and the Ph.D. degree in computer sciences from the
University of Wisconsin—Madison.
Prior to 1989, he was a Member of Technical Staff
at AT&T Bell Laboratories. He joined the University of Missouri—Kansas City, where he is currently
a Professor of the Computer Networking, Computer
Science and Electrical Engineering Department. He
was an invited visiting Professor at the Technical University of Denmark and a
visiting Research Fellow at Lund Institute of Technology, Sweden. He is a Fulbright Senior Specialist. His research interests are resilient multilayer network
design, network routing and design, and sensor networks. He has published over
70 papers and is coauthor of the books Routing, Flow, and Capacity Design in
Communication and Computer Networks (Morgan Kaufmann, 2004), and the
forthcoming book Network Routing: Algorithms, Protocols, and Architectures
(Morgan Kaufmann, 2007).

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

On Measuring Email-based Social Network Trust
Dijiang Huang and Vetri Arasan
School of Computing Informatics and Decision System Engineering
Arizona State University
{dijiang,varasan}@asu.edu
Abstract—Measuring trust among social network users is an
important research issue. In this paper, we present a new trust
model based on emails. We name this new trust model as Email
Trust (EMT). EMT is constructed based on the interactions
among users via their daily emails, which provides a level of belief
on the data transmitted by a use. In EMT, we require each user
to perform a trust checking procedure and process a received
trust checking request from their highly trusted email contacts
or through a trusted checking proxy server that is maintained by
a trusted third party. We evaluate the EMT through a small EMT
testing bed developed using Gmail services. Our preliminary
evaluation results show that the EMT evaluation results can be
used to represent users’ trust among email users.

I. I NTRODUCTION
Google and Yahoo have come up with new and very
similar plans to respond to the challenge from MySpace
and Facebook: They hope to turn their e-mail systems and
personalized home page services (iGoogle and MyYahoo) into
social networks. Web-based e-mail systems already contain
much of what Facebook calls the social graph - the connections
between people. That is the reason that the social networks
offer to import the e-mail address books of new users to jumpstart their list of friends. We realize that a new email social
trust model can be built through the public email systems to
benefit the emails users for their social life through the digital
world.
Generally speaking, emails represent many social activities
and connections that can be benefitting for setting up trust
among people. Email trust (EMT) provides a rich set of statistical features that provide attractive advantages over other social
networks. In this paper, we present a new trust evaluation system using, probably, the oldest social networks over Internet,
i.e., we investigate how to establish trust among email users by
exploring the statistical features of emails. Our research goal
is to use statistical evidence for trust measure among email
users. Compared to existing social network trust solutions,
our design goal is to reduce the users’ involvements for trust
establishment and automate the trust evaluation processes.
The proposed EMT is a distributed trust query system that
builds on the premise that email addresses are partially public
though people concern about third-party use. Although, this
represents the fundamental nature of email services: email is
designed for communications among people, it is the major
controversial aspect of EMT to extend the uses of email
services for setting up trust. The major challenge comes from
the fact that the EMT trust query service has two main
functions: (i) measuring trust between an email user with

(or through) his/her contacts; and (ii) protecting email users’
privacy during the trust establishment procedure. Particularly,
in a highly dynamic environment, when two persons meet, they
will exchange their email addresses (or in some anonymized
forms to preserve privacy). Once the trust is established
through EMT, we can utilize identity-based cryptography to
handle the entity trust, i.e., to verify each other’s identity and
set up common session keys.
This paper is to address the criteria to establish the email
trust through statistical method between any two email users.
The EMT is based on the spontaneous reactions of email users
and their email habits. For example, the email inbox has email
addresses of whom communication has taken place. There are
folders, address book, labels etc., which can give insight in
finding out the relation with the contacts. We consider that
trust between two people increases as they exchange emails
back and forth. On the other hand, in one way communication,
i.e., a person sends emails to another person without getting
replies, has a low trust rank.
The rest of paper is arranged as follows: the related work is
presented in Section II; in Section III, we present the system
and models of EMT; in Section IV, we present the email
trust architecture and trust measurement models; the emailbased trust validation and experimental results are presented
in Section V; finally, we conclude our research and indicate
the future research directions in Section VI.
II. R ELATED W ORK
Existing ways to establish social network trust consists of
centralized Public Key Infrastructures (PKIs) [1] and decentralized Web Of Trust (WOT)) [2]. Due to the decentralized
nature of WOT, it has been widely adopted by most social
networks. WOT is a community driven technique to vouch
for the trust worthiness of an entity. One of its application is
rating the trustworthiness of websites [2].
The Pretty Good Privacy (PGP) [3] trust model is an
application of WOT for email-based social networks. PGP trust
is built through the users’ public keys, where several PGP users
can sign a public key vouching that the key belongs to the
correct owner. This certificate can be either trusted directly or
there is chain going back to a trusted person. The trust rating is
provided by PGP users on their stored public keys and the trust
ranking is decentralized. OpenPGP [4] is the most widely used
email encryption standard, although the number of keys and
signatures present are only 41,294 and 414,424, respectively,
as on February 2009 [5]. Moreover, it is impractical for a user

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

assigning a trust level for a key every day according to his/her
trust interpretation on the key.
Email statistic properties have been extended studied mainly
for setting up spam filters [6]. To address the trust among email
users, a manual trust rating system has been built using trust
email [7] among university professors and students. A study
on email network was done through the use of their email
addresses. There, each email address is a node and two nodes
are linked if there are email communications between them
[8]. The data came from a university, observations suggest
that fellows (students, faculty, etc.) from the same department communicate more than between different departments,
corresponding to the reality and the strength of trust among
email users. Hierarchy in the social network is also studied
through hierarchical clustering [9]. None of previous research
has investigated in using email statistical features to evaluate
the trust among users. Our work is a pioneer in this direction.
III. S YSTEM AND M ODELS
A. Email-based Social Trust Model
Focusing on e-mail, the major challenge is how to compute
email-based trust and enable it for real-time mobile applications with security and privacy considerations. Ideally, EMT
services should be based on automated trusted agents to reduce
human interventions. To address these challenges, we present
two important components to build our email-based social
trust: entity profiles and social trust metrics.
1) Trust Entity and Profile: In an email-based trust framework, we need to provide a clear definition for each participant
(or entity) to address the question: “who are you?” This
requires the trust model to have a unique entity for each user.
According to the email marketing survey [10], 73% people
in U.S use email daily. Thus, email addresses can be used as
the identities for most people. More importantly, each email
address is associated with a certain profile, which can be
further used to quantify trust. This is because trust relations
are set up naturally among email users at a certain scrutinized
level by each email user using a number of metrics, such as,
the frequency of email exchanged between users, the labels,
tags, or directories created to categorize the users’ relations to
the email holder, the untrusted email addresses (such as spam)
are sent to Spam folders, etc. We must note that the profile
associated with an email address is generated by its user’s
daily online activity without needing continuous maintenance
effort for trust establishment.
Another important requirement of using email identities is
to preserve users’ privacy. To address this issue, we broadly
categorize emails according to the email usage:(i) Personal
emails containing private information exchanged between
friends and relatives, (ii) Business emails exchanged between
co-workers or business partners for business purposes, and (iii)
Public emails that do not have any privacy concerns. It is
highly desirable that users can use pseudonyms at initial trust
establishment using public emails instead of exposing their
personal or business email addresses. To this end, we need
to rely on the widely deployed public and free email services

such as Gmail, Yahoo, Hotmail, etc., where email users can
create pseudonymized email addresses to anonymize their real
identities. In our following descriptions and trust evaluations,
we focus on the trust model established using Gmail.
2) Email-based Social Network Relationships: The trust
relations of email-based social networks are embedded in
daily email exchanges and managements. The uniqueness of
measuring email trust is that we do not purposely require
emails users to manually rank trust. We exploit the social behaviors that reflect the natural social trust established through
daily email-related operations among email users. Generally
speaking, people are more serious about their email related
activities than other Internet-based social networks. This is
because email systems are designed for frequent interactive
communications, and the interactions can be used as a natural
metric to evaluate trust. Thus, our research goal is how to
use statistical properties of emails, such as measuring the
interactions among email users, to establish a quantifiable
social trust framework. This is the key advantage of emailbased social networks. We build email-based trust using the
following information associated with an email account: (i)
Contact list and email groups. (ii) Email exchange frequency
and time frame can be used to set trust levels. (iii) Archived
emails are usually more important than those deleted after
users read them. (iv) Spam filters can also help to skim off
abused emails when evaluating email trust. (v) The e-mail
service is made more personal because it displays messages
more prominently from people who are more important to you.
We must note that the inbox is based on what people send to
a email user, but not always what the users want to see. In
general, email users categorize the emails from the people
that they care about most. Meaningful folders (e.g., outlook)
or labels (e.g., Gmail), such as friend, family, colleagues,
business partner, customer, club buddies, etc., all represent
different levels of trust.
B. Communication Model
In EMT, an email-trust server is used to collect users’
information and then calculates the trust levels. An email user
who wishes to participate in the trust checking network needs
to register at the EMT server. The user should be able to
communicate using either mobile devices or computers with
internet capability. The EMT server logs on to the email
servers using the credentials supplied by the registered user.
It gathers the email statistics to calculate the trust rating for
the people with whom the registered user has communicated
through email back and forth.
Based on the privacy protection levels, there are three ways
of retrieving a registered user’s email information and our
constructed email-trust evaluation system can support all of
them, which provides flexibility for end users: (i) Minimal
privacy protection: User opts to trust EMT server. EMT server
will communicate with email server and download email information. (ii) Maximal privacy protection: User relays email
information to the EMT server. They do not want EMT server
to manage the client’s email credentials. They have the ability

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

to control the data that is being transmitted to EMT server.
This necessitates the usage of a client application at the user’s
side. The client application can filter the information and send
the filtered results to the EMT server. (iii) Moderate privacy
protection: A hybrid system. User can switch between the
above two modes.
In the rest of this paper, we do not particularly differentiate
the descriptions based on the above described privacy protection levels. The EMT implementation and client application
can be accessed at [11]. In the rest of description, we only
focus on the trust evaluation based on email statistic properties.

⎞

γij,k = ⎝ Lij
⎛

Lji

γij,k = ⎝ Lij

Lji

+

Lji
Lij

Lij
,
Lij + Lji

(2)

Lij
β.
Lij + Lji

(3)

⎠

⎞

2
+

Lji
Lij

⎠

γij,k
β=1/0.553

0.8
0.7
0.6

Equation (1)

0.5

Equation (3)

0.4

Equation (2)

0.3
0.2
0.1

Lij/(Lij+Lji)=0.5
0

EMT is based on the peer-to-peer email social network. We
assume each user will be able to run an email trust checking
agent (TCA) software on the user’s client device. It performs
the following two main operations: (a) send trust checking
requests, and (b) perform trust checking and ranking. After two
users exchange their email addresses, the TCA will perform
trust checking based on each other’s email addresses through
the EMT server. First, EMT server needs to perform statistical
analysis of the email header content and related information
such as folders or labels and contact list with respect to the
email address (ID) whose trust level has to be ascertained. We
call this as tier-1 trust checking.
If the tier-1 trust checking cannot discover the trust directly
between two email addresses (i.e., the checking email address
does not in the checker’s contact list), EMT needs to run tier2 trust checking, i.e., the checker evaluates the email trust
through his/her trusted email contacts. In the follows, we
describe the tier-1 and tier-2 checking schemes accordingly.
Tier-1 trust checking: Here, we first describe the tier-1 trust
checking. We use i and j to represent two users, and k denotes
a time frame for a sequence of time period {tk |k = 1, . . . , n},
for example each tk represents a month. n is the total time
frames which we consider for the algorithm. In our EMT test,
we look into the emails within 2 years, thus n = 24. Let the
number of emails sent from i to j be Lij , and Lji vice versa.
We calculate an email trust factor γij,k for the period tk for
user i:
⎞
⎛
2
⎠,
(1)
γij,k = ⎝ Lij
Lji
Lji + Lij
2

1
0.9

0

IV. E STABLISHING E MAIL T RUST

⎛

can achieve the maximum γij,k = 1 as shown in Figure 1.
In reality, trust is usually directional. However, (1) provides

0.2

Fig. 1.

0.6

0.8

Lij/(Lij+Lji)
1

Comparisons of Equations (1) - (3).

same trust evaluation from i to j and vice versa. We usually
consider the trust metric γij,k should be higher when user
i sends more emails to user j. Intuitively, we can emulate
the email trust to page ranking used by Google. However,
page ranking considers the number of incoming links to be
more important to evaluate a web link. On the contrary, EMT
weight more on the number of outgoing links, i.e., the number
of emails originated by a user, which is more reasonable to
evaluate email-based trust. In (2), we provide an adjusted
formula to evaluate γij,k by considering the proportion of
the number of emails sent from i to j to the total number
of emails exchanged between them. In Figure 1, we present
the values of (2) based on the proportion of Lij /(Lij + Lji ).
We can see that γij,k ≈ 0.553 achieves the maximum value
when Lij /(Lij + Lji ) = 0.6. To scale γij,k to 1, we can
simply introduce a scalar β = 1/0.553 in (3), which produces
the curve shown in Figure 1. In summary, (3) takes into
consideration, both evenness and trust directions.
Now, let us consider the total number of emails exchanged
between i and j during tk as Nij,k . We consider that the more
the number of emails exchanged between i and j, the more
the trust between them. This is intuitive since close friends
usually send more emails and close co-workers also send more
emails. To scale down the number of exchanged emails, we
take a base-2 logarithm function on the number of exchanged
emails. The trust evaluations from user i to user j during tk
can be represented as follows:
Tij,k = [log2 (Nij,k + 2)]γij,k .

(4)

In (4), Tij,k = 1 when Nij,k = 0, and Tij,k ≥ 1. The higher
the value of Tij,k , the more trust user i puts on
nuser j. To
evaluate the overall trust in past time period
k=1 tk , we
propose using the following formula:
n

1  Tij,k
.
Tij =
n
k

Lij
Lji

is the proportion of emails sent from i to j to
In (1),
the emails sent from j to i. In general, if Lij roughly equals
to Lji , we can derive the highest mutual trust between i and
j. In other words, (1) captures the evenness of interactions
between i and j. It is easy to prove when Lij = Lji , we

0.4

Lij/(Lij+Lji)=0.6

(5)

k=1

Tij is the overall trust rank of i to j for n time intervals. For
a sequence of time intervals k = 1, . . . , n, we represent t1 as
the current time interval and tn as the farthest time interval

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

from current time. 1/k in (5) takes weight more on the trust
evaluation of a given time interval that is closer to current
time. This is based on the fact that recent emails exchanges
contribute more trust measure, which is generally true for most
social activities.
Tij = [log2 (Nij + 2)]γij .

(6)

Trust can also be evaluated without time intervals. In (6), trust
is calculated based on the total number of emails exchanged
between i and j. A mail sent an year ago and an email sent
today has the same importance.
Each of the trust evaluation equations presented in (1) (6) can be used to measure trust with different properties
as we described above for an email system. The user can
always be given an option in choosing the trust evaluation
method in the EMT server. Additionally, we can also refer
to statistical analysis methods, such as mean, variance, and
standard deviation for each trust measure. In Section V-B, we
will discuss the above presented trust measure models and
corresponding statistic properties based on a study of using
Gmail services.
Tier-2 trust checking: When a user receives trust evaluation
replies from his/her trusted contacts, he/she needs to perform
tier-2 trust check to evaluate the overall trust rank of a checked
email ID. Tier-2 trust checking is essentially a distributed
shortest path algorithm that searches the shortest trusted path
(i.e., the most trusted path) towards the searching email ID.
The link weight of a trust path is T (Trust) or HT (High
Trust) except the last hop to the destination can be NT (Not
Trust). The link weight can be multiplicative or min (or
max) depending on the utilized trust computing algorithm.
For example, if we assign T=0.5, HT=1, NT=0, then a simple
multiplicative algorithm can compute the trust evaluation by:

Tij (H).
(7)
Tij =
H

For min (or max) algorithm, trust can be computed as follows:
⎧
⎨ minH {Tij (H)} or
maxH {Tij (H)} last − hop Tij (H) = N T or U
Tij =
⎩
0
otherwise
(8)
Running tier-2 trust checking does not require TCAs to be
online since the trust checking is performed by EMT server.
V. EMT E VALUATION

A. Validation Setup and Implementations
We developed the EMT server at https://www.wreferral.
com/EmailTrust/faces/index.jsp to perform trust evaluations
for Gmail accounts using the trust measures given in (5). As
shown in Figure 2, the EMT server accesses Gmail server to
retrieve an account’s email headers through IMAP protocol.
Additionally, it also accesses the account’s contacts using
Google Contact API. Using EMT server, we can access the
inbox and contact address book which are required for tier-1
trust checking.
TCA

TCA

TCA

IMAP
using
JavaMail
Gmail
Server
Google
Contact
API

...

Tier 1
(TEA)
Tier 2
(Analyze
results from
L(T, HT)
EMT Server

Fig. 2.

Trust checking through Gmail service.

The EMT server caches all the email IDs who had communicated with user i. The duration of time period k is set to 2
months. Overall, 12 time periods were considered, i.e., EMT
server will consider the emails exchanged during the past 2
years. During a time period, Lij and Lji are obtained by using
the search feature in IMAP.
We tested the trust checking for a given email ID in a Gmail
account that is heavily used containing 7,000+ emails and
occupying 4,325MB space. The trust checking takes about 23 seconds to complete. Thus, in a trust evaluation application
that requires minimal time delay, the real time trust checking
may not be a viable solution. However, we can set up a
trust checking proxy service that proactively and periodically
calculates the trust for each known email ID in advance. Once
a trust request is received, the trusted proxy server can simply
check its database and then send replies promptly. Moreover,
using a trust checking proxy service also makes it practical
for tier-2 trust checking since it does not require each user
to be online to help their trusted contacts to search for trust
ranks for a given email ID. However, we must note that the
proxy server must provide high security and privacy protection
against malicious attackers.
B. EMT Validation Results

To validate the trust model presented in the previous section,
we conduct an EMT evaluation based on Gmail accounts. This
evaluation is performed at Arizona State University (ASU).
Here, we first provide an analysis of the possible attacks,
an introduction to our system configuration for the EMT
validation, the corresponding implementations and then we
provide the validation results.

We conducted a focus group study of Gmail users. We
ran the EMT server for a group of students to extract their
email data from Google email servers. After we derived
the trust measures for the contacts of each user in the test
group, we found that the results match surprisingly well to
our expectations. Statistically, we found that, when the trust
measure is greater than 0.45, students usually consider those

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

contacts are in the category of HT; when the normalized trust
measure is between 0.3 and 0.45, students usually consider
those contacts are in the category of T. On an average, the
highest T value a contact without trust had 0.23. The average
T value of the most trusted contact was 1.192 among students
who used their email address for communication heavily.
In a survey among the test subjects, they responded that
they found their own other email addresses like work or
academic email addresses in the list. These email addresses
needs to be removed by sequence alignment [13]. The subjects
also mentioned that they found contacts at the bottom of the
list whom they trusted. These contacts were communicated
through email less frequently in the recent past. The reason
for such occurrence is that the algorithm considers only the
contacts who were contacted frequently. We can also conclude
the likelihood of false positive is more than false negative.

Fig. 4.

γ measure.

variance change confirms our trust measure model given in (1)
where continuous email exchanges in each time intervals will
usually produce high trust measure.
VI. C ONCLUSION AND F UTURE W ORK

Fig. 3.

Normalized trust measure – indexed by using (3).

In Figure 3, we present the trust measure for a student
who has more than 30 contacts in the trust level H or HT.
This figure is organized using the decreasing order of trust
measure based on the γ values derived from (3). We notice
that the trust measure using (1) is usually higher than the
corresponding trust measure using (3). There are more than
90% of trust measures with both (1) and (3) falling in the same
category T or HT. With students’ feedbacks, the trust measure
presented in Figure 3 shows that considering more weight on
outgoing emails for trust measure (using (3)) will reduce the
trust belief on a given email ID and make the trust measure
more conservative. Thus, we conclude that we can use (1) and
(3) to measure email-based trust for a user according to his/her
personalities: aggressive and conservative, respectively.
Based on the above discussion, we notice further that the
value of γ contributes significantly to a trust measure. In
Figure 4, we present the max-mean-min values of the student’s
γ evaluation using (3). We also notice that towards the left
of the figure, where the trust measure is HT, about half of
γ values have shorter distance between the max and min
(compared to the right side of the figure). This also means
that the variance (or standard deviation) of γ evaluation is
small. On the contrary, the right side of Figure 4 shows larger
variance of γ evaluation. The γ measure with respect to the

In this paper, we presented a email trust evaluation system
for email users. Potentially, there are many applications can
be benefit from using the proposed EMT framework. For
example, as a new trend, the network service model is shifting
from network-centric to user-centric model, in which the end
users can establish a service domain based on his/her social
network. The presented EMT can be used to bootstrap such a
user-centric service domain.
Next, we will perform a thorough EMT evaluation by involving more users and including more email data and conduct
focus group studies for users with different background. In this
way, we will be able to find new evaluation metrics and tune
existing metrics that can be customized for email users.
R EFERENCES
[1] IETF PIIX Working Group, “Public-key infrastructure (x.509) (pkix),
available at http://www.ietf.org/html.charters/pkix-charter.html,” Internet
RFCs.
[2] WOT (Web Of Trust), available at http://www.mywot.com/.
[3] S. Garfinkel, PGP: pretty good privacy. O’reilly, 1995.
[4] “Open PGP,” http:// www.openpgp.org/ .
[5] “Web of trust statistics and pathfinder,” http:// webware.lysator.liu.se/ jc/
wotsap/ wots/ latest/ wotinfo.txt.
[6] M. Xie and H. Wang, “A collaboration-based autonomous reputation
system for email services,” in Preceedings of IEEE INFOCOM, 2010.
[7] J. Golbeck, “TrustMail,” http:// trust.mindswap.org/ trustMail.shtml.
[8] R. Guimera, L. Danon, A. Diaz-Guilera, F. Giralt, and A. Arenas, “Selfsimilar community structure in a network of human interactions,” Phys.
Rev. E, vol. 68, no. 6, p. 065103, 2003.
[9] M. Newman, “Detecting community structure in networks,” The European Physical Journal B-Condensed Matter and Complex Systems,
vol. 38, no. 2, pp. 321–330, 2004.
[10] “Email and webmail statistics,” Email Marketing Reports http://www.
email-marketing-reports.com/metrics/email-statistics.htm, 2008.
[11] D. Huang and V. Arasan, “Email Trust Service,” http://emailtrust.eas.
asu.edu:8080/EmailTrust/faces/index.jsp.
[12] J. H. Spencer, The Strange Logic of Random Graphs (Algorithms and
Combinatorics). Springer Verlag, 2001.
[13] J. Kleinberg and E. Tardos, Algorithm design.
Addison-Wesley
Longman Publishing Co., Inc. Boston, MA, USA, 2005.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

On Measuring Anonymity For Wireless Mobile Ad-hoc Networks
Dijiang Huang
Computer Science and Engineering
Arizona State University
Tempe, AZ 85287-8809 USA
dijiang@asu.edu

Abstract

Thus, it is highly demanded to device an effective mechanism to measure the anonymity for automatic wireless communication systems.
In order to achieve the above mentioned goal, we apply the evidence theory [17], which is a branch of generalized information theory, as the mathematical foundation
to build our anonymity measuring mechanism. In evidence
theory, an evidence is a concrete measurement of the real
world and it serves as the basic element to set up the measuring mechanism. In this paper, we use the number of captured/detected packets to quantify the evidence to build our
anonymity measuring approach. Our approach is different
from the traditional Shannon information theory based solutions [5, 15], where the measure is based on hypotheses,
i.e., predetermined probability assignments. In other words,
our approach measures the anonymity from the views of
the adversaries rather than the system designers; thus, our
anonymity measure is scalable to the ability of adversaries.
The rest of this paper is organized as follows: we present
system models of our approach in Section 2; in Section 3,
we present an evidence collection approach, and using this
approach, we can derive the basic probability assignment
for each communication pair; in Section 4, we present how
to apply our approach with accurate and inaccurate evidence; finally, in Section 5, we summarize our work and
point out several future research directions.

We propose an evidence theory based anonymity measuring approach for wireless mobile ad-hoc networks. In
our approach, an evidence is a measure of the number of
detected packets within a given time period. Based on the
collected evidence, we can set up basic probability assignments for all packet delivery paths and use evidence theory
to quantify the anonymity in the number of bits. Our approach is more general and practical comparing to the traditional Shannon information theory based solutions where
the probability assignments are predefined.

1. Introduction
The field of anonymity research has received extensive
attention since late 90’s, although the started research can
be traced back to 80’s with David Chaum’s paper on untraceable electronic mail [3]. However, there are still two
major research issues that need to be solved: (i) what is the
impact of traffic analysis on anonymity of a given communication system? (ii) what is the effective mechanism we
can rely on to measure the impact (or compromise) due to
traffic analysis? Answering the above two questions will
help us to understand fundamental principles of anonymous
systems and design efficient and effective anonymous communication protocols.
Several approaches had been proposed to measure the
anonymity for Internet based protocols, such as [5, 15, 19].
These approaches use Shannon information theory as the
mathematical foundation and they use uncertainty as the
measuring metric to quantify (i.e., in number of bits) the
anonymity. These approaches work well in wired environments where the communication relations among potential
communication peers are relatively static; and the behavior of each communication node is predefined based on a
known probability assignment. However, in wireless environments, the above mentioned properties no longer exist.

1-4244-0419-3/06/$20.00 ©2006 IEEE

2. System and Models
2.1. Definitions of Anonymity and Unlinkability
Based on the definitions given in [14], we present a formal definition of anonymity as follows:
Definition 1 (Anonymity) Anonymity is the state of being
not identifiable within an anonymity set U(t) at a given time
t; At time t, the anonymity set is the set of all possible entities uk ∈ U (k = 1, . . . , N ). 

779

Note that |U| = N and without specific notation, we omit
the parameter t in the rest of representations.
In an anonymity communication system, adversaries
intend to discover the items of interests (IOIs), such as
network routing information, entities activities, initiating/terminating connections, and so on. The adversaries
acquire IOIs by discovering, interpreting, and compromising corresponding network functions (or protocols), such
as routing functions, encryption/decryption functions, network scheduling functions, and so on. Particularly, in this
paper, we focus on the IOIs – communication relations
between all possible communication pairs. We evaluate
the confidence (the level of assurance) to determine who
communicates with whom (i.e. the source-destination relation of a network event such as a transmission) as a(n)
(un)linkability measure.

2.2. Evidence Collection Model
2.2.1

In wireless communication environments, the characteristics of wireless media determine that detecting transmission
activities is recipient insensitive. This is because mobile devices remain silently when they accept packets. Thus, it is
difficult to tell which node is the corresponding recipient
from multiple potential receivers. However, it is not difficult to determine the wireless signal sender by using signal
positioning devices. Thus, anonymity measure of a given
MANET heavily depends on the detectable evidence such
as the captured/detected packets and identified packet originators.
2.2.2

Definition 2 (Perfect Unlinkability) When the event occurrence frequency used to identify the linkability from a
source to each destination (or from each source to a destination) is 1/N , where N is the total number of sources or destinations, the maximum unlinkability measure is achieved as
H(X) = − log2 p(x) = log2 N.

Constraints of Wireless Evidential Systems

IEEE 802.11-based PHY/MAC protocols are de facto standards for wireless Ad Hoc networks. 802.11-based Ad Hoc
protocol is vulnerable to traffic analysis attacks and several adjustments should be deployed to the single-channel
802.11 PHY/MAC protocols (for the comprehensive analysis of the following adjustments, see [9]):

(1)

H(X) is the Hartley uncertainty measure [7] and p(x =
X) = 1/N is the occurrence frequency of event X.

(i) ACK frames should be omitted, or both data frames
and ACK frames must have the same size; (b) the fields
of the source and destination addresses must be hidden
to reduce the opportunity for the adversaries to identify
the communication pairs. One way to achieve (a) and
(b) is to put the ACK information and address information at upper layers such as the application layer. Thus,
cross-layer design must be employed and the ACK and
addresses information should be protected by cryptographic algorithms deployed at the upper layers.

The unlinkability measure presented in (1) implies that the
maximum unlinkability is achieved when the communication system is in an indistinguishable state. In other words,
we cannot derive the preference of one event over another
one based on the system status (i.e., the total captured transmissions). Thus, achieving perfect unlinkability of a communication system is equivalent to random guessing.
In this paper our research focuses on measuring the unlinkability of a given wireless system. Without special notation, we use anonymity and unlinkability interchangeably.
2.1.1

Recipient insensitive

(ii) The virtual carrier sensing (RTS and CTS option) must
be disabled. Thus, the physical carrier sensing is the
only way to avoid collisions.

Attack Model

(iii) Omnidirectional antennas are preferred when the wireless nodes are easier to be identified and located. In
this way, more potential receivers are covered. Thus, it
is more difficult for the adversaries to identify the true
receiver.

In this paper we have the following assumptions for adversaries. They can detect, capture, and monitor the traffic
transmitted within a wireless communication system; however they cannot decrypt the content of captured frames
when cryptographic algorithms are applied. They are silent
observers, i.e., without injecting frames or interrupting
frame transmissions, but they can locate wireless nodes and
trace their movements. Moreover, the adversaries can use
sophisticated wireless signal detection devices to detect the
wireless signal transmission power and transmission directions at any given location within a communication system;
and in other words, the adversaries can locate the signal
source.

2.3. Anonymous Communication Model
Several anonymous routing protocols have been recently
proposed for wireless mobile ad-hoc networks, e.g., [2, 13,
16, 21]. Current anonymity research in wireless mobile adhoc networks mainly focuses the unlinkable data-delivering
and anonymous routing protocol, which are described as
follows.

780

2.3.1

Unlinkable data-delivering

(a)

In wireless environments, adversaries can easily capture
transmitted packets. Both packet content and packet header
can reveal the information of packet sources and destinations. Thus, for unlinkable data-delivering, the packet contents should be encrypted and the header fields such as the
MAC and network addresses must be hidden; for example,
the source and destination addresses are set to broadcasting addresses, i.e., all “1” for wireless broadcasting networks. In order to identify the receivers, a one-way trapdoor message (i.e., an encrypted message [13]) is associated with the packet and only the desired receivers can open
it, and then decrypt the packet. Other approaches such as
pseudonym/identity-based cryptography [10] can be used to
hide the communication relations from adversaries. In addition to link communication participants, the adversaries
can monitor the transmitted radio frequencies to deploy traffic analyzing attacks to disclose the communication participants.
2.3.2

i

A

j

B

2

2

1
(b)

A

C

B

C

Figure 1. An example of 3 nodes Ad-hoc network.
that the wireless devices have omnidirectional antennas. If
we can monitor the network at location i and j, we can detect the packets transmitted among nodes A, B, and C. It
may be noted that at the location i and j, we may receive
the same packet originated from node A; however, based
on the strength of the signal and the location of i and j, we
can determine this packet is originated from node A. As
discussed in [9], determining the packet recipients depends
on several factors: (i) the transmission rate (can be identified in the header of a captured frame), (ii) communication
distance between the sender and a potential receiver, and
(iii) the physical property of the physical device, such its
sensitivity, and the noise and interference level at the receiver’s location. All the above mentioned factors can be
detected and acquired by the adversaries. In addition, most
of energy-preserving communication systems prefer shorter
communication distance, i.e., the path A − B − C is preferred to the direct path A − C.
For example, as shown in Figure 1(b) the detected number of packets are given as follows:

Anonymous routing

The main goal of an anonymous routing protocol is to prevent adversaries from learning the packet forwarding paths.
On-demand anonymous path establishment has been proposed, i.e., a route request is broadcasted hop-by-hop and a
route reply is unicasted along the reverse direction of corresponding request path. Along the packet delivering path,
on each hop, the routing/data packets are protected by using
encryption with a unique cryptographic key. Thus, the same
packet looks different on each packet forwarding hop. As a
result, the adversaries cannot identify a packet forwarding
path by examining the packet content on each hop. Using
this approach, MIX-net type of routing (e.g., [13]), routing
table driven anonymous routing (e.g., [21]), and anti-traffic
analysis techniques (such as dummy traffic [4], spread spectrum [1] and frequency filtering approach [6]) have been
proposed to prevent the attackers from deploying both passive and active attacks to learn the packet delivery paths.
Although the above mentioned anonymous routing techniques can provide a certain level of anonymity, an external
adversary can still utilize monitor the transmitted packets
[9] to identify the communication peers.

Location
# of packets
Source

i
1
A

i
2
B

j
2
B

If we detect one packet from source A and two packets from
source B at i, and two packets from source B at j, we can
infer the following communication relations:

3. Evidence Collection and Basic Probability
Assignment

(i)
(ii)
(iii)

A → B,
B → A,
B → C,

(iv)

A → B → C.

Based on the above detected evidence, the question we want
to answer is “how much evidence supports the above claims
(i)-(iv)?” To answer this question, we make the following
deductions: the packet detected from source A at location i
is the evidence supporting the claim (i); the packets detected
from source B at location i is the evidence supporting the
claim (ii); the packets detected from source B at location
j is the evidence supporting the claim (iii); from claims (i)

A captured packet is an evidence that proves the existence of communications between two or more mobile
nodes. In this paper, we present our anonymity measuring
approach via a simple example shown in Figure 1. In Figure 1(a), three nodes form an ad-hoc network. We assume

781

F
A, B
B, A
B, C
A, B, C


and (iii), we can deduce the evidence for claim (iv), which is
the minimum evidence given by (i) and (iii) (see the Equation (2)). We define the following formula to compute the
quantity of the evidence of a claim:
w(V ) = min {w(U )},
U ⊆V

|V | ≥ 2.

(2)

3.1.1

Bel(V )
1/6
1/3
1/3
2/3

P l(V )
1
1
1
1

Lower-bound and upper-bound of anonymity
measure

Evidence theory (a.k.a., Dempster-Shafer theory) is an important tool to deal with uncertainty which is best covered
in a book by Shafer [17]. In our following presentations in
this section, we describe the basic representations of evidence theory and our interpretation in terms of anonymity
measure.
A belief measure is a function
Bel : P(X) → [0, 1];
and given a basic probability assignment m, the corresponding belief measure is determined for all ordered sets
V ∈ P(X) by the formulas

m(U ).
(3)
Bel(V ) =

m : P(X) → [0, 1],
which is required to satisfy two conditions:

(ii)

m(V )
1/6
1/3
1/3
1/6
1

Table 1. Body of evidence of the example
shown in Figure 1(b).

In Equation (2), w(V ) represents the evidence for the set
V ∈ P(X); X is a universal set (contains all mobile nodes
within the system) and P(X) denotes the power set of X
(i.e., all subsets of X).
We define the normalized value m(V )
=
w(V )/ U ∈P(X) w(U ) for each V ∈ P(X). It expresses the proportion to which all available and relevant
evidence supports the claim that a particular element
of X belongs to the set V , which is one of the acting
communication relations defined in P(X). We note that
the set V is an ordered set, where the elements are ordered
based on the packet delivery sequence. For example,
ordered sets A, B, C and B, A, C are different. In this
paper, we use ∗ to represent an ordered set and {∗} to
represent an unordered set. Using the definitions from the
evidence theory [17], m(·) is indeed the basic probability
assignment function and it has the following properties:

(i)

w(V )
1
2
2
1
6

m(∅) = 0;

m(V ) = 1.

U |U ⊆V

The dual function of belief measure function is called plausibility measure and it is defined as follows:

V ∈P(X)

Based on the evidence and the basic probability assignment function m(V ), we have the following definitions
(presented in [12]): given a basic probability assignment,
every set V ∈ P(X) for which m(V ) = 0 is called a focal
element; the pair F, m, where denotes the set of all focal
elements induced by m is called a body of evidence.
Using the example shown in Figure 1(b), we can derive the basic probability assignments for all possible ordered sets. The results are shown in Table 1 (the presented
Bel(V ) and P l(V ) will be discussed in next section).

P l : P(X) → [0, 1],

P l(V ) =
m(U ).

(4)

U |U ∩V =∅

It is easy to derive the relation P l(V ) = 1 − Bel(V̄ ) and
P l(V ) ≥ Bel(V ). In summary, the Bel(V ) denotes the
lower bound of the possibility that an element (e.g., a mobile node) in X involves in an acting relation (i.e., a packet
delivering path) defined in an ordered set V and its subsets;
whereas the P l(V ) gives the upper bound, i.e., the possibility that an element in X involves in an acting relation
defined in an ordered set V and its subsets and all other ordered set U where U ∩ V = ∅.
In Table 1, we present the values of belief and plausibility measure for the example given in Figure 1(b).

3.1. Measuring Anonymity
In this section, we present an anonymity measuring approach based on the evidence theory [17] and our approach
can be applied to measure more general anonymous communication systems. In addition, we show that our proposed anonymity measuring approach can be reduced to the
anonymity measuring approaches [5, 15] based on Shannon
information theory.

3.1.2

An Evidence Theory Based Anonymity Measure

Measuring anonymity has been explored by using Shannon
information theory [18], e.g., Dı̀az et al. [5], Serjantov and

782

with the set V , i.e., a claim is considered in a broader range
(set V and other
 set U ∈ F as long as V ∩ U = ∅). In
Equation (6),
U V m(U ) expresses the sum of all evidential claims that conflict with the one focusing on the
set V according to the following broader view of conflict:
m(U ) conflicts with m(V ) whenever U  V , i.e., a claim
is considered in a restricted range (set V and all its subsets).
E(m) does not provide a satisfied solution to measure
anonymity in wireless environments. This is because too
many irrelevant sets are considered as part of the acceptable scope to determine a claim. For example, in a 4node scenario, if we want to determine if node A communicates to node C via node B (defined in the ordered set
A, B, C), the evidence shows that node C communicates
to node D (defined in the ordered set C, D) is also considered as a support (since A, B, C ∩ C, D = ∅) for our
intended claim which is obviously irrelevant. Compared to
E(m), C(m) is more appealing for our purpose; however,
as pointed out in [12], C(m) does not properly scale each
particular conflict of m(U ) with respect to m(V ) according
to the degree of violation of the subsethood relation U ⊆ V .
In order to overcome the deficiencies of functions E(m)
and C(m), we utilize the discord function D(m) proposed
by Klir and Ramer [11].




|U − V |
m(V ) log2 1 −
m(U )
D(m) = −
|U |
V ∈F
U ∈F




|U ∩ V |
m(V ) log2
m(U )
. (7)
= −
|U |

Danezis [15], and Tóth et al. [19]. These approaches utilized entropy as the measuring metric, which measures uncertainty. Shannon information theory is based on probability theory. It has restrictions that the anonymity set1 must
be crisp and the anonymity measure must base on a clearly
predefined probability assignment for each communication
participant. Based on our presented anonymity measuring
approach, the shannon information theory based anonymity
measure can be represented as:

m({x}) log2 Bel({x}),
S(m) = −
{x}∈F

where the set {x} ∈ F is singleton and Bel({x}) is the
probability assignment to each mobile node.
Shannon information theory based anonymity measure
has several deficiencies in measuring the anonymity for
wireless mobile ad-hoc networks. It requires unambiguity
probability assignment for each element in X. This requirement leads to two difficulties for measuring anonymity in
wireless ad-hoc environments: (a) the measure should be
very accurate in order to establish the basic probability assignments, i.e., it should be able to measure the number of
packets sent and received by each mobile nodes without ambiguity; (b) the behavior of each mobile node is predictable,
i.e., there is a probability assigned to each mobile node to
send or receive packets. However, in a real wireless ad-hoc
networking environment, it is very difficult to measure the
exact number of packets sent and received by each mobile
node; furthermore, the mobile nodes’ behaviors are usually
unpredictable. Thus, the measured evidence can be very
“fuzzy”, i.e., with ambiguity.
To measure uncertainty, Yager [20] and Höhle [8] proposed entropy-like measure using plausibility measure and
belief measure, respectively.

m(V ) log2 P l(V )
(5)
E(m) = −
V ∈F

= −




m(V ) log2

V ∈F

C(m)

= −


V ∈F

= −


V ∈F

E(m) ≤ D(m) ≤ C(m).

m(U ) ,

D(m) is a generalized function to measure anonymity
of a given wireless mobile communication system in the
number of “bits”. D(m) can be reduced to Shannon measure when all evaluated sets are singletons. However, it is
more general than Shannon measure in that it can be used to
measure anonymity for any given communication scenarios
without probability pre-assignment to each individual node.
It must be noted that the key component in our proposed
anonymity measuring approach is to collect the evidence
and derive the basic probability assignment function m(·)
for each evaluated relation (e.g., a path). In this section, we
have presented an approach to derive the probability assignment m(·). In next section, we present a detailed example
to illustrate our anonymity measuring approach.

V ∩U =∅

m(V ) log2 Bel(V )

m(V ) log2 1 −



U ∈F


−V |
expresses the sum of
In Equation (7), U ∈F m(U ) |U|U
|
individual conflicts of evidential claims with respect to a
particular set V , each of which is properly scaled by the
degree to which the subsethood U ⊆ V is violated. Thus,
D(m) is a weighted version of C(m) and we have the following relations:





1−

V ∈F

(6)

m(U ) .

U V



In Equation (5), V ∩U =∅ m(U ) represents the total evidential claim pertaining to focal elements that are disjoint
1 In [14], anonymity is defined as the state of being not identifiable
within a set of subjects, the anonymity set, where the anonymity set is
the set of all possible subjects. Also see Definition 1.

783

H2

B

h2

C

A

H1

h1

B

H4

h3

G
h7

A

h8
G

E
D

C

h6

F

h4

E
h5

D

Figure 2. An example of 7 nodes form an Adhoc network.

F

H3

Figure 3. Communication area partitions.

4. Measuring Anonymity for Mobile Ad-hoc
Networks

#
1
2
3
4
5
6
7
8
9
10
11

It should be noted that the accuracy of an anonymity
measure totally depends on the ability of adversaries to detect and monitor wireless systems. Thus, the anonymity
measure is subject to the accuracy of captured evidence.

4.1. Measuring Anonymity with Accurate
Evidence
In Figure 2, we present a wireless ad-hoc networking
system with 7 nodes (A-G). A well-equipped adversary
can locate the exact location of each mobile node and detect the source of transmitted packets. We assume that
a sophisticated adversary can accurately detect the packet
source within the communication scope of each mobile
node. With such ability, in the views of the adversaries, a
wireless communication region can be partitioned into multiple hexagon zones and at most one mobile node located
in each zone. The adversaries can differentiate the packets
originated from/to such a small area; for example, hexagon
zones h1 − h8 are shown in Figure 3. In our analysis, we
assume that the mobile nodes prefer shorter communication distance for less energy consumption (see discussions
in Section 2.2.2). Thus, the adversaries can derive the network topology shown in Figure 2. The link between each
pair of nodes represents a possible wireless link between
two mobile nodes.
For example, within a time period ∆t, the adversaries detect exactly one packet originated from each of the hexagon
zones h1 , h2 , and h3 . Thus, the adversaries can compute the
values shown in Table 2. The w-value from line 1 to line 9
are derived directly from monitoring the wireless system;
the w-value in line 10 and line 11 are derived by applying Equation (2). Based on the definition of m and Equations (3) and (4), the adversaries can compute the value of
m(V ), Bel(V ), and P l(V ), which are shown in Table 2.

F
A, B
A, D
A, E
B, A
B, C
B, E
F, E
F, C
F, G
A, B, C
A,
 B, E

w(V )
1
1
1
1
1
1
1
1
1
1
1
11

m(V )
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1

Bel(V )
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1/11
1/11
3/11
3/11

P l(V )
8/11
6/11
8/11
8/11
7/11
8/11
6/11
5/11
3/11
9/11
9/11

Table 2. Body of Evidence.

Based on Equations (5), (6), and (7), the adversaries can
compute the anonymity measure E(m), C(m), and D(m)
as follows:
E(m)
D(m)

=
=

0.764 bits,
1.74 bits,

C(m)

=

3.171 bits.

The maximum entropy of a given set X is log2 |X| (refer to Definition 2 and [7]). In our example, log2 |X| =
log2 11 = 3.46 bits and our measure should be less than
the value of log2 |X|. E(m) and C(m) provide us the lower
bound and upper bound, respectively, of the anonymity
measure of a communication system within the time period
∆t. D(m) is the weighted version of C(m). In term of
anonymity measure, D(m) describes, on the average, the
amount of information to describe the system status within
a given time period ∆t; in other words, on the average, the
amount of efforts to fully describe the system within the
time period ∆t.

784

Since all nodes in V are treated equally, i.e., each node has
the equal opportunity to send or receive L packets, every
focal element in F(V ) has the same basic probability assignment. For example, each focal element K ∈ F(V ) has
the following basic probability assignment:

w(U ).
(9)
m(K) = L/

4.2. Measuring Anonymity with Inaccurate
Evidence
In Section 4.1, we showed how to measure the
anonymity based on accurate evidence. In reality, adversaries may derive fuzzy evidence based on his ability in
monitoring the wireless systems. As shown in Figure 3, the
adversaries can only identify the packets sent from a bigger area, i.e., the hexagon zones identified by H1 , H2 , H3 ,
and H4 . For example, within ∆t, the detected number of
packets originated from hexagons is given as follows:
Hexagon
# of Packets

H1
1

H2
0

H3
1

U ∈F

Equations (8) and (9) reduce the complexity of Equation (7). Nevertheless, computing Equation (7) with inaccurate evidence is not a trivial task due to the amplified
number of ordered sets.

H4
0

4.3. Procedures to Conduct Anonymity
Measure

The adversaries can infer the following communication relations:
(i)
(ii)
(iii)
(iv)
(v)

Based on the discussions in previous sections, here, we
summarize and propose a three-stage approach to compute
the anonymity measure by using Equations (7)-(9):

{A, D, E} → {B, C},
{A, D, E} → {F },
{F } → {A, D, E},
{F } → {B, C},

Stage 1: Derive the focal elements based on Equation (8)
for each unordered set V ∈ F; compute the basic
probability assignment for each focal element K ∈
F(V ) by using Equation (9); and then compute the

|U ∩K|
for each unordered set
U ∈F ,K∈F (V ) m(K) |U |
V . Using Equation (7), we can compute the anonymity
measure for each unordered set, and the summation is
denoted as S1 .

{F } → {G}.

Among these relations, (i)–(ii) are inferred from the packet
detected in H1 ; (iii)–(v) are inferred from the packet detected in H3 . Note that the sets presented from (i) to (v) are
not ordered sets. In this example, the relation (i) represents
12 communication relations in total: 6 internal relations
of the unordered set {A, D, E}, i.e., ordered sets A, D,
D, A, A, E, E, A, D, E, and E, D; 6 external relations between the sets {A, D, E} and {B, C}, i.e., ordered sets A, B, A, C, D, B, D, C, E, B, and
E, C. All these ordered sets are valid focal elements to
measure anonymity. The relations can be more complicated
if more than one packet is detected in the hexagon zone H1
since A, D, and E can form internal multi-hop paths, for
example, the additional number of ordered sets formed by
three elements (A, D, and E) are |{A, D, E}|! = 3! = 6.
Indeed, we should expect this to happen for more general
cases where the time interval ∆t is long enough to capture
more packets. We present the following formula to compute
the number of focal elements (i.e., ordered sets) formed by
an unordered set V (represented as |F(V )|)2 by detecting L
packets, where L ≥ |V | − 1 and |V | ≥ 2:
|F(V )| =



|V | 	

|V |
i=2

i

(i!).

State 2: For each acting relation between two unordered
sets V and U , where the packets originate from set V ,
form the new ordered sets by appending each node in
U to the end of each focal element K ∈ F(V ) derived
in stage 1; and this procedure creates a new set of focal elements denoted by F(K  ). For each element in
V , append each node in U to form a set of 2-member
ordered subsets denoted by F(K  ). Then we can compute:

U ∈F ,K∈F (K  )∪F (K  )

set V .

|U ∩ K|
.
|U |

(10)

Using the results from (10) as the input to the Equation (7) for each acting relation between two unordered
sets, and the summation is denoted as S2 .
Stage 3: Sum the results derived from Stage 1 and Stage 2,
i.e., S1 + S2 , which is the overall anonymity measure
for the evaluated wireless mobile system.

(8)

(8) calculates the number of non-empty and non-singleton
ordered sets formed by elements in V , where |V | ≥ 2.
2 F (V

m(K)

5. Conclusion and Discussions
In this paper, we present an anonymity measuring approach based on evidence theory. In our approach, an

) is defined as the body of focal elements derived from unordered

785

evidence is a concrete measure of a number of detected
packets within a given time period and it serves as the
basic element to set up our anonymity measuring mechanism. Our approach is more general comparing to the traditional Shannon information theory based solutions, where
the anonymity measure is based on the use of predefined
probability assignments. Thus, our approach is more practical in that it measures the anonymity from the views of the
adversaries. In real networking systems, we can utilize the
proposed approach to snapshot the anonymity for every ∆t
in order to monitor the anonymity performance.
Our research is the kickoff initiative to modeling the
anonymity measure for wireless mobile ad-hoc networks
using generalized information theory. The proposed model
has several limitations and further in-depth and broader investigations are required. Here, we point out several research issues and directions:

[5] C. Dı́az, S. Seys, J. Claessens, and B. Preneel. Towards measuring anonymity. In R. Dingledine and P. Syverson, editors,
Proceedings of Privacy Enhancing Technologies Workshop
(PET 2002). Springer-Verlag, LNCS 2482, April 2002.
[6] X. Fu, Y. Zhu, B. Graham, R. Bettati, and W. Zhao. On
flow marking attacks in wireless anonymous communication
networks. In Proceedings of the ICDCS 2005, 2005.
[7] R. V. L. Hartley. Transmission of information. The Bell
System, 7(3):535–563, 1928.
[8] U. Höhle. Entropy with respect to plausibility measures.
In Proceedings of 1th IEEE International Symposium on
Multiple-Valued Logic, pages 167–169, 1982.
[9] D. Huang. Traffic analysis-based unlinkability measure for
ieee 802.11b-based communication systems. In Proceedings
of ACM Workshop on Wireless Security (WiSe), 2006.
[10] D. Huang. A pseudonym-based cryptography for anonymous communications in mobile ad-hoc networks. Special
Issue on Cryptography in Networks, International Journal
of Security and Networks (IJSN), 2007.
[11] G. J. Klir and A. Ramer. Uncertainty in the dempster-shafer
theory: A critical re-examination. International Journal of
General Systems, 12(4):319–331, 1990.
[12] G. J. Klir and M. J. Wierman. Uncertainty-Based Information. Physica-Verlag, A Springer-Verlag Company, 1998.
[13] J. Kong and X. Hong. ANODR:ANonymous On Demand
Routing with Untraceable Routes for Mobile Ad-hoc Networks. In ACM MobiHoc, 2003.
[14] A. Pfitzmann and M. Hansen.
Anonymity, unlinkability, unobservability, pseudonymity, and identity
management - a consolidated proposal for terminology.
Working draft, avaliable at http://dud.inf.tudresden.de/literatur/Anon Terminology v0.26.doc, September 2005.
[15] A. Serjantov and G. Danezis. Towards an information theoretic metric for anonymity. In R. Dingledine and P. Syverson, editors, Proceedings of Privacy Enhancing Technologies Workshop (PET 2002). Springer-Verlag, LNCS 2482,
April 2002.
[16] S. Seys and B. Preneel. ARM: Anonymous routing protocol for mobile ad hoc networks. In Proceedings of of the
20th IEEE International Conference on Advanced Information Networking and Applications - Workshops (AINA 2006
Workshops), 2006.
[17] G. Shafer. A Mathematical Theory of Evidence. Princeton
University Press, 1976.
[18] C. E. Shannon. A mathematical theory of communication.
The Bell System Technical Journal, 27:379–423,623–656,
1948.
[19] G. Tóth, Z. Hornák, and F. Vajda. Measuring anonymity revisited. In S. Liimatainen and T. Virtanen, editors, Proceedings of the Ninth Nordic Workshop on Secure IT Systems,
pages 85–90, Espoo, Finland, November 2004.
[20] R. R. Yager. Entropy and specificity in a mathematical theory of evidence. International Journal of General Systems,
9(4):249–260, 1983.
[21] Y. Zhang, W. Liu, and W. Lou. Anonymous communications
in mobile ad hoc networks. In Proceedings of IEEE Information Communications Conference (INFOCOM), March
2005.

• In our approach, D(m) describes, on the average, the
amount of information to describe the system status
within a given time period ∆t. D(m) is used to describe the anonymity for a system. In some scenarios,
it is more desirable to measure the available anonymity
for a particular mobile user.
• We derived the relations between three measures
E(m), C(m), and D(m). A more rigorous proof is required to explain why D(m) is superior than the other
two methods.
• We use the number of detected packets within the time
period ∆t as the evidence. Other evidence such as timing, node location, and moving speed are also possible evidence that can be used to measure the system
anonymity.
• Packet delivery paths are different by using different
routing protocols. We need to create anonymity measuring models for different protocols.

References
[1] O. Berg, T. Berg, S. Haavik, J. Hjelmstad, and R. Skaug.
Spread Spectrum in Mobile Communication. Institution of
Electrical Engineers, 1998.
[2] A. Boukerche, K. El-Khatib, L. Xu, and L. Korba. A novel
solution for achieving anonymity in wireless ad hoc networks. In Proceedings of the 1st ACM international workshop on Performance evaluation of wireless ad hoc, sensor,
and ubiquitous networks, 2004.
[3] D. Chaum. Untraceable electronic mail, return addresses,
and digital pseudonyms. Communications of the ACM,
24:84–88, 1981.
[4] C. Dı́az and B. Preneel. Taxonomy of mixes and dummy
traffic. In Proceedings of I-NetSec04: 3rd Working Conference on Privacy and Anonymity in Networked and Distributed Systems, August 2004.

786

A Byzantine Resilient Multi-path Key Establishment Scheme and Its Robustness
Analysis for Sensor Networks
Dijiang Huang, Deep Medhi
Computer Science & Electrical Engineering Department
University of Missouri – Kansas City
Kansas City, Missouri 64110, USA.
{dhuang, dmedhi}@umkc.edu
Abstract
Sensor networks are composed of a large number of low
power sensor devices. For secure communication among
sensors, secret keys must be established between them. Random key predistribution and pairwise key establishment
schemes have been proposed for key management in largescale sensor networks. In these schemes, after being deployed, sensors set up pairwise keys via preinstalled keys.
The key establishment schemes are vulnerable to Byzantine
attacks, i.e., packet dropping or altering. To counter these
attacks, we propose a Byzantine resilient multi-path key
establishment scheme that uses the Reed-Solomon errorcorrect coding scheme to improve resilience to Byzantine
attacks. Our proposed scheme can tolerate at most t faulty
key paths, where t = (n − k)/2 when (n, k) Reed-Solomon
error-correct coding scheme is used. In addition, by using
the Reed-solomon coding scheme, sensors can identify the
faulty paths with minimal communication overhead.

1. Introduction
Sensor networks are composed of a large number of low
power sensor devices. For secure communication among
sensors, secret keys must be established between them. Recently, several pairwise key schemes have been proposed
for large-scale sensor networks. These schemes randomly
select a set of keys from a key pool and install the keys in
the memory of each sensor. After deployment, the sensors
can set up pairwise keys by using the preinstalled keys.
In order to improve the resilience to security attacks on
key management schemes for a large-scale sensor network,
several pairwise key management schemes have been proposed. Based on the formation of the key pool, we broadly
classify the proposed schemes into two groups: Purely Random Key Predistribution (P-RKP) schemes and Structured

Key-pool Random Key Predistribution Scheme (SK-RKP)
schemes.
The P-RKP scheme was ﬁrst proposed by Eschenauer
and Gligor [5], and we call it the basic scheme. The proposals that follow the basic scheme improve the basic scheme in ﬁve aspects: 1) shared keys threshold:
q-composite scheme [2] to to improve the resilience
against node capture attack, in which attackers can capture sensors and derive the preinstalled key information.
The compromized keys can be also used among uncompromised sensors [2].; 2) key pool structure: SK-RKP
scheme [9, 4] to improve the resilience to node capture attack; 3) location awareness: key predistribution and
sensors’ deployment are based on known sensors’ deployment information [3, 10, 7] (also target at improving the
resilience to node capture attack); 4) shared keys discovery [12, 11]: the one-way function schemes have been
proposed to reduce the communication overhead during the key discovery phase and improve the resilience
to node fabrication attack, in which attackers can fabricate new nodes based on information derived from the
captured sensors [7]; 5) path-key establishment protocol: multi-path key establishment [2, 19] to prevent a few
compromised sensors from knowing the established pairwise keys.
Rabin [13] proposed using dispersal of information for
security and fault tolerance; Tsirigos and Haas [18] proposed using multi-path coding schemes to solved the path
failure, such as packet dropping. However, when Byzantine
node modify the data, the proposed schemes fails to recover
the original message. Furthermore, the diversity coding cannot detect faulty path.
We can see from the above discussion that signiﬁcant
progress has been made in regard to guarding various attacks, yet Byzantine attacks (discussed below) on the pathkey establishment protocol are the hardest ones to guard
against. All of the previously discussed schemes are vulnerable to Byzantine attack, in which a faulty sensor (captured

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

by attackers) can (a) reveal the indirect keys set up via the
key establishment protocol (We use direct key to represent
a preinstalled key and indirect key to represent a pairwise
key established via direct keys); (b) stop forwarding the indirect keys to prevent the sensors from establishing the indirect keys; (c) or cheat the receivers by altering the forwarded
keys. The cheating attack can prevent the pair of key establishment nodes from deriving the same key. Before we go
further, we ﬁrst describe Byzantine attack.

1.1. Byzantine Attack
The Byzantine problem, also referred to as Byzantine
Generals problem [8], can be expressed abstractly in terms
of a group of generals of the Byzantine army camped with
their troops around an enemy city. Communicating only
by messengers, generals must agree upon a common battle plan. However, messengers may be captured by enemy
and they may deliver wrong messages among generals. The
problem is to ﬁnd an algorithm to ensure that the loyal generals will reach the right message.
Here, we consider any pair of nodes that want to set
up indirect keys as Byzantine Generals and the intermediate nodes that help set up indirect keys as messengers. The
Byzantine attack is deﬁned as the messengers sniff, drop, or
alter transmitted messages between Byzantine Generals.
In snifﬁng attacks, a malicious node just behaves like
normal node, but it will reveal all transmitted information to
attackers. In stop forwarding attack, a malicious node drops
the received key establishment packets. In this way, it can
prevent the indirect key from being established via the malicious node. In cheating attacks, a malicious node alters the
received key establishment packets. In this way, it can prevent the key establishment pairs from establishing the correct key.

1.2. Guarding Against Byzantine Attack
To safeguard the indirect key, multiple key-path schemes
have been proposed in [2] and [19] to prevent the faulty sensors from deriving indirect keys. In [2], multiple physically
link-disjoint paths between two nodes are used to set up an
indirect key. When two nodes u and v want to set up an indirect key via multiple (say j > 1) link-disjoint paths, the
source node, e.g., node u, selects j secrets, s1 , . . . , sj , and
sends each of the secrets onto a unique key establishment
path. To secure a secret message, say s1 , via a key establishment path, say u → x → v, following key establishment steps are performed:
u → x : {s1 }kux ; x → v : {s1 }kxv
where kux and kxv are direct keys shared between pair
(u, x) and pair (x, v), respectively. Upon receiving all the

secrets, node v just simply uses bitwise XOR operation to
derive the indirect key, i.e.,
indirect key = s1 ⊕ . . . ⊕ sj .

(1)

In [19], multiple logical link-disjoint paths between two
nodes are used to set up an indirect key. A logical path
means there exists a key sharing relations among source,
destination, and intermediate nodes along the key establishment path. For example, source node u share t1 direct keys
with intermediate node x and node x shares t2 direct keys
with destination node v (note that u and v do not share a direct key). Since a direct key can be only used for one logical
path, there can be zx = min(t1 , t2 ) key establishment paths
between u and v via intermediate node x. The secrets selection and transmission proposed in [19] is similar to the one
described in [2]. The difference is the use of physical or
logical key establishment paths in corresponding proposed
schemes.
Both proposed multi-path key establishment schemes are
efﬁcient to guard against outsider’s node capture attacks and
Byzantine attacks by passively learning the forwarded messages. However, they are vulnerable to active Byzantine attacks, i.e., an attacker can stop forwarding the secrets or
alter the forwarded secrets which can prevent the receiver
from deriving the right indirect key.

1.3. Contribution of the work & Organization
In this paper, we propose a new multiple node-disjoint
paths key establishment scheme. This scheme is based on
error-correct coding scheme – Reed-Solomon Codes [15].
A sensor applies Reed-Solomon encoding scheme to partition an indirect key into multiple codewords. Each codeword is transmitted via a different node-disjoint path. The
receiver applies Reed-Solomon decoding scheme to identify the faulty key establishment paths and then recover the
original indirect key.
In a sensor network, sensors share the same communication channel, thus the physical node-disjoint paths may
not be possible. However, messages are protected by pairwise keys; only legitimate sensors can decrypt the information. In this way, we can form multiple virtual node-disjoint
paths through shared channels. The main beneﬁts of proposed scheme are three folds:
• The proposed scheme is resilient to t faulty paths. If
(n, k) Reed-Solomon codes is used, t = (n − k)/2.
• The receiver can identify faulty key establishment paths.
• No interactive communications are required to identify
the faulty key establishment paths, which is communication efﬁcient.

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

preinstalled secrets for each sensor
generator polynomial g(x), 2t roots α1 , . . . , α2t , where n − k = 2t, see Equation (2)
key establishment procedure, (n, k) RS codes, multi-path scheme
sender u
receiver v
1. generates p node-disjoint paths between u and v, see [1]
1. uses majority rule to eliminate bad codeword(s)
2. composes received key polynomial r(x)
2. generates key message polynomial m(x), see Algorithm 3
3. creates k codewords mi , i = 1, . . . , k, see Algorithm 3
3. uses Equation (5) to identify faulty path(s)
4. uses source routing to send at most t codewords on each path 4. uses Forney’s algorithm to derive error polynomial e(x)
where t = (n − k)/2
5. recovers the original message polynomial, see (8)
properties of proposed multi-path key establishment scheme
1. resilient to t = (n − k)/2 faulty paths when (n, k) Reed-Solomon codes is used.
2. receiver can identify the faulty key establishment paths.
3. no interactive communications are required, thus is communication efﬁcient.
4. Reed-Solomon error correcting codes are computationally efﬁcient: in the order of O(n log2 n), see [16].

Table 1. t-faulty resilient multi-path key establishment scheme
Note that the proposed scheme is not restricted only to sensor network and key management. It also applies to general
multi-path data transmission to guard against Byzantine attacks.
The rest of the paper is organized as follows: in section 2,
our proposed Reed-Solomon error correcting codes based
multi-path key establishment scheme is discussed in details;
we present the robustness analysis of our schemes in terms
of insider passive/active attacks in section 3; ﬁnally, we give
conclusion and future work in section 4.

2. Node-disjoint Multi-path Key Establishment Schemes
The multi-path key establishment schemes described in
[2, 19] are vulnerable to Byzantine attacks. One of the reasons is that both these schemes use multiple link-disjoint
paths to set up indirect keys. Their schemes are originally
proposed to mitigate node capture attacks. Since a direct
key can be preinstalled in multiple nodes by using the key
predistribution schemes proposed in [5, 2], an attacker can
capture nodes and derive the preinstalled keys that may be
used among uncompromised nodes. Thus, using multiple
link-disjoint paths to establish indirect keys can help to mitigate the node capture attack1 . However, attackers can perform more sophisticated attacks, such as node fabrication
attacks [7] and Byzantine attacks. The attacker can fabricate sensors based on captured nodes and implant malicious codes in the fabricated sensors. These fabricated sensors can be deployed in the sensor network that can perform malicious functions, such as snifﬁng, stop forwarding, and cheating. Link-disjoint multi-path key establishment scheme cannot mitigate these attacks, since the malicious nodes can serve as proxy to set up indirect keys
1

A link is protected by a direct key.

and they can perform malicious functions without being detected.
Another reason that the previously proposed multi-path
key establishment schemes are vulnerable to Byzantine attacks is the proposed key recovery scheme (i.e., bitwise
XOR multiple secrets, see Equation (1)); it is vulnerable
to packet dropping or packet altering. For example, only
one bit altering or packet dropped in one path can prevent
the receiver from correctly deriving the indirect key. Moreover, there is no way for the receiver to identify the problem
source. Zhu et al. [19] proposed using a (k, n) threshold secret sharing scheme [17]. Such a threshold secret sharing
scheme, based on polynomial interpolation, allows a node
receiving any k (out of the n) shares to recover an indirect key, while no information about the indirect key can
be determined with less than k shares. In other words, this
scheme allows malicious nodes on n − k disjoint key paths
to drop packets and the receiver still can recover the indirect key. Although, the threshold secret sharing approach
can mitigate the stop forwarding attacks, it can do little
on cheating attacks. The original threshold secret sharing
scheme proposed by Shamir [17] cannot detect and identify the cheaters.
In order to counter stop forwarding and cheating attacks, we propose a new multi-path pairwise key establishment scheme. Our proposed scheme employs multiple node-disjoint paths and Reed-Solomon error correcting
codes [15] to mitigate stop forwarding and cheating attacks.
The properties and operational procedures of the proposed
scheme are shown in Table 1. In the following sections, we
will discuss the proposed scheme in detail.

2.1. Multi-path Key Establishment Schemes
In general, p-node-disjoint paths are obtained from the
knowledge of (p − 1)-node-disjoint paths by applying the

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

Algorithm 1 (Number of paths)
Initialize H, n , and T ; set h = 2 and P = 0
1. if h ≥ H && pr (h, n ) < T
Stop;
else if pr (h, n ) ≥ T
n = n − h; P = P + 1;
else
h = h + 1;
2. goto 1;

14

T=0.95, p =0.3, H=4, n=25~50
1

13
12
11
10

Number of paths

shortest path algorithm in a modiﬁed graph. The modiﬁed
graph is obtained by replacing the edges of the (p−1)-nodedisjoint paths with arcs directed towards the source node,
and making these arcs negative; in addition, the nodes, except for the endpoint vertices of the (p − 1) disjoint paths,
are split in accordance with the node-splitting method. Note
that the p-node-disjoint paths algorithms have been extensively studied. The detail description of the p(> 2) nodedisjoint shortest path algorithm is out scope of this paper.
For details, please see [1].
In this section, our focus is to analyze the number of
available node-disjoint paths for a node in large-scale sensor networks. In our analysis, we utilized the sensor deployment method proposed in [7]. We use n to denote the average number of direct communication neighbors of a sensor
and p1 to denote the probability that two neighbors share
a direct key. Thus the maximum number of node-disjoint
paths max number paths ≤ n p1 . In [6], we have derived
the probability pr (h, n ) that a node can reach any of its n
neighbors within h hops. Due to the requirement that multiple paths are node-disjoint, once a node is selected by a
path, it cannot be used by other paths. The following algorithm is used to compute the number of paths within h hops
with the probability pr (H, n ) ≥ T , where T is a probability threshold and H is the hop count threshold.

9
8
7
6
5
4
3
2
1
0

25

30

35

40

45

50

Number of neighbors

Figure 1. Number of paths to a neighbors (n =
25 ∼ 50, average number of neighbors; H = 4,
maximum number of hops; T = 0.95, probability threshold to evaluate a viable path;
p1 = 0.3, probability a node shares a direct
key with one of its neighbors.

RS code with symbols from GF (2q ) with following parameters:
n = 2q − 1
and
n − k = 2t
where n is the total number of code symbols in the encoded block, t is the symbol-error correcting capability of
the code, and n − k = 2t is the number of parity symbols.
A publicly known generator polynomial is of the form:
g(x)

(2)
= (x + α)(x + α2 ) · · · (x + α2t )
2
2t−1
2t
+x
= g0 + g1 x + g2 x + · · · + g2t−1 x

Based on Algorithm 1, we plot the average number of
paths between two nodes in Figure 1. We analyze the case
where the number of neighbors range from 25 to 50. We notice that, with the increasing number of neighbors, the number of paths between a pair of nodes increases.

where gi ∈ GF (2q ) and g(x) has α, α2 , . . . , α2t as roots.
Using the RS encoding algorithm (see Algorithm 3 in
Appendix A), we can derive the codeword polynomial c(x):

2.2. Multi-path Encoding

where

The Reed-Solomon codes (RS codes) are nonbinary cyclic codes with code symbols from a Galois
ﬁeld [15]. RS codes have been widely used in many applications from compact discs and digital TV to spacecraft
and satellite.
Brieﬂy, RS codes are deﬁned as follows. Let α be a primitive element in the Galois Field, GF (2q ). For any positive
integer t ≤ 2q − 1, there exists a t-symbol-error-correcting

c(x) = b(x) + x2t m(x)

(3)

b(x) = x2t m(x) mod g(x)

(4)

and where b(x) is the parity polynomial, m(x) is the message polynomial.
Every element in GF (2q ) can be represented uniquely
by a binary q-tuple, called a q-bit byte. Suppose an (n, k)
RS code with symbols from GF (2q ) is used for encoding
binary data. A message of kq bits is ﬁrst divided into k q-bit
bytes. Each q-bit byte is regarded as a symbol in GF (2q ).

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

The k-byte message is then encoded into n-byte codeword
based on the RS encoding rule. By doing this, we actually
expand a RS code with symbols from GF (2q ) into a binary (nq, kq) linear code, called a binary RS code. Binary
RS codes are very effective in correcting bursts of bit errors as long as no more than t q-bit bytes are affected.
If the length of an indirect key is kq, we can divide kq bits
into k q-bit segments. For example, in (15, 9), 3-symbolerror correcting RS code over GF (24 ), q = 4, k = 9, n =
15. The key length is kq = 36 and the parity length is
(n − k)q = 24. Thus, we can divide the key into k = 9
codewords. Each codeword contains q = 4 bits key information and 24 bits parity information, and the total length
of a codeword is 28 bits. Note that the 24 bits parity code is
used to check the entire 36 key message. In above example,
we partition a kq-bit key message into k q-bit bytes. In order to increase the resilience to Byzatine attacks, each codeword can be transmitted via a node-disjoint path. The following algorithm is used to partition keys into k codes and
the k codes are transmitted via p node-disjoint paths:

Algorithm 2 (Path-encoding)
Goal: node u sets up an indirect key M with node v
Initial: (n, k) t-symbol-error correcting RS
code over GF (2q ), size of an indirect key M is kq
1. create message polynomial
m(x) = m0 + m1 x + · · · + mk−1 xk−1 ,
where mi is a q bits code
2. compute b(x) = x2t m(x) mod g(x)
where b(x) = b0 + b1 x + · · · + b2t−1 x2t−1
b = b0 ||b1 || · · · ||b2t−1 is the parity code
3. compute p node-disjoint shortest paths,
where 2t < p ≤ k
4. create codewords mi = (mi ||b), i = 1, . . . , k,
and send at most t codewords on a path
∗
|| is concatenation operator

In Algorithm 2, node u wants to set up an indirect key
with node v. Node u randomly picks up an indirect key
M = (m0 ||m1 || · · · ||mk−1 ) and creates the message polynomial m(x). By using the RS encoding algorithm (see Algorithm 3 in Appendix A), node u derives parity polynomial b(x) and corresponding parity code b. It then computes
p-node-disjoint shortest paths, where 2t < p ≤ k is to guarantee no more than t codewords are delivered via the same
path. Finally, node u sends at most t codewords on each
path. We assume k, p > 2t, thus we can use majority rule
to rule out the compromised parity code b transmitted via
the compromised paths. In this way, we can recover the indirect key when at most t paths are compromised.

2.3. Multi-path Decoding
If malicious nodes alter the parity code b, we can use the
majority rule to rule out the compromised codeword. Thus,
the attacker may want to alter forwarded codeword mi instead of parity code b. From Equation (3) and Equation (4),
we know the roots of g(x) must also be the roots of c(x).
Since the received codeword r(x) = c(x) + e(x), where
n−1
e(x) = j=0 ej xj is the error polynomial, r(x) evaluated
at each of the roots of g(x) should yield zero only when it
is a valid codeword. Any errors will result in one or more
of the computations yielding a nonzero result. The computation of a syndrome symbol can be described as follows:
Si = r(x)|x=αi = r(αi )

i = 1, . . . , 2t

(5)

If there exists v errors, where 0 ≤ v ≤ t, in the unknown
locations j1 , j2 , . . . , jv , then
e(x) = ej1 xj1 + · · · + ejv xjV

(6)

Deﬁne the error values to be Yl = ejl , where l =
1, 2, . . . , v. And the error locators to be Xl = αjl , where
l = 1, 2, . . . , v. We can utilize Forney’s algorithm[14] to
derive the error values Yl . Thus, we can derive the error correcting polynomial:
e(x) =

v


Yl xjl

(7)

l=1

Then, we can recover c(x) as
c(x) = r(x) − e(x).

(8)

Finally, applying Equation (3), we can derive the key message polynomial m(x) and then derive the indirect key
M = (m0 || · · · ||mk−1 ).

3. Roubustness Analysis
In this section, we analyze the robustness of our proposed multi-path key establishment scheme under Byzantine attacks. The attacker can actively attack indirect keys
establishment by replicating captured sensors and deploy
the replicated sensors in sensor networks. In order to derive indirect keys established among uncompromised nodes,
the attacker ﬁrst inspects the key graph2 topology by passively snifﬁng the trafﬁc and quickly deploy the replicated
sensors in the sensor network to create a shortcut of the key
graph used by uncompromised nodes. These replicated sensors can serve as intermediate nodes in the key paths3 . Then,
2

A key graph maintained by node i is deﬁned as Gi = (Vi , Ei ) where,
Vi = {j|j ∈ Wi ∨ j = i}, Ei = {ejk |j, k ∈ Vi ∧ k ∈ Wj ∧ j ∈
Wk ∧ jSk}, S is a relation deﬁned between two nodes if they share
one direct key.

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

1

1

SK−RKP
h=2 p=5 t=2
h=3 p=5 t=2
h=4 p=5 t=2
h=2 p=5 t=1
h=3 p=5 t=1
h=4 p=5 t=1
h=2 p=5 t=0
h=3 p=5 t=0
h=4 p=5 t=0

0.6

(x,t;p,h)

0.7

0.8

0.5

Robustness R

Robustness Rpassive(x,t;p,h)

0.8

0.4

0.3

0.7

0.6

0.5

0.4

0.3

0.2

0.2

0.1

0.1

0

0

50

100

150

200

250

300

350

400

450

SK−RKP
h=2 p=3 t=2
h=3 p=3 t=2
h=4 p=3 t=2
h=2 p=5 t=2
h=3 p=5 t=2
h=4 p=5 t=2

0.9

passive

0.9

0

500

0

50

100

150

(a) Passive path-key establishment attack to P-RKP and SK-RKP
schemes (same number of paths with different path-length and resilient factor -t)

300

350

400

450

500

1

h=2 p=5 t=2
h=3 p=5 t=2
h=4 p=5 t=2
h=2 p=5 t=1
h=3 p=5 t=1
h=4 p=5 t=1
h=2 p=5 t=0
h=3 p=5 t=0
h=4 p=5 t=0

0.8

0.7

0.8

0.6

0.5

0.4

0.3

0.7

0.6

0.5

0.4

0.3

0.2

0.2

0.1

0.1

1

2

4

6

8

10

12

14

16

18

h=2 p=3 t=2
h=3 p=3 t=2
h=4 p=3 t=2
h=2 p=5 t=2
h=3 p=5 t=2
h=4 p=5 t=2

0.9

Robustness Ractive(x,t;p,h)

0.9

Robustness Ractive(x,t;p,h)

250

(b) Passive path-key establishment attack to P-RKP and SK-RKP
schemes (different number of paths and path-length with the same resilient factor -t)

1

0

200

Number of compromised nodes

Number of compromised nodes

20

0
1

2

4

(c) Active path-key establishment attack to P-RKP and SK-RKP
schemes (same number of paths with different path-length and resilient factor -t)

6

8

10

12

14

16

18

20

Number of compromised nodes

Number of compromised nodes

(d) Active path-key establishment attack to P-RKP and SK-RKP
schemes (different number of paths and path-length with the same resilient factor -t)

Figure 2. Attacks to path-key establishment (passive vs. active, h = 2, 3, 4; p = 3, 5; t = 1, 2)
they can derive the indirect keys established via these key
paths.
As we have discussed, single path key establishment
scheme is vulnerable to Byzantine attacks. Several multipath key establishment schemes have been proposed. In
[2, 19], the authors proposed to divide indirect key into multiple pieces and then send them via multiple paths; in the
following analysis, we call such schemes as Byzantine deﬁcient schemes. We deﬁne the robustness R(x, ·; ·, ·) as the
probability of an indirect key is not compromised due to x
3

A key path between node A and B is deﬁned as a sequence of nodes A,
N1 , N2 ,. . ., Ni , B, such that, each pair of nodes (A, N1 ), (N1 , N2 ),
. . ., (Ni−1 , Ni ), (Ni , B) has one direct key. The length of the key
path is the number of pairs of nodes in it.

compromised nodes.

3.1. Resilience Against Passive Key Establishment
Attacks
Suppose that there are x compromised nodes that collude
by sharing their key sets. The probability that a key is not
selected by a sensor is 1−m/P and is not selected by x sensors is (1−m/P )x , where P is the total size of the key pool,
m is number of keys selected for a sensor. Thus a key is selected by at least one of x sensors is 1 − (1 − m/P )x . We
assume that the direct keys used on a key path are all different; thus, all direct keys on a key path with h hops are not
selected by x sensors is [(1 − m/P )x ]h . Hence, the proba-

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

bility that at least one of direct keys on a h hop path is compromised is:
ppassive (x, h) = 1 − (1 − m/P )xh .

(9)

If all key paths have the same length h, we deﬁne robustness
as:
Rpassive (x, t; p, h)
t  

i 
p−i
p 
=
ppassive (x, h) 1 − ppassive (x, h)
i
i=0
(10)
In Byzantine deﬁcient multi-path schemes, t = 0. For our
proposed multi-key path key establishment scheme (which
we call it as Byzantine resilient scheme), we have t > 0.
InFigure 2(a) and 2(b), we notice that using different
key predistribution schemes, such as the SK-RKP key distribution scheme, the resilience to passive path-key establishment attacks can be increased dramatically compared to
Byzantine deﬁcient schemes. For sensor-class attackers, the
insider nodes must be physically located on all key paths to
derive the indirect keys, since a unique key can be derived
between a pair of sensors. It requires that at least p insider
nodes are deployed in the sensor network and each of the insider nodes is located on one of the p-disjointed key paths.
Figure 2(a) and 2(b) show that (i) the P-RKP scheme is still
vulnerable to passive key establishment attack and the SKRKP scheme is perfectly resilient to this type of attacks unless the sensors involved in the indirect key establishment
procedure are compromised; (ii) shorter path length exhibit
better Byzantine resilience; (iii) using RS codes, if t is closer
to the number of path p, we obtain the most gain in robustness from our scheme (see Figure 2(b)).

3.2. Resilience Against Active Key Establishment
Attacks
(ωτ)(ω−τ
τ )
is the prob2
(ωτ)
ability that two nodes share at least one key, where ω is the
number of key space, τ is the number of selected key spaces
for a sensor. For details, see [9, 4]. For the P-RKP scheme,
we have ω = P, τ = m; for details, see [5]. Thus, 1 − p21 is
the probability that a node does not share direct keys with at
least one of two uncompromised nodes; thus, (1 − p21 )x is
the probability that all x compromised nodes do not share
direct keys with at least one of two uncompromised nodes;
for a h-hop key path, [(1−p21 )x ]h is the probability that all x
compromised nodes do not share at least one of two uncompromised nodes on any hop of this key path. Thus, for a key
path with h hops, the probability that at least one of x compromised nodes can create a short cut on a key path is:
For the SK-RKP scheme, p1 = 1 −

pactive (x, h) = 1 − [(1 − p21 )]xh

(11)

If all key paths have the same length h, we have
Ractive (x, t; p, h)
t  

p
i
p−i
=
(pactive (x, h)) (1 − pactive (x, h))
i
i=0
(12)
Note that Byzantine deﬁcient multi-path schemes, t = 0.
Figure 2(c) and 2(d) show that both P-RKP and SK-RKP
schemes are vulnerable to active path-key attacks. Comparing with the passive path-key establishment attack shown
in Figure 2(a) and 2(b), the robustness of the PKE protocol decreases dramatically. Similar to the discussion in the
case of passive attacks, we notice that increase in threshold t will increase the resilience to Byzantine attacks. We
note that Figure 2(c) and 2(d) show the worst case of our
proposed scheme. In reality, the source node u will arbitrarily select p node-disjoint paths to set up indirect keys. The
malicious nodes may not be physically located on the selected key setup path. While in Figure 2(c), we address the
worst case of the studied multi-path PKE schemes, i.e., we
assume that a path is compromised as long as we can ﬁnd
a compromised node that can create a short-cut on any possible key path and this compromised node is physically located in the compromised key path.

4. Conclusion
In this paper, we propose a multi-path pairwise key establishment scheme to counter Byzantine attacks, i.e., attacks due to packet dropping and cheating. In our approach, we apply p(≥ 2) node-disjoint paths key establishment scheme and embed the Reed-Solomon error correcting coding scheme. Our proposed scheme is resilient
to t = (n − k)/2 faulty paths when (n, k) Reed-Solomon
codes is used. The receiver can identify the faulty key establishment paths and no interactive communications are required, and is communication efﬁcient.
Our proposed scheme can tolerate up to t faulty paths between the communication pairs. In our future work, we plan
to study how to improve the resilience to Byzantine attacks
with minimal interactive communications involved.

Acknowledgement
The authors would like to thank anonymous reviewers
for their valuable comments.

References
[1] R. Bhandari. Survivable Networks – Algorithms for Diverse
Routing. Kluwer Academic Publishers, 1999.

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

[2] H. Chan, A. Perrig, and D. Song. Random key predistribution schemes for sensor networks. In Proceedings of 2003
Symposium on Security and Privacy, pages 197–215, Los
Alamitos, CA, 11–14 2003. IEEE Computer Society.
[3] W. Du, J. Deng, Y. S. Han, S. Chen, and P. K. Varshney. A
key management scheme for wireless sensor networks using
deployment knowledge. In Proceedings of IEEE Information
Communications Conference (INFOCOM), March 2004.
[4] W. Du, J. Deng, Y. S. Han, and P. K. Varshney. A pairwise
key pre-distribution scheme for wireless sensor networks.
In Proceedings of 10th ACM Conference on Computer and
Communications Security (CCS’03), pages 42–51, October
2003.
[5] L. Eschenauer and V. D. Gligor. A key-management scheme
for distributed sensor networks. In Proceedings of 9th
ACM Conference on Computer and Communication Security (CCS-02), pages 41–47, November 2002.
[6] D. Huang, M. Mehta, D. Medhi, and L. Harn. Modeling
pairwise key establishment for random key predistribution
in large-scale sensor networks. submitted for publication
and available at http://conrel.sice.umkc.edu/HRP/modelling
pairwise key establishment schemes-v2.pdf, 2004.
[7] D. Huang, M. Mehta, D. Medhi, and H. Lein. Locationaware key management scheme for wireless sensor networks.
In Proceedings of ACM Workshop on Security of Ad Hoc and
Sensor Networks (SASN ’04), pages 29–42, October 2004.
[8] L. Lamport, R. Shostak, and M. Pease. The Byzantine generals problem. ACM Transactions on Programming Languages
and Systems,, 4(3):382–401, 1982.
[9] D. Liu and P. Ning. Establishing pairwise keys in distributed sensor networks. In Proceedings of 10th ACM Conference on Computer and Communications Security (CCS’03),
pages 52–61, October 2003.
[10] D. Liu and P. Ning. Location-based pairwise key establishments for static sensor networks. In Proceedings of the 1st
ACM workshop on Security of ad hoc and sensor networks
(CCS’03), pages 72 – 82, 2003.
[11] M. Mehta, D. Huang, and L. Harn. A practical scheme for
random key predistribution and shared-key discovery in sensor networks. In Proceedings of 24th IEEE International
Performance Computing and Communications Conference,
2004.
[12] R. D. Pietro, L. V. Mancini, and A. Mei. Efﬁcient and
resilient key discovery based on pseudo-random key predeployment. In Proceedings of 18th International Parallel
and Distributed Processing Symposium (IPDPS’04), April
2004.
[13] M. O. Rabin. Efﬁcient dispersal of information for security,
load balancing, and fault tolerance. Journal of the Association for Computing Machinery, 36(2):335–348, 1989.
[14] I. S. Reed and X. Chen. Error-Control Coding for Data Networks. Kluwer Academic Publishers, 1999.
[15] I. S. Reed and G. Solomon. Polynomial codes over certain ﬁnite ﬁelds. SIAM Journal of Applied Math, 8:300–304, 1960.
[16] D. V. Sarwate. On the complexity of decoding goppa codes.
IEEE Transactions on Information Theory, 23(4):515–516,
1977.

[17] A. Shamir. How to share a secret. Communications of the
ACM, 22(11):612–613, 1979.
[18] A. Tsirigos and Z. J. Haas. Analysis of multipath routingpart
i: The effect on the packet delivery ratio. IEEE Transactions
on Wireless Communications, 3(1):138–146, 2004.
[19] S. Zhu, S. Xu, S. Setia, and S. Jajodia. Establishing pair-wise
keys for secure communication in ad hoc networks: A probabilistic approach. In Proceedings of 11th IEEE International
Conference on Network Protocols (ICNP), November 2003.

Appendices A and B can be found in the Reed
and Chen’s book “Error-Control Coding for Data
Networks”[14]. We have reproduced them here for
the ease of following the paper.

A. Encoding of Reed-Solomon Codes
Algorithm 3 (Encoding of RS Codes)
1. let m(x) = m0 + m1 x + · · · + mk−1 xk−1 be the
message polynomial to be encoded
where mi ∈ GF (2q ) and k = n − 2t
2. Dividing x2t m(x) by g(x), we have
x2t m(x) = a(x)g(x) + b(x)
where b(x) = b0 + b1 x + · · · + b2t−1 x2t−1
b(x) is the parity check polynomial
Then c(x) = b(x) + x2t is the codeword
polynomial for the message m(x)

B. Decoding of Reed-Solomon Codes
Algorithm 4 (Decoding of RS Codes)
1. c(x) = c0 + c1 x + · · · + cn−1 xn−1
r(x) = r0 + r1 x + · · · + rn−1 xn−1
e(x) = e0 + e1 x + · · · + en−1 xn−1
where ci , ri , ei ∈ GF (2q ),
r(x) is received codeword,
and e(x) = r(x) − c(x) is the error polynomial
where ei = ri − ci is a symbol in GF (2q )
2. Suppose e(x) has v errors at the locations
then, e(x) = ej1 xj1 + ej2 xj2 + · · · + ejv xjv
The error-location numbers are
Xj1 = αj1 , Xj2 = αj2 , · · · , Xjv = αjv
Using Forney’s algorithm , the error values are
Yl = ejl , l = 1, . . . , v
3. To recover the original message c(x)
we have c(x) = r(x) − e(x)

: readers can refer to [14] for details of Forney’s
algorithm.

Proceedings of the 19th IEEE International Parallel and Distributed Processing Symposium (IPDPS’05)
1530-2075/05 $ 20.00 IEEE

A Distributed ePedigree Architecture
Dijiang Huang,
Mayank Verma,
Archana Ramachandran,
Zhibin Zhou
Arizona State University, Arizona State University, Arizona State University, Arizona State University,
dijiang@asu.edu,
mayank.verma@asu.edu, archana.ramachandran
zhibin.zhou@asu.edu.
@asu.edu,
Abstract
Current ePedigree creation and discovery services rely on
a centralized framework, i.e., EPCglobal network. The
centralized system has several restrictions to prevent it from
being widely adopted. For example, it is un-scalable when
ePedigree service requests are increased dramatically due to
the item-level product tracking; it has little privacy
protection since the product historical information can be
easily derived from the Object Name Service (ONS) provided
by the centralized EPCglobal network; it is cumbersome
since the ePedigree information will be amplified in the local
databases along with the product transportation stops; and
so on. To overcome the above mentioned problems, we
propose a distributed EPC Information Service (EPC-IS),
which makes the ePedigree creation and discovery more
robust, scaleable, and secure. Using our approach, the
ePedigree historical records of a product is created and
stored in the ePedigree creating parties’ EPC-IS servers; in
addition, each EPC-IS server maintains a look up table that
stores the EPC-IS providers’ one-hop up/down stream
information. In this way, the ePedigree service creation and
discovery are processed following a chain of processes with
a distributed manner. The distributed ePedigree architecture
and a set of EPC-IS service protocols are described in this
paper.

1. INTRODUCTION
An ePedigree is the historical records of a product distributed
along the distribution system in the supply chain from its
manufacture to the final customer. Electronic Product Code
(EPC) realized by RFID technology transfers traditional
Pedigree creation and verification from cumbersome paper
processing to efficient digital handling. In healthcare domain,
identifying counterfeit drugs becomes very critical. Thus, it is
highly desired that the ePedigree should provide item-level
tracking instead of massive-level tracking (e.g., pallet and
container). Existing ePedigree discovery system relies on a
centralized framework, i.e., EPCglobal network [3]. It brings
visibility of assets, reduction in inventories, just-in-time
inventory handling, reduction in labor, and many other
benefits.
The EPCglobal Network premises a lot to manufactures,
retailers, healthcare providers, hospitals, and many more

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

industries in the ecosystem. However, it does bring up
several concerns to prevent it from being widely deployed:
(a) it is vulnerable to single point failure, (b) it is not scalable
to handle a large number of requests, such as it involves
heavy load of communication overhead and administrative
overhead such as registration, records verification, updating,
and processing; (c) when a particular object moves form one
level to the other in the supply chain, more information about
the object would be added for its usage at the next level and
thus create additional overload in local databases; and (d) the
EPC discovery to its ePedigree service mapping is
maintained by a third party, and thus the centralized
framework has potential privacy exposure problems.
To address the above mentioned problems, we propose a
distributed EPC Information Service (EPC-IS) architecture
for ePedigree creation and discovery, which makes the
ePedigree services more robust, scaleable, and secure. The
distributed architecture consists of various components such
as Distributed Hash Table (DHT), ePedigree certificate
services, ePedigree creation parties, and the EPC-IS service
providers. Using our approach, the ePedigree historical
records of a product is created and stored in the ePedigree
creating parties’ EPC-IS servers; in addition, each EPC-IS
server maintains a look up table that stores the one-hop away
EPC-IS providers’ DHT ids and corresponding IP addresses;
the ePedigree discovery service is via DHT searching. Note
that all the operations of ePedigree creation and discovery
require mutual authentication via certificate services. Thus,
only legitimate parties are able to perform ePedigree related
operations.
Our research goal is to construct a reliable and secure
ePedigree creation and discovery infrastructure. Thus, the
sharing of pedigree information common to organizations
will ensure better security and data exchange mechanisms,
resulting in smoother operations and eradicating the storage
of repetitive data.
The rest of the paper is arranged as follows: in section 2,
we provide the background of EPCglobal network; the
system components to build up our distributed EPC-IS
services are presented in section 3; in section 4, we describe
the proposed distributed ePedigree architecture in details; the
protocols involved in our ePedigree architecture are
presented in section 5; finally, we summarize our research
and provide the research directions in section 6.

Figure-1: Centralized Architecture.

2. BACKGROUND
Research in creating ePedigree has increased extensively in
recent years. Most of existing work is relying on a
centralized approach [2]. EPC and ISO have been working in
this area, but the major contribution has been done by
EPCGlobal. The supply chain and ePedigree overview along
with demonstration of EPCglobal network is described in [1]
and [2], respectively. The architectural framework of
ePedigree has been described in [3]. It explains the various
components that combine to form the entire framework with
the technical principles and their role and interfaces along
with the data flow among relationship between various
interfaces.
The centralized architecture of ePedigree is shown in
Figure-1. It contains a centralized authority, which includes
ONS services [4]. There exists a direct relationship between
every participant in the network with the centralized server.
Every participant in EPCglobal network maintains an EPC-IS
(Electronic Product Code) server, which stores relevant
information related to specific EPC numbers. In centralized
approach, when a query is submitted to EPCGlobal network,
it is directed to root ONS, which returns the address of EPCIS server containing the requested information. The major
drawback of the existing ePedigree discovery and
verification service is its centralized infrastructure. The
centralized infrastructure imposes three restrictions: (1) It is
vulnerable to single point failure, (2) It requires complicated
registration and processing procedures, and (3) The
ePedigree owner has little control on the ePedigree
discovery, which creates potential privacy exposure
problems. Thus, it is highly desirable to replace the
centralized ONS by distributed EPC discovery service. A

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

distributed peer-to-peer network infrastructure is a promising
candidate.
ePedigree makes use of RFID tags [5] for identification
of products. There exist various types of tag formats. They
fall under two basic categories. General, EAN.UCC system
and DoD identity type [5]. We base our protocol on
generaltion2 (gen2) tag (see Figure-2), as there is no standard
tag format. The use of generation-2 (gen-2) tags makes our
protocol more roust. In gen-2 tags, tag the memory is
separated into four distinct banks, each of which comprises
one or more memory words, where each word is 16 bits long.
These memory banks are described as “Reserved”, “EPC”,
“TID” and “User”. The “Reserved” memory bank contains
kill and access passwords. The “EPC” memory bank contains
data used for identifying the object to which the tag is or will
be attached, the “TID” memory bank contains data that can
be used by the reader to identify the tag’s capability, and
“User” memory bank is intended to contain user-specific
data. As ePedigree uses RFID tag to identify tag by reading
it, problem of unauthorized reading can result in information
leak. So we provide a mechanism by which, the information
in the tag can only be read and modified by authenticated
participant. This is attained by encrypting information in user
bank of the tag.

Figure-2: Generation2 RFID tag.
As we plan to make ePedigree architecture distributed, we
use concept of distributed DNS as basis of our protocol. A
distributed DNS service using dHash (distributed hash table DHT) was proposed in [7]. dHash [8] is a Chord [10] based
distributed hash table. The basic idea of a distributed hash
table is to map the domain name of a node to its IP address
using a hash function. The IP addresses are stored and
retrieved using a distributed hash table protocol. The key
generated by hashing the domain name of a node is used as
an index to place the node’s IP address in Chord. In our
approach, we combine the information from RFID tag [5]
and distributed ONS using the idea of distributed DNS to
perform the discovery services. Apart from Chord, there are
many DHT protocols such as Pastry [9] and Tapestry [11]
which can be used to implement distributed hash table. In
this paper, we use Chord to explain our idea.

3. SYSTEM COMPONENTS

3.3 RFID tag encryption and decryption

There are four major components in our distributed
Electronic Product Code – Information Service (EPC-IS)
infrastructure, Object Name Service (ONS) based on
Distributed Hash Table (DHT), EPC-IS databases, RFID
encryption and decryption and certificate authorities. They
are described in details below.

ePedigree uses tag for identification and storing information
about the product. This information is confidential and
should only be accessed by authorized user. So we provide
encryption and decryption mechanism for tag to prevent
unauthorized reading of information. Unauthorized reading
can raise various concerns like an unauthorized user can
claim the goods by read information in the tag and updating
its EPC-IS.
In our mechanism, when the drugs are ready to be
shipped from one participant to another participant
downstream, the information in the user bank of the tag is
encrypted. This encrypting is performed on entire lot with
same key. The purpose of encrypting entire lot is to prevent
the overhead of computation of encrypting every item
independently. When tag information is to be read,
decryption of tag is done using decryption key. The
encryption and decryption is performed at each level by
every participant in the supply chain. Every participant
generates encryption and decryption for specific lot and
stores that key pair in its EPC-IS along with the certificate
associated with that lot. The encryption and decryption
mechanism is explained in detail later.

3.1 Object Name Services Using DHT
In current ONS service, a customer submits a query to
EPCGlobal network [2], which is processed by a centralized
ONS maintained in the EPCGlobal architecture. The ONS
performs lookup service to find the address of the responsible
EPC-IS server that contains the requested information [3].
Several difficulties exist in using this approach: (a) it is
vulnerable to single point failure and is not scalable to handle
massive requests; (b) it involves heavy load of administrative
overhead such as registration, records verification, updating,
and processing; and (c) the participants who create ePedigree
have little control on the ePedigree discovery service. Since
the EPC to EPC-IS mapping is maintained by a third party,
the centralized framework has potential privacy exposure
problems.
We create a distributed ONS structure by combining
ONS and DHT. We first construct a distributed ONS
structure using any of the DHT protocol. In this paper, we
choose Chord [10] to explain the working of our protocol.
The ID of the EPC-IS server is hashed to get a key. The
location of an EPC-IS server in Chord is determined by using
this key. Each of the EPC-IS servers maintains a hash table
and store a list of mappings between a key and corresponding
EPC-IS servers IP address in it. To find the IP address of an
EPC-IS server requested by an EPC query, the EPC number
is hashed to generate a key. This key is used for searching the
DHT to locate the corresponding EPC-IS server’s IP address.
The creation and searching of the DHT is explained in detail
in section 5.

3.2 EPC-IS Databases
The EPC-IS is maintained by each participant in EPCGlobal
network [1, 2] and it contains information mapping between
a National Drug Code (NDC) and corresponding electronic
product code (EPC). In addition, the EPC-IS server stores
each ePedigree processing history and corresponding
signatures. The local database (EPC-IS) provides information
for a submitted query and if it fails, distributed ONS is used
to lookup the address of appropriate EPC-IS server,
containing the requested information. Thus, in our approach
there is no centralized server to which the queries are
submitted. Instead, the distributed EPC-IS server is used to
redirect the EPC query to an appropriate EPC-IS server,
making the system more robust and scalable.

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

3.4 Certificate Authorities
A certificate authority (CA) provides authentication
services. All participants need to obtain a certificate from
CA, to become a part of ePedigree. When a participant
approaches CA to obtain a certificate, its identity is verified
and after complete verification, the certificate is issued.
These certificates play important role in ePedigree.
Communicating participants use them for mutual
authentication. Apart from that, by using certificates at each
level (as discussed in section 5.2) the certificate chain is
build, which helps in traversing the chain and discovering
level in ePedigree, where a possible drug counterfeit
occurred.

4

A DISTRIBUTED EPEDIGREE ARCHITECTURE

Our distributed ePedigree architecture is divided into various
components: ePedigree work flow, creating distributed ONS
using DHT, ePedigree discovery, and verification service.
The following sections describe them in detail.

4.1 ePedigree Work Flow
Creation of ePedigree is a step by step procedure. ePedigree
is initiated by manufacturer and contain all participants in the
chain of custody of a drug. Once the drugs are produced, a
unique RFID tag is attached by manufacturer to every
product. Manufacturer also adds some unique identification
about himself in user bank of the tag. Then the user bank of

the tags on the drugs is encrypted. After encryption they are
delivered to next level supplier which can be seen in figure 3.

Figure -4: ePedigree Format.
Figure-3: ePedigree Work Flow
This encryption is done at lot level. Manufacturer initiates
an ePedigree and signs a certificate for the specific drugs lot.
This certificate contains information related to the drug and
the transaction information about the sender and the receiver,
which can be seen in ePedigree format [11] (Figure 4). The
information related to sender and receiver is their name along
with their IP address. Before they are delivered Manufacturer
updates its EPC-IS with information (lot number, respective
EOC number, certificate and the key pair). Manufacturer also
sends list of EPC numbers to DS through a secure channel.
DS uses this information to authenticate the drug. When
these drugs arrive at specified receiver, they have to be
decrypted and authenticated. A request is made from DS to
the manufacturer for the decryption key with which the tags
can be decrypted. Manufacturer verifies the identity of DS
and after verification; lookup the decryption key in his EPCIS and provides it to DS. Once DS receives it, user bank of
the tag is decrypted and tags are verified by checking details
in the user bank. If any mismatch occurs then US (i.e.
manufacturer in 1st case) is contacted and after verification
drugs are accepted. Thus a link is built from manufacturer to
first supplier.
The certificate received from sender is stored in the
receiver EPC-IS and a new certificate is created instead of
forming a layer on previous certificate. Format of certificate
can be seen in Figure-4. Reason for creating a new certificate
is to hide the details of previous level supplier from the 2 hop
downstream supplier. For example if a distributor receives a
certificate, it will create a new certificate in order to hide the
details of his supplier i.e. wholesaler from his next
downstream receiver i.e. pharmacy. This procedure keeps on
repeating until the drugs reach the pharmacy, from where
they are sold to consumer. Thus a complete ePedigree is
built, along with a certificate chain from manufacturer to last

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

supplier. This certificate chain is used for traversing the
supply chain by performing discovery and verification
services.

4.2 Creating Distributed ONS using DHT
We create distributed ONS in our approach to replace the
existing centralized ONS. In centralized ONS, all the
information about a specific EPC-IS was stored in one
centralized entity. Every query is submitted to this entity,
which provided the address of appropriate EPC-IS to the
query generator. But using a centralized ONS have various
disadvantages, so we propose a distributed ONS as its
replacement.
In distributed ONS, the EPC-IS servers of all the
participants take part in the address location service. The
EPC-IS servers arrange themselves in a distributed manner
using any of the DHT protocols. We explain our idea using
Chord [10] protocol. Every EPC-IS server hashes its ID to
get a key. The key is used to arrange them in the chord
structure. Each of the EPC-IS servers stores the IP addresses
of its successors apart from their own IP address in a hash
table (i.e.) The hash table consists of a key and the IP address
mapped to the corresponding key. Every EPC-IS server is a
node in the chord and each of them contains a hash table thus
forming a distributed hash table structure. In this way, the
participants take part in the address discovery service and
centralized server is removed. Once the structure is built,
distributed ONS can be used to find an IP address of the
EPC-IS server in the network. Before the downstream
participant accepts the drug from the manufacturer, they do
mutual authentication. For this mutual authentication, both of
them should know each other’s IP addresses. If they already
know the peer’s IP address, they go ahead with the
authentication. Otherwise they need to send a request to the
distributed ONS service to find the IP address of a
responsible EPC-IS server. Also distributed ONS is

contacted by a participant to find the IP address of the
previous or the next level participant if the IP address is not
know. This is done to verify the ePedigree and move back
and forth in the chain as explained in 5.3. In both cases
distributed ONS is used to discover the IP address of an
EPC-IS server in the network. Construction of the
Distributed ONS is explained in detail in section 5.

4.3 ePedigree Discovery and Verification Service
Discovery and verification service is an integral part of
ePedigree. These services are required for locating EPC-IS
servers and verifying whether the request, that has been made
is by authenticated user or not. If the request is genuine, the
address of appropriate EPC-IS server is found and provided
to the requested user. Traditionally, these services were
provided by ONS [4] which worked in centralized manner,
thus was not very efficient. Our discovery service works in a
distributed manner and enables to find appropriate EPC-IS
server for the requested information. It also provides
verification services by authenticating the participant making
the request by checking their certificate. Another benefit is
that, it helps in traversing the ePedigree back and forth for
detecting the presence of counterfeit drug and the level at
which it got counterfeited. This prevents further introduction
of counterfeit drug and removal of sham participants from
the supply chain.

5

2log2 N, where N is the number of severs) successors
clockwise in chord. The EPC-IS server with the immediate
highest ID is said to be the immediate successor of a server.
Now the question is how the server knows the IP
addresses of its successor? When a server (say ID1) joins the
chord, it sends request to an existing server (say ID5) to find
the ID and IP address of its successor. The ID5 finds ID1’s
successors by searching the DHT [6] which is explained in
5.2. Once the successor ID2 is identified, ID1 requests ID2
for its successor and so on until it identifies r successor’s IP
address. Before the IP address is stored in a server, it is
verified and signed by the certificate authority [6]. This is
done to certify that this IP address belongs to the
corresponding EPC-IS server. When a new EPC-IS server
joins the network and say it’s mapped to ID2, the successors
of ID1 become the successors of ID2. Moreover IP addresses
are stored in redundant nodes (servers) so that even if one
node holding the IP address fails, then the other nodes which
store the replicas can be approached. The redundant nodes
are chosen using pseudorandom function. The number of
replicas varies according to the DHT protocol.

DISTRIBUTED EPEDIGREE PROTOCOLS

Our distributed ePedigree protocol consists of three phases:
phase I includes creation protocol for distributed ONS; phase
II deals with creation protocol for ePedigree; and phase III
includes discovery and verification procedures.

5.1 PHASE I: Distributed ONS creation protocol
Before creating and verifying the ePedigree, the distributed
ONS has to be constructed involving the EPC-IS servers of
all the participants. The distributed ONS creation protocol is
somewhat similar to “Serving DNS using a Peer-to-Peer
Lookup Service” [7] but our protocol can be adapted to any
DHT protocol like chord, Pastry, Tapestry, etc. Whenever an
EPC-IS server joins the network, its unique ID (e.g., name,
IP address, etc) is hashed to generate a key. Let’s call this
key as Mkey. Based on this Mkey value, the servers are
arranged in the DHT. This can be done by using any DHT
protocols. For example let’s consider the chord [10] protocol.
Chord has a unique m-bit ID based on the number of
participant in Chord, i.e., if there are K participants then the
ID’S range from 0 to 2k -1.The structure of chord is shown
in Figure-5. Here ID1, ID2, etc denotes the keys of the
chord. Mkey is mapped to one of the ID’s in the chord. For
example, if Mkey is between ID1 and ID2, it will be mapped
to ID2. Every server knows its own IP address and apart
from that each server stores the ID and IP addresses of r (r =

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

Figure-5: Constructing and Searching the DHT.
Searching the DHT is explained with chord as the DHT
protocol. To find the IP address of a EPC-IS server we need
to hash the ID of the server to generate a key (say) Mkey and
map Mkey with one of the ID’s in the chord as shown in
Figure-5. Note that the ID of the EPC-IS server is encrypted.
The requester of the IP address should first do the necessary
authentication and get the decryption key as explained in
section 3.3. Once the decryption key is obtained, the user
bank can be decrypted to yield the EPC-IS server’s ID. The
Mkey is given as a query to one of the existing servers in the
chord say ID2. ID2 compares its ID with the Mkey. If the key
falls between this node and its successor, then the successor
is the intended node (7). If not, the node forwards the key to
its successor whose ID is closest to this key. Each node
maintains a hash table containing its successors’ IDs and IP
addresses. The same process continues until the ID closest to
the key is found. Once the node is found, the IP address can
be retrieved from the node. For example, if one of the
participants in the ePedigree submits a query to ID2 asking to

find the ID7, node ID2 compares its ID2 with ID7. From this
comparison it knows that it is not the intended node. Now it
looks into its hash table, and sees which of its successor is
closest to ID7. In Figure-5, there are seven nodes in chord
and each of the node stores r= (8Log2 N) successors’ IDs and
IP addresses. The hash table of ID2 storing the IP addresses
and keys of its successors is shown in Figure-5. The
successors of ID2 are indicated in dotted squares. D2 knows
that ID6 is closer to ID7 so it forwards the request to ID6.
ID6 will have ID7 in its hash table and so it forwards the
request to ID7. ID7 knows that it is the intended node by
looking at the request and it retrieves the IP address and
returns it. Before the IP address is retrieved, the signature of
the certificate Authority on the IP address is verified. Thus
the IP address of any EPC-IS is retrieved from the DHT.

5.2 PHASE II: ePedigree Creating Protocol
This phase consist of creating ePedigree. As described in
section 4.1, after the drugs have been produced and tagged
by manufacturer at item level, they are placed in big cartons
which have RFID tag of their own. These cartons combine
together and form pallets, which in turn have their own RFID
tag. These pallets form a lot and all the tags in this lot are
encrypted using same encryption key. All information about
the drug (i.e. all EPC numbers, certificates and the key pair)
are stored in EPC-IS server of the manufacturer. The
manufacture also adds some information in RFID user bank,
which helps in his identification. All information added by
manufacturer in user bank is encrypted by using encryption
key. Manufacture initiates an ePedigree and signs a
certificate which contains information about the drug, shipper
co. name, the receiver co. name and their IP addresses.
Before manufacturer ships out this drug to next level
supplier, a mutual verification of each other is performed.
The certificates which they obtained from Certificate
authority are verified. After mutual authentication is
complete, drugs are shipped to specified receiver. A list of all
RFID tags along with their lot numbers is sends from
manufacturer to next level receiver before drugs reach
downstream supplier. This information is send through a
secure channel. It is done to aid next level receivers to
authenticate the drugs at the time of reception, by reading
their EPC number and checking their validity by mapping it
with the information previously received through secure
channel from the manufacturer.
When drugs are received by next level supplier, a
request is made to manufacturer for decryption key. After
obtaining this key, user bank is decrypted to get identification
of manufacturer. This information helps in authenticating
sender of the drug (in this case, manufacturer). In case of
mismatch, upstream organization (i.e. manufacturer) is
contacted. Each participant before distributing the drug
further down the chain performs same operations. It adds his
identifiable information in tag user bank and encrypts it. A

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

new certificate is signed, which contains information of
sender and next level receiver only. The same procedure is
repeated at every level.

5.3 PHASE III: ePedigree Discovery and
Verification Protocol
The main goal of ePedigree is to prevent introduction of
counterfeit drugs into the supply chain and also to trace back
to the level at which they got counterfeited. Discovery
services are used to locate the appropriate EPC-IS server,
which contains information related to specific EPC number.
By using discovery service, we can also traverse the
ePedigree chain in both directions, forward (i.e. from
manufacturer to last distributor in “chain of custody”) and
reverse (i.e. from last distributor to manufacturer) to
determine the location of a drug, in the supply chain. With
the help of certificate chain build during the creation phase,
discovery and verification protocol can trace down to the
level at which counterfeit occurred. Traversing can be done
in two ways, forward and reverse which are described below:

Forward Tracing: Suppose a consumer purchases a drug
and after some time realizes that drug is counterfeited. But he
doesn’t remember the pharmacy from where the drug was
purchased. With the use of discovery and verification
protocol, we can trace to the level at which this drug
counterfeit occurred. Figure-6 describes step by step working
of discovery and verification protocol.
Step 1: Consumer reports to a drug controlling agency that
the drug he has is counterfeit. The drug controlling agency
reads the RFID tag and obtains the manufacture ID, as it was
not encrypted. Then it will hash the manufacture ID to get the
Mkey. All we need to do is to map this Mkey with one of the
ID in the chord. The IP address of the server can be obtained
by searching the DHT which is explained in 3.2. In this case
the agency queries one of the existing servers in Chord to
find the IP address of the EPC-IS server by giving the
generated Mkey. Generally the result of DHT searching is the
IP address of the EPC-IS server of the participant. Note that
the IP address is signed by a Certificate Authority before it is
stored in a node. So before the IP address is retrieved the
signature on the IP address is verified. Then manufacture is
located by using this IP address and his signature can be
verified.
Step 2: upon manufacturer authentication, the query is
submitted to the manufacturer.
Step 3: After receiving the query from agency, manufacturer
reads the tag and get the unique serial number (EPC number),
since it cannot read the information in user bank as it is
encrypted.
Step 4: Manufacturer performs lookup in his EPC-IS server
to get the information (lot number) associated with that tag.
After lot number is found, corresponding certificate is

obtained. This certificate contains the information about the
next level receiver of the drugs. From this certificate next
level receiver information is retrieved.

Figure-6: Forward tracing.
Step 5: The query is forwarded to next level receiver in
downstream, whose address was obtained from the
certificate. The next level supplier also performs the same
operations. The EPC number is read from the tag and lookup
service is used to get the associated information available in
the downstream EPC-IS server. If searching the EPC number
in downstream EPC-IS does not result in any corresponding
entry, then we conclude that drug got counterfeited between
these two participants. As the drugs were present in supply
chain and EPC number information was available with
upstream supplier but was missing in downstream supplier,
we can deduce that downstream supplier was involved in
counterfeit. The main reason of us concluding this is because
when downstream supplier received the counterfeit drug,
their information would not have been present in the
certificate send by upstream supplier. So authentication
should have failed but still drugs were accepted and
forwarded downstream. This makes it obvious that particular
downstream supplier is involved in counterfeit. If specific
entry, to particular EPC number is not found, we conclude
that drug got counterfeited at next level supplier. But if the
corresponding entry exists in EPC-IS server of downstream
supplier, then related information is retrieved from
downstream supplier EPC-IS server and the query is further
forwarded to next level downstream supplier, which performs
the same operation. The certificate chain is traversed till the
point, where the information mismatch occurs. Once the
forged participants are found they can be questioned and put
under surveillance, to find out who performed the
counterfeit.
There exists a possibility, when two communicating
participants are involved in counterfeit. They both can
modify their own EPC-IS to store the false EPC number, but
even then our protocol will be able to trace them. As the two

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

participants do not have an agreement with the upstream
authority, so the entries in upstream EPC-IS won’t match.
The probability that all participants in ePedigree chain are
forged is very low.

Figure-7: Reverse tracing.

Reverse Tracing: Reverse tracing is done in the scenarios
when the consumer bought drugs from a particular pharmacy
and discovers the drug is counterfeit. Consumer goes back to
the pharmacy and reports the counterfeit. We use our
discovery and verification protocol to determine the level at
which counterfeit occurred explains it with Figure-7.
Step 1: The participant (pharmacy) read RFID tag with
reader and obtains the unique serial number (EPC number).
Step 2: Participant performs lookup service in EPC-IS to
retrieves the decryption key to verify the information (his
own information) which it stored in user bank before the
drugs were sold. After verification is complete, lot number is
retrieved, which was maintained and updated in EPC-IS of
participant at the time of reception of drugs from upstream
supplier.
Step 3: if the particular EPC number is found in EPC-IS, the
certificate associated with it is obtained. This certificate
contains the information (Shipper number, Co. number, IP
address, Lot # and the quantity) about the upstream supplier.
Step 4: Query is generated by the participant, which contains
the RFID tag and the certificate.
Step 5: This query is reverted back to upstream supplier
which on receiving the query, performs same operation. If
upstream supplier is unable to find the EPC number in its
EPC-IS, then we can conclude that the downstream
participant is forged and is involved in counterfeit of the
drug. If the EPC number is found, the associated certificate is
retrieved from EPC-IS and the query is forwarded to next
upper level supplier. At any level if the information
mismatch occurs, we can conclude the point at which
counterfeit took place.

6

CONCLUSION

In this paper, we propose a distributed EPC Information
Service (EPC-IS) to make the ePedigree creation and
discovery more robust, scaleable, and secure. Using our
approach, the ePedigree historical records of a product is
created and stored in the ePedigree creating parties’ EPC-IS
servers; in addition, each EPC-IS server maintains a look up
table that stores the EPC-IS providers’ one-hop up/down
stream information. Our approach brings three-fold benefits
for existing healthcare industry: (a) it relieves the single point
failure due to the centralized EPCglobal network
infrastructure, (b) it reduce the processing and storage
overhead due to distributed processing and storage
architecture, (c) it ensure the security and privacy via a chain
of ePedigree operations where only authorized parities can
conduct the ePedigree creation and searching functions.
It is a vital research area of ePedigree in healthcare
industry. Many research problems and implementation issues
are still unsolved and require more efforts from both
academia researchers and industrial practitioners. Our
research points out one of viable directions. We plan to
involve more efforts from industrial side and set up testing
bed to evaluate our solutions.

REFERENCES
[1] T. Applebaum, “ePedigree: Be Aware, Be prepared” in
Proceedings of Maxiom Group, pages, 11-33, OCT 5, 2006.
[2] EPCGlobal, “The EPCGlobal network demonstration”,
EPCGlobal draft, 2004.
[3] EPCGlobal, “The EPCGlobal Architecture Framework”,
EPCGlobal draft, Final version, July 1, 2005.
[4] EPCGlobal, “Object Name Service”, EPCGlobal draft, version
1, October 4, 2005.
[5] EPCGlobal, “EPCGlobal Tag Data Standards, version 1.3”,
EPCGlobal draft, March 8, 2006.
[6] EPCGlobal "Drug Pedigree messaging interface JWG
Requirement document, version 1”, EPCGlobal draft,
November 7th , 2005.
[7] R. Cox, A. Muthitacharoen, and R. T. Morris, “Serving DNS
using a Peer-to-Peer Lookup Service”, in proceedings of the
First International Workshop on Peer-to-Peer Systems (IPTPS
'02), March, 2002, Cambridge, MA.
[8] F. Dabek, M. F. Kaashoek, D. Karger, R. Morris, and I. Stoica,
“Wide-area cooperative storage with CFS”, in Proceedings of
the 18th ACM Symposium on Operating Systems Principles
(SOSP '01), Chateau Lake Louise, Ban.Canada, October 2001.
[9] A. Rowstron and P. Druschel, “Pastry: Scalable, decentralized
object location and routing for large-scale peer-to-peer
systems”, in proceedings of IFIP/ACM International Conference
on Distributed Systems Platforms (Middleware), Heidelberg,
Germany, pages 329-350, Nov 2001.
[10] I. Stoica, R. Morris, D. Liben-Nowell, D. R. Karger, M. F.
Kaashoek, F. Dabek, and H. Balakrishnan, “Chord: A Scalable
Peer-to-peer Lookup Protocol for Internet Applications”, in
IEEE/ACM Transactions on Networking (TON), Vol 11, Issue
1, Pages 17 - 32, 2003

Proceedings of the 11th IEEE International Workshop
on Future Trends of Distributed Computing Systems (FTDCS'07)
0-7695-2810-4/07 $20.00 © 2007

[11] B. Zhao and L. Huang and J. Stribling and S. Rhea and A.
Joseph and J. Kubiatowicz “Tapestry: A Resilient Global-scale
Overlay for Service Deployment”, in IEEE Journal on Selected
Areas in Communications, 2003.

International Workshop on the Network of the Future

Constructing a Virtual Networking Environment in
a Geo-Distributed Programmable Layer-2
Networking Environment (G-PLaNE)
Tianyi Xing1 , Xuan Liu2 , Chun-Jen Chung1 , Akira Wada3 , Shingo Ata3 , Dijiang Huang1 , Deep Medhi2
State University, USA, 2 University of Missouri–Kansas City, USA, 3 Osaka City University, Japan

1 Arizona

Abstract—With Cloud Computing technology occupying the
majority of future Internet research and development work,
research on deploying and extending existing capabilities onto
a newly emerging infrastructure becomes more signiﬁcant. For
example, extending the virtual network provisioning capability
onto a Geo-distributed programmable layer-2 networking environment (G-PLaNE) is a novel attempt and is different from
in a single domain system. In this paper, we aim to illustrate
how to construct the virtual networking environment upon our
self-designed resource provisioning system consisting of multiple
clusters through G-PLaNE. Experimenters and researchers are
able to develop and explore their own mechanisms in our
platform. Furthermore, a concrete example named Secure and
Resilient Virtual Trust Routing (SeRViTR) is given to illustrate
how this can be constructed over G-PLaNE.

I. I NTRODUCTION
The future cyber system is envisioned to be composed
of both Cyber Physical Systems (CPS) in ﬁelds to perform
communication, networking, and processing functions based
on data collected from various probes, and Cyber Virtual
Systems (CVS) to mimic the real world functions, perform
data mining, learning, analysis, and then provide locationbased, personalized and timely assistance. Usually, we use
the terms cluster and domain to represent the CPS and CVS
respectively. Domain can be regarded as a set of resources
virtually formed as a whole. It can reside within single clusters
or across multiple clusters geographically distributed. For
example, a domain may refer to a virtual network including 3
VMs located at three different locations. Although tremendous
efforts have been devoted on the physical side (i.e., CPS), the
current networking environment is prone to gradually shift its
functionality from the CPS side to the CVS side due to the
high ﬂexibility of virtual environments.
Virtual networking has become a representative component/infrastructure of CVS since single virtual machines cannot meet the requirements of many experiment users. It is
a computer network that consists, at least in part, of virtual
network links. A virtual network link is a link that does not
consist of a physical (wired or wireless) connection between
two computing devices but is implemented using methods of
network virtualization. The two most common forms of virtual
networks are protocol-based virtual networks (such as VLANs,
VPNs, and VPLSs) and virtual networks that are based on virtual devices (such as the networks connecting virtual machines

978-1-4577-2053-6/12/$31.00 ©2012 IEEE

inside a hypervisor). In practice, both forms can be used in
conjunction to construct a virtualized environment that has
some beneﬁts over the physical network environment.
After the neonatal stage of Cloud Computing, especially
within the past few years, Cloud Computing has shifted
its focus from a centralized architecture to a geographically
distributed Cloud service architecture [16] to achieve better
Quality of Experience (QoE) and enable features like high
availability. For example, a service/resource request from a
mobile user arriving at the system has to be sent to the master
domain to be processed to dispatch to the sub-domain, which
has available resources that are close to the user’s geographic
location. This demands resources such as computing, storage,
and networking be managed in a coherent and systematic
fashion. From the application perspective, the available resources should be provided within the same virtual networking
environment to reduce the resource management overhead
at the application level. Therefore, a ﬂexible, programmable,
and scalable point-to-point virtual networking environment is
desired. To this end, our research goal is to provide a way
to construct a layer-2 virtual network across multiple virtual
domains or physical clusters. The presented research is to
address the challenges brought by combining issues of virtual
networks and geo-distributed architectures as listed below:

5879

•

•

High Availability. High availability refers to the constant
ability of the user community to access the system.
Resources in a Cloud system are mainly in the form
of virtual machines (VMs) that are running and are
highly dependent on the physical metal. Resources will
probably become unavailable if there are some failures
on the hardware level or interferences from neighbor
VMs. Thus, it is better to put eggs in separate baskets. A
geo-distributed architecture improves the availability to
some extent. Data and ﬁles can be replicated at different
clusters to prevent trouble caused by a single point failure.
Intra- & Inter-Domain Communication. Experimenters
or users might expect certain types of resources, including virtual resources, connecting with each other
across domains. It is relatively easy to construct such
a virtual resource set in a single cluster since servers
in the same clusters are usually physically connected in
layer 2. However, trafﬁc between two VMs in the same

•

server also need to be sent to the connected physical
switch that makes packets exposed, and thus, brings
up inefﬁciency and raises security issues. Furthermore,
data and services need to be transferred from one to
another sometimes, which is highly dependent on interdomain communication. How to establish a type of highly
connected resources and securely transfer the service or
data to the destination server without noticeable delay
is also another challenge for the existing geographically
distributed system.
Network Programmability. Current experimenters and
researchers are not only looking forward to claiming plain
resources to run their services or applications but also
a virtual network with deeply programmable capabilities. However, providing programmable capabilities for
a virtual network across different domains introduces
more difﬁculty and highly depends on the virtualization level that the service provider provides. To better
take advantage of virtual network resources, various
networking programmable components, e.g., OpenFlow
[10] programmable switch, are expected from the service
providers.

The challenges listed above demand a comprehensive approach to construct a programmable virtual networking environment in a geo-distributed fashion. In this paper, we
aim to utilize both hardware and software layer-2 virtual
networking techniques to construct a virtual networking environment that is called Geo-distributed Programmable Layer-2
Networking Environment (G-PLaNE). G-PLaNE is based on
multiple physical/virtual domains among three Universities’
campus research platforms. The G-PLaNE provides a layer-2
programmable virtual network resource provisioning service
based on its geo-distributed infrastructure, which addresses
the challenges listed above. We also establish a demonstrative
virtual networking system SeRViTR [20] to illustrate how to
use G-PLaNE. The current research/development status and
future directions will be described.
The rest of the paper is organized as follows. Section
II brieﬂy introduces the overview of our Geo-distributed
Programmable Layer-2 Networking Environment called GPLaNE in short, and then illustrates how the virtual networking
environment is constructed upon the G-PLaNE system. A case
study built upon a G-PLaNE virtual networking environment
is given in section III to illustrate how this system can support
SeRViTR. Section IV discusses the related work, and ﬁnally,
the summary and future work is discussed in section V.
II. C ONSTRUCTING V IRTUAL N ETWORKING
E NVIRONMENT ON G-PL A NE
In this section, we present our novel Geo-distributed
Programmable Layer-2 Networking Environment (G-PLaNE)
upon which a virtual network construction approach is demonstrated. The overall description of the G-PLaNE system is ﬁrst
presented and then the detail of constructing virtual networks
in G-PLaNE is illustrated.






	'

	



	


(

	


	






	
	"


	
!

	"
#$


	"





	


	









	

	
)

*+	%	 )

!
,
	

	


	
	"

 
!

	%&	

Fig. 1.



	
	"




	



	


G-PLaNE Architecture Design

A. G-PLaNE Basics
G-PLaNE currently consists of three sites located at Arizona
State University (ASU), University of Missouri–Kansas City
(UMKC) in US and Osaka City University (OCU) in Japan.
It is designed to provide computing, storage, and networking
capabilities for both ﬁxed terminals and mobile devices that
usually have limited resources and capabilities. The system
component and architecture can be seen in Fig. 1.
1) System Components: We partition the G-PLaNE system
into a number of components as follows:
Computing Component. Computing capability is the major
provisioning service that the majority of resource provisioning
platforms provide. We use Xen [25] to maximally utilize
the resource pool (physical XenServers) by creating multiple
virtual machines. It has been shown that Xen has impressive
scalability, reliability, and security over other virtualization
technologies (i.e., VMware ESXi, Hyper-V, and KVM) [24].
With virtualization and programmability enabled, G-PLaNE
can provide logically separate resources for end users in
terms of a general routing suite, OpenFlow switch/router and
controllers. A resource pool always has at least one physical
node, known as the master. Other physical nodes join the
existing pool and are described as slaves. Only the master
node exposes an administration interface and will forward
commands to individual slaves as necessary.
Administrative Component. We also introduce dedicated
management and monitoring servers to administrate the VMs
and network resources in the resource pool and monitor
network trafﬁc within and across domains. NetFlow and
sFlow [21] are both enabled to inspect layer-2 and layer3 networking as well as host performance (i.e., CPU and
memory utilization). There is also a set of internal functional
servers serving different administrative purposes, i.e., Web
server, DHCP, DNS, Authentication Server, DB server, VPN,
etc.
Storage Component. Storage is another major concern for
a geographically distributed system since resources will be
prepared from a repository where the resource templates are
stored. We do not use the local storage in G-PLaNE but
chose the Network File System (NFS) to manage storage of

5880

resources. The NFS storage server connects the resource pool
via a dedicated storage switch, which greatly increase the
scalability.
2) Network Architecture: In the G-PLaNE system, the data
plane and the control plane are isolated. The management
network (Control Plane) is for management and control trafﬁc
(i.e., the trafﬁc of the service request, downloading applications from our repository and so on). On the other hand,
the data network is for data trafﬁc among different VMs, or
different terminals via VMs. From Fig. 1, there are 4 networks
in each cluster. The incoming and outgoing trafﬁc switches
isolate the trafﬁc going out of or coming into the G-PLaNE
domain. With this design, we can easily control the privilege of
resources accessing the Internet, which enhances the security
of the resource network environment.
The communications between VMs go through the data
network. The data network switch is a managed switch with
VLAN supported that enables different VMs being in different virtual domains. Additionally, the G-PLaNE management
network connects the internal NetFlow and sFlow monitoring
system to dynamically monitor the network performance by
an administrator. Not only VM-to-VM communication in one
physical cluster is considered, but also that of VMs located at
different clusters is considered. For this reason, the OpenFlow
switch [10] has been introduced to establish the inter-domain
data link. To increase efﬁciency and security, each G-PLaNE
server is installed with Open vSwitch [4] with which the trafﬁc
between two VMs in the same physical server does not need
to go through the physical data network switch so that it is
exposed in public. The detail of this dual switch design is
further explained in Section II-B.
3) Networking Programmability: Both the OpenFlow
switch (OF) and Open vSwitch (OVS) are OpenFlow-based
switches. In the OpenFlow architecture, a controller executes all control tasks of the switches and also those used
for deploying new networking frameworks, such as new
routing protocols or optimized cross layer packet-switching
algorithms. With these features, a programable network is
established to provide network programmability for Cloud
providers. It is feasible to develop a tenant-based policy or
protocol to control both internal OVS and external OFS in
a virtual networking environment. There are several OFS
controllers available following the OpenFlow standard, such
as Onix [19], SNAC [9], and NOX [14]. OFS as well as
the controller can be easily deployed on VM since they have
software based implementations. With the dynamic resource
provisioning mechanism supported, users are able to request
dedicate private virtual OpenFlow network upon G-PLaNE and
develop their own network topology and control mechanism.
A virtual network is created from several templates including
the software based OpenFlow switch and different controllers
pre-installed in VM. A user can easily turn the claimed general
virtual network into an OpenFlow-based programmable virtual
network by enabling some pre-installed functions. Besides this
OpenFlow based switch/control model, there are also all-inone routing suites; for example, Quagga Routing Suite [6]





#




#




















	



	



!"

)
 &

#$

Fig. 2.

	




	




)
 &

#$

Intra- & Inter-Domain Network Architecture

can be deployed into the virtual network upon which users
can develop their research and experiments.
B. Virtual Network Construction
To address challenges listed in Section I, we choose a geodistributed architecture to support resource provisioning over
multiple clusters. Resources that are mainly in the format
of VMs, connected as a network. The resource network
can be created by different conﬁgurations due to different
requirements: 1) a single physical server, 2) multiple servers
with one cluster (servers in the same cluster are connected
through a layer-2 physical switch), and 3) multiple servers
belong to different clusters.
1) Intra-Cluster Network Creation: Intra-Cluster means
there is always a native layer-2 connection among all resources
within the the same cluster. To create a virtual network
within the same cluster, VLAN technology is deployed. As
we previously mentioned, it is inefﬁcient to forward packets
through the managed switch from one VM to another one
in the same physical resource provisioning server. Therefore,
each XenServer has an internal Open vSwitch enabled to
handle trafﬁc inside the physical server as shown in Fig. 2.
Open vSwitch is designed to enable massive network automation through programmatic extensions, while still supporting
standard management interfaces and protocols (e.g. NetFlow,
sFlow, RSPAN, ERSPAN, CLI, LACP, 802.1ag, etc.). Open
vSwitch can operate as a software-based switch running within
the hypervisor (Xen Dom 0), in which many security control
functions can be implemented. With Open vSwitch enabled,
a packet sent from one VM to another one within the same
physical server does not need to be exposed out of the physical
box. When a virtual network is created within the same cluster
but across different physical servers, a packet sent from one
VM to another one on a different server should go through
the physically managed switch by enabling trunk ports. The
virtual network containing multiple VMs in different physical
servers is simply created by assigning the same VLAN ID so
that it is virtually isolated from other resources.
2) Inter-Cluster Network Creation: To enable provisioning
of virtual network across clusters in G-PLaNE, we establish a
layer-2 GRE tunnel among each site by deploying OpenFlow
switch running on top of NetFPGA box. After a layer-2 tunnel

5881

(
%()


$%&
' #*'()


•


')

"

12323236

1232323456

-
&



$-.- /,0-

+%	%
$%&
'# !"



Fig. 3.

7

MobiCloud Inter-Domain Connection

is established, VLAN can function well upon a layer-2 tunnel
since it is a 2.5 layer technology strictly speaking. Although
there are some options to establish the layer-2 tunnel, we
choose the OpenFlow solution since it is user-centric and can
be easily extended due to its programmability. OpenFlow is
an open standard that enables researchers to run experimental
protocols. In a classical router or switch, the fast packet
forwarding (data path) and the high level routing decisions
(control path) occur on the same device. An OpenFlow switch
separates these two functions. The data path portion still
resides on the switch, while high-level routing decisions are
moved to a separate controller, typically a standard server.
The OpenFlow switch and controller communicate via the
OpenFlow protocol, which deﬁnes messages, such as packetreceived, send-packet-out, modify-forwarding-table, get-stats,
etc. The data path of an OpenFlow switch presents a clean
ﬂow table abstraction; each ﬂow table entry contains a set of
packet ﬁelds to match, and an action (such as send-out-port,
modify-ﬁeld, or drop).
sFlow daemon is enabled to inspect the connection status
from the following three aspects as shown in Fig. 3: Internal
Connections, External Connections and Non-IP Connections.
The left-top part of Fig. 3 is internal connections that represent
the internal topology at the ASU site where the connections
between the Cloud server master node (10.0.0.3) and storage
server (10.0.0.253) can be seen. The top-right part is the layer2 Non-IP connections including unicast and broadcast. The
bottom part is the external connections that indicates the GRE
tunnel between two sites in the US and one site in Japan.
C. Enabling Additional Research Capabilities
With the virtual network provisioning service provided,
users are able to expand their own development and research
work. There are some representative ones listed below:
• Routing Algorithm & Protocol Design. Because we
provide resources at the IaaS level, users have more
ﬂexibility and privilege on their claimed resources. Each
virtual machine can be easily turned into a general virtual
router or OpenFlow switch by installing a software-based
routing suite. Thus, experimenters and researcher can
have a real network environment in any possible topology
they expect. With the capability of modifying the entire
routing protocol or algorithms module, research on routing protocols and other networking layer mechanisms can
be investigated, tested and measured in a real networking

•

environment.
Distributed Application Development. G-PLaNE users
can use any IP connected device to communicate with
their VMs supporting a variety of OS. So it enables developers to develop Cloud based applications on both the
Cloud side and the mobile device side. Moreover, after
the virtual network resources have been provided, more
complicated networking and distributed applications can
be developed and tested in a real distributed networking
environment.
Distributed Security and Privacy Model. There is some
research work [22] deploying a Cloud to help users keep
from viruses and enhance security. Cloud based anti-virus
engines have been emerging and are being studied. If
users are able to control a virtual network rather than a
single VM or multiple isolated VMs, then an advanced
model can be investigated. For example, different antivirus engines can be placed onto different VMs and
a centralized control VM running some algorithm to
coordinate them, is expected to enhance efﬁciency to
some extent. Generally speaking, any security and privacy
research issues can be investigated in a real distributed
environment that G-PLaNE provides.
III. C ASE S TUDY: S E RV I TR

The G-PLaNE system is designed to be able to support
research in a virtual networking environment. In this section,
we present a case study on how to utilize the G-PLaNE
system to generate and manage virtual domains between geodistributed platforms.
A. SeRViTR Architecture Overview
A trustworthiness model for future networks called the Virtual Trust Routing and Provisioning Domain (VTRouPD)[15]
has recently been proposed. Trustworthiness can be deﬁned in
many facets. From the viewpoint of a network, it means routing information must be conﬁdential, secured, and protected,
whereas from the service provider’s perspective, trustworthiness of service assures that the service is safe and exclusive
of anonymous users. Due to such variety of trustworthiness,
a network should be sliced into multiple virtual domains that
are isolated from each other. A VTRouPD is constructed by
a collection of networking resources including routers and
switches based on virtualization techniques; e.g., constructing
virtual managed domains through tunneling and VLAN technologies. Within one or multiple VTRouPDs, we can further
create ﬂow or application level virtual routing domains that
are denoted as μVTRouPDs[15]. In our recent work [20], the
intra- and inter-domain policy and trust management between
VTRouPDs within the SeRViTR architecture is discussed.
Fig.4 presents an overview of the SeRViTR architecture. The
ﬁgure presents two VTRouPDs that are geo-distributed clusters
at two places: Arizona State University and the University
of Missouri - Kansas City. Each VTRouPD is a overall
domain with the administrative control, and it may contain
multiple Virtual Domains. Here, we will only give a very

5882

,")-

%/.(-,%(-









)&%%.


,")-
0
,%-1%

,%-1%

,$*

,$*

,$*#

,$*#







,$*3

,$*3




,$*4

,$*4

)
 	

,")-%%.


,")-%%.


8	%	

		

Fig. 4.

2

 &&
&(


	

 &&
&
	


	

SeRViTR Architecture Overview

high level description on SeRViTR components along with
their relations; their functions in detail can be found in [20].
Packet ﬂows to Virtual Domain s in the SeRViTR architecture are differentiated based on trustworthiness policies, and
the Policy Manager plays a key role on setting up policies
along with establishing Virtual Domain s. First, it sends policy
rules to the VTRouPD Manager to make a request of Virtual
Domain creation or deletion. Second, it communicates with
the Flow Controller about ﬂow updating. A VTRouPD Manager manages the information of physical routers within the
VTRouPD, and it is responsible for the creation or deletion
of Virtual Domain as well as resource management. The Flow
Controller is placed at the edge of VTRouPD s, and it is in
charge of forwarding ﬂows to correct Virtual Domains based
on the policy.
B. SeRViTR Deployment on G-PLaNE
The core idea behind SeRViTR is constructing the network
by setting up policies to assure secured routing between
virtual domains across multiple sites. To achieve such a
goal, SeRViTR has to be deployed in a virtual networking
environment that is well supported by the G-PLaNE system.
The G-PLaNE system allows the cluster to be scalable. Take
the SeRViTR clusters at ASU and UMKC for example, presented in Fig. 4; here, two VTRouPD s are created at different
clusters. We have established a layer-2 GRE tunnel between
the two VTRouPD s through OpenFlow switches. Within the
cluster at each site, the G-PLaNE resource pool contains
physical XenServers where VMs are created. Recall that all
VMs can be created and deployed as any form of functional
entities; thus, we can customize VMs as dedicated SeRViTR
functional components as well as virtual routers. Particularly,
VTRouPD Manager s, Flow Controller s, and Policy Manager s
are implemented on VMs created on one XenServer from the
resource pool.
The virtual routing domain is a vital constituent part in the
SeRViTR architecture design, and it requires good isolation as

well as scalability when constructing virtual networks. With
the G-PLaNE system data network switch, which is VLAN
supported, VMs can be grouped into different virtual domains
by tagging VLAN IDs, and the ones which have been used
can be queried through the database of the G-PLaNE system.
Fig. 2 shows a high level virtual domain creation by grouping
VMs into the distinct VLANs. Particularly, consider cluster
A at ASU in Fig. 4, where four XenServers are reserved
from the resource pool for creating virtual routers. On each
XenServer, we can customize an arbitrary number of VMs
as dedicated virtual routers by deploying a routing suit (i.e.
OpenFlow switch, Quagga, etc) on it. Now, consider the
SeRViTR virtual domains. The PolicyManager-VM sends a
request along with a trustworthiness policy to announce the
creation of a new virtual domain to the VTRouPDManagerVM. The VTRouPDManager-VM, in turn, communicates with
every XenServer that is reserved for creating VMs as virtual
routers and sends out an unused VLAN ID. When creating
VMs, the XenServer will add this unused VLAN ID through
its API. Therefore, VMs (Virtual Routers) created by distinct
XenServers can be put into the same VLAN according to the
unique VLAN ID. The data network switch will enable the
intra- or inter-virtual domain communications.
IV. R ELATED W ORK
The virtual networking environment has become one of
the main focuses for Future Internet research. A recent survey [13] provides a comprehensive summary about network
virtualization technologies from multi-aspects. Particularly, it
states that a network can be sliced at four different layers.
Afﬁliated to Planetlab[5], VINI[7] supports arbitrary virtual
topology creation by establishing EGRE tunnels[11]. VNET[8]
established layer-2 tunnels between VMs through virtual LAN
(VLAN).
[18] realizes network virtualization from a different angle,
which creates a mapping from network virtualization to process invoked within virtual machines. Via this analog study, the

5883

authors addressed the design space for network virtualization
that requires good isolation and Coexistence of networks.
A virtual networking environment with good isolation and
scalability is able to well support various research works.
Network virtualization in GpENI [3], [23] is discussed in [12].
GENI[2] is a famous open and large-scale virtual laboratory
for researchers to collaborate and explore the future networks.
[17], which applies a distributed snapshot mechanism to
provide fault tolerance, is deployed and demonstrated across
multiple sites on GENI infrastructure. With FlowVisor[1], the
OpenFlow[10] network is able to support virtual networking
environment.
Recently, network virtualization has been extended into the
Cloud Computing environment, particularly embedded in the
distributed networked clusters. In [26], the authors state that
creating virtual networks between Cloud provider sites is able
to provision an inter-Cloud connection over geo-distributed
clusters or multi-domain networks. In previous studies, very
few discussed resource provisioning over distributed clusters.
V. F UTURE W ORK AND S UMMARY
In this paper, we ﬁrst discussed the challenges as well
as the motivation of creating a virtual network in a geodistributed Cloud environment. We design a geo-distributed
Cloud resource provisioning system called G-PLaNE. The GPLaNE system is discussed in terms of system components,
network architectures, and etc. Virtual network creation, as a
major service provided by G-PLaNE, is explained from two
perspectives, intra-domain virtual network and an inter-domain
virtual network. A concrete example, SeRViTR, is given to
illustrate how virtual network construction can help in the
current research. This paper posts an efﬁcient and ﬂexible
way to construct a virtual network in a geo-distributed Cloud
environment to enable more research capabilities.
Although G-PLaNE can provide a virtual network across
different clusters, there is still additional work to be done:
Dynamic VLAN recycling and assignment. Using VLANs
is an efﬁcient approach to provide a secure and isolated
networking environment for VMs. Currently, we are using a
database to manage VLAN resources. However, some communication sessions could be short-term, which require an
efﬁcient dynamic VLAN allocation scheme at both the Open
vSwitch level and the OpenFlow switch level. This will allow
the network conﬁgurations to be changed in a dynamic fashion
preventing attackers from learning the system weakness and
reducing the chances to be attacked.
Dynamic VM Migration. Based on a mobile users’ geographic location, its VM can be migrated from its home cluster
to a guest cluster for better performance. The VM migrations
are operated using the inter-cluster networking system. In
this way, VMs’ migrations are protected during the migration
procedure, in which the VMs will not be exposed to the public
domain.
ACKNOWLEDGMENT
The presented work is supported by Ofﬁce of Naval Research (ONR) Young Investigator Program (YIP), HP IRP, US

NSF grants CNS-1029562 and CNS-1029546, and Japan NICT
International Collaborative Research Grant. The authors would
like to thank Dr. Jeonakeun Lee from HP lab for insightful
discussions on network virtualizations.
R EFERENCES
[1] “FlowVisor,” http://www.openﬂow.org/wk/index.php/FlowVisor.
[2] “GENI,” available at http://www.geni.net/.
[3] “GpENI – Great Plains Environment for Network Innovation.”
http://www.GpENI.net
[4] “Open vSwitch,” http://openvswitch.org/.
[5] “PlanetLab,” http://www.planet-lab.org/.
[6] “Quagga Routing Suit,” http://quagga.net/.
[7] “VINI: Virtual Network Infrastructure,” http://vini-veritas.net/.
[8] “Virtuoso: Resource management and prediction for distributed computing using virtual machines,” http://virtuoso.cs.northwestern.edu/.
[9] “The SNAC OpenFlow controller,” http://snacsource.org/, 2010.
[10] “Open Flow Switch Speciﬁcation,” Feburary 2011.
[11] S. Bhatia, M. Motiwala, W. Muhlbauer, Y. Mundada, V. Valancius,
A. Bavier, N. Feamster, L. Peterson, and J. Rexford, “Trellis: a
platform for building ﬂexible, fast virtual networks on commodity
hardware,” in Proceedings of the 2008 ACM CoNEXT Conference,
ser. CoNEXT ’08. New York, NY, USA: ACM, 2008, pp. 72:1–72:6.
http://doi.acm.org/10.1145/1544012.1544084
[12] R. Cherukuri, X. Liu, A. Bavier, J. Sterbenz, and D. Medhi, “Network
virtualization in GpENI: Framework, implementation and integration
experience,” in Proc. of 3rd IEEE/IFIP International Workshop on
Management of the Future Internet (ManFI’2011), Dublin, Ireland, May
2011, pp. 1212–1219.
[13] N. M. K. Chowdhury and R. Boutaba, “A survey of network virtualization,” Computer Networks, vol. 54, pp. 862–876, 2010.
[14] N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown, and
S. Shenkes, “Nox: Towards an operating system for networks,” in ACM
SIGCOMM Computer Communication Review, July 2008.
[15] D. Huang, S. Ata, and D. Medhi, “Establishing secure virtual trust
routing and provisioning domains for future internet,” in Proc. of IEEE
Globecom 2010 Conference (Next Generation Networking Symposium),
2010.
[16] D. Huang, “MobiCloud: A Secure Mobile Cloud Computing Platform,”
E-Letter of Multimedia Communications Technical Committee (MMTC),
IEEE Communications Society (invited paper), 2011.
[17] A. Kangarlou, D. Xu, C. K. Ulas, P. Padala, B. Lantz, and K. Igarashi,
“In-network live snapshot service for recovering virtual infrastructures,”
Network, IEEE, vol. 25 Issue:4, pp. 12 – 19, 2011.
[18] A. Khan, A. Zugenmaier, D. Jurca, and W. Kellerer, “Network virtualization: A hypervisor for the internet?” Communications Magazine,
IEEE, vol. 50 , Issue:1, pp. 136 – 143, 2012.
[19] T. Koponen, M. Casado, N. Gude, J. Stribling, P. L., M. Zhu, R. Ramanathan, Y. Iwata, H. Inouye, T. Hama, and S. Shenker, “Onix: A
distributed control platform for large-scale production networks,” 2010.
[20] X. Liu, A. Wada, T. Xing, P. Juluri, Y. Sato, S. Ata, D. Huang, and
D. Medhi, “SeRViTR: A framework for trust and policy management
for a secure Internet and its proof-of-concept implementation,” in Proc.
of 4th IEEE/IFIP International Workshop on Management of the Future
Internet (ManFI’2012), Maui, Hawaii, April 2012.
[21] Network Instruments, “Extending network visibility by leveraging NetFlow and sFlow technologies,” February 2011, White Paper.
[22] J. Oberheide, E. Cooke, and F. Jahanian, “CloudAV: N-Version Antivirus
in the Network Cloud,” in 17th USENIX Security Symposium, 2009.
[23] J. Sterbenz, D. Medhi, B. Ramamurthy, C. Scoglio, D. Hutchison,
B. Plattner, T. Anjali, A. Scott, C. Bufﬁngton, G. Monaco, D. Gruenbacher, R. McMullen, J. Rohrer, J. Sherrell, P. Angu, R. Cherukuri,
H. Qian, and N. Tare, “The Great Plains Environment for Network Innovation (GpENI): A programmable testbed for future Internet architecture
research,” in Proc. of 6th International Conference on Testbeds and Research Infrastructures for the Development of Networks & Communities
(TridentCom), Berlin, Germany, May 2010, pp. 428–441.
[24] Xen Community, “Why Xen?”
[25] xen.org, “Xen Hypervisor,” http://www.xen.org/.
[26] Y. Xin, I. Baldine, A. Mandal, C. Heermann, J. Chase, and
A. Yumerefendi, “Embedding virtual topologies in networked clouds,”
in CFI ’11 Proceedings of the 6th International Conference on Future
Internet Technologies, 2011.

5884

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Secon 2009 proceedings.

Towards lightweight secure communication
protocols for passive RFIDs
Dijiang Huang, Harsh Kapoor
{dijiang,hkapoor}@asu.edu
Computer Science and Engineering Department
Arizona State University

Abstract—RFID technology has been applied to many business
applications in the past few years. The popularity of RFID
technology lies in its ability for automatic identification and low
cost. Most existing RFID security protocols utilize cryptography
based solutions relying on hash functions and symmetric-key
based encryptions, which incur high computational overhead and
thus are unsuitable for passive RFID tags. In this paper, we
present a lightweight secure reader-tag communication protocol
providing secure key lookup, key transportation, reader-tag
mutual authentication, and data confidentiality without using
traditional cryptography based encryption and hash functions.
Our approach is based on light-weight exclusive-or (XOR) onetime pad and modulo addition on passive RFID tags and readers.
Our security and performance analysis shows that the proposed
solutions are suitable for low-power passive RFID tags.

I. I NTRODUCTION
Radio Frequency Identification (RFID) tags are tiny wireless
microchips that are used to identify their attached objects.
It has been expected that RFID tags will proliferate into
billions and eventually into trillions soon as the successor
of bar codes. This is especially true for passive RFID tags,
which are cheap (less than 5 cents per tag [1]), do not have
power sources, and relay on RFID interrogators (or readers) to
energize their circuits for data processing and transmissions.
With fast deployments of passive RFID based information
management systems in medicare, asset management, supply
chain, transported goods, and many other areas, passive RFID
tags also exhibit their vulnerabilities under a number of passive
and active attacks. Among all known attacks, the information
leakage of passive RFID tags to unauthorized users has been
identified as a major challenge to the RFID technologies [2],
[3].
Information leakage of using passive RFID tags is mainly
due to their low-cost, low energy, and low computational capabilities. This is because passive RFIDs usually are not capable
of performing complex cryptographic algorithms. It is reported
that EPC [4] tags cost several US cents apiece [5] in 2006.
In the quest for minimal cost, the passive RFID tags possess
only several thousands of gate equivalents (GEs). For example, EPC class-1 generation-2 tags, energize themselves by
absorbing electromagnetic waves emitted from interrogators,
and then perform communications with interrogators without

authenticating the interrogators. The best implementation of
existing robust cryptographic algorithms along consumes at
least several thousands gates for passive RFID tags [6], which
makes it difficult to achieve the “five cents” goal. Thus, more
efficient secure communication solutions are highly desired.
Existing solutions protecting reader-tag communications
against attempted attacks mainly focus on using symmetrickey based encryption/decryption algorithms and hash functions as the fundamental building blocks [3], [7]–[9]. These
protocols aim to address data privacy, mutual authentication,
anti-replay, and un-traceability. To evaluate the performance
of using cryptography-base solutions, in [10], the authors presented analysis on the number of gates required for performing
hash functions like MD4, MD5, SHA-1, and SHA-256, and
showed that these protocols require 7,350 to 10,868 gates; in
[6], the authors showed that implementing AES-128 algorithm
requires at least 3,400 gates. Therefore, the most important
evaluation criterion to design light-weight security protocols
is to reduce the number of gates implemented in passive
RFID tags satisfying security features such as data and origin
integrity, data confidentiality, anti-reply, and anti-tracing.
In [11], [12], the authors proposed using light-weight trapdoor one-way function (SQUASH) proposed by Shamir [13],
[14] for secure authentications, which prevent tracking attacks.
However, the proposed solution heavily rely on the operations
of pseudo-random number generators, which is more heavier
than bit-wise XOR operations. Furthermore, their protocol is
to perform mutual authentications between one reader and
one tag, which assumes that the reader already knows the
communicating tag in advance. Thus, it is highly desired that
an efficient reader-tag communication protocol should allow a
reader to read multiple tags without knowing communicating
tags’ information as a priori condition.
Our research objectives are in two-fold for designing secure
reader-tag communication protocols: (a) Performance goal:
provides computational efficient RFID reader-tag communications and does not maintain the communication state of previous communication sessions; (b) Security goal: achieves security features such as secure key lookup, mutual authentication,
anti-replay, anti-tracing, and data privacy. Our research strat-

978-1-4244-2908-0/09/$25.00 ©2009 IEEE

egy to achieve the performance goal is to utilize lightweight
operations on passive RFID tags. In this way, we can achieve
the desired security features by running the minimal level of
computations on RFID tags. To achieve our security goal, we
propose novel challenge-response protocols using exclusive-or
(XOR) based one-time pad (a.k.a., Vernam Cipher [15]) and
modulo addition to secure reader-tag communications. With
pre-computed secret keys stored on RFID tags, our protocols
only require modular additions and bitwise XOR operations.
Moreover, one-time pad is used for securing the data sent
from tags to readers, which provides perfect secrecy if each
pad is equally likely. Further more, we do not need each tag
to maintain its previous communication state and update its
preinstalled secret keys for each communication session.
In this paper, we propose a comprehensive solution including several important security features, mostly addressed
separately in previous solutions. Our research contributions
are in three-fold: (1) We take an untraditional strategy without
using cryptographic encryption/decryption and hash functions.
Using our secure reader-tag communication protocols, we
show that the number of gates required for a tag is about
1,850 for basic scheme and 2, 850 for extended scheme, which
reduce the number of required gates significantly compared
to traditional cryptography-based solutions. (2) Our protocols
provide a set of security features such as secure key lookup,
mutual authentication, data privacy, and un-traceability against
strong adversaries who are capable of launching active attacks
such as active information leakage attacks and replay attacks,
and passive attacks such as eavesdropping and tracing. (3) We
also ensure low communication cost in terms of number of
rounds and exchanged messages that are involved in readertag communications. Our performance assessments show that
the proposed protocols achieve both their performance goal
and security goal.
The rest of the paper is organized as follows. In next
Section, we discuss recent work of RFID secure protocols.
In Section III, we outline our protocol design requirements
and used models. In Section IV, we present a basic scheme
to secure one-to-one reader-tag communications, which is
followed by an extended scheme to secure one-to-many readertag communications. In Section V, we assess the security
performance and computation & communication performance
of our protocols. Finally, we conclude this paper and provide
the directions of future work in Section VI.
II. R ELATED W ORK
In [16], [17], the authors proposed using RFID Keeper to
jam the communication channel and block unauthorized RFID
readers. However, these approaches require the Keeper to
know the physical properties of RFID tags before performing
block operations. In [9], the authors propose a scheme, in
which each RFID tag stores a unique meta-ID. Upon receiving

query from a reader, a tag responds with its meta-ID. The
reader forwards this meta-ID to a secure server that gives
the reader the real tag ID. To prevent tracking of the tag
from adversaries’ eavesdropping communications between the
reader and the tag, the authors proposed a randomized hash
lock scheme. In this scheme, each time a tag is queried, it
replies to the reader a payload generated using a pseudorandom function, a random number, and some shared keys.
Secure server searches its database to identify the response
from the tag and replies to the reader the real tag ID. This
scheme avoids the problem of tracking attacks, however it
introduces another security problem: the attacker can retain the
payload to impersonate as a tag later. To avoid this problem,
the authors in [8] suggested a scheme where the reader and the
tag both contribute random numbers r1 and r2 to a randomized
hash lock scheme. In their scheme, the reader knows the tag’s
secret key and does not need to be connected to secure server.
Several protocols have been proposed based on updating tag
ID after each query [18]–[20]. In [18], the author proposed a
scheme for synchronized updates of the tag ID. In this scheme,
the reader is connected to the secure server. The protocol
is based on exchanging random numbers between the reader
and the tag and independently calculating the next ID at a
secure server and a tag. A pseudo-random function based on
ID and random numbers is used to generate messages sent
between the secure server and the tag through the reader.
As only authentic server and the tag can calculate next ID,
attacker cannot impersonate authentic readers or tags. The use
of random number in the protocol ensures no replay attacks.
Recent work in [21], proposes a time-stamp based scheme
(YA-TRAP). In this scheme, the reader sends its time-stamp
to the tag, which responds with either a random number or
an encrypted message based on the time-stamp sent by the
reader and its internal time-stamp. The reader forwards tag’s
response to a secure server to retrieve information about the
tag. The attacks against these protocols is examined in [22],
[23].
In [3], the authors proposed a scheme for off-line readertag authentication using an access list. The reader receives an
access list for the tags it’s authorized to read from a secure
server. The scheme authenticates both the tag and the reader
without a centralized database. The authentication is based
on a challenge-response scheme where the reader and the tag
exchange random numbers. Messages sent between the reader
and the tag are generated using a pseudo random function, and
thus only authenticated readers and tags can generate correct
messages. This scheme introduce secure search, where the
reader issues a query that only authentic tags can understand,
and only authentic readers can understand tags’ responses.
In [7], the authors introduced the problem of forward untraceability. They proposed a solution to prevent attackers who
know the RFID tags’ current secrets from tracking them in

the future. The low-cost RFID tags usually cannot protect
their memory, and hence an adversary is able to access their
secrets. In addition, transferring the ownership of RFID tags
should prevent previous owners from tracking them in the
future. The proposed solution uses two one-way key chains;
a forward key chain is used to update the key chain value
by using a trusted authority (TA); and a backward key chain
is used for server validation. Another approach to tackle the
forward un-traceability problem is presented in [24], where
the authors presented two authentication protocols O-FRAP
and O-FRAKE for secure authentication and forward untraceability. These protocols heavily rely on pseudo-random
generators for anonymous authentication and key exchange.
They provide forward un-traceability by updating the secrets in
RFID tags upon each successful reading operation. A variation
is proposed in [11], [12], which utilize SQUASH [13], [14]
for secure and anonymous key look-up.
III. P ROTOCOL D ESIGN R EQUIREMENTS AND M ODELS
In this section, we describe security requirements and
models for designing reader-tag communication protocols.
Then, we present performance requirements with respect to
computation and communication efficiency. In Table I, a list
of used symbols in this paper is presented.
TABLE I
L IST OF S YMBOLS .

Symbol
R
Tj
TA
β
ni
nj , nonce1j ,
nonce2j
N
||
−→
(Yj , Zj )
Dataj
h(Dataj )
g(., .)
L

Description
A reader
An RFID tag j
A trusted authority (a back-end server)
An adversary
Random number generated by reader i
Random numbers generated by tag j
The total number of tags to be read by the
reader
Concatenation operation
Transmission
Data stored on Tag
Two shared secret key stored on tag j
Secret data stored on tag Tj
Hash of secret data stored on tag Tj
Trapdoor one-way function can be opened by
TA
Data obtained by reader
{Tj , Yj , Zj |j = 1, . . . , N } An access list
obtained by reader from the TA

A. Security Requirements
RFID tags store information about products they are attached to. The stored information is considered to be a secret
and should not be exposed to unauthorized readers. Security
requirements of our protocols are presented as follows:
1) Prevent unauthorized reading of RFID tags.

2) Prevent tracking of RFID tags.
3) Prevent replay attacks.
The first security requirement is to prevent unauthorized
readers from accessing the secret data stored in RFID tags.
This can be achieved by using a three-party authentication
protocol that involves a trusted authority (TA, i.e., a backend key management server), an RFID tag, and an RFID
reader. A unique key is shared between each tag and the TA.
We require that the reader must get authenticated by the TA
before starting the reader-tag communications. Once the reader
passes the authentication, the TA transfers the shared keys to
the reader through a secure communication channel. From the
tag’s perspective, the authentication is performed by verifying
if the communication peer possess the shared keys.
The second security requirement is to prevent tracking of
RFID tags in different locations or communication sessions.
Tracking attacks are possible when an unauthorized reader can
distinguish between messages from different tags. Sending the
same encrypted message every time by RFID tags will lead to
the tracking attacks. Even though an adversary does not know
the content of transmitted messages, he/she can still identify
identical messages sent from the same RFID tag. Tracking can
be prevented by sending a different message each time when
a tag is interrogated. This can be done by using a different
key to encrypt the messages sent by the RFID tag for each
transmission.
The third security requirement is to prevent the replay
attacks. An adversary should not replay a previously captured
message to impersonate as a legitimate reader or tag. One
solution to prevent replay attacks is to use a challenge-response
scheme, in which both readers and tags challenge each other
to ensure that only a legitimate reader and tag can respond
correctly.
To satisfy the security requirement (1), the reader needs to
know the tag’s ID before starting reader-tag communications.
However, to satisfy the security requirement (2), the tag cannot
send its ID in clear-text. Moreover, the tag needs to respond
to the request sent by the reader with a different response
each time to prevent tracking attacks. In [13], [14], Shamir
proposed a simple one-way trapdoor function g(., .), which
is called SQUASH. Using SQUASH, a tag can generates a
message g(TID , r)||f (k, r) as a challenge [11], [12] to the
reader. The reader can use its trapdoor t to discover TID and
a random number r in constant time. Based on the unique tag
ID TID , the reader can lookup the shared key k and then runs
function f to validate the random number r. As demonstrated
in [11], [12], the function g(., .) and a pseudo-random-number
generator can be implemented with about 1,000 gates, which
is very efficient. In our proposed solutions, the function f
implements bit-wise XOR.

B. Performance Requirements
In addition to ensuring security in RFID reader-tag communications, computation and communication efficiency is
equally important due to low-power and low-cost nature of
passive RFID tags. We consider the following important performance requirements for designing secure reader-tag communication protocols:
•
•

•

Reduce computational cost on passive RFID tags.
Decrease non-volatile and volatile memory requirements
of passive RFID tags.
Reduce the number of rounds and the size of messages
in reader-tag communications.

The first and second performance requirements of designing
reader-tag communications are to reduce the computational
cost on passive RFID tags. Adding security features usually requires to implement cryptographic algorithms, such
as encryption/decryption and one-way hash functions. These
operations require intensive computational power on RFID
tags, which are unsuitable for passive RFID tags due to their
limited resources in terms of number of gates and available
memory. In [25], the authors presented an example of EPC
specification for low-cost RFID tags. It requires 200 to 2,000
gates, 128 to 512 bits of read-only memory, and 32-128 bits
of volatile read-write memory on an RFID tag dedicated
for security. The number of gates required for performing
common hash functions like MD4, SHA-1, and SHA-256
requires 7,350 to 10,868 additional gates [10]. Adding more
gates and memory to an RFID tag increases the cost of the
RFID tag [9], and also increases the power required for the
computation. In [26], the authors stated that the computational
limitation on passive RFID tags is due to the limited power
for digital portion of the integrated circuit on the RFID
tags. Power limitation on the RFID tag is due to several
reasons including reading range as the RFID tags are powered
by RFID readers’ signals. Hence, providing security using
minimum number of gates will reduce the power consumption
of digital circuits, which will subsequently increase the reading
range. The third performance requirement is also to reduce
the power consumption by involving the minimum number of
transmissions.
Most existing secure reader-tag communication protocols
require to implement a random number generator on RFID
tags. Traditional approaches usually utilize hash functions to
generate random numbers, which will consume a lot computation power and are not suitable for passive RFID tags. Recent
research work in [27] showed that random number generator
can be implemented using the unique physical characters of
each RFID tag, which consume little computation power of
passive RFID tags. Thus, in this paper, we do not consider
the performance issues due to the implementation of random
number generator on RFID tags.

To summarize, our research goal is to propose efficient
reader-tag communication solution, which provide strong security features with a low computational cost for passive RFID
tags. In this paper, we assume that the TA and RFID readers
can perform heavy computations, and hence we do not analyze
their computational cost.
IV. S ECURE R EADER - TAG C OMMUNICATION P ROTOCOLS
In this Section, we first present a secure one-to-one readertag communication protocol between a reader and a tag, in
which we assume the reader already knows the tag’s ID and
possessed secret keys. We call this solution as basic scheme.
Then, we develop an extended scheme to reduce the communication overhead when a reader communicates with multiple
RFID tags. The extended scheme allows an RFID reader to
distribute a secret authenticator just by sending one message.
Our solutions are efficient in that we only require passive RFID
tags to implement computational efficient operations such as
modulo addition and bitwise XOR. We assume that the reader
serves as broker to the TA and it has established a security
channel connecting to a secure database that stores the tags’
information.
A. Basic Scheme for Secure Reader-Tag Communications
Algorithm 1 Basic Scheme.
1: R → T : A1 = ni − Zj

T : ni = A1 + Zj

2: R ← T : challenge = Yj ⊕ nj

R : nj = challenge ⊕ Yj
R : nij = ni ⊕ nj
3: R → T : A2 = nij − Zj
T : nij = A2 + Zj
T : ni = nij ⊕ nj

4: if n
i == ni then
R ← T : (Data||h(Data)) ⊕ nij
R : R performs the following verifications:
(Data||h(Data)) ⊕ nij ⊕ nij ⇒ Data ||h(Data)
if h(Data ) == h(Data)
accept
else
discard
end if
5: else
R ← T : nrand
R : Data verification fails
end if
∗

In essence, if we consider ni and nij are secret shares, the transmitted

messages ni − Zj in step 1 and nij − Zj in step 3 are the form of using
secret sharing scheme [28] when the degree of polynomial y(x) is 1.

In Algorithm 1, we present the basic scheme, which uses the
following notations: all the operations in Algorithm 1 is performed over the Galois Field GF (p), where p is a sufficiently
large prime; Yj , Zj ∈ GF (p) are shared secrets between the
reader R and the tag T ; ni , nj , nrand ∈ GF (p) are randomly
selected; the Data and its integrity checking value h(Data) are

pre-installed in the tag. In this paper, without special notation,
all mathematical operations are performed over the Galois
Field GF (p). The basic scheme is designed for a reader to
communicate with just one tag. Later, we will extend it to a
scenario where a reader communicates with multiple tags.
The basic scheme involves four transmissions: two messages
are transmitted from the reader to the tag (steps 1 and 3),
and the other two messages are transmitted from the tag to
the reader (steps 2 and 4 (or 5)). Since ni , nj , and nij are
randomly selected for reader-tag communications in Algorithm 1, an attacker cannot capture and then replay messages
to impersonate legitimated tags or readers. Moreover, these
random values can prevent passive attackers from tracking the
tag by identifying the same message transmitted in different
reader-tag communication sessions. Since the reader and the
tag share the secrets Yj and Zj , they can recover the random
values ni , nj , and nij from the messages received in steps 1,
2, and 3, respectively. By verifying the logic equation in step
4, the tag can authenticate the reader since the authenticated
reader must know the secrets Yj and Zj to recover the random
value nj from the challenge and then generates the value
A2 . When receiving the message in step 4, the reader can
first XOR nij and then check the integrity of the attached
hash value h(Data) . Note that only if the tag can derive the
random value nij using its pre-installed secret Zj , will pass
the integrity checking. If the verification at the step 4 fails, the
tag will send a random value nrand to confuse the attacker.
Based on the above discussions, the basic scheme satisfies the security requirements presented in Section III-A.
Moreover, the basic scheme is efficient for both the reader
and the tag, in which only modulo addition and bitwise
XOR operations are performed. Furthermore, the basic scheme
requires only two shared keys to be installed and involves two
transmissions for the RFID tag to achieve all desired security
features. Thus it satisfies our performance requirements.
Discussion of Basic Scheme: In Algorithm 1, reader R can
communicate one tag at a time involving 4 transmissions. It
has the following assumptions:
1) R already knows the tag’s ID before send the request
A1 .
2) R can differentiate the message sent by the tag from
other messages.
3) T can differentiate the message sent by R, which targets
to the tag.
However, in reality, the above described situations can hardly
be satisfied. This is because a reader usually reads many tags
at a same time. To read N tags, the reader needs to run this
algorithm N times for each of the tag it is communicating
with. Given the untraceability requirement, the tag should not
expose its identity in clear-text and a transmitted message
containing the identity of the tag should appear different each
time.

Additionally, we notice that the random value ni in step
1 is used for the tag to authenticate the reader in step 4. If
the reader transmits A1 just once for all tags to authenticate
the reader, we can save about 25% transmissions when reading
multiple tags. However, this requires the secret Z to be shared
with multiple tags to recover the authenticator ni , in which the
secret Z will be exposed to attackers by capturing just one tag.
To address the above described reader-tag communication
problems, we need to modify the basic scheme. We assume
that each tag has a pair of unique secret keys (Yj , Zj ) shared
with the T A, which is brokered by the reader R. The new
protocol is presented in the following section as Algorithm 2.
B. Extended Scheme for Secure Reader-Tag Communications
The extended scheme is to address several deficiencies of
the basic scheme. First, reader R may not know which tag it
is currently communicating with. As a result, an anonymous
search scheme is required for the reader to get tags’ IDs;
however, the search scheme should provide untrackable ability
for the reader-tag protocol. Second, there must be a secret
identifier in each message for the reader and tags to identify
that the message is originated from or targeted to which tag.
Otherwise, the reader and tags need to try their possessed
secrets on each of the received messages to discover the
intended receiver and the sender, which will consume a lot
of computation overhead for both the reader and tags. For
untrackable requirements, the secret identifier can be only
tracked by each pair of intended reader and tag. Third, the
extended scheme should preserve all the security features of
the basic scheme while introducing minimal level of additional
storage and computation overhead.
In following descriptions, we first describe the setup of the
extended scheme, then we describe the solution in detail.
1) Setup: An RFID tag is denoted as Tj , where j =
1, . . . , N . Tj stores Dataj and its integrity checking value
h(Dataj ). T A is responsible for managing all RFID tags and
installing their shared secrets. T A generates a unique pair of
secret keys (Yj , Zj ) for each tag Tj . T A is also responsible
for authorizing RFID readers to access tags. Before using
the extended scheme, an RFID reader R gets an access list
L = {Tj , Yj , Zj |j = 1, . . . , N } from the T A through a secure
channel.
To help the reader and tags to identify the type of a received
message, we introduce two bits at the beginning of each
message to identify the message type.
2) Secure reader-tag communication protocol: As shown
in Algorithm 2, initially, R generates a random number ni
and broadcasts it to all tags in L. On receiving the random
number ni , each tag, say Tj , sends a challangej to the reader.
The challenge includes a trapdoor one-way function value
g(Tj , nj ), which is described in Section III-A, and a secure
one-time padding message B = (Yj +ni )⊕nj . Only the reader

TABLE II
M ESSAGE TYPES .
State
s1
s2
s3
s4

Binary notation
00
01
10
11

Description
reader request
tag challenge
reader response
tag response

can open the trapdoor function g(., .) and then discovers tag
ID Tj and a random value nj . Based on the access list L, the
reader can perform (Yj +ni )⊕B ⇒ nj . Including ni and nj in
a message is to make sure that the message is recent for reader
and tags. Once a tag’s message passes the checking nj == nj ,
the reader generates a nonceij and a response Aj for tag
Tj . Note that nonceij is generated using the same one-way
method g(., .) with a different input nij . Our protocol does not
require each tag to open the received trapdoor; however, each
tag needs to compute this one-way function after sending its
challenge to the reader. By comparing received nonceij and
the one-way method value, tag Tj can identify if it is the
intended receiver. From the received Aj , Tj can recover the
random value ni and then checks if ni equals to previously
received challenge ni ; if the checking is passed, Tj computes
another nonceji by using a slightly different input nij + 1,
and then sends it along with the Dataj and its integrity
checking code, which are secured by the one-time padding
code nij = nj + Zj ; if the checking fails, Tj sends a random
number nrand .
Compared to the basic scheme, the extended scheme saves
about 25% transmissions, since it only sends one challenge
s1||ni to all RFID tags in step 1.
V. P ERFORMANCE A SSESSMENTS
In this section, we first assess the security performance.
Then, we present the computation and communication performance assessments. Our performance assessments focus on
the extended scheme.

A. Security Performance
In security performance assessments, we analyze proposed
solutions against several passive and active attacks. We explain
the nature of attacks, capabilities of an attacker, and the
strength of our protocols against attacks along with common
assumptions. The attacks considered for the security assessments are the ones aimed at compromising the authentication,
data and identity privacy of the presented reader-tag communication protocols.
In the following presentations, we denote an adversary as
β. We assume that secret keys Yj and Zj are stored on Tj and
R, which are not disclosed to β.

Algorithm 2 Extended Scheme.
1: R −→ Tj : s1||ni

2:

3:

4:

5:

Tj : x = g(Tj , nj )
Tj : B = (Yj + ni ) ⊕ nj
Tj : challengej = B||x
R ←− Tj : ∀Tj ∈ L, s2||challengej
R : for j = 1, . . . , N recovers Tj and nj from x
R : uses Yj and ni to recover nj from B, and checks
if nj == nj then
for j = 1, . . . , N computes:
Aj = (Zj + ni ) ⊕ (Yj + nj )
nij = ni + nj + Zj
nonceij = g(Tj , nij )
R −→ Tj : ∀Tj ∈ L, s3||nonceij ||Aj
else
stop
end if
Tj : ∀Tj ∈ L checks nonceij and then computes
ni = [nij ⊕ (Yj + nj )] − Zj
if ni == ni then
Tj : nonceji = g(Tj , nij + 1)
R ←− Tj : ∀Tj ∈ L
s4||nonceji ||(Dataj ||h(Dataj )) ⊕ nij
R : based on nonceji , R recovers Dataj and its integrity
checking code h(Dataj ) using nij and then checks:
if h(Dataj ) == h(Dataj ) then
accept
else
discard
end if
else
R ←− Tj : ∀Tj ∈ L, s4||nrand
R : Data verification fails
end if

1) Eavesdropping Attack: Under this attack, β can observe
all messages exchanged between R and Tj . In our scheme, β
can capture four messages: ni , (Yj +ni )⊕nj , (Zj +ni )⊕(Yj +
nj ), and (Dataj ||h(Dataj )) ⊕ nij . As shown in Table III, we
denote these messages as known variables Ki (i = 1, 2, 3, 4).
β does not know nj , Yj , Zj , and Dataj ||h(Dataj ), which
are represented as unknown variables Ui (i = 1, 2, 3, 4).
Theorem 1: Eavesdropping communications between R
and Tj is unable to get any valuable information stored in
R or Tj
Proof: As already explained, the messages obtained by
eavesdropping communications between R and Tj is considered known variables, and the secret information stored on R
and Tj is considered as unknown variables. β can try to solve
following equations along with known variables and publicly
know Algorithm 2 to determine unknown variables.
1) K2 = (U 2 + K1) ⊕ U 1,
2) K3 = (U 3 + K1) ⊕ (U 2 + U 1),
3) K4 = U 4 ⊕ (K1 + U 1 + U 3),
As there are 3 equations and 4 unknown variables, β cannot
determine values for unknown variables, which provides Unconditional (UC) security. Thus, β is unable to get any valuable
information by eavesdropping communications between R
and Tj . The security strength of trapdoor function g(., .) is

TABLE III
L IST OF K NOWN AND U NKNOWN VARIABLES .

Symbol

Variable Name

K1

ni

K2

B

K3
K4

Aj
(Dataj ||h(Dataj )) ⊕ nij

U1
U2
U3
U4

nj
Yj
Zj
Dataj ||h(Dataj )

Descriptions
Known Variables
Random number selected by R as the challenge for later authenticating the
reader.
Message sent by Tj to securely transmit random number nj to R using shared
secret key.
Message sent by R to securely transmit authentication message to Tj .
Message sent by Tj to securely transmit secret data Dataj ||h(Dataj ) to R.
Unknown Variables
A random number generated by Tj .
Secret key shared between T A, Tj , and R.
Secret key shared between T A, Tj , and R.
Secret data stored on Tj along with its hash.

provided in [13], [14], which is based on the difficulty of the
factoring problem.
The proof presented above also shows the reason why we
need two secret keys Yj and Zj in the protocol. If we use one
secret key in Algorithm 2, the attacker will be able to solve
the above listed equations.
2) Active Information Leakage Attack: In active information leakage attack, β can actively participate in communications with R or Tj . Under this attack, β can interrogate Tj by
sending messages pretending to be R, and β can also respond
to the query from R pretending to be Tj .
Theorem 2: β will not get any valuable information from
Tj when pretending to be R.
Proof: Based on Algorithm 2, β can generate two messages at step 1 and 3. Although β can generate a random
value ñi in step 1, β cannot compute nij after receiving the
challenge sent by Tj in step 2. This is because β does not have
the knowledge of Yj and Zj . As a result, β cannot generate
correct Aj in step 3. Thus, the verification in step 4 cannot
pass, and β will receive nrand sent by Tj . Thus, β is unable
to get any valuable information from Tj .
Theorem 3: β will not get any valuable information from
R when pretending to be Tj .
Proof: Based on Algorithm 2, β receives two messages
from R. In step 1, R sends a random number ni . Since β
does not have the knowledge of Yj , it can only generate a
fake challengeβ to R. After receiving challengeβ , R needs
to recover nj to authenticate the tag, which will fail. Thus, β
is unable to get any valuable information from R by actively
involving itself into reader-tag communications.
3) Tracking Attack: Under this attack, β tries to identify
two or more responses from Tj in different locations or communication sessions to track the activities of tagged objects.
β can eavesdrop communications between R and Tj . β is
also capable of interrogating Tj using messages obtained from
eavesdropping previous communications between R and Tj .
Theorem 4: β is unable to distinguish messages sent by Tj
and R from messages sent by other RFID tags and readers.

Proof: In our proposed protocol, following messages are
exchanged between R and Tj .
1)
2)
3)
4)

R → Tj : s1||ni ,
Tj → R : s2||(Yj + ni ) ⊕ nj ||g(Tj , nj ),
R → Tj : s3||g(Tj , nij ||(Zj + ni ) ⊕ (Yj + nj ),
Tj → R : s4||g(Tj , nij +1)||(Dataj ||h(Dataj ))⊕(ni +
nj + Zj ) or nrand .

Each of above presented messages contains one or more of the
following random values, ni , nj , nij (derived from nj and
Zj ), nrand , and g(Tj , ∗). For each communication session,
which includes four transmitted messages from step 1 to step
4 (or step 5), Tj will select a new random value nj . Both
passive eavesdropper and active attackers cannot identify the
messages from different communication sessions originated
from the same tag and reader. Moreover, β cannot identify the
a reader since two messages sent by R are also randomized for
each communication session. Thus, β is unable to distinguish
messages sent by Tj and R from messages sent by other RFID
tags and readers.
4) Replay Attack: Under this attack, β captures messages
between authorized R and legitimate Tj , and replays the
captured messages later to get access to the secret data stored
on Tj or to impersonate as Tj .
Theorem 5: β cannot successfully replay previous captured
messages to access secret data stored in RFID tags or impersonate legitimated RFID tags.
Proof: In steps 1 and 2, the reader and a tag generate two
random values ni and nj , respectively, as challenges for latter
authentication and encryption (use one-time pad). If β replays
a message ni , the verification at step 4 cannot pass because the
replayed message Aj in step 3 does not include a new random
number nj generated by the tag. Thus, β cannot access the
secret data stored in the tag. If β replays messages challegej
and Dataj ||h(Dataj ) ⊕ nij to impersonate as a legitimate
tag, the integrity checking h(Dataj ) == h(Data) cannot
pass. This is because the reader sends a new challenge ni in
step 1 and the old captured value nij does not include it in
step 2. Thus, β cannot replay previously captured messages to

TABLE IV
P ERFORMANCE A SSESSMENTS .
(a) Gate count for different
Operation
Adder
Subtractor
Multiplexer
g(., .)
Pseudo-random number generator
Basic scheme
Extended scheme

arithmetic blocks.
Gate Count (GEs)
640 (=5*128)
768 (=6*128)
442 (=2 * ((18*12) + 5)
512
∼ 500
1,850
2,850

impersonate as a legitimate RFID tags. Each trapdoor one-way
method g(., .) includes the random value nj and nij , which
are randomly generated or derived from a random value for
each communication session, thus it cannot be replayed.
B. Computation and Communication Performance
We analyze computation and communication overhead of
our proposed protocols. We present the computation analysis
in terms of the number of gate equivalents (gates for short)
required for each operation performed on RFID tags. We
compare our solutions with the implementations of using AES
algorithm and hash functions. As argued in [25], the number of
gates required for implementing security operations on lowcost RFID tags is limited to 200 - 2,000 gates. Using our
solutions, RFID tags perform bitwise XOR and modular addition. XOR is a bitwise operation and insignificantly expensive
compared to modular addition. Hence, we focus our analysis
on the modular addition. Based on our solutions, modular
addition of two numbers x and y in GF (p) is defined by:

x + y if x + y < m,
(x + y) mod p =
x + y − m if x + y > m,
which can be implemented using an adder, a subtractor, and a
comparator.
Other techniques to perform modular addition are suggested
in [29]. We use simple Ripple carry adder [30] implemented
using series of full adders for 128-bit addition. For subtraction,
we use Ripple carry adder in two’s complement, form which
uses invertor block. For 128-bit addition and subtraction the
estimated number of gates is listed in Table IV(a). For comparator, simple bitwise digital comparator can be used, which
makes use of multiplexer’s to provide one bit starting from the
most significant bit of x and y to the digital comparator. We
consider 128:1 multiplexer using eighteen 8:1 multiplexer and
one 2:1 multiplexer. Two 128:1 multiplexers are required for
two numbers being compared. Since gates required for one bit
digital comparator is insignificant, we do not consider its gate
count, and thus we focus on multiplexer’s only. Additionally,
as presented in [11], [12], the number of gates required by
g(., .) and a pseudo-random number generator is about 1000.
The total number of gates required for multiplexers is also
listed in Table IV(a). We do not claim that this is the best

(b) Gate count comparisons with cryptographic algorithms.
Algorithm
Gate Count (GEs)
SHA-256
10,868
SHA-1
8,120
MD-5
8,400
MD-4
7,350
AES
3,400

design in terms of number of gates or performance, and we
believe better optimized designs are possible. Our result of
the gate count is based on estimations but not on synthesis.
The Table IV(b) compares gate counts for hash functions
and AES algorithm as mentioned in [10], [31]. Clearly, the
number of gates required for our proposed solutions is the
minimal, which makes it more suitable for low-cost RFID
tags. Using 1,850 gates for basic scheme and 2,850 gates for
extended scheme is much lower in the gate count compared to
the most efficient encryption algorithm (AES), which requires
3,400 gates. Moreover, the proposed solution provides secure
key lookup, mutual authentication, data confidentiality, and
intractability, which require more implementations of using
several traditional cryptographic methods. Thus, the overall
gain is huge.
The amount of non-volatile memory required on RFID
tags of our solutions is 256 bits for two secret keys, when
the XOR padding block is 128 bits. Additional 128 bits are
occupied by a modulo prime p. If we also assume the tag’s ID
occupies 128 bits, the total non-volatile memory requirements
for storing protocol parameters is l512 bits. The amount of
volatile memory required on RFID tags for our scheme is 128
bits for random number ni sent by the reader, 128 bits for
random number nj generated by RFID tags, 128 bits for nij ,
and 128 bits for g(., .) values, which can be computed onthe-fly. Implementing 512 bits of volatile memory on RFID
tags will require additional chip area and further analysis are
required to determine the amount of increase in chip area on
the RFID tags.
The computation load on a reader is also lightweight as only
modulo addition and bitwise XOR are performed. Using the
propose solutions, we only require two transmissions for each
RFID tag. For each communication session, four messages
are transmitted. Considering the provided security features:
mutual authentication, data privacy, anti-tracking, anti-replay,
the communication overhead of our solutions is low.
VI. C ONCLUSION AND F UTURE W ORK
In this paper, we present lightweight protocols for securing
reader-tag communications for passive RFID tags. Without
using traditional encryption/decryption and keyed hash-based
functions, we present how to use XOR one-time pad and

modulo addition as the basic building blocks for reader-tag
authentication and data encryption. The advantage of our
schemes over other schemes lies in its applicability for lowcost passive RFID tags requiring strong security protections.
We also analyze the security and performance efficiency of
our protocols, which highlights their benefits.
Several security issues are not addressed in this paper,
which require further investigations: (1) How to prevent the
reader to learn the secret keys stored in RFID tags? (2)
How to effectively update the secret keys stored in RFID
tags after each communication session? (3) How to mitigate
denial of service (DoS) attacks during the challenge-response
procedures? (4) how to reduce the complexity of secure tag
searching protocol to identify RFID tags?
R EFERENCES
[1] S. Sarma, “Towards the Five-cent Tag,” Technical Report MITAUTOID-WH-006, MIT Auto ID Center, 2001. Available at
http://www.autoidcenter.org, Tech. Rep.
[2] A. Juels and R. Pappu, “Squealing Euros: Privacy Protection in RFIDEnabled Banknotes,” in Proceedings of 7th International Conference on
Financial Cryptography, 2003.
[3] C. Tan, B. Sheng, and Q. Li, “Severless search and authentication
protocols for rfid,” in Proceedings of IEEE International Conference
on Pervasive Computing and Communications (PerCom), 2007.
[4] E. Inc, “Class 1 generation 2 uhf air interface protocol standard version
1.0. 9,” EPCglobal Inc, 2004.
[5] A. Juels, “RFID security and privacy: a research survey,” Selected Areas
in Communications, IEEE Journal on, vol. 24, no. 2, pp. 381–394, 2006.
[6] M. Feldhofer and J. Wolkerstorfer, “Strong Crypto for RFID Tags-A
Comparison of Low-Power Hardware Implementations,” in Proceedings
of IEEE International Symposium on Circuits and Systems, (ISCAS), pp.
1839–1842, 2007.
[7] C. Lim and T. Kwon, “Strong and robust rfid authentication enabling
perfect ownership transfer,” in Proceedings of Conference on Information and Communications Security, 2006.
[8] D. Molnar and D. Wagner, “Privacy and security in library RFID: issues,
practices, and architectures,” in Proceedings of the 11th ACM conference
on Computer and communications security, pp. 210–219, 2004.
[9] S. Weis, S. Sarma, R. Rivest, D. Engels, and A. Center, “Security and
Privacy Aspects of Low-Cost Radio Frequency Identification Systems,”
in Proceedings of First International Conference on Security in Pervasive Computing, 2003.
[10] M. Feldhofer and C. Rechberger, “A Case Against Currently Used Hash
Functions in RFID Protocols,” in Proceedings of Workshop on RFID
Security, pp. 13–14, 2006.
[11] M. Burmester, B. de Medeiros, and R. Motta, “Robust, anonymous
RFID authentication with constant key-lookup,” in Proceedings of ACM
symposium on Information, computer and communications security, pp.
283–291, 2008.
[12] M. Burmester, B. De Medeiros, and R. Motta, “Anonymous RFID
authentication supporting constant-cost key-lookup against active adversaries,” International Journal of Applied, vol. 1, no. 2, pp. 79–90,
2008.
[13] A. Shamir, “Squash: A new one-way hash function with provable
security properties for highly constrained devices such as RFID tags,”
Invited Talk, International Conference on RFID Security (RFIDSec),
2007.
[14] ——, “SQUASH–A New MAC with Provable Security Properties for
Highly Constrained Devices Such as RFID Tags,” in Proceedings of the
Workshop on Fast Sofware Encryption (FSE), vol. 5086, pp. 144–157,
2008.
[15] D. Kahn, The Codebreakers: the Comprehensive History of Secret
Communication from Ancient Times to the Internet, Scribner Inc., 1996.
[16] Z. Zhou and D. Huang, “SRK: A Distributed RFID Data Access
Control Mechanism,” in Proceedings of IEEE International Conference
on Communications (ICC), 2008.

[17] ——, “RFID Keeper: An RFID Data Access Control Mechanism,” in
Proceedings of IEEE Global Telecommunications Conference, pp. 4570–
4574, 2007.
[18] T. Dimitriou, “A Lightweight RFID Protocol to protect against Traceability and Cloning attacks,” in Proceedings of the First International
Conference on Security and Privacy for Emerging Areas in Communications Networks (SecureComm)., pp. 59–66, 2005.
[19] M. Ohkubo, K. Suzuki, and S. Kinoshita, “Cryptographic approach to
privacy-friendly tags,” in Proceedings of RFID Privacy Workshop, pp.
624–654, 2003.
[20] S. Lee, Y. Hwang, D. Lee, and J. Lim, “Efficient authentication for
low-cost RFID systems,” in Proceedings of International Conference
on Computational Science and its Applications (ICCSA), pp. 619–627,
2005.
[21] G. Tsudik, “YA-TRAP: Yet another trivial RFID authentication protocol,” in Proceedings of IEEE International Conference on Pervasive
Computing and Communications (PerCom), 2006.
[22] T. Li and R. Deng, “Vulnerability Analysis of EMAP-An Efficient RFID
Mutual Authentication Protocol,” in Proceedings of the The Second
International Conference on Availability, Reliability and Security, pp.
238–245, 2007.
[23] T. Li and G. Wang, “Security Analysis of Two Ultra-Lightweight RFID
Authentication Protocols,” in Proceedings of IFIP SEC, 2007.
[24] T. Van Le, M. Burmester, and B. de Medeiros, “Universally composable and forward-secure RFID authentication and authenticated key
exchange,” in Proceedings of the 2nd ACM symposium on Information,
computer and communications security, pp. 242–252, 2007.
[25] A. Juels and S. Weis, “Authenticating Pervasive Devices with Human
Protocols,” Advances in Cryptology-Crypto: 25th Annual International
Cryptology Conference, 2005.
[26] S. Sarma, S. Weis, and D. Engels, “RFID Systems and Security and
Privacy Implications,” in Proceedings of Workshop on Cryptographic
Hardware and Embedded Systems (CHES), pp. 454–469, 2002.
[27] D. Holcomb, W. Burleson, and K. Fu, “Initial SRAM state as a
fingerprint and source of true random numbers for RFID tags,” in
Proceedings of the Conference on RFID Security, 2007.
[28] A. Shamir, “How to Share a Secret,” Communications of the ACM,
vol. 22, no. 11, pp. 612–613, 1979.
[29] J. Beuchat, “Some Modular Adders and Multipliers for Field Programmable Gate Arrays,” in Proceedings of the 17th International
Parallel and Distributed Processing Symposium, 2003.
[30] D. Lilja and S. Sapatnekar, Designing Digital Computer Systems with
Verilog. Cambridge University Press, 2005.
[31] M. Feldhofer, J. Wolkerstorfer, and V. Rijmen, “AES Implementation
on a Grain of Sand,” IEE Proceedings Information Security, vol. 152,
no. 1, pp. 13–20, 2005.

MobiCloud: a Geo-distributed Mobile Cloud
Computing Platform
Tianyi Xing1 , Dijiang Huang1 , Shingo Ata2 , Deep Medhi3
1

Arizona State University, U.S.A,{tianyi.xing,dijiang}@asu.edu
2
Osaka City University, Japan, ata@info.eng.osaka-cu.ac.jp
3
University of Missouri–Kansas City, U.S.A, dmedhi@umkc.edu

Abstract—In a cloud computing environment, users prefer
to migrate their locally processing workloads onto the cloud
where more resources with better performance can be expected.
ProtoGENI [1] and PlanetLab [17] have further improved the
current Internet-based resource outsourcing by allowing end
users to construct a virtual network system through virtualization
and programmable networking technologies. However, to the
best of our knowledge, there is no such general service or
resource provisioning platform designated for mobile devices.
In this paper, we present a new design and implementation
of MobiCloud that is a geo-distributed mobile cloud computing
platform. The discussions of the system components, infrastructure, management, implementation ﬂow, and service scenarios
are followed by an example on how to experience the MobiCloud
system.

I. I NTRODUCTION
Cloud computing has grown rapidly in the past few years
due to the increasing network bandwidth, mature virtualization
techniques, and emerging cloud based business demands. What
is more, by 2013, mobile devices will overtake PCs as the
most common web access entities worldwide as predicted by
Gartner [15]. Thus, a mix of cloud computing with mobile
technologies is highly expected. Mobile Cloud Computing
(MCC) is a term that refers to an infrastructure where both
data storage and data processing are done, outside of mobile
devices from which an application is launched. Besides that,
a mobile entity is not limited to only a mobile device; more
importantly, it could also be cloud resources, infrastructure,
services, and human beings. Hence, with this understanding,
MCC further refers to a cloud system where mobility happens
in infrastructure, resources, services, user devices and even
human beings.
The trend of the MCC system is not just aimed at providing
ﬁxed services for users in certain areas, but is especially to
look forward to establishing connections among mobile users
all over the world. Due to the mobility of MCC users, a
geographically distributed cloud system is a natural choice
that allows users to connect to cloud resources that are
geographically “close” to their mobile devices, which usually
means less communication delay compared to the centralized
approach.
In this research work, our goal is to establish a new MCC
service for mobile users with reduced service access latency
and increased cloud infrastructure utilization. We present a
new geo-distributed MCC infrastructure, called MobiCloud,
to address the following research challenges: 1) Resource
diversity – Virtual machines are the main resources due to its

c
978-3-901882-48-7 2012
IFIP

efﬁcient utilization of hardware resources. However, current
service providers pay more attention to system architecture
design but not enough to resources provisioning diversity,
which means users have little choice on resources. The resource diversity includes not only the type of guest OS,
but also different virtual hardware conﬁgurations, 2) Network
programmability and sensibility – A static and simple network
cannot meet the increasing demand from users nowadays.
Network programmability usually separates the control and
data path of network devices, and provides an interface of
the control path so that the control function can be easily
programmed. Sensibility provides a bridge connecting cloud
resources and the physical world. Sensibility greatly expands
the range of experiments supported in the system.
It is essential to propose a cloud provisioning platform by
considering mobile users and experimenters to solve the problems raised by the emergence of the popular geo-distributed
cloud systems. In this paper, we propose MobiCloud, a geodistributed MCC resource provisioning system. The major
contributions of this paper are summarized as below. We
design the MobiCloud framework, deﬁne its service model,
and propose a novel extension model CaaS. Then, components are implemented and a geo-distributed infrastructure
is established. A concrete example on how to experience
the MobiCloud system is given to better understand what
MobiCloud can support. MobiCloud is a geo-distributed MCC
service provisioning platform including elastic computing,
secure storage, and layer-2 and above networking capabilities.
This platform is currently implemented connecting three
sites located at Arizona State University (ASU), University
of Missouri–Kansas City (UMKC) in the USA and Osaka
City University (OCU) in Japan. Additional sites in Paris and
Beijing are under plan to be part of the MobiCloud system.
The rest of this paper is organized as follows. Section
II addresses related work. Section III discusses the design
and implementation of the proposed MobiCloud system. An
example of how to experience the MobiCloud is illustrated in
section IV. Section V concludes the paper and discusses the
future work.
II. R ELATED W ORK
GENI [5], A Global Environment for Network Innovations, is a project exploring the future global networking
infrastructure where different types of resource provisioning
platforms are residing. GENI’s projects can be divided into
backbone networks, programmable hosts, wireless testbeds,

164

TABLE I
C OMPARISON TABLE OF GENI P ROJECTS

OCU
UMKC

Project
PlanetLab
ProtoGENI
(Emulab)
OpenFlow
Networks
GENICloud
(opencirrus)
Seattle
ORBIT
DOME
DETER
(Emulab)
Kansei
ViSE
GpENI
MobiCloud

Major
Resource
Fedora VM
PC and VM

Sensing
Capability
No
USRP

Programmable
Networks
No
Yes

Extension
Simplicity
Difﬁcult
Difﬁcult

OF Switch

No

Yes

DD

Physical node

No

No

NA

Experimenter
Software
Dedicated node
Linux VM
PC

No

No

Easy

No
No
No

Yes
No
Yes

NA
NA
NA

No
Yes
Yes
Yes

NA
NA
DD
CaaS

Sensing node
Yes
Debian VM
Yes
Fedora VM
No
Windows, Linux
Yes
VMs
DD: Dedicated Device, NA: Not

ASU

Inter-cluster OpenFlow
Switch Router

o
To

rs
s te
r clu
the

Network File
System (NFS)

Cloud Management
Network

Cloud Internal Data Networks
(VLANs)
Open Virtual Switches (OVSes)

Cloud Internal Management
Servers
Web Server VPN Database

Resource
Pool

Domain
DNS Radius
Controller

Cloud internal & public services
(Using VMs and OVSes)

Fig. 1.

Incoming traffic network

Outgoing traffic network

OpenFlow Switch Router
(Incoming & Outgoing
traffic Gateways)

MobiCloud Architecture Design

Allowed

and specialized aggregates. Different GENI platforms, e.g.,
PlanetLab [17], ProtoGENI [1], and OpenFlow Networks
[16] have different concentration in terms of provisioning
resources, network architecture, programmable networks, etc.
For example, ProtoGENI has integrated a large group of
resources available from the world to provide resources with
network programmability and sensing features. Seattle [10]
has an efﬁcient design that can easily make spare nodes join
their available resource pool to be further utilized to provide
python based experiments. All related GENI projects [10], [9],
[18], [19], [8], [7], [14], [20] and our proposed MobiCloud are
summarized in Table I.
The proposed and implemented MobiCloud system is originally based on the work discussed in [11]. The major differences between this work and [11] are in the following
four perspectives: 1) This paper improves the original design
signiﬁcantly in terms of network connectivity, data storage,
and so on; For example, it now allows the network architecture to span in a geo-distributed fashion and introduces the
network-based remote storage; 2) This paper presents a fully
implemented cloud computing management system but not
just a design; 3) This paper establishes a monitoring system for
monitoring resources and presents a performance benchmark;
4) This paper identifys practical issues, which need to be
implemented in the near future. [12] concentrates on secure
data processing based on the overall MobiCloud architecture.
To the best of our knowledge, MobiCloud is the only MCC
system that is able to address all challenges listed above.
III. M OBI C LOUD S YSTEM D ESIGN AND I MPLEMENTATION
This section discusses the MobiCloud platform mainly in
terms of components and implementation ﬂow.
A. System Components
The prototype of the proposed MobiCloud system is now
available is presented in Fig. 1. We partition the MobiCloud
system into different types of components including computing, storage, administrative, and networking.
Computing Component. The computing component is the
entity that provides computing resources, i.e., cloud hosts.

The major difference among different computing components
depends on the virtualization technology being adopted. Virtualization in MobiCloud is based on XEN [?] that has
impressive scalability and efﬁciency. A cloud system can
provide logically separate resources upon the virtualization
layer. Usually, Cloud resources in one domain are grouped
into a resource pool that always has at least one physical
node known as the master node. Other physical nodes that
join existing pools are described as in slave nodes. Only the
master node exposes an administration interface and forwards
commands to individual slaves as necessary.
Storage Component. Storage cumulates all resource images and users’ data. Resource is prepared by cloning resource
templates that are stored in the storage repository. We choose
to establish a remote storage repository, Network File System
(NFS), to manage the storage of resources in our cloud system.
An NFS storage server is connected to the computing server
via a switch that greatly increases the scalability of storage.
Administrative Component. Dedicated physical servers
are for administrating resources and monitoring network trafﬁc
within and across domains. There is also a set of internal
functional servers serving various administrative purposes such
as web service, DHCP, DNS, authentication service, DB
service, and VPN.
Networking Component. The control plane and the data
plane are isolated based on the multi-network design of
MobiCloud. In Fig. 1, there are four networks in each cluster.
Incoming and outgoing trafﬁc switches isolate control trafﬁc
(i.e., resource access, OS update, and package download)
coming into or going out of the MobiCloud Gateway. The data
network switch is a managed switch with supper for VLAN
that enables VMs from different physical servers to reside
in the same virtual domain. Lastly, the cloud management
network connects the internal management and monitoring
server and NFS. Each cloud server is installed with an Open
vSwitch with which the data trafﬁc between two VMs in the
same physical server does not need to go through the physical
data network switch out of the cloud host.

2012 8th International Conference on Network and Service Management (CNSM 2012): Short Paper

165

Web Serivce

abc

Access Distributor

b

DMZ Firewall

b

Resource Allocation
& Management
Service

b

Network
Management
Service

ab
ab

c

VPN Service

a. Registration

c

ab
ID & Credential
Management
Service

b. Requesting Resource
Fig. 2.

b

b

Remote Configure
Service

Database Service

c. Accessing the system

Processing ﬂows in MobiCloud

B. Implementation Flow
After designing the framework and conﬁguring the infrastructure, we have implemented the system to provide resource
provisioning services to users. The implementation ﬂow is
deﬁned in terms of three major aspects: registration, requesting
resources, and accessing the system. These three procedures
are described below and are shown in Fig. 2.
∙

∙

∙

Registration. Anyone who wants to use the MobiCloud
system must have a valid account. Users have to register
an account by visiting the MobiCloud portal. After users
create an account, the account credential will be automatically stored in the ID and Credential Management
Service, which is implemented by the Kerberos based
Active Directory, and dedicated Databased Service.
Requesting Resource. After users’ credentials are authenticated, users are authorized to request resources from
Resource Allocation & Management Service. Although all
services are hosted in the MobiCloud private domain,
we still introduce a DMZ to enhance security of cloud
resources. Database Service stores all related information
of newly created resources, and Network Management
Service prepares and conﬁgures network attributes of
resources. So far, Network Management Service consists
of DHCP and Dynamic DNS. Users are also able to
conﬁgure network attributes of resources by themselves,
which is the reason why Remote Conﬁgure Service was
developed.
Accessing Resource. When users are about to access
their created resources, they have to connect to the VPN
server through the gateway. The VPN server authenticates
the users’ accounts at ID&Credential Management Service where users’ account credentials are stored. After
connecting to the VPN, users’ mobile devices are assigned with the MobiCloud private IP address and are
free to access their resources by using the corresponding
domain name assigned for each VM.
IV. E XPERIENCING M OBI C LOUD

In this section, we present the implementation of MobiCloud
through a simple example of its use. Through our developed
web interface, users are free to realize all operations (register, request resource, and access resource) we mentioned
in the previous section. The web portal can be accessed at
http://mobicloud.asu.edu.

166

Fig. 3.

Virtual network creation

A. Single VM Creation
To create a single VM, there are several ﬁelds that need
to be conﬁgured by users, which can be found in Table II.
After a user speciﬁes all the parameters in the corresponding
ﬁelds, a VM will be created at the backend side. One of the
advantages of MobiCloud over current existing platforms is
that the response time of the resource preparation is swift.
Because the VM template is already prepared, what the system
only needs to do involves two steps: 1) fast copy the VM
template and 2) conﬁgure the VM. When the VM is done being
prepared, users can use the management interface, shown in
Fig. 5(b), to manage their VMs. There are several options
available such as restart, resume, suspend, stop, and remove.
Each VM will be assigned with a unique domain name, in the
format of username.mobicloud.asu.edu that is registered in the
DNS system. A Single VM can also be set as a proxy of a
mobile device to enhance its capability. For example, users can
set their VMs as proxies with an anti-virus function enabled,
which greatly enhances security of mobile devices.
B. Virtual Network Creation
Besides creating a single VM, users are also allowed to
claim multiple VMs that can be connected as a virtual network. The interface can be seen in Fig. 3. Users can simply
click, drag, and drop on the canvas to create their desired
network components and connect them. There are three major
components in the network creation canvas: desktop, switch,

2012 8th International Conference on Network and Service Management (CNSM 2012): Short Paper

TABLE II
S INGLE VM C REATION S PECIFICATION

VM name
OS Type
Hard Disk Size
Ram Size
NIC conﬁgure

VM Host Conﬁguration
Deﬁne the name of the VM.
Specify the Operation System of VM. We use Xen Hypervisor, which supports a wide range of guest
OS including Windows, Linux, Solaris, and various versions of the BSD operating systems.
Specify the size of the virtual hard disk on each VM. There are several options ranging from 8GB
to 128GB.
Specify the size of the memory. The range of memory can be selected from 128MB to 4GB.
VM Network Conﬁguration
Specify IP address, netmask, and default GW.

and router. Users can conﬁgure the components in a popup window. Beside the virtual hardware conﬁguration (i.e.,
CPU, memory, harddisk), network information can also be
conﬁgured, including creating virtual interfaces, IP addresses,
netmasks, default gateways, and so on. We use a switch
component to represent a VLAN to partition the network.
Users can draw lines to connect two or more components
(i.e., desktop or router) through a switch, which means those
interfaces are in the same VLAN and are isolated from
others. The router is the last component with routing functions
enabled by a software-based pre-installed router (Vyatta [6]).
After the user conﬁrms the topology by clicking the submit
button, a summary page indicating all hardware and network
information of VMs is presented. When the preparation is
done, a resource page is returned with the details of the
resources created. Each VM is assigned a unique domain name
that is similar to the single VM creation case. However, each
user can have multiple VMs; the domain naming scheme is the
format of username-networkname-number.mobicloud.asu.edu
to identify different VMs for the same user. For example,
if user cnsm2012 creates a network named mynetwork with
three VMs, the domain name assigned to the ﬁrst VM would
be cnsm2012-mynetwork-1.mobicloud.asu.edu.
C. System Resource Monitoring
For system administrators to better monitor performance of
both network and cloud hosts in MobiCloud and track ongoing
and potential issues in the system, we introduce a multilayer monitoring mechanism that is enabled by sFlow and
NetFlow [13]. Note that NetFlow provides limited visibility
focused on layer-3 network connections, while sFlow provides
comprehensive visibility into network and system resources
needed to manage performance in a virtualized and cloud
environment. In each Open vSwitch in Dom 0 of each Cloud
server, we enable not only sFlow at the switch level but also
at the host level, which means not only can the trafﬁc be
monitored, but also the host performance (i.e., CPU utilization,
memory usage, virtual disk I/O, and so on) can be monitored.
From the analyzer of both NetFlow ManageEngine and
sFlow Flowtrend [3], [2], network parameters, e.g., top conversation, top connections, most popular protocols and so on
can be monitored. Besides layer-3 network monitoring, sFlow
is able to inspect connection relationships from the following
three aspects shown in Fig. 4: internal connections, external
connections, and non-IP connections. The left-top part of Fig.
4 shows the internal connections that represent the internal

Internal IP Connection

Layer- 2 Non-IP Connection

FFFFFFFFFFFF
Non-IP

unknown

10.0.0.3
10.0.0.253

United States

ASU, UMKC@US

OCU@Japan
Layer-2 GRE Tunnel Connection

Fig. 4.

Japan

sFlow Connection Circle

topology at the ASU site where the connections between
the cloud server master node(10.0.0.3) and the storage server
(10.0.0.253) can be seen. The top-right part shows the layer2 Non-IP connections including unicast and broadcast. The
bottom part shows the external connections that indicate the
inter-cluster connection among all three sites.
V. C ONCLUSION AND F UTURE W ORK
This paper takes presents an expected cloud environment
for mobile devices. Our proposed MobiCloud system is able
to provide resources in terms of computing, storage, and networking that greatly enhances the capability of mobile devices.
We combine network-based storage, Xen virtualization, and
OpenFlow based network management solutions into a single
smart system, which has not been done previously to our best
knowledge. Also, an example of system experience is given
to better state the capabilities of MobiCloud.
In the near future, we are planing to implement OAuth
2.0 to improve the MobiCloud system. The OAuth 2.0 [4]
authorization protocol enables a third-party application to
obtain limited access to an HTTP service, either on behalf
of a resource owner by orchestrating an approval interaction
between the resource owner and the HTTP service, or by
allowing the third-party application to obtain access on its
behalf. It helps manage MobiCloud users in accessing both
inside and outside services. An integrate OAuth 2.0 solution
will be an inevitable trend for an ID management system of
MobiCloud.
GENI provides collaborative and exploratory environments
for academia, industry and public, which is ideal for MobiCloud to extend on. The federation with GENI mainly would
involve the following two steps: (a) following the Slice-based
Facility Architecture (SFA) speciﬁcation, (b) providing aggregate API and interfacing with other GENI major platforms.
We plan to explore this in the near future.

2012 8th International Conference on Network and Service Management (CNSM 2012): Short Paper

167

ACKNOWLEDGEMENT
This work is supported by US NSF grants CNS-1029562
and CNS-1029546, Ofﬁce of Naval Researchs (ONR) Young
Investigator Program (YIP), an HP IRP grant, and Japan NICT
International Collaborative Research Grant.
R EFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]

[10]

[11]

168

http://www.protogeni.net/trac/protogeni.
inMon Flowtrend, http://www.inmon.com/products/sFlowTrend.php.
ManageEngine, http://www.manageengine.com/.
O-Auth Community, https://oauth.net/2.
The Global Environment for Network Innovations (GENI), http://groups.
geni.net.
Vyatta, http://www.vyatta.com/.
A. Arora, E. Ertin, R. Ramnath, M. Nesterenko, and W. Leal, “Kansei: A
high-ﬁdelity sensing testbed,” In Proceedings of the DETER Community
Workshop on Cyber-Security and Test, vol. 10, pp. 35–47, 2006.
T. Benzel, R. Braden, D. Kim, and C. Neuman, “Design, deployment,
and use of the deter testbed,” in In Proceedings of the DETER Community Workshop on Cyber-Security and Test, August 2007.
R. Campbell, I. Gupta, M. Heath, S. Ko, M. Kozuch, M. Kunze, T. Kwan,
K. Lai, H. Y. Lee, M. Lyons, D. Milojicic, D. OHallaron, and Y. C. Soh,
“Open cirrus: Cloud computing testbed: Federated data centers for open
source systems and services research,” in Proceedings of the USENIX
Hotcloud, June 2009.
J. Cappos, I. Beschastnikh, A. Krishnamurthy, and T. Anderson, “Seattle:
A platform for educational cloud computing.” in The 40th Technical
Symposium of the ACM Special Interest Group for Computer Science
Education (SIGCSE), 2009.
D. Huang, X. Zhang, M. Kang, and J. Luo, “Mobicloud: Building
secure cloud framework for mobile computing and communication,” in
Proceedings of 5th IEEE International Symposium on Service-Oriented
System Engineering, 2010.

[12] D. Huang, Z. Zhou, L. Xu, T. Xing, and Y. Zhong, “Secure data processing framework for mobile cloud computing,” in IEEE INFOCOM’s
Workshop on Cloud Computing, 2011.
[13] N. Instruments, “Extending network visibility by leveraging netﬂow and
sﬂow technologies,” in White Pape, February 2011.
[14] D. Irwin, N. Sharma, P. Shenoy, and M. Zink, “Towards a virtualized sensing environment,” in Conference on Testbeds and Research
Infrastructures for the Development of Networks and Communities
(TridentCom), 2010.
[15] Mark Walshy, “Gartner: Mobile to outpace desktop web by 2013,”
Online Media Daily, January 2010.
[16] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson,
J. Rexford, S. Shenker, and J. Turner, “Openﬂow: Enabling innovation
in campus networks,” in ACM SIGCOMM Computer Communication
Review, April 2008.
[17] L. Peterson, A. Bavier, M. Fiuczynski, and S. Muir., “Experiences building planetlab,” in Proceedings of the Seventh Symposium on Operating
System Design and Implementation (OSDI), November 2006.
[18] D. Raychaudhuri, I. Seskar, M. Ott, S. Ganu, K. Ramachandran,
H. Kremo, R. Siracusa, H. Liu, and M. Singh, “Overview of the orbit
radio grid testbed for evaluation of next-generation wireless network
protocols,” in Proceedings of the IEEE Wireless Communications and
Networking Conference (WCNC), 2005.
[19] H. Soroush, N. Banerjee, A. Balasubramanian, M. D. Corner, B. N.
Levine, and B. Lynn, “Dome: A diverse outdoor mobile testbed,”
in Workshop on Hot Topics of Planet-Scale Mobility Measurements
(HotPlanet), June 2009.
[20] J. Sterbenz, D. Medhi, B. Ramamurthy, C. Scoglio, D. Hutchison,
B. Plattner, T. Anjali, A. Scott, C. Bufﬁngton, G. Monaco, D. Gruenbacher, R. McMullen, J. Rohrer, J. Sherrell, P. Angu, R. Cherukuri,
H. Qian, and N. Tare, “The Great Plains Environment for Network Innovation (GpENI): A programmable testbed for future Internet architecture
research,” in Proc. of 6th International Conference on Testbeds and Research Infrastructures for the Development of Networks & Communities
(TridentCom), Berlin, Germany, May 2010, pp. 428–441.

2012 8th International Conference on Network and Service Management (CNSM 2012): Short Paper

HUANG LAYOUT

10/20/10

3:54 PM

Page 128

TOPICS IN AUTOMOTIVE NETWORKING

Situation-Aware Trust Architecture for
Vehicular Networks
Dijiang Huang, Arizona State University
Xiaoyan Hong, University of Alabama
Mario Gerla, UCLA

ABSTRACT
We present a new trust architecture — Situation-Aware Trust — to address several important trust issues in vehicular networks. SAT
includes three main components: an attributebased policy control model for highly dynamic
communication environments, a proactive trust
model to build trust among vehicles, and prevent
the breakage of existing trust, and an emailbased social network trust system to enhance
trust and to allow the set up of a decentralized
trust framework. To deploy SAT, we utilize
identity-based cryptography to integrate entity
trust, data trust, security policy enforcement, and
social network trust, allocating a unique identity,
and a set of attributes for each entity. We conclude by presenting research challenges and
potential research directions that extend this
work.

INTRODUCTION
Vehicular ad hoc networks (VANETs) will
enable vehicle-to-vehicle and vehicle-to-roadside
communications and are expected to greatly
enhance driving safety and improve roadway system efficiency. However, widespread deployment
and penetration will heavily depend on users’
perception of the VANETs as a readily available, secure, reliable, and trustworthy infrastructure for providing accurate traffic and road
system data. The state-of-the-art research on
VANET trust has mainly focused on building
entity-level trust and data-centric trust [1]. The
former is based on shared and public key management solutions, where messages must be
authenticated to prevent external attackers from
injecting, altering and replaying messages, as
well as to prevent eavesdropping and location
tracking. The latter is to assess the credibility of
the reported data. Recent research publications
have studied the use of both entity and data
trust for authentication while preserving privacy
and accountability, in robust broadcasting or
multi-hop message disseminations [2].
Solutions based on entity-level trust and datacentric trust still face many challenges raised by
the complex vehicular communications system
that includes dynamic user groups, stringent

128

0163-6804/10/$25.00 © 2010 IEEE

real-time constraints, and heterogeneous communication environments, which make existing
entity trust and data trust methods ineffective.
Considering the broadcast nature of the medium, multi-hop routing, and multiple communication paradigms (from broadcast with specific
geographic zones to multicast within a large
organization); also considering the short duration of vehicle to vehicle sessions — usually a
few seconds — the establishment of VANETs
trust in a timely fashion becomes critical. Existing entity or data trust is usually based on an
individual user, security-on-demand approach.
This method cannot deal efficiently with trust
establishment in a highly dynamic and ephemeral communication environment. For example,
while conventional message encryption can be a
solution for access control, it requires a few
rounds of message exchanges for secure key
establishment among entities and trust verifications on data items, greatly slowing down the
response time. The issue is especially serious in
view of VANET safety applications’ real-time
constraints. Furthermore, existing VANET trust
management solutions have very limited capability to support secure data access control and in
particular, group-based secure access considering
the broadcast nature of VANETs.
To highlight our research motivations, we
present the following three illustrative scenarios.
Scenario 1: following an emergency (say, a fire, a
chemical spill or a bomb threat) in a certain area
of the city, police headquarters broadcast an
alert message to enable qualified vehicles (e.g.,
patrol cars, fire trucks, ambulances) in selected
locations near the scene of the accident to take
over the control of traffic lights in order to facilitate rescue and carry out orderly vehicle evacuation. The light control can be performed using a
challenge-response protocol: if the vehicle can
decrypt and answer the challenge, then it can
control the traffic lights. The vehicle must also
validate its location with respect to scene of accident, in order to prevent the control message
from being read by other vehicles in the wrong
locations. This situation is representative of a
class of VANETs applications that require to
validate — with low processing latency — both
the roles (e.g., police patrol car) and the locations (near a designated intersection) of the

IEEE Communications Magazine • November 2010

HUANG LAYOUT

10/20/10

3:54 PM

Page 129

These quite different

Security Policy Management

examples (location
vs. affiliations vs.

Goal:
Handle various road situations and
application scenarios

social network trust)
all point to the need

Enabling technology:
Attribute-based data access control

of exploring an
Social Network Trust

efficient and
predictive trust

Goal:
Complement to cryptography based
trust management, and promote
application development and
adoption for VANETs

setup latency. To this
end, we present a

Proactive Trust Establishment
Goal:
Handle the dynamics of VANETs and
improve the trust management
efficiency

system to reduce
on-the-scene trust

new trust architecEnabling technology:
Email-based social network trust

ture, situation-aware
trust (SAT).

Enabling technology:
Way-point information framework

Figure 1. System components, goals, and enabling techniques of SAT architecture.

associated entities. Note that these validations
require a long chain of message exchanges using
existing schemes, thus leading to long response
delay. Scenario 2: a peer-to-peer information system provides services to its community of drivers.
For example, a taxicab has learned that customers of a major convention will be waiting
after the banquet for cabs at a Hotel on Washington St., 10am 8/25/2009. It informs fellow cab
drivers of the same company of this opportunity.
It wants to broadcast this information only to
drivers belonging to his company, and as a further restriction, only to the drivers who, given
their current location, are expected to reach
Washington St. in time. This example is representative of applications where data access control is based on the organizational affiliation
bounded by the effective intervention time period. It requires group shared keys to be established dynamically and on the fly. Using the
earlier proposed schemes, it will require multiple
steps of message exchange with long delay. Scenario 3: a social network trust network can be
viewed as an overlay layer on top of the vehicular communication networks. Suppose social network trust is established between driver A and
driver B through a social network. They can use
their social network associated credentials, e.g.,
cryptographic keys, to establish secure channels
between them when needed. This situation suggests that some trust relationships may already
exist and can be explored to help reducing the
latency of establishing trust and keys in the two
previous scenarios.
These quite different examples (location vs.
affiliations vs. social network trust) all point to
the need of exploring an efficient and predictive
trust system to reduce on-the-scene trust setup

IEEE Communications Magazine • November 2010

latency. To this end, we present a new trust
architecture, situation-aware trust (SAT) [3], for
VANETs to address the trust management issues
identified by the above scenarios. SAT includes
the following three key architectural design components:
• Security Policy Management to address a
number of trust situations and application
scenarios on-road
• Proactive Trust Establishment to manage
VANET dynamics and build inter-vehicle
trust in a timely fashion
• Social Network Trust to incorporate people
factors in the VANETs trust establishment
in addition to cryptography based trust
management solutions, in which more applications can be developed and adopted using
VANET communication environments.
Compared to previous trust management in
VANETs, SAT adds new enabling techniques to
achieve the described system components: using
an attribute-based data access control scheme to
handle dynamic changes of VANET applications
complying with various data access security policies, building a way-point information framework to support cryptographic tools and
communication protocols for proactive trust
management, and applying email-based social
network trust to support and enhance current
secure VANET communications. Figure 1
describes the architecture of SAT.
In summary, the goal of SAT is to build a
new trust model using architecture and cryptographic tools that provide predictive trust information and quick and flexible key management,
thus improving driving experience. SAT is
inspired by the observation that there exist many
different requirements for secure communica-

129

HUANG LAYOUT

10/20/10

3:54 PM

Similar to many
secure mobile
communication
systems, SAT needs
to address various

Page 130

tion and data correctness with respect to a certain group of vehicles in a certain application situation; an event that affects a certain region
with immediate processing needs, or a service
that has a clear organizational boundary for its
users. In the following sections, we provide
detailed descriptions of SAT.

active and passive

RATIONALE AND PRINCIPLES OF SAT

attacks. For example,

EFFICIENT CRYPTOGRAPHIC APPROACH FOR
VANETS DATA ACCESS CONTROL

active adversaries can
forge and inject
malicious packets,
or modify and replay
previously captured
packets; passive
adversaries can also
learn information
from captured
packets.

In SAT, we use a cryptography-based approach
that allows data access control by defining
attributes of receivers. Attributes describe the
properties of corresponding entities or data as
studied in entity trust and data trust. Attributes
are treated as multiple public key components
using attribute-based cryptography [4] and they
can be used to identify common properties for a
group of vehicles, which can enforce data access
control policies for a group of vehicles. Particularly, we call the group of entities that satisfy the
attributes specified in a policy statement as a
policy group. For example, the policy group qualifier can be taxicabs in a company, police cars in
a city, a type of events (e.g., accidents, congestions), a set of common interests shared among
vehicles, a set of security or service requirements, a set of road/environment constraints
(e.g., street name, time duration, driving direction), or a combination thereof. Attributes can
be further classified as static and dynamic
attributes, depending on how frequently the
attributes change in VANETs. Typically, dynamic attributes are tied to road segments and effective time duration.

PROACTIVE TRUST ESTABLISHMENT IN VANETS
Existing VANET trust management solutions
(e.g., 1609.2) assume that certificates are issued
before the actual communication act. SAT provides an assistant framework to distribute certificates to vehicles before the actual
communications among vehicles and RSUs. On
the other hand, SAT also provides a framework
to reduce unnecessary trust establishment actions
among vehicles encountered on the road. Particularly, knowing the attributes of an encountering
vehicle can help in deciding whether establishing
the trust is required. To this end, SAT uses a
proactive approach to establish trust with intended vehicles before they meet. This approach
requires that each vehicle predicts the potential
meeting peers by distributing its moving trajectory to others.

USING SOCIAL NETWORK TRUST FOR VANETS
SAT adopts social network trust as part of SAT
architecture to bootstrap trust, which can also
add incentives for users to adopt VANET-based
services. SAT particularly investigates emailbased social network trust [5]. Such a trust and
related usable values can be made usable for
message communication through automated
agents installed within the on-board vehicle communication units. The interaction can be triggered when a passenger uses his/her email
services. Extracting social network trust from

130

email services has many attractive advantages
with respect to other social networks:
• Email services usually provide a natural and
intrinsic layer of protection, e.g., scrutinizing the untrusted emails through spam filter
and manually setup filtering rules.
• Email management systems usually have
already encapsulated some services that
help to establish email-based social network
trust. For examples, managing labels or
folders to classify emails, statistic information such as email exchange frequency, priority level, email receiving dates, etc.
• Email IDs are unique, which can be easily
integrated with identity-based cryptography
system.
• Email trust can potentially provide a very
large trust database covering majority of
population, which can maximally benefit for
general users.

SECURITY ANALYSIS OF SAT
Similar to many secure mobile communication
systems, SAT needs to address various active
and passive attacks. For example, active adversaries can forge and inject malicious packets, or
modify and replay previously captured packets;
passive adversaries can also learn information
from captured packets. Traditional cryptography
based security services, e.g., Public Key Infrastructure (PKI), can be used to protect VANET
communication through authentication, confidentiality, and integrity security solutions. However, SAT is designed to assist these solutions to
counter the above described security threats in a
more effective way by proactively exploiting the
strategies and solutions proposed in the early
work that use PKI for security and privacy for
traditional entity trust and data-centric trust [1,
2]. Moreover, SAT integrates policy-based data
access control that cannot be effectively
addressed using PKI-based solutions.

SAT ARCHITECTURE
In this section, we first describe the system
model of SAT. Then, we present the basic construction of secure attribute-based policy
enforcement and group key management. Followed by the traffic management model to support proactive trust management, we present the
integration of email-based social network trust in
SAT.

SAT SYSTEM AND TRUST MODEL
The SAT system model includes vehicles, RoadSide Infrastructure (RSI), and Internet. The
RSI is composed by Road-Side Units (RSUs),
inter-connections among RSUs, and servers
running control and management functions.
Particularly, we assume a global trusted agent
that is in charge of the basic credentials distribution, e.g., keys are pre-installed through the
global trusted agent when a vehicle is manufactured or registered. Additionally, multiple local
trust agents can also be deployed when each is
responsible for situation detection, monitoring
and local trust management through RSUs in
their designated geographical areas. Both the
global trusted agent and local trusted agents

IEEE Communications Magazine • November 2010

HUANG LAYOUT

10/20/10

3:54 PM

Page 131

are inter-connected and can be reached by
vehicles through RSUs. Vehicles are equipped
with wireless communication devices to establish connections among vehicles and to RSI.
We also assume that inputs from GPS devices
or digital navigation systems are available to
provide locations or travel trajectories. The
vehicles include hardware and software that
supports general vehicle-to-vehicle (V2V) or
vehicle-to-infrastructure (V2I) communication.
They also have tamper resistance devices to
store critical data such as equipment identifier
(EID) and cryptographic keys. The existing
PKI-based secure communication package can
be installed as well [2].

CONSTRUCTING POLICY GROUPS FOR
VEHICULAR NETWORKS
Attribute-based cryptography [4] greatly
improves the efficiency of secure communication
among multiple vehicles. The efficiency is due to
the nature of using attributes that provide two
major benefits. First, specifying desired attributes
naturally incorporates data access control policies into the data encryption. The attributes
specified in a data access tree structure, which
will be illustrated later, are actually the data
access control policies enforced on the ciphertext. Second, the attribute-based cryptography is
suitable in a vehicular broadcasting environment,
where the message intended receivers cannot be
predefined through a group establishment procedure due to the mobility. Thus, using attributebased approaches, we can confine data access
based on various roles of vehicles. Such a policy
specific action makes the use of creating cryptography-binding policy groups [6]. For examples, cars can be classified based on their
functions or roles (e.g., police cars, ambulances,
general civilian vehicles, and commercial vehicles); and cars can also be classified as they are
designed for special functions or particular networking applications. Attributes can also be
dynamic according to on-road situations, such as
location, times, and events, which are considered
to form a policy group. Additionally, there are
many static attributes such as car types, affiliations that can help to construct an on-the fly
dynamic communication data access in an efficient way [7]. Each static attribute is associated
with a unique private key that is derived from a
global trusted party, e.g., Motor Vehicle Division
(MVD). The dynamic attributes and corresponding private keys can be derived from a local
trusted party, e.g., a local server connected
through an RSU. In this way, a decentralized
trust framework is formed by global and local
trusted parties. As a result, defining a policy
group is to define a collection of multiple
attributes and their logic connections (usually
are AND and/or OR gates)to allow data decryption by legitimated vehicles.
We present a policy tree example based on
the second illustrative scenario presented in
Introduction to highlight the salient features of
SAT to construct a cryptography-binding policy
group for dynamic data access control. Figure 2
left details a policy tree that defines the policy
formed by AND gates for the taxi car example

IEEE Communications Magazine • November 2010

AND

Taxi
CompanyA

Washington 10-11am
Street
3/28/08

A Policy Tree

AND

CompanyA

Taxi

AND

Static Tree
Dynamic
Tree

Washington 10-11am
Street
3/28/08

Figure 2. A policy tree example.
where location and time are mapped to a real
scenario. To differentiate the static and dynamic
attributes, a sub tree for dynamic attributes is recreated by connecting through another AND
gate to the static part (Fig. 2, right). This policy
tree represents the following policy enforcement:
attributes (company A ^ taxi ^ Washington St.
^ 10–11am : 3/28/08) ⎢⎢cipher⎢⎢ sigcompanyA.
(1)
The cryptographic method backing up the
above data access is for each attribute to be considered as a public key component. Thus, the
data access tree is a set of public key components and logic operators. The outcome of the
policy tree is the generation of the Data Encrypting Key (DEK) S for encryption and decryption.
This tree is sent with the ciphertext. The associated private key components should be available
at each associated vehicle. Whoever receives this
message will first to determine if it is an eligible
receiver, i.e., it must satisfy the policy tree, and
then it can compute the DEK S using its stored
private key components with respect to each
attribute in the tree. As a result, only vehicles
having the right set of the private keys can legitimately decrypt the ciphertext.
In Fig. 3, we present an example based on
Ciphertext-Policy Attribute-Based Encryption
(CP-ABE) [4]. In this example, attributes A1–A4
are arranged as leaves nodes of the attribute
tree, where each attributes is corresponding to a
set of secret key components S1–S4 assigned to
users u1–u3. We note that the private key components assigned u1–u3 are different even if they
own the same attribute. We use different colors
to highlight the difference of private key components. Thus, u1 has private key components {red:
S1, S2, S3, S4}, u2 has private key components
{green: S1, S2, S4}, and u3 has private key components {blue: S1, S2, S3}. The internal nodes of
the attribute tree are logical gates, such as AND,
OR, which are implemented using threshold
secret sharing scheme [8]. The secret S can be
reconstructed by using two secrets S′ and S″. At
the bottom level the encryption is performed
using identity-based encryption (IBE) [9], which
considers each attribute as a public key. S1–S4
are considered as the private keys for the corresponding attributes. To satisfy the AND gate, the
decrypter must have all the secrets to recon-

131

HUANG LAYOUT

10/20/10

3:54 PM

Page 132

S

Data
encrypting key

AND
Secret sharing
threshold gates

S‘
AND

Private key
components

S1

S3

S4
S4

S2

S1
Attributes

OR

S2

S1

S“

S2

S3

u1
u2
u3

A1

A2

A3

A4

Figure 3. Attribute-based encryption.

struct the higher level secret; to satisfy the OR
gate, the decrypter is only required to have one
of secrets at the lower level to reconstruct the
parent-level secret. In this way, the encryption
algorithm of CP-ABE is performed in a topdown manner by constructing the ciphertext to
the bottom level of the attribute tree; and the
decryption algorithm of CP-ABE is performed in
a bottom-up manner using the users’ pre-distributed secrets to reconstruct the higher level
secrets until derive the root-level secret (i.e., the
DEK). In this presented example, based on the
pre-distributed secrets, u1–u3 can decrypt the
secret S and thus they can access the data
encrypted by using the DEK S.
We must note that, using the presented
approach, it is efficient to enable multiple vehicles to access the message even if the message
sender does not know whether the receivers can
receive the message or not. This approach brings
the major benefit of flexibility in that the sender
does not need to negotiate a group key with the
intended receivers to send a message. However,
this also brings up a new problem, i.e., how to
create an attribute tree to effectively cover the
most intended receivers in VANETs. We will
address this question in the next section.

ESTABLISH PROACTIVE SAT TRUST IN VANETS
By dividing the information needed to access
messages into static and dynamic attributes, SAT
is able to identify various cases that the trust
information needed for each vehicle to collect
and propagate. More important, it is able to
help vehicles to predict future possible trust relations on the road. The way-point information
framework (WIF) [10] is a mechanism that SAT
uses to address the tight time constraints to
establish trust.
The data unit in WIF, namely, the way-point
information is composed by trajectory information bounded by approximated time stamps,
which can be derived from an embedded digital
navigation system. A typical way-point record
includes two types of information:

132

• Static attributes: Vehicle type, preferred
security policies, etc., which are derived
from the global trusted agent
• Vehicle moving properties: Moving direction, average speed, etc., which can help
local trust agents to predict the location of
the vehicle at a given time.
By knowing the way-point information from
each vehicle, a local trust agent can generate
appropriate dynamic attributes and help vehicles
to construct a policy group using both static and
dynamic attributes.
WIF can be applied using one or both of the
following approaches: a decentralized traffic prediction system with the help of RSI or a purely
distributed way-point information system model
when RSI is not available.
WIF with RSI Support — The inputs from a
navigator computation give the best paths to
given destinations, and predict future times and
locations based on the travel speed, direction,
and possibly global traffic information obtained
from the global and local trusted agents.
Clearly, road traffic conditions affect the
accuracy of way-point computations. Thus, we
associate a probability distribution to way-point
values. The way-point information is lightweight
and concise. It is only transmitted in every a few
minutes. RSI must maintain a set of local servers
(or agents) to collect and process way-point
information. This can be done very efficiently
using a Distributed Hash Table (DHT). The
DHT, or the Navigator Server (NS), maintains
up to date information on road traffic conditions. Typically, the global traffic database is
constructed by vehicles reporting their way-point
information to the NS.
A local agent generates the policy tree by
inspecting its traffic data base. Each vehicle gets
the dynamic attributes over a given time span by
interacting with the local agent that knows the
vehicle trajectory (from navigator) and the traffic database.
WIF without Support by RSI — To handle
RSI failures due to disaster, blackout, and unpredictable damages to RSI devices, a distributed
way-point information system model is required
in order to improve the failure resiliency of the
SAT model. We devise a backup system using
Way-point Geographic Hash tables (WGHT) to
store and retrieve the way-point information.
Our solution is inspired by the Grid’s Location
Services (GLS) implementation described in
[11]. In WGHT, a distributed hash table (DHT)
is established upon the vehicles. Basically, each
vehicle is considered as a server. The search
across various servers of the WGHT overlay is
accomplished using geographic routing, which is
made possible by relying on GPS support. In
SAT, we introduce a novel concept of virtual
peer. The virtual peer is one of the vehicles in an
area that is associated with a local policy agent.
The virtual peers in the WGHT store the waypoint information for vehicles. Many of these
areas and virtual peers create an overlay in
multi-hop vehicular networks. Thus a group of
vehicles will serve as a redundant distributed
storage server to store the way-point informa-

IEEE Communications Magazine • November 2010

HUANG LAYOUT

10/20/10

3:54 PM

Page 133

tion. A distributed information handoff scheme
is needed to make sure the way-point information is kept (and can be found) within the same
geographic area while vehicles move out and
move in.
SAT Performance Gain — The latency to
establish trust among vehicles is the most important performance issue. SAT addresses this
requirement by implementing a pre-trust-establishment phase before two vehicles need to communicate. In general, the latency in SAT is
mainly from two sources:
• Preparing policy trees that satisfy the originator’s security requirements
• Performing ABE algorithms to generate
cipher-text
The predictability of SAT through WIF allows
the reduction of latency by allowing each vehicle
to pre-fetch its dynamic attributes and hence
pre-compute the policy trees and ciphertext
(recall static attributes are always available to
vehicles). The performance gain using this
approach can be analyzed considering the following cases:
• When accurate dynamic attribute predictions are possible, the policy tree can be
pre-computed to bypass the traditional
handshaking during the V2V communication. Broadcasting messages can be within
tens of milliseconds with only message
encryption latency due to the ABE computation.
• When only partial dynamic attributes predictions are available, the system can still
benefit greatly from partial policy tree computations. When the predictions become
more accurate, vehicles can add their computation readily.
• Most of vehicles in a given zone will either
have complete predictions or partial results.
This locality feature can add to the overall
performance gain and improve the scalability.

INTRODUCING SOCIAL NETWORK TRUST IN
VANETS
SAT incorporates E-Mail-based Trust (EMT) to
complement cryptography-based solutions. In
general, social network trust can be applied in
the following two scenarios: the use of shared
keys or public key certificates is not available,
and data trust cannot be easily evaluated through
traditional methods, such as using majority rule,
watch dog solutions, etc. We must note that SAT
utilizes social network trust to bootstrap the
inter-vehicle trust. SAT is not restricted by scope
of EMT. Here, we use EMT as an illustrative
example. SAT is based on the social network
trust established among email contacts through
their email-based activities. Particularly, in SAT,
we address the following three email-based
social network trust functions:
• Measuring trust between an email user and
his/her contacts;
• Protecting email users’ privacy during the
social network trust establishment procedure; and
• Interfacing email-based social network trust
into VANETs related security functions.

IEEE Communications Magazine • November 2010

To address the first function, each user will
run an email trust checking agent (TCA) software. It performs the following two main operations: sending trust checking requests and
performing trust checking and ranking. After
two users exchange their email addresses, the
TCA will perform trust checking based on each
other’s email addresses through a trusted EMT
server. Current trust model using EMT services
is similar to the existing on-line web services,
such as Amazon, in which each user needs to tell
his/her private information to service providers.
Thus, to use EMT services, a user needs to register in an EMT server (a prototype is developed
in [5]). The EMT server performs statistic analysis of the email inbox to ascertain its trust level
based on statistical analysis on several email
exchanging activities, e.g., email exchange frequency, inbound ratio, outbound ratio, etc. In
general, more frequent, recent, and balanced
email exchanges represent higher trust level.
To address the second function, as shown in
Fig. 4, we present email domains based on their
usage scopes, i.e., personal emails, business
emails, and public emails that can be used as
anonymized email IDs. Each block represents a
trust domain with respect to the user’s email
addresses with trust-ranked contacts. For examples, the trust levels in a private trust domain
can be classified as: highly trusted, trusted, and
un-trusted. For the working domain, similar trust
structure or more scrutinized hierarchical trust
models can be defined. For the public domain,
we consider the EMT server as a trusted party
and it cannot be compromised or expose users’
private information. During the registration procedure, a user needs to provide a mapping
between his public email address (serves as a
pseudonym) and email addresses in the private
or working domains. Moreover, the EMT service
will access email servers in each domain to
retrieve statistical email data of corresponding
registered email accounts.
For the third function, obtaining email-based
trust is initiated by a TCA residing in the vehicle’s onboard unit or a passenger’s cell phone.
Each TCA broadcasts the user’s public email ID
periodically to look for trusted peers. Upon
receiving an email ID, the receiving TCA runs a
trust search protocol through the EMT server to
evaluate the trust level of the received email ID.
Based on the email trust social graph built at the
EMT server, the trust evaluation results are
returned to the vehicle or the user’s device.
Cryptography and secure policies can be integrated by considering the email ID as an
attribute. This requires the corresponding private key component be pre-installed through the
global trust agent. In this way, the data encrypting key can be finally calculated using the proposed policy tree scheme.

The predictability of
SAT through WIF
allows the reduction
of latency by
allowing each vehicle
to pre-fetch its
dynamic attributes
and hence
pre-compute the
policy trees and
ciphertext (recall
static attributes are
always available to
vehicles).

DEPLOYMENT AND
IMPLEMENTATION CONSIDERATIONS
SAT is composed by several interrelated key
components including policy enforced data
access control mechanism, proactive and predictive way-point information collection and distri-

133

HUANG LAYOUT

10/20/10

3:54 PM

Page 134

Private trust domain
Personal
email

Working trust domain
Business
email

Address

Address
Trust
rankings

Contacts
*Crypto keys

Contacts

Trust
rankings

*Crypto keys

Public domain
Anonymized
email
Addresses/pseudonyms
Trust
rankings

Contacts

Example: (private,
working, public) email IDs
Alice:
Alice@example.net
Alice@company.com
A’@gmail.com
Bob:
Bob@example.net
Bob@company.com
B’@gmail.com

*Crypto keys

Figure 4. EMT architecture.

bution framework, and social network trust
model. The proposed new trust infrastructure is
driven by new development of technologies.
Many wireless technologies are ready for
VANETs. For example, Dedicated Short-Range
Communications (DSRC) and IEEE 802.11p
are ready to support short range and low latency communication; 3G and WiMax can support
reliable and fast data delivery; the functionalities of digital navigation systems become more
accurate and widely used. In [12], a novel mobile
cloud framework is presented to utilize cloud
computing techniques to promote the development of various mobile services for mobile
users. Particularly, the trust management services, e.g., certificate services, social network
trust services, credential management services,
dynamic/static attributes, and corresponding private key management services, proactive and
predictive trust management services, way-point
information collection and distribution services,
and way-point information database services,
can be handled by emerging cloud computing
technologies.
Apart from emerging VANET and cloud
technologies, the applications based on intervehicle communication have proliferated recently, ranging from critical safety driving to
commercial services, such as location-based
advertising, content delivery, urban sensing, and
storage. Various vehicle social networks have
been implemented, e.g., RoadSpeak [13]. However, the major obstacle that prevents social network technologies from being adopted for
VANETs is a lack of efficient and user-friendly
interfaces to VANET applications. A tremendous software development effort is required to
bridge the gap between theory and applications
of social networks to real VANET applications.

134

Moreover, social network trust usually exhibits a
certain preference based on the nature of the
analyzed social domain. When the derived social
network trust is applied to another application
domain, the social network trust may not fit well
into the new application domain. Thus, it is critical to analyze the similarity between the social
network trust and a given application domain to
minimize the divergence of applying the social
network trust.
The proposed SAT architecture resides on
various network devices, including vehicles,
roadside units and servers sitting inside the
wired infrastructures. At system level, the Security Policy Management (SPM) and Vehicle
Trust Processing (VTP) are two required components. The SPM component consists of a global trusted agent and local trusted agents to
distribute cryptographic keys, and to manage
static and dynamic security policies. The global
and local agents connect to vehicles through the
way-point information framework. The VTP
component runs on each vehicle. It handles sensing, event perception, analysis and SAT related
network protocols. It supports the interactions
among the global and local agents, and runs the
SAT prediction protocols. Its networking services include cryptographic operations and communication protocols. As the two components
interact, the security policy is determined and
access permits can be verified.
With the development of vehicular technologies, installing cryptographic keys in vehicles can
be practically possible in near future. But the
major issue for implementing and deploying the
SAT techniques is the availability of trust infrastructure required to host the proposed local
trust agents and global trusted agents. Some
cryptographic credentials can be established offline with long lived validity; others, more dynamic credentials are obtained as the car joins the
VANET and travels through the urban grid. On
the other hand, the PKI based secure vehicle
communication techniques for securing vehicular
communication [1, 2] can be used underlying the
primitives for SAT.

CONCLUSIONS
Vehicular Situation-Aware Trust (SAT) architecture targets to build a fundamental trust
platform to handle various road situations. To
this end, we present a policy enforcement system utilizing identity and attributed-based cryptography to achieve group-based data access
control. We also presented away point information collection and dissemination framework to
address the communication and computation
latency issues due to the highly dynamic nature
of VANETs. Lastly, we present how to incorporate social network trust model for vehicular
systems, which can greatly improve the incentive of users to adopt new vehicular technologies and applications. In the future, great efforts
are needed on both the in-vehicular system and
RSI to enable SAT. These efforts include
deploying global and local trust agents using
cloud computing techniques, tackling the privacy issues of using social network trust, and conducting field test.

IEEE Communications Magazine • November 2010

HUANG LAYOUT

10/20/10

3:54 PM

Page 135

REFERENCES

BIOGRAPHIES

[1] P. Papadimitratos et al., “Secure Vehicular Communication Systems: Design and Architecture,” IEEE Commun.
Mag., vol. 46, no. 11, 2008, pp. 100–9.
[2] F. Kargl et al., “Secure Vehicular Communication Systems: Implementation, Performance, and Research
Challenges,” IEEE Commun. Mag., vol. 46, no. 11,
2008, pp. 110–18.
[3] X. Hong et al., “Sat: Building New Trust Architecture for
Vehicular Networks,” Proc. 3rd ACM MobiArch, 2008,
pp. 31–36.
[4] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-Policy Attribute-Based Encryption,” Proc. IEEE Symp. Security & Privacy, 2007, pp. 321–34.
[5] D. Huang et al., “Establishing Email-Based Social Network Trust for Vehicular Networks,” Proc. IEEE CCNC,
2010, pp. 1–5.
[6] D. Huang, W.-T. Tsai, and Y-hsin Tseng, “Policy Management for Secure Data Access Control in Vehicular
Networks,” J. Net. Sys. Management, 2010.
[7] N. Chen et al., “Secure, Selective Group Broadcast in
Vehicular Networks using Dynamic Attribute Based
Encryption,” Proc. 9th IFIP Annual Mediterranean Ad
Hoc Net. Wksp., 2010.
[8] A. Shamir, “How to Share a Secret,” Commun. ACM,
vol. 22, no. 11, 1979, pp. 612–13.
[9] D. Boneh and M. Franklin, “Identity-Based Encryption
from the Weil Pairing,” Proc. 21st Annual Int’l. Cryptology Conf. Advances Cryptology, 2001, pp. 213–29.
[10] Y. Qin, D. Huang, and V. Nagarajan, “Towards Delay
Tolerant Attribute Based Group Communications in
VANETs,” ASU Tech. Rep., 2010;http://dj.eas.asu.edu/
snac/document/WIF.pdf.
[11] J. Li et al., “A Scalable Location Service for Geographic
Ad Hoc Routing,” Proc. 6th ACM MobiCom, 2000, pp.
120–30.
[12] D. Huang et al., “Mobicloud: Building Secure Mobile
Cloud Framework for Mobile Computing and Communication,” Proc. 5th IEEE Int’l. Symp. Service-Oriented
Sys. Eng., 2010.
[13] S. Smaldone et al., “Roadspeak: Enabling Voice Chat
on Roadways using Vehicular Social Networks,” Proc.
1st IEEE Int’l. Wksp. Social Net. Sys., 2008, pp. 43–48.

D IJIANG H UANG [M] (dijiang@asu.edu) received his B.S.
degree from Beijing University of Posts & Telecommunications, China 1995. He received his M.S., and Ph.D.
degrees from the University of Missouri-Kansas City, in
2001 and 2004, respectively. He is an Assistant Professor
in the School of Computing Informatics and Decision
Systems Engineering (SCIDSE) at the Arizona State University. His current research interests are computer networking, security, and privacy. He is a recipient of Office
of Naval Research (ONR) Young Investigator Award
2010.

IEEE Communications Magazine • November 2010

In the future, great
efforts are needed
on both the
in-vehicular system
and RSI to enable
SAT. These efforts
include deploying

XIAOYAN HONG [M] (hxy@cs.ua.edu) is an associate professor in the Department of Computer Science at the University of Alabama. She received her Ph.D. degree in
Computer Science from the University of California, Los
Angeles in 2003. Her research interests include mobile
and wireless networks, challenged networks and future
Internet. Her current research focuses on mobility, routing, bio-inspired communications, and wireless network
trust and privacy.

global and local trust

M ARIO G ERLA [F‘02] (gerla@cs.ucla.edu) is a Professor in
the Computer Science at UCLA. He holds an Engineering
degree from Politecnico di Milano, Italy and a Ph.D.
degree from UCLA. At UCLA, he was part of the team
that developed the early ARPANET protocols under the
guidance of Prof. Leonard Kleinrock. He joined the
UCLA Faculty in 1976. At UCLA he has designed and
implemented network protocols including ad hoc wireless clustering, multicast (ODMRP and CODECast), and
Internet transport (TCP Westwood). He has lead the
$12M, 6 year ONR MINUTEMAN project, designing the
next generation scalable airborne Internet for tactical
and homeland defense scenarios. He is now leading
two advanced wireless network projects under ARMY
and IBM funding. His team is developing a Vehicular
Testbed for safe navigation, urban sensing, and intelligent transport. A parallel research activity explores personal communications for cooperative, networked
medical monitoring (see www.cs.ucla.edu/NRL for
recent publications).

trust, and conduct-

agents using cloud
computing
techniques, tackling
the privacy issues of
using social network
ing field test.

135

Demo: LIVES: Learning through Interactive Video and
Emotion-aware System
Min Chen

Yixue Hao

Yong Li

EPIC Lab
Huazhong Univ. of Science
and Technology
Wuhan, China

EPIC Lab
Huazhong Univ. of Science
and Technology
Wuhan, China

Department of Electronic
Engineering
Tsinghua University
Beijing, China

minchen@ieee.org

yixue.epic@gmail.com

liyong07@tsinghua.edu.cn
Dijiang Huang

Di Wu
School of Info. Sci. & Tech.
Sun Yat-Sen University
Guangzhou, China

Department of CSE
Arizona State University
Arizona, USA

wudi27@mail.sysu.edu.cn Dijiang.Huang@asu.edu
ABSTRACT

1

In order to improve the accuracy and efficiency of emotion recognition, we design a novel system called Learning through Interactive
Video and Emotion-aware System (LIVES). LIVES includes data
collection, emotion recognition, and result validation, as well as emotion feedback. We adopt transfer learning to label and validate
moods in LIVES, while the emotion can be classified into six types
of mood in a reasonable accuracy. Through transfer learning, the
time-consuming and labor-intensive processing cost on data collection and labeling can also be greatly reduced. In our prototype
system, LIVES is used to enhance an emotion-aware robot’s intelligence provided by cloud. LIVES-based emotion recognition is
executed in the remote cloud while corresponding result is sent to
the robot for emotion feedback. The experimental results demonstrate LIVES significantly improves the accuracy and effectiveness
of emotion classification.

0.9
0.8

Accuracy

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

happiness

sadness

fear

anger

disgust

surprise

Figure 1: Accuracy of mood recognition

Keywords
Affective interaction, transfer learning, sentiment anlysis

feedback. Especially, LIVES explores transfer learning on top of
robotics and cloud-terminal integration technologies.

1. INTRODUCTION

2. LIVES FRAMEWORK
2.1 LIVES Description

Nowadays, there are lots of works on emotion recognition. Previous work on emotion recognition can be categorized as follows:
(1) body signal-based recognition [4]; (2) audio-visual data based
recognition, including method through face video processing [5],
and (3) recognition based on the usage pattern of smartphone [7].
However, it is challenging to fuse large-scale heterogeneous emotion data in multi-dimensional spaces for analyzing user’s emotion while proactively activating surrounding hardware resources
to perform personalized actions to comfort user’s emotion. LIVES
based solution is the first to tackle above challenges through multispace emotion data collection, emotion recognition, validation and

In LIVES, user’s physical, cyber and social domain’s data are
first collected by wearable device, mobile devices and network devices. Physical data include physiological data, activity level, location, environmental and face/interactive video. Cyber data consist
of call, SMS, email, application usage, WiFi and network control.
Social network data include SNS content or image post, repost and
comment. Then, the data are preprocessed. After preprocessing,
we extract the data feature. For the emotion space, the data are
labeled and validated by transfer learning based on previously labeled results. Now we introduce the label and validate phase. In the
label phase, the source domain data xs input come from ten users’
personal information in terms of physical data, cyber and social network data and moods. The target domain data xt input data come
from other personal information. Our goal is to estimate the mood
c probability p(c|xt ), since the xs and xt may be in a different feature space, So we first need to find a translator to link the two feature spaces [3]. since the fs and ft are features and are conditionally independent xs , where xs ∈ χs , so we can calculate p(fs , ft ) as

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact
the Owner/Author.
Copyright is held by the owner/author(s).
MobiHoc’15, June 22–25, 2015, Hangzhou, China.
ACM 978-1-4503-3489-1/15/06.
http://dx.doi.org/10.1145/2746285.2764928 .

399

6HQVRU\'DWD

3UHSURFHVVHG'DWD

5RERWUHTXHVWVWRFRQQHFWWR'&

6PDUW$3IRUZDUGVURERWಬVUHTXHVWWR'&

6PDUW$FFHVV3RLQW$3
/7(EDVHVWDWLRQ

'DWD&HQWHU'&

5HIUHVKRSHQDQGFORVH
VHULDOSRUW

$IIHFWLYH)HHGEDFN

5HIUHVKRSHQDQGFORVH
VHULDOSRUW

6PDUW$3IRUZDUGVWKH
FRPPDQGWRURERW

$IIHFWLYH)HHGEDFN
'&JLYHVFRPPDQGWRURERW

&RQQHFWWR/7(EDVHVWDWLRQ

(PRWLRQDZDUH
$FWLRQV
&RRUGLQDWHGE\
5RERW

&RQQHFWWR/7(EDVHVWDWLRQ

/7(FHOOSKRQHHTXLSSHGLQ
(3,&URERWಬVKHDGSRVLWLRQ

/7(FHOOSKRQHHTXLSSHGLQ
(3,&URERWಬVKHDGSRVLWLRQ

(a)

(b)

(c)
Figure 2: LIVES based Testbed: (a) System architecture; (b) Control messages shown in LTE cell phone; (c) Test scenario.
∫
the robot via TCP protocol. Fig. 2(b) illustrates control messages
follows: p(ft , fs ) = χs p(ft , xs )p(fs |xs )dxs , Now we link the
shown in LTE cell phone. In Fig. 2(c), we use LIVES to predicate
unlabel feature ft and xs through Jensen-Shannon divergence. In
the user’s mood compared with the mood given by users, we can
the validation phase, We overhear users’ input of their own emotion
obtain the accuracy as shown in Fig. 1, where the recognition of
when they use some applications such as Moodagent. But one prinuser’s moods is achieved with acceptable accuracy which is higher
cipal problem is that, the mood we overhear is not the same as mood
than Moodscope [7]. When we find people in a unpleasant mood,
label space C. Thus, we need to compare the similarity of the label
we use robot to do some interactive actions to care user’s mood.
space C and the user’s input mood as M = {m1 , . . . , mn } which
is collected in each time slot as ground-truth label. Using a frameAcknowledgment
work similar to transfer learning [6], we can find the similarity be2
Many thanks to Yujun Ma, Yin Zhang, Hang Ruan, Wenye Wang,
tween mood c and m as follows: sim(c, m) = MMD [Dc , Dm ],
Shan Zhao, Chuanbei Wu for making tremendous system-building
The MMD2 [Dc , Dm ] is the maximum mean discrepancy [1], we
efforts on the testbed, where LIVES experiments are run.
validate the label which the most similar in C, Through transfer
learning the time-consuming and labor-intensive processing cost
3. REFERENCES
can be reduced extensively. After a certain time of labeling and val[1] K. Borgwardt, A. Gretton, and et al. Integrating stuctured
idation through transfer learning, the training sets are established.
biological data by kernel maximum mean discrepancy. In
By the utilization of Hidden Markov model, the emotion data are
Proc. of ISMB’06, 2006.
classified into six mood. These mood classification results are for[2] M. Chen, Y. Zhang, Y. Li, and et al. Aiwac: affective
warded to EPIC robot which is developed in Embedded and Pervainteraction through wearable computing and cloud technology.
sive Computing (EPIC) lab. During emotion feedback stage, EPIC
IEEE Wireless Communications, 22(1):20–27, Feb. 2015.
robot system carries out hardware resource cognition then performs
[3]
W.
Dai, Y. Chen, G.-R. Xue, Q. Yang, and Y. Yu. Translated
a series of actions to comfort user’s emotion using Markov decision
learning:
Transfer learning across different feature spaces. In
process. For example, a personalized video will be shown in an
Proc. of ACM NIPS. ACM, 2008.
available screen such as a projector. If the user is not satisfied with
[4] A. Gluhak, M. Presser, L. Zhu, and et al. Towards mood based
the emotion feedback actions, video contents and display method
mobile services and applications. In Proc. of ACM EuroSSC,
can be fine tuned through continuous learning until user’s emotions
pages 159–174. ACM, 2007.
are cared more accurately and efficiently. This is called feedback
[5]
J.
Hernandez, M. Hoque, W. Drevo, and R. Picard. Mood
data through the interaction between user and system. In order to
meter: Counting smiles in the wild. In Proc. of Int’l Conf. on
improve the accuracy of emotion recognition, we use physical data,
Ubiquitous Computing (UbiComp), pages 301–310. ACM,
cyber data, social network data and feedback data in next time.
Sept. 2012.
[6] D. H. Hu, V. W. Zheng, and Q. Yang. Cross-domain activity
2.2 Demonstration
recognition via transfer learning. Pervasive and Mobile
As shown in Fig. 2(a), we implement LIVES in AIWAC testbed [2],
Computing, 7(3):344–358, 2011.
which consists of robot, smart access point (AP), and data center
[7]
R.
LiKamWa, Y. Liu, N. D. Lane, and L. Zhong. Moodscope:
(DC). The testbed provides a version of software available to run in
Building a mood sensor from smartphone usage patterns. In
Linux in the DC, which generates command queue according the
Proc. of ACM MobiSys’13, pages 84–89. ACM, June 2013.
analyzed mood and these commands are transmitted from DC to
3DJH

3DJH

400

2015 3rd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering

978-1-4799-8977-5/15 $31.00 © 2015 IEEE
DOI 10.1109/MobileCloud.2015.29

177

178

179

180

181

182

2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications

VehiCloud: Cloud Computing Facilitating Routing
In Vehicular Networks
Yang Qin and Dijiang Huang

Xinwen Zhang

Arizona State University
Tempe, Arizona, USA
yang.qin.1, dijiang@asu.edu

Huawei Research Center
Santa Clara, CA USA
xinwen.zhang@huawei.com
predict future trafc information by collecting the trajectory
information of MSNs. Moreover, with the awareness of the
dynamic network topology, VehiCloud helps reduce the routing and communication uncertainty, which is especially critical
in vehicular network with high mobility. More than this, the
cloud is also capable of utilizing MSNs mobility and resource
to carry and forward messages.
Routing in vehicular networks has been considered as a
challenging task, with consideration of various factors, including vehicles mobility patterns, the ability of vehicles
to carry messages to different locations, and the availability
of Internet connections at roadside infrastructure. Moreover,
variant communication channels (e.g., ad hoc wireless channel
and the Internet connection) have different levels of reliability
in a location, which leads to various end-to-end delays and
communication costs. A good routing strategy should take all
these for an optimized and dynamic decision. Uniquely with
cloud-based architecture, VehiCloud introduces a way-point
information framework (WIF) to enable routing service for
highly mobile and dynamic topologies in vehicular networks.
In WIF, an MSN generates way points by anticipating its future
locations. A cloud decision module (DM) collects the way
points of MSNs through terminals (i.e., RSUs and vehicles
with Internet access). With this information, the DM constructs
a time-space link graph (TSLG) to model the entire network.
The TSLG is not only a snapshot of the network topology.
Instead, all topology changes within a certain time are captured
by the TSLG. Assisted by the TSLG, the DM is then able
to make globally optimal routing decisions for inter-vehicle
communication in temporal and dynamic manner, empowered
with the elastic computing resources of underlying cloud
platforms.
This paper has the following contributions:
1) We design and implement VehiCloud, transforming traditional vehicular networks into a service-oriented architecture,
and provide a potential platform to address several fundamental problems in vehicle networks including reliable routing.
VehiCloud maximally takes the advantage of each vehicle in
the system by utilizing cloud computing technologies;
2) We model the highly dynamic network topology as
a time-space link graph (TSLG). A TSLG includes three
types of communication links in vehicular networks: the ad
hoc wireless channels, the carry-and-forward links (i.e., the
operation of a vehicle carrying a message for some time and

AbstractEstablishing reliable routing among highly mobile
vehicles is a challenging problem in vehicular networks. Towards
this issue, we present VehiCloud, a novel cloud computing
architecture that leverages emerging cloud computing technologies to deal with unreliable inter-vehicle communications and
extend the restricted computational capabilities of mobile devices.
A way-point information framework (WIF) is devised within
the VehiCloud architecture, aiming to provide routing service
for vehicular network, where each vehicle serves as a mobile
service node and predicts its future locations by generating way
point messages, which describe the trajectory of the vehicles
movement. A decision module in VehiCloud collects vehicles way
points and makes routing decisions for inter-vehicle communication. Selected paths of the routing are globally optimized in
terms of message delivery ratio by respecting the constraints of
end-to-end delay and communication cost. Our implementation
of VehiCloud and real-road experiments demonstrate that it is
practical and efcient to address fundamental routing problems
for vehicular networks.
Index Termsvehicular networks; routing; mobile cloud;

I. I NTRODUCTION
Traditional vehicular networks are mostly established based
on pure ad hoc communication. Consequently, inter-vehicle
communication is unreliable because of the high mobility of
vehicles. Moreover, a vehicles communication and computation capabilities are constrained by the limited resources
of its on-board devices. On the other side, the development
of wireless communication technologies makes inter-vehicle
communication systems heterogeneous. For example, with
pervasive roadside infrastructures, vehicles can often access
the Internet via Vehicle-to-Infrastructure (V2I) channels. In
addition, with advanced wireless access technologies such
as 3/4G, LTE, and WiMax, vehicles can access the Internet
with longer communication distance than traditional shortdistance and low-speed wireless communication technologies.
Thus, we envision that vehicular network will eventually
become a mobile extension of the Internet. Following this,
mobile cloud computing (a.k.a., MobiCloud) is an emerging
technique [1] [2] that has been fundamentally changing the
research and development of mobile applications. With the
light of this trend and maturing related technologies, we devise
VehiCloud, a novel mobile cloud infrastructure for vehicular
communication system.
In VehiCloud, each vehicle is treated as a Mobile Service
Node (MSN), which monitors its own movement as well
as predicts its future locations. As a result, the cloud can
978-0-7695-4745-9/12 $26.00 © 2012 IEEE
DOI 10.1109/TrustCom.2012.16

1438

then forwarding it), and the Internet connections. Compared
to a conventional network connectivity graph which is just
a snapshot of a network topology, TSLG includes a time
dimension. That is, the topology changes of the network within
a certain duration are all mapped into a single graph;
3) We address the fundamental routing problem in vehicular
networks with VehiCloud, by modeling routing as a linear
program. The routing decision is globally optimized in terms
of the message delivery ratio by considering the constraints
on end-to-end delay and communication cost.
The rest of the paper is organized as follows. We describe
the VehiCloud architecture in Section II, and present the details
of the cloud routing service in Section III. In Section IV, we
present experiment details and analyze the results. We present
related work in Section V, and conclude this paper at the end.
.

RSU

RSU
RSU

Cloud Decision
Module

INTERNET

Wireless Ad
Hoc Links

Wired
Links

Fig. 1.

3/4G Links

Basic VehiCloud Architecture.
TABLE I
A SAMPLE WAY POINT

vid
123ABC

gt
12:00

ft
12:15

fp
   

pb
1.0

II. V EHI CLOUD A RCHITECTURE OVERVIEW
III. V EHI CLOUD ROUTING S ERVICE
In this section, we present how to establish the routing
service in VehiCloud. To achieve our goal, we devise a waypoint information framework (WIF) as follows.

We assume that every vehicle has an on-board unit (OBU),
including a built-in navigation system (NS) (e.g., GPS), with
maps and locations of available roadside units (RSUs). The
NS is also capable of anticipating the approximate locations
of the vehicle at certain points of time in the future, based on
path calculation and driving history mining.
Both OBUs and RSUs have wireless communication devices. The RSUs are sparsely distributed in the transportation system. Some of the OBUs have broadband wireless
communication capabilities, e.g., 3/4G cellular communication
devices, WiMax, and they can always connect to the Internet.
Some of the OBUs only have short range communication
capabilities, e.g., WiFi or Wireless Access in Vehicular Environment (WAVE). These OBUs usually can communicate
with each other or with RSUs within the range of up to
1,000 meters depending on the devices capability and channel
quality. In this hybrid vehicular networking environment, some
public vehicles (e.g. buses, police cars, etc.) are equipped
with broadband wireless devices. Other vehicles can use these
public vehicles and RSUs as access points to access the
Internet. These access points are called terminals in this
article. The public vehicles are the mobile terminals while
the RSUs are the xed terminals.
As we can see in Fig.1, OBUs and RSUs jointly form a
vehicular ad hoc network. The terminals serve as access points
to the Internet, upon which VehiCloud is established with
the heterogeneous communication mechanisms. Each MSN,
i.e., a vehicle, serves as a mobile agent, which predicts its
own moving trajectory, monitors certain conditions in certain
area, and performs other lightweight tasks such as message
transmission as needed. For instance, the MSNs generate their
way points by anticipating their future locations at certain
future time points. On the other hand, these MSNs are free of
computation and resource intensive tasks, such as data mining,
machine learning, and large-scale optimization. These tasks
are executed by a decision module empowered by traditional
cloud computing clusters.

A. Way points
A way point is essentially a pair of values: a given time
and its corresponding position for a vehicle. The time can be
the current time or a future time. The value of the position
is typically a geographic location. That is, the way points tell
the vehicles current and future locations.
We formally dene a way point as a tuple of ve attributes:
vehicle ID (vid), generation time (gt), future time (ft), future
position (fp) and probability (pb). A sample way point is
given in Table I. This way point is generated by the vehicle
123ABC at 12:00pm. It describes that the vehicle will be at
the location     at time 12:15 and the probability for
this prediction to be true is 1.
A vehicle usually generates a sequence of way points in a
batch, namely a way-point vector (W-Vector). The way points
in a W-Vector are generated for the (future) time points with
a given time interval (usually a xed time interval). Multiple
way points may be generated for the same time, which means
the vehicle would be at multiple possible locations at that time.
We say that a way point expires when its future time
has passed. A way point becomes inactive when it expires,
otherwise it is considered active. Two way points  and 
are considered to be adjacent if and only if they are from
the same vehicle, and for any way point  generated by
the same vehicle, we have   
      or
        . That is, there is no way points
generated by the same vehicle for the future time ( ) during
the future time interval    .
After generating the way points (or a W-Vector), a vehicle
(performed by its OBU) sends them to its nearest terminals.
The way points can be directly sent to an encountered mobile
terminal, or to a nearby xed terminal using geographic
routing. Here, we assume that every NS is aware of the exact

1439

locations of xed terminals, as mentioned in Section II. Upon
receiving a W-Vector, the terminal forwards it to the VehiCloud
decision module, which will be presented in the next section.

time

(c)

B. Service Decision Module
Given the way points collected from vehicles and the
locations of all xed terminals, the cloud decision module (the
DM, see Fig.1) is responsible for making the routing decision
by constructing a time-space link graph (TSLG).
1) The Time-Space Link Graph: If the network is static, the
network topology can easily be mapped to a simple link graph,
with vertices representing the network nodes and edges representing the communication channels between these nodes.
However, vehicular networks are not static. Vehicles usually
move in high speed and the network topologies keep changing
as time elapses. The TSLG     is a unique way of
handling time lapse and mobility in vehicular networks. It is
designed to map the changing network topology (over a certain
time period) onto a single graph. That is, the TSLG actually
adds the time dimension into a normal network connectivity
graph. In addition, the TSLG needs to model all possible
information-transfer links as its edges, including carry-andforward links (i.e., a vehicle carries the information from
one location to another), ad hoc wireless links, and Internet
connections. To illustrate the TSLG, we present an example
in Fig.2, in which multiple vertices are created to represent a
single entity (e.g., a vehicle) at different points of time (the
vertices connected by vertically directional edges in Fig. 2).
These vertices have completely different edges associated, reecting the topology changes due to mobility at different time
points. For example, two vertices representing two vehicles at
time  are disconnected, since at that time these two vehicles
are not within each others communication range; however,
the two vertices representing the same two vehicles at time 
are connected (by directional edges in both direction), which
means the two vehicles meet each other and an ad hoc wireless
channel between them exists at that time. On the other hand,
all vertices representing a RSU should have edges associated
which stand for the Internet connection available at all time.
In the following presentation, we describe the construction
of the TSLG. In TSLG, a physical entity can be represented as
multiple vertices in the graph. The edges between vertices that
represent different entities stand for can-ow, i.e., a message
can ow from one physical entity to a different entity, and the
edges between vertices that represent the same entity stand for
can-carry, i.e., the same physical entity can carry a message
for a certain time period.
The vertex set  is comprised of several subsets:
  





(e)
(h)

t3







(i)

(a)

(f)

(b)

S

(f)
(g)

R

Vc
t2

(h)

(d)

S

R

t1
(g)

I

Fig. 2.

F

WT

WO

Ms/Mr

The time-space link graph.

a mobile terminal, it also has a corresponding vertex   .
In addition, at the graph construction time, the DM enumerates
all different values of the active way points future times1 .
And for each future time point , a vertex   is created to
represent the Internet at that time. Similarly, a vertex  
represents the instance of the xed terminal (RSU)  at the
future time point .
In TSLG, every vertex  has a probability  , which is
dened as follows:





   
  

That is, the probabilities of vertices in  (representing the
way points) are determined by the way points probability
values. All other vertices have the probabilities of 1.
Each edge   has the following attributes attached: the
probability ( ), delay ( ) and cost ( ). First, we dene that
the probability of any edge equals to the probability of its
source (starting) vertex:


 

The edge set  is constructed according to the following rules.
Please refer to Fig. 2 for examples of each rule.
(a) Let          where        . We
have
     

 







Every edge       is directed, pointing from  to
 . This means that there is no backward link from a later
point of time to an earlier time. In other words, a message
cannot be sent back in time. For the delay and cost, we have
     and   , respectively.
(b) Let         
 be the vertices representing the xed terminal  at different points of time, where
       . We have



where  is a single vertex representing the cloud decision
module (DM). Each entity (vehicle or xed terminal)  has
two vertices: 
 and 
 , which stand for
the entity as a sender and receiver, respectively. We call 
the sender vertex and  the receiver vertex of . Each way
point  corresponds to a vertex   . If  is generated by

         

 







Data ow going through these edges means that the data is
carried by the terminal (RSU) for a certain period. Thus, the
1 Please

1440

refer to Section III-A for the denition of active way points.

edge delay is the interval between the two points of time, and
the cost is 0:         
(c) There are two symmetric edges       and  
    between vertex   and vertex 
 if and
only if    . That is,
       

 

   

vehicles, they have the same future time, and the geographic
distance between their future positions is less than ; (ii) one
of them represents a RSU instance at a certain point of time,
the other corresponds to a way point of the same future time,
and the distance between the way points future position and
the RSU is less than a communication threshold . Thus, we
have



These edges represent the Internet connections at RSUs. The
edge delay and cost are determined by the properties of the
local Internet connections:            
where we use  and  to denote the delay and cost of
the local Internet connection, respectively. Though we use the
same notations, the values of them can vary at different RSUs.
(d) Similar to RSU, each mobile terminal has Internet
access. Thus, there are also two symmetric edges      
and       between vertex   and vertex  
if and only if    , where   is the future time of the
way point . Then, we have:
       

  

    

         

  



  

    





   

  

  

  
   

  

  





 




 



Similarly , for each xed terminal  , there are edges from the
sender vertex   to all its vertices in F, and edges from
all its vertices in F to the receiver vertex   :
   

  





   

  





These edges have 0 delay and cost:      
(i) Lastly, there is an edge  from the vertex of the DM ( )
to every vertex representing the Internet:
   





The delay and cost of the edge depends on the property
of the Internet connection (as described in (c) and (d)):
        Since the DM does not provide data
transmission service and it only disseminates routing decisions
to vehicles, there are no reversed edges back to the DM.
The TSLG construction strategy described above assumes
that the message transmission delay (over an Internet connection or wireless channel) has negligible impact on the network
topology. For example, if vehicle A is directly connected to
 when vehicle B is directly connected to  , we
assume that if A sends a message to  who then sends
the message to  via Internet, B can still receive the
message from  because it has not moved out of  s
communication range. The assumption is usually sound, considering the vehicles moving velocity and communication

 


In this case, the delay of the edge is set to the time duration
between the future times of  and  , and the cost of the
edge is set to :            
(g) Two vehicles located within each others communication range can have a direct link between them. Therefore,
there should be two symmetric edges  and  between two
vertices in one of the following two cases: (i) the two vertices
correspond to two way points generated by two different
2 See

       

where  denotes the position of the RSU  . In these two
cases, the edge delay is set to the transmission delay ( )
of a direct wireless channel, and the edge cost if set to 0:
          
(h) For each vehicle  (whose ID is  ), there are edges
from the sender vertex   to all its way points, and
edges from all its way points to the receiver vertex   :



       



         

Obviously, the edge delay and cost are both 0 in this case:
     
(f) A moving vehicle can carry a message from one spot
to another and then forward it to others. Such carry-andforward links are modeled by the edges between adjacent way
points2 . For any two vertices   
 or   
 , there is an edge       from  to  if and
only if  and  are adjacent and      . Note that
the two adjacent way points may be generated within a single
W-Vector or two different W-Vectors with the same vehicle
ID (). That is,
     

              
and

The edge delay and cost are determined by the quality of
the Internet connections:            
Similarly,  and  may have different values for different
moving terminals. For example, different ISPs may offer
different prices for the 3/4G connections.
(e) Recall that every way point  generated by a mobile
terminal has two corresponding vertices,   and 
 . These two vertices have two symmetric edges between
themselves:
       

      

Section III-A for the denition of adjacent way points

1441

distance, and the transmission delay for short messages. For
example, transmitting a message of 1024 bytes via an 11mbps
wireless channel normally takes less than 1 millisecond. A
vehicle in the speed of 80mph can only move less than 0.04
meters in 1 millisecond, which is denitely negligible since
the communication range of a vehicle is usually larger than
100 meters.
We need to emphasize that the structure of the TSLG
changes as time elapses. When old way points expire, the
corresponding vertices and the associated edges need to be
removed from the graph. The new way points also need to
be incorporated into the graph as soon as they are collected.
Note that the set of active way points also affect the subset of
vertices representing the Internet and RSUs (set  and  ).
2) Optimal Routing: Once the TSLG  is constructed, the
DM can model routing as a path-searching problem. First, the
DM needs to determine the source vertex  and destination vertex  according to the actual information source and destination
of the requested session. If the actual information source is the
entity  ( can be a vehicle or a xed terminal), the source
vertex  must be   ; similarly, if the actual destination
is the entity  , the destination vertex  must be   .
Given the  and , the size of the data to be transferred denoted
as , the maximum acceptable end-to-end delay denoted as
, and the budget (maximum acceptable cost) denoted as
 . Our goal is to nd a    path on  such that the
path has the highest message delivery ratio and satises the
given delay and cost constraints. In order to model this routing
problem, we need to use the following denitions:
Message Delivery Ratio: The message delivery ratio 
of a path          is the joint probability of all
edges on the path:

path problem, i.e., to nd a    path          that:




  






 








 







We can use a linear program solver to solve this constraint
shortest path problem in polynomial time. The resulting   
path is a globally optimized route in terms of the message
delivery ratio, with a bounded end-to-end delay  and
message delivery cost . The path may contain carryand-forward links, wireless ad hoc links, as well as Internet
connections.
IV. E XPERIMENTS AND R ESULTS
We conduct real-world experiments to demonstrate how the
VehiCloud architecture can be used to address the fundamental
routing problem. We rst present the experiment setup and
then analyze the results.
A. Experiment Setup
1) Environment: The experiment is conducted in a residential area. The street map is shown in Fig. 3. The roads taken by



 

 


Here, we assume all edges are independent from each other.
End-to-end Delay: The end-to-end delay  of a path
        is the summation of the delay of all edges
on the path:


 

 
Fig. 3.



Path Cost and Message Delivery Cost: The cost  of a
path           is the summation of the cost of all
edges on the path. The cost of delivering a message  via the
path , say  is the product of the path cost and the size
of the message to be delivered:

our vehicles are highlighted by red lines. In the map, each of
three horizontal streets is approximately 400 meters in length,
and the distance between them is about 100 meters. Between
streets, the residential area is packed by buildings. The local
trafc within this experiment area is not very high, thus our
experimental vehicles can move in a relatively constant speed.
2) Vehicles: There are 10 vehicles involved in our experiment. Their starting positions are highlighted using blue tags
(round shape) in the map. Each of the vehicles carried an
Android phone, on which we implemented both the WIF and
a position based routing (PBR) scheme [3]. These phones are
all capable of receiving GPS signals to obtain their locations.



 

 

Experiment Environment.

     



In addition, given that the logarithm function is monotonically increasing, we know that maximizing  is equal to
maximizing  . Hence, we can model the complex
vehicular network routing problem as a constrained shortest

1442

performs well when the communication range is large (250
meters) and the vehicle speed is low (20mph) as shown in Fig.
4(a). However, PBR is too sensitive to both the two factors,
especially the communication range. For example, when the
communication range decreases at 150 meters (see Fig. 4(c)
and Fig. 4(f)), the performance of PBR is extremely poor;
the message delivery ratio is lower than 60% for most of the
time and the behavior is totally unpredictable. This is because
PBR highly relies on the connectivity of the network. When
the communication decreases and the vehicle speed increases,
the network connectivity cannot be easily maintained, and
vehicles can get disconnected more frequently. As a result,
PBR often fails due to vehicles not being able to nd the
next hop. On the contrary, we nd that WIF-NDC is the most
reliable routing strategy. The message delivery ratio of WIFNDC is usually greater than 80% and up to 100%. The reason
for such behavior is that WIF-NDC has no delay constraint
when making routing decisions. Thus, the routes selected have
more considerations on the route reliability. For example,
no matter how fast the vehicles move and how small the
communication range is, WIF-NDC will still nd the chances
for two vehicles to communicate directly with each other when
they meet on the street. Moreover, the source vehicle can also
leave the message to an RSU when it passes by the RSU,
which can then deliver it to the destination at a later time.
These behaviors can hardly be affected by the vehicle speed
and communication range. In the case of WIF-DC, we add a
30-second delay constraint when making routing decisions,
which makes it more sensitive to vehicles communication
range than WIF-NDC (but still much better than PBR). For
instance, comparing Fig. 4(a), 4(b) and 4(c), we can see that
the message deliver ratio of WIF-DC has a notable drop when
vehicles communication range decreases. Likewise, Fig. 4(d),
4(e) and 4(f) demonstrate the same behaviors. The reason for
this phenomenon is straightforward: since a 30-second delay
constraint is applied, highly reliable carry-and-forward links
cannot be used as much as in WIF-NDC. In this case, WIFDC has to use multi-hop ad hoc links to forward messages
within the delay constraint. Nonetheless, we claim that WIFDC is still reliable since at most of time, its message delivery
ratio is still as high as 80%. We also notice that, as shown in
Fig. 4(c) and Fig. 4(f), the decreasing of the communication
range has less impact on WIF-DCs performance when the
vehicles move faster. The reason is that an encounter between
two vehicles appears fasters when the vehicles move faster,
and so the delay constraint has less impact.
In Fig. 5, we present the results about the average hop
counts in different scenarios. It is necessary to point out that,
we ignore the hops of the query phase but only focus on
the hops taken by the actual message transfer. Using PBR,
every node, including the source and relay nodes, has to send a
query to a location server to get the location information of the
destination. However, in WIF, only the source needs to send a
query to the DM to get the route to the destination, which can
dramatically reduce the overhead during the route query phase.
However, since there are many different implementations of

TABLE II
E XPERIMENT S CENARIOS
Scenario
Vehicle Speed (mph)
Communication Range (m)

A
20
250

B
20
200

C
20
150

D
30
250

E
30
200

F
30
150

3) Network setup: The vehicular network is comprised
of the 10 MSNs (i.e., vehicles) and 2 xed nodes (RSUs,
emulated by 2 stationary phones). The positions of the two
RSUs are marked as yellow triangles in the map. When WIF is
in use, one of the 10 vehicles is randomly selected as a mobile
terminal. The RSUs and the mobile terminal had Internet
access, so they could directly talk with the cloud decision
module (DM), which is not shown in the map. The ad hoc
communication channels are emulated through 3G connections
via Android phones. At a certain point of time, if and only
if the distance between two nodes was less than the current
setting of the communication range, a direct ad hoc link
was assumed to exist between them. But when they actually
communicated with each other, the messages were transmitted
via the 3G network. All these nodes receive commands from
a centralized server and report their performance data, e.g.,
packet drop, to the server for post-experiment analysis.
4) Experiment Scenarios: We conduct a comprehensive set
of experiments including 6 different scenarios to evaluate our
solution. These scenarios are summarized in Table II.
Each scenario has three rounds, and each round lasts for
5 minutes. For each scenario, PBR is used in the rst round
and WIF-based strategies are used in the other two rounds. In
the second round, no delay constraint was applied (denoted as
WIF-NDC) when making routing decisions; while in the third
round, a 30-second delay constraint was applied (denoted as
WIF-DC). For each round, data transmission is started from
the 50th second and ended at the 250th second. During the data
transmission period, for each second, we (at the central server)
randomly choose a vehicle to initiate a message and send it to
another randomly chosen vehicle. Note that at the beginning
of each round, the vehicles start from their initial locations
highlighted in the map, and follow the same route in the same
moving speed to minimize the experimental inconsistency.
5) WIF settings: In the implemented WIF, the time interval
between two adjacent way points in a W-Vector is 5 seconds.
These way points are computed based on the vehicles moving
speed and its predetermined moving trajectory. Without losing
generality, cost was not considered as a constraint in either
WIF-NDC or WIF-DC for simplicity.
B. Experiment Results
The experimental results are depicted in Fig. 4 and Fig.
5. Fig. 4 compares the message delivery ratios of the three
different routing strategies (PBR, WIF-NDC, and WIF-DC)
in different scenarios, over the 200-second period of data
transmission (i.e., 50th -250th second). The message delivery
ratios are calculated (and marked in the gures) for every 10
seconds. First of all, we can clearly see that, both WIF-NDC
and WIF-DC outperform PBR signicantly in all cases. PBR

1443

(a) Scenario A

(b) Scenario B

(d) Scenario D

(e) Scenario E
Fig. 4.

(c) Scenario C

(f) Scenario F

Message Delivery Ratio

location services, it is not fair to compare the query phase
using some specic strategy for PBR. Thus, in our comparative
study of hop counts, we only focus on the message transfer,
in spite of the location query (PBR) and path query (WIF).
We observe that the hop count of WIF-NDC usually equals to
1 regardless the different settings of vehicles moving speed
and communication range.

for the messages that are successfully delivered. In Scenario F
(30mph, 150m), PBR has a very lower message delivery ratio
(see Fig. 4(f)). The low hop count tells us that PBR cannot
survive in multi-hop message transfer in this case.
V. R ELATED W ORK
Recent development of mobile cloud computing [1], [2]
constructed a new service oriented framework that recruits
mobile devices as service providers to build a sensing-based
new application platform. In such a framework, each mobile
device (usually an embedded device) is a service provider.
An embedded device senses its surrounding information, such
as wireless communication channel status, neighboring nodes
information, environmental information (e.g., CO2 and pollution levels, etc.), personal information (e.g., medical and health
information using bio sensors), etc. Mobile cloud computing
is an emerging research area. How to construct a mobile cloud
system to assist vehicular communication is still an unexplored
area.
Existing information dissemination strategies in vehicular
networks can be classied into three categories: restricted
ooding, carry-and-forward, and geographic routing. In order to alleviate the overhead incurred by ooding, improved
schemes such as [4], [5] and [6] have been proposed to restrict the ooding to certain extents. The carry-and-forward
strategy is commonly used for delay tolerant information
propagation. Generally, messages are carried by an intermediate vehicle until it nds the opportunity to forward the
messages further. By utilizing the predictable mobility of
vehicles, the messages will ultimately be transmitted to the
destination. Proposals such as MDDV [7], VADD [8], SADV

WIF-NDC always selects shorter paths. This is because
a path with less number of hops has higher reliability. For
instance, if vehicle A wants to send a message to vehicle B, it
is always better for A to carry the message until it meets with
B rather than send the message to B via relay nodes, since the
probability of carry-and-forward links is equal to 1 while
that of the ad hoc links is less than 1. However, WIF-DC will
select longer paths due to the delay constraint. This is because
a vehicle cannot carry the message for a long time, and thus it
has to send the message to the destination via available relay
nodes to satisfy the delay requirements. Hence, the average
hop count of WIF-DC increases notably when the vehicles
communication range decreases. In Fig. 5(a), we can see
that the average hop count of WIF-DC is the highest among
the three routing strategies when the communication range is
decreased to 150 meters. In comparison, we do not notice such
phenomenon in Fig. 5(b), which represents vehicles moving
in a higher speed. This is because the high moving speed
makes vehicles meet sooner, which reduces the impact of the
delay constraint. Additionally, we observe that in Fig. 5(b),
PBR has a lower hop count when the communication range
decreases to 150 meters, which is contradictory to Fig. 5(a).
That is actually because the average hop count is calculated

1444

2 5 0 m
2 0 0 m
1 5 0 m

2 .2

1 .6

25 0 m
20 0 m
15 0 m

3 0 m p h

2 0 m p h

2 .0

1 .4

1 .8
1 .6

1 .2

1 .4
1 .0

1 .2
1 .0

0 .8

0 .8

0 .6

0 .6
0 .4

0 .4
0 .2

0 .2

0 .0
P B R

W IF -N D C

0 .0

W IF -D C

P B R

(a) 20mph

W IF -N D C

W IF -D C

(b) 30mph
Fig. 5.

Average Hopcount

[9], Ferry [10] and ZebraNet [11] all applied the similar carryand-forward idea. However, these mechanisms can only send
messages to xed destinations such as roadside units, but
not moving vehicles; and they usually cause large end-to-end
delay. Geographic routing or position based routing (PBR) is
capable of disseminating information to mobile destinations
when their locations are known. As presented in [3], [12],
[13] and [14], PBR does not rely on the network topology.
Routing decisions are made at each hop by selecting the next
hop that is closest to the destination in terms of the geographic
distance. The prerequisite of applying geographic routing is
that the source vehicle and all the relays have to know the
exact geographic location of the destination in real-time. This
is hard to be satised because knowing the location of the
destination is difcult in vehicular networks. Protocols such as
DLS, SLS and RLS presented in [15] provide location services
by periodical location information exchange either proactively
or reactively across the entire network. Other protocols as GLS
[16] use grid hierarchy to maintain location information in
real-time. However, all these solutions can hardly be applied to
fast moving vehicles. They usually incur high communication
overhead when generating large amount of location updates,
and experience enormous number of location lookup failures.
VI. CONCLUSION
In this paper, we presented VehiCloud, a cloud assisted
architecture for inter-vehicle routing. Our approach transforms the conventional vehicular communication system into a
service-oriented architecture by extending the concept of mobile cloud into vehicular networks. VehiCloud treats vehicles
as both the mobile service nodes (MSNs) of the cloud and end
users of cloud services. We elaborate a concrete cloud-based
routing service to address the fundamental routing problem
for inter-vehicle communication. Our real-world experiment
demonstrates that, the VehiCloud routing service outperforms
previous solutions signicantly, in terms of the route reliability.
In addition, the experiment also shows the ability of VehiCloud on making the routing decision by considering variant
constraints.
ACKNOWLEDGEMENT
This research is sponsored by ONR YIP. Some of the work
is also partially sponsored by NSF CNS-1029546 and DUE0942453. The research outcomes do not necessarily reect the
views of sponsors.

R EFERENCES
[1] D. Huang, MobiCloud: A Secure Mobile Cloud Computing Platform,
E-Letter of Multimedia Communications Technical Committee (MMTC),
IEEE Communications Society (invited paper), 2011.
[2] D. Huang, X. Zhang, M. Kang, and J. Luo, Mobicloud: A secure mobile
cloud framework for pervasive mobile computing and communication,
in Proceedings of 5th IEEE International Symposium on ServiceOriented System Engineering, 2010.
[3] B. Carp and H. Kung, GPSR: Greedy Perimeters Stateless Routing for
Wireless Network, Proceedings of ACM/IEEE Mobicom, pp. 243254,
2000.
[4] R. Yadumurthy, A. CH, M. Sadashivaiah, and R. Makanaboyina, Reliable MAC broadcast protocol in directional and omni-directional
transmissions for vehicular ad hoc networks, Proceedings of the 2nd
ACM international workshop on Vehicular ad hoc networks, pp. 1019,
2005.
[5] G. Korkmaz, E. Ekici, F. Özgüner, and Ü. Özgüner, Urban multihop broadcast protocol for inter-vehicle communication systems, Proceedings of the 1st ACM international workshop on Vehicular ad hoc
networks, pp. 7685, 2004.
[6] C. Maihöfer, T. Leinmüller, and E. Schoch, Abiding geocast: time
stable geocast for ad hoc networks, Proceedings of the 2nd ACM
international workshop on Vehicular ad hoc networks, pp. 2029, 2005.
[7] H. Wu, R. Fujimoto, R. Guensler, and M. Hunter, MDDV: a mobilitycentric data dissemination algorithm for vehicular networks, Proceedings of the 1st ACM international workshop on Vehicular ad hoc
networks, pp. 4756, 2004.
[8] J. Zhao and G. Cao, VADD: Vehicle-assisted data delivery in vehicular
ad hoc networks, IEEE Transactions on Vehicular Technology, vol. 57,
no. 3, pp. 19101922, 2008.
[9] Y. Ding, C. Wang, and L. Xiao, A static-node assisted adaptive
routing protocol in vehicular networks, Proceedings of the fourth ACM
international workshop on Vehicular ad hoc networks, pp. 5968, 2007.
[10] W. Zhao, M. Ammar, and E. Zegura, A message ferrying approach
for data delivery in sparse mobile ad hoc networks, Proceedings of the
5th ACM international symposium on Mobile ad hoc networking and
computing, pp. 187198, 2004.
[11] P. Juang, H. Oki, Y. Wang, M. Martonosi, L. Peh, and D. Rubenstein,
Energy-efcient computing for wildlife tracking: design tradeoffs and
early experiences with ZebraNet, ACM SIGPLAN Notices, vol. 37,
no. 10, pp. 96107, 2002.
[12] R. Jain, A. Puri, and R. Sengupta, Geographical routing using partial
information for wireless ad hocnetworks, Personal Communications,
IEEE [see also IEEE Wireless Communications], vol. 8, no. 1, pp. 48
57, 2001.
[13] Y. Ko and N. Vaidya, Location-Aided Routing (LAR) in mobile ad hoc
networks, Wireless Networks, vol. 6, no. 4, pp. 307321, 2000.
[14] S. Basagni, I. Chlamtac, V. Syrotiuk, and B. Woodward, A distance
routing effect algorithm for mobility (DREAM), Proceedings of the
4th annual ACM/IEEE international conference on Mobile computing
and networking, pp. 7684, 1998.
[15] T. Camp, J. Boleng, and L. Wilcox, Location information services
in mobile ad hoc networks, Communications, 2002. ICC 2002. IEEE
International Conference on, vol. 5, 2002.
[16] J. Li, J. Jannotti, D. De Couto, D. Karger, and R. Morris, A scalable
location service for geographic ad hoc routing, Proceedings of the 6th
annual international conference on Mobile computing and networking,
pp. 120130, 2000.

1445

Using Delaunay Triangulation to Construct Obstacle
Detour Mobility Model
Dijiang Huang
Computer Science and Electrical Engineering
University of Missouri–Kansas City
Kansas City, Missouri 64110
Email: dhuang@umkc.edu

Abstract— With the rapid growth in wireless communication
technologies, mobility management research is in great demand.
Simulation has become an effective method to study the performance of many mobility issues. A realistic mobility model not
only reflects mobile users’ behaviors, but also affects correctness
of the simulation results. In wireless environment, obstacles
usually exist within the coverage area. We propose a new detour
model by using Delaunay triangulation through the incorporation
of obstacles. The proposed mobility model can create detour
paths as long as there exist gaps among obstacles. Comparative
studies show that our proposed model can construct more detour
paths than Voronoi model.

I. I NTRODUCTION
Wireless and mobile networks are becoming the networks
of choice, because of the flexibility and freedom they offer.
With the increasing use of small portable computers, wireless
networks, and satellites, a trend, known as mobile computing,
to support computing on the move has emerged. Wireless and
mobile networks are being used in diverse areas such as travel,
education, stock trading, military, package delivery, disaster
recovery, and medical emergency care. Wireless networking
is specifically appropriate for situations where installation
of physical media is not feasible and on-the-spot access to
information is required. Since a user may not maintain a
fixed position in such environments, the mobile and wireless
networking support allowing mobile users to communicate
with other users becomes crucial. A possible scenario may
involve several different networks that can support or can be
modified to support mobile users. When dealing with different
wireless networks, a universal mobile device should be able to
select the network that best meets user requirements. Wireless
channels experience high variability in channel quality due to a
variety of phenomenon, including routing, fading, atmospheric
effects, and obstacles. While real world tests are crucial for
understanding the performance of mobile network protocols,
simulation provides an environment with specific advantages
over real world studies. These advantages include repeatable
scenarios, isolation of parameters, and exploration of a variety
of metrics [1].
A variety of mobility models have been proposed for Ad
Hoc networks [2], [3], [4], [5], [6]. These models assume
no obstacles within the coverage area. During the simulation,
a mobile user randomly moves to a direction or a selected
destination. When the mobile user hits the boundary of the
IEEE Communications Society / WCNC 2005

coverage area or reaches its destination, a new direction or
destination is selected. These mobility models have been used
to evaluate many mobility issues. However, they have several
deficiencies on simulating the real world. First, artificial or
natural objects usually exist within the coverage area. A
mobile user may not be able to pass through obstacles. Second,
mobile users usually follow a certain movement pattern within
the coverage area. For example, when a mobile user purposely
moves to a destination within the coverage area or goes
through the coverage area, the user’s movement path is usually
the shortest paths between the source and the destination.
When obstacles exist within the coverage area, the shortest
detour path is usually the practical movement path. Most of
the existing mobility models cannot construct practical detour
paths.
A. Incorporation of Obstacles
In order to overcome the deficiencies discussed above,
Jardosh et. al [1] first proposed a realistic mobility model
by incorporating obstacles. The movement paths are created
by using the Voronoi diagram [7] of obstacle vertices. This
mobility model is called Voronoi model. For instance, Fig. 5(a)
shows five obstacles placed in a coverage area; thin lines are
paths created by using Voronoi model. A Voronoi diagram
is composed of multiple polygons with the center of each
polygon modeling a vertex of an obstacle. The edges of
polygons construct the movement paths. In this paper, we call
these edges as Voronoi edges. During the simulation, nodes
are randomly distributed across the paths. Destinations are
selected from the set of obstacles, and shortest path route
computations are used to determine the path each node will
use to reach its selected destination. Many line segments
are intersected with obstacles by using Voronoi diagram.
The intersection points can be used as the entrances/exits
of obstacles. This mobility model emulates a mobile user’s
movement in a more realistic fashion, however, it has two
drawbacks. (1) The destination of a mobile user is inside of an
obstacle which only apply to some simulation scenarios, such
as school campus or shopping mall etc. When the destination
of a mobile user is outside of the obstacles or the mobile user
just goes through the coverage area, the shortest path between
a source and a destination usually goes through some obstacles
which may not be practical. In some realistic scenarios, the

1644

0-7803-8966-2/05/$20.00 © 2005 IEEE

A6

A7

mobile user may just bypass the encountered obstacles. Thus,
a realistic obstacle detour mobility model is required. (2) If we
remove the paths that go into the obstacles to find the shortest
path between two points that located outside the obstacles,
the shortest path may be disconnected. By duplicating the
mobility model proposed in [1], we find that the closer the
obstacles located within the coverage area, the more the paths
intersecting with the obstacles, and consequently, the less the
number of detour paths that are created among the obstacles.

B4
B5

A8

A4
B3

B. Using Delaunay Triagulation to Create Detour Paths

B2

In this paper, we propose an obstacle detour mobility
model by using Delaunay triangulation [7] which is the dual
structure of Voronoi diagram. We call our proposed mobility
model as Delaunay model. The motivation of using Delaunay
triangulation to construct the mobility model is explained as
follows:
If we use barycenters of all obstacles as the center
points to create the Delaunay triangulation and Voronoi
diagram, each edge of a triangle of Delaunay triangulation (we call the edge as Delaunay edge) uniquely
identify a Voronoi edge and each Delaunay edge connects two center points of two adjacent polygons created
by Voronoi diagram. It may be noted that any point on
a Voronoi edge has the same distance to two adjacent
center points. Thus, the Delaunay triangulation creates a
planar graph based on the distance relations of obstacles.
In a Delaunay triangulation, we can always find a point
on the Delaunay edge between two obstacles as long as
two adjacent obstacles are not adjacent. We then can use
these points to create detour paths.
The proposed Delaunay model provide following improvements compared with Voronoi model:
• detour paths are created on all gaps among obstacles and
the detour paths are always connected.
• the Delaunay model generates shorter detour paths comparied with the Voronoi model.
• the Delaunay model generates more detour paths comparied with the Voronoi model.
By introducing obstacles in the simulation, the performance
of a simulated Ad Hoc routing protocols has been studied in
[1]. Their studies show that the incorporation of obstacles reduces the node density (average number of neighbors per node)
and increases the path length (number of hops from a source
to a destination). The lower node density results in less number
of paths between a source and a destination. In other words,
the number of communication sessions is decreased. Thus,
the performance of corresponding Ad Hoc routing protocol
(such as AODV [8]) is decreased. Due to lesser number of
communication sessions being available, the number of data
packets received at their intended destinations is decreased,
and hence the number of network layer control packets and the
end-to-end transmission time for data packets are decreased.
It may be noticed that nodes are randomly placed on paths.
Since the Delaunay model creates more detour paths which
are are located on all the possible gaps among obstacles, the
node density is increased. As a result, the performance of Ad
Hoc protocol is likely to improve. In addition, the longer path
IEEE Communications Society / WCNC 2005

A5

B1

A1

Fig. 1.

A2

A3

A configuration example for mobility simulation model

length downgrades the overall throughput of Ad Hoc networks.
Thus, shorter detour paths decrease the number of hops from
the sources to the destinations and increase the throughput
of Ad Hoc networks. In this paper, we present a method to
construct detour paths by using Delaunay triangulation and
a comparative study with Voronoi diagram based mobility
model. Simulation of Ad-hoc network is out of scope of this
paper.
C. Paper Arrangement
The rest of the paper is organized as follows: we present the
obstacle detour mobility model in Section II. In Section III, we
present a comparative study with the obstacle mobility model
proposed by Jardosh et al [1]. Section IV concludes the work
and provides future research directions.
II. A N O BSTACLE D ETOUR M ODEL
The coverage area is usually a polygon. The shape and
size of the coverage area are predefined in a simulation
configuration file. For example, in Fig. 1, obstacles are placed
within a 2-dimensional rectangular (100m by 100m) coverage
area A1 A3 A5 A7 . In this paper, we use the simulation configuration example shown in Fig. 1 to illustrate the proposed
method. However, the presented simulation methodology can
be applied to any arbitrary configuration.
In Fig. 1, A1 − A8 are assistant points which help to build
the detour paths. They are end points and midpoints of line
segments to form the coverage area. Any assistant point and
midpoint of a line segment can serve as a entrance/exit point of
the coverage area. Additional assistant points on the simulation
borders can be added in the configuration file. An obstacle is
constructed as a rectangle and is identified by its barycenter
(the details of construction of an obstacle is discussed in
Section II-A).
A goal of our proposed detour mobility model is to find
detour paths between any pair of points within the coverage
area. A point can be any point of a line segment and a detour
path is constructed by a set of line segments. The detour path

1645

0-7803-8966-2/05/$20.00 © 2005 IEEE

c2

to k
6
5
to m

to j

c1

angle

7
4

Bi

B

he

c3

igh
t

3
2
from i

1

Fig. 2.

c4
An example of detour paths

Fig. 3.

between point i and point j is denoted by pij , where pij ∈ Pij
and Pij is the set of all possible paths between i and j. For
example, a detour path, pij , i−1−2−3−4−5−j is illustrated
in Fig. 2 which is constructed by using multiple line segments.
A detour path pij has following properties: (1) the length of
the detour path |pij | is the minimun in set Pij ; (2) if multiple
detour paths have the same length, randomly pick one as the
detour path during the simulation; (3) a mobile user follows
the detour path from the source point to the destination point;
(4) a mobile user can only change the detour path to a different
destination at one of intersection points in the coverage area
(points 1-7 in Fig. 2).
In order to construct the detour paths among a set of points
in the coverage area, we utilize the Delaunay triangulation
by incorporating obstacles. The detour paths construction
procedure is shown as follows:

Step 1:
Step 2:
Step 3:
Step 4:
Step 5:

Detour paths construction procedure
initial simulation points set
=obstacle construction(input data);
triangle matrix A
=delaunay(initial simulation points set);
second simulation points set
=trim intersection(triangle matrix A);
triangle matrix B
=delaunay(second simulation points set);
path matrix
=trim path(triangle matrix B);

th

An obstacle

the proposed Delaunay model, we observed that rectangular
shapes can be used to approximate polygons with negligible
difference in results. Thus, in this paper, each obstacle is
represented by a rectangular shape.
An obstacle as shown in Fig. 3 is defined by 5-tuple
x1 , y1 , angle, width, height. Here, x1 and y1 are the x −
axis and y − axis coordinates of the starting point (corner
c1 ) to draw an obstacle. We use c1 , c2 , c3 , c4 to represent four
corners of an obstacle. The other three coordinates (x2 , y2 ),
(x3 , y3 ), and (x4 , y4 ) can be derived from the parameters of
the given 5-tuple. For example, 0 ≤ angle < 90 is the degree
between the horizontal line and the line segment c1 c2 in Fig. 3;
width = |c1 c2 | = |c3 c4 |, height = |c2 c3 | = |c4 c1 |, and the
barycenter Bi is used to identify an obstacle.
The output is the set of points (center points) within the
coverage area which contains all assistant points (A1 −A8 ) and
the barycenters of obstacles (B1 − B5 ). They are the inputs to
generate the Delaunay triangulation presented in the following
section.
B. Step 2: Generating the First Delaunay Triangulation

In the following sections, we discuss each step of the
presented simulation procedure in detail.
A. Step 1: Obstacles Constructions in 2-dimensional Simulation Plane
Function obstacle construction reads the input data to set
up the simulation initial environment. The input data specifies
the size and shape of a coverage area, the obstacles, and
the assistant points. In this section, our focus is on how to
construct obstacles.
Arbitrarily complex polygonal shapes can be used to specify the obstacles and non-linear shapes, such as circles can
be approximated by polygons. Based on our studies, using
IEEE Communications Society / WCNC 2005

wid

The Delaunay triangulation is the dual structure of the
Voronoi diagram [7]. Triangulation is the division of a surface
or plane polygon into a set of triangles, usually with the
restriction that each triangle side is entirely shared by two
adjacent triangles. In Delaunay model, the set of triangles is
created based on a set of center points and the circumcircle
of every triangle does not contain any center point of the
triangulation.
In order to understand the need of using Delaunay triangulation to create the mobility model, we explain the relations
between Delaunay triangulation and Voronoi diagram. A
Voronoi diagram partitions a plane with n central points into
n convex polygons such that each polygon contains exactly
one central point and every point in a given polygon is closer
to its central point than that of other ploygon. Each edge of
a constructed polygon represents a sequence of points having
equal distances to two closest central points. Jardosh et. al [1]
used the edges of the polygons to form the mobile user’s
movement paths. In their approach, an obstacle is represented
by one or multiple rectangles and the central points are
the corners of obstacles. Thus, the derived Voronoi diagram

1646

0-7803-8966-2/05/$20.00 © 2005 IEEE

A

6

A7

A6

A7

A5

A

5

B4

B

4

B5

B5

A

A8

A4

8

A

4

B

B3

3

B

B

2

2

B1

B1

A

1

A1

A

3

A

(b) Second Delaunay triangulation

A6

7

36

3

2

(a) First Delaunay triangulation
A

A

A

2

A6

A7

A5

29

A5

32
28

35

B4

34

27

26

B4

30

B

B

5

5

33

31

25

24

A

8

14

23

B3
12

3

22

B2

B2

16
B1

B1
38

18

9

1

20
19

10
A

A

2

A1

A

3

A

A

3

2

(c) Detour paths constructed by trimming the second
Delaunay triangulation
Fig. 4.

4

B

40

15

11

A

21

17

37

13

A8

A4

39

(d) Detour paths generated by Voronoi model

Using Delaunay triangulation to construct detour pathes and using Voronoi diagram to construct detour pathes

creates many line segments that intersect with the obstacles
and simulation boundaries. These line segments can prevent
from forming detour paths. In order to overcome the problem
described above, we use Delaunay triangulation to find the
relations among multiple center points. We utilize the relation
between Voronoi diagram and Delaunay triangulation that
each Voronoi edge is identified by a Delaunay edge which
connects two center points. In other words, a Delaunay edge
identify a boundary relation of two adjacent polygons. Since
each polygon contains one simulated obstacle, we can use
the midpoint of the Delaunay edge as an end point of a line
segments in a detour path.
In the step 2 of the detour paths construction procedure,
the function delaunay(initial simulation points set) outputs
the triangulation derived from the center points. The Delaunay
triangulation of Fig. 1 is shown in Fig. 4(a). In this figure,
a planar graph is constructed by Delaunay triangulation. The
implementation of delaunay() is based on qhull algorithm [9].
The complexity of qhull algorithm is n log n for 2-dimension,
where n is the number of center points.
IEEE Communications Society / WCNC 2005

C. Step 3: Midpoints Creation
The output of step 2 is a set of line segments connecting
obstacle barycenters and assistant points. The midpoints of
these line segments either may be located within obstacles
or may be located very close to one connected obstacle
compared to the other one. In order to find the midpoint of
a given line segment that has equal distance between two
obstacles’ boundaries or the boundary of an obstacle and
an assistant point, we simply find the intersections of all
line segments generated from step 2 and use the intersection
points to replace the barycenters of all intersected obstacles.
In this way, all generated midpoints are located in the middle
of pathways. The function trim intersection(triangle matrix A)
achieves above.
D. Step 4: Generating the Second Delaunay Triangulation
In step 3, we generate a set of midpoints among obstacles
and assistant points. To generate the detour paths, we simply use the set of midpoints (second simulation points set)
generated in step 3 as the center points to generate

1647

0-7803-8966-2/05/$20.00 © 2005 IEEE

A

A

6

7

A5

A

A

6

7

B4

A

6

A7

A5

B4

B4
B5

A

B5

A4

8

A5

A

B5

A4

8

B

A4

A8
B3

B

3

3

B
B2
B

1

B

B

1

A

2

B2
1

1

A

2

A

3

A

1

A

A

A1

A3

A

3

2

2

(a) Detour paths constructed via Voronoi model. The (b) Detour paths constructed via Voronoi model. The (c) Detour paths constructed via Delaunay model.
line segments that intersect with the obstacles are not line segments that intersect with the obstacles are
removed.
removed.
Fig. 5. Delaunay model constructs more detour paths than Voronoi model. When the obstacles are located closer, Voronoi model cannot construct detour
paths among obstacles.

c2

the second Delaunay triangulation. The results of delaunay(second simulation points set) is shown in Fig. 4(b).
We can see that as long as there exists a pathway between
two obstacles, using the Delaunay triangulation, we can always
construct detour paths going through it. We also notice that
there are several line segments intersect the obstacles.

c1
B5

E. Step 5: Generating Obstacle Detour Paths
Fig. 4(b) shows the detour paths derived from step 4. We notice that several line segments intersect the obstacles. We trim
the detour paths using the following methods: (1) if a line segment intersects two parallel sides of an obstacle, the line segment is deleted (2) if a line segment intersects two non-parallel
sides of an obstacle, we replace the line segment by two
new line segments using the trim path(intersection lines)
method described as follows:
Input
Begin

trim path(intersection lines) method
∀(m, n) ∈ E ∧ [(m, n)⊥Bi = a, b]
where a⊥b = cj
∀(m, n) do the following
find l ∈ Sm \{n} ∧ l ∈ Sn \{m}
if l exists ∧ test(l, cj ) == 1
find k, where k is the midpoint of (l, cj )
draw line segments (m, k) and (k, n)
delete line segment (m, n)
end if

End
E is the set that contains all line segments
a, b are the intersected sides of an obstacle
Bi is the barycenter of obstacle i
Sm , Sn are the sets of end points that share the same line
segment with point m, n respectively
⊥ means intersecting
The inputs to the function trim path are all the end
points of line segments that intersect non-parallel sides of the
IEEE Communications Society / WCNC 2005

24

c3
c4

25

39
23
Fig. 6.

Path trimming

obstacles. For each pair of end points, such as points m and n,
the function trim path first find all the end points (represented
by point set L = Sm ∩ Sn ) that share a line segment with
points m and n simultaneously. For each l ∈ L, the function
test(l,cj )=1 if the point l is the closest point located outside
the corner point cj . For example, in Fig. 6, the line segment
(24, 25) intersects with obstacle sides (c1 , c4 ) and (c3 , c4 ).
The intersection point of these two sides is c4 . l (point 23)
must be located underneath the line goes through points 24
and 25. If the point 23 is the closest point to c4 located
underneath the line segment (24, 25), we say the point 23
is the closest point located outside the corner point c4 and
then we have test(23, c4 ) = 1. The test condition is the same
when the intersections sides are (c2 , c3 ) and (c3 , c4 ). When the
intersection sides are either (c1 , c2 ) and (c1 , c4 ), or (c1 , c2 )
and (c2 , c3 ), l must be located above the line segment. In
the example, once the point 23 is found, the mid-point 39 of
line segment (23, c4 ) is derived and two new line segments
(24, 39), (25, 39) are created in the coverage area. Finally, the
line segment (24, 25) is deleted. In this way, we construct the
detour paths that are shown in Fig. 4(c). Points 37, 38, 39,

1648

0-7803-8966-2/05/$20.00 © 2005 IEEE

and 40 are new points created by function trim path.
III. C ONSTRUCT D ETOUR PATHS U SING D ELAUNAY
MODEL AND VORONOI MODEL
In this section, we compare Delaunay model and Voronoi
model. Our comparative study shows that our proposed model
is more suitable to construct detour paths.
In our comparative study, we use Matlab as the simulation
platform. The Matlab functions can be called by C compiler.
Thus, our obstacle detour mobility model can be easily integrated into other simulators, such as ns-2.
Created by Delaunay model
Created by Voronoi model

160

Path length (m)

140

120

100

80

60

40

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Randomly selected shortest paths

Fig. 7. path length comparisons by randomly selecting source-destination
pairs using Delaunay model and voronoi model

Using the Voronoi model, we derive the detour paths1 based
on the simulation configuration in Fig. 1. In order to present
the detour paths, we remove all the paths that intersect with
the obstacles. The result is shown in Fig. 4(d). The detour
paths derived from the Delaunay model are shown in Fig. 4(c).
Comparing the detour paths derived from these two models,
the Delaunay model creates more paths and all detour paths
are connected.
When the obstacles are located close to each other, the
Delaunay model can always construct detour paths as long
as there are gaps among obstacles. Fig. 5(a) shows the paths
constructed by Voronoi model. In this figure, the obstacles B1 ,
B2 , and B3 are located close to each other and since the
Voronoi diagram is a planar graph, the links that intersect
the obstacles prevent detour paths from going through the
gaps. Fig. 5(b) shows the detour paths by removing the line
segments that intersect the obstacles. We can see that there are
no paths going through the gaps among the obstacles B1 , B2
and B3 . As shown in Fig. 5(c), the detour paths can always be
constructed as long as there are gaps among obstacles. Thus, as
long as there exist nodes on these detour paths, they can serve
as intermediate nodes to forward traffic and consequently, the
path length between the source and destination may be shorter.
1 Using Voronoi model, the obstacles’ vertices and assistant points are the
center points.

IEEE Communications Society / WCNC 2005

A mobile user moves to a destination via a shortest detour
path. The detour path length affects the performance of Ad
Hoc routing protocols. Fig. 7 shows the shortest path comparisons by using Delaunay model and Voronoi model. In this
comparison study, we randomly select 20 source-destination
pairs from the coverage area given in Fig. 1. The path length
shown in the figure is sorted in increasing order of the path
length derived from Delaunay model. The path length for
each pair is computed based on Fig. 4(c) and Fig. 4(d). On
average, the detour paths created by using Voronoi model are
26% longer than the detour paths created by using Delaunay
model. We have simulated many different configurations. We
find that a denser obstacles configuration usually results in a
longer detour paths by using Voronoi model.
IV. C ONCLUSION
In this paper, we propose an obstacle detour mobility model
by using Delaunay model. Using this model, the obstacles
detour paths are created on all gaps among obstacles within
the coverage area. We also compare the Delaunay model with
the Voronoi model proposed in [1]. The Delaunay model shows
the following improvements:
• detour paths are created on all gaps among obstacles and
the detour paths are always connected.
• the Delaunay model generates shorter detour paths comparing with the Voronoi model.
• the Delaunay model generates more detour paths comparing with the Voronoi model.
The Delaunay model can be easily plug into exist simulators. Our future work is to evaluate the performance of various
Ad Hoc routing protocols using Delaunay model.
ACKNOWLEDGMENTS
The author would like to thank Deep Medhi for his valuable
comments and Balaji Krithikaivasan for his help in improving
the presentation of the paper. The author would also like to
thank anonymous reviewers for their valuable comments.
R EFERENCES
[1] A. Jardosh, E. M. Belding-Royer, K. C. Almeroth, and S. Suri, “Towards
realistic mobility models for mobile ad hoc networks,” in ACM MobiCom,
2003.
[2] J. Broch, D. A. Maltz, D. B. Johnson, Y.-C. Hu, and J. Jetcheva, “A
performance comparison of multi-hop wireless ad hoc network routing
protocols,” in Mobile Computing and Networking, 1998, pp. 85–97.
[3] Z. J. Haas and M. R. Pearlman, “A new routing protocol for reconfigurable
wireless networks,” in IEEE International Conference on Universal
Personal Communications (ICUPC), 1997, pp. 562–565.
[4] X. Hong, M. Gerla, G. Pei, and C. Chiang, “A group mobility model for
ad hoc wireless networks,” in ACM/IEEE MSWiM, 1999, pp. 53–66.
[5] B. Liang and Z. J. Haas, “Predictive distance-based mobility management for multidimensional pcs networks,” IEEE/ACM Transactions on
Networking (TON), vol. 11, no. 5, pp. 718 – 732, October 2003.
[6] E. M. Royer, P. M. Melliar-Smithy, and L. E. Mosery, “An analysis of the
optimum node density for ad hoc mobile networks,” in IEEE International
Conference on Communications, 2001.
[7] M. de Berg, M. van Kreveld, M. Overmars, and O. Schwarzkopf,
Computational Geometry: Algorithms and Applications. Springer Verlag,
2000.
[8] C. E. Perkins, E. M. Belding-Royer, and I. Chakeres, “Ad hoc on demand
distance vector (aodv) routing,” IETF Internet Draft, October 2003.
[9] C. B. Barber, D. P. Dobkin, and H. Huhdanpaa, “The quickhull algorithm
for convex hulls,” ACM Transactions on Mathematical Software, vol. 22,
no. 4, pp. 469–483, 1996.

1649

0-7803-8966-2/05/$20.00 © 2005 IEEE

A Behavior based Policy Management for Adaptive
Trustworthiness Assignment in Future Network
Akira Wada∗ , Yasuhiro Sato† , Xuan Liu‡ , Tianyi Xing§ ,
Shingo Ata∗ , Deep Medhi‡ , Dijiang Huang§ and Ikuo Oka∗
∗ Graduate

† Faculty

School of Engineering, Osaka City University
of Maritime Safety Technology, Japan Coast Guard Academy
‡ University of Missouri–Kansas City, U.S.A
§ Arizona State University, U.S.A

Abstract—A secure network is considered to be an important
goal of the Future Internet; one way which can be embodied
is by having ﬂexible and robust routing functionality with
built-in security and trustworthy mechanisms. However, there
is a fundamental and important challenge how to determine
the trustworthiness to every trafﬁc ﬂow to realize trustable
communications. In this paper, we propose a framework to
manage the trustworthiness automatically based on the policy
by administrator, hysteresis of the trafﬁc, and/or behavior of end
users. We describe the role and function on to manage policy and
trustworthiness and illustrate the implementation of SeRViTR,
which is a trust routing framework, with communication experiment.
Index Terms—Trustworthiness, SeRViTR, Future Internet, Policy based Management, Routing

I.

INTRODUCTION

The current Internet has many problems that had never
been expected when designed. One such problem is that the
current Internet lacks functionalities regarding security. With
the background of the growth of the Internet, it was originally
designed from the belief that human nature is fundamentally
good. There was no consideration against the security issues
for example anomaly attacks, and privacy protection, etc.
However, as many researchers have noticed, many attacks that
cheat vulnerabilities in the Internet have led to critical social
problems, so the security is the highest prioritized issue to be
solved in the current and future Internet [1]. Moreover, as there
is an increase in the number of people who use the Internet,
a demand for providing a safe and secure communication
infrastructure where people can easily communicate without
high-level literacy on security becomes much higher.
From this background, many proposals towards the future
Internet are taking security issues into consideration [2]. We
also propose a Virtual Trusted Routing and Provisioning
Domain (VTRouPD) [3] that is a secure, ﬂexible, scalable, and
robust routing framework suitable for future Internet. As the
security issue, we especially focus on trustworthiness, which
presents a degree on how much we can trust a user, node,
trafﬁc, and/or network. We believe that trustworthiness is a
fundamental principle for people to decide who, where, or
what to communicate, or judge whether the communications
have been really valuable, reliable, and safe. We consider that
controlling the trafﬁc based on trustworthiness should be a

c
978-3-901882-50-0 2013
IFIP

built-in functionality to provide a seamless communication to
end users without any special knowledge on security. Our routing framework, called VTRouPD, provides a resilient network
in which the trafﬁc is controlled according to trustworthiness.
Speciﬁcally, we ﬁrst introduce trust level as a metric of
trustworthiness. VTRouPD provides the number of virtualized
networks realized by the network virtualization, and trafﬁcs
with different trust level are transferred in different virtual
networks that enable to completely isolate the trafﬁc ﬂows
each other, based on their trust level.
As a proof-of-concept model, Secure and Resilient Virtual
Trust Routing (SeRViTR) [4] has been proposed. We deﬁne
some key functional components that are mandatory to realize
the VTRouPD. We also deﬁne sequences of signaling and
processing in SeRViTR to control the trafﬁc according to
trustworthiness. A prototype of SeRViTR has already been
developed to validate our concept. However, in both VTRouPD
and SeRViTR, some important problems still remain. The main
questions are “What is trustworthiness in actuality?” “How
is the trust level assigned to corresponding trafﬁc?”, “Is it
possible to assign trust level automatically?” We consider that
these functionalities would be a key of successful deployment
of a trustworthy routing framework.
Based on the above-mentioned background, in this paper,
we propose a framework of the component (called Policy
Manager) to manage the trustworthiness automatically based
on the policy by an administrator, the hysteresis of the trafﬁc,
and/or behavior of the end users. The policy manager can
control all ﬂows’ trust based on the policy deﬁned by the
network administrator. At ﬁrst, we describe the function of the
policy manager, which centrally manages the trustworthiness
of all trafﬁc based on the policy. However a decision on the
trust level for each ﬂow must be performed automatically and
must be changed according to the conditions. The difﬁculty
to manage the trust level is that the trust level is a relative
criterion to differentiate the trafﬁc ﬂow from others and must
be changed by the event that occurred in the network. For this
problem, we propose a behavior based dynamic trust level
calculation mechanism in the policy manager.
This paper is organized as follows: we show the overview
of SeRViTR and its policy manager in Sections II and III
respectively. The designed functions in the policy manager

784

are shown in Section IV, and then we show the experiment
on the ﬂow management in Section V. We conclude this paper
with future works in Section VI.
II. B EHAVIOR BASED P OLICY M ANAGEMENT WITH
S E RV I TR
A. Overview of SeRViTR
We proposed a prototype of SeRViTR that realizes a ﬁnegrained routing management with network virtualization based
on the ﬂow’s trust level [4]. The SeRViTR framework consists
of some key components. There are Policy Manager, Domain
Controller, Flow Controller, and Behavior Analyzer, etc. In
this paper, we describe the details of the policy manager that
controls the whole of its Managed Domain according to the
policy deﬁned by the network administrator. More speciﬁc
information and the other components about SeRViTR are
available in [4].
B. Behavior-based policy management
We utilize user behavior, which is based on the hysteresis
of ﬂow, to quantify the trust of ﬂow. The behavior analyzer
classiﬁes the ﬂows’ behavior into some patterns according
to the number of warnings reported by the trafﬁc monitor,
encrypted ﬂow or not, trafﬁc volume, and so on. This pattern
is sent to the policy manager and the policy manager decides
whether the trust of the ﬂow should be updated based on the
policy. If needed, the policy manager recalculates the trust and
assigned network resource of the ﬂow. The policy manager
then sends the update message to the components to adjust
the resource due to the change of the trust level.
III. F UNCTION OF P OLICY M ANAGER
In this section, we describe the overview of the functions
of the policy manager, which is a fundamental component of
our framework.
A. Policy setting
The network administrator deﬁnes the policy to specify the
initial trust level of ﬂow, treatments of ﬂows, and judgement
rules of user behavior. These rules are statically set by the
administrator in the policy. The policy manager applies them
to the behavior analyzer to classify user behaviors. Exchange
information with the other managed domains is also deﬁned
in the policy.
Note here that to support various types of entities to set the
trust level, we need to accept an arbitrary degree of aggregation
of ﬂows. Basically, we classify ﬂows by regarding packets
having the same values in the speciﬁed ﬁelds (called ruleset)
of the packet header, as the same ﬂow. The granularity of ﬂows
is varied by changing the number of the header to be speciﬁed.
Though we only discuss the trust of ﬂows in this paper, we
can extend out discussion to a trust of hosts/networks/users by
changing the aggregation level of ﬂows. Therefore, throughout
this paper, we refer to ﬂows not only as the trafﬁc ﬂows
themselves but also other entities like nodes, networks, and/or
users.

B. Behavior-based trust calculation
The assigned trust levels are maintained only in the policy
manager protected to be read by other components because
the trustworthiness of ﬂow is conﬁdential information for the
routing that must be hidden from other domains. It is very
important to prevent the case where a malicious user illegally
speciﬁes the tampered trust level to let an unfair forwarding of
ﬂows in the trusted network. By protecting the actual trust level
to other components, the trust level is just an ID to distinguish
a different trust level as observed from any components expect
the policy manager.
Moreover, the policy manager usually updates the trust level
of ﬂow based on the recorded behaviors of the ﬂow. When an
anomaly warning is reported from the behavior analyzer, the
policy manager degrades the trust level of the ﬂow alerted. On
the other hand, if anomaly warnings relevant to a ﬂow are not
reported within the speciﬁed observation window, such as time
interval or transferred bytes, the policy manager then increases
the trust level for the ﬂow.
C. Comprehensive control to forward ﬂows
The comprehensive control to the other components is an
important role of the policy manager. After determining the
trust level for the unknown ﬂow, the policy manager next
checks whether the trust level is already associated with
the virtual domain to forward. If there is no virtual domain
associated with the trust level to forward a ﬂow, the policy
manager sends a request to create a new virtual domain for
the newly created trust level. The request is sent to the domain
controller and the policy manager receives Virtual Domain ID
(VDI) and Virtual Link ID (VLI) as the reply. Otherwise, the
policy manager sends an update request including the ﬂow
controller’s address to add the associated virtual domain. For
deletion, the policy manager ﬁrst sends a deletion request
message to remove the ﬂow controller that has no ﬂow
to forward the virtual domain. After deletion of the ﬂow
controller, the policy manager next sends a request of virtual
domain deletion if there is no ﬂow controller in the virtual
domain.
D. Collaboration with other managed domains
In case of inter-domain communication where the ﬂow is
traversed across the multiple managed domains, one problem
raised is how to decide the trust level for the ﬂow that is
coming from/going to another managed domain. Generally,
the administrator of the managed domain can only control
the trust level within his/her domain. It is impossible to give
explicit control to the ﬂow in other managed domains, even
if the trafﬁc is coming from the administrator’s domain. A
regulation scheme of the trust level between multiple managed
domains to treat the same ﬂow is necessary.
The trust level for trafﬁc coming from another managed
domain is again re-calculated at the edge of the managed
domain. Indeed, the policy manager can assign the trust level
of inbound trafﬁc by itself, based on the results of behavior
analysis, as that taken for in-domain ﬂows. However, the

2013 IFIP/IEEE International Symposium on Integrated Network Management (IM2013): Short Paper

785

information of trust level assigned by the policy manager of
the foreign managed domain would be useful and reliable to
decide the trust level within the managed domain. Therefore,
for inter-domain communications, the policy managers of both
managed domains can exchange not only the trust levels used
in their own managed domain (called Outbound Domain ID
(ODI)) but also the priority order of these levels.
IV. D ESIGN OF B EHAVIOR - BASED P OLICY M ANAGEMENT
We design behavior-based policy management according to
the functions described above.
A. Design concept and basic operation
As the basic principle, we consider designing the policy
manager from the database-oriented approach. The reasons
why we apply the database-oriented principle are (1) to achieve
the consistency of the information easily against huge updates
by various components, and (2) to operate the information
update and the control of components independently and
asynchronously.
Each function of the policy manager should treat various
information that was generated in it or received from other
components. However, the operations of these components
and functions are basically independent and not synchronized.
There may be a conﬂict that a certain component is updating
information while another component is retrieving the information. To achieve the consistency of the information that
is stored in the policy manager, we consider maintaining the
information for the policy manager by a relational database.
B. Description of functional blocks
The diagram of functional blocks in the policy manager is
shown in Fig. 1. This ﬁgure clariﬁes how the information is
transferred between function blocks.
1) Host and ﬂow management: This group consists of the
blocks to process when a new/unknown ﬂow is coming. The
Flow Information collects the information about hosts and
ﬂows, such as HostID, FlowID, Flow Controller Address,
Flow GroupID (FGI), and Priority for ODI from the Flow
Information Manager. Here, FGI is used to manage a set of
ﬂows such as the forward and the reverse ﬂows between source
and destination hosts.
Regarding the initial trust calculation, the policy manager
calculates the initial trust level for the incoming FlowID to
control forwarding the process in the managed domain. This
calculation also assigns the initial trust level for the host
joining the managed domain. The trust level of the host is
calculated based on the summary of trust levels of ﬂows
in which the address of the host is speciﬁed as the source
or destination of ﬂows. Additionally, the trust level of other
managed domain is calculated based on the priority of ﬂows
to make the decision easily.
After preparing virtual domains, the Flow Table Update
function creates a new ﬂow entry relevant to the ﬂow and
sends an update message to the ﬂow controllers that are edges
of its managed domain, which the ﬂow passes through. This

786

message includes FlowID and VLI to control how to forward
the ﬂow.
2) Behavior management: The main function of behavior
management is to determine change in the trust level for every
ﬂow registered in the ﬂow database. We call the function as
Behavior Judgement, while the determination is Judgement.
The judgement is the metric of whether the trust level of the
registered ﬂow should be changed. If the judgement means it
would be updated, the Trust Level Update acquires the trust
level and the judgement from the database and calculates the
updated trust level. After that, this block updates trust in Trust
table by the calculation result. If it changes the trust level
for ODI, the policy manager may notify this change to other
managed domains through the trust level regulator. Based on
the policy, the policy manager determines whether it sends a
Trust Level Change Notiﬁcation message.
The Outbound Domain Notiﬁcations receive all of the
notiﬁcation messages from other managed domains, such as
the trust level change notiﬁcation messages. By receiving the
ODI in the notiﬁcation, the policy manager recognizes that
an outside domain has judged the associated ﬂow is untrusted
ﬂow. Based on the notiﬁcation, the policy manager assigns a
negative score to the ﬂow and recalculates the trust level of
the ﬂow.
3) Resource management: The main role of the resource
management is for trafﬁc engineering of the managed domain.
Speciﬁcally, in the managed domain, there are a number of
virtual domains that are isolated from each other to transfer
ﬂows independently based on the trust level. The explicit
resource of the network should also be assigned according
to the trust level. The main function of the resource management is to calculate sufﬁcient network resources for each
virtual domain and send a resource request message to the
resource mapper. Though the actual resource management is
taken by the domain controller, the policy manager needs the
information regarding the current assignments to the virtual
domains and available resources in the network.
V. I MPLEMENTATION OF POLICY MANAGER
A. Implementation of policy manager’s function
We implement function blocks of the policy manager as
C++ programs running on a generic Linux based PC. Our
relational database is operated on MySQL 5.1. As the initial
implementation, we consider the scenario where the policy is
statically deﬁned by the administrator, and two hosts are newly
connected to the managed domain. We use OpenFlow switches
for the ﬂow controller and the virtual router. Therefore, the
ruleset is created based on OpenFlow semantics. Moreover,
we adopt VLAN ID as VLI and deﬁne VDI is the same as
VLI, for simplicity. We also assign the successive number to
the trust level.
B. Experimental environment
The network environment of our implementation is shown in
Fig. 2. We established layer-2 GRE connections among three
sites: Osaka City University (OCU), Arizona State University

2013 IFIP/IEEE International Symposium on Integrated Network Management (IM2013): Short Paper



+*$* * %$
(,(
,+&,%
	&$!%
	
&+!0+!&%

%)*(+)*
$(

%+$*
$%(#* %$


#&.
	&,%+
	
&,%+++,*

'+)*
$- *
"+"* %$


#&.
	
 -!&)++)%



#&.
%&

, %(
$"./(

$%+$
(1
%$ *%(



		

	

	




+*%+$
(1
%$ *%(



 %%&+!0+!&%

(+)*,"
+"*%(


#&.
	),*+),*+
	

+*%+$
%# $
%* 0* %$)
, %(
%* 0* %$)


#&.
	

, %(

+#$*

&*+
	
#&.
	
),*+),*+
	

	!$,

$*#)

	"%-

%+$*

$()

	!$,	

	!$,$#)'$!!'	

$*#)))*(

	!$,
'$*%

&*()#,)


#&.
	&,%+
	
&,%+++,*
(,*+%.!+


#&.
	
 -!&)++)%

	!$,$#)'$!!'

	!$,
'$*%

	"%-%$*(%""(

	"%-
(%+&

	!$,$#)'$!!''((

	!$,	


#&.
	 -!&)++)% +$'
,$%+
$()	
	"%-	

!)+,#!%"
	

	!$,$#)'$!

'*()

	"%-	

(+)*

'*()	

'*()


#&.
	 -!&)++)% 
*"#)
,$%+),*+),*+
	


#&.
	
$"#$#)'$!!'


#&.
	),*+
	),*+

)%+(
&&(

	

!)+,#	&$!%
	**!%%.!+



!)+,#	&$!%%$%+**'#/

 (*+"
%# $
$%(#* %$

),*+
	!)+,#	&$!%
	!)+,#!%"
	

),*+
	
!)+,#	&$!%
	
!)+,#!%"
	

')*!$"#

')*!#

 (*+"%# $

 (*+"%# $	

$"#$#)'$!!'	

	"%-%$*(%""(	

'*()	

')*!# 


	


Fig. 1.



 !








 !


#	!
!""!

OCU
$


	!

Fig. 2.

 (*+"%# $
&*
)%+(
$(

	"%%$*(%""(

,+&,%	&$!%
	
&+!0+!&%

 %
&+!0+!&%

(+)*,"
+"*%(

!)+,#	&$!%
%$%+**
)+	#+

%# $
%$*(%""(

!)+,#	&$!%
%$%+**
&!/
!)+,#	&$!%
	
(,*+%.!+

)%+(
&&(

$'	*#)$#%'$((
)'	*#)$#%'$((

Function block diagram of policy manager

UMKC

		



!)+,#	&$!%
	

#&.&%+)&##)
	

 (*+"%# $
(* %$
"* %$

$#)'$!((
#%*)#$'")$#)$
*)%*)#$'")$#)$!$
-##$'")$#

)'$"%$##)#



(+)*,"
$%(
$%# $


#&.#
'+**




	*#)$#!!$ $$!.#'
-)#*#)$#!$ $$!.#'

ASU

!)+,#	&$!%
	

!)+,#	&$!%
	
(,*+%.!+

!)+,#	&$!%
	**!%%.!+

)%+(
%* 0* %$)

+*%+$
%# $
%$*(%""(

%# $%$*(%""(


#&.&%+)&##)
	
#&.&%+)&##))**

*-%(!
%&%"%.

	"%-"
&*

((##,)


#&.
	),*+
	),*+

+$'))'#

(+)*,"
&*


#&.
	

)**
!)+,#!%"
	

$"#$#)'$!!''((


#&.&%+)&##))**

%# $
%$*(%""(

$ * "(+)*
"+"* %$

&*+
	
#&.
	
#&.&%+)&##)
	
#&.)&,'
	



&*+
	
#&.
%&
&,%+++,*


#&.
%&

	"%-
$%(#* %$





#&.
	


#&.
	&*+
	
)!&)!+/

$#)'$!!'(

)(((

!*!)$'(

$#)$'(


#&.
	&*+
	)!&)!+/

#&.)&,'
	
%"%&.%
#&.
%&
	"%
)**
%$*(%""(
	"%-

#&.
	&,%+++,*
$%(#* %$
&*+
	&,%+++,*

#&.
%&
$(

$ !
"
	!!
%#
%#

Single managed domain environment

(ASU), and the University of Missouri-Kansas City (UMKC)
by using Open vSwitch [5]. In this experiment, we used three
sites as a single managed domain, and the policy manager was
located in OCU. The policy manager assigned the value of
VLAN (VLI) for each packet, which were randomly selected
and ranged from 1 to 100.
C. Validation of ﬂow management
We considered two different applications: HTTP and SSH.
We assumed that the SSH ﬂow is more trustable than the
HTTP ﬂow. First, we showed the VLI of each ﬂow in
Fig. 2. We then validated that the ﬂow was forwarded to a
correct virtual domain according to the control of the policy
manager. We checked whether each ﬂow was forwarded to
the appropriate virtual domain, by tracking two ﬂows that
were sent from Host1 to Host2. Although we did not show
the packet traces due to space limitation, we could conﬁrm
that each ﬂow was forwarded to the destination host via the

appropriate virtual domain.
VI. C ONCLUSION AND F UTURE W ORK
In this paper, we described the functions of the policy
manager. To show the ﬂow control based on ﬂow’s trust,
we implemented the functions of the policy manager, and
performed some experiments in the network where three
distinct sites were connected. As a result, the policy manager controlled the ﬂow which was inputted to the managed
domain according to its trust. In the future, we implement the
remaining function of the policy manager.
ACKNOWLEDGMENTS
This work is supported by US NSF grants CNS-1029562
and CNS-1029546, the Ofﬁce of Naval Research’s (ONR)
Young Investigator Program (YIP), an HP IRP grant, and a
Japanese NICT International Collaborative Research Grant.
R EFERENCES
[1] U. Kuter and J. Golbeck, “Using probabilistic conﬁdence models for trust
inference in web-based social networks,” ACM Transactions on Internet
Technology, vol. 10, no. 2, pp. 1–23, May 2010.
[2] T. Li-qin, L. Chuang, and Sunjinxia, “A kind of prediction method of user
behaviour for future trustworthy network,” in Proceedings of the 10th
IEEE International Conference on Communication Technology (ICCT
2006), Guilin, China, November 2006, pp. 1–4.
[3] D. Huang, S. Ata, and D. Medhi, “Establishing secure virtual trust routing
and provisioning domains for future Internet,” in Proceedings of IEEE
GLOBECOM 2010, Miami, FL, USA, Decenber 2010, pp. 1–6.
[4] X. Liu, A. Wada, T. Xing, P. Juluri, Y. Sato, S. Ata, D. Huang, and
D. Medhi, “SeRViTR: A framework for trust and policy management for a
secure Internet and its proof-of-concept implementation,” in Proceedings
of the 4th IEEE/IFIP International Workshop on Management of the
Future Internet (ManFI), Maui, HI, USA, April 2012, pp. 1159–1166.
[5] T. Xing, X. Liu, C.-J. Chung, A. Wada, S. Ata, D. Huang, and D. Medhi,
“Constructing a virtual networking environment in a geo-distributed programmable layer-2 networking environment (G-PLaNE),” in Proceedings
of the IEEE 5th International Workshop on the Network of the Future
(FutureNet-V), Ottawa, Canada, June 2012, pp. 1–6.

2013 IFIP/IEEE International Symposium on Integrated Network Management (IM2013): Short Paper

787

Computing Cryptographic Pairing in Sensors
Zhibin Zhou
Arizona State University

Dijiang Huang
Arizona State University

zhibin.zhou@asu.edu

dijiang@asu.edu

Abstract

tions and results of Tate pairing in lightweight devices such
as PDA and smartcard, respectively.

In this paper, we present a methodology and preliminary result of computing the Tate Pairing on a supersingular curve over a prime field in the wireless sensors (MICAz Mote). The aim of this work is to study the feasibility of pairing based protocols and applications in sensors with limited computational resources. Tate pairing
is the most computationally intensive computation in most
pairing-based cryptographic algorithms. Our preliminary
results showed that without hardware upgrades (esp. memory) or further optimization of algorithms and parameters,
sensors not yet ready for computing pairing-based cryptographic algorithms.

3 Pairing Preliminaries and Testing Platform
Let n be a natural number coprime to q. The Tate pairing
of order n is the bilinear map:
en (P, Q) : E(Fq )[n] × E(Fkq )[n] → Fq∗k .

(1)

It has the following properties:
1) Bilinearity: en (P1 + P2 , Q) = en (P1 , Q) · en (P2 , Q)
and en (P, Q1 + Q2 ) = en (P, Q1 ) · en (P, Q2 ) for all
P, P1 , P2 ∈ E(Fq )[n] and all Q, Q1 , Q2 ∈ E(Fqk [n]).
2) Nondegeneracy: If en (P, Q) = 1 for all the Q ∈
E(Fqk [n]), then P = O. Alternatively, for each P 6= Q
there exists Q ∈ E(Fqk [n]) such that en (P, Q) 6= 1.
MICAz sensor running TinyOS was used for implementing Tate pairing. The pairing implementation was developed in TinyOS operating system using NESC programming language. TinyOS is an open source embedded system operating system targeted for wireless sensor network.
It is written in Nesc language as a set of cooperating tasks
and processes. The hardware configurations are given in
following Table:

1 Introduction
Pairing-based cryptography is based on elliptic curve operations. The central idea of pairing is the construction of a
mapping between two finite groups. It allows for new cryptographic schemes using the transformation from one group
to the other group. Much research has showed that pairing has great potential in wireless sensor networks. However, the really evaluation of pairing in sensors have not
been studied in literature. In this paper, we show that the
computation of pairing in wireless sensors (MICAz) is conditionally feasible. We have the following contributions:
1) We implement the Tate pairing algorithm using Nesc
in 8-bit processor sensor, i.e., MICAz Mote.
2) We adopt majority of available optimizations for pairing operations and make several improvements of the pairing algorithms over a supersingular curve.
3) Based on our research results, we propose some future
software based improvements for pairing implementations
in sensors.

Model
Micro-controller
Clock Speed
RAM
Program Memory
Flash
Radio Frequency

MICAz
ATMega128L (8 bit)
7.37 MHZ
4 KB
128 KB
512 KB
2400 MHZ

We have to make sure the size of memory required by
the program variables does not exceed 4 KB. Since MICAz
has only a 8 bit processor, the computation of pairing takes a
long time because all primitive operations of pairing are Big
integer operations and they have to be implemented using
Multi-precision algorithms.

2 Related Work
Most of pairing algorithms are based on Miller Algorithm [8]. In [1, 3], the authors described in details of various solutions to implement Tate pairing in the characteristic
2 and 3 for large prime numbers. In the [6], the authors reported an implementation of Tate pairing in MICAz sensor
which used 256-bit prime field with 128-bit sub-group size.
In [9] and [2], the authors demonstrated the implementa-

4 Results and Observations
In this section, we present the dome preliminary results
for computing Tate pairing in MICAz sensor and some observations through our implementation.
1

4.1

Implementation Results

Our preliminary implementation is based on a modified Miller Algorithm to compute Tate pairing on a MICAz
Mote. The MICAz Mote runs TinyOS using NESC programming language. The primitive operations of pairing,
i.e., field operations on Fp were implemented using the software package RSAREF [5] provided by RSA Laboratories.
In addition, we implemented our own field operations on
Fp2 and we modified the point addition function provided
by TinyECC [7] to calculate the slope function which is one
of the time consuming operations of pairing. The following parameters were used in our implementation. The cost
Super Singular curve : y 2 =
x3 + x
k:2
l : 160 bit Solinas prime
p : 256 bit

Curve
Embedded Degree
Sub-group size
Prime

of running one Tate pairing operation in MICAz is given in
the following Table. The cost is measured in terms of computational time and memory usage. The memory usage is
further divided to indicate the amount of the program memory and data memory (RAM) used by the program.
Tate Pairing
on MICAz
Time
Data memory
(RAM)
Program memory (Flash)

4.2

2) Implement more efficient field multiplications for sensors. In the paper [4], the author proposed a multiplication
algorithm which combines column-wise and row-wise multiplication to reduce the number of memory access during
the computation. We can actually implement and test the
algorithm in the MICAz Mote.
3) Adopt memory efficient system parameters. As a matter of fact, there is a tradeoff between the memory usage
and the computation speed. If we use the finite field with
the characteristic 2 or 3, the embedded degree k increase to
4 or 6, which means the pairing is mapped to F2m or F3m ,
respectively. However, to reach the same security level as
Fp where p is a 512-bit prime, each group element can be
256 bits or 160 bits, compared to 512-bit in the Fp .
4) Implement pairing in Imote sensors Imote sensor are
equipped with more powerful hardwares and thus is more
suitable for test platform.

6 Conclusion

31.25 seconds
974 bytes

Memory consumption percentage
24%

From our preliminary implementation of pairing in MICAz, we showed that computing secure Tate pairing in MICAz is quite expensive. We have also identified various
optimizations to improve the computational time and memory usage of pairing in sensors. Therefore without hardware
upgrades especially memory or further optimizations it may
be infeasible to implement 512 bit pairing in Micaz. Our future work will be implement more optimized tate pairing in
Micaz and Imote sensors.

16686 bytes

13%

References

Cost

Observations

The following are some of the observations we made
through the pairing implementation.
1) Dynamic allocation of memory posed some problems
while computing pairing in MICAz though it is efficient in
terms of memory usage than static allocation. This is because pairing by itself is time consuming operation for sensor and dynamic memory allocation would further increase
the time.
2) We also observed that calculating slope of point addition is faster using affine coordinates system compared to
using projective coordinates system.
3) We tried to compute Tate pairing using 512 bit prime
number p instead of 256-bit p to achieve higher security. We
observed that 512-bit field operations are very expensive in
terms of memory for MICAz. With the given hardware,
pairing could not run to completion.

5 Future Improvements
To further improve the efficiency, we can adopt the following strategies:
1) Adopt precomputation in the pairing implementation.

[1] P. Barreto, H. Kim, B. Lynn, and M. Scott. Efficient
algorithms for pairing-based cryptosystems. Advances in
Cryptology–Crypto, 2442:354–368, 2002.
[2] G. Bertoni, L. Chen, P. Fragneto, K. Harrison, and G. Pelosi.
Computing Tate Pairing on Smartcards. White Paper STMicroelectronics, 2005.
[3] S. Galbraith, K. Harrison, and D. Soldera. Implementing the
Tate pairing. Algorithmic Number Theory 5th International
Symposium, ANTS-V, 2369:324–337.
[4] N. Gura, A. Patel, A. Wander, H. Eberle, and S. Shantz. Comparing Elliptic Curve Cryptography and RSA on 8-bit CPUs.
Proceedings of Workshop on Cryptographic Hardware and
Embedded Systems (CHES 2004), 2004.
[5] R. Laboratories. Rsaref: A cryptographic toolkit, version 2.0.
1994.
[6] E. M. F. D. J. L. Leonardo B. Oliveira, Diego Aranha and
R. Dahab. TinyTate: Identity-Based Encryption for Sensor
Networks.
[7] A. Liu and P. Ning. Tinyecc: Elliptic curve cryptography for
sensor networks.
[8] V. Miller. Short programs for functions on curves. Unpublished manuscript, 1986.
[9] A. Ramachandran, Z. Zhou, and D. Huang. Computing Cryptographic Algorithms in Portable and Embedded Devices. to
appear at IEEE PORTABLE 2007.

C-Mix: A Lightweight Anonymous Routing
Approach
Vinayak Kandiah, Dijiang Huang, and Harsh Kapoor
Arizona State University

Abstract. Low latency mix networks such as onion routing (Tor), heavily utilize cryptographic operations for transmitting a message to the
receiver resulting in substantial computational and communication overhead. To address the performance and security issues of low latency mix
networks, we propose a novel anonymous routing scheme called C-Mix.
Its design principles are inspired by network coding techniques and the
properties of polynomial interpolation. Based on our security analysis
and performance evaluations, C-Mix achieves same level of anonymity
with comparable computation overhead in comparison to traditional low
latency mix networks.

1

Introduction

Communication networks are used in various activities of our everyday life and
have become commonplace. A signiﬁcant portion of the communications taking
place over a conventional wired network requires both cryptographic security and
user anonymity. Cryptographic security ensures secrecy of the message while user
anonymity deals with hiding the identities of the communicating users and the
routing path in the network. Several techniques have been proposed to achieve
anonymity over communication networks [1,2,3,4]. Extensive research has taken
place in the last few decades in a great eﬀort to keep data communications private and anonymous. One main class of solutions that achieves user and path
anonymity is based on Onion Routing, such as [5,3] and I2P [6], which provide
anonymity for low latency networks using cryptographic operations and overlay
techniques. Under normal circumstances, mix networks which use several Chaumian nodes provide anonymity, i.e. attackers cannot gain end-to-end routing
information from the network. However, they are vulnerable to various active
and passive attacks [7,8,9,10,11]. Many implementations of anonymous services
for low latency networks and the Internet such as Tor and I2P [5,6] are based
on onion routing. For example, onion routing (Tor) performs multiple encryptions and decryptions for both path setup phase and data forwarding phase. The
amount of computation performed by the sender of a message (i.e., the sender
performs multiple encryption for both path set up and data transmissions) is not
commensurate with the computation at the other nodes in the network. Hence,
scalability suﬀers when implemented in networks with low computation capability. This situation is especially true when a user wants to voluntarily use his/her
K. Solanki, K. Sullivan, and U. Madhow (Eds.): IH 2008, LNCS 5284, pp. 294–308, 2008.
c Springer-Verlag Berlin Heidelberg 2008


C-Mix: A Lightweight Anonymous Routing Approach

295

non-high-performance computer (no dedicated hardware for cryptography computation) as a relay node to improve the communication anonymity. Thus, it is
highly desirable to improve the computation eﬃciency of mix networks.
To address above describe issues of Mix networks, we present a novel technique
– C-Mix – a coding inspired anonymous routing scheme. This new technique is
inspired by network coding [12] where the information is processed and coded by
each forwarding node. However, instead of using XOR coding method, we utilize
the properties of polynomial interpolations [13] to achieve our security goal. In
particular, the proposed anonymous scheme requires the use of the onion structure (public key cryptography) only during the path setup phase. Once a packet
forwarding path has been established, no encryption/decryption is required to
forward messages. C-Mix reconstructs the message in a distributed hop-by-hop
manner. In this way, the intermediate nodes are only required to perform a few
multiplications and addition operations over a ﬁnite ﬁeld Zp instead of performing the decryption operation. As a result, less computation eﬀorts required at
mix nodes in the network, thus improving the eﬃciency of the system. When
compared to AES encryption/decryption, C-Mix signiﬁcantly reduces the computation involved at the sender nodes and some improvements are achieved at
forwarding nodes as well. Speciﬁcally, in cases where the size of the message
is signiﬁcantly greater than the size of the ﬁnite ﬁeld Zp , our scheme greatly
reduces the computational overhead at the mix nodes. The primary goal of this
new technique is to introduce a novel Mix technology to reduce the computational overhead for Mix nodes. At the same time, it provides same level of
anonymity and security as onion routing based mix schemes under strong attack models. Compared to existing low-latency mix networks, C-Mix is built
on a stronger attack model, i.e., the adversaries are global passive or active
observers. We evaluate the security and anonymity performance of C-Mix under insider colluding attacks, blending attacks, and traﬃc analysis attacks. The
message secrecy can be proven based on the polynomial interpolation properties.
We will show that C-Mix has levels of security and anonymity akin to those of
the onion routing–based mix networks. Performance testing of the underlying
mathematical techniques used in the proposed scheme has been done using real
experiments.
The rest of the paper is organized as follows. Section 2 contains the system
and models that will be used in C-Mix. In section 3, the formal mathematical
foundation of C-Mix is provided. The security, anonymity and performance of
the proposed scheme is analyzed and compared with onion routing in section
4. Finally, the scope for future work and concluding remarks are provided in
section 5.

2

System and Attack Model

In this section, we ﬁrst present the fundamentals of polynomial interpolation
and the attack models used to evaluate the proposed technique.

296

2.1

V. Kandiah, D. Huang, and H. Kapoor

Polynomial Interpolation and Secret Sharing

Polynomial Interpolation based secret sharing scheme [13] has been proposed to
share a secret among Nusr entities such that any t ≤ Nusr entities can recover
the secret but any t < t entities know no more about the secret than any
non-participating entity. This scheme is based on the interpolation property of
polynomials computed over a ﬁnite ﬁeld Zp according to which, a polynomial
equation y(x) of degree (t − 1) can be reconstructed only if at least t points that
lie on y(x) are available. A degree t − 1 polynomial of the form
y(x) = a0 + a1 x + a2 x2 + a3 x3 + . . . + at−1 xt−1

(1)

is constructed, where a0 equals the secret S (i.e., the y-intercept of the curve)
and the other coeﬃcients a1 , a2 , . . . , ak−1 are chosen randomly over the ﬁeld
Zp . Now, Nusr points {(xj , yj )|1 ≤ j ≤ Nusr } on the curve are obtained
and distributed to the participating entities. Any t of these Nusr entities can
combine their points to reveal the secret. The polynomial y(x) can be reconstructed using the Lagrange Interpolation formula. If the points are represented
as {(x1 , y1 ), (x2 , y2 ), . . . , (xt , yt )}, the Lagrange Interpolation formula is
given by:
t
t


x − xk
bi yi
where, bi =
.
(2)
y(x) =
xi − xk
i=1
k=1,k=i

The traditional secret sharing scheme is operated in a centralized system,
i.e., all participants submit their points to a server which computes the secret.
In C-Mix, we need to decentralize the secret sharing algorithm, and we require
that without the destination’s involvement, intermediate nodes cannot collude
to derive the secret.
2.2

Attack Model

We now present the attack models, against which the new scheme is evaluated.
The attacks chosen in this paper are the ones that are commonly used to evaluate an anonymous routing scheme. In addition, these attacks are representative
of the various classes of attacks like passive/active, internal/external. A passive attack is one where the adversary does not modify or alter the functioning
of the anonymous scheme. An active attack on the other hand involves some
form of intentional modiﬁcation to the working of the scheme by the attacker
like dropping, modifying or delaying the messages. An external attack is a form
of attack where the adversary only has access to the communication links and
hence cannot aﬀect the intermediate nodes and an internal attack is one where
the adversary can observe and/or modify the internal operations performed by
the forwarding intermediate nodes in the network. We do not make restrictive assumptions for the attack models enabling us to evaluate our new scheme against
a powerful adversary. Proving the anonymity and security of our scheme against
a powerful attacker will obviously show the scheme’s security and anonymity in

C-Mix: A Lightweight Anonymous Routing Approach

297

a practical attack which may be less powerful. Without losing generality, our
discussion focuses on three attacks. The collusion attack is an internal attack,
where two or more forwarding nodes share all their knowledge regarding the
data transmissions. The blending [7] and traﬃc analysis attacks are external.
However, the blending attack is active while the traﬃc analysis attack is passive. The C-Mix relies on hop-by-hop in-network data processing, and it does
not use cryptographic method to protect the message integrity. We assume that
the end-to-end message integrity checking is at the application layer. In section
4, we examine the security and anonymity provided by our scheme when these
attacks are deployed.

3

C-Mix Anonymous Routing Scheme

In this section, we start with the principles of our approach and then iteratively
reﬁne it by adding new mechanisms to increase the security and anonymity of
the scheme. A list of symbols that are frequently used in the description of the
C-Mix is provided in Table 1.
C-Mix involves three phases: virtual circuit setup, data transmission, and virtual circuit termination, which are described as follows. However, unlike onion
routing, we do not use any form of symmetric encryption or decryption during
the data transmission phase. We do not provide much detail about the circuit
termination phase as breaking down a virtual circuit is trivial and can be performed by transmitting some equivalent of a KILL message.
Virtual Circuit Setup. In the circuit initiation phase, the sender (or source)
identiﬁes the path to be followed to the intended receiver (or destination). Let
Table 1. List of Symbols
Symbol

Description

General
Number of forwarding nodes on the path.
Integer value chosen by sender for circuit initiation.
Polynomial used by sender for circuit initiation.
Forwarding node i.
Sender.
Destination.
Number of messages to be transmitted.
Indicates the current message being transmitted (1 ≤ α ≤ N U M ).
Curve chosen by sender for message α.
C-Mix Scheme
binit(i)
Secret b value for node i obtained during circuit initiation.
(xi , yi )
Secret point for node i obtained at circuit initiation.
(xα(L+2) , yα(L+2) ) Point chosen by sender for transmission of message α.
bα(i)
b value to be used by node i for transmission of α message.
L
INIT
yinit (x)
Mi
sd
dn
NUM
Iα
yα (x)

298

V. Kandiah, D. Huang, and H. Kapoor

Fig. 1. Circuit Setup: Information distributed to the C-Mix nodes

there be L forwarding nodes in the path, which means L + 2 nodes (including
sender and destination) are involved in the complete route. The sender now
prepares an INIT value which is an integer over a ﬁnite ﬁeld Zp . In rest of the
paper, we assume all calculations are done over a ﬁnite ﬁeld Zp and we do not
explicitly show it. The sender now chooses a polynomial yinit (x) over the ﬁeld
Zp which has INIT as the y–intercept:
yinit (x) = INIT + a1 x + a2 x2 + a3 x3 + . . . + aL xL .
The curve yinit (x) has a degree L and the sender now determines L + 1 points
that lie on it as {(x1 , y1 ), (x2 , y2 ) . . ., (xL , yL ), (xL+1 , yL+1 )}. Now, in order to
recompute the INIT value, we can substitute x = 0 and t = L + 1 in (2) to
obtain these new equations:
yinit (0) = INIT =

L+1

i=1

binit(i) yi ,

where

binit(i) =

L+1

k=1,k=i

xk
.
xk − xi

(3)

Now, the sender calculates the values (binit(i) |1 ≤ i ≤ L + 1) over the ﬁeld Zp .
In the circuit initiation phase, the INIT message need not be actually transmitted to the destination. The sender just uses this phase to distribute triplets
of the form (xi , yi , binit(i) ) |1 ≤ i ≤ L) to the L forwarding nodes and the
triplet (xL+1 , yL+1 , binit(L+1) ) to the destination. The xi , yi and binit(i) values
will be used in the data transmission phase. Thus, the sender uses an onion
to securely transmit the triplets to all forwarding nodes and the destination.
The sender ﬁrst prepares a header for the destination which contains the triplet
(xL+1 , yL+1 , binit(L+1) ) and the public keys of the forwarding nodes in the path.
This header is then encrypted using the destination’s public key. To the resulting cipher text, the sender attaches a header containing (xL , yL , binit(L) ) along
with the next hop and Time To Live (TTL) and encrypts the resulting content
with the forwarding node ML ’s public key. (Note that ML is the last forwarding
node on the path from sender to destination). In this way, the sender continues adding headers and encrypting iteratively in the reverse order of the path
(i.e. last public key encryption will be using M1 ’s public key). The sender then

C-Mix: A Lightweight Anonymous Routing Approach

299

transmits this onion message into the network. Each intermediate forwarding
node i upon decryption of the onion message will perceive the message as:
{nextHop, {(xi , yi , binit(i) )}, T T L, {payload}},
where the {payload} is an inner onion message. The ﬁrst forwarding node M1
on the path receives the onion message from the sender and decrypts it using
its private key to read the header. M1 realizes that this is a request to create a
virtual circuit and hence generates a new VCI for this communication interface.
The forwarding node then associates the previous hop, next hop and the triplet
(x1 , y1 , binit(1) ) with the VCI and stores this information. This indicates to M1
that for future data transmissions through the same interface it will have to
use (x1 , y1 , binit(1) ) to operate on the message and forward it to the next hop
(indicated by the VCI). In this way, as the onion message is transmitted through
the network, a virtual circuit is created from the sender to the destination.
The triplets obtained by each node should not be disclosed as they are considered as secrets and will be used in the data transmission phase. The sender
also retains all the triplets that it calculated and transmitted for this path.
Note that each pair of neighboring nodes will choose their own VCI for the
circuit being created. When the onion message reaches the destination the last
layer of the onion message is decrypted and the destination obtains the triplet
(xL+1 , yL+1 , binit(L+1) ). Figure 1 shows the values that each node on the path
from sender to destination will store after the transmission of this onion message. Also in ﬁgure 1, though the previous hop of M1 shows sd and the next
hop of ML shows dn these are not revealed as the sender and destination. This
is because sd and dn are just identiﬁers of the nodes and are no diﬀerent from
the identiﬁers M1 or ML . We just use the sd and dn notations to clearly show
the sender and destination to the reader. The destination will also receive the
public keys of all the intermediate nodes in this path in the innermost layer of
the setup message along with the triplet. Using these public keys, the destination
now prepares a reply onion to the sender which will be sent through the reverse
path (i.e. ML → ML−1 → . . . M1 → Sender). The sender on receiving this reply
onion will know that the virtual circuit to the destination has been successfully
setup and is ready for data transmission.
Data Transmission Phase. Let us assume that there are N U M messages
to be sent by the sender. The sender then maps these N U M data packets to
integers I1 , I2 , . . . , IN UM over the ﬁeld Zp using a publicly known two–way
function M ap(). This function M ap() could be sent to the destination using
the onion header during the circuit setup phase. To transmit an integer Iα ,
where, 1 ≤ α ≤ N U M , the sender uses the point (0, Iα ) along with the points
{(x1 , y1 ), (x2 , y2 ), . . . , (xL , yL ), (xL+1 , yL+1 )} to compute a polynomial yα (x) of
degree L + 1 using polynomial interpolation. The sender can now identify a new
point {xα(L+2) , yα(L+2) } that lies on the polynomial yα (x). The construction of
the curve yα (x) and its relationship with the initial curve yinit (x) are shown in
ﬁgure 2. The nodes on the path already possess L + 1 points that lie on the

300

V. Kandiah, D. Huang, and H. Kapoor

y

(xL, yL)

(xL+1, yL+1)

(xa(L+2), ya(L+2))

(xj, yj)
INIT

(x1, y1)

(x2, y2)

Ia
0

x

yinit(x)

ya(x)

Fig. 2. Relationship between Circuit Initiation and Message Transmission Curves

polynomial yα (x), i.e., the points {(x1 , y1 ), (x2 , y2 ), . . . , (xL , yL ), (xL+1 , yL+1 )}
that were distributed during circuit setup. If we consider {xα(L+2) , yα(L+2) }
being the L + 2th point, then the sender along with the destination and the L
forwarding nodes now have the potential to recalculate Iα using the following
equations which are derived from (3):
yα (0) = Iα =

L+2

i=1

bα(i) yi

where, bα(i) =

L+2

k=1,k=i

xk
.
xk − xi

(4)

For nodes i = 1 . . . L + 1 (i.e. the forwarding nodes and the destination), bα(i)
can be calculated as:
xα(L+2)
.
(5)
bα(i) = binit(i)
xα(L+2) − xi
From (5), each node i (where, 1 ≤ i ≤ L+1) can calculate the bα(i) values from
binit(i) , xi and xα(L+2) . Each node i knows its binit(i) and xi , and hence only needs
the xα(L+2) value. Also, the nodes are distributed over a network and hence the
calculation speciﬁed in (4) should be done in a distributed manner while ensuring
that the destination is able to determine Iα . The following procedure ensures
that these requirements are satisﬁed.
1. The sender uses (4) to obtain bα(L+2) from which bα(L+2) . yα(L+2) can be
calculated.
2. The sender transmits this along with xα(L+2) to the forwarding node M1 .
(Note that the sender can calculate bα(L+2) as it has stored all the points it
distributed to the other nodes).
3. The intermediate node M1 now computes bα(1) . y1 and adds this to the value
bα(L+2) . yα(L+2) received from the previous hop to generate a new payload.
(Note that the node can calculate bα(1) using (5)). This new payload is then
transmitted to M2 along with xα(L+2) .
4. M2 performs operations similar to node M1 and forwards the payload to the
next hop along the path.
This procedure is continued until the destination adds bα(L+1) . yL+1 to the payload it receives to reveal Iα . Remember that all the above calculations are performed over the ﬁnite ﬁeld Zp .

C-Mix: A Lightweight Anonymous Routing Approach

301

An Example of Using C-Mix Basic Scheme. A simple example is provided
to illustrate the operations of the C-Mix basic scheme. To simplify the presentation, the following example is demonstrated over the characteristic ﬁeld zero. Assume the following 3-hop routing path for this example: sd → M 1 → M 2 → dn,
where sd is the sender and dn is the destination. Hence, for this case L = 2.
Let the INIT value chosen by the sender be 20 and let the polynomial of degree
2 be: yinit (x) = 20 + 4x + 3x2 . The sender then locates the following 3 points
on the curve: {(1, 27), (2, 40), (3, 59)}. The sender also calculates the binit(i) values as: binit(1) = 3, binit(2) = −3, binit(dn) = 1. The sender distributes the
triplets {(1, 27, 3), (2, 40, −3), (3, 59, 1)} to the forwarding nodes and the destination. This completes the circuit setup phase. Now, let us assume that the
sender needs to transmit I1 = 31 to the destination. The sender ﬁrst constructs a polynomial of degree 3 (as, L + 1 = 3) using the following points:
{(0, 31), (1, 27), (2, 40), (3, 59)}. The resulting polynomial of degree L + 1 = 3 is
97
3
2
y1 (x) = − 11
6 x + 14x − 6 x + 31.

b 1(L+2) =-1

b 1(1) =4

Payload:
- 73

`

(a)

b 1(2) =-6

Payload:

Payload:

I1:

35+(-6) (40) =-205 - 205 +(4) (59) =31

- 73 +(4) (27) =35

- 73 .

b 1(L+1) =4

35 .

- 205 .

`

(b)

Fig. 3. (a) Shared points on the initialization and I1 polynomials. (b) Calculations
performed at each node during transmission of I1 .

Note that the two curves y1 (x) and yinit (x) share the points held by the intermediate nodes and the destination as shown in ﬁgure 3(a). The calculations
performed at each node and the payload forwarded during transmission of I1
is shown in ﬁgure 3(b). Next the sender ﬁnds the L + 2th point on this curve
as (4, 73). The b1(L+2) value is calculated by the sender as −1. The payload
for initial transmission is prepared as b1(L+2) y1(L+2) = −73 which is transmitted along with x1(L+2) = 4 to M1 . The forwarding node M1 calculates b1(1)
x1(L+2)
4
as: b1(1) = binit(1) x1(L+2)
−x1 = 3 4−1 = 4. Thus, the new payload is calculated as −73 + (4)(27) = 35 and it is forwarded to M2 . Similar to the previous step, M2 can calculate b1(2) = −6 and recompute the new payload as

302

V. Kandiah, D. Huang, and H. Kapoor

35 + (−6)(40) = −205. The destination gets this new payload and calculates
b1(L+1) = 4 and I1 = −205 + (4)(59) = 31. It can also be observed from this
simple example that the intermediate nodes cannot collude to derive I1 .
Using Globally Determined xα(L+2) Values. Previously presented C-Mix
scheme is susceptible to colluding nodes or passive traﬃc analysis attack, which
allow the adversary to obtain information about the path. The anonymous routing scheme based on polynomial interpolation needs to ensure that a forwarding
node calculates diﬀerent bα(i) yi values for each transmission along the virtual
circuit. Also, colluding nodes on a virtual circuit should not be able to obtain path information by comparing xα(L+2) values that are propagated by the
sender.
To achieve the above desired property, we propose to use a globally known
function Ψ (α) which determines an xα(L+2) for every data transmission Iα where
(1 ≤ α ≤ N U M ). This function should be made accessible to all the users
(senders and destinations) and forwarding nodes across the network. The forwarding nodes will use Ψ (α) for all virtual circuits that they are handling. Thus,
all nodes on the path keep a track of the number of messages transmitted through
each virtual circuit. After the sender has calculated the new polynomial yα (x)
for the message Iα , it uses Ψ (α) as its x–coordinate xα(L+2) (where α is basically one plus the number of messages it has previously sent through the circuit). The sender obtains the corresponding yα(L+2) from the polynomial. It
then calculates the bα(L+2) yα(L+2) value and transmits this as the payload to
the ﬁrst forwarding node M1 . As it is easy for M1 to keep track of the number
of messages it has forwarded so far for this particular VCI, it can determine
Ψ (α)
. The node M1 can then
xα(L+2) = Ψ (α) and update its bα(1) as binit(1) Ψ (α)−x
1
determine binit(1) y1 , update the payload and forward it to the next node on
the path. In general, a node Mi (or the destination) can update its bα(i) as:
bα(i) = binit(i)

Ψ (α)
.
Ψ (α) − xi

(6)

In this manner, all nodes in the network including the sender and the destination can calculate the appropriate value for each transmission α. This ensures
that each node calculates diﬀerent bα(i) yi for every transmission. This will prevent a passive attacker from correlating incoming and outgoing messages at a
node because the diﬀerence in value between the incoming and outgoing messages
is diﬀerent for every transmission. This approach of using globally determined
values also mitigates the collusion attack. Note that the forwarding node uses
the same global function Ψ (α) for all the virtual circuits that it supports and
the number of transmissions (α) for every virtual circuit begins at 1 and increments by 1 for every transmission. As a result, two or more colluding nodes
cannot compare their Ψ (α) values to determine path information for a particular
sender–destination pair because for a particular α the Ψ (α) value is the same
for every virtual circuit in the system.

C-Mix: A Lightweight Anonymous Routing Approach

303

However, it is likely that diﬀerent senders (sd1 , sd2 , . . .) have diﬀerent number of messages to transmit (N U Msd1 , N U Msd2 , . . .). Consider a case where a
sender has a lot of messages to transfer than the average in the network. After
a period of time, only that sender will have very high α values. In this scenario, when forwarding nodes collude, they will notice the presence of a virtual
circuit with a large α value. Although two or more non-contiguous forwarding
nodes cannot determine with complete certainty that the virtual circuits with
the high α are on the same path, the probability of these colluding forwarding
nodes being on the same path is high. In order to oﬀer better protection against
collusion in such scenarios it is necessary to ensure that each virtual circuit can
only transmit messages until a certain αmax and a corresponding Ψ (αmax ) are
reached. After the sender has sent αmax messages through the path, the circuit
must be broken down and a new virtual circuit (which may take a diﬀerent
path) must be created. Thus the sender needs to continually do this until all
its N U Msd messages are transmitted. The sender uses this new virtual circuit
to transmit the remaining messages (Iαmax +1 . . . IN UMsdX ) messages assuming
(N U MsdX < 2αmax ). However, when the sender transmits the message Iαmax +1 ,
it is the ﬁrst message transmitted through the new virtual circuit. As a result
all nodes in the path consider α = 1 and use Ψ (1) to calculate bα(i) . Thus, the
sender also uses xα(L+2) = Ψ (1) to calculate bα(L+2) and yα(L+2) . In eﬀect, the
virtual circuit uses α = 1 . . . (N U MsdX − αmax ) for the transmission of messages (Iαmax +1 . . . IN UMsdX ). In this case, we assumed that the sender sdX only
needed 2 virtual circuits to transmit all messages to the intended destination.
However, in general the number of virtual circuits that need to be constructed
by a sender is given by the following equation:
Number of VCs for sdX = RndU p(

N U MsdX
),
αmax

where RndU p() rounds the result to the ceiling function.
We must note that each forwarding node may support multiple virtual circuits.
The forwarding node also keeps track of the α value for each of these virtual
circuits. When the αmax value is reached for a particular VC, only that circuit
is torn down while the functioning of all other VCs supported at the forwarding
node is unaﬀected. Using this scheme of Globally determined xα(L+2) values
bounded by αmax , C-Mix scheme is resilient to collusion attacks by comparing
α values.

4

Security, Anonymity, and Performance Analysis

In this section, we ﬁrst discuss how the various attacks can be launched on the
C-Mix scheme and what the attacker can learn from these attacks. The impact of
the revealed information on the security and anonymity of the proposed scheme
is also evaluated. In the second part of this section, we present the performance
analysis of the C-Mix scheme which is based on experimental results.

304

4.1

V. Kandiah, D. Huang, and H. Kapoor

Anonymity and Security Analysis of the C-Mix Scheme against
Attacks

The attack model is described in section 2.2. The eﬀect of the various attacks
and the extent of information revealed from them are discussed here.
Resilience to Collusion Attack. This is a type of attack where several forwarding nodes in C-Mix collude and try to obtain the path information and the
message being transmitted. In a scenario where the colluding nodes are contiguous, the path information will be revealed. This is obvious because a forwarding
node can compare the messages it sent with the messages received by neighboring node. Now we consider a case where there is at least one uncompromised
node F Nh in the network. This is suﬃcient to preserve the end–to–end path
anonymity. The colluding nodes can track the path up to the node F Nh . However, the colluding nodes do not know the results of the calculations performed by
F Nh . Hence, they cannot track the path by just observing the output messages
of F Nh .
Thus, when a collusion attack is launched, the level of anonymity and security
provided by the C-Mix scheme is similar to those provided by the onion routing–
based schemes. Even in onion routing–based schemes, a single uncompromised
node is suﬃcient to preserve end–to–end path anonymity and non-contiguous
colluding nodes can compare the number of messages transmitted through a
virtual circuit.
Blending Attack. A successful blending attack discloses the portion of the path
which is enclosed by the compromised nodes. However, it is necessary to check
if any other information is revealed by the attack. To increase the amount of
information unknown to attacker at each node, we allow each node to have more
than one triplet. We call the number of triplets held by a node for a virtual circuit
as a ”multiplicity”. In the ﬁrst case, assume that the attacker has also been able
to obtain the secret multiplicities of each node. Consider a blending attack at
a node on the transmission path. The adversary can observe the incoming and
outgoing message at the compromised node and calculate their diﬀerence as a
constant K over the ﬁeld Zp . In this case, if the attacker can carry out adequate
blending attacks he/she can construct suﬃcient equations which the forwarding
node would have used to obtain K. If the number of equations is equal to or
more than the number of unknowns, the system of equations can be solved over
the ﬁeld Zp . The solution will reveal the triplets held by the node i. However,
this information in turn can only reveal the next hop (which is already known
to the attacker) and does not compromise other forwarding nodes. In a more
practical scenario where the adversary does not know the multiplicity, it is more
diﬃcult for the attacker to obtain equations and solve them. The attacker will
have to guess the lowest and highest possible multiplicities and obtain systems
of equations for each possible multiplicity value in the range. Also, the blending
attack does not compromise the secrecy of the message Iα as the adversary
cannot obtain the receivers triplets. When compared to onion routing–based

C-Mix: A Lightweight Anonymous Routing Approach

305

schemes, the security of the C-Mix scheme is the same – the message cannot
be revealed. However, in terms of anonymity C-Mix may reveal the triplets of
forwarding nodes in addition to the next hop. But, this is not very useful as the
compromised triplets cannot be used to track the path at other nodes.
Traﬃc Analysis Attacks. Finally, the impact of traﬃc analysis attacks on the
proposed scheme is discussed. The simplest form of traﬃc analysis involves identifying transmission paths by examining the network for changes in the size of messages and similarities in the appearance of the messages. Both these techniques will
be unsuccessful against our scheme because we use globally determined xα(L+2)
values and multiple (xi , yi , binit(i) ) triplets for each node. These two techniques
make the same message Iα appear diﬀerently over diﬀerent links. However, C-Mix
is still vulnerable to long term traﬃc analysis attacks like the hitting set attack
[14] as these attacks are based on the volume of traﬃc sent and received by the end
users. The secrecy of the message Iα is not compromised by passive traﬃc analysis
attacks. Even though the payloads are not encrypted, the attacker cannot deduce
the ﬁnal value of the message by observing the intermediate values. This is due to
the fact that the values held by the destination can be obtained only if the exact
polynomial used is known and there is no way for the passive attacker to determine
the polynomial. Also, it is not possible for the adversary to deploy dictionary attacks on the observed data values to deduce the message (Iα ). A dictionary attack
is one where the adversary obtains various cipher–text messages which were encrypted using the same symmetric key. Then using frequencies of occurrence for the
letters in the English Alphabet, the attacker decodes the cipher text to obtain the
plain–text. In the proposed scheme, even though the same function M ap() is used
for every transmission to convert text to integer messages, the value to be added
by the destination to recover the integer Iα changes for every transmission. As a
result, the frequency of occurrences of the numbers in the messages transmitted
from the last forwarding node to the destination is distorted. As for anonymity of
C-mix scheme the simplest form of traﬃc analysis involves identifying transmission
paths by examining the network for changes in the size of messages and similarities
in the appearance of the messages. Since all the calculations are performed in the
ﬁnite ﬁeld Zp , such attack will be unsuccessful.We note that the C-Mix scheme is
potentially still susceptible to well-deployed traﬃc analysis attacks like the timing
attack [15]. This is potentially because the existing low-latency mix networks are
relatively static and only involve small number of mix nodes, for example, Tor only
allows 3-hop path length route. Due to the computational and communication efﬁciency of C-Mix, we can allow a longer path and involve more mix relay servers.
With more nodes involved the end-to-end latency may be deviated more and thus
the consequence of timing attack can be also mitigated.
4.2

Computational Performance Assessment of C-Mix Based on
Experimental Results

In this section, we present the performance assessment based on our experimental results. The time taken to perform the encryptions in AES and the ﬁeld

306

V. Kandiah, D. Huang, and H. Kapoor

Multiplication (10 points)

Multiplication 1024 field size

Encryption - AES 256 CBC/CFB modes

AES 128-bit key encryption

Encryption - AES 128 CTR mode
8

1.2

7

1
0.8

5

Time (ms)

Time (ms)

6

4
3

0.6
0.4

2
0.2

1
0
512

0
1024

2048

4096

8192

16384

Message Size (bits)
(a) Comparision of C-Mix w ith AES (no. of nodes
= 10, Message size = Field size)

1024

2048

4096

8192

16384

Message size (bits)
(b) Comparison of C-Mix w ith AES-128 CTR mode
(field size = 1024, no. of nodes = 10)

Fig. 4. Performance Evaluations

multiplications were measured using the C/C++ code [16] and Maple, respectively. The hardware conﬁguration of the machine used for testing is: AMD 64
bit, 2 Ghz processor with 1G RAM. We assume an anonymous path that has 10
nodes. The encryption time was measured for AES 128-bit key and AES 256-bit
key encryption in CTR, CBC and CFB modes for various message sizes (512
bits to 16,384 bits). The time taken to perform multiplications with various values of ﬁnite ﬁeld and message sizes were recorded. The value of the ﬁnite ﬁeld
Zp is determined by the bit representation size of this value i.e. a 512 bit ﬁeld
means that the value of the ﬁeld is between 2511 + 1 and 2512 . In the ﬁrst case,
we assumed the sizes (not values) of the message and the ﬁeld to be the same.
With this assumption, we compare the time taken to perform AES encryption
with time taken to perform ﬁeld multiplications on various message sizes in Figure 4(a). For message sizes up to 4096 bits, it can be seen that C-Mix scheme
has computation cost between AES 128-bit key encryption and AES 256-bit key
encryption.
However, the computation time for C-Mix can be further optimized by selecting a ﬁnite ﬁeld size which is smaller than the message size. In this case, the
C-Mix will process the message in ﬁxed–size blocks (determined by ﬁeld size).
For example, a ﬁeld size of 1024 bits can process a 2048 bit message by operating on the ﬁrst 1024 bits and then on the second block. Note that choosing
a ﬁeld size smaller than message size does not compromise the security of the
message. Each block of size k bits will have the same security oﬀered by using a
k bit ﬁeld over a k bit message. The next comparison considers message whose
sizes are multiples of 1024 and shows the time taken to perform AES encryption
and C-Mix operations using a ﬁxed 1024 bit size ﬁnite ﬁeld. It can be seen from
Figure 4(b) that the time taken for preparing messages of all sizes is least when
C-Mix with a ﬁxed size ﬁnite ﬁeld. In onion–routing techniques, the intermediate

C-Mix: A Lightweight Anonymous Routing Approach

307

node just needs to perform one decryption and forward the message. In C-Mix,
the forwarding node needs to update its bα(i,j) values for each point it holds.
This involves one multiplication for each point possessed by the node. The time
observed for decryption of various size messages using 128 bit keys is very close
to the time taken to perform an encryption.
4.3

Communication Performance Analysis of C-Mix

After the path establishment phase, C-Mix sender does not need to create an
onion structure for data transmission (see Figure 3). Instead, the sender just
needs to specify the outgoing VCI number and attach the initial value I0 . Once
the second C-Mix node received the message, it checks its routing table and swap
a new outgoing VCI number and computer I1 = I0 + b1 y1 over the ﬁnite ﬁeld Zp .
Then the new computed value I1 is the new payload. Due to the ﬁeld operation,
the payload size will never increase. Using C-Mix, the communication overhead
is similar to the low latency mix network solutions such as Tor [17].
4.4

Storage Performance Analysis of C-Mix

In Tor, each intermediate node stores a shared key with the source. While in
C-Mix, each intermediate node needs to store one or multiple coordinates distributed by the source. Thus, the storage complexity of C-Mix is at the same
level of Tor.

5

Conclusion

Most of the existing anonymous routing schemes like Tor are based on the onion
routing technique. Onion routing requires multiple encryptions to be performed
by a sender for the transmission of each message. The forwarding nodes in the
transmission path decrypt once and forward to the next hop. Due to the heavy
use of encryption, these schemes have a considerable computational overhead
(especially at the sender). As a result, scalability suﬀers in large networks.
In this paper, we have proposed a novel anonymous routing technique called CMix inspired by network coding and the properties of polynomial interpolation.
C-Mix reduces the computation time required by the forwarding nodes for all
message sizes. In general, our proposed C-Mix scheme is built on strong attack
models and resilient to several global passive and active attacks, which are not
addressed by existing low-latency mix networks.
However, there is still scope for improving C-Mix and for applying these techniques in other computing environments. Particularly, our research challenges are
(a) Improving the computational eﬃciency further by reducing the number of
multiplications performed by the sender. (b) Enabling the sender to dynamically
change the path to the destination during the message transmission phase using
predistributed secrets. (c) Anonymity and security performance under traﬃc
analysis attacks is required for longer path length in large C-Mix networks. (d)
Apply the principles of C-Mix in wireless network environments.

308

V. Kandiah, D. Huang, and H. Kapoor

Acknowledgement
The authors would like to thank anonymous reviewers for their insightful comments to improve the quality of this paper.

References
1. Chaum, D.: Untraceable electronic mail, return addresses, and digital pseudonyms.
Communications of the ACM 24(2), 84–88 (1981)
2. Chaum, D.: The dining cryptographers problem: Unconditional sender and recipient untraceability. Journal of Cryptology 1(1), 65–75 (1988)
3. Goldschlag, D.M., Reed, M.G., Syverson, P.F.: Hiding Routing Information. In:
Anderson, R. (ed.) IH 1996. LNCS, vol. 1174, pp. 137–150. Springer, Heidelberg
(1996)
4. Gulcu, C., Tsudik, G.: Mixing E-mail with Babel. In: Proceedings of the Symposium on Network and Distributed System Security, pp. 2–16 (1996)
5. Dingledine, R., Mathewson, N., Syverson, P.: Tor: The Second-Generation Onion
Router. In: Proceedings of the 13th USENIX Security Symposium (August 2004)
6. I2P: Anonymizing Network, http://www.i2p.net/
7. Serjantov, A., Dingledine, R., Syverson, P.: From a Trickle to a Flood: Active Attacks on Several Mix Types. In: Petitcolas, F.A.P. (ed.) IH 2002. LNCS, vol. 2578,
pp. 36–52. Springer, Heidelberg (2003)
8. Back, A., Moller, U., Stiglic, A.: Traﬃc analysis attacks and trade-oﬀs in anonymity
providing systems. In: Moskowitz, I.S. (ed.) IH 2001. LNCS, vol. 2137. Springer,
Heidelberg (2001)
9. Danezis, G.: Statistical disclosure attacks: Traﬃc conﬁrmation in open environments. In: Proceedings of Security and Privacy in the Age of Uncertainty (SEC
2003), pp. 421–426 (2003)
10. Levine, B., Reiter, M., Wang, C., Wright, M.: Timing Attacks in Low-Latency
Mix Systems. In: Juels, A. (ed.) FC 2004. LNCS, vol. 3110, pp. 251–265. Springer,
Heidelberg (2004)
11. Zhu, Y., Fu, X., Graham, B., Bettati, R., Zhao, W.: On ﬂow correlation attacks
and countermeasures in mix networks. In: Martin, D., Serjantov, A. (eds.) PET
2004. LNCS, vol. 3424, pp. 207–225. Springer, Heidelberg (2005)
12. Ahlswede, R., Cai, N., Li, S., Yeung, R.: Network information ﬂow. IEEE Transactions on Information Theory 46(4), 1204–1216 (2000)
13. Shamir, A.: How to Share a Secret. Communications of the ACM 22(11), 612–613
(1979)
14. Kesdogan, D., Pimenidis, L.: The Hitting Set Attack on Anonymity Protocols.
In: Fridrich, J. (ed.) IH 2004. LNCS, vol. 3200, pp. 326–339. Springer, Heidelberg
(2004)
15. Murdoch, S., Danezis, G.: Low-cost Traﬃc Analysis of Tor. In: IEEE Symposium
on Security and Privacy, pp. 183–195. IEEE CS, Los Alamitos (2005)
16. Gladman, B.: AES-CTR C Implementation,
http://fp.gladman.plus.com/cryptography technology/fileencrypt/index.
htm
17. Dingledine, R., Mathewson, N.: Tor Protocol Speciﬁcation,
http://www.torproject.org/svn/trunk/doc/spec/tor-spec.txt

J Netw Syst Manage (2012) 20:463–467
DOI 10.1007/s10922-012-9254-0
GUEST EDITORIAL

Cloud Computing, Networking, and Services
Bhumip Khasnabish • Dijiang Huang • Xiaoying Bai
Paolo Bellavista • Gregorio Martinez •
Nick Antonopoulos

•

Received: 14 August 2012 / Revised: 31 August 2012 / Accepted: 31 August 2012 /
Published online: 9 September 2012
 Springer Science+Business Media, LLC 2012

Welcome to the special issue of JNSM on Cloud Computing, Networking, and
Services (CCNS).
The concept of Cloud Computing (CC) is based on utilizing distributed
(computing) resources for application and services that need massive amount of
computing assets for a specific short period of time. The cost of procuring,
deploying, and maintaining such massive amount of computing resources for a short
time duration is prohibitively high. Therefore, the concept of virtualization has been
developed over the last few years to enable sharing of computing resources from
distributed clusters of resources (the ‘‘Cloud’’) over the Internet for a fraction of the
cost. The early adopters of CC are small and medium Enterprises. Government
B. Khasnabish
ZTE USA, Inc., Morristown, NJ, USA
e-mail: vumip1@gmail.com
D. Huang
Arizona State University, Phoenix metropolitan area, AZ, USA
e-mail: Dijiang.Huang@asu.edu
X. Bai
Tsinghua University, Beijing, China
e-mail: baixy@tsinghua.edu.cn
P. Bellavista
University of Bologna, Bologna, Italy
e-mail: paolo.bellavista@unibo.it
G. Martinez (&)
University of Murcia, Murcia, Spain
e-mail: gregorio@um.es
N. Antonopoulos
University of Derby, Derby, UK
e-mail: N.Antonopoulos@derby.ac.uk

123

464

J Netw Syst Manage (2012) 20:463–467

entities and big Corporations are also increasingly adopting private and hybrid
(public plus private) Cloud paradigms in order to reduce their capital expenditure
(CapEx).
Cloud computing, networking, and their related service (CCNS) management
including grid computing (as appropriate) have recently emerged out of hypes to
viable computing/networking tools for reducing infrastructure deployment and
service management costs without sacrificing the quality of service/experience (QoS/E).
There are many definitions of CC; see for example, IETF Website, http://trac.tools.
ietf.org/area/app/trac/wiki/Clouds and NIST website, http://www.nist.gov/itl/cloud/.
The concept of CC has since been expanded to cover other types of resources as well.
These resources include storage resources (DropBox, Microsoft SkyDrive, Google
Drive, etc.), communications resources (software defined networking, Networkingas-a-Service or NaaS, etc.), and others. Consequently, the term CC is being commonly
used for applications and services that utilize distributed virtualized computing,
communications, storage, and any other resources, in general.
Although the virtualization of computing and networking resources, and their
self-organizing interconnection is at the heart of it, the methods/mechanisms/tools
that are used to expose (visualize) resources and their utilization (the application
programming interfaces of APIs) for developing anything (*) as a service (*aaS) are
still ad-hoc and/or proprietary in nature. Security, privacy, and multi-tenancy
support requirements add another dimension to the already complex set of CCNS
management problems.
The major challenges of adopting cloud computing, networking, and services
include seamless cloud service hosting, mobility and service migration, elastic
computing using mobile code, distributed CC policy management, and regulations
and export control of information.
The general and broad-scope interest raised by the above challenges and related
technologies is also demonstrated by the success of submissions to this Special
Issue, for which we received more than four dozen papers covering a wide range of
topics, including the following:
•
•
•
•
•
•
•
•
•
•

Cloud Applications and Services
API for enabling Public/Private/Hybrid Cloud-based Services
Virtualization (of any and all resources) and Hosting
Protocols and Interoperability
Cloud Service Logging and Monitoring
Soft and Hard Privacy and Security for Cloud-based Services
Risk, Resiliency, and SLA (RRS) of Services in Clouds
Cloud Service and Infrastructure Management
Reports from CCNS management Experiments and Field Deployments
Mobility Management in Cloud Computing

However, because of time and space limitations, we are able to accommodate
only a limited number of papers, selected after a rigorous review process using
relevance, timeliness, and depth of the reported research as criteria. To introduce the
interested readers to the contents of this Special Issue, a high-level summary of each
selected paper is as follows.

123

J Netw Syst Manage (2012) 20:463–467

465

The paper ‘Efficient Online Virtual Network Mapping using Resource Evaluation’ by Hao Di, Hongfang Yu, Vishal Anand, Lemin Li, Gang Sun, and Binhong
Dong presents an FVN_Sort (First Virtual Node Sorting) function-based On-line
Virtual Network Mapping (OVNM) algorithm for maximizing the number of
coexisting virtual nodes, and increasing the utilization and revenue obtained from
the substrate resources of virtual nodes. By mapping the virtual nodes and links in a
coordinated fashion, the authors demonstrate efficient resource utilization without
the need of performing excessive mapping.
In the paper, ‘Towards Runtime Reconfiguration of Application Control Policies
in the Cloud,’ Luis M. Vaquero, Daniel Morán, Fermı́n Galán, and José M. AlcarazCalero describe the use cases and implementation of an adaptive architecture for
dynamically controlling the behavior of the applications deployed over the Cloud by
using a set of high-level rules. This flexibility allows run-time re-definition of
service management policies. Ultimately, this mechanism delivers a successful
management of different cloud providers in a highly competitive fashion without
sacrificing the associated QoE.
The paper, ‘A Metric-Based Approach to Assess Risk for ‘‘On Cloud’’ Federated
Identity Management’ by Patricia Arias-Cabarcos, Florina Almenárez Mendoza,
Andrés Marı́n López, Daniel Dı́az Sánchez, and Rosa Sánchez-Guerrero discusses
how evidence-based trust management can be utilized for access control and
identity management in a dynamic federation environment. The authors also define
a set of new metrics using a hierarchical risk aggregation system in these
environments.
In the paper, ‘Secure and Fast Aggregation of Financial Data in Cloud-Based
Expense Tracking Applications,’ Juan Camilo Corena and Tomoaki Ohtsuki explain
how an architecture based on additive homomorphic cryptosystems and secret sharing
schemes can be used to store information securely while still allowing fast aggregation
queries at an outsourced untrusted cloud server. The proposal is evaluated in terms of
security, server load and complexity of user interaction, computational load at the
acquiring terminal, and computational load at the untrusted server.
The paper ‘Online Randomization Strategies to Obfuscate User Behavioral
Patterns’ by Juan E. Tapiador, Julio C. Hernandez-Castro, and Pedro Peris-Lopez
examines the vulnerability of a CC environment. The authors explore how security
and privacy leakages derived from the analysis of user activities can be used to
capture computationally the working behavioral patterns of the users. This captured
information can be used by an adversary for many subversive activities, including
(a) predict future activities, (b) detect the occurrence of events of interest, and
(c) infer the organization’s internal structure. The authors then propose and analyze
the concept of disguising user behavior through Online Action Randomization
Algorithms (OARA) to randomize user traces in an incremental way.
The final paper ‘Efficient Diagnosis Protocol to Enhance the Reliability of a
Cloud Computing Environment’ by Mao-Lun Chiang discusses the crucial
challenge of fault-tolerance in a CC environment. Noting the inefficiency with
the traditional Byzantine agreement protocol, the author proposes a FCA (Fast
Cloud Agreement) protocol to enhance CC reliability. The FCA can detect a
maximum number of faulty processors using a minimum set of messages.

123

466

J Netw Syst Manage (2012) 20:463–467

We sincerely thank the anonymous reviewers who tirelessly contributed to
maintain the highest standard of the publication by reviewing the submissions and
updated versions of the accepted articles notwithstanding their busy schedules. Our
special appreciation also goes to Deep Medhi, for his valuable suggestions during
the review process and for constant encouragement to maintain the schedule of
publication of this Special Issue. We also thank Paul Brusil for commenting on an
earlier draft of this guest editorial.
We enjoyed putting this Special Issue together in this emerging area of CCNS,
and fruitfully used this opportunity to have an overview of many emerging and
relevant research projects in the area of CCNS during the Special Issue
preparation process as well. We hope that the readers will find the selected
articles useful and notable in their cloud computing and networking research and
implementations.
Author Biographies
Bhumip Khasnabish, PhD, AMCPM is a Senior Member of IEEE and an emeritus Distinguished
Lecturer of the IEEE Communications Society (ComSoc). His current research interests and focus include
next-generation networking, platform and services that use cross-domain virtualized computing and
communication entities, and tighter cross-layer communications. Bhumip (http://tinyurl.com/bhumip)
initiated cloud and data center activities in the IETF, and co-chaired the T&I activities of ATIS IPTV
Interoperability Forum (IIF). He is currently a Senior Director in the Technology Strategy Department of
ZTE USA, Inc. Dr. Khasnabish has published (http://tinyurl.com/bhumips-pubs) numerous articles,
books, and book chapters, and has been awarded several patents (http://tinyurl.com/bhumips-patents) in
his research areas. He is an associate editor of the Journal of Network and Systems Management (JNSM),
and edited/co-edited many Special Issues of IEEE Network, IEEE Wireless Communications, IEEE
Communications Magazines, and JNSM.
Dijiang Huang received his BS degree from Beijing University of Posts & Telecommunications, China
1995. He received his MS, and PhD degrees from the University of Missouri–Kansas City, in 2001 and
2004, respectively. He joined Arizona State University (ASU) in 2005 as an assistant professor. He is
currently an Associate Professor in the School of Computing Informatics and Decision System
Engineering at ASU. His current research interests are computer networking, security, sensor network
security, and secure mobile cloud computing. He is currently an associate editor of the Journal of
Network and System Management (JNSM) and an editor of the IEEE Communications Surveys and
Tutorials. He has served as an organizer for many International conferences and workshops. Dr. Huang’s
research is supported by NSF, ONR, ARO, Intel, and HP. He is a recipient of ONR Young Investigator
Program (YIP) Award 2010 and HP Innovation Research Program (IRP) award 2011 and 2012. He is a
senior member of IEEE.
Xiaoying Bai is an Associate Professor at the Department of Computer Science and Technology of
Tsinghua University, Beijing, China. She received her PhD degree in computer science in 2001 from
Arizona State University in the USA. Her major research area is software engineering, especially modeldriven testing and test automation techniques in various software paradigms such as distributed
computing, service oriented architecture, cloud computing and embedded systems. She has published
over 90 papers in journals and conferences, and is the co-author of a Chinese book on ‘‘Service-Oriented
Software Engineering’’. She is an associate editor of the International Journal on Software Engineering
and Knowledge Engineering (IJSEKE), an editor of Service Oriented Computing and Application
(SOCA), and guest editor of several special issues of IJSEKE, SOCA, Journal of Systems and Software,
and JNSM. Her work has been supported by National Science Foundation China, National High
Technology Program 863, National Basic Research Program of China, and industry companies like IBM,
Freescale, and Fujitsu.

123

J Netw Syst Manage (2012) 20:463–467

467

Paolo Bellavista is an Associate Professor of computer engineering at the University of Bologna, where
he has received his Laurea degree and PhD. He is a senior member of the IEEE and of the ACM, and
serves on the Editorial Boards of the IEEE Communications Magazine, the IEEE Transactions on
Computers, the IEEE Transactions on Services Computing, the IEEE Transactions on Network and
Service Management, the Springer Journal of Network and Systems Management, and the Elsevier
Pervasive and Mobile Computing Journal. His research activities span from mobile computing to mobile
agent-based middleware, from pervasive wireless computing to location/context-aware services, from
vehicular/sensor wireless ad hoc networks to adaptive multimedia. He is co-editor of the ‘‘Handbook of
Mobile Middleware’’ and authored more than 140 journal/conference papers. Additional information at:
http://lia.deis.unibo.it/Staff/PaoloBellavista/.
Gregorio Martinez is an Associate Professor in the Department of Information and Communications
Engineering of the University of Murcia. His research interests include security and management of
distributed communication networks. He received the MSc and PhD degrees in Computer Science from
the University of Murcia. He has published more than a hundred journal articles and conference papers.
He has been involved as collaborator or supervisor in several open-source software projects. He is also on
the editorial or review board of more than 20 international journals. Additional information at:
http://webs.um.es/gregorio/.
Nick Antonopoulos is currently the Head of the School of Computing & Mathematics and Assistant
Dean (Research) of the Faculty of Business, Computing & Law at the University of Derby. Prior to
joining the University of Derby in 2009 he was a Senior Lecturer (US Associate Professor) and Director
of the MSc Degrees at the Department of Computing, University of Surrey, UK. He holds a BSc in
Physics (1st class) from the University of Athens in 1993, an MSc in Information Technology from Aston
University in 1994 and a PhD in Computer Science from the University of Surrey in 2000. He has over
14 years of academic experience during which he has published over 110 articles in fully refereed
journals and international conferences. He has received a number of best paper awards in conferences and
graduated 7 PhD students. He has edited two books in the field of P2P, Grids and Cloud Computing
published by IGI Global and Springer respectively. He is on the editorial board of the Springer journal of
Peer-to-Peer Networking and Applications and co-editor-in-chief of the Springer journal of Cloud
Computing. He is a Fellow of the UK Higher Education Academy and a Fellow of the British Computer
Society.

123

2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications

    
      

  

        
      
         
        
          
         
        
         
        
         
       
          
        
      

  
         
      
         
      
        
        
       
          
 
         
        
        
          
        
         
         
          
     

         
       
         
       
         
         

978-0-7695-4745-9/12 $26.00 © 2012 IEEE
DOI 10.1109/TrustCom.2012.103

       
      
        
          
         
        
       
        
        
       
       
       
        
          
         
          
         
         
         
           
        
        
       
        
       
       
          
        
       
       
   
          
       
        
       
       
         
        
        


193

    
         
          
        
        
    
       
        
       
         
          
        
    
        

       

         

         
         
        
           
         
        
  
       
      
          
         
       
         
       
       
        
        
         

        
        

       
        
 
  



 

      
         
      

 

     

        
        
        
          
           
           
     
        
         
           

         
        
        
       
     

194

        
 
        
       
   
          
      

        
     
         
    
         
       
             
         
          
           
           

          
        
          
       

 

 

          
         
         
    
        
         
         
        
        
         
          
        
         
           
        

         
    

     
     
        
         
         
        
      
       
         
          
        
    

  
    
      
     
   
      
      
       
           
         
          
          
          
         
         
      
  
          
         
       
         
      
       
         
        
       
         
       

  

         

       

        
        

          
      
        
           

195

        
         
         

          
   


   

 
 


 
 




   
  


 
   













    
        
 
   

 


          
 
            
     
            
           
          
  















         
          
     

        
         
       
       
       
        
         
      
           
  
  

 




 







               
            
            
          
         

         
              
            
            
          
          
        
         
          
           
         
            
          
              
        
      
          
 
         
 
        
       
       
         
          
          
   



  



    

         
            
             
           
         
        
         
           
        

 



 

 



          
         
         
            

196

      
     




 


     



      



     











              
         
         
       
         
 

         
 
     
    
               
             
                
   

         
      
      
        
         
          
             
        
       
       
           
     
         
        
        
        
            
          
          
           
         
         
         
            
         
          
          
  




 

 



 

      

         
        
          
        
       
         
              
         
            
         
          
            
        
           
           
         
        
          
         
         
         
        
        
         
        
       
         
    
         
         
      
        

197

     
       
      
   
           
 
         
        
         
          
           
         
      
       

          
       
        
       
         
         
       
     
        
        
        
        
        
         
      
       
         
         
        
             
          
           
         
                  
       
               
         
            
         
          
          
   

        
         
           
          
       
        
           
        
         
       
         
        
    
         
        
       
         
           
           
 
        
  
        
        
       
         
       
       
        
       
         
         
       
          
         
        
  
          
       
         
        
         
       
        
     
    
        
        

198

       
         
   






























          
         

      
           
  
         
            
          
         
       
       

          
        
         
      

 

  

        
       
        
        
        
       
         
         
   

       
        
        
      
        
         
         
       
          
       
         
      
        

        
      
        
       
       
        
         
         
       
        
          
        
        

         
       
     
        
        

        
          
       
199



       



 
          
         





       




      




          
        


















          


  


          
 

         
        
        
       
          
       
         
         
        
  



   

       
       
       

        

           
           
      
   

         

            
        


 
       
          
  
           
           
      

         
       
          
 

   
     
        
        
       
            
        
          
       
           
         
    
            
      
     
            
          
           
        
        
 
            
    
         


   

 

200

RINK-RKP: A Scheme for Key Predistribution and Shared-Key
Discovery in Sensor Networks
Manish Mehta Dijiang Huang

Lein Barn

Computer Science and Electrical Engineering
University of Missouri - Kansas City
Kansas City, hiIissouri 64110, USA.
{manish.mehta, dhuang, harnl}@umkc.edu
Abstract
Eficient schemes for key predistribution and
shared-key discovery play a vital role in security and
eficiency of pairwise key establishment an sensor
networks. In this paper, we propose a scheme f o r
key predistribution using hash-chain and subsequent
shared-key discovey. We show potential active attacks
on sensor networks due to key predistribution which
can have severer consequences as compared to attucks
described i n existing proposals. We also show that as
compared to the existing schemes, our scheme is more
resilient t o these active attacks.

1

In this paper, we introduce a scheme for RKP and
subsequent shared-key discovery. The main idea of our
scheme is to define RINK (Relationship between the
node I D aNd the Keys possessed by each sensor). We
use node i d of each sensor to determine the keys to be
preinstalled in that sensor. The RINK alleviates the
security risks due to node capture by restricting the
ability of an attacker to fabricate fake sensor nodes.
Further, unlike the existing schemes in [l]and [2], this
design obviates the need for transmission of all key
identifiers during shared-key discovery phase; and unlike the scheme proposed in [3], this design does not require computationally expensive operations for sharedkey discovery.

Introduction

2

Sensor networks are composed of a large number of
low-power sensor devices. For secure communication
among the sensors, pairwise keys are needed to be established between each pair of communicating sensors.
Recent proposals 11, 21 use Random Key Predistribution (RKP) to achieve the goal. In RKP schemes, each
sensor is preIoaded with certain number of keys. The
sensors can communicate with each other secureiy if
they share at least one key. The probability of two
sensors sharing at least one key is proportional to the
number of preinstalled keys in each sensor.
The wireless nature of communication among sensors makes sensor networks vulnerable to passive and
active attacks. Also, for many applications, the lowcost sensors are deployed in unattended environments
which make them physically insecure. Due to the
low-cost design, the sensors are not considered to be
tamper-proof devices. Physical capture of sensors may
lead to severe security problems. One of the goals of
a secure scheme for pairwise key establishment is to
minimize the effect of physical node capture in sensor
networks.

2.1

Phases in RKP Schemes

Key predistribution phase: A centralized key
server first generates a large key pool offline. Keys
from this key pool are distributed as follows: 1. Assign a unique node identifier or key ring identifer t o
each sensor 2. Select m different keys for each sensor
from the key pool to form a key ring 3. Load the node
identifier and the key ring into memory of the sensor.
Sensor deployment phase: The sensors are randomly picked and uniformly distributed in a large area.
Typically, the number of sensors in communication
range (neighbors) of a sensor (n')is much smaller than
the total number of deployed sensors ( N ) .
Shared-key discovery phase: During the sharedkey discovery (SKD) phase, each sensor attempts to
find other sensors in its communication range. A set
of neighbors ( W )is maintained by each sensor. It then
attempts to discover shared key(s) with them. Each
sensor builds a key gmph (see Definition 1) according
to its view of the network. Next, each sensor shares
its key graph with other sensors and updates its key

,

0-7803-8991-3/O5/$20.00 Q 2005 IEEE

Background of RKP Schemes

193

not define any relationship between the node i d and
the keys possessed by each sensor.
The main idea behind our approach is to define a
relationship between the node id and the keys possessed by each sensor while maintaining the required
randomness in choice of keys. Our scheme requires
the key predistribution phase to first choose a unique
identifier for e x h sensor node. To determine the keys
t o be installed in the sensor, we use a secure one-way
hash function as defined in 181. It may be noted that
a.ny pseudo-random function which can produce output uniformly distributed in a given range for given
input set can be used.
Before describing the use of one-way hash functions
for RINK-RKP, we summarize the notations used in
the rest part of the paper as follows: N is the total
number of sensors to be preloaded, n is the total number of sensors to be deployed for a sensor network and
R 5 N , n’ is the number of sensors in the communication range of a sensor (i.e. neighbors), id is a unique
sensor ideptifier, where zd = 1, 2, , ,,, N , Sid is the sensor with unique identifier d u e id, P is size of the key
pool, m is the number of keys loaded in each sensor, q is
the required number of common keys between sensors
in P-RKP, 11 is concatenation operator, { x } j means TC
concatenated with itself j times, A(M)is a secure oneway hash function on M producing z-bit output, kjd
is the identifier of Z t h key for S i d , i=l, 2, . . . , m,
is
the actual key value for key identifier ktd (e.g. 128-bit,
256-bit key etc.), KCid is the set of all key identifiers
. @ a j ~ Il ai f A,
( k i d ) for id, @ ( A } = (ai a2 e..
for i = 1, 2, . . . , IAI}, @ is bitwise XOR, K , is the
discovered key between si and s j .
For key predistribution in RINK-RKP, we require
key server to first generate keys ( Y ’ s )and their identifiers ( k ’ s ) in a key pool of size P. The pseudo code
in Procedure 1 shows our key predistribution method.
This scheme generates a chain of practically random
numbers by taking the unique node id as the seed. In
turn, it binds the node i d with the set of keys the node
possesses. This procedure is followed for each of the
N sensors to be preloaded. By including the PrevKey
and node id along with the SHA-1 [9] output as input
to the next hash operation, we make the probability of
merging of chains of two different sensors negligible.

graph according to the key graphs from other sensors.
Pairwise key establishment phase: If a sensor discovers shared key(s) with a given neighbor, the shared
key(s) can be used as their pairwise key(s). If a sensor
does not share required key(s) with a given neighbor,
the sensor uses the key graph built during SKD phase
to find a key path (see Definition 2) to set up the pairwise key for future communication.
Definition 1 (Key graph) A key graph maintained
by node i is defined as Gi = (V, , Ei) where, V, = { j Ij E
Wi V j = i), Ei = ( e , k l j , k E Wi A (j S k)), and S is
a relation defined between two nodes if they discover
shared key(s) during the SKD phase.
Definition 2 (Key path) A key path between node
A and B is defined as a sequence of nodes A,
N I , !V2,. , ,, N,, B. such that, each pair of nodes
( A N , ) , ( N l , N 2 ) ,. . ., (NZ-1,Nt),
(N,,B) has discovered shared key(s) during the key discovery phase. The
length of the key path i s the number of pairs of consecutive nodes in the sequence.

2.2

R e l a t e d Work

The first P-RKP scheme was proposed by Eschenauer and Gligor [I],and we refer to it as the basic
scheme. The proposals that followed the basic scheme
suggested improvements in terms of security. Chan et
al. proposed the q-composite scheme in [2]. In this
scheme, the shared-key threshold is set to a variable q.
To form a secure link between two sensors, the scheme
requires them to share at least q keys. The scheme
proposed by Du et al. [3] and Grid-based scheme proposed by Liu and Ning [4]change the unstructured
key pool in earlier schemes to a structured key pool by
dividing the unstructured key pool into multiple key
spaces. IVe refer to these schemes as Structured-Keypool RKP (SK-RKP) schemes. Within each key space,
the key structure uses the group key scheme proposed
by Blom [5] and further developed by Blundo et al. [6].
The Grid-based scheme is equivalent to the scheme
proposed in [3] in that it uses polynomials instead of
key spaces. Recently, Peitro et al. presented a pseudorandom key predistribution in [TI. This scheme uses a
pseudwandom function for predistribution of keys.

3

cd

RINK-RKP

3.2

In this section, we introduce RINK-RKP, a new

Shared-Key Discovery Scheme

The shared-key discovery (SKD) phase is the next
phase after deployment of the sensors. In this phase,
each sensor attempts to find other sensors in its range
and discovers possible shared-keys with them.
As shown in Procedure 2, in RINK-RKP, a sensor,
say s i , initiates this phase by broadcasting its identi-

scheme for random key predistribution and subsequent
shared-key discovery in sensor networks.
3.1 K e y P r e d i s t r i b u t i o n
The key predistribution phase for RKP scheme introduced in [l] and adopted by Chan et al. [2] does

I94

Procedure 1 (Key Predistribution)
1.

2.
2.1.
2.1.1.
2.1.2.
2.2.

2.3.
2.4.
2.4.1.
2.5.
2.6.

2.6.1.
2.7.
2.8
3.

Pick a unique identifier id for a sensor.
Initialize Output = {I)*
for i = 1 to m
if (i 5 2)
then PrevKey = 0
else PrevKey = k i t 2
Af:d = Output 11 PrevKey 11 i d
output = H ( M ; ~ )
if( Output 2 2" - 1 - (2" mod P))
then i = i - 1, goto step 2
Key = Output mod P
if (Key has already been generated
for this sensor)
then i = i - 1, goto step 2
kid = Key
add kid to KCid
Store i d , Kcid, and corresponding keys
'(Y's)in the Sensor.

fier, i. Similarly, it receives the ids from its neighbors.
At this point, the sensor builds a key gmph with ids of
all the neighbors as vertices. For each of the neighbors,
say s j , the sensor generates the key chain KCj using
the neighbor's identifier j as shown in Procedure 1. It
now finds the key identifiers shared between KCi and
K C j . If there exists at least q shared key identifiers, a
key is said to be discovered between si and s j . From
the shared key identifiers, s, builds a set, Q, of the
corresponding key values (Ys).
Now, the value of the
discovered key Ki, is computed as @IQ}. After this,
si adds an edge between si and s j in its key gmph.

4

Security Analysis

RINK-RKP is closest to the schemes proposed
in [l,2, 31. In their works, they analyze the security of
sensor networks on the basis of fraction of the communication links compromised due to captured sensors.
In existing schemes, the security analysis is done on
the basis of random capture of sensors. However, in
practice, an attacker can selectively capture sensors to
learn the keys in a quicker fashion. We analyze the
existing schemes under selective node capture. In the
following, we introduce active attacks on sensor networks due to node capture and analyze the security
of the schemes under active attacks. Specifically, we
introduce and analyze node replication and node fabrication attacks.
4.1 Selective node capture attack
In all current RKP proposals, the sensors are assumed to be captured randomly. But in practice, the

Procedure 2 (Shared-Key Discovery)
1.

2.

3.

3.1.

3.2.

Broadcast node identifier,.i
Receive node ids transmitted by neighbors
and generate set of ne'ighbors, W . Generate
key graph with elements of W as vertices.
for (V j E W ) do
Generate KCj using the node identifier,
j, as the input to Procedure 1
Generate &, a set of key values (Ys)
corresponding to common key identifiers
in KC, and K C j .

3.3.
3.3.1.
3.3.2.
4.

if(lQ1 2 q ) ahen

e{&)

Compute the shared-key Kij as
Add a link between node i and node j
in the key graph
stop.

random capture assumption is too weak. The attacker
can purposely attack certain area or a group of sensors.
Thus, an attacker can purposely locate and capture
the sensors which can give more information about the
sensor network. For example, in P-RKP scheme, each
sensor broadcasts its list of keys. An attacker can selectively attack a sensor that possesses the most number
of keys that are not already compromised. In the best
case for the attacker, for a key pool of size P and the
m keys in each sensor, the attack can compromise all
communication links by capturing [P/ml sensors. In
practice, an attacker can inspect all keys possessed by
sensors and find the minimal cover set which contains
the minimal number of sensors that can cover the maximum number of keys in the key pool. Alternatively,
a less powerful attacker can use heuristic technique to
choose the next node to capture. However, due to the
purely random selection of keys in P-RKP schemes, the
attacker does not gain significantly more information
using selective capture attack as compared to random
capture. Similarly, for RINK-RKP, the gain due to
selective capture attack over random capture attack
is not significant as the keys are practically randomiy
selected for each node.
As compared to the P-RKP schemes, the selective
attack on SK-RKP scheme can cause severer problems.
This is due the fact that in SK-RKP scheme, the nodes
derive a shared key if they share a key space. As the
number of key spaces is generally much smaller than
number of individual keys used in P-RKP to derive a
shared key, the attacker has better selection criterion.
I n SK-RKP scheme, each sensor broadcasts its node id
and the key-space ids in order to discover shared-key
with its neighbors. At the same time, the node id and

195

cannot be considered tamper-resistant. Under some
practical assumptions about capabilities of the attacker, we now describe two related active attacks on
sensor networks due to captured nodes.

Node replication attack: In this attack, the attacker captures a sensor and clones it as per require-

Number of compromised n&s

Figure 1: Selective node capture attack on SK-RKP
scheme [3] with m = 100, pconnect = 0.432

key-space ids can be extremely helpful to the attacker
to launch selective attack. The attacker can selectively
capture the sensors that possess keys within the same
key space. Once X 1 sensors in a key space are compromised, all the keys in that key space are compromised. In this fashion, an attacker can incrementally
capture the sensors that use same key space. Since
sensors possess keys from more than one key space,
the number of sensors required to be captured to compromise subsequent key spaces is less. We use c ( i ) to
represent the average number of additional sensors to
be captured in order to compromise a key space when
i - 1 key spaces an! already compromised. In order
to compromise the first key space, the attacker needs
to capture at least A 1 nodes (i.e. c(1) = X 1).
Since each sensor is allocated T key spaces (7 2 Z ) , a
captured node also uses an uncompromised key space
with probability p' =
Thus, to compromise ith
key space, we have

+

+

+

5.

i-1

c(i)= x + 1 - C c ( k ) . p ' ,

2575w

(1)

k=l

Security analysis for SK-RKP scheme proposed by
Du et al. in [3] assumes random node capture in sensor networks. In Fig. 1, we use (1) to show SK-FtKP
scheme [3] under selective node capture attack (SA)
and compare it with that under random node capture
attack (RA). As shown in the figure, the robustness
(threshold) of SK-RKP scheme decreases dramatically
under selective node capture attack,

4.2

Active attacks using captured nodes

Since sensors are low-cost devices and operate in
unattended environment for many applications, they

ment. Since the attacker is assumed to have the ability
to listen to the traffic in the network, the attacker can
deploy the clones in the other parts of the network.
Due to lack of a-priori knowledge of post-deployment
configuration, the uncompromised sensors in the other
parts of the network cannot detect the cloned sensor
as an anomalous sensor. This attack can have severer
consequences a5 compared to the passive listening attacks on links between uncompromised nodes.

Node fabrication attack: In this attack, the attacker captures sensors and fabricates fake sensors using the information gathered from captured nodes.
Similar to the node replication attack, the attacker can
deploy the fabricated nodes in the parts of the network
where the original sensor i s not present. The uncompromised sensors in the network cannot detect the fabricated nodes as anomalous nodes as long as they can
have expected communication with them. This attack
is severer as compared to node replication attack as
the attacker may have enough information to fabricate
multiple sensors in order to inject, sink, modify, and
reroute the sensed data.
Since node replication is a special case of node fabrication, we analyze the schemes for node fabrication
attack in general. The basic aim of the attacker launching this attack is to fabricate fake nodes and deploy
them in the existing system. The more the number
of uncompromised nodes that can be used by the fake
nodes to get connected to the network, the faster the
attacker can take control over the network.
Fig. 2 shows the node fabrication attack on different schemes. In the P-RKP schemes, by capturing less
than 10 nodes the attacker can gather enough information to fabricate fake nodes that can establish connection with most of the uncompromised nodes. This
is possible in P-RKP because there is no defined relationship between the node id and the keys possessed
by each sensor. By capturing only a few nodes, the
attacker can fabricate fake nodes with identity of his
choice with the same set of keys. For example, by c a p
turing two nodes, the attacker can fabricate and deploy
approximately (2,") fake nodes. These nodes possess
valid keys and hence cannot be detected. Unlike PRKP schemes, the SK-FXP scheme and our scheme
bind the possessed keys with the node i d ofsensors. As
a result, the attacker has to capture significantly more

196

'

binding between the node id and the possessed keys
in SK-RKP scheme and our scheme largely restricts
the ability of the attacker to fabricate fake nodes with
identities of his choice.

5

Conclusion

In this paper, we identify a limitation in one of the
existing schemes and propose a new scheme for RKP
in sensor networks. In all existing proposals, the s e
curity analysis is based on random capture of sensors.

4 sKR(pdt-2

Number of cwnoromised nodes

Figure 2: Active attacks : Node fabrication attack
(m= 200)

By analyzing the robustness of SK-RKP scheme under
selective node capture attack, we show that the assumption of random node capture is weak in practice.
Also, we analyze active attacks OR sensor networks due
to node capture and compare our scheme with the existing schemes under these attacks.

References
[l] L. Eschenauer and V. D. Gligor, “A key-management
scheme for distributed senwr networks,” in Proc. of
ACM CCS, 2002, pp. 41-47.

number of sensors t o achieve the same goal in SK-RKP
and our scheme. In SK-RKP scheme, the attacker
can incrementally compromise key spaces and fabricate fake sensors using the compromised key space.
Equation (1)can be used to determine the number of
additional sensors required to be captured in order to
compromise each additional key space. In our scheme,
in order for a fabricated node t o get connect to the
network via an uncompromised node, the node needs
to satisfy the following conditions: 1. It should share
required number of keys (q) with the uncompromised
node. 2. Given that the first condition is satisfied,
all the shared-keys must be already known t o the attacker. The probability that a fabricated node will
satisfy these conditions with x nodes already captured
can be computed as:

Where,

c, = [l - (1 -

3 1

[Z] H. Chan,A . Perrig, and D. Song, “Random key predistribution schemes for sensor networks,” in Proc. of
the IEEE Symposium on Security and Privacy, 2003,
pp. 197-215.
[3] W. Du, J. Deng, Y . S . Han, and P. K. Varshney, “A
pairwise key pre-distribution scheme for wireless sensor networks,” in Proc. of ACM CCS, 2003,pp. 42-51.

[4]D. Liu and P. Ning, “Establishing pairwise keys in
distributed Sensor networks,” in Proc. of ACM CCS,
2003, pp. 52-61.
[5] R. Blom, “An optimal class of symmetric key generation systems,” in Pmc. of the EUROCRYPT 84,1985,
pp. 335-338.

[6] C. Blundo, A. D. Santis, A. Herzberg, S. Kutten,
U. Vaccaro, and M. Yung, “Perfectly-secure key distribution for dynamic conferences,’, in Pmc. of the
12th Annual International Cryptology Conference on
Advances in Crgptology, 1993, pp. 471-486.
’

[7] R. D. Pietro, L. V. Mancini, and A. Mei, “Efficient
and resilient key discovery based on pseudo-random
key pre-deployment,” in Proc. of IPDPS’04, 2004.

P

Where a: is the number of captured nodes, [l ?)”I is the fraction of keys that are compromised due to capture of x nodes, and C, is the number of keys compromised due to capture of x nodes.
As shown in Fig. 2, our scheme performs significantly
better than P-RKP schemes. As compared to SK-RKP
scheme, our scheme provides more robust security after a smal1 threshold. As compared to the existing
P-RKP schemes t h a t use unstructured key pool, the
ability of our scheme to resist node fabrication attack
is significantly more. Unlike in P-RKP schemes, the
(1 -

[S] B. Schneier, Applied cryptography: protocols, algorithms, and source code in G, 2nd ed. John Wiley

and Sons, Inc., 1995.

FIPS PUB 180-1, National
Institute of Standards and Technology, US. Department Of Commerce, April 1995.

[9] “Secure hash standard,”

197

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2009 proceedings

SEAS: A Secure and Efficient Anonymity Scheme
for Low-Cost RFID tags
Satyajayant Misra, Mayank Verma, Dijiang Huang, Guoliang Xue
Abstract— In this paper, we propose SEAS, a novel privacy
preserving, anonymous authentication scheme for RFID tags,
which allows the tags to use pseudonyms instead of their true
identity for authentication. Using SEAS, a tag generates random
numbers and uses them to create a pseudonym as its identity for
authentication. The pseudonym does not reveal the identity of
the tag and the pseudonyms of multiple authentications appear
random and uncorrelated to the adversary. A pseudonym can
only be deciphered by the back-end authentication authority to
identify the tag. No other entity in the network can link the
pseudonym to the identity of the tag. Our scheme is efficient,
with a tag needing to perform only simple operations such as
XOR, bits shifting, bits concatenation, and random number
generation. We perform security analysis of our scheme to
show its effectiveness against different forms of attacks. We
also perform comparison of our scheme with existing schemes
in terms of efficiency in the use of resources. Our scheme
performs effectively, while at the same time being better than
the other popular schemes in the literature in terms of cost and
computation efficiency.
Keywords: RFID, anonymity, authentication, logical operations,
rotation operations.

1. I NTRODUCTION
Radio Frequency Identification (RFID) tags have existed
for more than six decades [14]. RFID technology has been
identified to provide support for a wide variety of applications including consumer products, microchip fabrication,
and automobile industry. The low cost of RFID tags [17]
makes them a suitable candidate for the replacement of the
barcode technology in the near future. Due to its capability
to support numerous ubiquitous services while being cost
effective, RFID technology has received significant attention
from both industry and academic researchers. However, till
date, large scale deployment of RFID tags is limited because
of many privacy and security issues.
RFID tags are used to automatically identify the objects
to which they are attached. An RFID tag does not require
physical contact for identification as it can be read from a
distance using the strength of the electromagnetic field of
the interrogating reader. This makes RFID tags vulnerable to
information leak. Any reader, genuine or malicious, can read a
tag’s information if the tag is close enough to the reader. This
problem can be resolved by introducing a mechanism where
the tag authenticates the reader. If the reader is genuine, the
tag provides the information, otherwise it ignores the reader’s
request. However, such mechanism cannot be deployed in
the low cost tags, which are envisioned to form the bulk
All the authors are with the Department of Computer Science and Engineering at Arizona State University, Tempe, AZ 85287. Email: {mayank.verma,
satyajayant, dijiang, xue}@asu.edu. This research was supported in part
by NSF grants CNS-0721803 and CCF-0830739. The information reported
here does not reflect the position or the policy of the federal government.

of the tags used in the future, due to their low energy and
computational capability. The low cost tags are also known
as passive tags and may cost as low as 5¢ each [17]. These
passive tags contain only a few thousand gates (maximum
4000), have no power of their own, and derive their power
from the signal of the interrogating reader [11]. Hence, these
tags cannot perform complex cryptographic operations such as
public key cryptography to preserve their privacy.
There exist research in the literature that focus on solving
the problem of anonymous authentication using hash functions [2], [13], [22], [23] or cryptographic operations [3],
[4], [5], [6]. Although these solutions successfully address
the issues of secure and anonymous authentication, they are
expensive to implement on passive tags. As identified by
Feldhofer and Rechberger in [7], to perform hashing itself
using MD4, SHA-1, or SHA-256 the number of gates required
by the tag ranges from 7350 to 10868. Whereas, the implementation of symmetric key encryption schemes such as AES
itself, requires 3, 400 gates. Thus, in order to implement the
existing protocols the passive tags need to be upgraded by
the addition of more gates, which will result in an increase
in their cost. There exist other solutions in the literature that
do not use hash functions nor cryptographic operations [10],
[11], [15], [20], [21]. These solutions are based on logical
operations or bit shifting/rotation operations. Most of these
solutions are extension of the HB scheme proposed by Hopper
and Blum [9]. However, these schemes require many rounds of
communication or complicated hardware implementation thus
sacrificing operational speed and scalability. From the above
discussion, the need for a light weight cost effective solution
that provides anonymous authentication to the RFID tags is
evident. The solution must achieve tags privacy preservation,
authentication with the authenticating authority, and untraceability over multiple authentications.
In this paper, we present SEAS, a scheme that satisfies
the above discussed requirements. SEAS provides anonymous
authentication to the tags by equipping them to generate
unlinkable pseudonyms. The messages sent by the tag do not
give out the identity of the tag to any entity other than the
authenticating authority. At the same time, our solution is efficient, having lower computation and complexity requirement
from the tag in comparison to the other popular schemes in the
literature. We note that despite the low cost of its operations,
SEAS still achieves a very high level of security.
The rest of this paper is organized as follows. In Section 2,
we present the related work. In Section 3, we present the
system and threat model for our scheme. In Section 4, we
present our scheme SEAS and perform its security analysis.
In Section 5, we present a comparative performance evaluation
of our scheme. In Section 6, we conclude our paper along with

978-1-4244-3435-0/09/$25.00 ©2009 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2009 proceedings

the directions for future work.
2. R ELATED W ORK
Extensive research has been done to solve the issues with
secure authentication and privacy in RFID tags. The solutions
proposed can be broadly classified under three categories
namely, hash-based, encryption based, and logical and bit
operations based solutions. The hash-based solutions proposed
in [2], [13], [22], [23] require a tag to perform hashing using
schemes such as MD5, SHA-1, and SHA-256. In [2], Dimitriou proposed a lightweight scheme to prevent traceability.
To maintain unlinkability, a shared secret between the tag and
the server was refreshed after every transaction. However, the
scheme required the tag to perform two hashing operations,
which is expensive for passive tags. Lee et al. [13] proposed a
hash-based scheme to achieve mutual authentication between
the tag and the reader. Weis et al. in [22], introduced a hashlock based scheme, where each tag was locked and could only
be identified using its meta-ID. Although the scheme achieved
tag authentication, to avoid traceability, it required the tag
to perform hash operations. In [23], Yang et al. proposed
a mutual authentication scheme that achieved pre-defined
security and privacy properties, using expensive keyed-hash
operations. It has been noted in the literature that hash based
solutions cannot be used by passive tags. As identified by
Feldhofer and Rechberger [7], most hashing operations require
gates ranging from 7, 350 to 10, 868. However, the maximum
number of permissible gates for passive tags is generally upper
bounded by 4000. The proposed hash based solutions may be
more applicable for expensive tags with more gates.
The solutions proposed in [3], [4], [5], [6] adopted a
different approach, that is, using symmetric key encryption
to achieve security and privacy of RFID tags. The scheme
proposed in [3] performed symmetric key encryption, which
required a Pseudo Random Number Generator (PRNG) and
a Pseudo Random Function (PRF). Dominikus et al. [4]
proposed a scheme that performed AES encryption and decryption on the tag. Although the scheme guaranteed strong
authentication, it could not be realized for passive 5¢ tags.
Another scheme based on AES was proposed by Feldhofer
in [5]. The scheme presented an implementation of standard
symmetric two-way challenge-response protocol. The hardware implementation of the protocol was presented in [6]. The
same authors showed in [7] that a standard passive tag needs
3, 400 gates to perform AES encryption and decryption. Even
though the number of gates was less with the AES scheme, it
was still high for the passive tags.
The next category of solutions [10], [11], [15], [20], [21]
utilized logical bitwise operation and have proved to be the
most efficient. Juels [10] presented a minimalist cryptography
based mutual authentication scheme. The protocol was based
on storing a list of pseudonyms and keys on the tag and
the back-end server. The pseudonym list on the tag was
updated by using a one-time pad, which resisted cloning and
eavesdropping from a malicious reader. Although the scheme
did not require any hashing or symmetric key operations, the
communication cost for updating the pseudonym list was high.

Also it assumed a secure channel between the tag and the
server, which is generally not possible. In another scheme,
Juels and Weis [11] introduced a low-cost authentication
scheme based on the work of Hopper and Blum (HB) [9].
In addition, to the scheme proposed in [11], authors in [8],
[12], [16] have also based their construction on the original
HB scheme [9] to resolve various attacks and enhance system
security. It should be noted that all such schemes only require
bitwise AND and XOR operations and one random “noise bit”.
As bitwise operations are inexpensive compared to hashing
and encryption, all schemes based on HB can be easily
implemented in current passive RFID tags. However, all HB
based schemes suffer from two common drawbacks. First,
the tag and the reader share k-bit random secret(s). If even
one tag is compromised, then all tags with common secret
are also compromised. Second, the authentication procedure
in HB based schemes require significant number of rounds
for effective security. This makes all HB based solutions
limited in terms of scalability and speed of authentication.
The scheme proposed by Molnar et al. in [15] suffered from
the drawbacks of using a shared secret between the tag and the
reader. It also required the use of a pseudo-random function.
In [20], Tsudikin proposed an authentication protocol called
YA-TRAP. YA-TRAP provided tracking-resistance by using a
monotonically increasing timestamps and PRNG from the tag.
The scheme was vulnerable to Denial of Service (DoS) attack
through timestamp desynchronization. Chatmon et al. [1]
extended YA-TRAP scheme to provide authentication for the
tag and resolved some vulnerabilities of the original scheme
at the cost of an increase in the load at the server.
Our scheme falls into the third category of solutions. We
propose a novel solution that uses only XOR and bits shifting
operations to provide an efficient anonymous authentication
scheme for passive RFID tags.
3. S YSTEM AND T HREAT M ODEL
Before stating the system model, we underline the assumptions on which our anonymity scheme is based. We assume
that an RFID tag has a few thousand gates and can perform
logical operations such as XOR, comparison, and bitwise
rotations. The tags cannot perform expensive operations such
as hashing and encryption. The tags can generate pseudorandom numbers and have memory to store the information
necessary for the execution of our protocol. The tag is passive
and obtains the energy to perform its operations from the
reader. The tag reader uses a MAC protocol that allows it
to distinguish the response of the tags in its neighborhood.
A. System Model
The system consists of three components namely, the backend server S, the tag reader(s), and the tag(s). Each reader
Ri and the server S are connected using the wired network
and can communicate with each other at all times. The
communication channel between Ri and S is secure and nontamperable. A tag Tj can communicate with any reader in its
vicinity by wireless signals. The tags and the readers share
secrets with S, which are stored in them before deployment.

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2009 proceedings

The server S has separate databases where it stores the
secrets shared with the readers and the tags. The tags are
resource constrained and operate only using the energy that
is provided to them by the reader(s). A reader Ri polls the
cards in its vicinity with an authentication message which
the cards use and authenticate themselves. The content of the
authentication message is random each time and is used to
help S authenticate Ri and also acts as a challenge for the
tags. The response to the challenge allows the server S to
verify the authenticity of the responding tag.

TABLE I
N OTATIONS U SED

Notation
Ri :
Xj :
Sj :
⊕:
,:
N:
x ∈R N :

Description
Reader Ri ’s identity
Tag Tj ’s identity
Secret shared between Tj and S
XOR operation
Concatenation operator
Set of non-negative integers
x is chosen randomly from N

B. Threat Model
In our setup, we assume that the back-end server S cannot
be tampered by an external adversary. A card reader Ri and
an RFID tag Tj can be tampered and the adversary can obtain
their stored secrets. Given this attack model, the aim of an
adversary, which is not part of the system, is to gain access to
the system as a legitimate member. To this end, the attacks of
the adversary on the RFID tags may range from impersonating
one or more tags to capturing and cloning the tags. Here
we detail the threat model and the scenarios for attack on
a tag. a) The adversary can capture the messages resulting
from the communication between a tag and the reader and
perform traffic analysis to track the tag. b) The adversary
can replay the information that it has captured from a tag
to the same reader or another reader to authenticate itself as
a valid tag in the system. c) The adversary can also perform
a desynchronization attack [2]. This type of attack is possible
if the server S and the tag Tj require to be synchronized
on some common variables for authentication. Each time
that the authentication is performed, S and Tj update the
synchronization variable(s). The adversary can masquerade as
Tj and perform multiple authentication attempts with S. This
will result in multiple updates of the shared synchronization
variables at S. However, the synchronization variables are
never updated in Tj . Hence when Tj tries to authenticate
itself to S using a card reader Ri it will not be able to do
so because the shared variables are no longer synchronized.
This is called the desynchronization attack. d) Another potent
attack is the man-in-the-middle attack, where the adversary
places itself between the reader and the tag. The adversary
forwards the authentication message from Ri to the tag Tj
and then receives the response from Tj and transmits it back
to Ri to authenticate itself as Tj . e) The adversary can also
capture and clone the tag thus obtaining the shared secrets of
the system.
In the case of the reader, f) we assume that the adversary
can compromise the reader itself. Hence the adversary can
obtain the compromised reader’s secrets. g) In addition, the
adversary can use fake readers and try to authenticate the tags
in an attempt to obtain their identities. In the next section, we
propose our scheme and also show how our scheme handles
the possible threats outlined above.
4. C RYPTOGRAPHICALLY S ECURE A NONYMITY S CHEME
In this section, we present our anonymity scheme. Table I
presents the notations used in our scheme. Before deployment,

the tag Tj ’s identity Xj and its secret Sj are stored in it.
Each reader Ri stores its identity Ri . The server S stores
the identity of each reader Ri , the secrets of the tag Tj , Xj
and Sj in separate databases. Fig. 1 illustrates our complete
anonymity protocol. The server is denoted as S, the reader
as Ri , and the tag as Tj . Reader Ri initiates the anonymous
authentication protocol. It generates a random number r and
uses it to calculate the variable R1 , obtained by XOR-ing its
identity with r. It then transmits R1 to the tag Tj .
The tag Tj then generates two random numbers R2 and
R3 and uses them to generate R4 , which results from R2
being left shifted depending on the number of ones in the
bits representation of R3 . This shifting is denoted as R2 <<
R3 . We note that the nature of the shift does not affect the
security of the scheme. Thus without loss of generality, we
assume that the shift is a cyclic left rotation. The rotation
operation preserves the randomness of the resulting number
R4 for an adversary as both R2 and R3 are secrets for it.
Tag Tj then calculates the variables C, D, and E and creates
the message M , which it transmits back to the reader Ri for
its authentication, as shown in Lines 4 through 8 in Fig. 1.
Reader Ri appends Ri and the random number r to M to
create the message M  , which it transmits to S. When the
server S receives M  it authenticates the reader Ri using its
ID Ri by checking if Ri exists in its database for the readers.
This search can be performed in O(1) using a hash table. This
ensures that the reader communicating with S is authentic.
Then S computes R1 using the Ri and r obtained from M  .
As shown in the figure, the server S searches for a secret
S  , in its database for the tags, such that using S  it can find
Xj , the correct ID of the tag Tj . This step has a running
time of O(N ), where N is the number of tags in the system.
This is because S has to use each secret S  in its database
and perform the procedure illustrated in Steps 12 through 15
to obtain X and check if it matches X  stored with S  . If
there is a match it implies that X is actually Xj and this
identifies and authenticates the RFID tag. The server sends
the authentication status of the tag Tj to the reader Ri . If the
status in Mauth is a success, then Ri provides access to Tj ,
as it is authenticated. Otherwise Tj is not provided access.
When the tag Tj is being authenticated, it is possible that the
choice of S  , where S  = Sj , could lead to the generation
of an X = Xj , such that X = Xk , for some other valid tag
Tk . However, the probability of this happening is negligible
as proved in Theorem 4.1.

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2009 proceedings

Tj

Ri

S

1. Generates r ∈R N .
2. Computes R1 = r ⊕ Ri .



M
10. Checks if Ri exists.
11. Computes R1 = r ⊕ Ri .
Searches for S  in the database of
tags such that:
12. R2 = D ⊕ S  ,
13. R3 = E ⊕ S  ,
14. R4 = R2 << R3 and
15. X  = C ⊕ R1 ⊕ R4 , where
X  is a valid ID in the database.
16. Transmits Mauth .
Mauth contains if X  is valid or not.
Fig. 1.



-


M
9. Creates M =< M, Ri , r > .


R1
3. Generates R2 , R3 ∈R N .
Computes:
4.
5.
6.
7.
8.

R4 = R2 << R3 ,
C = Xj ⊕ R1 ⊕ R4 ,
D = R2 ⊕ Sj ,
E = R3 ⊕ Sj .
Creates M =< C, D, E > .

- 18. Provides access based on Mauth .

Illustration of SEAS, involving the server S, a reader Ri , and a tag Tj .

Theorem 4.1: Given that the numbers used in our scheme
are n-bit numbers and that the number of tags in the system
is given by N , the probability that the ID generated by the
search procedure at the server S during the authentication of
2
Tj identifies another tag is (N − 1)/2n .
For lack of space, we do not prove the theorem.
We note that the O(N ) time complexity for the search operation at S scales slowly with N . However, this is unavoidable
if the operation at the tags need to be kept at a minimum. We
also note that our scheme requires the storage of only six nbit numbers at the RFID tag, which is very minimal memory
requirement. In the next subsection, we perform the security
analysis of our protocol.
A. Security Analysis
In this subsection, we analyze the security of our scheme
with reference to the threat model that we presented in Section
3-A. As we have stated in the threat model, the aim of an
adversary is to masquerade as a legitimate member of the
system. Here we shall show how our scheme handles the threat
scenarios. Note that the connection between the server and a
card reader is secure as it is in the wired network domain
and so cannot be traffic analyzed. Hence the adversary can
only capture and analyze the messages exchanged between the
reader(s) and the tags. Our scheme ensures that if the adversary
captures the messages exchanged between the tag and the
reader it still cannot successfully perform traffic analysis using
those messages.
To show this, we use the reader Ri for illustration. Each
time Ri sends a message to the tag, it uses a random number r,
to create R1 , as shown in Line 1 of the protocol. An adversary
does not know r and Ri , hence it cannot distinguish R1 from
another random number. In reply, the tag sends the message M
that is composed of the concatenation of the components C,

D, and E. As stated before, an adversary cannot differentiate
R4 from another random number as it does not know R2 and
R3 . The adversary has no access to Xj , as it is a secret, nor
does it know R1 . In addition, R4 which is generated by the
tag appears random to the adversary. Hence the adversary
cannot perform any analysis of C. Since R2 and R3 are
random numbers generated by Tj and Sj is a secret, hence
the adversary cannot obtain any identity information from D
and E as well.
Even if the adversary captures a significant number of
messages obtained during multiple authentications of Tj it
still cannot identify Tj . In fact, the extra messages with the
adversary do not improve its traffic analysis abilities. This is
because all the messages are equally random for the adversary.
In this scenario, the best that an adversary can do is to
guess R2 and R3 so that it can identify Sj from D and E.
However, the probability of the adversary guessing both R2
and R3 correctly is negligible. For instance, if we use 32-bit
numbers then the probability that the adversary can guess both
R1 and R2 correctly would be given by 1/232 × 1/232 , which
is as low as 5 × 10−20 . Hence an adversary that has no access
to the system can obtain no information about the identity
of a tag by analyzing the message exchanges between a tag
and one or more card readers. This proves that our scheme is
successful in preventing traffic analysis by an adversary.
Another possible attack that can be mounted by the adversary is the replay of the message sent by the tag Tj to
the reader at a later time. We show here how this attack is
prevented by our scheme. Let the tag Tj authenticate itself
to reader Ri at some time t0 . At a later time, say tδ , the
adversary tries to authenticate itself, masquerading as Tj . Then
the reader Ri will send it another random number R1δ , which
is different from R1 that it sent to the tag Tj at the time of
its authentication. The adversary will replay the message M
that it had captured at the time of the authentication of Tj . Let

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2009 proceedings

5. P ERFORMANCE E VALUATION
In this section, we perform the evaluation of our scheme
in comparison to the other schemes in the literature. The
performance parameters we use are, the number of gates
used to implement a scheme and the number of clock cycles
required to perform the necessary operations. The number
of gates required gives an idea of the amount of current
needed to power the circuit of the RFID to perform the
necessary operations. With an increase in the number of gates
the current needed to power the circuit also increases. The
number of clock cycles helps calculate the time duration for
which the tag needs to be in the proximity of the reader
during authentication. These two parameters are important in
deciding the effectiveness of a scheme. In our analysis, we
use the values obtained by Feldhofer and Rechberger [7] in
their synthesis of an RFID tag based on a 18.75µA, 0.35µm
CMOS process technology operating at 100 kHz. Since in [7],
all numbers are assumed to be 32-bit numbers, for the sake
of comparison, in our scheme we assume that all the numbers

used are 32-bit numbers as well. We note that our scheme can
handle bigger numbers also.
12000
10,868

10000
8,120

Number of gates

the ID that is obtained by S after going through the procedure
in Steps 9 through 15 be given as Xf alse . Since R1δ = R1 ,
hence it is obvious that Xj = Xf alse . In addition, as we have
proved in Theorem 4.1, the probability that Xf alse matches
the ID of some other valid tag is negligible. This ensures that
the adversary can not authenticate itself by replaying messages
it has captured.
The adversary cannot perform desynchronization attack in
our system as well. This is because there are no shared
variables between the tags and the server that need synchronization at the time of authentication. We also note that
our scheme ensures forward secrecy, that is, due to the fact
that the messages generated are uncorrelated and random, the
messages that are used to authenticate the tag at a given point
of time cannot be used to obtain its identity later.
If the adversary compromises the reader, it still cannot
identify the tags that authenticate themselves using the reader,
nor can it perform better traffic analysis. If the adversary
compromises a reader, Ri say, then it obtains the secret Ri .
Consequently, the adversary knows R1 . However, this does
not help it decrypt M when it receives it from the tag. The
content of M still appears perfectly random to the adversary.
Further, if the adversary masquerades as an authentic reader
and obtains the response from a valid tag, it cannot use that
information to authenticate itself as a tag nor can it obtain
the identity of the tag. The reason that the adversary cannot
authenticate itself is similar to that for the replay attack.
We note that the man-in-the-middle attack and the cloning
attack cannot be prevented by our scheme. Unfortunately, we
did not find any scheme in the literature that adequately prevent these two attacks in an RFID system. This fact has been
noted by Schneier as well [18]. We note here that our scheme
ensures that in the event of a tag being compromised the
adversary has access to only the secrets of the compromised
tag. Hence, the compromise of a tag is localized and does not
in any way compromise the integrity and anonymity of the
other tags in the system.

8,400

8000

7,350

6000

4000

3,400
2,220
1,680

2000

0

Fig. 2.

SHA−256SHA−1

MD5

MD4

AES

HB+

SEAS

Comparison of the number of gates used.

As we have mentioned in the categorization in Section 2,
the schemes proposed can be classified into those that use
hash functions, symmetric key operations, and those that use
logical operations. For comparison with the hash function
based schemes we shall compare with just the hash functions themselves, while noting that the schemes themselves
require extra resources for implementation in the tags. The
hash functions used for comparison are SHA-256, SHA-1,
MD5, and MD4 [19]. Similarly, for the symmetric key based
schemes, we compare with the encryption scheme only. For
comparison, we use the AES only as it performs better than
any other symmetric encryption algorithm [7]. For comparison
with schemes based on logical operations, we compare our
scheme with the basic HB+ scheme proposed by Juels and
Weis [11]. The HB+ scheme forms the basis for many other
enhancements proposed in the literature.
Fig. 1 illustrates the number of gates needed in the RFID
tags for implementing our scheme SEAS and the other
schemes used for comparison. The hashing based schemes
require a large number of gates in comparison to the schemes
that use symmetric encryption. This has been demonstrated by
Feldhofer and Rechberger [7]. We used the techniques used
in [7] to calculate the number of gates for HB+ and SEAS.
Our scheme requires less number of gates in comparison to
every schemes except for HB+ . The HB+ scheme requires
less number of gates because it uses only two XOR and two
AND operations, three constants, and one temporary register.
In comparison, our scheme requires four XOR operations, uses
two constants, four variables, performs one rotation operation,
and needs one temporary register. We note that the other
schemes that are enhancements of the HB+ may require more
gates. Despite our scheme requiring more gates, it is more
efficient than HB+ . This is because the HB+ scheme is a
multi-round scheme, which requires a significant number of
rounds to perform secure and anonymous authentication of
the tag. Multi-round schemes require more clock cycles thus
requiring interface between the reader and the tag for a longer
time. SEAS on the other hand, has the advantage of being a
single round scheme.
Fig. 2 shows the number of clock cycles required for the
execution of the schemes. Our scheme performs the best in

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2009 proceedings

1400
1,274

1200

1,128

Number of clock cycles

1,032

1000
800
612

600
456

400
160

200

44

0

Fig. 3.

SHA−256SHA−1

MD5

MD4

AES

HB+

SEAS

Comparison of the number of clock cycles used.

terms of number of clock cycles required. For the HB+ scheme
we assumed that the number of rounds required is 20, which
is a small number. In reality, the number of rounds could be
more. As stated before, a scheme with multiple rounds requires
the tag to be in the proximity of the reader for the whole
duration that the rounds are being executed. This slows down
the authentication process and affects the scalability of the
scheme. The above analysis shows that our scheme SEAS, is
both efficient and effective in providing the RFID tags with
private and anonymous authentication.
6. C ONCLUSION AND F UTURE W ORK
In this paper, we propose SEAS, an efficient anonymity
scheme for providing authentication to RFID tags while still
preserving their privacy. Our scheme uses efficient operations
such as XOR and bits rotation only and provides a secure
mechanism for the tags to authenticate themselves to the readers. We perform security analysis and performance evaluation
to demonstrate the effectiveness and efficiency of our scheme.
In the future, we wish to make the scheme more secure and
implement it on existing RFID tags for evaluation.
R EFERENCES
[1] C. Chatmon, T. van Le, and M. Burmester. Secure anonymous RFID
authentication protocols. Florida State University, Department of Computer Science, Tech. Rep, 2006.
[2] T. Dimitriou. A Lightweight RFID Protocol to protect against Traceability and Cloning attacks. In First International Conference on
Security and Privacy for Emerging Areas in Communications Networks
(SecureComm), pages 59–66, 2005.
[3] T. Dimitriou. A Secure and Efficient RFID Protocol that could make Big
Brother (partially) Obsolete. In Proceedings of the Fourth Annual IEEE
International Conference on Pervasive Computing and Communications
(PERCOM), pages 269–275. IEEE Computer Society Washington, DC,
USA, 2006.
[4] S. Dominikus, E. Oswald, and M. Feldhofer. Symmetric authentication
for RFID systems in practice. In ECRYPT Workshop on RFID and
Lightweight Cryptography, pages 14–15, 2005.
[5] M. Feldhofer. An authentication protocol in a security layer for
RFID smart tags. In IEEE Mediterranean Electrotechnical Conference
(MELECON), volume 2, pages 759–762, 2004.
[6] M. Feldhofer, S. Dominikus, and J. Wolkerstorfer. Strong Authentication
for RFID Systems Using the AES Algorithm. Lecture notes in Computer
Science, pages 357–370, 2004.
[7] M. Feldhofer and C. Rechberger. A Case Against Currently Used Hash
Functions in RFID Protocols. Lecture Notes in Computer Science,
4278:372–381, 2006.
[8] H. Gilbert, M. Robshaw, and H. Sibert. Active attack against HB/sup+: a
provably secure lightweight authentication protocol. Electronics Letters,
41(21):1169–1170, 2005.

[9] N. Hopper and M. Blum. A Secure Human-Computer Authentication
Scheme. Technical report, Tech Report CMU-CS-00-139, Carnegie
Mellon University, School of Computer Science, 2000.
[10] A. Juels. Minimalist cryptography for low-cost RFID tags. In The
Fourth International Conference on Security in Communication Networks (SCN), volume 3352, pages 149–164, 2004.
[11] A. Juels and S. Weis. Authenticating Pervasive Devices with Human
Protocols. Lecture Notes In Computer Science, 3621:293–308, 2005.
[12] J. Katz and J. Shin. Parallel and Concurrent Security of the HB and HB
Protocols. In EUROCRYPT, pages 73–87. Springer, 2006.
[13] S. Lee, Y. Hwang, D. Lee, and J. Lim. Efficient authentication for
low-cost RFID systems. In International Conference on Computational
Science and its Applications (ICCSA), pages 619–627. Springer, 2005.
[14] M. Lehtonen, T. Staake, F. Michahelles, and E. Fleisch. From identification to authentication - A review of rfid product authentication techniques. In Printed handout of Workshop on RFID Security, RFIDSec’06,
2006.
[15] D. Molnar and D. Wagner. Privacy and security in library RFID: issues,
practices, and architectures. In ACM conference on Computer and
communications security, pages 210–219. ACM New York, NY, USA,
2004.
[16] S. Piramuthu. HB and related lightweight authentication protocols
for secure RFID tag/reader authentication. Collaborative Electronic
Commerce Technology and Research–CollECTeR, 2006.
[17] S. Sarma. Towards the five-cent tag. Auto-ID Center Massachusetts
Institute of Technology-Technical Report, Cambridge, 2001.
[18] B. Schneier.
Rfid cards and man-in-the-middle attacks.
http://www.schneier.com/blog/archives/2006/04/
rfid_cards_and.html, April 2006.
[19] Bruce Schneier. Applied Cryptography. John Wiley and Sons, 2 edition,
1996.
[20] G. Tsudik. YA-TRAP: Yet Another Trivial RFID Authentication
Protocol. In IEEE International Conference on Pervasive Computing
and Communications (PerCom), pages 640–643, 2006.
[21] P. Tuyls and L. Batina. RFID-Tags for Anti-counterfeiting. Lecture
Notes In Computer Science, 3860:115–131, 2006.
[22] S. Weis, S. Sarma, R. Rivest, and D. Engels. Security and Privacy
Aspects of Low-Cost Radio Frequency Identification Systems. Lecture
Notes In Computer Science, 2802:201–212, 2004.
[23] J. Yang, J. Park, H. Lee, K. Ren, and K. Kim. Mutual authentication protocol for low-cost RFID. In Ecrypt Workshop on RFID and Lightweight
Crypto, pages 17–24, 2005.

On Efficient Ciphertext-Policy Attribute Based Encryption
and Broadcast Encryption
[Extended Abstract]

∗

Zhibin Zhou

Dijiang Huang

Arizona State University

Arizona State University

zhibin.zhou@asu.edu

dijiang@asu.edu

ABSTRACT

size of a ciphertext increases linearly with respect to the
number of included attributes. For example, the message
size in BSW CP-ABE [1] starts at about 630 bytes, and
each additional attribute adds about 250-300 bytes.
In this paper, we propose a novel CP-ABE construction,
named Constant-size Ciphertext Policy Attribute Based Encryption (CCP-ABE), which incurs constant-size of ciphertext, regardless of the number of attributes in a logical AN D
data access policy with wildcards. Besides the encrypted
message and encoded access policy, each ciphertext only requires 2 bilinear group elements, which are bounded by 300
bytes in total.
Based on presented CCP-ABE, we further provide a new
construction named as Attribute Based Broadcast Encryption (ABBE) that supports eﬃcient Broadcast Encryption
(BE). In existing BE schemes, e.g., [2], a broadcaster encrypts a message for an speciﬁed set of receivers who are
listening on a broadcast channel. Each receiver in the speciﬁed set can decrypt the message while all other receivers that
are not in the speciﬁed set cannot decrypt even though they
collude together. However, in a system with large number of
users, identifying every decryptor may be impractical. For
example, to broadcast a message to all Computer Science
students, the encryptor needs to query a central directory
to get the contact information from every CS student in the
roaster, in which the operation could be very expensive and
time consuming. Using ABBE, an encryptor has the ﬂexibility to encrypt the broadcasted data using CCP-ABE, either
with or without the information of each intended receiver.
ABBE also signiﬁcantly reduces the storage overhead compared to many existing BE schemes. For example, in BGW
scheme [2], the public key size is O(N ) or O(N 1/2 ), where N
is the number of users in the system. ABBE addresses this
key storage overhead problem by optimizing the organization of attribute hierarchy to minimize the storage requirement for each user to O(log N + m), where m is a constant
number and m ≪ N .

Existing CP-ABE schemes incur very large ciphertext size,
which increases linearly with respect to the number of attributes in the access policy. Large ciphertext prevents CPABE from being adopted in the communication constrained
environments. In this paper, we proposed a new construction of CP-ABE, named Constant-size CP-ABE (denoted
as CCP-ABE) that signiﬁcantly reduces the ciphertext to a
constant size for an AND gate access policy with any given
number of attributes. Each ciphertext in CCP-ABE requires
only 2 elements on a bilinear group.
Based on CCP-ABE, we further proposed an Attribute
Based Broadcast Encryption (ABBE) scheme. Compared to
existing Broadcast Encryption (BE) schemes, ABBE is more
ﬂexible because a broadcasted message can be encrypted by
an expressive access policy, either with or without explicit
specifying the receivers. Moreover, ABBE signiﬁcantly reduces the storage and communication overhead to the order
of O(log N ), where N is the system size.
Categories and Subject Descriptors: E.3 [DATA ENCRYPTION]: Public key cryptosystems
General Terms: Security.
Keywords: Attribute-based Encryption, Broadcast Encryption.

1. INTRODUCTION
Research in Ciphtertext Policy Attribute-Based Encryption (CP-ABE) has been a very active area in recent years
[1, 4, 3, 5]. Under the construction of CP-ABE, an attribute
is a descriptive string assigned to (or associated with) an entity and each entity may be tagged with multiple attributes.
Many entities may share common attributes, which allow
message encryptors to specify a data access policy by composing multiple attributes through logical operators such as
“AND”, “OR”, etc. To decrypt the message, the decryptor’s
attributes need to satisfy the access policy.
Apart from the promising features provided by CP-ABE
solutions, there is a major problem of the existing CP-ABE
schemes, which usually incur large, linearly increasing ciphertext. In the CP-ABE schemes reported in [1, 3, 5], the
∗A full version of this paper
http://eprint.iacr.org/2010/395

is

available

2.

BACKGROUND AND MODELS

Bilinear Pairing is a bilinear map function e : G0 × G0 →
G1 , where G0 and G1 are two multiplicative cyclic groups
with large prime order p. The Discrete Logarithm Problem (DLP) on both G0 and G1 is hard. One of the pairing
properties is Bilinearity: e(P a , Qb ) = e(P, Q)ab , ∀P, Q ∈
G0 , ∀a, b ∈ Z∗p .
Decisional K-BDHE The decisional K-BDHE assumption
is said to be hold in G0 if there is no probabilistic polynomial
time adversary who is able to distinguish the following 2

at

Copyright is held by the author/owner(s).
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
ACM 978-1-4503-0244-9/10/10.

753

The private key for user u is computed as:

tuples:
< h, g, Yg,α,K , e(g, h)

α(K+1)

−
SKu = (D, {Di |∀i ∈ L+
u }, {Di |∀i ∈ Lu },

R

>, < h, g, Yg,α,K , e(g, h) >

{Fi |∀i ∈ L∗ }).

with non-negligible advantage, where α, R ∈ Zp and g, h ∈
G0 are chosen independently and uniformly at random and
Yg,α,K = {g , g
α

(α2 )

,··· ,g

αK

,g

αK+2

,··· ,g

α2K

Encryption: The encrypter picks a random t in Zp and sets
the one-time symmetric encryption key Key = e(gK , g1 )kt .
Suppose AND-gate policy is W with k attributes. Each
attribute is either positive/negative or wildcards.
The encryptor ﬁrst encrypts the message using symmetric
key Key as {M }Key . The∏encryptor also sets C0 = g t .
Then, it calculates C1 = (v j∈W gK+1−j )t . The ciphertext
is:
∏
CT = (W, {M }Key , g t , (v
gK+1−j )t )

}.

Let U = {A1 , A2 , · · · , Ak } be the Universe of attributes in
−
∗
the system. Each Ai has three values: {A+
i , Ai , Ai }. When
a user u joins the system, u is tagged with an attribute list
deﬁned as follows:
Definition 1. A user’s attribute list is defined as L =
+/−
+/−
+/−
+/−
−
{A1 , A2 , . . . , Ak }, where Ai
∈ {A+
i , Ai } and k
is the number of attributes in the universe. L = L+ ∪ L− .
L+ = {A+
· · · k}} and L− = {A−
i |∀i ∈ {1
i |∀i ∈ {1 · · · k}}.
+∩ −
Also, we have L
L = ∅.


j∈W

= (W, {M }Key , C0 , C1 ).
Decryption: The decryptor u needs to checks whether
Lu |= W when receiving the ciphertext. If not, u returns
⊥.
Then for ∀i ∈ W , u calculates the following terms:

−
Intuitively, A+
i denotes the user has Ai ; Ai denotes the
user does not have Ai or Ai is not a proper attribute of this
user. For example, suppose U = {A1 = CS, A2 = EE, A3 =
Faculty, A4 = Student}. Alice is a student in CS department; Bob is a faculty in EE department; Carol is a faculty
holding a joint position in EE and CS department. Their
attribute lists are illustrated in the following table:

Attributes
Description
Alice
Bob
Carol

A1
CS
A+
1
A−
1
A+
1

A2
EE
A−
2
A+
2
A+
2

A3
Faculty
A−
3
A+
3
A+
3

i

e(gi , C1 ) = e(g α , g t(γ+
i

= e(g, g)tγα

A4
Student
A+
4
A−
4
A−
4

j∈W

+t

αK+1−j )

∑

)

K+1−j+i

j∈W

α

, and

gK+1−j+i )

j∈W,j̸=i
∑
+ri′ )+ j∈W,j̸=i αK+1−j+i

i

= e(g t , g γ(α

i

= e(g, g)tγ(α

Definition 2. Let W = {A1 , A2 , · · · , Ak } be an AND−
∗
gate access policy, where Ai ∈ {A+
i , Ai , Ai }. We use the
notation L |= W to denote that the attribute list L of a user
satisfies W , as:
∪
L |= W ⇐⇒ W ⊂ L {A∗1 , A∗2 , · · · A∗k , }.

3. CONSTANT CP-ABE

∏

e(C0 , Di ·

∑

+ri′ )+t

∑

)

K+1−j+i

j∈W,j̸=i

α

.

Then, we calculate
∏

e(gi , C1 )/e(C0 , di ·

gK+1−j+i )

j∈S,j̸=i
K+1

= e(g, g)−tγri′ +tα



.

After we calculate all k terms, we make a production of
all the quotient terms and get:

Setup(k): Assuming there are k attributes {A1 , A2 , · · · , Ak }
in the system, we have K = 3k attributes values since
−
∗
each attribute Ai has 3 values: {A+
i , Ai , Ai }. For ease
+
+
+
of presentation, we map {A1 , A2 , · · · , Ak } to {1, · · · , k},
−
−
∗
∗
∗
{A−
1 , A2 , · · · , Ak } to {k + 1, · · · , 2k} and {A1 , A2 , · · · , Ak }
to {2k + 1, · · · , 3k}.
Let G0 be the bilinear group of prime order p. Trusted
Authority (TA) ﬁrst picks a random generator g ∈ G0 and a
i
random α ∈ Zp . It computes gi = g (α ) for i = 1, 2, · · · , K, K+
2, · · · , 2K where K = 3k. Next, TA picks a random γ ∈
Zp and sets v = g γ ∈ G0 . The public key is: P K =
(g, g1 , . . . , gK , gK+2 , . . . , g2K , v) ∈ G2K+1
.
0
The master key M K = {γ, α} is guarded by the TA.
Key Generation :Each user u is tagged with the attribute
−
list Lu = L+
We have
u ∪ Lu when joining the system.
+
Lu ⊂ {1, · · · , k}, L−
u ⊂ {k + 1, · · · , 2k}. We also have
L∗ = {2k + 1, · · · , 3k}. The TA ﬁrst selects k random num∑
bers {r1 , r2 , · · · , rk } from Zp and calculate r = ki=1 ri .
The TA computes D = g γr = v r . For every i ∈ L+
u , TA
i
calculates Di = g γ(α +ri′ ) where i′ = i; for every i ∈ L−
u,
i
TA calculates Di = g γ(α +ri′ ) where i′ = i − k; for every
i
i ∈ L∗ , TA calculates Fi = g γ(α +ri′ ) where i′ = i − 2k.

754

k+1

e(g, g)−tγ(r1 +r2 +···+rk )+ktα

K+1

= e(g, g)−tγr+ktα

.

We calculate:
e(D, C0 ) = e(g, g)tγr .
Then, we produce these two terms and get
K+1

Key = e(g, g)ktα

= e(gK , g1 )kt

and decrypt the message.

4.

ABBE

In ABBE with N users, each user is issued an n-bit binary
ID b0 b1 · · · bn , where bi represents the i’th bit in the user’s
binary ID, where n = log N . Accordingly, we can deﬁne
n bit-assignment attributes {B1 , B2 , · · · , Bn }. Each user
is assigned n bit-assignment attribute values according to
his/her ID. If the bi = 1, he/she is assigned the Bi+ , if
the bi = 0, he/she is assigned the Bi− . For example, in
a system with 8 possible users, each user is assigned 3 bitassignment attributes to represent the bit values in their ID,
as illustrated in Figure 1:

bit-assignment attributes to identity each user. We can refer
BGW scheme in [2] as maximalist. In BGW scheme, for a
system with N users, each user is mapped to a unique public
key. Given all N public keys, the number of combinations
is 2N − 1, which equals to the number of receiver subsets in
the system. Thus, each encryptor needs maximal number of
public keys to perform broadcast encryption.
To compare the minimalist and maximalist storage strategy, we can treat each attribute or public key as an binary variable v ∈ {1, 0}. We denote p = Pv=1 as the percentage of totals users who have this attributes or public
key and 1 − p = Pv=0 as the percentage of totals users
who do not have this attributes or public key, given that
P(v=1) + P(v=0) = 1.

Figure 1: An illustration of bit-assignment attributes assignment for a 3-bit ID space.
With the 3n + 3m attribute values, the authority runs
Setup(n + m) algorithm and generate public keys and private keys.
Here, we focus on how an encryptor can specify the list
of receivers explicitly using n bit-assignment attributes. We
ﬁrst deﬁne some of the terms used in the following presentations:

Definition 3. The entropy of an attribute or a public
key is defined as:
H(v) = p log p−1 + (1 − p) log(1 − p)−1 .

• Literal : A variable or its complement, e.g., b1 , b1 , etc.
• Product Term: Literals connected by AND, e.g., b2 b1 b0 .
• Sum-of-Product Expression (SOPE): Product terms connected by OR, e.g., b2 b1 b0 + b2 .
Given the set of receivers S, the membership functions
fS (), which is in the form of SOPE, speciﬁes the list of receivers:
{
0 iﬀ u ∈ S,
fS (bu1 , bu2 , . . . , bun ) =
1 iﬀ u ∈
/ S.

5.

For example, if the subgroup S = {000, 001, 011, 111}, then
fS = b0 b1 b2 + b0 b1 b2 + b0 b1 b2 + b0 b1 b2 .
Then, the broadcast encryptor runs the Quine-McCluskey
algorithm [6] to reduce fS to minimal SOPE fSmin . The
reduction can consider do not care values ∗ on those IDs that
are not currently assigned to any receiver to further reduce
number of product terms in the membership function. For
example, if S = {000, 001, 011, 111}, fSmin = b0 b1 + b1 b2 .
Since fSmin is in the form of SOPE, encryption is performed on each product term. That is, for each product
term E in fSmin , the encryptor speciﬁes an AND-gate access
policy W using the following rules:
1. For positive literal bi ∈
policy W .

fSmin ,

set

Bi+


Based on the Deﬁnition 3 , we see the entropy of each
attribute in minimalist strategy as Ha (1/2) = 1 since ,for
each particular attribute, exact half of the users have it while
the other half do not have it. On the other hand, the entropy of public key in maximalist strategy is Ha (1/N ) =
(1/N ) log(N ) + ((N − 1)/N ) log(N/(N − 1)) < 1. Hence, we
can conclude that minimalist strategy attains maximal binary entropy while the maximalist strategy attains minimal
binary entropy.

CONCLUSION

In this paper, a Constant Ciphertext Policy Attribute
Based Encryption (CCP-ABE) was proposed. Compared
with existing CP-ABE constructions, CCP-ABE signiﬁcantly
reduces the ciphertext size from linear to constant and supports expressive access policies. Based on CCP-ABE, we
further proposed an Attribute Based Broadcast Encryption
(ABBE) scheme that attains information theoretical minimal storage overhead. Thus, a storage restricted user can
easily pre-install all required key materials to perform encryption and decryption.

6.

REFERENCES

[1] J. Bethencourt, A. Sahai, and B. Waters. Ciphertext-policy
attribute-based encryption. In SP ’07: Proceedings of the 2007
IEEE Symposium on Security and Privacy, pages 321–334,
Washington, DC, USA, 2007. IEEE Computer Society.
[2] D. Boneh, C. Gentry, and B. Waters. Collusion resistant
broadcast encryption with short ciphertexts and private keys.
In Advances in Cryptology–CRYPTO 2005, pages 258–275.
Springer, 2005.
[3] D. Boneh and B. Waters. Conjunctive, subset, and range
queries on encrypted data. In TCC’07: Proceedings of the 4th
conference on Theory of cryptography, pages 535–554, Berlin,
Heidelberg, 2007. Springer-Verlag.
[4] L. Cheung and C. Newport. Provably secure ciphertext policy
abe. In CCS ’07: Proceedings of the 14th ACM conference on
Computer and communications security, pages 456–465, New
York, NY, USA, 2007. ACM.
[5] J. Katz, A. Sahai, and B. Waters. Predicate encryption
supporting disjunctions, polynomial equations, and inner
products. In EUROCRYPT’08: Proceedings of the theory and
applications of cryptographic techniques 27th annual
international conference on Advances in cryptology, pages
146–162, Berlin, Heidelberg, 2008. Springer-Verlag.
[6] E.J. McCluskey. Minimization of Boolean functions. Bell
System Technical Journal, 35(5):1417–1444, 1956.

in the access

2. For negative literal bi ∈ fSmin , set Bi− in the access
policy W .
3. Set Bi∗ for the rest of bit-assignment attributes.
For each W , the encryptor uses Encrypt(PK, W, M) algorithm to encrypt the message. The total number of encrypted message equals to the number of product terms in
fSmin .
For example, if S = {000, 001, 011, 111}, fSmin = b0 b1 +
b1 b2 . We can ﬁnd that fSmin contains 2 product terms. the
message M for S can be encrypted into 2 ciphertexts with
2 product terms respectively.

4.1 Information Theoretical Optimality
If we denote our optimal bit-assignment attributes assignment to be minimalist, which requires the least number of

755

XING_LAYOUT_Layout 1 9/20/13 12:43 PM Page 6

Mobile Cloud Computing Service Models:
A User-Centric Approach
Dijiang Huang, Tianyi Xing, and Huijun Wu, Arizona State University
Abstract

Mobile devices are rapidly becoming the major service participants nowadays.
However, traditional client-server based mobile service models are not able to meet
the increasing demands from mobile users in terms of services diversity, user experience, security and privacy, and so on. Cloud computing enables mobile devices
to offload complex operations of mobile applications, which are infeasible on
mobile devices alone. In this article, we provide a comprehensive study to lay out
existing mobile cloud computing service models and key achievements, and present a new user-centric mobile cloud computing service model to advance existing
mobile cloud computing research.

T

oday, the Internet web service is the main way we
access information from fixed or mobile terminals.
Some of the information is stored in Internet clouds,
where computing, communication, and storage are
common services provided for Internet users. In the non-distant
future, many of our queries will be beyond the current Internet
scope and will be about the people, physical environments that
surround us, and virtual environments with which we will be
involved. With the Internet environment improving, mobile
phones are overtaking PCs as the most common web access
entities worldwide by 2013 as predicted by Gartner [1]. Current
mobile devices have many advanced features such as mobility,
communication, and sensing capabilities, and can serve as the
personal information gateway for mobile users. However, when
running complex data mining and storing operations, the computation, energy, and storage limitations of mobile devices
demand an integrated solution relying on cloud-based computation and storage support. As a result, a new research field,
called mobile cloud computing (MCC), is emerging.
In MCC, a mobile entity can be considered as either a
physical mobile device or a mobile computing/storage software agent within a virtualized cloud resource provisioning
system. In the latter view of the cloud system, a software
agent’s main functionality is the mobility associated with software codes. In other words, mobile cloud applications may
migrate or compose software codes in the distributed MCC
resource provisioning environment. Mobile cloud services will
account for delay, energy consumption, real-time entity presence, information caching capabilities, networking and communication connectivity, data protection and sharing
requirements, and so on. By achieving these features, we are
actually able to create a new world composed of both physically networked systems and virtualized entities that are
mapped to the physical systems, preserving and in some cases
extending their functions and capabilities.
MCC distinguishes its research focuses on tight interaction
between, and construction and integration of, the cyber physical system (CPS) and cyber virtual system (CVS), in which the
CPS is immensely composed by computational and physical
smart and mobile entities, and the CVS is mainly formed by

6

0890-8044/13/$25.00 © 2013 IEEE

cloud-based virtualized resources and services. Recent developments in augmented reality (AR) have demonstrated some
of the application capabilities of MCC.
This article first focuses on a comprehensive study of existing MCC service models, and then a user-centric MCC service
framework is presented. The rest of this article is arranged as
follows. We summarize current mobile cloud service models
based on the role of mobile devices. We illustrate the current
representatives according to the different service models previously defined. We state the transformation from the traditional
Internet cloud to the mobile cloud and highlight features of
MCC. The future research directions of MCC are proposed,
focusing on a new user-centric service model and corresponding application scenarios. Finally, we conclude this article.

Current Mobile Cloud Service Models
Current Internet clouds have been broadly classified in three
service models: infrastructure as a service (IaaS), platform as
a service (PaaS), and software as a service (SaaS). They are
classified according to the layers of virtualization. However,
due to the involvement of both CPS and CVS, MCC’s service
models are more appropriately classified according to the
roles of computational entities within its service framework,
where the classification of MCC service models can use the
roles and relations between mobile entities and their invoked
cloud-based resource provisioning. Based on this view, existing MCC services can be classified into three major models:
mobile as a service consumer (MaaSC), mobile as a service
provider (MaaSP), and mobile as a service broker (MaaSB).
These MCC service models are illustrated in Fig. 1, in which
arrows indicate service processing flows from service providers
to service recipients.
MaaSC is originated from the traditional client-server
model by introducing virtualization, fine-grained access control, and other cloud-based technologies at the initial stage.
Mobile devices can outsource their computation and storage
functions onto the cloud in order to achieve better performance and more application capabilities. In this architecture,
the service is one-way from the cloud to mobile devices and

IEEE Network • September/October 2013

XING_LAYOUT_Layout 1 9/20/13 12:43 PM Page 7

Service recipient

mobile devices are service consumers. Most existing
MCC services fall into this category.
MaaSP is different from MaaSC in that the role of a
mobile device is shifted from a service consumer to a
service provider. For example, with onboard sensors
(GPS module, camera, gyroscope, etc.), mobile devices
are able to sense data from the devices and their neighboring environment, and further provide sensing services to other mobile devices through the cloud. In Fig.
1, consumers receive services provided by both the
cloud and mobile devices. The types of services provided by mobile devices are diverse based on their sensing
and processing capabilities.
MaaSB can be considered as an extension of MaaSP,
where MaaSB provides networking and data forwarding
services for other mobile devices or sensing nodes.
MaaSB is desired under some circumstances because
mobile devices usually have limited sensing capability
compared to sensors that are dedicated for specially
designed functionalities and sensing locations. For example, mobile phones can be used to collect users’ physical
activities from Nike Fuelband [2]. MaaSB extends the
cloud edges to mobile devices and wireless sensors. Thus,
a mobile device can be configured as a gateway or proxy
providing networking services through various communication approaches such as 3/4G, Bluetooth, and WiFi.
Moreover, the proxy mobile device can also provide security and privacy protections to their interfaced sensors.

Existing Mobile Cloud Applications

Service AP

Cloud resource
Mobile as a service consumer (MaaSC)

Service AP

Cloud resource

Service
recipient

Service
provider

Mobile as a service provider (MaaSP)

Service AP

Cloud resource

Service

Service

Sensor

broker
networks
recipient
We summarize existing MCC services and applications in
Table 1. We discuss four major MCC service types and
Mobile as a service broker (MaaSB)
corresponding representatives. Each service or application can be categorized into one or multiple service models. MaaSC is the most common MCC service model
Figure 1. Current service models of MCC.
because most existing mobile devices are still restricted
by their computation and energy capacities. As an example, clonecloud [3] provides computation task offloading
Mobile Cloud Storage
service for mobile devices. In this case, the mobile device is the
service consumer since it only benefits from the service providStorage capacity is another constraint of mobile devices.
ed by the cloud rather than providing services for other users.
There are many existing storage services for mobile devices,
such as Dropbox, Box, iCloud, Google Drive, and Skydrive
Mobile Cloud Computation
[6]. Besides manually uploading the files or data onto the
cloud, one desired feature of mobile cloud storage services is
Computation task offloading is a demanding feature for
the automatic synchronization between mobile devices and
mobile devices relying on Internet clouds to perform resourcethe cloud. Multimedia data generated by mobile devices
intensive computation tasks. Partitioning computation tasks
demands a stable and highly available storage solution. This is
and allocating them between mobile devices and clouds can
the reason why many smartphone operating systems natively
be very inefficient during the application runtime considering
implant the multimedia data synchronization feature (iCloud
various performance metrics such as energy consumption,
for iOS, Skydrive for Windows Phone, Google Drive for
CPU usage, and network delay. How to efficiently and intelliAndroid, etc.). Moreover, mobile users’ behavior data, such as
gently offload the computation tasks onto the cloud is one of
location traces, browsing history, personal contacts, and prefthe main research issues of MCC. CloneCloud [3] and MAUI
erence settings, need to be kept in a reliable and protected
[4] are two pioneer projects in this area. Both can automatistorage space. Most existing commercial cloud storage solucally offload computing tasks to the cloud.
tions are built on a centralized data center, which is appropriCloneCloud serves as an application partitioner as well as
ate for Internet clouds.
an execution runtime environment that allows unmodified
Storage mobility has gradually become a current research
mobile applications to seamlessly offload parts of the execufocus. WhereStore [7] is a location-based data storage solutions from mobile devices onto a cloud server. The offloading
tion for smartphones. It uses filtered replication (a filter
decision is made by optimizing execution time and energy
expressing the set of data items that are likely to be accessed
usage for mobile devices. In contrast to CloneCloud, MAUI
in the near future) along with each device’s location history to
allows modifying offloading applications at the coding level to
distribute data items between smartphones and the cloud.
maximize the energy saving of mobile devices. Thinkair [5]
STACEE [8] proposes a peer-to-peer (P2P) cloud storage
demands dedicated virtual machines (VMs) in clouds as part
where mobile phones, tablets, set-top-boxes, modems, and
of a complete smartphone system, and removes the restricnetworked storage devices can all contribute as storage within
tions on applications/inputs/environmental conditions by using
these storage clouds. It provides a P2P cloud storage solution
online method-level offloading.

IEEE Network • September/October 2013

7

XING_LAYOUT_Layout 1 9/20/13 12:43 PM Page 8

MCC services and applications
MCC service types

Mobile cloud computation

Mobile cloud storage

Service models

Representative approaches

MaaSC

CloneCloud [3]



MAUI [4]



ThinkAir [5]



Dropbox, Box, iCloud, GoogleDrive and Skydrive [6]



WhereStore [7]



STACEE [8]



CloudAV [9]



Secure Web Referral Services for Mobile Cloud Computing [10]



Zscaler [11]



Google Wallet [12]



MaaSP

MaaSB



Security and privacy

Context awareness

An Integrated Cloud-Based Framework for Mobile Phone Sensing [13]





Table 1. Summary of MCC services and applications.

and addresses the storage issue for mobile users as a quality
of service (QoS)-aware scheduling problem.

computing elements on the board to prevent malicious attacks
on mobile devices.

Security and Privacy

MCC Context Awareness

Security related services aim to provide data security protections through the cloud. The security of mobile devices can be
enhanced under the help of cloud security mechanism including cloud-based secure proxy, remote anti-virus, remote attestation, and so on.
CloudAV [9] advocates such a cloud-based security model
for malware detection for end hosts by providing antivirus as
an in-cloud security service. Secure web referral services [10]
enable antivirus and antiphishing services through the cloud.
Referral services depend on a secure search engine to validate
URLs accessed by a mobile device to prevent mobile users
from accessing phishing websites.
Zscaler [11] is one of the most well-known commercial
cloud-based security companies, providing policy-based secure
Internet access for mobile devices. It provides a comprehensive
cloud-based security solution including three main components: ZEN (proxy), central authority (CA), and Nanologs
server (log server). Various cloud-based security services are
built based on these components. For example, the ByteScan
service enables each ZEN to scan every byte of the web
request, content, responses, and all related data to block malicious actions and data such as viruses, cross-site scripting
(XSS), and botnets. The PageRisk service relies on the ZEN to
compute a PageRisk index for every page loaded and enables
the administrator to control content served to their users based
on an acceptable risk evaluation. The NanoLog service enables
administrators to access any transaction log in real time.
An increasing number of security features can be enabled
in the cloud, in which a reliable and secure connection
between a mobile device and the cloud is the main challenge
for this type of solution. Google Wallet [12] was developed on
a cloud-mobile dual trust root model, where the cloud is in
charge of the application-level security such as credit card
transactions and user credential management, and the Google
Wallet enabled mobile device is protected by strong trust

Nowadays, a smart mobile device usually serves as an information gateway for mobile users involving various personalized activities such as checking emails, making an
appointment, surfing the web, locating some interesting spots,
and analyzing personal behavior data based on data mining
and machine learning. For example, in [13], each mobile
device has a dedicated mobile cloud engine (MCE) including
three modules: decision module, publish subscribe module,
and context awareness module. The decision module handles
and regulates the transactions among the different parts of
the MCE. The publish subscribe module is responsible for
establishing the data flow between the mobile application and
the MCE. Finally, the context awareness module provides
context information to the application. The state-of-the-art
solutions lack a unified approach suitable to support diverse
applications while reducing the energy consumption and providing intelligent assistance to mobile users.

8

Transitions from Internet Clouds to UserCentric Mobile Clouds
Current MCC Issues and Transition Directions
From the service point of view, current MCC service providers
and their customers (i.e., mobile devices) are clearly defined.
Most existing computing models are similar to the traditional
client-server service models. Several issues with existing MCC
services are explained, and the expected transition characteristics are also discussed below.
Symmetric MCC service model: Most current MCC service
models are asymmetric. As shown by the examples presented
in Table 1, mobile devices are usually considered as clients of
cloud services. The service (e.g., computing and storage services) direction is mainly unidirectional, from the cloud to
mobile devices. With the increasing capability of mobile

IEEE Network • September/October 2013

XING_LAYOUT_Layout 1 9/20/13 12:43 PM Page 9

RC

VC

Cloud data
fusion function
cloud
servers

MC
CVRC
{PF}C

VC

CVRA
{PF}A

Traffic display
and advising
functions in
vehicle

RA

Video capture
(VC) function

Physical-virtual
environment integration
(offloading, migration,
and composition)

CVRB
{PF}C

MA
MCC

RB
MB

CVR: Cloud virtual resource (e.g., computing, communication, storage resources)
Integrated provisioning function group for mobile user.
PF: Provisioning function (can be composed/offloaded to form MCC applications)

(a)

(b)

Figure 2. An example of mobile cloud applications: a) MCC application scenario; b) user-centric MCC application model.
devices, mobile devices can also collaboratively execute the
applications’ tasks. Moreover, the virtualized environment
should provide intelligent feedback to physical devices to
adjust their behaviors or actions in order to provide better virtualized services. This virtualization-feedback loop model
demands a symmetric MCC service model; that is, both
mobile devices and the virtualized cloud are service providers
as well as clients at the same time.
Personalized situation awareness: In the current complicated
mobile cloud environment, data sources could be diverse (e.g.,
a mobile device, the environment, or a social network). Sometimes, a single data source is not sufficient to support MCC
applications in the cloud; moreover, data collected from heterogeneous networks might be unstructured or unclassified.
For example, in the physical world, there could be multiple
networking interfaces and services that are available to a
user’s device (a wireless sensor network, social network, vehicular network, personal and body area network, etc.). The
cloud should be able to get data from different source networks and then cluster them together to make the data structural and readable in the future. Thus, more work is expected
to construct situation awareness services that can be personalized according to individual users in the virtual environment.
User-centric trust model: Most current cloud trust models
are centralized: all mobile entities need to trust the cloud service provider. Storing private data in the cloud environment is
a big hurdle for most mobile cloud applications. It is desirable
to establish a distributed or decentralized trust management
framework within the virtualized cloud system to address the
privacy concerns of mobile users. In the physical world, the
virtualized resource could be hosted in either public or private
clouds that are tailored according to users’ preference. This
requirement demands that the current centralized cloud be
transferred in a distributed or decentralized fashion. For
example, including mobile users’ computing and storage
resources into the mobile cloud infrastructure without requiring (or even allowing) administrative privilege can significantly reduce the privacy concerns of mobile users.

User-Centric Mobile Cloud Computing
The next-generation MCC applications demand tight integration of the physical and virtual functions running on the
mobile devices and cloud servers, respectively. Moreover, due
to the mobility of mobile users and changes in the application
running environment, the MCC application functions are not
fixed on their running hosts. An illustrative vehicle traffic
management example is shown in Fig. 2a, in which a vehicle

IEEE Network • September/October 2013

may request video capture (VC) functions from other vehicles
directly (the dashed line) or through a centralized video
fusion function to get a holistic view of the entire road intersection. In this example, the VC providers are not fixed and
are selected by their location. Moreover, a VC function may
not only be used for an individual vehicle; it can also be used
for road traffic management, accident/hazard detection, and
so on. The resources, including mobiles, cloud servers, and
corresponding networking, that form an ad hoc cloud application running environment can be customized for each individual user; we refer such a customizable ad hoc cloud
application running system as user-centric MCC. The basic
functions used to form this MCC application (VC, display,
data fusion, etc.) are called provisioning functions (PFs).
The user-centric mobile cloud application running environment can be further illustrated in Fig. 2b, where mobiles (MA,
MB, MC) and their responding cloud virtual resources (CVRA,
CVRB, CVRC) construct a pairwise resource pool, RX = (MX,
CVRX), including both physical and virtualized resources. RX
represents user X constructing MCC applications formed by a
set of PFs {PF}X running on local or remote resource pools.
In this user-centric mobile cloud application running environment, a PF can be highly mobile, and composed and used by
multiple applications at the same time.

Design Principles of User-Centric Mobile Cloud
Computing
Future MCC should be reconsidered as a new service model,
where mobile agents (i.e., both physical and virtual entities)
and related resources collectively operate as mobile clouds
that enable computing, storage, and networking capabilities,
context awareness modeling, content discovery, and data collection and dissemination. To build future user-centric MCC
based on the described concepts and requirements, mobile
clouds should be shifted from the traditional Internet cloud by
using the following principles:
• Principle 1: User-centric: MCC applications should be
designed in such a way that a user can control their own
data and activities with strong privacy and security protection. Cloud resources should be collected and allocated
according to mobile applications customized for each individual user.
• Principle 2: Service-oriented application platform: Due to the
symmetric service model, every mobile node can potentially
serve as an MCC service provider; thus, a service-oriented
application platform is the natural choice for MCC.

9

XING_LAYOUT_Layout 1 9/20/13 12:43 PM Page 10

Physical
representor

Virtual
representor

Service
AP

Cloud resource
Mobile as a service representor (MaaR)

Figure 3. Mobile as a representor (MaaR).
• Principle 3: Mobility efficiency: MCC resources should be
dynamically allocated and managed according to the need
of mobile cloud applications. The mobility of MCC should
be confined through a set of mobile cloud application constraints to maximize efficiency using a set of system performance evaluation metrics such as availability, computing
power, storage, and their spacial-temporal boundaries.
• Principle 4: Virtual representation: MCC maintains a trusted,
reliable, and accessible virtual representation for each user.
The virtualized representation can be considered as an
assistant for mobile users and performs actions such as
sensing a user’s daily activity to build the user’s behavior
and activity profiles, and delegate the user’s activities in the
virtual environment.

Mobile as a Representer: A User-Centric
Approach
The future mobile cloud service model should be delivered
based on the principles illustrated. Besides previously presented
service models (i.e., MaaSC, MaaSP, and MaaSB), we present a
new user-centric MCC service model called mobile as a representer (MaaR). The architecture of MaaR can be found in Fig.
3. In MaaR, each user can be represented by a virtualized entity
in the cloud through his/her physical entity (i.e., mobile device).
Users’ behaviors and attributes can be collected from the real
world (people, environment, or mobile devices) in real time and
sent to their corresponding virtual entities in the cloud to perform further analysis and processing. Data mining and machine
learning algorithms can be used to analyze a mobile user’s situation and perform actions proactively. MaaR can be regarded as
the next-generation MCC service model in that both physical
systems and virtual systems are seamlessly integrated through
virtualization technologies to provide services. In MaaR, the
mobile devices and clouds are highly interactive, and as a result,
the service flow can be presented as bidirectional arrows. In
addition to helping mobile entities execute tasks more efficiently, MaaR is able to accomplish some tasks that are impossible to
realize in current MCC architecture.
MaaR model is presented to support the next-generation
user-centric MCC services and applications. A conceptual
architecture of MaaR is presented in Fig. 4, where both CPS
and CVS are integrated as a whole system. In the CPS, heterogeneous networks coexist, and all these networks can be
virtualized at the CVS by performing operations including
presenting, offloading, abstracting, caching, migration, and so
on. All data with the spatial, temporal, and correlation information from the CPS will be submitted to the CVS. Among
all these three types of information, correlation information is
essential in that it helps to fuse different types of data together into a well formatted one so that the CVS can further perform context awareness, user-centric proactive, and security
protection tasks. For example, the sensor network carries

10

sensed data, while the social network collects and
generates the social relationship data. The correlation information helps the CVS to generate sensing
data with social attributes (e.g., personal data that
Real user
is only accessible from a specific social group, like
people in the user’s friend list).
In MaaR, the CVS has three main types of provisioning resources: computing resource, storage
resource, and networking resource. The user’s virtual entity is represented by maintaining seamless
communication between the CPS and the CVS,
which also allows for establishing multiple personalized MCC clouds due to different application
purposes. An MCC application is able to control integration
of CPS and CVS through a well defined application programming interface (API) and MCC tools. The traditional Internet
cloud is one-way operational as users can only submit data
from the CPS to the CVS, while it is possible to allow the
CVS to further control the CPS functions in a highly adaptive
and dynamic fashion based on the MaaR model. Besides
physical data being virtualized to a virtual environment, the
CVS can provide feedback and control functions in the CPS.
To enable the service-oriented application running environment, MaaR provides a personal on-demand execution environment for MCC (POEM) framework [14] to achieve the
user-centric MCC service running platform highlighted in Fig.
2b. POEM is a mobile cloud application execution platform
that enables mobile devices to easily discover and compose
cloud resources for their applications. For mobile resource
providers, they may not even know what applications and who
may call their provisioned functions beforehand. In this way,
the mobile application design should not be application-oriented; instead, it should be functionality-oriented (or serviceoriented). To achieve these features, we can consider those
PFs as the fundamental application components in the MaaR
model, which can be composed by mobile cloud service
requesters in runtime.
POEM takes a comprehensive approach by incorporating
the OSGi-based [15] service-oriented architecture into MCC.
It treats the offloading as part of service composition, and as
a result, the codes (or computation tasks) are considered as
services provided by mobile devices and the cloud. In this way,
offloading and migration operations can be multidirectional
(i.e., among mobile devices and the cloud) compared to onedirectional (i.e., from a mobile device to the cloud) in previous solutions. Moreover, due to the popular Java-based OSGi
framework, POEM can greatly improve the adoption of the
SoA-based code reuse and composition for MCC.

An Application Scenario Based on the User-Centric
MaaR Model
To better understand the proposed future MaaR model, we
revisit the vehicular video sensing and collaboration example
presented in Fig. 2a. We assume that MaaR service modules
are already equipped on many users’ smartphones. When user
Alice is driving, her smartphone uses onboard sensors like a
camera or GPS to detect her location, driving speed, and
image/video captured on the road. The information can be collected and virtualized into the CVS to construct a virtual representation of the mobile device in the cloud for Alice, which is
the essence of MaaR in that the virtual representer represents
the real situation of the physical user. Practically, the representer is implemented through a set of software agents (i.e., OSGi
bundles) on a dedicated VM allocated for Alice, where Alice
has the administrative privilege on the VM to decide which
data can be shared and protected (by encryption). The dedicat-

IEEE Network • September/October 2013

XING_LAYOUT_Layout 1 9/20/13 12:43 PM Page 11

Mobile cloud application scenarios

.....

APIs and tools
Coordination and integration
Cyber virtual system: abstracted network systems

Cyber physical system: complex heterogeneous network systems

Cellular and data
networks

Vehicular
networks

Physical
life
Social networks

Personal and body
networks

Mobile ad hoc
networks

Mission critical
networks

*Situation-aware
*Human-centric
Control *Proactive
*Security and
privacy
protection

*Presentation
*Offloading
*Abstraction
*Caching Virtualization
*Migration
*Data

Correlation

Virtual-life

Mobile cloud
resource provisioning
Time

ce
Spa

Computing
resource

Storage
resource

Networking
resource

Figure 4. MaaR conceptual architecture.
ed VM is the application holder for Alice to incorporate various data processing models and functions for security, data
mining, and intelligent situation-aware decision making that are
personalized for Alice’s use. In this model, the VM can be
hosted in a public or private cloud as Alice chooses.
User Bob may want to know the current traffic status around
the bridge five miles ahead where Alice is driving. Users with
MaaR services running on their mobile devices near the bridge
can provide sensing functions (e.g., GPS, video/camera), which
are searchable by Bob so that Bob’s display function can call
those functions in real time through either direct P2P connections or a centralized traffic monitoring function provided by a
third party. In addition to the presented video capturing usage
of the application, MaaR services and applications can also
maintain social diagrams for each user. For example, when Bob
is driving in the area during lunchtime, the MaaR service representer of Bob can prepare for suggestions such as good nearby
restaurants with high rates by Bob’s trusted friends. Other suggestions may relate to Bob’s daily activities and job functions
according to his current location, and provide resources
promptly when Bob needs them. These personalized suggestions are based on correlating the location and various sensed
data by the MaaR service representor.

Summary
This article focuses on the introduction of MCC concepts and is
tutorial in nature so that readers are able to have a holistic view
of the current development of and vision for user-centric mobile
cloud computing. We first provide a classification and representative achievements of current MCC service models. Then we
discuss the transformation from the traditional Internet cloud to
the user-centric mobile cloud by listing the issues for current
MCC and presenting user-centric MCC and its design principles.
Finally, an MaaR service model with an illustrative example is
presented for achieving the user-centric MCC.

Acknowledgment
The presented work is sponsored by the ONR Young Investigator Program (YIP) award and NSF grant CPS1239396.

References
[1] M. Walshy, “Gartner: Mobile to Outpace Desktop Web by 2013,”
Online Media Daily, 2010.
[2] Nike Inc., http://www.nike.com.
[3] B. Chun et al., “Clonecloud: Elastic Execution between Mobile Device and
Cloud,” Proc. 6th Conf. Computer Systems, 2011, pp. 301–14.

IEEE Network • September/October 2013

[4] E. Cuervo et al. , “Maui: Making Smartphones Last Longer with Code
Offload,” Proc. Int’l. Conf. Mobile Sys., Applications, and Services, 2010.
[5] S. Kosta et al., “ThinkAir: Dynamic Resource Alloation and Parallel Execution in
Cloud for Mobile Code Offloading,” Proc. IEEE INFOCOM, 2012.
[6] A. Covert, “Google Drive, iCloud, Dropbox and More Compared: What’s
the Best Cloud Option?” Technical Review, 2012.
[7] P. Stued, I. Mohomed, and D. Terry, “Wherestore: Location-based Data
Storage for Mobile Devices Interacting with the Cloud,” Proc. 1st ACM
Wksp. Mobile Cloud Computing & Services: Social Networks and Beyond,
2010.
[8] D. Neumann et al. , “Stacee: Enhancing Storage Clouds Using Edge
Devices,” Proc. 1st ACM/IEEE Wksp. Autonomic Computing in Economics,
2010.
[9] J. Oberheide, E. Cooke, and F. Jahanian, “CloudAV: N-Version Antivirus
in the Network Cloud,” Proc. 17th USENIX Security Symp., San Jose, CA,
July 2008.
[10] D. H. Le Xu, V. Nagarajan, and W.-T. Tsai, “Secure Web Referral Services for Mobile Cloud Computing,” IEEE Int’l. Symp. Mobile Cloud, Computing, and Service Engineering, 2013.
[11] Zscaler Inc., http://www.zscaler.com.
[12] Google Inc., http://www.google.com/wallet.
[13] R. Fakoor et al. , “An Integrated Cloud-Based Framework for Mobile
Phone Sensing,” Proc. ACM SIGCOMM MCC Wksp., 2012.
[14] H. Wu and D. Huang, “Personal On-Demand Execution Environment for
Mobile Cloud Computing,” http://poem.mobicloud.asu.edu, 2013.
[15] OSGi Alliance, http://www.osgi.org.

Biographies
DIJIANG HUANG (dijiang@asu.edu) received his B.S. degree from Beijing University of Posts and Telecommunications, China, in 1995. He received his
M.S. and Ph.D. degrees from the University of Missouri Kansas City in 2001
and 2004, respectively. He is currently an associate professor in the School of
Computing Informatics and Decision System Engineering (CIDSE)at Arizona
State University. His current research interests are computer networking, security, privacy, and mobile cloud computing. He is an Associate Editor of the
Journal of Network and System Management and an Editor of IEEE Communications Surveys and Tutorials. He has served as an organizer for many international conferences and workshops. His research has been sponsored by
NSF, ONR, ARO, NATO, Hewlett Packard, and Consortium of Embedded
Systems (CES). This research is a result of his ONR Young Investigator Program Award.
TIANYI XING (tianyi.xing@asu.edu) is currently a Ph.D. student in CIDSE at Arizona State University. He received a B.E. in telecommunications engineering
from Xidian University and an M.E. in electronic engineering from Beijing University of Posts & Telecommunications in 2007 and 2010, respectively. He
worked in Microsoft Research Asia as a research intern from July to December
2009. His research interests are future Internet, mobile cloud computing, and
computer network security.
HUIJUN WU (huijun.wu@asu.edu) is currently a Ph.D. student in CIDSE at Arizona State University. He received his B.E. and M.E. in electronics and information engineering from Huazhong University of Science & Technology in
2007 and 2009, respectively. He worked in Alcatel-Lucent Shanghai Bell as a
SIT engineer from July 2009 to July 2011. His research interests are mobile
cloud application, mobile cloud service framework, and cloud computing.

11

2014 IEEE Conference on Communications and Network Security

Attribute-based Access Control for ICN Naming
Scheme
Bing Li1 , Ashwin Prabhu Verleker1 , Dijiang Huang1 , Zhijie Wang1 , and Yan Zhu2
1

School of Computing Informatics and Decision Systems Engineering, ASU, USA
2
School of Computer and Communication Engineering, USTB, China
1
{bingli5, anprabhu, dijiang, zhijie.wang }@asu.edu, 2 zhuyan@ustb.edu.cn

Abstract—Information Centric Networking (ICN) is a new
network architecture that aims to overcome the weakness of
existing IP-based networking architecture. Instead of establishing
a connection between the communicating hosts, ICN focuses on
the content, i.e. data, transmitted in network. Content copies
in ICN can be cached at different locations. The content is
out of the owner’s control once it’s published. Thus, enforcing
access control policies on distributed content copies is crucial in
ICN. Attribute-Based Encryption (ABE) is a feasible approach to
enforce such control mechanisms. However, applying ABE in ICN
has two challenges: from management perspective, managing
attributes is complicated in distributed manners; from privacy
perspective, unlike in traditional networks, the enforced content
access policies are public to all the ICN users. Thus, it is desirable
that unauthorized content viewers are not able to retrieve the
access policy. To this end, a privacy-preserving access control
scheme for ICN and associated attribute management solution
are presented in this paper. This proposed approach is compatible
with existing flat name based ICN architectures.
Index Terms—privacy, naming, information centric networking, access control, attribute management

I. I NTRODUCTION
In traditional networking schemes, if a network entity wants
to access some information content, it has to locate and
connect to the server that provides such service following
network routing protocols. As a result, the information is
associated tightly with the location of the server. The entire
network is centered around the connections between content
consumers and content providers, making connection status an
important factor to the network.
Witnessed by the fact that most of the network traffic is file
sharing, especially video sharing [1], various ICN architectures
[2, 3, 4, 5, 6] are proposed. In ICN architecture, the focus is
shifted to connecting the content consumers to the content.
Thus, instead of identifying the content owner’s address, the
network changes to identify authentic content copies. The
content name is sufficient to direct to a content copy. Content
owners publish the content, which can be copied and stored
in the network using network caches [7]. This design enables
contents being efficiently delivered to consumers.
Though the design is efficient in retrieving content, it brings
great challenges to security issues during content caching
and retrieving. One of them is that traditional access control
mechanisms cannot be easily enforced. This is because, in
ICN, content owners and consumers are not directly connected.

978-1-4799-5890-0/14/$31.00 ©2014 IEEE

Content owners have no control over the distributed network
caches. To enforce access control to the content, several
frameworks have been proposed [8, 9]. Most of them require
additional authorities in network to authenticate each content
consumer. These schemes are sound but still rely on traditional
control schemes, making them inefficient in practice.
In this paper, we propose an attribute-based access control
for ICN naming scheme. Particularly, to address the attribute
management problem, we present an ontology-based attribute
management solution to manage the distributed attributes in
ICN network. In this scheme, attributes defined by different
authorities can be synchronized more efficiently than traditional approaches. Content consumers do not need to negotiate
their attribute keys when they request contents from other
authorities.
With this ontology-based management scheme, we propose
an ABE-based naming scheme. This approach is inspired by
Attribute Based Encryption (ABE) schemes [10, 11, 12]. In
our approach, each network entity is assigned with a set
of attributes with the help of a Trusted Third Party (TTP)
according to their real identities. The access control policy
is enforced according to the content names instead of the
contents. Moreover, privacy-preservation is provided for the
content access policies. This feature can greatly improve the
privacy protection on ICN data when they are distributed in
the public domain. In this way, a user is able to identify
its eligibility of the accessed contents through the encrypted
names before actually accessing the data content. In summary,
the contributions of our work can be listed as follows:
• It provides ontology-based attribute management, which
greatly reduces the cost for attribute management in
distributed environment;
• It preserves the confidentiality of the content access
policy. Ineligible consumers cannot derive the data access
policies even if they collude together;
• It combines the privacy preserving access policy and
the flexible attribute management solution through the
naming scheme;
• It supports flexible attribute combination operations in the
access control policies;
• It significantly reduces the computation and communication overhead for a potential consumer to determine his
eligibility to access the content.

391

2014 IEEE Conference on Communications and Network Security

The remainder of this paper is organized as follows. Section
II goes through the related work on ICN and its security.
Section III presents the system models and preliminaries. We
present detailed description of the naming scheme in Section
IV and the ontology-based attribute management scheme in
Section V. We evaluate the performance of proposed solution
in Section VI and conclude this paper in Section VII.
II. R ELATED W ORK
In this paper, we propose an ABE-based scheme to enforce
a secure access control mechanism in ICN network. Before
going into details of our approach, we firstly introduce related
research results on ICN and ABE respectively.
A. ICN Solutions
Several ICN architectures have been proposed in the past
years. CBCB [2] runs on the application layer. It uses publish/subscribe scheme to publish contents. Each consumer broadcasts its interest in the form of attribute combinations. At each
router, the interests associated with an interface are updated in
the form of predicates. When content is transferred through the
network, the content is compared with the predicates on every
interface to determine through which interfaces to forward the
content.
DONA [3] is deployed above IP layer. The name of a
content is in the form of P:L, where P represents the hash of
the owner’s public key, L is a unique label the owner assigns
to the content. The owner registers the content into the name
resolution system. The consumers use the name resolution
system to find the nearest copy of the content. The system
returns with the content copy or the IP address of the content
location. NetInf [4] uses a similar naming scheme as DONA.
But instead of using the owner’s public key to generate the
digest, it uses a pair of public/private keys for the content.
It uses multi-level Distributed Hash Table (DHT) for name
resolution. PURSUIT [5] uses a similar naming scheme as
DONA. But it has a much different structure for retrieving
the content location which involves topology information and
load balance.
NDN [6] doesn’t specifically define the name structure.
A name in NDN consists of multiple components, each of
which can be a human-readable string or a digest of the
content. Content providers guarantee the uniqueness of name
components.
All these ICN solutions focus on the efficiency and security aspects of the network while access control to the
content and content privacy are not well addressed. In [8],
an independent access control system is introduced to support
the need in ICN. This system connects to the ICN structure
through a component called the Relaying Party (RP). An
additional component called Access Control Provider (ACP) is
in charge of creating access policies and enforcing the policies
to consumers’ credentials. This system incorporates access
control into ICN systems but requires much more network
interactions. For content privacy purposes, [13] proposes a
design in which each file is divided into blocks. A block

from the file is mixed with blocks from "cover" content using
randomizing transformations and the results are published to
the network. To recover the file, an authentic consumer needs
to get more information related to the file from a secure
channel.
B. ABE Schemes
Ciphertext-Policy ABE (CP-ABE) [10] was introduced by
J. Bethencourt et al. This scheme assigns each user with a set
of attributes according to their identities. There is one private
key corresponding to each attribute. A policy specifying under
what condition the ciphertext could be successfully decrypted
is constructed by the encryptor. This policy is attached with the
ciphertext in plaintext. Users who do not possess a satisfactory
combination of attributes are not able to decrypt the ciphertext.
This scheme enables providing access control to individual
messages. A content owner is able to specify the required
attribute combinations without knowing the receivers’ keys. In
addition, this scheme can defend against collusion attackers.
The reason why CP-ABE is not suitable for ICN usage
is that the policy is transmitted in clear text. In traditional
network, a user is authenticated before access is granted.
However, once a content is published in ICN, the owner
has no control of it. In this way, any network user who has
access to the ciphertext can access the policy. Attackers can
deduce the sensitivity of the message as well as inferring
the identities of those who are involved in the message
transmission. For example, a message encrypted with the policy {Dean} AN D {U niversityP resident} could be more
important than one with policy {F aculty} AN D {Student}.
Thus, attackers can identify those high-value users and concentrate attacks on these targets by simply conducting a traffic
analysis.
What needs to change to CP-ABE is to hide the policy into
the ciphertext. For this purpose, several works [11, 14] are
proposed. An attacker cannot get any information about the
policy. But these solutions sacrifice efficiency to security in
that any party that tries to decrypt the ciphertext will have
to go through the entire decryption process which involves a
heavy computation overhead.
To save computation resources for the unsatisfactory users,
D. Huang et al. proposed a scheme [15] to expose the policy
attributes step by step. In this way, the decrypter is able to
stop the decryption process as soon as it fails at one step.
But the price for this ability is that one additional attribute,
which is the one that fails the decrypter, is exposed. Besides,
this approach does not support OR-gates which limits the
flexibility of the policy.
C. Ontologies
To accurately and efficiently manage attributes in ICN
environment, we adopt ontologies for synchronizing the distributed attribute authorities. Ontologies are a way to share
knowledge between different components of a system, such
as two programs that work on similar data. They are a form
of agreement or a contract between all such components

392

2014 IEEE Conference on Communications and Network Security

regarding the "meaning" of the concepts and data that they
work with. We use ontologies to define the structure and
schema for the attributes that would be used in the ABE
scheme.
The standard form of defining an ontology is the Web
Ontology Language (OWL) [16] which is based on the Resource Description Framework (RDF) and defines an XML
based syntax for specifying all the different aspects of the
ontology. We can query OWL ontologies using the SPARQL
language [17] that takes into account the ontology structure
while executing.

physicians and nurses working at hospital A, the policy can
be {A} AN D {{P hysician} OR {N urse}}.
After creating the policy, the owner generates a random data
encrypting key and uses it to encrypt the file. The encryption
result is set as the data part of the content item. The metadata includes public parameters to decrypt the data and data
integrity related information. Then the owner creates a name
for the content. He uses the proposed scheme to encrypt the
random key under the policy he has specified. The result is
used as the content name.

III. S YSTEM AND M ODELS

Random Data
Enrypting Key

In this section, we present a basic medical ICN framework,
the attribute-based naming and access control model, and the
attack model.

Access
Policy

A. A Medical ICN Framework Model

MRI

Attributes:
* Hospital A
* Physician
* Cardiologist

Attributes:
* ID=x
* Hospital A

Patient
(content owner)

Trusted Third Party

Neurology
Cardiology
Oncology

Objects

Attributes:
* Hospital A
* Nurse (senior)

Medical ICN Network
Content
* Distribution
* Search
* Retrieve

MRI
Report
of
Patient
x

Name
Publishing

Report
of
Patient x

Name
Searching

MRI
Report
of
Patient
x

Name-based
Routing
MRI
Report
of
Patient
x

Content Cache
Servers

Name
DA
(Public)
ACA
(Private)

Encryption

Content
Name

Content

Metadata

Fig. 2: Creating a Content.
A consumer who needs this file can get the content by the
content name. Before he gets the content, he uses his assigned
attributes to decrypt the name. If his attributes satisfy the
hidden policy in the name, he can then get the random dataencrypting key protected in the name.

Attribute Management

Subjects

Naming
Scheme

2. Encrypt
Data

3. Create
Name

In a typical ICN system, there are three roles: content owner,
content consumer and content cache. As the example shown
in Figure 1, the content owner can be a Patient, a content
consumer can be a Nurse or a Physician, and the content
caches are content cache servers storing encyrpted contents.

Cardiology Cardiologist

1. Owner
Proposed
Define Policy

Data

Attributes:
* Hospital A
* Category:
Cardiology
* Type: Report
* Name: MRI
* Owner: Patient x

B. Attribute-based Naming and Access Control

* Patient x
* Report
* Hospital A
* Physician
* MRI
* Cardiology

Generate the name of the content

Fig. 1: Basic ICN System Model.
In an ICN network, users get content names from a Name
Searching service (NSS) and use the names to get the content
through a Name-based Routing (NR) system. Additionally,
our model includes a Trusted Third Party (TTP) that sets up
Attribute-Based Access Control (ABAC) and Attribute-Based
Encryption (ABE) related public parameters for the network,
and it also helps assign and manage attributes to entities.
In the proposed scheme, every network entity is associated
with a unique identifier (U ID) and a set of attributes. U ID
itself can be treated as a special attribute. Attributes (other than
U IDs) can be defined and managed by any entity in network.
This entity is denoted as the authority of an attribute.
Initially, the TTP sets up global parameters for the entire
network. Then, any entity in network can create attributes and
assign them to other entities. As the example shown in Figure
2, when an entity publishes a file, as the content owner, it
creates an access policy for the content. For example, if a
content owner wants to create a record accessible only to

Attributes in an ICN network can be categorized into subject
attributes and object attributes. As shown in Figure 1, attributes
in green are subject attributes while the red attributes are object
attributes of the report. When they are used in ICN, there
are some relations between the subject attributes and object
attributes. For example, {Cardiology} and {Cardiologist}
are a subject and an object attribute, respectively. They can be
treated as equal since a cardiologist always works on cardiology. Another example is {M RI}. As a useful tool, several
medical subjects may use MRI for diagnosis, such as neurology, cardiology, and oncology. To model such relationship, we
define {N eurology, Cardiology, Oncology} as sub-attributes
of {M RI}. The proposed ontology-based attribute management approach is to handle such attribute equivalence and attribute hierarchy relations. When a content owner publishes the
content, he decides which attributes are used for access control
and which are for content search and description. We denote
them as Access Control Attributes (ACAs) and Descriptive
Attributes (DAs), respectively. As in the example of Figure
1, {HospitalA, P hysician, M RI, Cardiology} are used as
ACAs. Thus, network entities can only see that this content is
a report of Patient x as the DAs are publicly search-able.
An Illustrative Example
In the example of Figure 1, there are three subjects: a
Nurse, a Physician, and a Patient. Their attributes are as shown

393

2014 IEEE Conference on Communications and Network Security

in the figure. The patient publishes his MRI report in the
network as the content. He, as the content owner, specifies
an access policy as shown in Figure 3 for the MRI report.
Its object attributes are listed in Figure 1. The content name
is created following the procedure in Figure 2. When the
nurse tries to access this content, she can successfully use her
{HospitalA} attribute to decrypt the first node but will gets
stuck at {P hysician}, meaning this content is not intended
for her. When the Physician accesses the content, she can
successfully decrypt the entire decryption process from the leaf
to the root level-by-level to reveal the random data encrypting
key. Here, {M RI} is substituted with {Cardiology} since
{Cardiology} is a sub-attribute. This is shown with the arrow
in Figure 3. Also, {Cardiology} equals to {Cardiologist}
in this case. Then, the Physician uses the NR system to get
the nearest copy of the content and uses the random data
encrypting key derived from the name to decrypt the MRI
report.
Random Data
Encrypting Key

Subject Attributes
Object Attributes
Subject/Object Shared Attributes

AND
Attribute Reveal Direction

Content Name
DA
* Patient x
(Public)
* Report
* Hospital A
* Physician
ACA
(Private) * MRI
* Cardiology

MRI

AND

Cardiology
AND

Physician

Hospital A

IV. ABE- BASED ICN NAMING S CHEME
We will illustrate our ABE-based naming scheme for ICN
network, which is based on our previous work [15, 18].
A. ABE-based Naming Scheme
Attributes of an entity can be any value in strings. In
our scheme, each attribute string Ai corresponds to a triplet
(Ti , Ii , ki ), Ii , ki ∈ Zp and Ti ∈ G0 , where Ti is assigned
by the TTP. An access policy can be expressed in Disjunctive
Normal Form (DNF) of attributes. The sequence of encrypting
a conjunctive clause (encryption sequence) is opposite to the
decryption sequence. We define a public attribute AP ub in the
scheme. Unlike other attributes, AP ub is associated with a pair
(TP ub , IP ub ). For each conjunctive clause, the encryptor adds
AP ub at the end of the encryption sequence.
In this scheme, a GlobalSetup algorithm is run by the TTP
to generate global parameters for the system. For each node
joining in the network, the TTP runs NodeJoin algorithm once
to generate a unique secret for the node. For each attribute,
the authority in charge runs an AuthoritySetup algorithm
to generate secrets associated with that attribute. Besides,
our naming scheme includes other three basic algorithms:
KeyGen, Encrypt, and Decrypt.
The GlobalSetup algorithm generates the global parameters {G0 , g, g β , e(g, g)α , Enck (·), Deck (·), (SP ub , TP ub ),
ROOT }, and global secrets {β, g α }, where α and β are
random values and Enck (·), Deck (·) are a pair of asymmetric
encryption algorithms. The NodeJoin algorithm are defined as
in Algorithm 1.
Algorithm 1 NodeJoin
1: For each node with U ID in network, generate a random number

Fig. 3: Creating a Content Name.

rU ID ∈ Zp ;

2: Calculate DU ID = g (α+rU ID )/β ;
3: Calculate:

C. Attack Model

r

XP ub,U ID = g rU ID TPPubub ,

In the following, we assume that the attackers have two
goals in compromising the ICN access control scheme: (1)
acquiring unauthorized privilege to the data; (2) retrieving
constitutional information of access policies to gain more
information about the content, the owner, and the consumers.
The information includes but is not limit to the identity of
the owner or consumers, the sensitivity of the content and
the potential value of data in the content. For the first goal,
the attackers have to break the confidentiality mechanism of
the protected data. Possible methods include collusion attacks
and vulnerability exploitation. For the second goal, attackers
need to analyze the proposed ABE-based scheme to identify
possible ways to reveal the policy.
D. Preliminaries of ABE
The foundation of ABE is bilinear pairing computation.
Assume two groups: an additive group G0 and a multiplicative
group G1 with a same large prime order p. Discrete Logarithm
Problem is difficult in both of them. We define a bilinear map
e : G0 × G0 → G1 [10].

YP ub = g rP ub ,
ZP ub,U ID = e(g, g)rU ID IP ub .
where rP ub ∈ Zp is a random number for each node;
4: Choose a random value PU ID ∈ Zp ;
5: Assign to the node {DU ID , XP ub,U ID , YP ub , ZP ub,U ID ,

PU ID }.

Each individual authority that manages an attribute Ai will
have to run AuthoritySetup to set up attribute secrets.
The KeyGen algorithm generates the private keys corresponding to each attribute for each node holding this attribute.
It is defined in Algorithm 2. When the node receives the keys
U ID
from the authority, it checks if LP
U ID = TP ub is true. If it’s
2
true, it updates PU ID with PU ID and accepts the keys. If not,
it will discard the keys.
The Encrypt algorithm works following the encryption
sequence of each clause, denote each attribute from I1 to Im ,
m is the number of attributes in the clause. Choose a random
value s ∈ Zp , set I0 = s and follow Algorithm 3.

394

2014 IEEE Conference on Communications and Network Security

Algorithm 2 KeyGen
passes U ID, Ii and Ti to TTP;
2: TTP computes and sends back to the authority:

Xi,U ID = g rU ID Tiri ,
Yi = g ri ,
Zi,U ID = e(g, g)rU ID Ii ,
1/P

LU ID = TP ubU ID .
where ri ∈ Zp is a random number;
3: The authority assigns Xi,U ID , Yi , Zi,U ID , and LU ID to the node

together with Ti , Ii and ki .

Algorithm 3 Encrypt
= Sk e(g, g)αs , C 0 = g βs and C 00 =
EncSk (ROOT );
2: For each attribute An , if a triplet (C1,n , C2,n , C3,n ) has already
been calculated, move to the next attribute An+1 and restart step
3 with An+1 ; else, goto step 4;
3: Choose a random number hn ∈ Zp ;
4: Calculate:
C1,n = g (In−1 −In )hn ,
1: Calculate C

(In−1 −In )hn

C2,n = Tn

C3,n = (kn hn )

−1

,

.

1 ≤ n ≤ m;

(I

m
5: Calculate C1,m+1 = g (Im −IP ub ) , C2,m+1 = TP ub

−SP ub )

.

The Decrypt algorithm works in the decryption sequence.
Note that the first attribute in decryption sequence is always
AP ub . The decrypter follows Algorithm 4.
Algorithm 4 Decrypt

Zn,U IDdec · e(Xn,U IDdec , (C1,n )kn C3,n )
e(Yn , (C2,n )kn C3,n )
= e(g, g)rU IDdec (In−1 ) ;
rU ID

(In−1 )

is the decrypter’s private key, go to step
2 with attribute An−1 ; else go to step 4;
4: Calculate
dec

V. O NTOLOGY- BASED ATTRIBUTE M ANAGEMENT
Using the proposed naming scheme, how to efficiently and
accurately manage the attributes is crucial. In this section, we
describe our ontology-based attribute management scheme that
can be used to manage attribute names and values of both
ACAs and DAs in a distributed manner suitable for the ICN
architecture.
In the ICN model (III-A), we aim to make sure that each
user can specify the access policy independently in a decentralized manner instead of placing the entire responsibility
In our design, the TTP specifies an Attribute Ontology that
defines the set of attributes that the users can use to define the
access policies for the content they publish over the network.
Our design uses the following approach that distinguishes it
from the current systems.
A. Attribute Equivalence

1: Start from the public attribute AP ub ;
2: For each attribute An that the decrypter possesses, compute:

3: If e(g, g)

Step-by-step attribute exposure for consumers to determine their eligibility efficiently in computation;
• Flexible attribute management.
Using this scheme, any entity who wants to publish data
needs to create the content following the process in Figure 2.
The owner firstly creates a random symmetric key K. Then
the data to be published is encrypted using K. The resulting
ciphertext C is then used to generate a metadata of C. Both the
metadata and C are parts of the final content. Then the owner
needs to specify an access policy P of attributes to define
what an authentic consumer should satisfy. Then the owner
uses this policy to encrypt K following Encrypt algorithm.
The result is used as the content name.
In this way, the owner does not need to know individual
public keys of all the potential consumers in advance as the
traditional methods would do.
•

1: For each attribute Ai assigned for node with U ID, the authority

Sk = C/(e(C 0 , D)/e(g, g)rU IDdec (In−1 ) .
if DecSk (C 00 ) == ROOT , Success; else Failure.

When Decrypt algorithm succeeds, Sk is the random data
encyrpting key embedded in C.
B. Apply ABE-based Naming Scheme in ICN
With the above Naming scheme, we can achieve the following capabilities:
• Specifying the access control policy without knowing the
consumers’ keys;
• Full preservation of the policy confidentiality from leaking to adversaries;

The main advantage of using Ontologies to define the
attributes is that it allows us to declare equivalent attributes.
For example, if we declare attributes (or properties) A and A’
as equivalent, some users can use the property name A for
defining their policy and others can use A’ for defining their
policy. The ontology ensures that both these properties map
to the same attribute. Equivalent properties can be specified in
an OWL document using the owl:equivalentProperty element.
We can define two attributes attribute1 and attribute2 as data
type properties. In any one of these attributes we can declare
the equivalence by adding the owl:equivalentProperty element
in the property definition [16]. Once the equivalent set of
attributes is defined, the users can use either of the attributes
from the set for sharing as well as accessing data since all
of them map to the same attribute. For example, if we have
equivalent attributes {F aculty} ≡ {T eacher} and they map
to a unique triplet, then this unique triplet can be used to
encrypt the data using the ABE based algorithm.
B. Attribute Hierarchy
Another advantage of using ontologies for defining attributes is we can define a hierarchy of attributes. One attribute

395

2014 IEEE Conference on Communications and Network Security

For comparison purpose, we test every operation for fifty
times and choose the average value as basics for our comparison. Results of our experiment (Table I) show that pairing
operation takes longer than any other operations. Therefore,
our comparison metric is set to be the number of pairing
operations in decryption process.
1000

C. Distributed Policy Specification
Since our design assumes multiple trusted attribute authorities, we need an initial negotiation between these authorities to
decide the structure of attributes and properties to be specified
in the attribute ontology. This [19] can be achieved with the
help of the TTP. Once this agreement is established, the users
can access this ontology from any of the attribute authorities
and design the access policy for their shared data. This policy
can then be translated to an equivalent ABE compatible form
to be used for encrypting the contents. This approach allows
the access policies to be generated in a distributed manner
by the users themselves and as long as these access policies
satisfy the established ontology, they can be used over the
entire network.
VI. P ERFORMANCE A NALYSIS AND E VALUATION

800
700
600
500
400
300
200
100
0

1

2

3

4

5

6
7
8
9 10
Number of Attributes

15

20

25

30

Fig. 4: Computation Performance

TABLE I: Different operations’ time-consumption (in milliseconds)
Operation
Time

A. Evaluation of the Naming Scheme
In this section, the ABE-based naming scheme is evaluated
from performance aspect. We analyze its computation consumption and communication (and storage) overhead.
From computation perspective, we tested the time consumption for key generation, encryption and decryption processes.
In real application, we are more concerned with the time
consumption for a consumer to decrypt the content’s name.
Therefore, we also compare the decryption overhead with
existing ABE solutions: CP-ABE [10], CN scheme [20], NYO
scheme (the 2nd construction in [14]) , YRL scheme [11] and
GIE scheme [15]. The idea is to compare the number of most
time-consuming operations needed in each scheme.
We use a machine with a four-core 2.80GHz processor and
4GB memory running Ubuntu 10.04 for experiment. A Type
A pairing with the help of PBC Library [21] is set up. We
test each operation ten times for key generation, encryption
and decryption (Figure 4). Here the policies are set to be a
conjunctive clause of different number (shown in x-axis) of
attributes. This is because given a number of attributes, this
form requires the most time for computation. The reason why
encryption consumes more time when attributes are fewer is
that the cost for computing C in Algorithm 3 requires an additional pairing computation which is independent to the number
of attributes. When few attributes are involved, this additional
pairing takes a high portion of the time consumption. This
portion reduces as the attribute numbers grow.

Decryption
Encryption
KeyGeneration

900
Time Consumption (milliseconds)

can be defined as a sub-attribute of another. For example,
in a hospital, a user can have the attribute {Employee}.
We can define an attribute {N urse} as a sub-attribute of
{Employee}. This means that a "Nurse" is also an "Employee" and he can have more properties than other "Employees". This is done by using the rdfs:subPropertyOf element in
the OWL specification [16]. The advantage is that if the access
policies specifies that all users having attribute {Employee}
can access a particular data, the attribute hierarchy specified
in the ontology will also allow a {N urse} to get it, but any
other "Employee" cannot access the data that requires the user
to be a "Nurse" to access it.

Pairing
4.561

Exponentiation
0.088

Multiplication
0.032

Inversion
0.036

Following the above-mentioned idea, we use Nattr to denote
the number of attributes a consumer has, Nall as the total
number of attributes defined in the network (Nall  Nattr ).
Since the policy is publicly known in CP-ABE and CN, decrypters are able to decide what attributes to use in decryption.
Therefore, for those who satisfy the policy, the time taken for
decryption is proportional to the number of attributes involved,
which is denoted as Ninvo , Ninvo 6 Nattr . It is obvious
that unauthentic decrypters would not bother to try decryption,
which is why it takes 0 in time. An unauthentic decrypter in
GIE and EA-ABE is not able to proceed with the decryption
process if it cannot meet the next attribute. In this situation, we
use Npart to denote the number of attributes that the consumer
has already decrypted, where Npart 6 Ninvo . The result of
our test is shown in Table II.
To evaluate the communication costs, we compare the size
of the name. In PBC library [21], a data structure element_t
with size of 8 bytes is used to represent an element. For
our scheme, we need 24 bytes to store the network name.
Compared with this name size, a content in CBCB [2] is
identified by a set of attributes determined by the content
owners. Thus, we can model the names as a human-readable
string of an undetermined size. NDN [6] shares a similar
problem with the name size. As mentioned before, DONA

396

2014 IEEE Conference on Communications and Network Security

TABLE II: Comparison of computation cost in decryption
Scheme
CP-ABE
CN
NYO
YRL
GIE
EA-ABE

Anonymity Support
No
No
Yes
Yes
Yes
Yes

Number of Pairings
2Ninvo + 1 or 0
Nall + 1 or 0
2Nattr + 1
2Nattr + 2
3Ninvo or 3Npart
2Ninvo + 1 or 2Npart

TABLE III: Comparison of ciphertext size
Scheme
CP-ABE
CN
NYO
YRL
GIE
EA-ABE

Ciphertext Size
1G1 + (2Nciph + 1)G0
1G1 + (Nall + 1)G0
> 1G1 + (2Nall + 1)G0
1G1 + (3Nall + 3)G0
Nciph G1 + 3Nciph G0
1G1 + (2Nciph + 4)G0 + Nciph Zp

[3], NetInf [4] and PURSUIT [5] share the same naming
scheme. Therefore, we only use the size of DONA’s name
for comparison. In [3], the size of the name is confined to 40
bytes in its protocol header. Thus, the network name size in
our scheme is small enough to fit in ICN usage.
B. Security Analysis
From the security perspective of the proposed solution, we
analyze the performance based on the attack model in III-C.
For the first attack goal, we will provide a security theorem
and give the security proof sketch as the appendix in this paper.
For the second goal, we will analyze the scheme based on the
algorithms.
Theorem 1: Let G0 and G1 defined as in IV. For any
adversary A, the advantage it can gain from the interaction
with the security game defined in Appendix A is negligible.
The proof for this theorem is provided in Appendix B. In
the proof, it is verified that the attacker cannot break the
encryption algorithm to get any data exposed. Furthermore,
it is also proved that the attackers cannot conduct collusion
attacks onto the system. This is because if the collusion attack
is feasible, the adversary in the security game can ignore
constrains that no single user can satisfy the policy and still get
the secret decrypted. Thus, making it gaining a non-negligible
advantage in this game.
For the second attack goal, the attacker will stop at the first
attribute it doesn’t own in the decryption process. If it can get
to know one additional attribute, it must get it from step 3 in
Algorithm 4. This means that this attacker possesses the secret
key Zi,U ID of the attribute, which contradicts the assumption
that it does not possess this attribute.
C. Evaluation of Ontology based Attribute Management
In this section we create an application scenario to demonstrate the effectiveness of ontology-based attribute manage-

ment.
In an ICN healthcare network, there are hospitals, clinics,
and medical institutions that share information and data. Each
institution defines its own users and attributes. A trusted
Attribute Authority (AA) is set for each institution to generate
the attributes for the users and assign them correctly when
users joined in the system. This AA will also generate the
private keys to be used for ABE operations by the users and
securely transfer them to the intended user(s). An institution
defines its own setup like the various departments (Pediatric,
Cardiology, etc), employees (Surgeon, Physician, Nurse, Staff,
etc), patients, etc. We assume that each institution will use its
own nomenclature so that the same department can have a
different name in different institutions. The users can have a
hierarchy among themselves, for example Nurse < Resident <
Consultant < Surgeon < Head of Department < Chief Medical
Officer.
1) Medical Records Transfer: Consider the case where a
patient is being transferred from one hospital to another for
better facilities or location preference. In this case, the medical
records of the patient need to be transferred from the first
hospital to the second one. Since these are highly sensitive
data, they are stored in an encrypted form (in our case the
encryption is ABE-based) and only medical personnel having
the required privileges can access and decrypt this data. Let TE
be the time taken to encrypt data and TD be the corresponding
time taken to decrypt it.
If no ontology has been specified by the two hospitals and
no attributes are shared among them, the attributes used to
encrypt the data by the first hospital would be invalid in the
second. Therefore the data would first have to be decrypted,
and then encrypted using the attributes defined in the second
hospital. If we also consider the initial encryption of the data,
it accounts for two encryptions and one decryption: Ttotal =
2*TE + TD .
Now if we consider using an ontology that maps the
attributes of one hospital to its equivalent attributes in another
hospital over the ICN network. Since the attributes are already
mapped, we don’t need to encrypt/decrypt the data again. Only
the initial encryption would be required to be performed in this
case: Ttotal = TE .
A comparison of the two cases is illustrated in Figure 5.
Considering that the encryption and decryption operations can
be computationally intensive, the performance gain by using
ontologies and ICN network is very significant.

2) Storage Overhead: When n institutions are sharing data
without using an ICN network, it results in n copies of the
data, one for each institution and encrypted using its own set
of attributes. With the use of ICN network in our design along
with ontology to specify relation between the attribute sets of
all the different institutions, we reduce this to a single copy of
the encrypted data. Since the attribute relations have already
been defined by the attribute ontology, any eligible user from
the various institutions can decrypt the encrypted data thereby

397

2014 IEEE Conference on Communications and Network Security

2500

Time Consumption (milliseconds)

With Ontology
Without Ontology

[6]

2000

1500

[7]

1000

500

[8]
0

1

2

3

4

5

6
7
8
9 10
Number of Attributes

11

12

13

14

Fig. 5: Time Consumption for Medical Records Transfer
[9]
removing the need for multiple copies. This is a huge saving
of the storage space on the network especially when many
different types of data is being shared. Such a saving also
makes our design much more scalable allowing more data to
be shared among different entities on the ICN network.
VII. C ONCLUSION

[10]

[11]

In this paper, we have proposed a novel access control
approach for ICN naming scheme. This scheme is based on
a new design of ABE-based algorithm and the content names
are protected based on attributes. We also proposed a new
ontology-based scheme for flexible attribute management with
significant performance gains in terms of time consumption
and storage costs. From security and privacy perspective, this
scheme achieves a high security level as CP-ABE but with
attribute anonymity guarantees of the policy. Experiments and
analysis confirm the effectiveness of our schemes and design.
ACKNOWLEDGEMENT

[12]

[13]

[14]

This research is supported by ONR Young Investigator
Program (award NO. N00014-10-1-0714) and ARO research
grant (award NO. W911NF-11-1-0191).
R EFERENCES

[15]

[1] Cisco, “Cisco visual networking index: forecast and
methodology, 2012-2017,” 2013.
[2] A. Carzaniga, M. Rutherford, and A. Wolf, “A routing
scheme for content-based networking,” in INFOCOM
2004.
[3] T. e. Koponen, “A data-oriented (and beyond) network
architecture,” in Proceedings of the conference on Applications, technologies, architectures, and protocols for
computer communications, 2007.
[4] C. Dannewitz, J. Golic, B. Ohlman, and B. Ahlgren, “Secure naming for a network of information,” in INFOCOM
2010.
[5] N. Fotiou, P. Nikander, D. Trossen, and G. Polyzos, “Developing information networking further: From psirp to
pursuit,” ser. Lecture Notes of the Institute for Computer

[16]

[17]
[18]

[19]

[20]

398

Sciences, Social Informatics and Telecommunications
Engineering, 2012.
V. Jacobson, D. K. Smetters, J. D. Thornton, M. F.
Plass, N. H. Briggs, and R. L. Braynard, “Networking
named content,” in Proceedings of the 5th international
conference on Emerging networking experiments and
technologies, 2009.
I. Psaras, W. K. Chai, and G. Pavlou, “Probabilistic innetwork caching for information-centric networks,” in
Proceedings of the second edition of the ICN workshop
on Information-centric networking, 2012.
N. Fotiou, G. F. Marias, and G. C. Polyzos, “Access
control enforcement delegation for information-centric
networking architectures,” in Proceedings of the second
edition of the ICN workshop on Information-centric
networking, 2012.
S. Singh, “A trust based approach for secure access
control in information centric network,” International
Journal of Information and Network Security (IJINS),
2012.
J. Bethencourt, A. Sahai, and B. Waters, “Ciphertextpolicy attribute-based encryption,” in Proceedings of the
IEEE Symposium on Security and Privacy, 2007.
S. Yu, K. Ren, and W. Lou, “Attribute-based on-demand
multicast group setup with membership anonymity,” in
Proceedings of the 4th international conference on Security and privacy in communication netowrks, 2008.
A. Lewko and B. Waters, “Decentralizing attributebased encryption,” in Proceedings of the 30th Annual
international conference on Theory and applications of
cryptographic techniques: advances in cryptology, 2011.
S. Arianfar, T. Koponen, B. Raghavan, and S. Shenker,
“On preserving privacy in content-oriented networks,”
in Proceedings of the ACM SIGCOMM workshop on
Information-centric networking, 2011.
T. Nishide, K. Yoneyama, and K. Ohta, “Attribute-based
encryption with partially hidden encryptor-specified access structures,” in Proceedings of the 6th international
conference on Applied cryptography and network security, 2008.
D. Huang, Z. Zhou, and Z. Yan, “Gradual identity exposure using attribute-based encryption,” in Social Computing (SocialCom), IEEE Second International Conference
on, 2010.
S. Bechhofer, F. v. Harmelen, J. Hendler, I. Horrocks,
D. L. McGuinness, P. F. Patel-Schneider, and L. A. Stein.
(2004) Owl web ontology language reference.
(2008) Sparql query language for rdf. [Online].
Available: http://www.w3.org/TR/rdf-sparql-query/
B. Li, Z. Wang, and D. Huang, “An efficient and anonymous attribute-based group setup scheme,” in Proceedings of GLOBECOM, 2013.
P. Ashwin. (2014) Ontology based attribute management
for abac. [Online]. Available: http://ontology-ABAC.
mobicloud.asu.edu
L. Cheung and C. Newport, “Provably secure ciphertext

2014 IEEE Conference on Communications and Network Security

TABLE IV: Query information accessible to the adversary

policy abe,” in Proceedings of the 14th ACM conference
on Computer and communications security, 2007.
[21] B. Lynn, “Pbc library the pairing-based cryptography library,” in http://crypto.stanford.edu/pbc/, Accessed
March 2014.
A PPENDIX
A. ABE Security Model
In the following, we introduce a game between a challenger and an adversary, where the challenger simulates the
operations of the TTP and the attribute authorities while the
adversary plays the role of a user. There are five steps in this
game:
Setup. The challenger executes the GlobalSetup algorithm
and feeds back to the adversary the global parameters.
Phase 1. The adversary asks for a number of user keys from
the challenger. The challenger runs the NodeJoin algorithm for
the requests and returns the secrets. The adversary then and
the KeyGen algorithm to generate keys.
Challenge. The adversary provides an access policy A to
the challenger. A satisfies that none of the users it created
satisfies A. The challenger flips a coin b and produces the
ciphertext C using A as:

e(g, g)αs
if b = 1
C=
e(g, g)θ
if b = 0
The challenger sends the ciphertext to the adversary;
Phase 2. The adversary creates more attributes and users
from the challenger. But if any single user satisfiesA, the
challenger aborts the game.
Guess. The adversary makes a guess b’ for the real value
of b.
The adversary’s advantage in this game is ADV = P [b0 =
b]− 12 . The proposed scheme is secure if for all the adversaries,
the advantage is at most negligible in the game.
B. Security Proof Sketch
We provide the sketch for security proof following the
steps in [10]. We will show that no polynomial adversary can
distinguish between e(g, g)αs and e(g, g)θ in the game.
We use a simulator to model the security game between the
challenger and the adversary. It encodes any member in G0
and G1 to a random string following two mappings: f0 , f1 :
Zp → {0, 1}dlog pe . Another mapping f2 can convert elements
in Zp to string representations: f2 : Zp → {0, 1}dlog pe .
Setup. The simulator defines the global parameters and
secrets.
Phase 1. When the adversary runs NodeJoin for a new
user with U ID, the simulator generates a random number
rU ID ∈ Zp . It returns to the adversary with DU ID =
f0 ((α + rU ID )/β), XP ub,U ID = f0 (rU ID )f0 (λrP ub,U ID ) =
f0 (rU ID + λrP ub,U ID ), YP ub = f0 (rP ub ), and ZP ub,U ID =
f1 (rU ID IP ub ), here rP ub,U ID ∈ Zp is a random number. For
each attribute key request made from the adversary, the simulator computes Xi,U ID = g rU ID Tiri = f0 (rU ID + ti ri ), Yi =
g ri = f0 (ri ), and Zi,U ID = e(g, g)rU ID Ii = f1 (rU ID Ii ),

λ
rU ID + λrP ub,U ID
rU ID + ti ri
tn (In−1 − In )hn

β
rP ub
ri
(In−1 − In )hn

(α + rU ID )/β
ti
βs

α

rU ID IP ub

rU ID Ii

IP ub
(kn tn )−1

Ii

ki

where ri is a random number chosen from Zp . The simulator
passes all these values to the adversary as the attribute keys.
Challenge. When the adversary asks for a challenge, the
simulator flips a coin b and chooses a random value s ∈ Zp .
If b = 1, the simulator calculates C = f1 (αs); if b = 0, it
picks a random value s0 ∈ Zp and calculates C = f1 (s0 ). It
also computes other components of the ciphertext following
Encrypt.
Phase 2. The simulator interacts with the adversary similar
as in Phase 1 with the exception that the adversary could
not acquire attribute keys enabling a single user to satisfy the
access policy A.
Now we argue that the adversary’s views are identically
distributed between the two cases when C = f1 (αs)(b =
1) and when C = f1 (s0 )(b = 0). In fact, additive terms.
Then we have: ν1 − ν2 = γαs − γ 0 s0 , where γ is a constant.
Thus, we have ν1 − ν2 + γ 0 s0 = γαs. This implies that by
constructing a query ν1 − ν2 + γ 0 s0 , the adversary may get the
value for e(g, g)γαs . Now we prove that such query cannot be
constructed by the adversary.
In fact, the information that an adversary can acquire from
this game can be listed as in Table IV. The only way to obtain a
value containing αs is to pair βs and (α+rU ID )/β to get αs+
rU ID s in G1 . Then, by conducting theP
query in Phase 1, the
adversary can get a polynomial γαs + U ID∈Uquery γrU ID s,
where Uquery is the set of UIDs used by the adversary. The
adversary can use items in the table containing In−1 − In and
rU ID . But this is impossible for the adversary under the game
assumption because:
Firstly, the adversary can’t reconstruct s from either
tn (In−1 − In )hn or (In−1 − In )hn since the hn s are chosen
as random values for each attribute.
Secondly, the adversary can’t reconstruct s from IP ub and
Ii in Zp as no single user can satisfy the attribute policy.
Therefore, the attacker could not differentiate a random
ciphertext from an authentic one. The security of the proposed
scheme is proved. 

399

2015 IEEE International Conference on Mobile Services

POEM: On Establishing A Personal On-demand Execution Environment for Mobile
Cloud Applications
Huijun Wu, Dijiang Huang
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University
{Huijun.Wu, Dijiang.Huang}@asu.edu

Min Chen
School of Computer Science and Technology
Huazhong University of Science and Technology
minchen@ieee.org

	

	



Abstract—A distributed mobile cloud service model called
“POEM” is presented to manage the mobile cloud resource
and compose mobile cloud applications. POEM provides the
following salient features: (a) it considers resource management
not only between mobile devices and clouds, but also among
mobile devices; (b) it utilizes the entire mobile cloud system as
the mobile application running platform, and as a result, the
mobile cloud application development is significantly simplified
and enriched; and (c) it addresses the interoperability issues
among mobile devices and cloud resource providers to allow
mobile cloud applications running cross various cloud virtual
machines and mobile devices. The proposed POEM solution
is demonstrated by using OSGi and XMPP techniques. Our
performance evaluations demonstrate that POEM provides a
true elastic application running environment for mobile cloud
computing.


























''(

''(





''(


 
!	


"##	$
%

$
%

&










)
	
*


Keywords-mobile cloud computing; offloading; service oriented architecture; OSGi; XMPP

Figure 1.

Overview of POEM.

I. I NTRODUCTION
etc.), is difﬁcult due to the mobility of mobile users. The
second challenge is that knowing the available PFs on each
mobile device is not a trivial task. Currently, there is no
such a common framework allowing mobile devices for
exchanging the available PFs information and running such
a system in a distributed environment. The third challenge
is to compose PFs crossing various hardware and software
platforms, which demands a universal programming and
application running environment with little compatibility
issues.
To address these challenges, we present a new mobile cloud application running system, which is called
POEM (Personal On-demand execution Environment for
Mobilecloud computing), as shown in Figure 1. POEM
treats each mobile device as a PF provider. In addition,
POEM is designed based on the mobile cloud framework,
where a dedicated Virtual Machine (VM) is assigned to each
mobile device providing computing and storage support.
Moreover, PFs can be ofﬂoaded/migrated from a mobile
device to its assigned VM. Thus, the VM can not only
run mobile devices’ PFs (i.e., as shadows), but also can
it run extended PFs that mobile devices may not have the
capacity to execute. Thus, we also call the VM in the

An ideal mobile cloud application running system should
enable mobile devices to easily discover and compose
cloud resources for its applications. From mobile resource
providers’ perspectives, they may not even know what applications are using their resources and who may call their provisioned functions beforehand. In this way, the mobile application design should not be application-oriented; instead,
it should be functionality-oriented (or service-oriented). For
example, the video function of a mobile device should
provide general calling interfaces that can be called by
multiple local or remote functions in the runtime. To achieve
this feature, we can consider these Provisioning Functions
(PFs) as the fundamental application components in the
mobile cloud, which can be composed by mobile cloud
service requesters in realtime. As a result, mobile cloud
can signiﬁcantly reduce the mobile application development
overhead and greatly improve the agility and ﬂexibility to
build a personalized mobile cloud computing system that
can be customized for each mobile user.
There are several challenges in current mobile cloud
application scenarios. The ﬁrst challenge is that knowing
the status of mobile devices, e.g., online/ofﬂine and runtime
information (such as battery, computing power, connectivity,
978-1-4673-7284-8/15 $31.00 © 2015 IEEE
DOI 10.1109/MS.2015.16

41

POEM framework as ESSI (Extended Semi-Shadow Image).
Collectively, the PFs provided by a mobile device X and
its corresponding ESSIX is denoted as {P F }X . POEM
regards mobile devices and their dedicated ESSIs both as PF
providers. As a result, the mobile user’s applications can be
composed by PFs from local PFs (may be ofﬂoaded/migrated
to its dedicated ESSI) and/or remote PFs (may run on remote
mobile devices or their dedicated ESSIs).
To demonstrate the proposed POEM solutions, we implemented a pilot POEM system based on OSGi [1] and
XMPP [2] techniques. In summary, the contributions of the
presented research is highlighted as follows:
• Social mobile cloud computing: POEM solution enables mobile cloud application to utilize social network
power, i.e., in addition to the discovered PFs through
the mobile cloud system, mobile user can establish
mobile cloud applications through their trusted social
connections. In this way, POEM applications not only
can use the resource in cloud by ofﬂoading resource
intensive components but also can use services provided
from their social connections.
• Versatile and personalized application offloading, migration, and composition: POEM maintains available
mobile cloud resource and allows users choosing a
mobile cloud application by using different approaches (ofﬂoading, migration, and composition) based on
the available system resources and their personalized
application requirements.
The paper is organized as follow. Section II introduces
related work. Section III describes systems and models. Sections IV and V discuss POEM design and implementation,
respectively. Section VI presents evaluation results. Finally,
Section VII concludes the paper.

POEM
manager

2 discover

2 discover

a

POEM 1 publish
manager
b
b

POEM framework

POEM framework

(a) PF publishing and discovery.
POEM
manager
2 respond

1 request
c

1 request
2 respond

POEM 1 request
manager
d
2 respond

POEM framework

POEM framework

(b) PF composition.

1 migrate

POEM
manager

1 migrate

e

POEM 1 migrate
manager
e

POEM framework

POEM framework

(c) PF ofﬂoading.
Figure 2.

POEM functionalities.

Zhang et al. model restricts application structure to User
Interface (UI), weblet and manifest, which force application
components to communicate through web service. MAUI [8]
and ThinkAir [9] use similar ofﬂoading technique and both
have their own decision making algorithms. They require
the programmer to mark the ofﬂoadable method and they
generate two versions of an application: one is for mobile
execution and the other is for cloud. Cuckoo [10] focuses
on ofﬂoading technique. Cuckoo generates local and remote
version of an Android Service component, which is similar
to MAUI and ThinkAir. Cuckoo requires programmer support to build the ﬁnal application and it’s ofﬂoading decision
making algorithm is static.

II. R ELATED W ORK
Most of the previous research focuses either on mobile
tasks partition and composition or on ofﬂoading techniques.
μCloud [3] describes a framework for mobile cloud application composition from heterogeneous software components.
μCloud is a static mobile cloud application model, which requires a lot of work for programmers to partition application
and decides which partition runs on which part of the cloud.
eXCloud [4] focuses on ofﬂoading and migration: it migrates
Java Virtual Machine (JVM) runtime to cloud. However it
migrates only the top portion of runtime stack, rather than
the whole virtual machine, to cloud using Stack On Demand
(SOD) [5] migration technique. CloneCloud [6] maintains a
clone of mobile device in the cloud. CloneCloud can deal
with dynamic ofﬂoading, however it requires synchronization between mobile device and cloud, which is not always
satisﬁed in mobile cloud application scenario due to unstable
mobile connection to cloud. Zhang et al. [7] proposed a
web based mobile cloud application model. It deﬁnes weblet
as independent compute unit that provides web service.

III. S YSTEMS

AND

M ODELS

We propose three fundamental POEM functionalities, as
shown in Figure 2. There are two POEM frameworks running on two devices or machines. Each POEM framework
has an identity so that they can form friendship relation, and
the PFs on the framework can beneﬁt from this friendship
relation in the service discovery procedure. The items a to
e present PFs.
The Figure 2(a) describes how one PF discovers remote
available PFs. PF b hosts a service and it publishes the
service through local POEM for remote PF to discover. Then
PF a can discover the published service on remote side with
local POEM PF’s help. One prerequisite for a to discover

42

"#$$

!

!















	

$



a systematic decision model, POEM initiates the migration
operations for PF ofﬂoading. In the following sections, we
describe each component within the POEM framework.

	



A. Distributed POEM Service Platform
POEM’s networking and signaling system is deployed
based on XMPP approaches. The communication between
POEM entities (i.e., mobile devices and ESSIs) is full
duplex compared to half duplex HTTP approach deployed
by many web-based service frameworks. In a distributed
execution environment, any entity can be both a client and
a server at the same time, which is different from webbased service models where clients and servers are explicitly
deﬁned. Moreover, POEM inherits the XMPP trust and
identity management framework, where every POEM entity
is authenticated when joining the system and data transferred
are also protected through cryptographic approaches. As a
result, the PF ofﬂoading and PF compositions can utilize
the XMPP trust management framework with ﬁne-grained
access control capabilities. Furthermore, POEM entities need
to provide their presence information to indicate its availability information in real-time, which is as well used to
indicate their service status.
1) POEM Service Discovery and Publishing: POEM service discovery is designed based on XMPP service discovery
protocol[11] and XMPP publish-subscribe extension[12]. A
PF may reside on a mobile device or its corresponding ESSI.
The ESSI takes the responsibility to represent the mobile
user for any PF related operations and the mobile device
POEM Manager can frequently update its available PFs
information to the ESSI. In this way, the main POEM service
discovery, migration, and composition operations will not be
ﬂooded to end mobile devices. The ESSI POEM Manager
also maintains the mobile device availability information and
provides its reachability information to its trusted POEM
peers. When the ESSI POEM Manager receives the service
discovery message, it replies with its available PFs with the
available remote service interfaces.
POEM Manager also monitors local service changes and
notiﬁes its friends. This is done through a publishing procedure. POEM Manager ﬁrst registers a publish node (i.e.,
a virtual node in the XMPP server) under its JID. Thus,
when local service status changes, POEM Manager can post
the notice on its publish node and its friends get notiﬁed
and update their PFs availability database. We note that this
concept can be extended to the scenario for POEM users
are not on each others friend list. POEM can create interest
groups for who have registered and receive notices published
in the corresponding interest group.
2) POEM Service Composition: When POEM discovers
service provided by remote POEM entities, it tries to create
a proxy for that service so that remote PF can be used
locally. POEM uses Java dynamic proxy technique to create
proxy. Dynamic proxy requires that the target interface’s



"#$%


Figure 3.

POEM components.

and use service of b is that they are mutual friends, in other
words they in each other’s contact list. PF a does not know
that PF b is running on remote side because POEM pretends
that b is running locally. Thus, a programmer does not need
special treatments in coding when developing PF a.
The Figure 2(b) presents how an application recruit a
service provided by a remote PF. The PF c sends method
invocation parameters, which are transferred by the POEM
on local side and then on remote side, to the destination PF
d. Then, the service result returns along the reverse route
from d back to c. PF c also regards it is calling a local target
d due to POEM transparent transfer, and d also thinks local
c is calling it.
The Figure 2(c) presents how one PF migrates to a remote
entity. A POEM PF initializes the migration process. There
are two types of migrations: pull and push. In pull migration,
the POEM PF on the right side sends request to left side
POEM PF, and then the later fetches and transfers the target
PF e to the right side. In push migration, the POEM PF on
the left side transfers PF e to the remote side. The source
keeps the PF e active during transfer to provide the failsafe
when the transferring is not successful.
IV. POEM D ESIGN
POEM is designed for a distributed application running platform and provides service publish, discovery and
composition as a uniform execution environment. In this
environment, transparent and seamless PF migration is the
key POEM function, i.e., mobile users will not notice the
platform level operations when running POEM supported
applications.
Figure 3 illustrates the overall design of POEM system.
The POEM Manager monitors local services, tracks service
state change, maintains local PF repository and responds to
remote service queries. Its networking component also maintains XMPP connections to XMPP peers that provides the
communication and signaling infrastructure among mobile
devices and their ESSIs. The POEM composition component
creates local proxy for remote service provider that responds
to service request by transferring the request to the remote
PF, and then getting the result to the local PFs. Based on

43

framework and cease the potential attack from the migrated
PF.
The POEM manager initializes a separate PF container for
each friend who wants to ofﬂoad his PF. The PF container
is duplication of the surrogate host POEM framework. The
only difference is that this nested PF container is empty and
dedicate for the corresponding friend. The friend identity is
stored and managed by identity manager. The surrogate host
deﬁnes the accepted PF policies that are enforced by policy
manager.
3) Connection Failsafe: The connection between mobile
device and cloud is usually not stable as mobile device
moves. When the connection is lost, POEM Manager restarts
the PF that has been stopped in ofﬂoading process. The
recovery process has the following two steps: First, the target
PF is started. Then, the proxy service is unregistered and
the proxy object is destroyed. The ﬁrst step prepares for
receiving service request. The second step destroys proxy,
which makes the target service provider object be the ﬁrst
in the ranking order to receive service request.

Class instance must exist. To have remote service interface’s
Class instance in local OSGi framework instance, POEM
fetches PF JAR ﬁle corresponding to the target service from
remote POEM framework. POEM Manager installs the PF,
and then the target Class instance is available and proxy
generation is done.
POEM uses JavaScript Object Notation (JSON) over
XMPP for service composition because JSON is lightweight
and has abundant expression ability. The service proxy
generated by POEM Manager captures local service requests
that are then converted into JSON requests. Then the JSON
request is sent to XMPP channel to the destination. The
destination POEM Manager receives the JSON request and
translates it to method invocation on service provider’s
object. It then returns the result in form of JSON back to the
source POEM Manager. Then the JSON response is decoded
and returned to calling object.
B. PF Offloading
When application decides to ofﬂoad a service provider
object and migrate it to cloud, POEM Manager chooses to
send the object’s byte code to cloud and start the object
from byte code. How to choose POEM PFs to be migration
is based on several conditions described as follows: First,
thread migration solution is not adopted because some
objects that exist in the same thread have to run on mobile device, such as user interfaces and sensors. Second,
an application usually wants to migrate only the compute
intensive operations rather than the whole thread. Third,
object state is not maintained because the insight private
details of the object to be migrated cannot be fetched due
to Java security management. Our recent practice suggests
that service implementation should be stateless, so that the
object states will not bother POEM like Representational
State Transfer (REST) does [13].
1) Migration: The service provider object ofﬂoading
process follows a three-step approach: First, the target PF
JAR ﬁle is transferred to ESSI and started. Then, a proxy
object is created to intercept and capture service request
to remote target service. Finally, the PF containing target
service provider object is stopped.
The migration happens according to the migration decision module command. POEM constructs the migration
decision module as plug-in framework. User can develop the
migration decision strategy plug-ins and install the strategy
bundle into POEM, which not only provides the ﬂexibility
for user customized migration strategy but also scales the
POEM intelligence.
2) PF Isolation: The migrated PFs are running in the
surrogate POEM framework for providing service for its
origination. These PFs may interact with the POEM framework and interrupt the PFs that belong to surrogate host.
The PF isolation is required to protect the surrogate POEM

V. POEM I MPLEMENTATION
This section describes the implementation details of the
POEM Manager OSGi bundle as well as the seamless
ofﬂoading procedure.
A. POEM Manager OSGi Bundle Implementation
POEM Manager consists of several objects as shown
in Figure 4. They are categorized as three sets - XMPP
connection and related listeners, PF context and related
listeners, and proxy and migration management. The three
object sets represent three POEM functional sets: XMPP
connection set represents remote POEM framework; PF
context set represents local POEM framework; and proxy
and migration management represent core POEM logic and
operation that connect the other two parts.
XMPP connection object maintains three XMPP managers
that manage service discovery, publish-subscribe, and ﬁle
transfer separately. Besides, it also maintains a roster that
publishes local presence and a publish node that local
service change notiﬁcation is posted on. There is a set
of listeners registered with XMPP connection. They are
noticed when corresponding events occur. Roster listener
tracks friends’ presence and update proxy pool accordingly.
Item event listeners, one listener for one friend, wait for
friends’ service change notice and update proxy pool accordingly. Connection listener monitors connection status and
executes robustness strategy. File transfer listener handles
ﬁle transferring. Packet listeners handle iq packets deﬁned in
POEM name space between POEM PFs. Service discovery
provider responses to remote service discovery by querying
PF context.
Other POEM components are as follows: PF context
handles interaction to POEM framework. Service listener

44

	





 
"







"



	









!



&

&

&


 




+



'


'


'

















 !"













#
 !"







 !"



 



!











 !*






































	


































 !"



	



	



 






 








Figure 5.
Figure 4.

POEM Migration Sequence

POEM Manager Details

provided by the ESSI. The sequence diagram of migration
process is shown in Figure 5.
Besides device 1 and the ESSI, a third framework instance
on device 2 is using the service being migrated. When
POEM Manager in the ESSI signals the new service, POEM
Manager on device 2 creates proxy for the new service with
a higher ranking as device 1 does. When POEM Manager
in the ESSI signals the service recycling, POEM Manager
on device 2 recycles the proxy for that service.

monitors local service change and publish change to publish
node maintained by XMPP connection. Proxy management
contains a database and a proxy pool. It memorizes remote
service status and local proxy status in database, and provides proxy generation and recycling methods. Migration
management implements migration service registered by
POEM Manager. PF repository provides JAR ﬁle source for
ﬁle transfer request.
B. Seamless Offloading

VI. P ERFORMANCE E VALUATION

POEM Manager registers a service with an Java interface
that contains a method to do service migration. Service
migration involves two framework instances that are source
framework and destination framework. The ofﬂoading process can be illustrated using the following application scenario. The source is device 1 and the destination is an ESSI.
The migration method is called on device 1. Service name
and destination XMPP identity are passed to the migration
method. The migration process consists of ﬁve steps as
follow. First, a migration notice is sent by device 1 to the
ESSI. Along with the migration notice, the PF JAR ﬁle that
owns the indicated service is transferred from device 1 to
the ESSI. Second, POEM Manager in the ESSI starts the PF.
When PF is running, services including the indicated service
are registered. Third, POEM Manager in the ESSI is notiﬁed
with service changes in last step. it unregister existing proxy
under the same service name. Then it publishes the new
services to the ESSI’s publish node. At this point, both sides
have the running PF that provides services to local PFs.
Fourth, POEM Manager on device 1 is notiﬁed due to the
publishing in last step. it creates the proxy for the published
services with a higher ranking. Then it stops the local PF.
At this point, the PFs on device 1 are consuming services

This section describes POEM performance evaluation and
case study.
A. Methodology
The POEM Manager is implemented on Felix [14] OSGi implementation version 4.0.3. Mobile application that
contains a Felix OSGi framework instance that hosts POEM Manager runs on Android Motorola phone A855. The
phone’s parameters are 600MHz CPU and 256M memory.
The Android version is 2.2.3. The virtual machine is with
1GHZ CPU and 512M memory, which runs Ubuntu 11.10.
Four applications are used to evaluate the POEM performance. They are Fibonacci sequence generator, N-Queens
puzzle, nested loop and permutation generator. The Fibonacci application generates Fibonacci sequence in a recursive
manner. Its time complexity is O(2n ) and its stack usage is
high due to recursive algorithm. The N-Queens application
calculates all solutions for input chessboard size. Its time
complexity is O(n2 ) and its stack usage is also high due to
recursive algorithm. The nested loop application contains
a six layer loop which leads to time complexity O(n6 ).
The permutation application’s time complexity is O(n!) and
uses little memory. Experiment result is obtained by running

45

Table I
M AX SPEED UP

Case

Fibonacci

N-Queens

Nested loop

Permutation

Input
26
27
28
29
30
8
9
10
11
12
14
15
16
17
18
5
6
7
8
9

Phone
(ms)
59.25
99.5
156.75
251
408.25
11
39.75
222.75
1593.5
9630.25
157
332
276.75
392.5
560.25
1.25
1
6.5
49.25
1124.75

Cloud
(ms)
2
3.05
5
7.65
12
1.1
3.05
12.2
64.4
377.2
15.05
21.55
28.6
39.85
54.35
0.25
0.25
0.4
2.05
12.1

time of N-Queens application. The execution time on phone
rises dramatically as the chessboard size increases one scale.
Ofﬂoading offers beneﬁt after chess size is larger than 10.
Nested loop application takes loop times and execute loop
without memory operation. The execution time on phone
is convex, which means it is less than exponential increase
compared to the above two applications that requires both
computing and storage. The execution time of ofﬂoading
increases slowly. The Permutation application takes a max
number N and returns count of prime number within the
range (1,N). The prime number searching algorithm used
is Permutation algorithm. The execution time increases on
phone, however the execution time for ofﬂoading approach
almost remains same.
The ofﬂoading line of four applications is increasing
slowly compared to phone line. As the phone line starts
from a low point, which indicates the application runs fast
when input is small, the ofﬂoading line and phone line
intersects ﬁnally. Comparing ofﬂoading line and the ESSI
execution time column in Table I, the slow increase is
reasonable due to execution time increase slowing in the
ESSI as well. Besides, the starting point of ofﬂoading line
is higher than phone line, so there must be cost for remote
method invocation.

Max speed
up (ms)
57.25
96.45
151.75
243.35
396.25
9.9
36.7
210.55
1529.1
9253.05
141.95
310.45
248.15
352.65
505.9
1
0.75
6.1
47.2
1114.65

the application 50 times for every scenario and averaged.
Between two consecutive executions there is a pause of 1
second.
The experiments are run under two scenarios:
• Phone: Applications are run only in phone.
• WiFi: Phone is connected to the ESSI through WiFi.
The WiFi connection has averaged latency of 70 ms, download bandwidth of 7 Mbps, and upload bandwidth of 0.9
Mbps. Ping is used to report the average latency from the
phone to the ESSI, and Xtremelabs Speedtest, downloaded
from Android market, is used to measure download and
upload bandwidth.

C. Micro-benchmarks
This experiment measures service invocation time. This
time is measured on phone where is service consumer
side. The remote service consuming time consists of three
parts: marshaling time of both consumer and provider sides,
network transfer time and actual execution time. The result
is shown in Figure 7.
Figure 7 shows time against different input parameters.
From the table, the actual execution time is similar to the
execution in the ESSI of column the ESSI in table I. At
the beginning, execution time is nearly zero. The execution
time increases along with input parameter value increases.
Figure 7 shows that marshaling time is relatively small
compared to network delay. Figure 7 also shows that the
main cost for remote method invocation is network delay
around BIV point. And marshaling time and network time
against different input parameters are approximately identical. The marshaling and network cost decides the start points
of ofﬂoading line in Figures 6(a)-6(d). And execution time
decides the trend of those ofﬂoading line. If the network
delay or the marshaling is reduced in some situation, the
ofﬂoading line will drop and then BIV point will go to left,
which means the range of beneﬁt increase and application
components are supposed to be ofﬂoaded to the ESSI. In
another perspective, if component’s ratio of computation
cost to network cost increases, it is better to ofﬂoad that
component to the ESSI.
Besides service invocation time, the proxy generation
time is also measured. The proxy generation time indicates

B. Macro-benchmarks
For typical input parameter values, four applications are
run on phone and in the ESSI separately. The application
running time is recorded in Table I. By subtracting time on
phone and in the ESSI, the max speed up is put in the last
column of the table. However, the max speed up is seldom
achieved due to cost of communication and proxy. This cost
changes little while ofﬂoading beneﬁt changes much, so
there should be some point when the beneﬁt of ofﬂoading
surpasses its cost giving application net gain.
Fibonacci application takes a sequence index number
and calculates the corresponding number in the Fibonacci
sequence. Figure 6(a) shows execution time of Fibonacci
application. The intersection of execution time on phone
and WiFi ofﬂoading is the Boundary input value (BIV) [9]
that shows the ofﬂoading beneﬁt starting point. N-Queens
application takes chess board size and calculates all solutions
and return solution number. Figure 6(b) shows execution

46

(a) Execution time of Fibonacci application.

(b) Execution time of N-Queens application.

(c) Execution time of nested loop application.

(d) Execution time of Permutation application.

Figure 6.

Execution time.

(a) invocation time of Fibonacci application.

(b) invocation time of N-Queens application.

(c) invocation time of nested loop application.

(d) invocation time of Permutation application.

Figure 7.

Service invocation time

POEM initialization time, which is paid once at starting
POEM Manager.

issued and ends when proxy for migrated service is available.
The result is in table II which shows that the migration
time is nearly same for the tested four applications. This
is reasonable because the migration time is mainly the time
of transferring PF bundles on the network and these four PF
bundle sizes are similar.

D. PF Migration
This experiment measures PF migration time. PF migration time period starts when service migration command is

47

R EFERENCES

Table II
S ERVICE M IGRATION T IME
Cases
Fibonacci
N-Queens
Nested loop
Permutation

[1] OSGi Core Release 5, OSGi Alliance, March 2012, http://
www.osgi.org/Release5/HomePage.

migration time (ms)
272
335
290
304

[2] “Extensible Messaging and Presence Protocol (XMPP), available at http://xmpp.org/,” Open Source.
[3] V. March, Y. Gu, E. Leonardi, G. Goh, M. Kirchberg, and
B. S. Lee, “ucloud: Towards a new paradigm of rich mobile
applications,” 8th International Conference on Mobile Web
Information Systems (MobiWIS), 2011.
[4] R. Ma, K. T. Lam, and C.-L. Wang, “excloud: Transparent
runtime support for scaling mobile applications in cloud,”
in 2011 International Conference on Cloud and Service
Computing (CSC), 2011, pp. 103–110.

Figure 8.

[5] R. Ma, K. Lam, C. Wang, and C. Zhang, “A stack-ondemand execution model for elastic computing,” in Proc.
of the 39th International Conference on Parallel Processing
(ICPP 2010), 2010, pp. 208–217.

real application evaluation

E. Image Capture Application Evaluation

[6] B. G. Chun, S. Ihm, P. Maniatis, M. Naik, and A. Patti,
“Clonecloud: elastic execution between mobile device and
cloud,” in Proceedings of the sixth conference on Computer
systems, 2011, pp. 301–314.

We developed a remote image capture application to
evaluate the prototype. The application implements a PF
function to capture the image. The evaluation scenario is
that the cloud server composes the image capture function
from the remote android phone. The cloud server initiates
the PF composition process, and the android phone execute
the image capture function and return the image to the
cloud server. We measure the time cost for each step in
this scenario as shown in Figure 8. In the ﬁgure, we use
the network handshaking time as the unit time. The phone
and the cloud server are connected by a router that is also
wiﬁ access point for the phone. From the ﬁgure, we can
see that the time spent for the POEM prototype is relatively
lower than the time for image transfer, which shows the good
performance of the prototype.

[7] X. Zhang, S. Jeong, A. Kunjithapatham, and S. Gibbs,
“Towards an elastic application model for augmenting computing capabilities of mobile platforms,” Mobile wireless
middleware, operating systems, and applications, pp. 161–
174, 2010.
[8] E. Cuervo, A. Balasubramanian, D. Cho, A. Wolman,
S. Saroiu, R. Chandra, and P. Bahl, “Maui: making smartphones last longer with code ofﬂoad,” in Proceedings of the
8th international conference on Mobile systems, applications,
and services. ACM, 2010, pp. 49–62.
[9] S. Kosta, A. Aucinas, P. Hui, R. Mortier, and X. Zhang,
“Thinkair: Dynamic resource allocation and parallel execution
in the cloud for mobile code ofﬂoading,” in 2012 Proceedings
IEEE INFOCOM, 2012, pp. 945–953.

VII. C ONCLUSION

[10] R. Kemp, N. Palmer, T. Kielmann, and H. Bal, “Cuckoo: a
computation ofﬂoading framework for smartphones,” Mobile
Computing, Applications, and Services, pp. 59–79, 2012.

This paper proposes a novel application running platform
for mobile cloud computing that allow mobile users to
ofﬂoad and compose mobile cloud application with little
management overhead. The implementation is based on
OSGi platform and XMPP protocols. The proposed service
platform handles service migration, service discovery and
service composition seamlessly in a transparent fashion. The
evaluation shows the proposed service platform is ﬂexible
and efﬁcient. The future work on POEM is to improve
security and privacy control of the POEM system. Moreover,
the service discover should incorporate more social network
features to make the discovery scalable and customizable.

[11] J. Hildebrand, P. Millard, R. Eatmon, and P. Saint-Andre,
XEP-0030: Service Discovery, XMPP Standards Foundation
(XSF), 2008, http://xmpp.org/extensions/xep-0030.html.
[12] P. Millard, P. Saint-Andre, and R. Meijer, XEP-0060: PublishSubscribe, XMPP Standards Foundation (XSF), 2010, http:
//xmpp.org/extensions/xep-0060.html.
[13] R. T. Fielding and R. N. Taylor, “Principled design of the
modern web architecture,” ACM Transactions on Internet
Technology (TOIT), vol. 2, no. 2, pp. 115–150, 2002.
[14] “Apache Felix,” http://felix.apache.org/site/index.html, Apache Felix. [Online]. Available: http://felix.apache.org/site/
index.html

ACKNOWLEDGMENT
The authors would like to thank NSF CPS #1239396 grant
to support the research on the MIDAS project.

48

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 7, NO. 3, MARCH 2008

1025

Unlinkability Measure for
IEEE 802.11 Based MANETs
Dijiang Huang, Member, IEEE

Abstract— In this paper, we propose a two-step unlinkability
measuring approach for MANET, i.e., (a) evidence collection
using statistical packet-counting traﬃc analysis, (b) evidence
theory-based unlinkability measure. We use IEEE 802.11b-based
MANETs as our analytical systems. Using our approach, we can
collect a set of evidence to set up a probability assignment for
each possible communication relation (i.e., the data sender and
corresponding receiver); and then we can apply the evidence
theory-based unlinkability measuring methods to derive the
unlinkability evaluations of the 802.11b MANET.
Index Terms— Unlinkability, traﬃc analysis, evidence theory.

I. Introduction

S

EVERAL wireless ad hoc network-based anonymous
routing protocols have been recently proposed for wireless mobile ad-hoc networks, e.g., [1], [2], [3], [4]. These
approaches target at making data transmissions unlinkable,
i.e., they make it diﬃcult to trace who communicates with
whom. To achieve this goal, hop-by-hop packet re-encryption
is used to prevent adversaries from identifying the end-to-end
transmission relations. However, adversaries can detect and
capture data traﬃc in the media, and then statistically analyze
point-to-point data traﬃc to discover end-to-end communication relations [5]. In particular, the adversaries can simply
count the number of transmitted packets to analyze captured
traﬃc. Such an attack is called as statistical packet-counting
traﬃc analysis (SPTA) attack [5].
In order to measure the performance of unlinkability of
a MANET communication system under SPTA attacks, a
theoretical unlinkability measuring framework for SPTA attacks is highly desired. To this end, we introduce evidence
theory [6] as a mathematical tool to evaluate the unlinkability
of a MANET. We use IEEE 802.11b-based MANETs as our
analytical communication system due to their popularity. In
our approach, evidence is defined as the number of captured
data frames (or packets) within a given time period.
We summarize our main contributions of this paper in twofold:
•

We analyze physical and MAC layers of IEEE 802.11b
protocols. The categorization and analysis of physical
and MAC layers properties help us to understand how
adversaries collect evidence to conduct SPTA attacks.

Manuscript received October 3, 2006; revised January 17, 2007, April
5, 2007, and June 4, 2007; accepted June 8, 2007. The associate editor
coordinating the review of this paper and approving it for publication was
V. Leung.
D. Huang is with the Department of Computer Science and Engineering,
Arizona State University, Tempe, AZ, 85287 USA (e-mail: dijiang@asu.edu).
Digital Object Identifier 10.1109/TWC.2008.060777.

We introduce evidence theory to measure the unlinkability. Based on our approach, multi-hop end-to-end
communication relations can be derived from directly
captured point-to-point evidence.
Since the evidence theory does not restrict the types of
measurements, it leaves space for us to inspect broader evidence such as timing, mobility, etc., where the art is to
quantify evidence and convert the evidence to probability
assignments for all possible communication relations. We note
that the traﬃc analysis-based unlinkability research is not
just restricted within IEEE 802.11b networks. Our proposed
approaches point towards a research direction that can cover
various types of wireless networks.
The rest of this paper is organized as follows: in section
II, we present the related work; in section III, we present
the communication models of IEEE 802.11b MANET; we
describe the SPTA attacks in section IV; the unlinkability
measuring approaches are presented in section V; in section
VI, we use simulation to demonstrate the use of our proposed
unlinkability measuring approaches; finally, we conclude our
research and future work in section VII.
•

II. Related Work
Most of the existing anonymous multi-hop wireless communication systems [1], [2], [3], [4] utilize two techniques:
1) on-demand path discovery, and 2) packet re-encryption. To
set up a packet forwarding path, a route request is broadcasted
hop-by-hop from the source to the destination; on receiving a
request, the destination node generates a reply (a confirmation)
and sends it along the reverse direction of the corresponding
request path. To prevent adversaries from identifying the same
packet transmitted on every packet forwarding hop, both the
routing and data packets are encrypted by a unique cryptographic key. These solutions are eﬀective in preventing certain
active traﬃc analysis attacks such as packet marking attacks
[7] and context-based traﬃc analysis attacks at the network
layer. However, due to the open communication environment,
anonymous MANET communication is still vulnerable to
statistical traﬃc analysis attacks. To measure the unlinkability,
in [5] and [8], we proposed a solution include the following
components: (i) the transmission model and channel model for
IEEE 802.11b protocols, (ii) an unlinkability evaluation model
using evidence theory, and (iii) a simulation study to validate
the proposed models based on a fixed wireless communication
system. Though the work presented in [5] provides a guideline
to evaluate the unlinkability of an MANET, there are still
several important questions need to be answered as follows.
How to build the end-to-end communication-relation matrix

c 2008 IEEE
1536-1276/08$25.00 

1026

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 7, NO. 3, MARCH 2008

based on captured traﬃc matrices? How to take the mobility
into consideration to set up the end-to-end communicationrelation matrix? What are the relations between evidence
theory based unlinkability measuring methods and other unlinkability measuring methods? What are the validation results
when we incorporate mobility in the simulation study? In this
paper, we will address these questions. Note that active traﬃc
analysis attack [9] is an important class of attacks to discover
the MANET traﬃc relations. Due to the page limitations,
our research focus in this paper is on passive traﬃc analysis
attacks.
Although the anonymous routing and packet delivery approaches can provide a degree of unlinkability, the adversaries
can conduct traﬃc analysis [10], [11], [12] at substrate layers
to deduce the end-to-end communication relations. Several
approaches were proposed to measure the unlinkability for
Internet-based protocols, such as [13], [14], [15]. These
approaches use Shannon information theory (based on probability theory) as the mathematical tool which use uncertainty
as the measuring metric to quantify (i.e., in number of bits)
the unlinkability. However, these approaches are unable to
deal with imprecise data, such as traﬃc captured in open
wireless environments. In section V-C, we provide a detailed
description of unlinkability measure using probability theory
and evidence theory.
III. Communication Models of IEEE 802.11b MANET
In this section, we analyze the data transmission, MAC
layer protocols, and communication channel model of IEEE
802.11b standards. Based on our analysis, we categorize and
evaluate the potential threats to discover the point-to-point
communication relations.

802.11b

Rate

SNR
( ≈ dB )

(Mbps)

11

DQPSKCCK
13

DQPSKCCK
5.5

8.88
DQPSKBaker DBPSK
Baker 4.5
1.2

2
1
30

70

90

120

(m)

Distance

Fig. 1.
802.11b communication Rate–Distance–SNR–Modeling/Codeing.
The physical layer head is always transmitted by 1Mbps and the rate is set
in the PLCP signal sub field. Diﬀerent rates use diﬀerent signal modulating
and coding schemes, e.g., DBPSK (Diﬀerential Binary Phase Shift Keying),
DQPSK (Diﬀerential Quadrature Phase Shift Keying), Baker sequence, and
CCK (Complementary Code Keying).

B. Virtual Carrier Sensing and Data Transmission of 802.11b
MAC Layer Protocol
802.11b data transmission with acknowledgement (ACK)
and virtual carrier sensing reveals point-to-point communication relations. For example, the frame transmission sequence
must follow a distributed synchronization mechanism. This
frame transmission mechanism requires that a frame must be
transmitted in sequence and as a result, the type of the next
frame is predictable, such as ACK, RTS, and CTS. The source
and destination addresses in data, ACK, RTS, and CTS frames
disclose the point-to-point communication relations.
C. 802.11b Channel Model

A. 802.11b Transmission Rate Control
802.11b protocol [16] covers the MAC and Physical layers.
An 802.11b frame header is always transmitted at a fixed
rate. The signal subfield in the physical layer convergence
procedure (PLCP) header indicates the data transmission rate
of its data portion.
In general, there are three types of rate selection algorithms
[17]: (a) Throughput-based Rate Control, (b) Frame error rate
(FER) -based Rate Control, and (c) Retry-based rate control.
These rate control algorithms are directly related to signal to
noise ratio (SNR), where the noise includes both ambient noise
and accumulative interference from other wireless devices.
Consequently, the SNR determines the selected transmission
rate and corresponding transmission distance. Since most of
rate selection algorithms choose the best rate to transmit a
frame, the locations of potential receivers are determined if
the level of SNR can be detected.

In Fig. 1, we draw the relations between distance, transmission rate, and SNR values based on the experiments and
analysis from [18] and [19]. SNR is firmly related to the biterror rate of the wireless channel, and hence to the FER. Pavon
1
. Thus, we can derive
and Choi [19] showed that FER ∝ S NR
1
the following relations: FER ∝ S NR ∝ d ∝ 1r , where r is the
communication rate.

We assume that wireless station S transmits with rate x ∈
{1, 2, 5.5, 11}. Based on the 802.11b channel model proposed
in [18], we classify three ranges as follows:
• Stations at a distance d < T X Range(x) to S are able
to correctly receive data from S , if S transmits at a rate
lower or equal to x.
• Stations at a distance d < IF Range to S are not able
to concurrently and correctly receive the transmissions
from other nodes. IF Range is changeable depending on
the hardware properties and the noise level. It may be
less or greater than T X Range(x).
• Stations at a distance d < PCS Range to S are able to
sense the physical carrier and detect the transmissions of
S.
In general, we have the relations T X Range(x) < IF Range <
PCS Range [18].
The 802.11b-based wireless communications are confined
by both timing as well as spatial restrictions. For example, let
S 1 and S 2 to be located in each other’s PCS range but outside
of IF Range. If S 1 and S 2 transmit concurrently, the potential frame receivers locating in their overlapped IF Range
can be excluded. To prevent such conflicting evidence, we
should avoid concurrent transmissions when two stations are
located within each other’s PCS Ranges. This communication
phenomenon is similar to the wireless systems when directional antennas are used. Directional antennas will decrease

HUANG: UNLINKABILITY MEASURE FOR IEEE 802.11 BASED MANETS

1027

Δ t1

the possibilities of the adversaries detecting the source of
transmitted signals; however, once a signal source is detected,
the intended receivers are easier to identify. Based on the
above discussions, if the signal source is diﬃcult to identify
(such as tiny and concealed objects), directional antennas are
preferred; otherwise omnidirectional antennas are preferred.
When omnidirectional antennas are used, a safer technique is
to defer the transmission when a station is located within the
transmitting station’s PCS Range.

1

IV. Packet Counting Traffic Analysis Attacks

1

Evidence collection and processing of SPTA attacks include two steps: (i) an evidence collection method based on
packet counts to derive point-to-point traﬃc matrices between
each pair of wireless stations for a given time period; (ii)
deriving the traﬃc-communication relation matrix between
each pair of end-to-end communication nodes. We present
our approaches via a simple 3-hop MANET example. The
frequently used notations in this section are given in follows:


k
k
WΔtk = wΔt
N × N traﬃc matrix during Δt, wΔt
{i, j} N×N
{i, j}
is the captured traﬃc from i to j.
a sequence of traﬃc matrix WΔtk , k =
W|1×K
1, . . . , K.
 t 
tK
K
RtK = ri,
r
denotes the maximum accumuj N×N
i, j
lative data from i to j via all possible
paths within the time period tK =
K
k=1 Δtk .
ATi,∗ , AT∗, j , AT∗,∗
amplification ratios for sender, receiver, and the overall system.
the set started with i and ended by j,
Vi, j = i, Λ, j
Λ is arbitrary set not including i, j.
. . . represents an end-to-end relation while {i, j} represents a point-to-point relation.
A. Adversaries’ Capabilities
The goal of the adversaries is to derive both point-to-point
and end-to-end communication relations. We assume that the
adversaries have the following capabilities: (a) adversaries can
detect, capture, and monitor the traﬃc transmitted within a
wireless communication system, however they cannot decrypt
the content of captured frames when cryptographic algorithms
are applied; (b) adversaries are silent (passive) observers
without injecting frames or interrupting frame transmissions;
(c) adversaries can locate wireless stations and trace their
movements (techniques such as triangulation [20] can be
used.); (d) based on the assumptions (a) - (c), adversaries can
detect the wireless signal transmission power and transmission
directions at any given location, i.e., the adversaries can locate
the signal source; (e) the mobile devices’ hardware properties
are known by the adversaries, thus the transmission range and
physical carrier sensing range of a mobile device are known to
the adversaries. In addition to the adversaries’ capability, we
assume that both MAC and IP addresses are set to all “1” (the
broadcasting address); hop-by-hop packet re-encryption (using
diﬀerent cryptographic key) is applied and thus the adversaries
cannot identify the same packet on diﬀerent hops by inspecting
the packet content.

t1
t1

Δ t2

t

Timing

2

t2

3

(a) A receiver changes to a sender

t1

1

2

t2

3

(b) A receiver receives from multiple
senders

t2

2

t1

3

(c) A sender changes to a receiver

Fig. 2.

Timing conditions.

B. Timing Constraints
Timing is a critical component for packet-counting based
evidence collection since we need to use timing information
to determine if a detected packet is eligible on successive
packet forwarding hops, e.g., the maximum retransmission
time out (MRTO). In general, there are two-type of timers.
(a) At the link-level, 802.11 standards allow 7 retransmissions
of RTS/CTS frames and 4 retransmissions of data frames; for
an end-to-end packet delivery, the maximum retransmission
time of a packet is computed as: (MRTO on each hop)×(total
numbers of hops). (b) At the transportation-level, the MRTO
is used to determine if a connection has timed-out. The value
of MRTO is determined by the channel quality and the end-toend requirements of upper-layer applications. In our unlinkability measuring model, the MRTO should be the smaller
one of accumulated link-layer MRTO or transportation-layer
MRTO.
C. Multi-hop Linkability Constraints
We partition the evidence collection procedures into a sequence of time intervals by continuously counting the number
of transmitted data frames. Note that the traﬃc matrices
are built as inputs of the tra f f ic() algorithm presented in
Section IV-D. The goal of tra f f ic() algorithm is to deduce
multi-hop communication relations. Thus, the constructions
of traﬃc matrices should not remove any potential multi-hop
communication relation. To this end, we construct a set of
traﬃc matrices W|1×K and each traﬃc matrix WΔtk ∈ W|1×K
must satisfy the following requirement: it only represents onehop communication relations among multiple mobile stations
within the time interval Δtk . To fulfill this requirement, we
need to consider the following four timing-decision conditions
(shown in Fig. 2) to confine the sole point-to-point communication relations as follows: (a) a receiver changes to a sender,
(b) a receiver receives packets from multiple senders, (c) a
sender changes to a receiver, and (d) t2 − t1 < MRTO. As
shown in Fig. 2, one packet is detected at epochs t1 and t2 in a
successive two-hop path; and the packet transmission relations
are indicated by corresponding arrows. In (a), we can make
the deduction: “it is possible that node 1 sends packets to
node 3 via node 2”. If we merge them as one traﬃc matrix
WΔt1 +Δt2 , the two-hop communication relation from node 1 to

1028

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 7, NO. 3, MARCH 2008

Detect
(a)

1

(b)

1

2

l
Δ t1 ,1

Δt2 , 2

3

Δ t 2 , 2 Δ t3 ,1

2
Δt4 , 3

Fig. 3.

m

a sequence of traﬃc matrices W|1×K by using the algorithm
tra f f ic(WΔtk ) presented as follows:

Δ t3 ,1

3

4

n
Δ t 2 ,1

4

Δt4 , 3

An example of 4 nodes Ad-hoc network.

node 3 is eliminated (i.e., in WΔt1 +Δt2 , w{1,3} = 0). Thus, for
condition (a), we cannot merge them as one traﬃc matrix for
the time interval t2 − t1 due to the one-hop property of traﬃc
matrix WΔt . In both (b) and (c), we observe that merging
traﬃc matrices will not eliminate potential deduced multi-hop
traﬃc relations. Finally, if t2 − t1 is larger than the MRTO,
two traﬃc matrices can be merged and this will not remove
potential multi-hop communication relations.
We note that the mobility is captured by a sequence of
traﬃc matrices W|1×K = {WΔtk |k = 1, . . . , K}. This is because
adversaries can monitor the mobile nodes’ movements and
the mobility will cause the changes of corresponding pointto-point communication relations. Thus a new traﬃc matrix
W Δtk+1 must be created according to current traﬃc matrix WΔtk .
D. Deriving Traﬃc-Communication Relation Matrix
We define the traﬃc matrices for a wireless network with
N nodes  as follows:
W|1×K = {WΔtk |k = 1, . . . , K}, where

Δtk
Δtk
is a N × N square traﬃc matrix during
W = w{i, j}
N×N
Δtk
time interval Δtk ; w{i, j} is the one-hop data traﬃc from node
k
denotes
i to node j (i  j) during the time interval Δtk . wΔt
{i,i}
the amount of traﬃc originated from the node i. We have
k
k
≤ wΔt
, where
the following traﬃc constraint: ∀ j, wΔt
{i, j}
{i,i}
i  j. We illustrate our construction of traﬃc matrices via a
simple example as shown in Fig. 3 through this section. In
the example, as shown in Fig. 3-(a), four wireless nodes form
a wireless network and packets are detected at locations l, m,
and n. The detected number of packets and corresponding
time series are shown in Fig. 3-(b). Based on the captured
traﬃc during the time period T = Δt1 + Δt2 + Δt3 + Δt4 , we
derive the following traﬃc matrices:
⎡
⎡
⎤
⎤
⎢⎢⎢1 1 0 0⎥⎥⎥
⎢⎢⎢0 0 0 0⎥⎥⎥
⎢⎢⎢0 0 0 0⎥⎥⎥⎥
⎢⎢⎢2 2 2 0⎥⎥⎥⎥
⎥⎥⎥ ,
⎥,
WΔt1 = ⎢⎢⎢⎢
WΔt2 = ⎢⎢⎢⎢
⎢⎢⎣0 0 0 0⎥⎥⎦
⎢⎢⎣0 0 0 0⎥⎥⎥⎥⎦
0 0 0 0
0 0 1 1
⎡
⎡
⎤
⎤
⎢⎢⎢0 0 0 0⎥⎥⎥
⎢⎢⎢0 0 0 0⎥⎥⎥
⎢⎢⎢0 0 0 0⎥⎥⎥⎥
⎢⎢⎢3 3 3 0⎥⎥⎥⎥
⎥⎥⎥ ,
⎥ . (1)
WΔt4 = ⎢⎢⎢⎢
WΔt3 = ⎢⎢⎢⎢
0
1
1
1
⎢⎢⎣
⎢⎢⎣0 0 0 0⎥⎥⎥⎥⎦
⎥⎥⎦
0 0 0 0
0 0 0 0
In (1), we cannot merge these matrices due to the timingdecision condition (a). We define
 the Traﬃc-communication
tK
tK
, where ri,
denotes the
relation matrix as: RtK = ri,
j N×N
j
maximum accumulative data from i to j via all possible paths
K
tK
Δtk . ri,
represents the
within the time period tK = k=1
j
maximum actual and deduced data traﬃc transmitted from i to
j based on the captured evidence W|1×K . RtK is derived from

Rtk = tra f f ic(WΔtk )
1:
i f k == 1 
return Rtk = WΔtk ;
tk
tk−1
2:
R =R
WΔtk ;
3:
f or(i = 1; N; i + +)
4:
f or( j = 1, j  i; N; j + +)
tk−1
tk−1
5:
r̄i,
= MRTO(ri,
, t );
j
j k
tk−1
6:
i f r̄i, j  0
7:
f or(k = 1, k  i, k  j; N; k + +)
k
0
8:
i f wΔt
 j,k
tk
tk
tk−1
k
+ min{r̄i,
, wΔt
};
9:
ri,k = ri,k
j
 j,k
tk
tk
tk
10:
ri,k = min{ri,k , ri,i };
11: return Rtk ;

MRTO(r, t) returns the amount of traﬃc r constrained
by the time window [t − MRTO, t].
We use traﬃc matrices given in (1) as our illustrative
example to demonstrate tra f f ic(WΔtk ) algorithm. In line 1,
if WΔtk is the first traﬃc matrix, we assign it to Rt1 and then
return Rt1 . If k = 2, in line 2, Rt2 takes the inner addition of Rt1
and WΔt2 . Then, we have a temporary traﬃc-communication
relation matrix (left):
⎡
⎡
⎤
⎤
⎢⎢⎢ 1 1 0 0 ⎥⎥⎥
⎢⎢⎢1 1 1 0⎥⎥⎥
⎢⎢⎢ 2 2 2 0 ⎥⎥⎥⎥
⎢⎢2 2 2 0⎥⎥⎥⎥
⎥⎥⎥ → Rt2 = ⎢⎢⎢⎢⎢
⎥ . (2)
Rt2 = ⎢⎢⎢⎢
0
0
0
0
⎢⎢⎣
⎢⎢⎣0 0 0 0⎥⎥⎥⎥⎦
⎥⎥⎦
0 0 1 1
0 0 1 1
Lines 2-9 compute the traﬃc through multiple hops between
each pair of nodes by inspecting if the previous traﬃc in Rt1
can travel one more hop using WΔt2 . In our example, we derive
t2
t1
2
= 0 + min{r1,2
, wΔt
} = 1.
a possible multi-hop traﬃc: r1,3
{2,3}
Line 10 is used to guarantee that the traﬃc from node i to
any node j should not exceed the amount of data transmitted
from node i, i.e., to avoid double counting a packet through
one node. Then, we can derive Rt2 shown in (2) (right). Using
the tra f f ic algorithm iteratively, we can derive Rt3 and Rt4
as follows:
⎡
⎢⎢⎢1
⎢⎢⎢2
t3
R = ⎢⎢⎢⎢
⎢⎢⎣0
0

⎡
⎤
⎢⎢⎢1 1 1 1⎥⎥⎥
⎢⎢⎢5 5 5 1⎥⎥⎥
⎥⎥ .
Rt4 = ⎢⎢⎢⎢
(3)
⎢⎢⎣1 1 1 1⎥⎥⎥⎥⎦
1 1 1 1
K
Δtk , we summarize the
Within the time period T = k=1
properties of the traﬃc-communication relation matrix RT =
tra f f ic(WΔtK ) as follows:
1
2
1
1

1
2
1
1

⎤
1⎥⎥
⎥
1⎥⎥⎥⎥
⎥,
1⎥⎥⎥⎦⎥
1

T
(i) RT is a N × N square matrix, and each element ri,
j > 0
represents both the actual and deduced traﬃc from node
i to node j during the time period T . The diagonal of RT
is the actual (or detected) traﬃc sent by node i, where
T
T
∀i, j ∈ X and ri,
j ≤ ri,i .
T
(ii) ri, j is the maximum accumulative traﬃc from node i
to node j via all possible paths. We have the following
observations:

T
∀j r
is the maximum traﬃc to all
a) RTi,∗ =
ji i, j
potential receivers from node i.

HUANG: UNLINKABILITY MEASURE FOR IEEE 802.11 BASED MANETS

1029


T
∀i r
b) RT∗, j =
is the maximum traﬃc to one
i j i, j
receiver j from all possible sources.
 
T
c) RT∗,∗ = ∀i ∀ j ri,
j is the maximum traﬃc among
ji
all possible pairs.
 T
d) RTi,i = ∀i ri,i
is the actual traﬃc transmitted in
the system.
The actual network traﬃc W|1×K is amplified by using the
tra f f ic algorithm. We define the ratio of the traﬃc amplification as a metric to evaluate the amount of noise information
for confusing the adversaries. We define the following three
amplification ratios:
ATi,∗
AT∗, j
AT∗,∗

=

T
RTi,∗ /ri,i
,

(4)

=

RT∗, j /γTj, j ,
RT∗,∗ /RTi,i .

(5)

=

(6)

(4) is the sender amplification ratio from one source to all
possible destinations; (5) is the receiver amplification ratio
from all possible sources to one destination; (6) is the system
amplification ratio, i.e., the total deduced traﬃc to the total
actual traﬃc. In single tranceiver wireless communications, an
actual receiver remains silent during the transmission. Here,
we use γTj, j to represent the actual traﬃc accepted by node j
T
. It is diﬃcult to
which is diﬀerent from the definition of ri,i
T
accurately derive the actual traﬃc γ j, j in (5) accepted by node
j. Thus, our following discussions focus on the amplification
ratios defined in (4) and (6).
V. Measuring Unlinkability
A. Some Definitions Related to Unlinkability Measure
Definition 1 (Perfect Unlinkability): The occurrence frequency of a transmission relation used to identify the linkability from a source to a destination is 1/N, where N is the total
number of potential destinations. The maximum unlinkability
measure is achieved as:
H(X) = − log2 p(x) = log2 N.

(7)

H(X) is the Hartley uncertainty measure [21] and p(x = X) =
1/N is the occurrence frequency of event X.
The expectation of Hartley uncertainty measure H =

− iN p(x) log2 1/p(x) = log2 N achieves the maximum value
when every event X (among all N possible events) has the
same occurrence frequency 1/N [22]. Note that the event
X defined in this paper represents a transmission relation
between the source/destination pair including all possible
paths between the two-end nodes. The unlinkability measure
presented in (7) implies that the maximum unlinkability is
achieved when the communication system is in an indistinguishable state. In other words, the adversaries cannot derive
the preference of one event over another. Thus, achieving
perfect unlinkability of a communication system is equivalent
to a random guess.
Definition 2 (Set Relation Definitions): In following context, we use Vi, j = i, Λ, j to represent the set starting with i
and ending with j, where Λ = {∀λ|λ ⊆ P(X) \ {i, j}}. We also
define the inclusive subset relation U  Vi, j if U = {i, μ, j}
and μ ⊆ Λ. Vi, j is an inclusive set.

Using evidence theory [6], we define p(Vi, j ) as the basic
probability assignment to set Vi, j , i.e., all paths start from i
and end at j. X is a universal set (contains all entities within
the communication system and |X| = N) and P(X) denotes the
power set of X (i.e., all subsets of X). We have the following
definition.
Definition 3 (Body of Evidence): Given a basic probability
assignment p(V)  0 for set V ∈ P(X) which is called a
focal element denoted by F ; B = {F , p} is called a body of
evidence, which denotes the set of all focal elements induced
by p (i.e., the set includes all basic probability assignments).

B. Derive Basic Probability Assignments
We propose the following lemmas to derive the probability
assignments for communication pairs:
Lemma 1: Given a traﬃc-communication relation matrix
RT , pT (Vi, j∗ ) is the probability that node i sends a packet to
node j when the packet is transmitted from node i. pT (Vi, j∗ )
is given as:

T
T
T
T
pT (Vi, j∗ ) = ri,
ri,
(8)
j /Ri,∗ = ri, j /
j .
∀j
ji

T
traﬃc
Proof: ri,
j represents the accumulative deduced

T
from node i to node j via all possible paths. RTi,∗ = ∀ j ri,
j
ji
is the accumulative traﬃc to all potential receivers from
node i. Thus, pT (Vi, j∗ ) represents the proportion of the traﬃc
transmitted from node i to node j to all the traﬃc sent by
node i.
Lemma 2: Given a traﬃc-communication relation matrix
RT , pT (Vi∗ , j ) is the probability that node j receives a packet
sent by node i. pT (Vi∗ , j ) is given as:

T
T
T
T
pT (Vi∗ , j ) = ri,
ri,
(9)
j /R∗, j = ri, j /
j .
∀i
i j

T
traﬃc
Proof: ri,
j represents the accumulative deduced

T
from node i to node j via all possible paths. RT∗, j = ∀i ri,
j
i j
is the accumulative traﬃc from all possible senders to node
j. Thus, pT (Vi∗ , j ) represents the proportion of the traﬃc
transmitted from node i to node j to all the traﬃc received by
node j.
Lemma 3: Given a traﬃc-communication relation matrix
RT , pT (Vi, j ) is the probability that node i sends a packet to
node j when a packet is detected in the communication system.
pT (Vi, j ) is given as:

T
T
T
T
/R
=
r
/
ri,
(10)
pT (Vi, j ) = ri,
∗,∗
j
i, j
j .
∀i

∀j
ji

 
T
Proof: RT∗,∗ = i j ri,
j is the deduced accumulative
ji
traﬃc among all possible communication pairs. Thus, pT (Vi, j )
represents the proportion of traﬃc transmitted from node
i to node j to the traﬃc transmitted among all possible
communication pairs.
Lemmas 1 and 2 evaluate the receiver’s probability of one
packet from one sender and from all senders to a particular
receiver j, respectively; while, Lemma 3 evaluates the communication relations from the perspective of the whole system.

1030

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 7, NO. 3, MARCH 2008

TABLE I
Probability assignments (example shown in (1) and (3))

Anonymity
receiver set
p

Evidence
T
i, j
ri,
j
1, 2
1
1, 3
1
1, 4
1
2, 1
5
2, 3
5
2, 4
1
3, 1
1
3, 2
1
3, 4
1
4, 1
1
4, 2
1
4, 3
1

BelT (Vi, j∗ )
1/3
1/3
1/3
5/11
5/11
1/11
1/3
1/3
1/3
1/3
1/3
1/3

Measures
BelT (Vi∗ , j )
1/3
1/7
1/3
5/7
5/7
1/3
1/7
1/3
1/3
1/7
1/3
1/7

BelT (Vi, j )
1/20
1/20
1/20
5/20
5/20
1/20
1/20
1/20
1/20
1/20
1/20
1/20

C. Belief Unlinkability Measure
The belief measure represented as Bel(V) : P(X) → [0, 1]
denotes the lower bound of an unlinkability measure [22].
Based on our set relation defined in Section V-A, we have the
following belief measure definition:


p(U) = 1 −
p(U).
(11)
Bel(V) =
U|UV

U|UV

In (11), only if an evidence U is an inclusive subset of V, it
will be counted as the evidence supporting the claim V.
The belief unlinkability measure depends on the abilities
of adversaries. It shows the confidence of adversaries on
unlinkability measurements based on a given set of evidence.
For example, if the adversary can determine the paths relation
U  V, ∀U ∈ P(X), the adversary has more confidence in
using the belief measure. pT (Vi, j∗ ), pT (Vi∗ , j ), and pT (Vi, j ) are
derived by using tra f f ic(WΔtk ) algorithm that captures all
possible traﬃc between two nodes in traﬃc-communication
relation traﬃc matrix RT . Based on the definition of belief
measure in (11), it is easy to prove that BelT (Vi, j∗ ) = pT (Vi, j∗ ),
BelT (Vi∗ , j ) = pT (Vi∗ , j ), and BelT (Vi, j ) = pT (Vi, j ). Based on the
traﬃc example shown in (1), the probability assignments (or
belief measure) are shown in Table I.
Relation to Probability Theoretic Anonymity Measure
Probability theory is a branch of evidence theory, while
evidence theory is, in turn, a branch of fuzzy measure theory.
In (11), only if an evidence U is a subset of V, will it be
counted as the evidence supporting the claim V. Note that if
V is singleton, we have Bel(V) = p(V) where p(V) (= m(V))
is the probability assignment of the singleton V and a belief
measure is reduced to a probability measure. Compared to the
probability theory, the basic element in evidence theory is a
set. Every set is crisp and the issue here is the likelihood of
membership in each of these sets of an object whose characterization is imprecise and, possibly, fuzzy. This property
perfectly fits into the wireless communication system. Existing
probability theoretic models are suitable for wired network.
For example, in wired communication systems, a probability
is usually used to describe the likelihood of a transmission
between two nodes and a transmission evidence is associated
with a particular physical link. However, in wireless systems,

AUB

AUB

p
p

p

p

P’

P’

p
A
One-to-many
One-to-one
relations
relations
(a) Wired vs. wireless in one-hop
network

B
A

B

(b) W ired vs. wireless in two-hop
network

Fig. 4. The diﬀerence between evidence theory and probability theory using
network examples.

a packet sender and its potential receivers form an one-tomany communication relation. The real communication role of
a wireless node in the receiver set is fuzzy (i.e., it is uncertain
if the node in the receiver set is the real receiver) when the
receiver’s addresses in both link layer and network layer are
hidden.
As proposed in [22], the following two formulas demonstrate the fundamental diﬀerences between the evidence theory
(here we use belief measure as the example) and probability
theory.
Bel(A ∪ B) ≥ Bel(A) + Bel(B),
(12)
where A and B are disjoint sets and Bel(A ∪ B) is the
measurement of evidence supporting the claim A ∪ B. The
property shown in (12) is called supperadditive. If both A and
B are singletons, we can reduce (12) to the following equation:
p(A ∪ B) = p(A) + p(B),

(13)

where |A| = |B| = 1 and A ∩ B = ∅. The diﬀerences
between (12) and (13) are subtle. As shown in Figure 4(b),
it is quite possible that a potential receiver in anonymity
set A is also involved in anonymity set B (as shown in dot
circles). Thus, the new anonymity set A ∪ B is not simply
the addition of sets A and B. We can use evidence theory to
represent the set intersections and involvements in an eﬀective
way. In addition to the described fuzziness of wireless links,
mobility will change the membership of neighborhood set and
makes it more diﬃcult for probability theory to enumerate all
possible communication relations. Whereas, the set notation
in evidence theory will abstract the details and make it easier
to represent the information involvement, such as using subset
inclusive U  V in (11).
D. Measuring System Unlinkability
Hartley addressed [21] that the amount of uncertainty associated with a set of alternatives can be measured by the amount
of information needed to remove the uncertainty. Under set
constructions, we rewrite (7) as follows:
H(V) = log2 |V|,

where, |V| = max{λ ∈ Λ} + 2.

(14)

One bit of uncertainty is equivalent to the total uncertainty
regarding the truth or falsity of one atomic proposition. When
the Hartley function H is applied to subsets of a given
universal set X, it has the form H : P(X) → R+ , where R+
denotes the set of nonnegative real numbers. In this case, its
range is:
(15)
0 ≤ H(V) ≤ log2 |X|.

HUANG: UNLINKABILITY MEASURE FOR IEEE 802.11 BASED MANETS

Dubois and Prade [23] proposed non-specificity in evidence
theory based on Hartley function:

p(V) log2 |V|.
(16)
N(p) =
V∈F

Function N is a weighted measure by using Hartley function
for all focal elements. The weights are values of the basic
probability assignments. In particular, for each focal element
{Vi, j , p(Vi, j )} ∈ B indicates the degree of evidence focusing
on a source/destination pair (i, j). log2 |Vi, j | indicates the lack
of specificity of this evidential claim. The larger the value
of p(Vi, j ), the stronger the evidence (in other words, the less
unlinkability); the larger the value of the inclusive set |Vi, j |
(i.e., the longer the packet forwarding path from i to j), the
less specific the evidence (i.e., the more unlinkability).
E. Diversity of Unlinkability Measure
Shannon information theory based unlinkability measure
has been proposed, such as [13], [14]. These approaches utilize
entropy (i.e., the uncertainty measure) as the evaluation metric.
The entropy H is represented as follows,


1
,
where
p(x) log2
p(x = X) = 1. (17)
H=
p(x)
X
X
where p(x = X) is the occurrence probability of event X.
It is useful to compare the actual unlinkability measure of
a communication relation to its maximum achievable unlinkability measure. We propose to use Kullback-Leibler divergence [24] (denoted by KL, a.k.a., information divergence, or
information gain, or relative entropy) for this purpose. The KL
measure is represented as follows:

p(x)
,
(18)
p(x) log2
KL(P||Q) =
q(x)
X
where we measure the probability distribution P = {p(x)|x =
V, ∀V ⊆ P(X)} to an arbitrary probability distribution Q =
{q(x)|x = |X|} and |X| = N. Using the property of perfect
unlinkability, we require q(x) = 1/N, ∀x.
KL (a.k.a., information divergence, or information gain,
or relative entropy) is a natural distance measure from a
true probability distribution P to an arbitrary probability
distribution Q. Typically P represents data, observations, or
a precise calculated probability distribution. The measure Q
typically represents a theory, a model, a description or an
approximation of P. (18) can be interpreted as the expected
extra message-length per datum that must be communicated if
an unlinkability measure that is optimal for a given distribution
Q is used, compared to using the unlinkability measure based
on the true distribution P.
F. Summary of Unlinkability Measure
To analyze the unlinkability of a given communication
system, the first step is to understand the transmission properties of the system, e.g., the channel model we presented
in Section III. Once the channel model is determined, we
can use our packet-counting based evidence collection scheme
to create traﬃc matrices W|1×K = {WΔtk |k = 1 . . . , K} for
K
a given time period T =
k=1 Δtk . Here, we consider a

1031

TABLE II
Unlinkability measure (example shown in (1) and (3))
i− j

Maximum
Unlinkability
KL
Amplification
Unlinkability
Measure
Measure
Factors by
by (7)
by (17)
by (18)
(4) and (6)
1, j∗ 
1.585
1.585
0
3
∗
1.585
1.349
0.236
2.2
2, j 
3, j∗ 
1.585
1.585
0
3
4, j∗ 
1.585
1.585
0
3
i∗ , 1
1.585
1.149
0.436
i∗ , 2
1.585
1.585
0
i∗ , 3
1.585
1.149
0.436
1.585
1.585
0
i∗ , 4
i, j
3.585
3.161
0.424
2.5
 The maximum unlinkability is computed based on the number of nondiagonal elements in RTi,∗ , RT∗, j , and RT∗,∗ , i.e., the receiver unlinkability
N = 3 and the system unlinkability N = 12.

captured data packet as an evidence to prove a corresponding
point-to-point communication relation. Then, by recursively
using tra f f ic(WΔtk ) algorithm, we can derive the traﬃccommunication relation matrix RT where the pairwise endto-end communication relations are weighted by the amount
of deduced traﬃc between two end nodes. Using Lemmas 1-3
and probability assignment functions (8)-(10), we can derive
the basic probability assignment (or belief measure) for each
communication pair. We summarize the set of unlinkability
measurement methods as follows:
•
•

•
•
•

•

RT determines the traﬃc distribution to/from a particular
receiver/sender.
Amplification ratios (4) and (6) define the amount of
noise information introduced into the communication
systems.
Maximum unlinkability (7) and (14) represent the maximum receiver or system unlinkability.
Belief measure (11) represents the degree of confidence
of an unlinkability measure.
Information measure (17) defines the minimal amount
of information (counted by the number of “bits”) to
represent the system status.
KL measure (18) represents the diﬀerence between the
measured unlinkability and the maximum unlinkability.

In our demonstrative example, the maximum unlinkability
is computed based on the number of non-diagonal elements
in RTi,∗ , RT∗, j , and RT∗,∗ ; for example, N = 3 for the receiver
unlinkability and N = 12 for the system unlinkability. In
Table II, excepting node 2, the receiver unlinkability measure
equals the maximum receiver unlinkability. This is due to
the fact that node 2 sends more packets than other nodes

during the time period 41 tk . The extra packet sent by node 2
also reduces the unlinkability of its immediate communication
neighbors 1 and 3 (see the first and third column of (3)). The
overall system unlinkability is also aﬀected by node 2 and
it bellows the maximum achievable system unlinkability. The
unlinkability measure by using KL measure and amplification
ratios are similar to the unlinkability performance measured
by using (17). We conclude that the evenly distributed traffic of a MANET exhibits better unlinkability performance
when packet-counting-based evidence collection approach is
applied.

1032

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 7, NO. 3, MARCH 2008

3500
3000

3000

Src
2

2500
Src

5

2

7
2000

9
1500

10
12
14

1000

5

2000

8

Deduced Traffic

Deduced Traffic

2500

7
8
1500

9
10
12

1000

14

15

15
16

16

500

500

0
0

1 2 3 4 5 6 7 8 9 10 1112 13 1415 1617 18 1920 2122 2324 25 2627 2829 30

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30

Destination Node

(a) Deduced traﬃc
T x Range=160m

RTi,∗

Destination Node

from one source, 11Mbps,

(b) Deduced traﬃc
T x Range=270m

3500

RTi,∗

from one source, 5.5Mbps,

3000

Dst
3000

Dst

3

6

7

7

8
9
2000

10
11
12

1500

13
14
1000

8

2000
Deduced Traffic

Deduced Traffic

3

2500

6
2500

9
10
11

1500

12
13
1000

14

15

15

16

16

17

500

500

17

18

18

0

0

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30

Source Node

(c) Deduced traﬃc
T x Range=160m

RT∗, j

Source Node

from all sources, 11Mbps,

(d) Deduced traﬃc
T x Range=270m

RT∗, j

from all sources, 5.5Mbps,

0.8
0.7
0.6
Receiver
Amplification
Ratio (11)

27
25

System
Amplification
Ratio (11)

23
21

Receiver
Amplification
Ratio (5.5)

19

System
Amplification
Ratio (5.5)

17
15
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
Source Node

(e) Amplification Ratio using (4) and (6)
Fig. 5.

KL Measure

Reciever Amplification Ratio

29

0.5
0.4
0.3
0.2
0.1
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
Source Node
KL Measure by one sender (11)

KL Measure by all senders (11)

System KL Measure (11)

KL Measure by one sender (5.5)

KL Measure by all senders (5.5)

System KL Measure (5.5)

(f) KL Measure using (18)

Using various approaches for unlinkability measure

VI. Simulation Analysis
We used network simulator (NS2) to conduct a comparative study in the following scenarios: (a) the transmission
rate is at 11Mpbs with T x Range(x) = 160m; and (b) the
transmission rate is at 5.5Mpbs, with T x Range(x) = 270m.
The two scenarios follow the same simulation construction:
30 wireless nodes are selected and deployed in a 800 ×
800m2 simulation area; random way-point mobility model is
used (each mobile user randomly selects a moving speed
between 0m/s and 4m/s towards its destination); 15 end-toend pairs (i.e., 2-3, 5-6, 5-7, 7-8, 8-9, 8-10, 9-10, 10-11, 1012, 12-13, 12-14, 14-15, 15-16, 16-17, 16-18) are randomly
chosen to transmit CBR traﬃc, where 10 nodes originate
data frames (i.e., 2,5,7,8,9,10,12,14,15,16) to 14 sinks (i.e.,
3,6,7,8,9,10,11,12,13,14,15,16,17,18); the simulation time is
200 seconds; and the end-to-end transport layer MRTO value
is 4 seconds. All other nodes are packet forwarding nodes.
Simulation Results and Analysis
In our following analysis, we compare diﬀerent measuring
approaches and demonstrate their eﬀectiveness in measuring
the communication unlinkability.

Fig. 5(a) and Fig. 5(b) present the deduced traﬃc by
applying algorithm RT = tra f f ic(WΔtk ) on sequentially

captured traﬃc matrices W|1×K , T = 1K tk = 200s, when
the transmission rates are 11Mbps (T X Range = 160m) and
5.5Mbps (T X Range = 270m), respectively. Here, we only
present the communication patterns of actual traﬃc originators
(i.e., 2,5,7,8,9,10,12,14,15,16). The coordinate fixed by the
same source id and x-axis value represents the total amount
of traﬃc originated by the corresponding source node. Other
coordinates represent the deduced traﬃc from the source node
to all destination nodes. We analyze the unlinkability measure
from three perspectives using Fig.5(a) and Fig. 5(b). For each
curve, we first look at the traﬃc gap between the total traﬃc
originated from a source node and the deduced traﬃc between
each pair of nodes. A large gap represents a small probability
that a packet originated from the source node to the destination
node. Secondly, we look at the flatness of each curve. We
observe that the flatness of a curve represents the degree of a
unlinkability measure of a packet sending node, i.e., a flatter
curve means that a packet sent by the source node has similar
probability to be received by each node. Thirdly, the gaps

HUANG: UNLINKABILITY MEASURE FOR IEEE 802.11 BASED MANETS

between two curves represent the degree of unlinkability for
distinguishing a packet originated from two sources in the
communication system.
Comparing Fig. 5(a) and Fig. 5(b), we notice that the scenario (b) achieves better unlinkability using three perspectives
described in previous paragraph. The reason being a lower
transmission rate causes a longer transmission distance (i.e.,
270m vs. 160m). Thus the number of potential packet receivers
is increased due to larger area covered by the T x Range.
Hence, if lower rate can fulfill the traﬃc demand, we prefer
the lower rate to achieve better unlinkability.
Fig. 5(c) and Fig. 5(d) are derived from the traﬃccommunication relation matrix RT∗, j . Here, we present the
communication patterns from all source nodes to a particular
destination (e.g., 3,6,7,8,9,10,11, 12,13,14,15,16,17,18). Each
curve represents the amount of traﬃc from every source
to one destination node. In both figures, (i) most of the
destination nodes receive similar amount of traﬃc and traﬃc
originators (e.g., 2,5,7,8,9,10,12,14,15,16) occupy the peaks of
these curves; (ii) several forwarding nodes also form peaks in
both figures; however, the peak values of forwarding nodes are
diﬀerent in two scenarios. The above discovered phenomena
are due to the fact that (1) with CBR traﬃc it is easier to
expose the traﬃc originators when the traﬃc capturing time
is suﬃciently long and (2) the mobility leverages the traﬃc
forwarded by the intermediate nodes. Based on the above
observations, we conclude that we should avoid using CBR
traﬃc (i.e., sporadic transmission should be applied) and avoid
using routing protocols based on the minimum number of hops
(i.e., multi-hop packet deliveries increase the traﬃc forwarded
by intermediate nodes).
Comparing Fig. 5(c) and Fig. 5(d), we notice that the
diﬀerences between the peak values are reduced and more
forwarding nodes occupy the peaks. This is because scenario
(b) involves more potential packet forwarding nodes due to its
longer transmission range.
In Fig. 5(e), the amplification ratio for each source node and
the overall system have been presented for both scenarios (a)
and (b). The system amplification ratio is the average value of
the receiver amplification ratios. The lower the amplification
ratio, lower the unlinkability. We notice that both receiver
and system amplification ratios of scenario (a) is below the
scenario (b), which confirms the unlinkability comparative
analysis of deduced traﬃc for scenarios (a) and (b). The figure
also shows an interesting source 30 whose amplification ratio
value is far below other source nodes. This is because most
of the nodes are located out side of the T x Range of node 30.
Fig. 5(f) is derived from the probability assignments defined
in Lemmas 1–3 (corresponding equations (8)–(10)) and the
KL unlinkability measure defined in (18). The smaller KL
value means the closer to the maximum unlinkability defined
in (7). When the KL measure equals to zero, the ultimate
unlinkability is achieved. Confirming our previous unlinkability analysis (i.e., deduced traﬃc and amplification ratio),
scenario (b) exhibits better receiver and system KL measure
than scenario (a). In particular, the peak values of each KL
curve represent the fact that the corresponding source nodes
have worse unlinkability than other source nodes. The single
sender KL measure curves also show that the node 30 has the

1033

worst unlinkability among all source nodes. In our simulation,
node 30 only sends 2 packets to one reachable node; thus its
transmission pattern can be easily determined.
We finally present our analysis using traditional information theory unlinkability measure (use (17)) and the results
are shown in Fig. 5. The measurement values confirm our
previous analysis using various metrics. However, (17) is
not a good metric for graph-based unlinkability evaluations.
This is because (17) is the expectation of logarithm-scaled
probability assignments for each communication pair. The
logarithm function scales down the measurement diﬀerence
exponentially. In addition, the diﬀerence between the actual
unlinkability measure and the maximum unlinkability measure
can be eﬀectively captured by using KL measure. Based on
our anonymity analysis in each layer of MANET protocol
stack, the solution of anonymous MANET communications
should use a cross-layer approach. In addition, the solution
should not only satisfy the anonymity requirements, but also
fulfill various QoS constraints such as delay, reliability, energy
consumptions, etc. The QoS guaranteed anonymous MANET
system is scheduled as our next research step.
VII. Conclusion and Future Research Directions
In this paper, we analyzed the communication properties of
wireless systems using IEEE 802.11b standards. We present
an evidence collection and processing scheme to derive the
traﬃc-communication relation matrix. Using this matrix, we
propose a set of unlinkability measuring methods to evaluate the unlinkability of a given MANET. Based on our
study in this work, we observed that compared to Shannon
information theory, evidence theory must rely on a well
founded evidence collection mechanism in order to correctly
conduct unlinkability evaluation. This requirement means that
the evaluator must understand the mechanism/infrastructure of
the evaluating system and clearly define what the evidence is
and how accurate the evidence can be collected. Our research
provides a novel approach for evaluating the unlinkability of
MANET. However, our research is still in its infant stage. For
conducting future research, we present several open problems
in measuring unlinkability in MANET:
• Using rate control and location control (or mobility
control), we can improve the communication system’s
unlinkability. Will multi-layer and cross-layer approaches
be viable solutions to improve the unlinkability of a
MANET?
• How to design anonymous MANET routing protocols to
distribute traﬃc evenly to against traﬃc analysis attacks?
• How to solve the scalability problem due to the set
involvement relations in (11)? In Table I, we enumerate
the possible paths among 4 nodes. When the number of
nodes increases in the MANET, the number of passible
paths between two end nodes is increased exponentially.
• The evidence theory is a subset of fuzzy measure theory
and the super set of the possibility theory. Can we extend
or reduce the evidence theory to get better unlinkability
measurements?
• How to construct the metrics using the evidence theory
to measure multi-channel MANETs?

1034

•

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 7, NO. 3, MARCH 2008

What is the impact of evidence theory on evaluating the
anonymity, capacity, and mobility of MANET? Can we
set up a generalized analytical framework?
References

[1] A. Boukerche, K. El-Khatib, L. Xu, and L. Korba, “A novel solution for
achieving anonymity in wireless ad hoc networks,” in Proc. 1st ACM
International Workshop on Performance Evaluation of Wireless Ad Hoc,
Sensor, and Ubiquitous Networks, 2004, pp. 30–38.
[2] J. Kong and X. Hong, “ANODR: anonymous on demand routing with
untraceable routes for mobile ad-hoc networks,” in Proc. ACM MobiHoc,
2003, pp. 291–302.
[3] S. Seys and B. Preneel, “ARM: anonymous routing protocol for mobile
ad hoc networks,” in Proc. 20th IEEE International Conference on
Advanced Information Networking and Applications - Workshops (AINA
2006 Workshops), pp. 133–137.
[4] Y. Zhang, W. Liu, and W. Lou, “Anonymous communications in
mobile ad hoc networks,” in Proc. IEEE Information Communications
Conference (INFOCOM), Mar. 2005, pp. 1940–1951.
[5] D. Huang, “Traﬃc analysis-based unlinkability measure for IEEE
802.11b-based communication systems,” in Proc. ACM Workshop on
Wireless Security (WiSe), 2006, pp. 65–74.
[6] G. Shafer, A Mathematical Theory of Evidence. Princeton University
Press, 1976.
[7] X. Fu, Y. Zhu, B. Graham, R. Bettati, and W. Zhao, “On flow marking
attacks in wireless anonymous communication networks,” in Proc.
ICDCS 2005, pp. 493–503.
[8] D. Huang, “On measuring anonymity For wireless mobile ad-hoc
networks,” in Proc. 2nd IEEE International Workshop on Performance
and Management of Wireless and Mobile Networks (P2MNet), 2006, pp.
779–786.
[9] X. Fu, B. Graham, R. Bettati, and W. Zhao, “Active traﬃc analysis
attacks and countermeasures,” in Proc. International Conference on
Computer Networks and Mobile Computing, 2003, pp. 31–39.
[10] A. Back, U. Moller, and A. Stiglic, “Traﬃc analysis attacks and tradeoﬀs in anonymity providing systems,” in Proc. Information Hiding (IH
2001), Springer, 2001, p. 245.
[11] J. Raymond, “Traﬃc analysis: protocols, attacks, design issues and open
problems,” in Designing Privacy Enhancing Technologies: Proceedings
of International Workshop on Design Issues in Anonymity and Unobservability. Springer, 2001, pp. 10–29.
[12] A. Serjantov and P. Sewell, “Passive-attack analysis for connectionbased anonymity systems,” International J. Inf. Security, vol. 4, no. 3,
pp. 172–180, 2005.

[13] C. Dıaz, S. Seys, J. Claessens, and B. Preneel, “Towards measuring
anonymity,” in Proc. Privacy Enhancing Technologies Workshop (PET
2002), Lecture Notes in Computer Science, vol. 2482, Springer, 2002,
pp. 54–68.
[14] A. Serjantov and G. Danezis, “Towards an information theoretic metric
for anonymity,” in Proc. Privacy Enhancing Technologies, Springer,
2002, pp. 41–53.
[15] G. Tóth, Z. Hornák, and F. Vajda, “Measuring anonymity revisited,” in
Proc. Ninth Nordic Workshop on Secure IT Systems, S. Liimatainen and
T. Virtanen, eds., Espoo, Finland, Nov. 2004, pp. 85–90.
[16] IEEE Standard 802.11, “Wireless LAN medium access control (MAC)
and physical layer (PHY) specifications,” 1999.
[17] I. Haratcherev, J. Taal, K. Langendoen, R. Lagendijk, and H. Sips, “Automatic IEEE 802.11 rate control for streaming applications,” Wireless
Commun. Mobile Computing, vol. 5, no. 4, pp. 421–437, 2005.
[18] G. Anastasi, E. Borgia, M. Conti, and E. Gregori, “Wi-Fi in ad hoc
mode: a measurement study,” in Proc. IEEE Annual Copnference on
Pervasive Computing and Communications (PERCOM), 2004, pp. 145–
154.
[19] J. del Prado Pavon and S. Choi, “Link adaptation strategy for IEEE
802.11 WLAN via received signal strength measurement,” in Proc. IEEE
International Conference on Communications, 2003, pp. 1108–1113.
[20] Cisco, “Wi-Fi based real-time location tracking: solutions and technology,” white paper, http://www.cisco.com/application/pdf/en/us/guest/
products/ps6386/c1244/cdccont 0900aecd80477957.pdf.
[21] R. V. L. Hartley, “Transmission of information,” The Bell System, vol. 7,
no. 3, pp. 535–563, 1928.
[22] G. J. Klir and M. J. Wierman, Uncertainty-Based Information. PhysicaVerlag, A Springer-Verlag Company, 1998.
[23] D. Dubois and H. Prade, “A note on measures of specificity for fuzzy
sets,” International J. General Systems, vol. 10, no. 4, pp. 279–283,
1985.
[24] T. M. Cover and J. A. Thomas, Elements of Information Theory. New
York: Wiley, 1991.
Dijiang Huang (M’00, ACM’00) received his B.S.
degree from Beijing University of Posts & Telecommunications, China 1995. He received his M.S.,
and Ph.D. degrees from the University of Missouri–
Kansas City, in 2001 and 2004, respectively. He is
an Assistant Professor in the Computer Science &
Engineering Department at the Arizona State University. His current research interests are computer
networking, security, and privacy.

IEEE International Conference on Social Computing / IEEE International Conference on Privacy, Security, Risk and Trust

Email-based Social Network Trust
Dijiang Huang∗ , Vetri Arasan
School of Computing Informatics and Decision Systems Engineering
Arizona State University
Tempe, USA
Email: [dijiang,varasan]@asu.edu

Abstract—In this paper, we present a comprehensive trust
model using emails. A bootstrapping trust model – Email Trust
(EMT) – in pervasive communication environments. EMT focuses
on email-based social network trust, which provides a level of
belief on the data transmitted by an entity. To achieve the emailbased social network trust, we require each user to perform a
trust checking procedure and process a received trust checking
request from their highly trusted email contacts or through a
trusted checking proxy server that is maintained by a trusted
third party. We present the basic trust models based on emails.
This paper is a pioneer work to demonstrate the basic trust model
that can be established by using email-based social network.

I. I NTRODUCTION
In this paper, we present a new trust evaluation system
using, probably, the oldest social networks over Internet, i.e.,
we investigate how to establish trust among email users. Our
research goal is to use statistical evidence for trust measure
among email users. Compared to existing WOT solutions, e.g.,
WOT [1], our design goal is to reduce the users’ involvements
for trust establishment and automate the trust evaluation processes.
Emails represent many social activities and connections that
can be beneﬁtting for setting up trust among people. The use
of email trust (EMT) has many attractive advantages over other
social networks. We classify the advantages of using EMT as
follows: (i) Email services usually use natural and intrinsic
layer of protections of email services, e.g., scrutinizing the
untrusted emails through spam ﬁlter and manually setup
ﬁltering rules; (ii) The email management system encapsulates some services that help to establish EMT social trust.
For example, folder management, statistic information such
as email exchange frequency, priority level, email receiving
dates, key words/sentences, etc.; (iii) Trust ranking among
email receivers can be incorporated naturally through email
contact lists (Automatic procedures can be performed without
much effort for email users, e.g., Gmail automatically adds
email addresses in contact list); (iv) Email users can check
EMT anywhere and anytime when Internet is available; (v)
Most importantly, EMT can potentially provide a very large
trust data base covering majority of population, which can
maximally beneﬁt for general users; (vi) The most sensitive
issue relating to using email trust is the privacy issue. However,
advantages still exist in the versatile email services that can
∗ The presented work is supported by US NSF grant CNS-1029546 and
ONR-YIP award.

978-0-7695-4211-9/10 $26.00 © 2010 IEEE
DOI 10.1109/SocialCom.2010.59

be used in practice, e.g., free emails vs. commercial/workrelated emails, web-based vs stand-alone, which allow us to
promote EMT gradually to address privacy and deployment
issues. More discussions on privacy are given in later part of
the paper.
Foremost, the proposed EMT is a distributed trust query
system that builds on the premise that email addresses are
partially public though people concern about third-party use.
Although, this represents the fundamental nature of email
services: email is designed for communications among people,
it is the major controversial aspect of EMT to extend the uses
of email services for setting up trust. The major challenge
comes from the fact that the EMT trust query service has
two main functions: (i) measuring trust between an email
user with (or through) his/her contacts; and (ii) protecting
email users’ privacy during the trust establishment procedure.
Particularly, in a highly dynamic environment, when two
persons meet, they will exchange their email addresses (or
in some anonymized forms to preserve privacy). Once the
trust is established through EMT, we can utilize identity-based
cryptography to handle the entity trust, i.e., to verify each
other’s identity and set up common session keys. In this paper
we describe the EMT framework and we address the following
research issues:
(1) What are the criteria to establish the email trust through
statistical method between any two people? The email inbox
has email addresses of which communication has taken place.
There are folders, address book, labels etc., which can give
insight in ﬁnding out the relation with the contacts. We
consider that trust between two people increases as they
exchange emails back and forth. On the other hand, in one
way communication, i.e., a person sends emails to another
person without getting replies, has a low trust rank.
(2) How to initiate, maintain and request (search) for
trust ranking through existing email system? An email user
wouldn’t have communicated with all the people having email
accounts. Hence, the user wouldn’t have an established trust
value for them. Whenever an unknown email address comes
across the user, the user has to request the trust value from
his/her trusted contacts. The trusted contacts might also relay
the request to their contacts. The relaying of the request is
controlled by applying a threshold on the number of relays
allowed. Upon receiving a reply for the trust rank, the value is
cached for future encounters with the unknown email address.
(3) How to preserve user’s email privacy? Pseudo-email
363

addresses are exchanged around in the EMT network. The
personal and work related email addresses are mapped to
pseudo-email addresses, thereby preventing the exposure of
actual email addresses.
The rest of paper is arranged as follows: the related work is
presented in Section II; in Section III, we present the system
and models of EMT; in Section IV, we present the email
trust architecture and trust measurement models; the emailbased trust validation and experimental results are presented
in Section V; ﬁnally, we conclude our research and indicate
the future research directions in Section VII.
II. R ELATED W ORK
The Pretty Good Privacy (PGP) [2] trust model is an
application of web of trust for email-based social networks.
PGP trust is built through the users’ public keys, where several
PGP users can sign a public key vouching that the key belongs
to the correct owner. This certiﬁcate can be either trusted
directly or there is chain going back to a trusted person. The
trust rating is provided by PGP users on their stored public
keys and the trust ranking is decentralized unlike centralized
PKI approach. OpenPGP [3] is the most widely used email
encryption standard, although the number of keys and signatures present are only 41,294 and 414,424, respectively, as
on February 2009 [4]. Moreover, it is impractical for a user
assigning a trust level for a key every day according to his/her
trust interpretation on the key.
According to the email marketing survey [5], 73% people
in U.S use email daily. In February 2008, Hotmail and Yahoo
Mail had 256.2 million and 254.6 million users respectively
[6]. Gmail had 91.6 million users. AOL which was one
the ﬁrst companies that popularized email, had 48.9 million
users. Although emails have been very popular for users in
their daily life, research in email trust is still in its infant
stage. Some preliminary works has been conducted in the
past. For example, HP [7] email logs within the organization
were analyzed using the email headers to identify different
communities of users. A graph was constructed where the
nodes denote the users and edges represent the emails sent
between the users. This research also tried to identify nodes
with leadership within the communities. A manual trust rating
system has been built using trust email [8] among university
professors and students. A study on email network was done
through the use of their email addresses. There, each email
address is a node and two nodes are linked if there are email
communications between them [9]. The data came from a
university; observations suggest that fellows (students, faculty,
etc.) from the same department communicate more than between different departments, corresponding to the reality and
the strength of trust among email users. Hierarchy in the social
network is also studied through hierarchical clustering [10].
Platforms are built to improve social connectivity within
physical communities. The middleware called MobiSoC is a
platform for mobile social computing applications (MSCAs)
[11], [12]. It can capture, manage, and share the social states
of physical communities. RoadSpeak [13] is a platform in

Vehicular Social Networks (VSNs) that build virtual mobile
communities. Each commuter is able to communicate more
on the road, which gives drivers the ability to join such social
networks while traveling on highways and the opportunity to
communicate with other drivers via voice chat messages.
III. S YSTEM AND M ODELS
Focusing on e-mail, the major challenge is to compute
email-based trust and enable it for real-time mobile applications with security and privacy considerations.
A. Email-based Social Network Relationships
Compared to other social networks, the trust relations of
email-based social networks are embedded in daily email
exchanges and managements. The uniqueness of measuring
email trust is that we do not purposely require emails users to
manually rank trust. We exploit the social behaviors that reﬂect
the natural social trust established through daily email-related
operations among email users. Generally speaking, people are
more serious about their email related activities than other
Internet-based social networks. This is because email systems
are designed for frequent interactive communications, and the
interactions can be used as a natural metric to evaluate trust.
Thus, our research goal is how to measure the interactions
among email users and then establish a quantiﬁable social trust
framework. This is the key advantage of email-based social
networks. We build email-based trust using the following
information associated with an email account:
(i) Contact list and email groups: e.g., when a user replies
to an email address, Gmail automatically puts the email
address in its contact list.
(ii) Email exchange frequency and time frame can be used
to set trust levels. Many recent back-and-forth email
exchanges represent strong bonds among email users.
More recent email exchanges may represent more trust
relations than emails sent several years ago. There can
be a lot of one-way emails to a user, which means it
might come from an email list. Few two-way emails
usually mean a weak trust relationship.
(iii) If a user does not have his/her email address book
organized by relationship types, we can analyze the key
words to categorize the relationship, such as romantic,
friendship, professional, etc.
(iv) Archived emails are usually more important than those
deleted after users read them. Spam ﬁlters can also help
to skim off abused emails when evaluating email trust.
(v) The e-mail service is currently made more personal
because it displays messages more prominently from
people who are more important to you. The inbox you
have today is based on what people send to you, not
what you want to see. In general, email users categorize
the emails from the people that they care about most.
Meaningful folders (e.g., outlook) or labels (e.g., Gmail),
such as friend, family, colleagues, business partner,
customer, club buddies, etc., all represent different levels
of trust.
364

B. Communication Model
The main infrastructure is the EMT server which calculates
the trust levels. An email user who wishes to participate in the
trust checking network needs to register at the EMT server.
The user should be able to communicate using either mobile
devices or computers with internet capability. The EMT server
logs on to the email servers using the credentials supplied by
the registered user. It gathers the email statistics to calculate
the trust rating for the people with whom the registered user
has communicated through email back and forth.
There are three ways of retrieving a registered user’s email
information
1) User opts to trust EMT server. EMT server will communicate with email server and download email information.
2) User relays email information to the EMT server. They
do not want EMT server to manage the client’s email
credentials. They have the ability to control the data that
is being transmitted to EMT server. This necessitates the
usage of a client application at the user’s side.
3) A hybrid system. User can switch between the above
two modes

We enumerate the following possible attacking methods.
Malicious attackers can purposely eliminate the repetitive
task of adding friends to networks and stop forwarding trust
requests issued by other users. A malicious email user can
collude with others, and send trust checking requests to his/her
contacts to explore the trust relations among other email
users, e.g., to check if two email users have a direct trust
relations between them. Attackers can spoof email addresses
and purposely send a number of emails to change the trust
evaluation results between two email addresses.
IV. E STABLISHING E MAIL T RUST
In this Section, we ﬁrst describe the architecture and related
concepts of EMT. Then, we present a mathematical model to
measure EMT through a Gmail service.
A. EMT Architecture
Private trust domain
Personal
Email

Working trust domain
Business
Email

Address

Address

Contacts

Contacts

Crypto keys

Crypto keys

Email Servers
Work
Domain

Public trust domain
2A

Internet

Private Domain

Anonymized
Email
Internet

2A

1A 3A

Address
Internet

EMT Server

Public Domain

Contacts

2B 3B

1A
Internet
3A
Computers (Trusts EMT
server entirely
1A – Give consent to EMT server
to access email data
2A – EMT server gathers email
data from email servers
3A – Pass trust rank results

Fig. 1.

Crypto keys

1B

3B

Example: (private, working, public) email IDs
Alice:
alice@example.net
alice@company.com
A’@gmail.com
Bob:
bob@example.net
bob@company.net
B’@gmail.com

Fig. 2.

2B
Computers (relays email
information)
1B – Get email data from
email server
2B – Relay the email data to
EMT server
3B – Pass trust rank results

Communication Model

An alternative communication model can eliminate the EMT
server. But, the trust calculations have to be performed by the
email servers in different domain. A protocol is needed to
exchange trust information between these servers whenever a
trust checking request arrives.
C. Attack Models
The attackers’ goals are: (1) breaching privacy of email
users, e.g., disclosing email users’ contact list, (2) impersonating an email user with valid or fake email addresses, and (3)
vandalism of the email trust framework. Attackers can be from
many sources. They are interested in putting together a holistic
or partial picture of an email user’s friends and associates.

EMT architecture.

The EMT architecture is highlighted in Figure 2. Trust levels
are set according to users’ email domain based on their usage
scopes, i.e., personal email, business email, and public email
that can be used for anonymizing email IDs. As shown in the
ﬁgure, each block represents a trust domain with respect to a
user’s email addresses with trust-ranked contacts. For example,
the trust levels in a private trust domain can be classiﬁed as:
highly trusted friends, trusted friends, and un-trusted. For the
working domain, similar trust structure or more scrutinized
hierarchical trust models can be applied according to the
underlying business structure.
The trust model of EMT is similar to existing on-line
shopping services such as Amazon [14] and paypal [15] in
that the user needs to tell his private information (i.e., credit
card, email address) to service providers. To use EMT, ﬁrst,
we require users to register in EMT server. The EMT server
is considered as a trusted party and it cannot be compromised
or expose users’ private information. During the registration
procedure, a user needs to provide a mapping between the
pseudo email address and email addresses in the private or

365

$FFRXQW0DSSLQJ

7UXVW5DWLQJ

$FFRXQW1XPEHU (PDLO$GGUHVV

3YWB$GG

3XEB$GG

3VB$GG

3XEB$GG

3VB$GG

3VB$GG



8VHU¶V$FFRXQW1XPEHU





Fig. 3.

&RQWDFW

3XEB$GG
3VB$GG
3YWB$GG


7UXVW5DWLQJ





Pseudonym Map.

working domains. As shown in Figure 3, account number
1 is mapped to private address P vt Add1 , public address
P ub Add1 and pseudo address P s Add1 . The EMT server
will access email servers in each domain to retrieve statistical
data of corresponding registered email accounts. The user can
relay the email information to EMT server in the event of user
not trusting the EMT server entirely. Trust rating of a contact
is usually mapped against the email address of the contact. In
Figure 3, user with account number 1 has a trust rating with
contacts with email address P ub Add2 and P s Add3 . If a
person happens to receive mail from P s Add2 and user with
account number 1 is a trusted contact, the EMT server can
infer that the trust rating for P s Add2 can be obtained from
P ub Add2 . If the default depth of the searching is set to 2,
then EMT server can search one more round. It sends requests
to account 1’s trusted contacts if it cannot ﬁnd a record in
account 1’s trusted list.

Ka

A

EMT Server

Email/MAC Ka(Email)

Email/MACKa(Email)

Fig. 4.

B

Email Veriﬁcation

When user opts to relay email data to the EMT server,
there is a possibility of the user sending fake email data. This
necessitates a veriﬁcation procedure by the EMT server. In
this procedure, each user shares a key with the EMT server.
In Figure 4, user A shares a key Ka with EMT server. When
user A sends an email to user B, A also sends a MAC based
on Ka. When B relays email data to EMT server, the MAC
is also sent. Since, the EMT server is aware of Ka, it can
verify whether the email data sent by B is authentic. The
limitation in this procedure is that the EMT server must have
users registered in order to verify whether email was sent by
them. B can try to retransmit the email data to EMT server
many times to change the trust level between B and A. This
is countered by the EMT server which records the time stamp
of the email sent from A to B. Hence, it can discern duplicate
emails.
B. Trust Query and Evaluation
EMT is based on the peer-to-peer email social network. We
assume each user will be able to run an email trust checking

agent (TCA) software. The TCA is running at the user’s client
device. It performs the following two main operations: (a)
send trust checking requests, and (b) perform trust checking
and ranking. After two users exchange their email addresses,
the TCA will perform trust checking based on each other’s
email addresses through the EMT server. First, EMT server
needs to perform statistical analysis of the email inbox, folders
or labels and contact list with respect to the email address
(ID) whose trust level has to be ascertained. We call this
as tier-1 trust checking. A typical ranking scheme includes
trust levels: (HT) high trust, (T) trust, (NT) no trust, and (U)
unknown. If the EMT server returns HT, T, or NT, the user
will respond depending on pre-setup policies of the function
action(∗), which is deﬁned by user’s running application and
is out of scope of this paper. However, the trust level cannot be
calculated if the user never had a history of interacting through
email with ID. In that case, the TCA returns U. It will form
a trust checking request and send the request to its T and HT
contacts that is represented as a set L(H, HT ).
If the algorithm returns an unknown (U), it will also check
if the request path length (H) exceeds the trust checking hopcount threshold; if not, the EMT server will generate a request
and attaches the increased H to his/her contacts in L(T, HT ),
otherwise, the EMT server will return a “fail to ﬁnd” to the
requester. It is possible that the initial requester might receive
the rank of ID of varying levels from L(T, HT ), which returns
the contacts whose trust level could be U, NT, T, or HT. This
calls for another algorithm to analyze ranks obtained from
L(T, HT ). We call this as tier-2 trust checking.
Tier-1 trust checking: Here, we ﬁrst describe the tier-1 trust
checking. We use i and j to represent two users, and k denotes
a time frame for a sequence of time period {tk |k = 1, . . . , n},
for example each tk represents a month. n is the total time
frames which we consider for the algorithm. In our EMT test,
we look into the emails within 2 years, thus n = 24. Let the
number of emails sent from i to j be Lij , and Lji vice versa.
We calculate an email trust factor γij,k for the period tk for
user i:
⎞
⎛
2
⎠,
γij,k = ⎝ Lij
(1)
Lji
+
Lji
Lij
⎞
⎛
Lij
2
⎠
,
(2)
γij,k = ⎝ Lij
Lji
Lij + Lji
Lji + Lij
⎞
⎛
Lij
2
⎠
γij,k = ⎝ Lij
β.
(3)
Lji
L
ij + Lji
+
Lji

L

Lij

In (1), Lij
is the proportion of emails sent from i to j to
ji
the emails sent from j to i. In general, if Lij roughly equals
to Lji , we can derive the highest mutual trust between i and
j. In other words, (1) captures the evenness of interactions
between i and j. It is easy to prove when Lij = Lji , we
can achieve the maximum γij,k = 1 as shown in Figure 5.
In reality, trust is usually directional. However, (1) provides

366

ϭ

time. This is based on the fact that recent emails exchanges
contribute more trust measure, which is generally true for most
social activities.

Ȗij,k

Ϭ͘ϵ

ȕ=1/0.553

Ϭ͘ϴ
Ϭ͘ϳ
Ϭ͘ϲ

ƋƵĂƚŝŽŶ;ϭͿ

Ϭ͘ϱ

Tij = [log2 (Nij + 2)]γij .

ƋƵĂƚŝŽŶ;ϯͿ

Ϭ͘ϰ

ƋƵĂƚŝŽŶ;ϮͿ

Ϭ͘ϯ
Ϭ͘Ϯ
Ϭ͘ϭ

>ŝũͬ;>ŝũн>ũŝͿсϬ͘ϱ

Ϭ
Ϭ

Ϭ͘Ϯ

Fig. 5.

Ϭ͘ϰ

>ŝũͬ;>ŝũн>ũŝͿсϬ͘ϲ
Ϭ͘ϲ

Ϭ͘ϴ

>ŝũͬ;>ŝũн>ũŝͿ
ϭ

Comparisons of Equations (1) - (3).

same trust evaluation from i to j and vice versa. We usually
consider the trust metric γij,k should be higher when user
i sends more emails to user j. Intuitively, we can emulate
the email trust to page ranking used by Google. However,
page ranking considers the number of incoming links to be
more important to evaluate a web link. On the contrary, EMT
weight more on the number of outgoing links, i.e., the number
of emails originated by a user, which is more reasonable to
evaluate email-based trust. In (2), we provide an adjusted
formula to evaluate γij,k by considering the proportion of
the number of emails sent from i to j to the total number
of emails exchanged between them. In Figure 5, we present
the values of (2) based on the proportion of Lij /(Lij + Lji ).
We can see that γij,k ≈ 0.553 achieves the maximum value
when Lij /(Lij + Lji ) = 0.6. To scale γij,k to 1, we can
simply introduce a scalar β = 1/0.553 in (3), which produces
the curve shown in Figure 5. In summary, (3) takes into
consideration, both evenness and trust directions.
Now, let us consider the total number of emails exchanged
between i and j during tk as Nij,k . We consider that the more
the number of emails exchanged between i and j, the more
the trust between them. This is intuitive since close friends
usually send more emails and close co-workers also send more
emails. To scale down the number of exchanged emails, we
take a base-2 logarithm function on the number of exchanged
emails. The trust evaluations from user i to user j during tk
can be represented as follows:
Tij,k = [log2 (Nij,k + 2)]γij,k .

(4)

In (4), Tij,k = 1 when Nij,k = 0, and Tij,k ≥ 1. The higher
the value of Tij,k , the more trust user i puts on
nuser j. To
evaluate the overall trust in past time period
k=1 tk , we
propose using the following formula:

Trust can also be evaluated without time intervals. In (6), trust
is calculated based on the total number of emails exchanged
between i and j. A mail sent an year ago and an email sent
today has the same importance.
Each of the trust evaluation equations presented in (1) (6) can be used to measure trust with different properties
as we described above for an email system. The user can
always be given an option in choosing the trust evaluation
method in the EMT server. Additionally, we can also refer
to statistical analysis methods, such as mean, variance, and
standard deviation for each trust measure. In Section V-C, we
will discuss the above presented trust measure models and
corresponding statistic properties based on a study of using
Gmail services.
Tier-2 trust checking: When a user receives trust evaluation
replies from his/her trusted contacts, he/she needs to perform
tier-2 trust check to evaluate the overall trust rank of a checked
email ID. Tier-2 trust checking is essentially a distributed
shortest path algorithm that searches the shortest trusted path
(i.e., the most trusted path) towards the searching email ID.
The link weight of a trust path is T or HT except the last
hop to the destination can be UT. The link weight can be
multiplicative or min (or max) depending on the utilized trust
computing algorithm. For example, if we assign T=0.5, HT=1,
NT=0, then a simple multiplicative algorithm can compute the
trust evaluation by:

Tij =
Tij (H).
(7)
H

For min (or max) algorithm, we can compute the trust as
follows:
⎧
⎨ minH {Tij (H)} or
maxH {Tij (H)} last − hop Tij (H) = N T or U
Tij =
⎩
0
otherwise
(8)
Running tier-2 trust checking does not require each user’s TCA
to be online since the trust checking is performed by EMT
server.
V. EMT E VALUATION

n

1  Tij,k
Tij =
.
n
k

(6)

(5)

k=1

Tij is the overall trust rank of i to j for n time intervals. For
a sequence of time intervals k = 1, . . . , n, we represent t1 as
the current time interval and tn as the farthest time interval
from current time. 1/k in (5) takes weight more on the trust
evaluation of a given time interval that is closer to current

To validate the trust model presented in the previous section,
we conduct an EMT evaluation based on Gmail accounts. This
evaluation is performed at Arizona State University (ASU).
Here, we ﬁrst provide an analysis of the possible attacks,
an introduction to our system conﬁguration for the EMT
validation, the corresponding implementations and then we
provide the validation results.

367

A. Robustness on Privacy Exploration Attacks
Consider the scenario where the attacker Alice spoofs email
from Bob (B) to Carol (C) to change the trust evaluation
from Carol to Bob. This changes Carol’s calculation TCB with
respect to Bob. TCB is different for both Bob and Carol. To
counter this attack, we can have a protocol which mandates
that after calculating trust TCB , Carol starts veriﬁcation process with Bob. Bob will be asked to calculate TCB . When
Carol’s TCB do no match with Bob’s TCB , Carol will set
TCB to Bob’s TCB . All these calculations will be conducted
by the EMT server.
The above mentioned attack scenarios will not work in
ﬁnding the discrepancies of trust evaluation value T . First,
let us analyze the corresponding social behaviors of Bob and
Carol. Assume that Bob and Carol are responsible users. When
either of them observes a lot of unnecessary “spoofed” mails,
they will usually delete them. It is prudent to assume that not
all people would show responsible behavior. Second, the other
solution makes use of EMT server, which calculates the trust
ranking. The EMT server has a record of number of mails sent
by Bob to Carol. This was obtained from Bob’s “sent” folder.
This can be compared with the number of emails received by
Carol from Bob. This was obtained from Carol’s inbox.
Now, let us assume Alice is a trusted contact of Bob. Alice
can turn to renegade and try to ﬁnd out the direct trust relations
of Bob. To evaluate the trust performance of EMT model under
this privacy exploration attack, we view the graph generated
by links of contacts as a random graph G(n, p). n denotes the
number of users in G and p is the probability that an edge
exists between two users. Based on Erdős and Rényi [16],
given n and Pc , the probability that a graph is connected, the
degree of a user is deﬁned as:
d=

n−1
(ln(n) − ln(−lnPc )),
n

(9)

and

d
.
(10)
n−1
Assume in the EMT network, n=1,000,000 users and the
network connectivity probability Pc = 0.99999. In other words,
most of the users in the network are connected to each other
through at least one trusted contact. This does not mean that
the trusted contacts are connected through direct trust links.
From (9) and (10), we can ﬁnd that p = 2.532∗10−5 when Pc
= 0.99999 and n=1,000,000. The average of direct trust link
for each user is d ≈ 25. This shows that Alice has very less
probable chance to guess a direct trust link from Bob, even
Bob has about 25 trusted contacts.
p=

B. Validation Setup and Implementations
We developed the EMT server at https://www.wreferral.
com/EmailTrust/faces/index.jsp to perform trust evaluations
for Gmail accounts using the trust measures given in (5). As
shown in Figure 6, the EMT server accesses Gmail server
to retrieve the headers’ information through IMAP protocol.
Additionally, it also accesses the account’s contacts using

Google Contact API. Using EMT server, we can access the
inbox and contact address book which are required for tier-1
trust checking.
TCA

TCA

TCA

IMAP
using
JavaMail
Gmail
Server
Google
Contact
API

...

Tier 1
(TEA)
Tier 2
(Analyze
results from
L(T, HT)
EMT Server

Fig. 6.

Trust checking through Gmail service.

The EMT server caches all the email IDs who had communicated with user i. The duration of time period k is set to 2
months. Overall, 12 time periods were considered, i.e., EMT
server will consider the emails exchanged during the past 2
years. During a time period, Lij and Lji are obtained by using
the search feature in IMAP.
We tested the trust checking for a given email ID in a Gmail
account that is heavily used containing 7,000+ emails and
occupying 4,325MB space. The trust checking takes about 23 seconds to complete. Thus, in a trust evaluation application
that requires minimal time delay, the real time trust checking
may not be a viable solution. However, we can set up a
trust checking proxy service that proactively and periodically
calculates the trust for each known email ID in advance. Once
a trust request is received, the trusted proxy server can simply
check its database and then send replies promptly. Moreover,
using a trust checking proxy service also makes it practical
for tier-2 trust checking since it does not require each user
to be online to help their trusted contacts to search for trust
ranks for a given email ID. However, we must note that the
proxy server must provide high security and privacy protection
against malicious attackers.
C. EMT Validation Results
We conducted a focus group study of Gmail users. We
ran the EMT server for a group of students to extract their
email data from Google email servers. After we derived
the trust measures for the contacts of each user in the test
group, we found that the results match surprisingly well to
our expectations. Statistically, we found that, when the trust
measure is greater than 0.45, students usually consider those
contacts are in the category of HT; when the normalized trust
measure is between 0.3 and 0.45, students usually consider
those contacts are in the category of T. On an average, the
highest T value a contact without trust had 0.23. The average
T value of the most trusted contact was 1.192 among students
who used their email address for communication heavily.

368

In a survey among the test subjects, they responded that
they found their own other email addresses like work or
academic email addresses in the list. These email addresses
needs to be removed by sequence alignment [17]. The subjects
also mentioned that they found contacts at the bottom of the
list whom they trusted. These contacts were communicated
through email less frequently in the recent past. The reason
for such occurrence is that the algorithm considers only the
contacts who were contacted frequently. We can also conclude
the likelihood of false positive is more than false negative.

Fig. 8.

γ measure.

VI. H OW TO D EPLOY EMT FOR T RUST C OMPUTING
A PPLICATIONS

Fig. 7.

Normalized trust measure – indexed by using (3).

In Figure 7, we present the trust measure for a student who
has more than 30 students in the trust level H or level HT.
This ﬁgure is organized using the decreasing order of trust
measure based on the γ values derived from (3). We notice
that the trust measure using (1) is generally higher than the
corresponding trust measure using (3). There are more than
90% of trust measures with both (1) and (3) falling in the same
category T or HT. With students’ feedbacks, the trust measure
presented in Figure 7 shows that considering more weight on
outgoing emails for trust measure (using (3)) will reduce the
trust belief on a given email ID and make the trust measure
more conservative. Thus, we conclude that using (1) and (3)
provides us a way to measure email-based trust for a user
according to his/her personalities: aggressive and conservative,
respectively.
Based on the above discussion, we notice further that the
value of γ contributes signiﬁcantly to a trust measure. In
Figure 8, we present the max-mean-min values of the student’s
γ evaluation using (3). We also notice that towards the left
of the ﬁgure, where the trust measure is HT, about half of
γ values have shorter distance between the max and min
(compared to the right side of the ﬁgure). This also means
that the variance (or standard deviation) of γ evaluation is
small. On the contrary, the right side of Figure 8 shows a
larger variance of γ evaluation. The γ measure with respect to
the variance change conﬁrms our trust measure model given in
(1) where continuous email exchanges in each time intervals
will usually produce high trust measure.

Decentralized business model: For the decentralized business model, we consider that there exist multiple business domains. Each business domain maintains its own trust checking
server provided for its email users. In general, a business domain, usually a company, will control its own email services.
Thus the trust checking can be done by constructing a trust
graph based on the email data in the server. Each user just
sends a trust checking request to their email provider. The
email provider will check the request and see if the checking
email ID is in the same domain and then return the trust
checking value; otherwise, the provider can base on DNS
service and forward the request to another business domain
that can handle the social trust checking. This trust checking
procedure is similar to the procedure of BGP inter-domain
routing protocol. Mutual trust checking agreement is required
to be set up among different business domains.
Centralized business model: Under centralized business
model, a central domain takes care of trust checking for
individuals having emails across different service providers.
This necessitates sharing of private information with the
central domain. This brings up protection of privacy and
security issues. Security of the repository holding the private
information is critical. Moreover, users will have to trust
the central domain in sharing their personal information. An
alternative can be using Cloud Computing services of trusted
parties like IBM or Amazon. They provide reliable and secure
web services. The private information resides in these trusted
parties. So, a user can be assured of security. But, the problem
of the user trusting the application developing entity to share
personal information still persists.
Email body analysis: Emails are sometimes sent by nonhuman entities. For example, a shopping site might send
an email to customers listing new products every month. In
a business environment, a manager might send a monthly
report email to the subordinates and peers. In both cases,
the receiver would not reply to the emails. But, the receiver
would most probably trust the manager and have no trust

369

with the automatic email generator from the shopping site.
The Trust Calculating entity cannot calculate the trust using
the email headers. The email body has to be analyzed to
determine trust rating for these situations. Words like “free”,
“price”, “shipping”, “rebate”, “deals” in an email indicate that
the email was sent from a shopping site. A new subsystem
is needed in the trust calculating application which performs
semantic analysis of the email body.
Adhoc mobile applications: The trust provided through
email services may experience long delay due to network
latencies, and the locations of email trust management entities
to check the contact lists. Some users may choose to keep the
contact list/trust management utilities at the mail servers, so to
enjoy the ﬂexibility of reading emails when they move. Some
users may have local copies. Other users may use whatever
their default conﬁgurations provide. Furthermore, some may
have concerns about their handhelds’ storage and computation
limitations to perform trust checking. If contact lists cannot
be obtained from local copies, network connections to the
EMT server are needed when performing the trust searches
and validations. In some vehicle network scenarios, connection
may be intermittent or short-lived. The possible scenario of the
lack of instant connection suggests that a back-up plan could
enhance the use of email-based trust in vehicular network
applications.
On the other hand, we argue this trust service will be very
useful to jumpstart the vehicular ad hoc network trust at bootstrap phases. Thus, we need to provide reliable connections
for vehicle-to-vehicle and vehicle-to-network communications
that can be used to strengthen the availability of the social
network trust. As the matter of fact, e-mail has become one
of the most important services for mobile users (pedestrians
and drivers). For vehicles in the urban grid, the Internet is just
one hop away. Thus, email based trust can be introduced quick
and helpful.
Applications with pre-setup membership of trust group:
The email trust can be classiﬁed for weak and strong trusts.
Though “human ﬁlters” have been applied when accepting
emails, the inherited security of the email senders, for example,
a buggy client, may be more complicated than what the
frequency or the number of emails implies. For mobile ad hoc
network applications, where a strong trust is a must, a presetup is necessary. This pre-setup procedure should promote
the users to further scrutinize the contact lists proposed by the
email systems (we discussed them as trust agents). For this
reason, such an email-based trust network can be regarded as
a private network, where each node has only a view about
their neighbors (in contrast to social networks like LinkedIn).

paper to rank the relationships among the email IDs. We
present several trust measuring models to conduct a proofof-concept study based on Gmail system.
We must note that the presented research is still at its
preliminary level. There are many factors need to be considered such as the time interval on replying a user’s email, the
folders (or labels) need to be considered in the trust decision.
Protecting users’ privacy still needs further study. Since we
performed the trust evaluation based on students, using tier2 trust checking, the number of hops from a requestor to a
designated email ID is usually within 3 hops (due to page
limit, we omit the validation of tier-2 trust checking). Thus,
a wider-range of email trust testing is required. Moreover,
the inter-operability among multiple email systems should be
also addressed. Furthermore, our future work will study the
issue of incorporating the email trust to a distributed key
management system, so that the trust value can be transformed
into temporal session keys between two mobile users for
secure communication. We expect the social trust through
EMT is highly related to the trustworthiness of data and the
data source.
ACKNOWLEDGEMENT
Authors would like to thank anonymous reviewers for their
constructive comments to improve the quality of this work.
R EFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]

[8]
[9]
[10]
[11]
[12]
[13]

VII. C ONCLUSION AND F UTURE W ORK
The paper presented a system to use the email social
network for calculating trust between pairs of users. The
applications of the scheme include using the trust to validate
the data contents and data sources for pervasive Internet
applications. Our system, an automated software agent, resides
in an email system and uses the algorithm proposed in this

[14]
[15]
[16]
[17]

370

WOT (Web Of Trust), available at http://www.mywot.com/.
S. Garﬁnkel, PGP: pretty good privacy. O’reilly, 1995.
“Open PGP,” http:// www.openpgp.org/ .
“Web of trust statistics and pathﬁnder,” http:// webware.lysator.liu.se/ jc/
wotsap/ wots/ latest/ wotinfo.txt.
“Email and webmail statistics,” Email Marketing Reports http://www.
email-marketing-reports.com/metrics/email-statistics.htm, 2008.
USA Today, “E-mail carriers deliver gifts of nifty features
to lure, keep users,” http:// www.usatoday.com/ tech/ products/
2008-04-15-google-gmail-webmail N.htm, 2008.
Joshua R. Tyler, Dennis M. Wilkinson, Bernardo A. Huberman,
“Email as Spectroscopy: Automated Discovery of Community Structure within Organizations,” http:// www.hpl.hp.com/ research/ idl/ papers/
email/ email.pdf .
J. Golbeck, “TrustMail,” http:// trust.mindswap.org/ trustMail.shtml.
R. Guimera, L. Danon, A. Diaz-Guilera, F. Giralt, and A. Arenas, “Selfsimilar community structure in a network of human interactions,” Phys.
Rev. E, vol. 68, no. 6, p. 065103, 2003.
M. Newman, “Detecting community structure in networks,” The European Physical Journal B-Condensed Matter and Complex Systems,
vol. 38, no. 2, pp. 321–330, 2004.
S. Smaldone, L. Han, P. Shankar, and L. Iftode, “RoadSpeak: Enabling
Voice Chat on Roadways using Vehicular Social Networks,” in Proceedings of MobiHoc, 2007.
C. Borcea, A. Gupta, A. Kalra, Q. Jones, and L. Iftode, “The mobisoc
middleware for mobile social computing: Challenges, design, and early
experiences,” in Proceedings of MobilWare, 2008.
S. Smaldone, L. Han, P. Shankar, and L. Iftode, “Roadspeak: Enabling
voice chat on roadways using vehicular social networks,” in Proceedings of the First International Workshop on Social Network Systems
(SocialNets’08, in conjunction with EuroSys), 2008.
“Amazon,” http:// www.amazon.com/ .
“Paypal,” https:// www.paypal.com/ .
J. H. Spencer, The Strange Logic of Random Graphs (Algorithms and
Combinatorics). Springer Verlag, 2001.
J. Kleinberg and E. Tardos, Algorithm design.
Addison-Wesley
Longman Publishing Co., Inc. Boston, MA, USA, 2005.

Journal of Systems Architecture 54 (2008) 1077–1088

Contents lists available at ScienceDirect

Journal of Systems Architecture
journal homepage: www.elsevier.com/locate/sysarc

FPGA implementations of elliptic curve cryptography and Tate pairing
over a binary ﬁeld q
Hao Li a,*, Jian Huang b, Philip Sweany a, Dijiang Huang c
a

University of North Texas, Department of Computer Science and Engineering, P.O. Box 311366, Denton, TX 76203, USA
School of Electrical Engineering and Computer Science, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL 32816, USA
c
Department of Computer Science and Engineering, Arizona State University Tempe, AZ 85287, USA
b

a r t i c l e

i n f o

Article history:
Received 27 August 2007
Received in revised form 16 April 2008
Accepted 17 April 2008
Available online 27 April 2008
Keywords:
Field programmable gate array
Elliptic curve cryptography
Tate pairing
Parallel processing
Galois ﬁeld arithmetic

a b s t r a c t
Elliptic curve cryptography (ECC) and Tate pairing are two new types of public-key cryptographic
schemes that become popular in recent years. ECC offers a smaller key size compared to traditional methods without sacriﬁcing security level. Tate pairing is a bilinear map commonly used in identity-based
cryptographic schemes. Therefore, it is more attractive to implement these schemes by using hardware
than by using software because of its computational expensiveness. In this paper, we propose ﬁeld programmable gate array (FPGA) implementations of the elliptic curve point multiplication in Galois ﬁeld
GFð2283 Þ and Tate pairing computation in GFð2283 Þ. Experimental results demonstrate that, compared
with previously proposed approaches, our FPGA implementations of ECC and Tate pairing can speed
up by 31.6 times and 152 times, respectively.
Ó 2008 Elsevier B.V. All rights reserved.

1. Introduction
Elliptic curve cryptography (ECC) and Tate pairing are two new
types of public-key cryptography. Using cryptography is an efﬁcient
way to protect conﬁdential information to be sent over an insecure
media, such as the Internet. Galois ﬁeld arithmetic operations are
the bases of both ECC and Tate pairing. ECC and Tate pairing are both
computationally expensive. The FPGA-based implementation can
improve the performance of ECC and Tate pairing compared with
software implementation. In addition, FPGA has the advantage of
ﬂexibility compared to traditional application-speciﬁc integrated
circuit (ASIC) implementation. We used resource sharing and parallel processing in our FPGA implementations of ECC and Tate pairing.
Binary-ﬁeld Galois ﬁeld arithmetic is easier to implement in hardware. Therefore, in this work, our ECC and Tate pairing are based
on a binary ﬁeld.
1.1. ECC
E-commerce has become more and more popular in recent
years. According to the Census Bureau of the US Department of
Commerce [46], retail e-commerce sales for the fourth quarter of
2006 was $29.3 billion. Hence, the security of Web transactions

q Research is supported by Arizona State University Embedded System Consortium (CES) grant #AQS0005.
* Corresponding author. Tel.: +1 940 5654278; fax: +1 940 5652799.
E-mail address: hli@unt.edu (H. Li).
1383-7621/$ - see front matter Ó 2008 Elsevier B.V. All rights reserved.
doi:10.1016/j.sysarc.2008.04.012

is extremely important because a lot of sensitive information is
transmitted over the Internet during these transactions; e.g., credit
card numbers, social security numbers, etc.
Cryptography is the most standard and efﬁcient way to protect
the security of Web transactions. It can be used to protect the conﬁdentiality, integrity, authentication, and non-reputation of the
Web transactions. There are two major categories of cryptography
schemes; i.e., public-key cryptography and symmetric-key cryptography. In public-key cryptography, the receiver and the sender
have their own private key and share a common public key. In
symmetric-key cryptography, the receiver and the sender must
have the same private key, which makes it difﬁcult to manage
the private key. Public-key cryptography is easy for key distribution and key management, but it is not as efﬁcient as symmetrickey cryptography [15,35]. Thus, it is interesting to use dedicated
hardware for public-key cryptography to improve performance.
A well-known public-key cryptographic algorithm is RSA, which
was ﬁrst proposed by Rivest et al. in 1977 [36]. The security of RSA
is based on the difﬁculty of the integer factorization problem. It is
commonly used in the secure sockets layer (SSL) protocol, which is
the most popular way of protecting secure Web transactions nowadays. SSL runs over transportation layer and it secures many
application protocols such as hypertext transfer protocol (HTTP),
telnet, and ﬁle transfer protocol (FTP). However, due to the performance issue of RSA, using SSL usually slows down the Web servers
by three to nine times [6].
ECC is an efﬁcient substitution for RSA. It was originally proposed by Miller [29] and Koblitz [20]. The security of ECC is based

1078

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

on the difﬁculty of elliptic curve discrete logarithm problem
(ECDLP). ECC can improve the performance of SSL because ECC
has a smaller key length yet still provides the same security level
compared with RSA. A smaller key length results in faster computation, lower power consumption, and lower memory and bandwidth. Table 1 shows the equivalent key sizes of ECC and RSA
[14]. Currently, 1024-bit RSA is standard, and it is projected that
its size will increase to 2048 bits after 2010. The performance issues of RSA with such a large key size will then become a dominant
force, which can severely affect the performance of RSA. So, we
would like to use 283-bit ECC in place of the 2048-bit RSA since
it can signiﬁcantly reduce the key length and still provides the
same security level.
Despite ECC’s advantages over RSA, software-based ECC implementations usually require long computation time; hence, it makes
difﬁcult to be effectively utilized in real-time Web-based transactions. To overcome this drawback, we propose an efﬁcient FPGA
implementation of ECC over GFð2283 Þ, where GF stands for Galois
ﬁeld and 2283 means 283-bit binary operation. The key arithmetic
operation in ECC is point multiplication. It determines the performance of the elliptic curve cryptosystem because it is the most
computationally expensive unit.
The main contributions of our FPGA-based design are resource
sharing and parallel processing optimization. The simulation results show that our implementation is signiﬁcantly faster than
the software implementation as well as previous FPGA implementations with the same security level [9,22].

ﬁeld addition, Galois ﬁeld multiplication, Galois ﬁeld squaring, and
Galois ﬁeld inversion. Note, in the rest of this paper, without
explicitly mentioning, the terms such as ‘‘addition”, ‘‘multiplication”, ‘‘squaring”, ‘‘inversion”, etc. are all Galois ﬁeld operations.
Our proposed FPGA implementation of the Tate pairing computation is in GFð2283 Þ. We have designed and implemented the toplevel architecture for Tate pairing in order to optimize resource
sharing. The simulation results show that our FPGA-based implementation is faster than the software implementation as well as
previous hardware implementations [19,27].
The rest of this paper is organized as follows. In Section 2, we review previous hardware-based implementations of both ECC and
Tate pairing. In Section 3, we review the mathematical background
of ECC and Tate pairing. In Section 4, we provide the detailed designs of individual Galois ﬁeld arithmetic units that to be used in later ECC and Tate pairing implementations. In Section 5, we present
the algorithms, architectures, and implementations of ECC and Tate
pairing. We then provide experimental results and compare with
previous approaches. In Section 6, we conclude our work.

1.2. Tate pairing

2.1. Elliptic curve cryptography

Identity-based cryptography schemes have opened a new territory for public key cryptography [5,34,38]. Using identity-based
cryptography schemes, a sender can derive the public key of a receiver without receiving the certiﬁcate of the receiver issued by a
certiﬁcate authority. The public key can be derived from the identity of the receiver such as the email or IP address. Pairing over an
elliptic curve can be used to construct the identity-based cryptography schemes. It is a map from two points on the elliptic curve to
another multiplicative group. It has special properties of bilinearity. Currently, the most commonly used pairing methods are Tate
pairing [10] and Weil pairing [28]. Originally, Weil pairing was
used to attack public key cryptosystems. Later it was used for pairing-based cryptosystems. It can be computed using either Miller
algorithm [30] or modiﬁed Miller’s algorithms [3,4,21]. Tate pairing is more efﬁcient than Weil pairing because it requires one
application of Miller’s algorithm instead of two and it allows a host
of optimizations [25]. Tate pairing is more than two times faster
than Weil pairing [11]. Currently, Tate pairing computation is the
most popular method used in many identity-based cryptography
schemes [5,34,38].
However, Tate pairing is computationally expensive, which
makes it difﬁcult to be efﬁciently implemented using software.
Thus, in this work, we design and implement Tate pairing using
an FPGA over a binary ﬁeld GFð2m Þ. It is more computationally efﬁcient for hardware implementation over a binary ﬁeld compared
with other ﬁelds such as cubic ﬁeld GFð3m Þ because of its simple
underlying algorithms and binary arithmetic [43]. The main arithmetic units needed for the Tate pairing computation include Galois

ECC has become a popular cryptographic scheme in recent year
because it uses smaller key size while maintaining the same level
of security. Hardware implementation of ECC generally yields better performance than software-based implementation. Existing
hardware implementations vary in the following aspects: GFð2m Þ,
GFðpÞ, key lengths (from 163 to 233 bits), and implementation
platforms (FPGA, ASIC, and sensor). In this section, we review some
of the FPGA implementations of ECC over GFð2m Þ.
Orlando and Paar [32] designed a reconﬁgurable elliptic curve
processor (ECP) over GFð2167 Þ. The ECP consists of a main controller, arithmetic unit controller, and arithmetic units. Point multiplication can be computed in 0.21 ms using the Montgomery
algorithm. This work is generally considered the benchmark of
FPGA implementation of ECC. Its main advantages include scalable
hardware architecture and reprogrammable processing units.
Morales-Sandoval and Feregrino-Uribe [31] proposed a hardware architecture that can perform three different ECC algorithms;
i.e., elliptic curve Difﬁe-Hellman (ECDH), elliptic curve digital signature (ECDSA), and elliptic curve integrated encryption scheme
(ECIES). The main functional units in their cryptosystem are coprocessor for scalar multiplication, random number generator, algorithm modules, and main controller. Its scalar multiplication can
be completed in 4.7 ms for GFð2191 Þ.
Leung et al. [22] presented a microcoded FPGA-based elliptic
curve processor. This design is parameterized for arbitrary key
sizes and allows for rapid development of different control ﬂows.
They used a normal basis for the Galois ﬁeld operations, and the
point multiplication can be computed in 14.3 ms for GFð2281 Þ.
Ernst et al. [9] presented a generator-based elliptic curve cryptosystem. The generator program can create customized VHSIC
hardware description language (VHDL) netlists according to different key sizes and multiplier radix. Thus, this work is ﬂexible in validating the correctness of the design. The authors chose the
Massey–Omura ﬁnite ﬁeld multiplier and the double-and-add
algorithm for point multiplication. Their point multiplication can
be computed in 6.85 ms for GFð2270 Þ.

Table 1
Equivalent key sizes between ECC and RSA
ECC

RSA

Protection lifetime

163
283
409

1024
3072
7680

Until 2010
Until 2030
Beyond 2031

2. Previous work
In this section, we ﬁrst brieﬂy review some previous FPGA
implementations of ECC over a binary ﬁeld. Then, we review the
hardware implementations of Tate pairing, including FPGA, ASIC,
and sensor implementations.

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

In addition to the above mentioned hardware implementations,
there exist other FPGA-based implementations for a binary ﬁeld
are described in the literature [1,8,12,17,37,39,42]. A survey study
conducted by Dormale and Quisquater [7] summarizes these
FPGA-based implementations.
2.2. Tate pairing
Tate pairing is relatively a new topic in cryptography; thus,
there are not many existing hardware implementations of it. The
existing implementations also vary from characteristics [GFð2m Þ,
GFð3m Þ, GFðpÞ], elliptic curve types (supersingular, non-supersingular, different embedded degrees). In this section, we brieﬂy review
some hardware implementations for a supersingular elliptic curve
over GFð2283 Þ.
McCusker et al. [27] designed Tate pairing over GFð2283 Þ. The
authors used the algorithm proposed by Kwon [21]. They implemented Galois ﬁeld multiplication, squaring, exponentiation, and
inversion. In addition, they used Karatsuba algorithm [18] for the
Galois ﬁeld multiplication in GFð24m Þ.
Keller et al. [19] also used the Karatsuba algorithm for the Galois ﬁeld multiplier in GFð24m Þ. Karatsuba algorithm uses the
GFð2m Þ multiplier to realize the GFð24m Þ multiplier. They used a digit-serial architecture to design the GFð2m Þ multiplier [44].
Shu [41] and Shu et al. [43] used two modiﬁed Kwon algorithms. They designed squaring, multiplication, inverter, and exponentiation. In addition, they made use of a digit-serial multiplier in
the design. Their implementation can compute the Tate pairing
over GFð2283 Þ quickly. The algorithm used for Tate pairing [43] is
different from the ones used by Keller et al. [19] and McCusker
et al. [27]. In our work, we implemented the algorithms proposed
by McCusker et al. [27].
2.2.1. ASIC implementations
Satoh and Takano [40] presented a processor that can support
both prime and binary ﬁnite ﬁelds for arbitrary prime numbers
and irreducible polynomials. This characteristic is achieved by
introducing a dual-ﬁeld multiplier. A Montgomery multiplier with
an optimized data bus and an on-the-ﬂy redundant binary converter boost the throughput of the elliptic curve scalar multiplication. All popular cryptographic functions such as digital signature
algorithm (DSA), EC-DSA, RSA, CRT, and prime generation are also
supported. Scalar multiplication can be performed in 0.19 ms in
the binary ﬁeld F 2160 .
Sozzani et al. [45] presented a hardware implementation of ECC
that includes some parallelism to maximize the usage of the ﬁeld
function units. They combined the double-and-add algorithm with
the Montgomery algorithm to compute two different kP scalar
multiplications in parallel. They have carried out modiﬁcations of
the scheduling to synchronize the control units according to the
availability of resources. The coprocessor is synthesized in 0.13lm CMOS technology. For 163-bit points, the scalar multiplication
can be completed in 0.027 ms on average of two independent kP
scalar multiplications.
2.2.2. Sensor implementations
Malan et al. [26] presented the ﬁrst known implementation of
ECC over F 2p for sensor networks based on the 8-bit, 7.3828-MHz
MICA2 mote. Using instrumentation of the University of California
at Berkeley’s TinySec module, the authors argued that there was a
need for an efﬁcient, secure mechanism for distribution of secret
keys among nodes. And through their analysis of the implementation for TinyOS of multiplication of points on elliptic curves, public-key infrastructure is viable for TinySec key’s distribution. They
demonstrated that public keys can be generated within 34 s, and
that shared secrets can be distributed among nodes in a sensor net-

1079

work within the same, using just over 1 kb of static random access
memory (SRAM) and 34 kb of read-only memory (ROM). Polynomial base is used for the implementation. The key size is 163 bits.
Wang et al. [47] described a public-key implementation of access control in a sensor network. The authors implemented ECC
over a primary ﬁeld, a public-key cryptographic scheme. Their
implementations are conducted on TelosB mote (TPR2400), which
is the latest product in the Mote family. The experiment results
show that the ﬁxed point multiplication can be completed in
3.13 s, random point multiplication can be completed in 3.51 s,
and the digital signature can be completed in 3.35 s. All of these
implementations are based on a 160-bit elliptic curve.

3. Background
In this section, we review the mathematical background of both
ECC and Tate pairing, including point addition and point doubling,
bilinearity of pairing, and security of ECC and Tate pairing.
3.1. ECC
According to the group law of points on elliptic curve E, both
point addition and point doubling need a Galois ﬁeld inversion
[15]. Galois ﬁeld inversion is much more expensive than Galois
ﬁeld multiplication. Using projective coordinates can eliminate
the use of Galois ﬁeld inversion in point addition and point doubling. The point addition and point doubling in projective coordinates can be computed as follows [24]:
 Point addition in projective coordinates:

Z 3 ¼ ðX 1  Z 2 þ X 2  Z 1 Þ2

ð1Þ

and

X 3 ¼ x  Z 3 þ ðX 1  Z 2 Þ  ðX 2  Z 1 Þ

ð2Þ

where ðX 3 ; Z 3 Þ is the result of the point addition in the projective
coordinates and ðX 1 ; Z 1 Þ and ðX 2 ; Z 2 Þ are the projective coordinates
of P and Q, respectively.
 Point doubling in projective coordinates:

Z ¼ X 41 þ b  Z 41

ð3Þ

and

X ¼ Z 21  X 21

ð4Þ

where ðX; ZÞ is the result of the point doubling in the projective
coordinates, and ðX 1 ; Z 1 Þ are the projective coordinates of P.
The security of ECC is based on the difﬁculty of the problem
ECDLP [31]. ECDLP is designed to ﬁnd d, given points P, Q on the
elliptic curve, where Q ¼ dP.
3.2. Tate pairing
The central idea of pairing is to map points from an additive
group to a multiplicative group. The major pairing-based construct
is the bilinear map. Considering two groups G1 and G3 , we denote
G1 using additive notation and G3 using multiplicative notation.
The bilinear map can be denoted by

^e : G1  G1 ! G3

ð5Þ

And bilinear map has the following three properties:
Bilinearity: ^eðaP; bQ Þ ¼ ^eðP; Q Þab 8P; Q 2 G1 8a; b 2 ZdP .
This can be restated in the following way. For P; Q ; R 2 G1

^eðP þ Q; RÞ ¼ ^eðP; RÞ  ^eðQ ; RÞ

ð6Þ

1080

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

and

^eðP; Q þ RÞ ¼ ^eðP; Q Þ  ^eðP; RÞ

ð7Þ

Non-degeneracy: if ^eðP; Q Þ ¼ 1 for all Q 2 G1 , then P must be the
identity element in G1 .
Computability: the bilinear map ^
e is efﬁciently computable.
The pairing operation ^
e : G1  G1 ! G3 is a mapping from addition group G1 to multiplicative group G3 . It is built on elliptic curve
theory, where a set of solutions (x, y) to an equation of the form
y2 ¼ x3 þ Ax þ B, together with an extra point 1, which is called
the point at inﬁnity. This set of points on the elliptic curve forms
a group under a certain addition rule. The point 1 is deﬁned as
the identity element of the group, where P 2 G1 , P 2 EðFq Þ, P is
the generator of G1 , and dP is the smallest value to satisfy
dP P ¼ 1 and we call dP as the order of point P. We can use Eqs.
(6) and (7) to further derive the following equation:

^eð2P; PÞ ¼ ^eðP þ P; PÞ ¼ ^eðp; pÞ  ^eðp; pÞ ¼ ^eðp; pÞ2 ¼ ^eðP; P þ PÞ
¼ ^eðP; 2PÞ

ð8Þ
3

Similarly, we can derive ^eð3P; PÞ ¼ ^eðP; PÞ ¼ ^eðP; 3PÞ. Therefore, we
have

^eðaP; bPÞ ¼ ^eðP; PÞab ¼ ^eðabP; PÞ ¼ ^eðP; abPÞ

ð9Þ

Eq. (9) is very important in pairing-based cryptography. We will
demonstrate how it can be used in various applications in later section. In this paper, we use the supersingular elliptic curve

Eb : Y 2 þ Y ¼ X 3 þ X þ 1

ð10Þ

So, the points on Eb are the additive group G1 in Eq. (5). Therefore,
we will need elliptic curve addition, elliptic curve double, point
multiplication in G1 , and ﬁnite ﬁeld multiplication for G3 . We will
use projective coordinates for the elliptic curve computations. Detailed arithmetic of the elliptic curve will be introduced later.
The security of many pairing-based cryptosystems is based on
the hardness of some related problems; i.e., bi-linear Difﬁe-Hellman problem (BDHP), computational Difﬁe-Hellman problem
(CDHP), and discrete logarithm problem (DLP) [33].
4. Implementations of Galois ﬁeld arithmetic units
In this section, we present the FPGA implementations of Galois
ﬁeld arithmetic units, including adder, squarer, multiplier, reduction, exponentiation, and inverter. These units are the bases of both
ECC and Tate pairing. We describe the experimental results of all
these arithmetic units.
4.1. Adder in a Galois ﬁeld
The addition unit in a Galois ﬁeld is straightforward to implement over a binary ﬁeld. One of the advantages of implementing
the Tate pairing computation over a binary ﬁeld is that it can be designed by using an array of exclusive or (XOR) gates.
4.2. Squarer in GFð2283 Þ
We have designed a bit parallel squarer that is much faster than
multiplying two binary polynomials [48]. Assume that the binary
P
i
polynomial is aðxÞ ¼ 282
i¼0 ai x ; then the squaring formula can be
calculated using the following equation [15]:

aðxÞ2 ¼

282
X

ai x2i

ð11Þ

ing x283 by x12 þ x7 þ x5 þ 1. Therefore, the squarer is simply a set of
XOR arrays to recombine the coefﬁcients of a(x), and the gate count
is proportional to the polynomial bit [43], which is 283 in our case.
4.3. Multiplier in GFð2283 Þ
Multiplication is a basic computation for Tate pairing computation. There are many algorithms for computing it. We use the digit
serial multiplier introduced in [15]. The advantage of this digit serial multiplier over the most-signiﬁcant bit (MSB) multiplier is that
it can increase the speed of the multiplication operation. The digit
serial multiplier requires a reduction modulo. The algorithm to design the digit serial multiplier is shown below:
Algorithm 1: Digit serial multiplier for GFð2m Þ
P
Pl1 ki
m
m
i
INPUT: a ¼ m1
i¼0 ai z 2 GFð2 Þ, b ¼
i¼0 Bi z 2 GFð2 Þ, reduction polynomial f ðzÞ.
OUTPUT: c ¼ a  b
Set c ¼ 0
for i ¼ 0 to l  1 do
c ¼ c þ Bi a
a ¼ a  zk mod f ðzÞ
end for
return c mod f ðzÞ

In Algorithm 1, l ¼ dm=ke, k is the digit size, and l is the number
of digits. In our implementation, we set m ¼ 283, k ¼ 32, l ¼ 9.
Using the digit serial multiplier can improve the performance of
the Galois ﬁeld multiplier compared to the bit serial multiplier.
4.4. Reduction in GFð2283 Þ
The reduction function is used in designing a multiplier. We
adopt the fast reduction modulo algorithm with digit size of 32 in
our implementation [15]. The pseudocode is shown in Algorithm 2.
Note that C½i is a 32-bit word of cðzÞ; i.e., cðzÞ ¼ ðC½17; C½16;
. . . ; C½0Þ, which is at most 564 bits long and the reduction result consists of ðC½8; C½7; . . . ; C½0Þ, which has a bit width of 283. The reduction modulo is composed of shift registers, XORs, and AND gates. Our
reduction modulo can ﬁnish the computation in four clock cycles.
Algorithm 2: Fast reduction modulo
f ðxÞ ¼ x283 þ x12 þ x7 þ x5 þ 1 in GFð2283 Þ (with W ¼ 32)
INPUT: A binary polynomial cðzÞ of degree at most 564
OUTPUT: cðzÞ mod f ðzÞ
for i ¼ 17 downto 9 do
T ¼ C½i
C½i  9 ¼ c½i  9 þ ðT  5Þ þ ðT  10Þ þ ðT  12Þþ
ðT  17Þ
C½i  8 ¼ c½i  8 þ ðT 	 27Þ þ ðT 	 10Þ þ ðT 	 12Þþ
ðT 	 17Þ
end for {Reduce C½iz32i modulo f ðxÞ}
T ¼ C½8 	 27. {Extract bits 27  31 of C½8}
C½0 ¼ C½0 þ T þ ðT  5Þ þ ðT  7Þ þ ðT  12Þ
C½8 ¼ C½8&0x7FFFFFF. {Clear the reduced bits of C½8}
return ðC½8; C½7; . . . ; C½1; C½0Þ

4.5. Multiplier in GFð21132 Þ

i¼0

Because we use f ðxÞ ¼ x283 þ x12 þ x7 þ x5 þ 1 as the reduction polynomial, we can obtain the formula of the coefﬁcients of aðxÞ2 by replac-

We use the Karatsuba multiplier [18] presented by Keller et al.
[19] to implement the multiplier in GFð21132 Þ. In this work, the

1081

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

GFð21132 Þ is deﬁned over the polynomial x3 þ x2 þ x þ 1. It uses nine
283-bit multipliers and 22 XORs to implement one 1132-bit multiplier. The architecture of the Karatsuba multiplier is shown in
Fig. 1. Using the Karatsuba multiplier can improve the performance
of the Tate pairing computation, but it also increases the chip area
because it uses nine multipliers in GFð2283 Þ.
4.6. Exponentiation in GFð21132 Þ
The ﬁnal exponentiation of the Tate pairing computation is to
2283
1
, where cðxÞ 2 GFð21132 Þ. The deﬁnition of
compute cðxÞ2
1132
Þ is provided in Section 4.5. We divide the exponentiation
GFð2
into two steps. The ﬁrst step is to compute the exponentiation of
2283
, and the second step is to compute the inversion of
cðxÞ2
cðxÞ1 and then multiply it with the exponentiation computed in
the ﬁrst step.
The exponentiation can be computed using a Frobenius map
[27]. Let cðxÞ ¼ c0 þ c1 x þ c2 x2 þ c3 x3 . Note that cðxÞ 2 GFð21132 Þ
and coefﬁcients c0 ; c1 ; c2 ; c3 2 GFð2283 Þ. Then

cðxÞ2

283

¼ ðc0 þ c1 Þ þ ðc2 þ c3 Þx þ ðc1 Þx2 þ c3 x3

ð12Þ

The exponentiation operation only requires addition and reordering
of the coefﬁcients. Therefore, the exponentiation in GFð21132 Þ can be
implemented using the inverter in GFð21132 Þ and a few XORs.
4.7. Inverter in GFð2283 Þ
Inversion, the most complex operation in Galois ﬁeld arithmetic, is based on Fermat’s little theorem [13]. Let a be a non-zero ele283
ment in GFð2283 Þ, then a1 ¼ a2 2 . We can see that 2283  2 ¼
P282 i
i¼1 2 . Thus,
282
P

2

i

a1 ¼ a i¼1 ¼

282
Y

a2

i

tmp1 ¼ a2

1

m1
2 1

¼ ða2

Þ2

m1
2

2

¼ tmp1  ðtmp1Þ2

tmp2 ¼ a

4

tmp3 ¼ a2

8

tmp4 ¼ a2

16

1

¼ tmp3  ðtmp3Þ2

tmp5 ¼ a2

17

1

¼ a  ðtmp4Þ2

tmp6 ¼ a2

34

1

¼ tmp5  ðtmp5Þ2

tmp7 ¼ a2

35

1

¼ a  ðtmp6Þ2

tmp8 ¼ a2

70

1

¼ tmp7  ðtmp7Þ2

tmp9 ¼ a2

140

¼ tmp2  ðtmp2Þ2

1

1

283

17

ð14Þ

35

70

¼ tmp8  ðtmp8Þ2

1

¼ a  ðtmp9Þ2

282

1

¼ tmp10  ðtmp10Þ2

tmp11 ¼ a2

a1 ¼ a2

8

141

tmp10 ¼ a2

2

141

¼ ðtmp11Þ2

where tmp1 to tmp11 are 283-bit registers used to store temporary
data for the inversion operations. We can see from Eq. (14) that the
inversion only needs 11 multiplications and 282 squarings.
4.8. Inverter in GFð21132 Þ
The inverter in GFð21132 Þ is the most complex unit among all the
arithmetic units. It can be implemented with one inverter in
GFð2283 Þ, one multiplier in GFð21132 Þ, and one exponentiation in
GFð21132 Þ. The algorithm to compute inversion in GFð21132 Þ is
shown below:
Algorithm 3: Inversion in GFð24m Þ
1:
2:
3:
4:
5:
6:
7:

ð13Þ

According to Eq. (13), the inversion can be implemented using 282
squarings and 281 multiplications. Actually, the number of multiplications can be reduced because of the following features
[15,16]. When m is odd
m1

¼ a  a2

1

24 1

i¼1

a2

2

INPUT: a 2 GFð24m Þ
OUTPUT: b ¼ a1 , b 2 GFð24m Þ
4m
2
Compute ar1 , here r ¼ 22m 1
Compute ar ¼ ar1 a
Compute ðar Þ1
Compute b ¼ ðar Þ1 ar1
return b

m1
2 1

a2

m1

m2

When m is even, a2 1 ¼ aða2 1 Þ2 .
Based on the above, we derive the following formula to compute the inversion in GFð2283 Þ:
a1 a3 b1 b3 a2 a3 a0 a1 b0 b1 b2 b3 a0 a2 b0 b2

Algorithm 3 is derived from Eq. (15), which was proposed by
McCusker et al. [27]

a1 ¼ a2

4m

2

¼ ðar Þ1 ar1

where m ¼ 283, r ¼
r

24m 2
2m 1

m

ð15Þ
and

4m

a 2 GFð2 Þ; a 2 GFð2 Þ
Line 3 in Algorithm 3 can be computed as follows:
283

283

283

ar1 ¼ ðða2 aÞ2 aÞ2

ð16Þ

Thus, it can be implemented with three exponentiations in
GFð21132 Þ and two multiplications in GFð21132 Þ.
Line 4 in Algorithm 3 is a multiplication in GFð21132 Þ. Line 5 is
implemented with an inverter in GFð2283 Þ because ar 2 GFð2283 Þ.
Line 6 is also a multiplication in GFð21132 Þ. So the entire inversion
algorithm in GFð21132 Þ can be implemented with one inverter in
GFð2283 Þ, one multiplier in GFð21132 Þ, and exponentiations in
GFð21132 Þ.

a0 b0 a1 b1 a2 b2 a3 b3

multiplier

4.9. Experimental results

XOR
c0

c1

c2

c3

Fig. 1. Karatsuba multiplier architecture for GFð21132 Þ.

We ﬁrst synthesize all the arithmetic units by using Xilinx ISE
8.2i. The target FPGA device is Virtex 4 XC4VFX140-FF1517-11.
The maximum frequency and the device utilization summary of

1082

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

xk ¼ X 1 =Z 1

Table 2
Device utilization summary of Galois ﬁeld arithmetic units
Arithmetic unit
Multiplication GFð2
Multiplication
GFð21132 Þ
Squaring GFð2283 Þ
Reduction GFð2283 Þ
Inverter GFð2283 Þ
Inverter GFð21132 Þ

283

Þ

ð17Þ

and

Maximum frequency
(MHz)

CLBs

FFs

LUTs

246.670
248.447

1781
25,955

2156
32,578

3367
48,591

675.676
346.981
160.817
122.592

306
787
7354
33,594

317
825
6999
43,746

567
1439
13,944
54,988

yk ¼ ðx þ xk Þ½ðy þ x2 Þ þ ðX 2 =Z 2 þ xÞðX 1 =Z 1 þ xÞ  ð1=xÞ þ y

the individual arithmetic units are shown in Table 2. Columns 3
through 5 list the number of conﬁgurable logic block (CLB), ﬂip-ﬂops
(FFs), and lookup-tables (LUTs), respectively. The inverse in
GFð21132 Þ is the most complicated unit. It uses 33,594 slices, accounting for 52% of the whole chip area, because the inverse in GFð21132 Þ
consists of the inverse in GFð2283 Þ and multiplication in GFð21132 Þ.
Squaring uses the least area among all the arithmetic units.
From Table 2, we observe that the synthesis will not meet area
constraints if we instantiate the inverter in GFð21132 Þ as well as the
multiplier in GFð21132 Þ. Therefore, we share the multiplier in
GFð21132 Þ and the inverter in GFð2283 Þ to implement the inverter
in GFð21132 Þ. By doing so, the area constraints are satisﬁed.
5. Algorithms, architectures, and implementations of ECC and
Tate pairing
In this section, we discuss the algorithms, architecture, and
implementations of both ECC and Tate pairing. The experimental
results are also described in this section. In addition, we compare
our work with software implementations and previous FPGAbased implementations.
5.1. Algorithm for ECC
Point multiplication is to compute kP, where k is an integer and
P is a point on an elliptic curve E deﬁned over a ﬁeld F q . In our design, the Weierstrass equation for ECC is y2 þ xy ¼ x3 þ ax2 þ b,
which is non-supersingular. Point multiplication, also called scalar
multiplication, dominates the execution time of ECC schemes.
There are several algorithms for point multiplication over an elliptic curve. In our design, we use the Montgomery point multiplication algorithm for the implementation of point multiplication
[15,24,39]. The pseudocode is shown below:

5.2. Architecture for ECC
In this subsection, we present the design hierarchy of ECC, the
top-level architecture of elliptic curve cryptosystem, and the
implementation of point multiplication unit.
5.2.1. Design hierarchy
The design hierarchy of a typical elliptic curve cryptosystem is
shown in Fig. 2. The top level of the system contains cryptographic
protocols. In an ECC-based SSL connection, the ECC-based cipher
suite uses ECDH for key exchange, and ECDSA for authentication
of the public key. Point multiplication is used in both of the ECDH
and ECDSA protocols. The secondary level in the design hierarchy is
point multiplication. Point multiplication is composed of point
doubling, and point addition. Point multiplication, point doubling,
and point addition are operations involving the points on the elliptic curve. The bottom level of the ECC system is Galois ﬁeld arithmetic including Galois ﬁeld multiplication, Galois ﬁeld inversion,
and Galois ﬁeld squaring. Our design focuses on all but the protocol
level of the elliptic curve cryptosystem.
5.2.2. Top level architecture and point multiplication
The top-level architecture of a typical elliptic curve cryptosystem is illustrated in Fig. 3. It is composed of main controller, register ﬁles, and point multiplier. The main controller is used to realize
speciﬁc cryptographic protocols, such as ECDSA or ECDH. The point
multiplier consists of point adder, point doubler, and conversion
module, and its implementation is our focus in this work. Details
of the implementation of point multiplier are described in the next
section.
The diagram of the point multiplier is shown in Fig. 4. Based on
the Montgomery point multiplication algorithm, the point multiplier is composed of point adder, point doubler, coordinates converter, squarer, and XORs.
We use two Galois ﬁeld multipliers, one Galois ﬁeld squarer,
and XORs to implement point adder. Point doubler is composed
of two Galois ﬁeld squarers, one Galois ﬁeld multiplier, and XORs.
The coordinate converter is more complicated than point adder
and point doubler. It consists of two Galois ﬁeld multipliers, one
Galois ﬁeld squarer, one Galois ﬁeld inverter, and XORs. In our

Algorithm 4: Montgomery point multiplication algorithm
INPUT: An integer k ¼ ðkn1 ; kn2 ; . . . ; k1 ; k0 , kn1 ¼ 1Þ, a point
Pðx; yÞ 2 EðGFð2m ÞÞ
OUTPUT: Q ¼ kP
Set X 1 ¼ x; Z 1 ¼ 1; X 2 ¼ x4 þ b; Z 2 ¼ x2
for i ¼ n  2 downto 0 do
if ki ¼ 1 then
PointadderðX 1 ; Z 1 ; X 2 ; Z 2 Þ, PointdoubleðX 2 ; Z 2 Þ
else
PointadderðX 2 ; Z 2 ; X 1 ; Z 1 Þ, PointdoubleðX 1 ; Z 1 Þ
end if
end for
return Q ¼ Mxy ðX 1 ; Z 1 ; X 2 ; Z 2 Þ

Protocols
(ECDH, ECDSA)
Point
multiplication

Point addition
and point doubling

Note that ‘‘Pointadder” and ‘‘Pointdouble” in Algorithm 4 are
computed using Eqs. (1)–(4). Mxy is the function to convert the projective coordinates to afﬁne coordinates [1]. Its output, the coordinate of point Q, xk and yk , can be computed as

ð18Þ

Galois field arithmetic

Fig. 2. Hierarchy of the typical elliptic curve cryptosystem.

1083

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

X1

Register Files

Z2

X2

Main
Controller

Z1

t1
Point Multiplier

t2

t1

t2

Multiplier

Fig. 3. Top-level view of the elliptic curve cryptosystem.

t3

work, all the arithmetic units are designed in GFð2283 Þ. The data
ﬂows we used to design the point adder, point doubler, and coordinate converter are shown in Figs. 5–7, respectively, where
t1; t2; t3, and t4 are all 283-bit registers. One of the major objectives in our design is to optimize the parallel processing of the
Montgomery point multiplication unit to speed up the circuit
speed. Meanwhile, we devise to share the arithmetic units in order
to reduce chip area.
The block diagram of point multiplier is shown in Fig. 8. One
point double, one point adder, one ﬁnite ﬁeld inversion and two ﬁnite ﬁeld multipliers are instantiated in the point multiplier module. The control unit controls the ﬂow of the computation. The
deﬁnitions of ports are shown in Table 3 and the state diagram
of the point multiplier is shown in Fig. 9.

t4

x

XOR
Z3
Squarer
Z3

t3
X3

Fig. 5. Data ﬂow of point adder.

Z1

X1

5.3. Experimental results of ECC
We have implemented and simulated the elliptic curve point
multiplication with Xilinx’s FPGA device. To show the effectiveness
of hardware implementation over the software-based approach,
we have also realized the design in software. We ﬁrst provide
the setups used in our work, then compare our FPGA-based design
with several previous works, and then show the differences between software and hardware implementations.

SQU GF(2

m

SQU GF(2

XORs
Point Addition

XORs

SQU GF(2

m

Z
t1

Squarer

X

Fig. 6. Data ﬂow of point doubler.

We have synthesized all arithmetic units, including point multiplication, point addition, point doubling, and coordinate converter. The device utilization summary of the individual
arithmetic units is provided in Table 4. The second column lists
the maximum frequency to run each unit individually. The rest
of the columns list the number of CLB slices, ﬂip-ﬂops (FFs) and
lookup-tables (LUTs), respectively. Note that point addition, point
doubling, and point multiplication are all performed in GFð2283 Þ.

m

)

m
MUL GF(2 )
2

SQU GF(2

m

)

XORs

XORs

Point Double

m
INV GF(2 )
Coordinates Converter

)

t2

XOR

m
MUL GF(2 )

)

b

t1

5.3.2. FPGA implementation
The hardware implementation is simulated by ModelSim XE and
synthesized with Xilinx ISE 8.2i. The target device is Xilinx Virtex 4
XC4VFX140-FF1517-11. The optimization goal during synthesis is
set as ‘‘speed”, and the optimization effort is set to ‘‘normal”.

2

t2

Multiplier

5.3.1. Software implementation
The software implementation of the elliptic curve point multiplication is done by using C++ and LiDIA. LiDIA is a C++ library of
computational number theory [23]. The simulation of the point
multiplication in GFð2283 Þ is based on Algorithm 4 and carried
out on a Pentium4 2.8-GHz desktop with 1 gigabyte (GB) memory.
The source codes are compiled by the GNU Compiler Collection
(GCC) version 4.1.1. The running time to perform a single Tate pairing operation is 9.6 ms.

m
MUL GF(2 )

t1 t2

t1

m
Point Multiplier GF( 2 )

Fig. 4. Architecture of the point multiplier.

2

1084

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

Z1, Z2, x

IDLE
t1, t2, t3
t1 X2 t2 x

X1

req = 1
REV

Multiplier

xk

XOR

x

x

t2

t1

y

t4

INIT
t2
t4

Squarer

t1

no

k i =1
Inverter

t4

ready = 1

yes
t3

t4

COMP0

COMP1
y

t4

yk
Fig. 7. Data ﬂow of the coordinate converter.

counter = m–1

no/counter++

yes
ready

clk

MXY

x_out [M–1:0]

reset

y_out [M–1:0]

req
Point Multiplier

k [M–1:0]

FINISH

x [M–1:0]
y [M–1:0]
Fig. 8. Block diagram of the point multiplier for GFð2m Þ.

Table 3
Deﬁnitions of ports of the point multiplier
Name

Direction

Deﬁnition

clk
Reset
req
k[M-1:0]
x[M-1:0]
y[M-1:0]
Ready
x_out[M-1:0]
y_out[M-1:0]

Input
Input
Input
Input
Input
Input
Output
Output
Output

System clock
System reset, low active
Request signal for multiplication
The integer for multiplication
x coordinate of point on E in afﬁne coordinates
y coordinate of point on E in afﬁne coordinates
Ready signal
Output result in afﬁne coordinates
Output result in afﬁne coordinates

We have also simulated the elliptic curve point addition, point
doubling, coordinate converter, and point multiplication in both
software and hardware. The simulated latencies for these operations are shown in Table 5. Here, latency is the time to perform

Fig. 9. State diagram of the point multiplier for GFð2m Þ.

one speciﬁc arithmetic operation. The k values in our simulation
have the same number of 1s and 0s in the binary representation.
According to Table 5, the FPGA implementation of the point
multiplication is 31.6 times faster than the software implementation. We compare the simulated latency with the work of [22,9]
and show the results in Table 6. Our FPGA implementation of
the point multiplication is 47 times faster than that in Leung’s
work (14.3 ms) and 22.5 times faster than that in Ernst’s work
(6.85 ms).
5.4. Algorithm for Tate pairing
Typically, Tate pairing can be computed by using Miller’s
algorithm [30] or modiﬁed Miller’s algorithms [2,4,21]. These
algorithms are usually developed by mathematicians in number
theory. The algorithm we chose to compute Tate pairing is shown
in Algorithm 5 [27]. This algorithm can be divided into four phases:
initialization (lines 1–3), accumulation (lines 5–18), squaring (lines
19–20), and exponentiation (line 22).

1085

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088
Table 4
Device utilization summary of ECC
Arithmetic unit

Maximum frequency (MHz)

CLBs

FFs

LUTs

Point addition
Point doubling
Coordinate converter
Point multiplication

283.728
281.861
183.968
171.247

7412
5378
15,009
30,001

9016
6031
16,129
36,142

13,826
10,341
27,753
51,094

clk

xp [m–1:0]

reset

yp [m–1:0]

req
ready

Register Files

xq [m–1:0]

Main
Controller

yq [m–1:0]
Arithmetic Units

r [m–1:0]

cx [4m–1:0]

Fig. 10. Top-level architecture for Tate pairing in GFð2m Þ.

Table 5
Speedup of hardware over software

Table 7
Port deﬁnitions of the Tate pairing module

Operation

FPGA latency, ls

Software latency, ls

Speedup

Name

Direction

Deﬁnition

Point addition
Point doubling
Coordinate converter
Point multiplication

0.6
0.41
24
304

29
21
58
9600

48
51
2.4
31.6

clk
Reset
req
xp[M-1:0]
yp[M-1:0]
xq[M-1:0]
yq[M-1:0]
r[M-1:0]
Ready
cx[4M-1:0]

Input
Input
Input
Input
Input
Input
Input
Input
Output
Output

System clock
System reset, low active
Request signal
x coordinate of point P
y coordinate of point P
x coordinate of point Q
y coordinate of point Q
Reduction polynomial
Ready signal
Computation results

Table 6
Comparisons of latency of point multiplication
Design

Key size

Latency (ms)

Leung et al. [22]
Ernst et al. [9]
Our work

281
270
283

14.3
6.85
0.304

IDLE
req = 1
Algorithm 5: Algorithm for Tate pairing over GFð2m Þ
1: INPUT: P ¼ ðxp ; yp Þ; Q ¼ ðxq ; yq Þ
2: OUTPUT: CðxÞ
3: INITIAL CðxÞ ¼ c3 x3 þ c2 x2 þ c1 x1 þ x1 ¼ 1
4: for i ¼ 1 to m do
5: xp ¼ x2p ; yp ¼ y2p
6: z ¼ xp þ xq
7: m1 ¼ xp xq
8: w ¼ z þ m1 þ yp þ yq þ 1
9: m2 ¼ c0 w; m3 ¼ ðc2 þ c3 Þðz þ 1Þ
10: m4 ¼ ðc1 þ c2 þ c3 Þw
11: m5 ¼ ðc0 þ c2 þ c3 Þðw þ z þ 1Þ
12: m6 ¼ c3 ðz þ 1Þ
13: m7 ¼ ðc1 þ c2 Þðw þ z þ 1Þ
14: c00 ¼ m2 þ m3 þ c3
15: c01 ¼ m2 þ m4 þ m5 þ m6 þ c0 þ c3
16: c02 ¼ m2 þ m4 þ m5 þ m7 þ c1
17: c03 ¼ m4 þ m7 þ c2
18: c0 ¼ c00 , c1 ¼ c01 , c2 ¼ c02 , c3 ¼ c03
m1
19: xq ¼ x2q
2m1
20: yq ¼ yq
21: end for
2m
22: CðxÞ ¼ CðxÞ2 1
23: return CðxÞ

ACCU

SQUA

ready = 1

EXP

FINISH

Fig. 11. State diagram of the Tate pairing computation.

tiation, and inverters are optional; however, they can be utilized to
improve the performance. In our implementation, we use all of
these functional units.
5.5. Architecture for Tate pairing

Using Algorithm 5, we compute Tate pairing for a supersingular
elliptic curve over GFð2m Þ. The inputs are two points P and Q on
elliptic curve Eb . P and Q are m-bit binary sequences. The output
is CðxÞ. The coefﬁcients of CðxÞ – i.e., c3 ; c2 ; c1 ; c0 – are the pairing
results, which are 4 m-bit binary sequences in the multiplicative
group of G2 ; and c3 ; c2 ; c1 , and c0 are m-bit sequences. Based on
the above discussion, we can ﬁgure out that the Tate pairing computation requires at least one Galois ﬁeld multiplier in both GFð2m Þ
and GFð24m Þ, and XOR. Other operations such as squarer, exponen-

In this section, we present the top-level architecture of Tate
pairing and architecture of arithmetic units. We also show the
experimental results of Tate pairing and compare our work with
software implementation and previous FPGA implementations.
5.5.1. Top-level architecture
The top-level architecture of Tate pairing, shown in Fig. 10, is
composed of the main controller, register ﬁles, and arithmetic
units. The main controller can be designed by using a ﬁnite state

1086

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

m

MUL GF(2 )
RED GF(2

m

Table 8
Device utilization summary of Tate pairing

4m
INV GF(2 )
m
INV GF(2 )

2
)

m
MUL GF(2 )
SQU GF(2

m

)

2

SQU GF(2

XORs

m

)

MUL GF(24m )
m
MUL GF(2 )

Arithmetic Units

Maximum frequency
(MHz)

CLB
slices

FFs

LUTs

Multiplication
GFð2283 Þ
Multiplication
GFð21132 Þ
Squaring GFð2283 Þ
Reduction GFð2283 Þ
Inverse GFð2283 Þ
Inverse GFð21132 Þ
Tate pairing GFð2283 Þ

246.670

1781

2156

3367

248.447

25,955

32,578

48,591

675.676
346.981
160.817
122.592
159.758

306
787
7354
33,594
55,844

317
825
6999
43,746
57,753

567
1439
13,944
54,988
104,860

9
inverter in GFð2283 Þ, one multiplier in GFð21132 Þ, and XORs to implement the arithmetic units. Fig. 12 also illustrates the hierarchy of
the arithmetic units. The inverter in GFð21132 Þ, the most complex
unit, consists of one inverter in GFð2283 Þ and one multiplier in
GFð21132 Þ. The inverter in GFð2283 Þ is composed of one multiplier
and one squarer. We adopt the Karatsuba multiplier for GFð21132 Þ,
which is implemented with nine multipliers in GFð2283 Þ [19]. The
multiplier, a digit serial multiplier [15], consists of a modulo to reduce the degree to 283. Both the squarers and the adders can be
computed in one clock cycle in our implementation.
We use two multipliers and two squarers because they optimize
the parallel computation in the accumulation part and the squaring
part of the Tate pairing algorithm. The data ﬂow of the accumulation part of the Tate pairing algorithm is shown in Fig. 13. For the
squaring part, two squarers are also optimal because xq and yq
can be squared simultaneously. In the ﬁnal exponentiation part,
we use the Frobenius map and one inverter in GFð21132 Þ, but we
do not really instantiate the inverter in GFð21132 Þ. Instead, we share
the inverter in GFð2283 Þ and the multiplier in GFð21132 Þ to implement
the inverter in GFð21132 Þ. The detailed implementations of these
arithmetic units will be presented in the following sections.

Fig. 12. Architecture of the arithmetic units.

machine (FSM) to control state transitions. Register ﬁles are implemented using ﬂip-ﬂops available on the FPGA chip. Let m ¼ 283,
the arithmetic units we have designed include multipliers in
GFð2m Þ and GFð24m Þ, exponentiation in GFð24m Þ, inverter in
GFð2m Þ and GFð24m Þ, squarer in GFð2m Þ, reduction in GFð2m Þ.
The port deﬁnitions are shown in Table 7. The ports can be categorized as control signals, data signals, and system signals. Control signals include req and ready. Data signals include
xp; yp; xq; yq; cx, and r. The reduction polynomial r used in our design equals x283 þ x12 þ x7 þ x5 þ 1, which is recommended by ANSI
[15]. System signals include clk and reset. The state diagram of the
Tate pairing computation, shown in Fig. 11, consists of states such
as IDLE, ACCU (accumulation), SQUA (squaring), EXP (exponentiation), and FINISH. These states correspond to the various parts described in Algorithm 5.
5.5.2. Architecture of arithmetic units
The architecture of the arithmetic units in our design shown in
Fig. 12 is designed in such a way that we can share functional units
to minimize chip area. The majority of operations are carried out in
GFð2283 Þ. So from this point on, an arithmetic unit will be in
GFð2283 Þ by default unless speciﬁed otherwise. We use two multipliers (MUL), two squarers (SQU), an inverter (INV) in GFð21132 Þ, an

xp

Arithmetic unit

xp

yp

5.6. Experimental results of Tate pairing
We present the experimental results of Tate pairing for both
software implementation and FPGA implementation in this
section.

yp
stage1

xq
xq

Squarer

c1

yp

xp

xp

c2

c2

c3

xp

xq

1

stage2
Multiplier

m1

tmp1 tmp2

z

1

tmp6

c3
tmp1 c0

tmp1 c1

yq

tmp2

yp

stage3

c0

XOR

m3

w

m6

w

w

tmp3
tmp4

m2

m3

c3

m2

m5m6 c0
m2 m4
c3

m4 m5 m7
m2
c1

m7
m4
c2

m4

tmp5

stage4
tmp6

tmp5

stage5
c0

c1

c2

c3

m5

Fig. 13. Data ﬂow for accumulation of Tate pairing.

m7

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

1087

5.6.1. Software implementation
The software implementation of the Tate pairing computation is
done by using C++ and LiDIA. We have simulated the Tate pairing
computation over GFð2283 Þ based on Algorithm 5 on a Pentium 4
2.8-GHz computer with 1 GB memory. The source codes are compiled by GCC version 4.1.1. As a result, the running time to perform
one Tate pairing operation is 90 ms.

reduction modulo algorithm. It is not clear what kind of reduction
modulo algorithms [19,27] used. In addition to increasing the
speed for individual arithmetic units, we also optimize the parallel
processing of the Tate pairing algorithm due to the data
dependencies.

5.6.2. FPGA implementation
The hardware implementation of Tate pairing in GFð2283 Þ is
written in Verilog. The designs are simulated using ModelSim XE
and synthesized using Xilinx ISE 8.2i. The target device is Xilinx
Virtex 4 XC4VFX140-FF1517-11. The optimization goal of the synthesis is set as speed, and the optimization effort is set to normal.
We ﬁrst conduct synthesis on each arithmetic unit. The device
utilization summary of the individual arithmetic units is shown
in Table 8. The inverse in GFð21132 Þ, the most complicated unit, uses
33,594 slices, which accounts for 52% of the whole chip area, because the inverse in GFð21132 Þ consists of the inverse in GFð2283 Þ
and multiplication in GFð21132 Þ. Squaring uses the least area among
all the arithmetic units.
Then we synthesize the Tate pairing computation with these
arithmetic units. The device summary for Tate pairing computation
is also given in Table 8.
We have simulated all arithmetic units to evaluate the latency
for each operation. Here, latency is the time to perform one speciﬁc
arithmetic operation. To compare the latency of our work with that
of [27], we also set the simulation frequency at 250 MHz. The latency of each arithmetic unit is shown in Table 9. Here, speedup
means how much faster our work is than previous work.
According to Table 9, on average, our work is 2.6 times faster
than McCusker’s work [27]. We also estimated latency of our
implementation based on the model proposed by Keller et al.
[19]. We compare the estimated latencies with the work of Keller
et al. [19,27] and show the results in Table 10. This is 2.5 times faster than that in Keller’s work (1.48 ms), and 1.4 times faster than
that in McCusker’s work (0.84 ms). In addition, the latency of our
FPGA-based implementation is 152 times faster than that of software implementation (90 ms). FPGA implementation is faster than
software implementation because Tate pairing is processed in parallel in the FPGA implementations. In contrast, the Tate pairing
algorithm is implemented in a sequential fashion in the software
implementation. Our work is faster than the previous work of Keller et al. [19] and McCusker et al. [27] because we increase the
speed for individual Galois ﬁeld arithmetic units. For example,
we use a digit serial multiplier with digit size as 32 and use a fast

In this article, we have studied hardware implementation of
elliptic curve point multiplication to speed up secure Web transactions. We propose an FPGA-based implementation in GFð2283 Þ optimizing the data ﬂow based on data dependency. Our
implementation is signiﬁcantly faster than those previous works
presented in the literature. We also compared the FPGA implementation to its corresponding software implementation. The experimental results show that the hardware-based implementation
can improve the latency by a factor of 31.
ECC and Tate pairing are new techniques in public-key cryptography. ECC is an efﬁcient substitution to RSA, which is one of the
most commonly used public-key cryptographic schemes nowadays. ECC has shorter key sizes with the same security level compared to RSA. Shorter key sizes will save power and bandwidth and
improve performance. Tate pairing is used for identity-based cryptosystem. Using Tate pairing, the public key can be derived from
the identity information without issuing certiﬁcates. Both ECC
and Tate pairing are built upon Galois ﬁeld arithmetic. Because
they are very computationally expensive, we used FPGA to implement them. Through parallel processing and resource sharing, we
are able to improve the performances signiﬁcantly compared to
the software-based implementations.
In addition to ECC, we have also explored hardware implementation of Tate pairing. We proposed an FPGA-based implementation for a Tate pairing computation in GFð2283 Þ. Experimental
results show that, on average, the arithmetic units in our work
run 2.6 times faster than in previous work [27]. The estimated latency of our implementation is 1.4 times faster than that in [27],
and 2.5 times faster than that in [19]. We also compared the FPGA
implementation with its software implementation. The results
show that the FPGA implementation can speedup the latency by
a factor of 152. The reason that our implementation is faster is that
we used parallel processing for the Tate pairing algorithm because
of the data dependencies, and we used fast algorithms for the individual Galois ﬁeld arithmetic units such as digit serial multiplier
and fast reduction modulo. We also used resource sharing in our
design to meet the area constraints.

6. Conclusion

References

Table 9
Latency comparisons of arithmetic units
Operation

McCusker et al. [27] (ns)

Ours (ns)

Speedup

Multiplication GFð2283 Þ
Multiplication GFð21132 Þ
Squaring GFð2283 Þ
Inverse GFð2283 Þ
Inverse GFð21132 Þ

897
940
4
10,769
14,666

218
254
4
5758
6518

4.11
3.7
1
1.87
2.25

Table 10
Comparisons of estimated latency of Tate pairing
Reference

Latency (ms)

Speedup over software

Keller et al. [19]
McCusker et al. [27]
Our work

1.48
0.84
0.59

60
107
152

[1] B. Ansari, M.A. Hasan, High performance architecture of elliptic curve scalar
multiplication, Technical Report, Center for Applied Cryptographic Research,
2006.
[2] Paulo S.L.M. Barreto et al., Efﬁcient algorithms for
pairing-based
cryptosystems, in: CRYPTO’02: Proceedings of the 22nd Annual International
Cryptology Conference on Advances in Cryptology, 2002, pp. 354–368.
[3] Paulo S.L.M. Barreto et al., Efﬁcient implementation of pairing-based
cryptosystems, Journal of Cryptology 17 (2004) 321–334.
[4] Paulo S.L.M. Barreto et al., Efﬁcient pairing computation on supersingular
Abelian varieties, Cryptology ePrint Archive.
[5] D. Boneh, M. Franklin, Identity-based encryption from the Weil pairing, in:
21st Annual International Cryptology Conference, 2001, pp. 213–229.
[6] C. Coarfa et al., Performance analysis of TLS Web servers, in: Network and
Distributed Systems Security Symposium, 2002, pp. 553–558.
[7] G.M. de Dormale, J.-J. Quisquater, High-speed hardware implementations of
elliptic curve cryptography: a survey, Journal of Systems Architecture 53
(2007) 72–84.
[8] H. Eberle et al., A cryptographic processor for arbitrary elliptic curves over
GFð2m Þ, Application-Speciﬁc Systems, Architectures and Processors (ASAP)
(2003) 444–454.
[9] M. Ernst et al., Rapid prototyping for hardware accelerated elliptic curve
public-key cryptosystems, in: Proceedings of the 12th International Workshop
on Rapid System Prototyping, 2001, pp. 24–29.

1088

H. Li et al. / Journal of Systems Architecture 54 (2008) 1077–1088

[10] G. Frey, H.-G. Ruck, A remark concerning m-divisibility and the discrete
logarithm in the divisor class group of curves, Mathematics of Computation 62
(1994) 865–874.
[11] S.D. Galbraith et al., Implementing the Tate pairing, in: ANTS-V: Proceedings of
the 5th International Symposium on Algorithmic Number Theory, 2002, pp.
324–337.
[12] C. Grabbe et al., A high performance VLIW processor for ﬁnite ﬁeld arithmetic,
in: IPDPS’03: Proceedings of the 17th International Symposium on Parallel and
Distributed Processing, 2003, p. 189b.
[13] J. Guajardo, C. Paar, Itoh–Tsujii Inversion in Standard Basis and Its Application
in Cryptography and Codes, Designs, Codes and Cryptography 25 (2002) 207–
219..
[14] V. Gupta et al., Performance analysis of elliptic curve cryptography for SSL, in:
3rd ACM Workshop on Wireless Security, 2002, pp. 87–94.
[15] D. Hankerson et al., Guide to Elliptic Curve Cryptography, Springer, 2004.
[16] T. Itoh, S. Tsujii, A fast algorithm for computing multiplicative inverses in
GFð2m Þ using normal bases, Information and Computation 78 (1988) 171–177.
[17] K. Jarvinen, A scalable architecture for elliptic curve point multiplication, IEEE
Field Programmable Technology (FPT), 2004, pp. 303–306.
[18] A. Karatsuba, Y. Ofman, Multiplication on many-digital numbers by automatic
computers, Translation in Physics-Doklady 7 (1963) 595–596.
[19] M. Keller et al., FPGA implementation of a GFð24m Þ multiplier for use in pairing
based cryptosystems, Field Programmable Logic and Applications (2005) 594–
597.
[20] N. Koblitz, Elliptic curve cryptosystems, Mathematics of Computation 48
(1987) 203–209.
[21] S. Kwon, Efﬁcient Tate pairing computation for elliptic curves over binary
ﬁelds, in: Australasian Conference on Information Security and Privacy, 2005,
pp. 134–145.
[22] K.H. Leung et al., FPGA implementation of a microcoded elliptic curve
cryptographic processor, in: IEEE Symposium on Field-Programmable
Custom Computing Machines, 2000, pp. 68–76.
[23] LiDIA Group, Darmstadt University of Technology, LiDIA – A Library for
Computational Number Theory, 2007. <http://www.cdc.informatik.tudarmstadt.de/TI/LiDIA/>.
[24] J. Lopez, R. Dahab, Fast multiplication on elliptic curves over GFð2m Þ without
precomputation, Cryptographic Hardware and Embedded Systems (1999)
316–327.
[25] B. Lynn, ECC Programming, n.d. <http://rooster.stanford.edu/~ben/maths/ep/
tate.html>.
[26] D.J. Malan et al., A public-key infrastructure for key distribution in TinyOS
based on elliptic curve cryptography, in: First Annual IEEE Communications
Society Conference on Sensor and Ad Hoc Communications and Networks,
2004, pp. 71–80.
[27] K. McCusker et al.,
Low-energy ﬁnite ﬁeld arithmetic primitives for
implementing security in
wireless sensor networks, in: International
Conference on Communications, Circuits and Systems, 2006, pp. 1537–1541.
[28] A. Menezes et al., Reducing elliptic curve logarithms to logarithms in a ﬁnite
ﬁeld, in: STOC’91: Proceedings of the 23rd annual ACM symposium on Theory
of computing, 1991, pp. 80–89.
[29] V.S. Miller, Use of elliptic curves in cryptography, Advances in Cryptology
(1985) 417–426.
[30] V.S. Miller, Short programs for functions on curves, Unpublished Manuscript,
1986.
[31] M. Morales-Sandoval, C. Feregrino-Uribe, On the hardware design of an elliptic
curve cryptosystem, in: Proceedings of the 5th Mexican International
Conference in Computer Science, 2004, pp. 60–70.
[32] G. Orlando, C. Paar, Ahigh-performance reconﬁgurable elliptic curve processor
for GFð2m Þ, in: Second International Workshop on Cryptographic Hardware
and Embedded Systems – CHES, 2000, pp. 41–56.
[33] K.G. Paterson, Cryptography from pairings: a snapshot of current research,
Information Security Technical Report, vol. 7, 2002a, pp. 41–54.
[34] K.G. Paterson, ID-based signatures from pairings on elliptic curves, Electronic
Letters (2002) 1025–1026.
[35] C.P. Pﬂeeger, S.L. Pﬂeeger, Security in Computing, Prentice-Hall, 2006.
[36] R. Rivest et al., A method for obtaining digital signatures and public-key
cryptosystems, Communications of the ACM 21 (1978) 120–126.
[37] M.C.Rosner,
Rosner, Elliptic Curve Cryptosystems on Reconﬁgurable
Hardware, Department of Electrical and Computer Engineering, Worcester
Polytechnic Institute, 1998.
[38] R. Sakai et al., Cryptosystems based on pairing, in: Symposium on
Cryptography and Information Security, 2000, pp. 26–28.
[39] N.A. Saqib et al., A parallel architecture for fast computation of elliptic curve
scalar multiplication over GFð2m Þ, in: Proceedings of the International Parallel
and Distributed Processing Symposium (IPDPS’04), 2004, p. 144a.
[40] A. Satoh, K. Takano, A
scalable dual-ﬁeld elliptic curve cryptographic
processor, IEEE Transactions on Computers 52 (2003) 449–460.
[41] C. Shu, Hardware architectures of elliptic curve based cryptosystems over
binary ﬁelds, Ph.D. thesis, George Mason University, Fairfax, Virginia, 1998.
[42] C. Shu, Low latency elliptic curve cryptography accelerators for NIST curves on
binary ﬁelds, IEEE Field-Programmable Technology (FPT), 2005, pp. 309–310.

[43] C. Shu et al., FPGA accelerated Tate pairing based cryptosystems over binary
ﬁelds, in: IEEE International Conference on Field Programmable Technology,
2006, pp. 173–180.
[44] L. Song, K. Parhi, Low energy digit-serial/parallel ﬁnite ﬁeld multipliers,
Kluwer Journal of VLSI Signal Processing Systems 19 (1998) 149–166.
[45] F. Sozzani et al., A parallelized design for an elliptic curve cryptosystem
coprocessor, in: Proceedings of the International Conference on Information
Technology: Coding and Computing (ITCC’05), vol. 1, 2005, pp. 626–630.
[46] US Department of Commerce, Quarterly Retail E-Commerce Sales, 2007.
<http://www.census.gov/mrts/www/data/html/06Q4.html>.
[47] H. Wang et al., Elliptic curve cryptography based access control in sensor
networks, International Journal of Security and Networks Sensor Networks 1
(2006) 127–137.
[48] H. Wu, Bit-parallel ﬁnite ﬁeld multiplier and squarer using polynomial basis,
IEEE Transactions on Computers 51 (2002) 750–758.

Hao Li is currently an assistant professor of Computer
Science and Engineering Department at the University
of North Texas. He received Ph.D. degree in Computer
Science and Engineering from the University of South
Florida. He received B.S. in Telecommunication Engineering and M.S. in Electrical Engineering from Beijing
University of Posts and Telecommunications. His
research interests include FPGA synthesis and design,
hardware security, and electronic design automation.

Jian Huang received M.S. in Computer Science and
Engineering from the University of North Texas. He is
currently pursuing Ph.D. in Electrical Engineering at the
University of Central Florida. His research interests
include VLSI architecture for cryptography and reconﬁgurable computing.

Philip Sweany associate professor in UNT’s Computer
Science and Engineering Department, maintains a
research focus in both compiler optimization for architectures exhibiting ﬁne-grained parallelism and application of compiler optimization algorithms to
automated synthesis of net-centric systems.

Dijiang Huang is an assistant professor in the School of
Computing Informatics (SCI) at the Arizona State
University. He received the B.S. degree in Telecommunications from Beijing University of Posts & Telecommuni- cations, China 1995, M.S. degree in Computer
Science and Ph.D. in Computer Networking from the
University of Missouri-Kansas City, USA, 2001 and 2004,
respectively. His current research interests are computer networking, security, and privacy.

Distributed Data-theft Detection in Wireless Sensor
Networks
Mukesh Jagasia and Dijiang Huang
Arizona State University
Abstract—Data theft in wireless sensor networks could prove
disastrous and most of the time gets undetected due to no
apparent abnormal behavior of malicious nodes. To counter such
attacks, we propose an anomaly based distributed data-theft
detection protocol. Our approach works at the MAC layer by
effectively measuring the MAC control packets. In this paper,
we present a novel detection metric, a centralized and a gossipbased distributed protocol whereby a network can self-heal itself
of such malicious nodes. Our performance evaluation defines how
we measure the rate of detection and false positives rate and
shows that our approach to detect malicious nodes is reliable,
inexpensive and accurate.

I. I NTRODUCTION
Wireless sensor networks are susceptible to many types
of attacks because of reasons such as deployment in open
and unprotected environment, an inherently broadcast wireless
medium and lack of centralized control. Attacks could involve
external and internal attackers with the latter being more
difficult to detect. An attack like data theft does not leave
any evidence behind and does not have a visible signature as
attacks like DoS has. Cryptographic solutions can help tackle
data confidentiality and secrecy but not data theft or internal
attackers because a compromised node can still gain access to
the sensed data, regardless of type of keys used by the sender.
Consider an example of battlefield monitoring [1], national border monitoring (to prevent illegal immigrants) or
an acoustic counter-sniper system [2], the stringent security
requirements of which are heavily stressed and where the
benefits and motivation of attacking the network are very high
from an adversary’s perspective. An attacker may not be able
to physically attack the network, but he can create an overlay
of malicious nodes, within the existing network infrastructure,
who camouflage themselves well, to ensure their activities go
undetected. The attacker can then analyze the captured data
and mount a more powerful active attack later. Even if the
data packets flowing through the network are encrypted and
the malicious nodes fail to break into the secret key distribution
scheme deployed, the adversary can still get to know the
network topology, number of sensors deployed, sensor density
and their traffic patterns to make tactical decisions accordingly
and mount a more powerful attack in the near future.
We propose detection of such malicious nodes to be at the
MAC layer because, it is believed, they would continue to
adhere to the IEEE 802.11 DCF based RTS/CTS protocol
and reliably forward the sensed/received traffic towards the
destination sink. The malicious nodes would want to limit
the suspicion of their wrong doing rather than attempting a
short-lived attack such as disrupting network traffic, choking

network bandwidth or causing network congestion that could
lead to their faster detection and expulsion from the network.
In this paper, we introduce a distributed, scalable, cooperative and lightweight data-theft node detection protocol by
measuring MAC layer control packets. Our approach includes
both clustering and distributed approaches and we explore
its applicability using the popular MAC protocols for sensor
networks, such as S-MAC [3], B-MAC [4] and T-MAC [5]. If
a malicious node tries to take advantage of the sleep-wakeup
scheduling in S-MAC by remaining awake during its sleep
schedule and attempting to forward data towards the attacker,
it will not find any peer node to help it do data forwarding as
all peers in the cluster would be sleeping then. The probability
of having enough malicious nodes to collude to do hop-by-hop
data forwarding during their sleep schedule is very less. Our
performance analysis shows that detecting malicious nodes
using our distributed approach has relatively higher detection
rates, less false positives and minimum overhead.
The salient contributions of this paper are two-fold:
1) Defining, measuring and analyzing rate of detection of
malicious nodes doing data theft, false positive rate and
overhead associated with the protocol. The distributed
version supports piggybacking the unicast suspicion
exchange of nodes to ensure a low energy solution for
resource-constrained wireless sensor networks.
2) Resiliency to node replication attacks (i.e. clone attacks) [6] and Sybil attacks [7].
The rest of the paper is organized as follows: In Section II
we highlight the selected related research initiatives. In Section
III, we define the network architecture and the attack model.
We present our solution in Section IV. We then present the
performance of our schemes in Section V and conclude our
paper in Section VI.
II. R ELATED W ORK
There has been a lot of work done in the area of detection of malicious nodes and eliminating them from the
network [8], [9], but none targets the data theft attack.
Reputation-based [10] evaluates credit rating for nodes using
elaborative methods involving a reputation parameter table
and reputation management module which seem to involve a
lot of computation for resource-constrained sensors. CONFIDANT [11] sends off alarms that might alert malicious nodes
and they might exercise caution while our solution adopts
a more silent approach by exchanging suspicions bilaterally.
CORE [12] does complex prioritization of owner’s suspicions
versus neighbor’s suspicions; a malicious node is malicious for
all and should be expelled from the network once detected; unnecessary prioritization should be avoided. Data theft detection

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

should involve studying communication patterns and not data
values [13], [14]. In [15], [16], the authors talked about malicious nodes that change route information and thus get caught;
malicious nodes aiming at data theft would not do something
this blatant to get caught so easily. While in [17] the authors
put forward a very interesting concept of ”bad mouthing”, its
approach towards counting ”good” recommendations fails to
hold ground when malicious nodes collude with each other.
Complex attacks leaving larger footprint such as network
congestion, disruption, jamming, spamming and altering data
values tackled in [18] [19] are easier to detect than data theft
which is harder to detect as proven even by forensic analysis
for carefully designed malicious software [20].
In [21], the authors categorized malicious activities in a
wireless sensor network at various layers of the protocol stack
including jamming attack and uses RSSI to detect suspicious
activity. Solutions relying on RSSI [9], [21] are vulnerable to
background noise and weather conditions leading to a high
degree of false positives.
The solutions presented in [22] come quite close to our
approach of using MAC layer primitives to detect masquerade
attacks in wireless sensor networks. In [23], the authors
proposed to involve multiple layers in detection and prevention
of DoS attacks in wireless sensor networks but without any
solid criteria or evaluation in place. Decentralized approach
in [24] covers active attacks like jamming, blackhole, selective
forwarding but does not define how does it measure detection
efficiency or false positive rates.
III. S YSTEM AND M ODELS
In this section, we present the network model and attack
models that will be utilized and evaluated in this paper.
A. Network Model
Our centralized protocol assumes a cluster-based wireless
sensor network; clusters are formed and then cluster-heads are
elected [25]. Each node sends the sensed data to the elected
cluster head via forwarding through its immediate neighbors.
Each node knows its neighbors (nodes within its transmission
range). We advocate rotation of cluster head amongst the nodes
in a cluster. The criteria and algorithm for selecting a cluster
head is beyond the scope of this paper; any of the existing
schemes can work with our solution. While we do not enforce
any particular MAC layer protocol, we do impose IEEE 802.11
DCF behavior in the wireless MAC.
For purposes of simplicity, it is assumed that all nodes in
the network are homogeneous with respect to the processing
and networking components. Our distributed protocol does
not need clustering and is scalable with respect to number of
nodes in the network and number of neighbors of a node. We
assume deployment of nodes for our experiments as provided
by TinyOS simulator but do not lay any limitations on the
exact layout of nodes. Routing protocol considerations do not
arise as this is a L2 layer approach. Each node would do a
local directed dissemination of messages to a subset of its
neighbors, to avoid an infinite loop by sending data back to
its neighbor from whom it received. This helps our distributed

protocol where we can employ piggybacking of suspicious
node IDs and conserve energy of the nodes. Alternatively, a
node could send packets, one at a time; this approach works
well with a security model that entails each node having a
unique pair-wise key with each of its neighbors. Our malicious
node detection protocols require live data communication in a
peer-to-peer manner to maintain a channel via which exchange
of mutual suspicions can be done; any communication strategy
would work fine with our solutions.
In-network processing like data aggregation can been delegated to cluster-heads (if any) who aggregate sensor readings
and forward a single aggregated packet to the sink. We can
safely assume that the base station is physically guarded and
cannot be compromised and that the nodes are stationary.
Message loss due to channel error in the RF medium can be
assumed to be uniform for all nodes, including the malicious
ones. Any attempt of the malicious node attempting to hide its
alternate communication path with the attacker in the disguise
of corrupted/unacknowledged/lost packets due to channel error
would prove futile since monitoring nodes would be aware of
the channel error as they themselves would be involved in
the communication. The application can have multiple sinks
that can significantly reduce latency since network area can be
covered faster and since there is no mobility in our network,
accurate and coordinated self-organizing placement of sinks
would ensure each sink gets a disjoint area of network to
service.
We can safely rule out spatial aggregation as an event would
be localized and nodes may not archive messages to analyze
new incoming messages and then proceed to aggregate them.
B. Attack Model
The attack we are interested in is data theft - something
that harms the network to a great extent but does not leave
behind a trail to detect it. Malicious nodes may be transmitting
just not sensed/forwarded data but vital information like list
of neighbors, location information, etc. that might help the
attacker understand the span and structure of the network
and open up risks for more precise and effective attacks.
Given a network, there could be zero or more malicious nodes
that are either erstwhile good nodes compromised by the
attacker or malicious nodes deployed by the attacker through
some means. The attack technique is that a malicious node
would raise multiple RTS to forward data packets (e.g. one
towards the sink and one towards the attacker). Once granted
CTS, however, it can not use the same to transmit multiple
messages, one to the intended receiver and the other(s) to
the attacker because the CTS is meant for just a single data
packet. Malicious nodes should be smart enough to prevent
easy detection and would thus continue to perform normal
sensor-related and network operations, adhering to the rules
of the MAC protocol just as other nodes do. It is in the best
interests of the malicious node to make the forwarding of data
packets towards the attacker, look as genuine data forwarding.
It may or may not have fellow malicious nodes within its
transmission range to collude with and this does not affect or
influence our protocol in any way.

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

IV. P ROPOSED M ETHODOLOGY
The proposed methodology consists of defining a new
MAC layer-based detection metric and protocols for detecting
malicious nodes.
A. Detection Metric: Number of RTS raised
Any node A monitoring another node B could get suspicious about B’s behavior if it raises comparatively large number of RTS per unit time. The cluster head (in cluster-based
approach) or neighboring nodes (in distributed approach) are
able to monitor nodes with its transmission range due to the
inherent broadcast wireless medium and are aware of the
approximate number of messages (and hence number of RTS
raised) per unit time depending on the node’s relative location
within the network, the event driven application on hand and
the event probability. Any additional RTS raised due to channel
error and message retransmissions can be considered genuine
as these conditions would be uniform for all nodes in the
neighborhood, including the malicious ones. Beyond these, if a
node attempts to communicate more than it should would raise
a flag. Both the following approaches allow for administratorconfigurable thresholds of the detection metric based on the
application.

Algorithm 1 Distributed Malicious Node Detection protocol
for node Bi
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:

INPUT: Node neighbor list for node Bi , Ni
List of suspicions Si = NULL {Initialize the list of suspicions}
Input queue of messages received by node Bi Qi = NULL
Count of RTS raised by each neighbor in list Ni by node Bi Ci = 0
while T IM ER = 0 do
listenForAndCollectMACMessages(Qi )
end while
for j = 1 to number of messages received in the queue, Qi .length do
msg ⇐ Qi [j]
if msg.type == RTS then
Ci [msg.nodeID] ++
end if
end for
for k = 1 to number of neighbors, Ni .length do
if Ci [k] ≥ MAX RTS THRESHOLD then
Si ⇐ Si + Bk
end if
end for
for k = 1 to number of neighbors, Bk in the neighbor list Ni - Si do
sendSuspicionList (Si , Bk )
Sk ⇐ recvSuspicionList (Bk )
for m = 1 to number of number of suspicions in received list, Sk
do
if Bm ∈ Ni then
Sk ⇐ Sk - Bm {Ignore the suspicion that is not my neighbor}
end if
end for
Si ⇐ Si + Sk {Update my suspicion list with those of my neighbors}
end for
OUTPUT: Suspicion List Si for node Bi

B. Centralized Malicious Node Detection Protocol
In this approach, the cluster head is the arbitrator of RTS
requests and it decides which node should be given CTS to
transmit data. This solution assumes the cluster-head is not
malicious. With cluster head rotation, before leaving, a cluster
head would transfer its suspicions based on the proposed
measurement criteria to the newly appointed cluster head.
Based on an empirically computed threshold, the suspicious
node could then be branded as a malicious node. A cluster
head could choose to relinquish its position to someone else,
asynchronously, to get rid of the malicious node faster which
might need a ”vote” from more than one cluster head.
C. Distributed Malicious Node Detection Protocol
Having a centralized solution is often attractive as it is
relatively easy but is a single point of failure and does not
scale well. Having the cluster head(s) make decisions seems
flawed if we consider the case when the cluster head itself is
compromised (before or after it is appointed the cluster head)
- then the malicious cluster head can easily send sensitive
data that is relayed via itself to the attacker, mark innocent
nodes as malicious, eliminate them out of the network and
allow entry to newer malicious entities in the network thereby
compromising complete network security. This motivated the
design of a distributed solution to this problem.
Nodes intending to communicate with a given node would
raise RTS with the intended receiver who would then make
the decision and respond with a CTS. Neighbors start communicating with each other exchanging IDs of nodes they feel
suspicious based on the proposed detection metric via a silent
bilateral ”gossip” [26]. Now the malicious node would also be
part of this exchange and can attempt to mislead the identity
of the malicious node by ”bad mouthing” others.

However, if the un-compromised nodes in the network
outnumber the malicious nodes, a consensus based scheme
could help majority of nodes zero down on the exact identity of
the malicious node. This is demonstrated by a simple protocol
as follows:
[Rule-1] Each node suspects zero or more nodes in its
span/range of control for a fixed period of time; end of which,
it would nominate one or more nodes it feels suspicious. See
line 5-18 in Algorithm 1.
[Rule-2] Each node communicates its suspicion to all its
neighbors and updates a vector of neighborhood suspicions.
The node can choose not to communicate with its suspicion;
this is, however, recommended for accurate and faster operation. IDs of suspicious nodes stored are simply numbers
and would not warrant any large memory. See line 20-21 in
Algorithm 1.
[Rule-3] A node would not take an entry of another suspicious node into its decision making if the suspicious node is
beyond its range or span of control. However, the node would
continue to store its entry for future diagnostic purposes. See
line 22-26 in Algorithm 1.
[Rule-4] A node may not have any suspicion on any other
node if it is unable to detect malicious activity around it.
[Rule-5] If a node A has two neighbors B and C who give
their suspicions to node A as C and B respectively, then one
of them is surely malicious; in such a case, node A could
choose to either discard both of them or brand one of them
suspicious based on consensus of votes it has received from
all its neighbors about nodes B and C.
[Rule-6] One strong observation that nodes can use to
easily detect the identity of the malicious nodes is to first

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

TABLE I
C ONSENSUS OF D ISTRIBUTED M ALICIOUS N ODE D ETECTION P ROTOCOL .
Owner
1
2
3
4∗
5
6
7∗

Suspicion
4
4
4
1, 2, 3
5, 6
4, 7
7, 4
5, 6

Neighbor
2
1
1
1
5
2
3
4∗

Suspicion
4
4
4
2, 3
2
4
4
5, 6

Neighbor
3
4∗
4∗
2
6
4∗
4∗
5

stop communication with their suspicions and asking other
nodes about what its suspicion has communicated to them.
If any node has not been consistent with its response to its
neighboring nodes, the nodes could cross-talk, confirm their
suspicions and brand it as the malicious node.
[Rule-7] Exchanging its own suspicions with all neighbors
in its immediate neighborhood may not require any arbitration
as we propose piggybacking it at the end of a forwarded data
packet leading to minimal impact on the energy levels of the
resource-constrained node.
The proposed distributed protocol has the following features:
1) There is a periodic pair-wise inter-node exchange of
suspicions. Each node chooses its suspicions based on
the new MAC layer-based measurement criteria defined.
2) The nodes are monitoring their neighbors continuously
during the time they are awake as per their sleepwakeup schedule; we have chosen S-MAC protocol for
simulation.
3) The information exchanged is very small i.e. just the
node ID(s) of neighbors that one feels suspicious about.
4) Reliable and symmetrical communication is assumed for
this interaction.
5) The frequency of this exchange is expected to be much
lower than typical data exchange/forwarding frequencies, so overhead is negligible.
6) No node can judge about the level of susceptibility
for any node which is outside its transmission range.
This is due to the fact that not even a malicious node
has the computational or radio capacity to determine
the neighbors of its neighbors and convey them as its
suspicions.
7) One-to-one interaction is better than a local broadcast
done by a node to announce its suspicions as local
broadcast is susceptible to DoS attacks and scales poorly.
Let us illustrate this using a simple example as shown in
Fig.1(a); nodes 4 and 7 are shown malicious and they attempt
transmit extra amount of data through the network. The above
rules that constitute our distributed protocol are run on each
node including the malicious ones. Here, node 1 (hereafter
referred to as N1 ) has its own suspicion on N4 . N1 then does
a mutual exchange of suspicions with its neighbors:
1) N2 (which gives it a suspicion on N4 ),
2) N3 (which also gives it a suspicion on N4 ) and
3) N4 (which gives it a suspicion on N3 ).
Note that the abnormal behavior of N4 will also be noticed by
all its neighbors viz. nodes 2, 3, 5 and 6. Thus the suspicions’

Suspicion
4
1, 5
1, 6
1, 5
3
2
3
6

Neighbor
4
5
6
3
7∗
7
7
6

Suspicion
2, 3
4, 7
4, 7
1, 6
5, 6
6
5
5

Verdict
4, 4, 4,
4, 4, 7,
4, 1, 6,
2, 3, 1,
6, 2, 3,
4, 7, 4,
7, 4, 4,
5, 6, 5,

2,
1,
4,
5,
5,
2
3
6

3
5
7
1
6

list for N1 is derived as:
1) N4 (is own suspicion),
2) N4 (received from N2 ),
3) N4 (received from N3 )
Thus, N1 can conclude that N4 is a suspicious node. This
procedure is performed by every node and eventually, N4 and
N7 can be detected as shown in Table I.
D. Defenses against Sybil and Replay attacks
A malicious node may not raise an abnormally huge number
of RTS to be caught in a couple of steps. A possible security
attack in this case is the Sybil attack wherein the malicious
node may masquerade the IDs of other innocent nodes. A
simple solution for this is to have the RTS from every sender
to the receiver encrypted using a shared secret negotiated prior
between the pair. The malicious node can masquerade the ID
of an innocent node but it cannot get access to its shared
secret. Such a malicious node does not have the computational
and storage capability to mount a known cipher-text attack
on the encrypted RTS. Solving the Sybil attack provides
an important characteristic of non-repudiation. Any existing
solution defending the network against the Sybil attack can
also be used in place of encrypting RTS.
A possible replay attack can be prevented by adding encrypted HMAC of the current timestamp in the encrypted
RTS to achieve the data freshness objective as outlined in
the SPINS protocol. The argument that a malicious node can
replay the RTS after few seconds can be offset by the fact
that the destination node will reject messages from the same
source bearing the same timestamp under the safe assumption
that the source node would not need to communicate with the
destination node immediately with the same timestamp. This
would also help the destination node discard duplicates.
V. P ERFORMANCE A SSESSMENTS
To evaluate the performance of our approach, we conducted
extensive simulation on a TinyOS-based wireless sensor network simulator. The physical layer assumes a fixed transmission range model, where nodes can directly communicate
with each other successfully only if they are in each other’s
transmission range. The network traffic characteristics chosen
are periodic but can be altered to suit any application type. The
traffic load to the network is balanced by the MAC protocol
with no collisions. The network size Ns is varied from 1 to 10
nodes while the number of malicious nodes (Nm ) and number
of neighboring nodes (Nn ) are also varied to study detection
patterns. This is summarized in the Table II.

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

3

3

1

6

4

6

4

2

7

5

(a)

4

2

7

Innocent
Node
Exchange of suspicions
amongst innocent nodes

2

7

5

5

(b)

(c)

Exchange of suspicions
amongst an innocent
and a malicious node
Collusion between
two malicious nodes

(a) Original network (b) Un-restrictive and (c) Restrictive Distributed Malicious Node Detection Protocol with nodes 4 and 7 malicious.

TABLE II
N ETWORK PARAMETERS .
Network Size Ns
Number of Malicious Nodes Nm
MAC protocol
Number of Neighbors Ni
Node Positioning
Node Mobility

10
Varied from 1 to 10
IEEE 802.11 DCF
Varied from 1 to 6
Fixed
Static

The performance assessment was carried out using two
different scenarios:
1) A node communicates with all its neighbors including
its suspicions, as shown in Fig.1(b).
2) A node chooses not to communicate with its suspicions,
as shown in Fig.1(c).
Suppose there are N nodes in a network; a given ith node
voices a total of ni votes out of which ni−mal(j) votes are
useful to identify its jth suspicion.
Definition 1: The rate of detection is the rate at which each
node is able to claim the right suspicion towards a malicious
node in its neighborhood; is defined as the arithmetic mean
of ratio of votes per node:
N

1  ni−mal(j)
.
N i=1
ni
Definition 2: The false positive rate is the rate at which
malicious node collude to brand an innocent node as malicious; is defined as the ratio of total number of votes for an
innocent node to the total number of votes:
N
i=1 ni−mal(j)
.
N
i=1 ni

implementations fair equally and the rate of detection is 50%.
Fig. 2(b) shows that if node do not communicate with its own
suspicions, malicious nodes have far lesser chances to collude
together thereby significantly reducing the false positive rate.

Fig. 3.

(a) Rate of Detection v/s Ns (b) False Positive Rate v/s Ns .

Network Size: Fig. 2(a) shows the rate to detect a malicious
node is significantly higher when the nodes do not communicate with their suspicions. For a network with 2 nodes, both the

(a) Rate of Detection v/s Nm (b) False Positive Rate v/s Nm .

Number of Malicious Beacon Nodes: In Fig. 3(a), we can
see varying Nm has a drastic impact on the rate of detection.
As Nm increase, the rate of detection falls almost linearly
till a threshold beyond which it goes constant due to no
innocent neighboring nodes. Finally, it is drops to zero as
Nm =over 78% (three-fourths) of Ns and none of them have
any suspicion against each other. Similar behavior is seen
for false positive rate also, as shown in Fig. 3(b), in which
false positive rate is higher most of the times when nodes
communicate with all its neighbors including its suspicions.
The false positive rate shoots up when Nm =over 60% of Ns
but drops down to zero when Nm =82% of Ns .

Fig. 4.

Fig. 2.

Malicious
Node

1

6

Fig. 1.

3

1

(a) Rate of Detection v/s Ni (b) False Positive Rate v/s Ni .

Number of Innocent Neighbors: An analysis of number
of innocent neighbors (Ni ) guarding against a given malicious
node was done and it showed, as seen from Fig. 4(a) and Fig.
4(b), that the rate of detection increases and false positive rate
decreases a little less than linearly, but still significantly, as
we scale Ni in steps of 1.
Communication Overhead: Fig. 5 shows expected trends
of communication overhead in our distributed gossip approach.
If piggybacking is implemented, the number of messages
exchanged would translate to number of bytes used.

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

Fig. 5. Communication Overhead of Distributed Malicious Node Detection
Protocol.

The wave-like pattern observed in above figures is due to
Ns , for example, in Fig. 2(a), when Ns =2, then Nm =Ni =1.
When Ns =3, then Ni =2 while Nm =1 and thus the increase
in rate of detection. Again, when Ns =4, then Nm =Ni =2 and
rate of detection is lower, and so on.
VI. C ONCLUSION AND F UTURE W ORK
In this paper, we have presented basic requirements that an
ideal malicious node detection protocol for data theft should
possess. In particular, we have introduced a new concept of
detection metric that conveys a measure of the traffic pattern
of a node in the network. Number of RTS requests raised by
a node gives a higher degree of confidence on how a node is
performing. The use of this parameter to detect data theft is
justified as it is a degree of the communication pattern that
all nodes, including the malicious ones, strictly adhere to. It
is quite certain that if a node is raising many RTS requests,
either there are many collisions in the medium or the node is
attempting to use the resources of the network and utilizing
the multi-hop property and infrastructure of the network to
propagate data to a possible attacker. Anomalies in control
(and not data) behavior in communications stimulate detection
of data theft attack.
We also have presented a cluster-based and a distributed,
co-operative, lightweight, scalable protocol for detecting malicious nodes. The evaluation of the distributed approach is in
synchronization with underlying characteristics of a wireless
sensor network for low energy, self-organizing, peer-to-peer
nodes with a multi-hop communication pattern. Though we
retain the choice of a node to maintain a communication path
with its suspicion, performance results for rate of detection and
false positives recommend that nodes should not use nodes,
as their next-hop, on whom they have suspicions.
We identify the need to have self learning thresholds in
cases when there are more events to be sensed and reported
and more MAC access contention.
Temporal aggregation if employed, could have some impact
on our detection metric because it intentionally reduces periodic hop-by-hop packet forwarding causing false negatives in
our solution.
R EFERENCES
[1] R. Szewczyk, J. Polastre, A. Mainwaring, and D. Culler, “Lessons from
a sensor network expedition,” Tech. Rep., 2004.
[2] S. Gyula, M. Mikls, L. kos, B. Gyrgy, K. Branislav, N. Andrs, P. Gbor,
S. Jnos, and F. Ken, “Sensor network-based countersniper system,” in
Proceedings of the 2nd international conference on Embedded networked sensor systems, 2004.

[3] Y. Wei, J. Heiermann, and D. Estrin, “An energy-efficient MAC protocol
for wireless sensor networks,” in Proceedings of the IEEE Infocom,
2002.
[4] J. Polastre, J. Hill, and D. Culler, “Versatile low power media access
for wireless sensor networks,” in Proceedings of the 2nd international
conference on Embedded networked sensor systems, 2004.
[5] T. van Dam and K. Langendoen, “An adaptive energy-efficient MAC
protocol for wireless sensor networks,” in In Proceedings of the First
ACM Conference on Embedded Networked Sensor Systems, 2003.
[6] M. Conti, R. D. Pietro, L. V. Mancini, and A. Mei, “A randomized,
efficient, and distributed protocol for the detection of node replication
attacks in wireless sensor networks.” in In Proceedings of the 8th ACM
international Symposium on Mobile Ad Hoc Networking and Computing,
2007.
[7] J. Newsome, E. Shi, D. Song, and A. Perrig, “The sybil attack in sensor
networks: analysis and defenses.” in In Proceedings of ACM IPSN, 2004.
[8] G. Thamilarasu, A. Balasubramanian, S. Mishra, and R. Sridhar, “A
Cross-layer based Intrusion Detection Approach for Wireless Ad hoc
Networks,” in Proceedings of IEEE International Conference Mobile
Adhoc and Sensor Systems Conference, 2005.
[9] R. W. R, T. H, C. Hao, and A. Antonio, “Malicious Node Detection
in Wireless Sensor Networks,” Proceedings of the 18th International
Parallel and Distributed Processing Symposium, 2004.
[10] G. Yin, G. Yang, Y. Wu, X. Yu, and D. Zuo, “A Novel Reputation Model
for Malicious Node Detection in Wireless Sensor Network,” in Wireless
Communications, Networking and Mobile Computing, 2008.
[11] S. Bichegger and J.-Y. L. Boidec, “The Selfish Node: Increasing Routing
Security in Mobile Ad Hoc Networks,” Tech. Rep., 2001.
[12] P. Michiardi and R. Molva, “Core: A collaborative Reputation mechanism to enforce node cooperation in Mobile Ad Hoc Networks,” in Sixth
IFIP conference on security communications and multimedia, 2002.
[13] R. Behnke, J. Salzmann, D. Lieckfeldt, K. Thurow, F. Golatowski, and
D. Timmermann.
[14] D. Curiac, O. Banias, F. Dragan, C. Volosencu, and O. Dranga,
“Malicious Node Detection in Wireless Sensor Networks Using an
Autoregression Technique.” in In Proceedings of the Third international
Conference on Networking and Services, 2007.
[15] C. Lin, W. Lai, Y. Huang, and M. Chou, “Secure Routing Protocol with
Malicious Nodes Detection for Ad Hoc Networks.” in In Proceedings of
the 22nd international Conference on Advanced information Networking
and Applications - Workshops, 2008.
[16] D. Somasundaram and R. Marimuthu, “A Multipath Reliable Routing
for detection and isolation of malicious nodes in MANET,” in In
proceedings of International Conference on Computing, Communication
and Networking, 2008.
[17] Y. Sun, Z. Han, W. W. Yu, and K. Liu, “Attacks on Trust Evaluation in
Distributed Networks,” in Information Sciences and Systems, 2006 40th
Annual Conference, 2006.
[18] P. Agarwal, B. Yadav, and J. Chandra, “Statistical analysis based efficient
decentralized intrusion detection scheme for mobile ad hoc networks,”
in 16th IEEE International Conference on Networks, 2008.
[19] S. Sancak, E. Cayirci, V. Coskun, and A. Levi, “Sensor wars: detecting
and defending against spam attacks in wireless sensor networks,” in
IEEE International Conference on Communications, 2004.
[20] A. Young and M. Yung, “On Fundamental Limitations of Proving Data
Theft,” in IEEE Transactions on Information Forensics and Security,
2006.
[21] V. Bhuse and A. Gupta, “Anomaly Intrusion Detection in Wireless
Sensor Networks,” Journal of High Speed Networks, vol. 15, no. 1,
2006.
[22] ——, “Detection of masquerade attacks on Wireless Sensor Networks,”
in Proceedings of IEEE International Conference on Communications,
2007.
[23] Y. Zhang and W. Lee, “Intrusion detection in wireless ad-hoc networks.”
in In Proceedings of the 6th Annual international Conference on Mobile
Computing and Networking, 2000.
[24] A. P. da Silva, M. H. Martins, B. P. Rocha, A. A. Loureiro, L. B. Ruiz,
and H. C. Wong, “Decentralized intrusion detection in wireless sensor
networks.” in In Proceedings of the 1st ACM international Workshop on
Quality of Service and Security in Wireless and Mobile Networks, 2005.
[25] O. Younis and S. Fahmy, “Distributed Clustering for Scalable, LongLived Sensor Networks,” Tech. Rep., 2003.
[26] J. Birman, “The promise, and limitations, of gossip protocols.” SIGOPS
Oper. Syst., vol. 41, no. 5, 2007.

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

Efﬁcient and Secure Data Storage Operations for
Mobile Cloud Computing
Zhibin Zhou and Dijiang Huang
{zhibin.zhou,dijiang}@asu.edu
Arizona State University

Abstract—
In a mobile cloud computing system, lightweight wireless
communication devices extend cloud services into the sensing
domain. A common mobile cloud secure data service is to inquiry
the data from sensing devices. The data can be collected from
multiple requesters, which may drain out the power of sensing
devices quickly. Thus, an efﬁcient data access control model is
desired. To this end, we present a comprehensive security data
inquiry framework for mobile cloud computing. Our solution
focuses on the following two research directions: First, we
present a novel Privacy Preserving Cipher Policy Attribute-Based
Encryption (PP-CP-ABE) to protect sensing data. Using PP-CPABE, light-weight devices can securely outsource heavy encryption and decryption operations to cloud service providers, without
revealing the data content. Second, we propose an Attribute
Based Data Storage (ABDS) system as a cryptographic groupbased access control mechanism. Our performance assessments
demonstrate the security strength and efﬁciency of the presented
solution in terms of computation, communication, and storage.

I. I NTRODUCTION
With the fast development of wireless technology, mobile
cloud computing has become an emerging cloud service
model [19], [9], where mobile devices and sensors are used
as the information collecting and processing nodes for the
cloud infrastructure. This new trend demands researchers and
practitioners to construct a trustworthy architecture for mobile
cloud computing that includes a large numbers of lightweight,
resource-constrained mobile devices. In such a mobile cloud
sensing environment, cloud users may inquiry the data from
sensing devices. A simple solution to protect the data is to
encrypt the sensing data with a group key and broadcast
the encrypted data; only legitimated users can reveal the
data content with the predistributed group key. However, this
approach demands high key management overhead and it is
vulnerable to single point failure problems.
Ciphtertext Policy Attribute-Based Encryption (CP-ABE)
schemes [3], [7], [6], [21] were proposed to facilitate key
management and cryptographic access control in an expressive
and efﬁcient way. Under the construction of CP-ABE, an
attribute is a descriptive string assigned to (or associated with)
a user and each user may be tagged with multiple attributes.
Multiple users may share common attributes, which allow
sensors to specify a data access policy by composing multiple
attributes through logical operators such as “AND”, “OR”,
c 2012 IFIP
978-3-901882-48-7 

c
978-3-901882-48-7 2012
IFIP

etc. To decrypt the message, the decryptor’s attributes need
to satisfy the access policy.
To illustrate the application scenario, let us consider a
mobile remote health sensing scenario, where a doctor using a
mobile device (e.g., smart phone) to inquiry the sensing data
collected from a set of body sensors attached on a patient at
home. It is convenient to encrypt the data and enforcing data
access policies that only eligible users can decrypt it. To this
end, The sensed data can be encrypted using the following
policy:
12/08/2011 AND Doctor AND Saint Luke Hospital.
In this example, doctors who are working in Saint Luke
hospital on 12/8/2011 can decrypt the data. Using CP-ABE
scheme, the sensor can use the above described policies to
encrypt the data and the data inquirers must satisfy the given
policies in order to decrypt the data.
To establish the highlighted mobile cloud data inquiry
services, we need to address the following research challenges:
• With the CP-ABE enabled mobile cloud data inquiry
services, the main challenge is originated from the fact
that CP-ABE schemes always require intensive computing resources for sensors or mobile devices to run the
encryption and decryption algorithms.
• Given the sensitivity of data and multitenancy nature
of public cloud, critical customer secrets should not be
exposed to the cloud.
• Another major challenge is how to upload/download
and update encrypted data stored in the mobile cloud
system. Frequent upload/download operations will cause
tremendous overhead for resource constrained wireless
devices.
To address the above described research challenges, in this
paper, we present a secure data inquiry framework for mobile
cloud computing that includes two major components:
1) A Privacy Preserving CP-ABE (PP-CP-ABE) scheme;
2) An Attribute-Based Data Storage (ABDS) scheme that
achieves information theoretical optimality.
Using PP-CP-ABE, users can securely outsource computation intensive CP-ABE encryption and decryption operations
to the cloud without revealing data content and secret keys.
In this way, lightweight and resource constrained devices can
access and manage data stored in the cloud data store. The

37

ABDS system achieves scalable and ﬁne-grained data access
control, using public cloud services. Based on ABDS, users’
attributes are organized in a carefully constructed hierarchy
so that the cost of membership revocation can be minimized.
Moreover, ABDS is suitable for mobile computing to balance
communication and storage overhead and thus reduces the
cost of data management operations (such as upload, updates,
etc.) for both the mobile cloud nodes and storage service
providers. Our performance evaluation demonstrate that the
proposed solution is computation efﬁcient (i.e., saving 90%
for encryption and 99% for decryption) for lightweight mobile
devices and it is storage efﬁcient of ABDS scheme, where both
data inquirers and sensors only need to store log2 (N ) private
keys while N keys are required when using CP-ABE scheme.
The rest of this paper is organized as follows. Section II
presents system models used in this paper. We present detailed
PP-CP-ABE construction and ABDS design in Section III and
IV, respectively. In Section V, we analyzed the security and
discuss the performance of proposed schemes with comparison
to several related works. We describe related works in Section
VI. Finally, we conclude our work in Section VII.
II. S YSTEM AND M ODELS
A. Notations
The notations used in this paper is listed in the following
table:
Acronym
DO
DR
ESP
DSP
SSP
TA
T

Descriptions
Data Owner
Data Requester/Receiver
Encryption Service Provider
Decryption Service Provider
Storage Service Provider
Trust Authority
Access Policy Tree

B. Overview
In our proposed system, we denote the Data Owner as
DO. A DO can be a mobile wireless device such as a smart
phone or an environmental sensor that can request and/or store
encrypted information from/in the Cloud storage. The data are
encrypted using the proposed PP-CP-ABE scheme. Other than
DO, there are many DRs (Data Requesters or Receivers) who
can inquiry the information from the storage services of the
mobile cloud. For example, a user may want to inquiry current
pollution map of a particular city area. Since the data provided
by DOs can be proprietary, it should be encrypted and only
pollution map service subscribers can retrieve the data. In
this case, the mobile cloud system only provides a service
platform and it should not be able to access the data content
from the DOs. In this paper, our focus is on the encryption
and decryption model to support the described application
scenario; thus, due to the space limit, we do not describe how
exactly the application is established in details. The presented
system model should provide the following properties:
1) The data must be encrypted before sending to storage
service provider (SSP);

38

2) The encryption service provider (ESP) provides encryption service to the data owner without knowing the actual
data encryption key (DEK);
3) The decryption service provider (DSP) provides decryption service to data inquirers without knowing the data
content;
4) Even ESP, DSP and SSP collude, the data content cannot
be revealed;

Fig. 1.

System Architecture of Our Proposed Framework.

As shown in Figure 1, the SSP, ESP, and DSP form the
core components of the proposed system. A DR inquiries
the data provided by a DO. ESP and DSP provide PP-CPABE services and SSP, e.g., Amazon S3, provides storage
services. The cloud is semi-trusted, in which the cloud only
provides computing and storage services with the assistance
on data security; however, the data is blinded to the cloud. In
particular, more powerful PCs and Mobile Phones can works
as communication proxy for sensors that collect information.
Essentially, the basic idea of PP-CP-ABE to outsource
intensive but non-critical part of the encryption and decryption
algorithm to the service providers while retain critical secrets.
As we can prove later in this paper, the outsourcing of
computation does not reduce the security level compared
with original CP-ABE schemes, where all computations are
performed locally.
The encryption complexity of CP-ABE grows linearly on
the size of access policy. During the encryption, a master secret
is embedded into ciphertext according to the access policy tree
in a recursive procedure, where, at each level of the access
policy, the secret is split to all the subtree of the current root.
However, the security level is independent on the access policy
tree. In other words, even if the ESP possesses secrets of most
but not all parts of the access policy tree, the master secret is
still information theoretically secure given there at least one
secret that is unknown to ESP. Thus, we can safely outsource
most part of encryption complexity to ESP by just retaining a
small amount of secret information, which is processed locally.
As for the decryption, the CP-ABE decryption algorithm
is computationally expensive since bilinear pairing operations
over ciphertext and private key is a computational intensive
operation. PP-CP-ABE addresses this computation issue by
securely blinding the private key and outsourcing the expensive Pairing operations to the DSP. Again, the outsourcing will
not expose the data content of the ciphertext to the DSP. This

2012 8th International Conference on Network and Service Management (CNSM 2012)

is because the ﬁnal step of decryption is performed by the
decryptors.
C. Attacking Models
The malicious attackers’ goal is to reveal data in the cloud
without authorization from DOs. Service providers (ESP, DSP
and SSP) and the attacks can combine their information to
perform collusion attacks, in which they can try to decrypt
the ciphertext and compromise the decryption keys that they
are not authorized to access. One particular example of this
attack is that they gather enough information to compromise
 as
the decryption keys SK from many blind private keys SK
 In addition, the attacks
DSP has the ability to get a lot of SK.
may compromise the encrypted data by use of the advantage
which ESP provides the encryption service to gain from the
DO.
In particular, attackers want to break the Forward Secrecy,
which is deﬁned as follows: After a user is revoked from
accessing a ﬁle, he/she may have a local copy of the ﬁle;
however, the revoked user must not get any future updates on
this ﬁle.
While data integrity and retrievability in the cloud are also
important security requirements, they are not the focuses of
this paper. Readers can refer to research works in the provable
data possession (PDP) [1], [12].
D. Access Policy Tree
In this section, we brieﬂy describe the model of an access
policy tree used in PP-CP-ABE as illustrated in Figure 2.
The data access policy tree of PP-CP-ABE is composed by
leaf nodes and internal nodes. Each leaf node represents an
attribute, and each internal node is a logical gate, such as
“AND”, “OR”, “n-of-m”. Several functions and terms are deﬁned as follows to facilitate the presentation of our solutions:
• parent(x): return the parent node of node x;
• att(x) denotes the attribute associated with the leaf node
x in the data access tree;
• The access tree T composed by a set of leaf nodes
(i.e., attributes) and internal nodes (i.e., logical gates)
deﬁnes the data access policies, i.e., if a user owns a
set of attributes that satisfy the logic operations of the
tree to reach the root, it can access the secret secured by
T . Here owns means that the user has the private keys
corresponding to the set of attributes. AND and OR are
the most frequently used logical gates.
• numx is the number of children of a node x. A child
y of node x is uniquely identiﬁed by an index integer
index(y) from 1 to numx .
• The threshold value kx = numx − 1 when x is an AND,
and kx = 0 when x is an OR gate or a leaf node. kx
is used as the polynomial degree for node x using the
threshold secret sharing scheme [29].
E. Bilinear Pairing
Our proposed PP-CP-ABE is constructed using bilinear
pairing. Pairing is a bilinear map function e : G0 × G0 → G1 ,
where G0 and G1 are two multiplicative cyclic groups with

Fig. 2.

Illustration of a sample access policy tree.

large prime order p. The Discrete Logarithm Problem on both
G0 and G1 are hard. Pairing has the Bilinearity property:
e(P a , Qb ) = e(P, Q)ab ,

∀P, Q ∈ G0 , ∀a, b ∈ Z∗p .

III. P RIVACY P RESERVING CP-ABE
A. Overview of the Construction
Essentially, the basic idea of PP-CP-ABE to outsource
intensive but non-critical part of the encryption and decryption
algorithm to the service providers while retain critical secrets.
As we can prove later in this paper, the outsourcing of
computation does not reduce the security level compared
with original CP-ABE schemes, where all computations are
performed locally.
The encryption complexity of CP-ABE grows linearly on
the size of access policy. During the encryption, a master secret
is embedded into ciphertext according to the access policy tree
in a recursive procedure, where, at each level of the access
policy, the secret is split to all the subtree of the current root.
However, the security level is independent on the access policy
tree. In other words, even if the ESP possesses secrets of most
but not all parts of the access policy tree, the master secret is
still information theoretically secure given there at least one
secret that is unknown to ESP. Thus, we can safely outsource
most part of encryption complexity to ESP by just retaining a
small amount of secret information, which is processed locally.
As for the decryption, the CP-ABE decryption algorithm
is computationally expensive since bilinear pairing operations
over ciphertext and private key is a computational intensive
operation. PP-CP-ABE addresses this computation issue by
securely blinding the private key and outsourcing the expensive Pairing operations to the DSP. Again, the outsourcing will
not expose the data content of the ciphertext to the DSP. This
is because the ﬁnal step of decryption is performed by the
decryptors.
B. System Setup and Key Generation
The TA ﬁrst runs Setup to initiate the PP-CP-ABE system
by choosing a bilinear map: e : G0 × G0 → G1 of prime order
p with the generator g. Then, TA chooses two random α, β
∈ Zp . The public parameters are published as:
P K = G0 , g, h = g β , e(g, g)α .

2012 8th International Conference on Network and Service Management (CNSM 2012)

(1)

39

The master key is M K = (β, g α ), which is only known by
the TA.
Each user needs to register with the TA, who authenticates
the user’s attributes and generates proper private keys for the
user. An attribute can be any descriptive string that deﬁnes,
classiﬁes, or annotates the user, to which it is assigned. The
key generation algorithm takes as input a set of attributes S
assigned to the user, and outputs a set of private key components corresponds to each of attributes in S. The GenKey
algorithm performs the following operations:
1) Chooses a random r ∈ Zp ,
2) Chooses a random rj ∈ Zp for each attribute j ∈ S.
3) Computes the private key as:
SK =D = g (α+r)/β ;
∀j ∈ S : Dj = g r × H(j)rj ; Dj = g rj .
4) Sends SK to the DO through a secure channel.
C. PP-CP-ABE Encryption
To outsource the computation of Encryption and preserve
the data
 needs to specify a policy tree T =
 privacy, a DO
TESP TDO , where
is an AND logic operator connecting
two subtrees TESP and TDO . TESP is the data access policy
that will be performed by the ESP and TDO is a DO controlled
data access policy. TDO usually has a small number of
attributes to reduce the computation overhead at the DO, in
which it can be a sub-tree with just one attribute (see the
example shown in Figure 3).
In practice, if TDO has one attribute, DO can randomly
specify an 1-degree polynomial qR (x) and sets s = qR (0),
s1 = qR (1), and s2 = qR (2). Then DO sends {s1 , TESP } to
ESP, which is noted as:
{s1 ,TESP }

DO −−−−−−−→ ESP.
Here, we must note that sending s1 and TESP will not expose
any secret of our solution. We will prove this in Section V-A.
ESP then runs the Encrypt(s1 , TESP ) algorithm, which is
described below:
1) ∀x ∈ TESP , randomly chooses a polynomial qx with
degree dx = kx − 1, where kx is the secret sharing
threshold value:
a) For the root node of TESP , i.e., RESP , Chooses a
dRESP -degree polynomial with qRESP (0) = s1 .
b) ∀x ∈ TESP \RESP sets dx -degree polynomial with
qx (0) = qparent(x) (index(x)).
2) Generates a temporal ciphertext:

Fig. 3.

Illustration of access policy T = TESP



TDO .

 C to the ESP:
3) Sends CTDO , C,

{CTDO ,C,C}

DO −−−−−−−−→ ESP.
On receiving the message from the DO, ESP generates the
following ciphertext:

 = M e(g, g)αs ; C = hs ;
TDO ; C
CT = T = TESP

∀y ∈ YESP
YDO : Cy = g qy (0) ; Cy = H(att(y))qy (0) .
Finally, the ESP sends CT to the SSP.
D. Outsourcing Decryption
CP-ABE decryption algorithm is computationally expensive
since bilinear pairing is an expensive operation. PP-CP-ABE
addresses this computation issue by outsourcing the expensive
Pairing operations to the DSP. Again, the outsourcing will not
expose the data content of the ciphertext to the DSP.
To protect the data content, the DO ﬁrst blinds its private
 =
key by choosing a random t ∈ Zp and then calculates D

Dt = g t(α+r)/β . We denote the blinded private key as SK:

SK

=

 = g t(α+r)/β ,
D
∀j ∈ S : Dj = g r · H(j)rj , Dj = g rj .

(2)

Before invoking the DSP, the DO ﬁrst checks whether its
owned attributes will satisfy the access policy T . If so, the
 to the DSP, and requests the SSP to send
DO sends {SK}
the ciphertext to the DSP. On receiving
 the request, the SSP
sends CT  = {T ; C = hs ; ∀y ∈ Y1 Y2 : Cy = g qy (0) ; Cy =
H(att(y))qy (0) } and CT  ⊂ CT to the DSP:
{CT  }

SSP −−−−→ DSP.
(3)
 and CT  , it then runs
Once the DSP receives both {SK}


the Decrypt(SK, CT ) algorithm as follows:

1) ∀y ∈ Y = YESP YDO the DSP runs a recursive
 R), where R is the
function DecryptNode(CT , SK,
root of T . The recursion function is the same as deﬁned
 y) is proceeded as
in [3] and DecryptNode(CT  , SK,
qy (0)

qy (0)
CTESP = {∀y ∈ YESP : Cy = g
, Cy = H(att(y))
},
follows:
where YESP is the set of leaf nodes in TESP .
 y) = e(Di , Cy )
DecryptNode(CT  , SK,
At the meantime, the DO performs the following operations:
e(Di , Cy )
1) Performs Encrypt(s2 , TDO ) and derives:
e(g r · H(i)ri , g qy (0) )
=
e(g ri , H(i)qy (0) )
CTDO = {∀y ∈ YDO : Cy = g qy (0) , Cy = H(att(y))qy (0) }.
= e(g, g)rqy (0)
 = M e(g, g)αs and C = hs , where M is
2) Computes C
= Fy .
the message.

40

2012 8th International Conference on Network and Service Management (CNSM 2012)

The recursion is processed as follows: ∀y is the child
 y) and stores the
of x, it calls DecryptN ode(CT  ; SK;
output as Fy . Let Sx be an arbitrary kx -sized set of
children nodes y, the DSP computes:
	 Δi,S (0)
Fy x
Fx =
y∈Sx

=

	

(e(g; g)r·qy (0) )Δi;Sx (0)

y∈Sx

=

	

(e(g; g)r·qparent(y)(index(y)) )Δi;Sx (0)

y∈Sx

=

	

(e(g; g)r·qx(i)·Δi;Sx (0)

y∈Sx

=

e(g, g)rqx (0) ,

(4)

where i = index(z) and Sx = {index(z) : z ∈ Sx },
Δi;Sx (0) is the Lagrange coefﬁcient. Finally, the recursive algorithm returns A = e(g, g)rs .
2) Then, computes
 = e(hs , g t(α+r)/β ) = e(g, g)trs · e(g, g)tαs .
e(C, D)
 = e(g, g)trs ·
3) Sends {A = e(g, g)rs , B = e(C, D)
tαs
e(g, g) } to the DO:
{A,B}

DSP −−−−→ DO.
On receiving {A, B}, DO calculates B  = B 1/t =
e(g, g)rs · e(g, g)αs and then it recovers the message:
M=


C
M e(g, g)αs
.
=
(B  /A)
(e(g, g)rs · e(g, g)αs )/e(g, g)rs

IV. ATTRIBUTE BASED DATA S TORAGE
In this section, we present an Attribute Based Data Storage
(ABDS) scheme that is based on PP-CP-ABE to enable
efﬁcient, scalable data management and sharing.
A. Data Management Overview
The frequent data updates will cause additional expense for
ﬁle managements. For example, to update existing ﬁles, e.g.,
changing certain data ﬁelds of an encrypted database, in which
the encrypted data need to be downloaded from SSP to DSP
for decryption. Upon ﬁnishing the updates, the ESP needs to
be re-encrypted and upload the data to the SSP. Thus, the
re-encrypted process requires downloading and uploading the
data, which may incur high communication and computation
overhead, and as a result, will cost more for DOs.
To address the described cost issue, it is reasonable to divide
a ﬁle into independent blocks that are encrypted independently.
To update ﬁles, the DO can simply download the particular
blocks to be updated. In this way, we can avoid re-encrypting
the entire data. Moreover, data access control can be enforced
on individual blocks using “lazy” re-encryption strategy. For
example, when the data access memberships to a particular
ﬁle are changed (i.e., the access tree is changed), this event
can be recorded but no ﬁle changes are invoked. Until the

Fig. 4.
blocks.

Illustration of a ﬁle organized into blocks with multiple control

data content needs to be updated, the re-encryption is then
performed using the proposed PP-CP-ABE scheme.
Partitioning the data into multiple small blocks also introduces addition overhead. This is because the extra control
information needs to be attached for each data block for data
management. For example, the control message should include
a block ID and a pointer to its corresponding data access tree
T . In Figure 4, we depicted a sample ﬁle stored in SSP. As
shown in Figure 4, each ﬁle is divided into blocks. A block is
a tuple {BID, Ptr, Encrypted Data}, where BID is the unique
identiﬁcation of the block; Ptr is the pointer to the control
block CT; and data is encrypted with a DEK. A control block
{CID, Encrypted DEK} has a control block ID, i.e., CID and
DEK encrypted by using PP-CP-ABE scheme.
The ABDS system should determine what is the appropriate
data block size to be partitioned with a known ﬁle size. In this
work, our goal is to minimize the storage and communication
overhead with the considerations of the following simple
assumptions:
1) Every data update should only affect a small amount of
data, e.g., updating certain data ﬁelds in the Database;
2) In each unit time period, the number of blocks to be
updated is known;
3) Each data block has the same probability to be updated;
Based on the above discussions, we can model the total cost
C in a unit time period as follows:
C = 2nSb Cc +

F
Sc C s ,
Sb

(5)

where n is the number of updated blocks in a unit time period
and 2n stands for an update includes one encryption and one
decryption that require two transmissions; Sb is the size of
block; Cc is the cost rate of data transmission that is charged
by both cloud storage providers and wireless communication
service providers; F is the size of ﬁle; Sc is the size of control
data for each data block, and Cs is the charging rate of storage.
To minimize cost C, DO can minimize (5) and derive the
optimal block size:


Sb ≥ 2 2nCc F Sc Cs .
B. Setup
PP-CP-ABE enables expressive policy with descriptive attributes to enforce data access control on the stored data. For
example, if Alice wants to share a ﬁle to all CS students, she
can specify the policy “CS AND Student”. All the users whose
attributes satisfy this policy can decrypt the data.
Besides the set of descriptive attributes enabled in
the system, each user is assigned a unique binary ID:

2012 8th International Conference on Network and Service Management (CNSM 2012)

41

b0 b1 . . . bn−2 bn−1 . We can deﬁne the term “bit-assignment
attribute” that is represented as “Bi ” or ”Bi ” to indicate the
binary value at position i in the ID. Bi indicates that the i’th
bit of an ID is 1; B i indicates that the i’th bit of an ID is
0. If the length of an ID is n, then the total number of bitassignment attributes is 2n. This means that two binary values
are mapped to one bit position (one for value 0 and one for
value 1). Thus, a DO with ID u is uniquely identiﬁed by the
set of bit-assignments Su . Also, multiple DOs may have a
common subset of bit-assignments. For example, a DO u1 ’s
ID is 000 and a DO u2 ’s ID is 001,
 Su1 = {B 0 , B 1 , B 2 }
and Su2 = {B 0 , B 1 , B2 } and Su1 Su2 = {B 0 , B 1 }. Bitassignment attributes can be used when the DO wants to share
data to any arbitrary set of DOs. In this case, it may be hard to
describe the set of DOs efﬁciently using descriptive attributes.
C. Upload New Files
Before uploading new ﬁles to the SSP, both ESP and DO are
required to determine the encryption parameters such as the
block size. DO then invokes ESP with an access policy TESP ,
which is the access policy to be enforced on the uploaded
ﬁles. Here, we deﬁne some terms used in the following
presentations:
• Literal: A variable or its complement, e.g., b1 , b1 , etc.
• Product Term: Literals connected by AND, e.g., b2 b1 b0 .
• Sum-of-Product Expression (SOPE): Product terms connected by OR, e.g., b2 b1 b0 + b2 .
Given the set of shared data receivers S, the membership
functions fS (), which is in the form of SOPE, speciﬁes the
list of receivers:

0 iff u ∈ S,
u u
u
fS (b1 , b2 , . . . , bn ) =
1 iff u ∈
/ S.
For example, if the subgroup S = {000, 001, 011, 111}, then
fS = b0 b1 b2 + b0 b1 b2 + b0 b1 b2 + b0 b1 b2 .
Then, the DO runs the Quine-McCluskey algorithm [24]
to reduce fS to minimal SOPE fSmin . The reduction can
consider do not care values ∗ on those IDs that are not
currently assigned to any DO to further reduce number of
product terms in the membership function. For example, if
S = {000, 001, 011, 111}, fSmin = b0 b1 + b1 b2 .
Finally, DO uploads the data blocks and the control block
to SSP, where each data block is encrypted by the DEK and
DEK is protected by the access policy in control block.
D. Data Updates
Now, we investigate into how to efﬁciently handle the data
updates, i.e., how to modify encrypted data with or without
changing data access control policy.
1) Data Updates With Access Policy Change: In Section
IV-A, we described the “lazy” re-encryption strategy adopted
by DOs. Using the “lazy” re-encryption scheme, the DO
continuously records the revoked data receivers. When there
is a need to modify the data, the DO will choose a new
data access tree that can revoke all previously recorded data
receivers.

42

When DO updates a data block with access policy change,
we need to consider the following cases:
•

•

•

If there is no control block associated with the latest
access policy, i.e., no data updates occurred after the latest
access policy change event, the DO encrypt a new random
DEK associated with the latest access policy with PP-CPABE and attach a new control block to the end of the ﬁle,
see Figure 4.
If there exists a control block associated with the latest
access policy, i.e., at least one data block was encrypted
with the newest access policy, the DO can simply redirect the control block pointer, see Figure 4, to the
control block associated with the latest access policy.
If a control block is not pointed by any data block, this
control block should be deleted.

2) Updates Without Access Policy Change: If no change
is required to the access policy, DO can simply perform the
PP-CP-ABE scheme and upload the updated data block in the
SSP. The Block ID and the pointer to control the block are
not changed.
V. P ERFORMANCE E VALUATION
In this section, we ﬁrst present the security assessments
of the presented solution. Then, we present the computation,
communication, and storage performance evaluation.
A. Security Assessments
We now brieﬂy analyze the security of PP-CP-ABE
scheme. We ﬁrst describe the hardness assumptions used
in this scheme: Given a bilinear map group system S =
(p, G, GT , e(·, ·)), where two groups G, GT have the prime
order p. The security of this scheme is constructed on
two basic assumptions: Co-Decision Bilinear Difﬁe-Hellman
(Co-DBDH) assumption and Decision Linear Difﬁe-Hellman
(DLDH) assumption.
The data structure of ciphertext and private key in PP-CPABE is the same as the original BSW CP-ABE [3]. Thus PPCP-ABE can be viewed as a variation of CP-ABE. Particularly,
in PP-CP-ABE, the access
 policy tree is constructed by two
sub-trees T = TESP TDO . In general, TDO contains a
single attribute to reduce the computation and communication
overhead. Thus, DO randomly speciﬁes a 1-degree polynomial
q(x) and sets s = q(0), s1 = q(1) and s2 = q(2). The tuple
{s1 , TESP } is sent to ESP. It is easy to prove that, based on
the threshold secret sharing scheme [29], for a given 1-degree
polynomial q(x), knowing s1 , secrets s and s2 are information
theoretically secure. In order to avoid the leakage of encrypted
information for cloud service providers (including ESP and
DSP), the following theorem proves that this scheme is secure
against the adaptive chosen plaintext attacks (IND-CPA) based
on Co-DBDH assumption.
Theorem 1: Let E is a PP-CP-ABE scheme. If Co-DBDH is
(t, q, ε)-hard on G, then the PP-CP-ABE scheme is (t , q  , ε )secure against the adaptive chosen plaintext attacks (INDCPA), where ε > ε/4, q = q  and t > t. Here q is the

2012 8th International Conference on Network and Service Management (CNSM 2012)

TABLE I
AVAILABLE RATIONAL TERMS TO ESP AND DSP

ESP
DSP

s1

e(g, g)r s1

αs1

e(g, g)

e(g, g)r s2

βs1

g

e(g, g)r s

s1 /β

g

e(g, g)tαs+tr s

number of hash function queries made by the adversary, and
t is the run time of attacks.
Based on the security assumptions presented in Section
II-C, ESP, DSP and SSP are untrusted but honest service
providers that will perform proper computation according to
PP-CP-ABE protocol and returns correct results. In order to
compromise users’ secret information, the ESP, DSP and SSP
can perform collusion attacks. In this scenario, an authorized
user u who satisﬁes the access tree T provides his blinded
 to the DSP for decryption. Then, ESP and
private key SK
DSP can try to utilize the blinded private key of u to derive
M from M e(g, g)αs . ESP has s1 , and thus it can easily
derive e(g, g)αs1 . This is because e(g, g)α is available from
the public parameters presented in (1). As the user u satisﬁes
the access policy TDO , DSP can derive the following values




e(g, g)r s1 , e(g, g)r s2 , e(g, g)r s , and e(g, g)tαs+tr s through
the Fx function (see (4)) without knowing alpha and r . In the
following table, we listed all rational terms that are available
to ESP and DSP.
As we can see, ESP has the values s1 and e(g, g)αs1 , but
it is unaware of values s2 or s. DSP possesses more terms as
 of u (see (2)). We must
well as the blinded private key SK

note that SK is not a valid CP-ABE private key, since the
 = g t(α+r )/β is embedded with tr and tα, and the rest of
D

all private key components {∀j ∈ S : Dj = g r ·H(j)rj , Dj =
g rj } are embedded with r . Essentially, this blinded private
key can be a valid CP-ABE private key when (i) the master
key is M K = {β, g tα }; (ii) a colluding user contributes D =

g t(α+r )/β , which is a valid component embedded with tr ;

and (iii) a colluding user contributes {∀j ∈ S : Dj = g r ·
rj

rj

H(j) , Dj = g }, which are binded by a random r , which
is different from tr in D. Since the t is the exponent of the
generator g, deriving it is equivalent to solve the DLP problem,
which is considered to be hard. Thus, given the security of
secret sharing and hardness of DLP on G0 and G1 , ESP and
DSP cannot derive e(g, g)αs2 or e(g, g)αs even if they collude.
Strictly speaking, the following theorem proves that this
scheme holds the collusion key security against the blinded
key attacks (KS-BKA) based on the DLDH assumption:
Theorem 2: Let E is a PP-CP-ABE scheme. If DLDH is
(t, q, ε)-hard on G, then the PP-CP-ABE scheme is (t, q, ε)secure against the blinded key attacks. Here q is the number
of hash function queries made by the adversary, and t is the
run time of attacks.
B. Performance Evaluation
To evaluate the performance of the presented PP-CP-ABE
scheme, we evaluate the computation overhead of service
providers and users based on both theoretical analysis and experimental results. In our experimental analysis, we compared
the computing overhead of various cryptographic operations
in PC, Pocket PC and mobile sensors. The result showed that,

TABLE II
N UMBER OF CRYPTOGRAPHIC OPERATIONS COMPUTED BY ESP
U SER
ESP
User

Exp G0 /G1
2a1 /0
3/1

Mul G1
0
1

Hash to G0
a1
1

TABLE III
N UMBER OF CRYPTOGRAPHIC OPERATIONS COMPUTED BY DSP
U SER
DSP
User

Exp G1
a1
1

Mul G1
2a1
2

AND

Inv G1
a1
1

AND

Pairing
2a1 + 1
0

without oursourcing, it is rather infeasible for the resource
constrained devices to perform the operations.
Firstly, we analyzed the number of expensive cryptographic
operations over G0 and G1 , i.e., pairing, exponentiation, multiplication, performed by service providers and users’ devices.
In our analysis we assume that the access policy TESP has a1
attributes connected by an AND logical gate and TDO only
has 1 attribute. In addition, the root node is an AND gate.
In the Table V-B, we compared the number of exponentiations, multiplications and hash to G0 operations incurred on
ESP side and user side in the encryption outsourcing, where
a1 is the number of attributes in TESP :
We also provided a comparison of the number of exponentiations, multiplications, inversion, and pairing operations
incurred by decryption outsourcing on DSP side and user side
as shown in the Table V-B, where a1 is the number of attributes
in TESP :
From the above analysis, we can see that the computation
overhead is linear for service providers (ESP and DSP) and
constant for the user. Among all operations, pairing and ECC
operations are most computationally intensive. We conducted
the experimental evaluation of cryptographic pairing and ECC
operations on a wireless Mote sensor (8 bit-7.37 MHZ ATMega128L, 4KB RAM) , a pocket pc (600 MHZ CPU) and
a PC (1GHZ CPU). The testing environments and results are
listed in the Table V-B:
The result in Table V-B showed that, without oursourcing,
it is rather infeasible for the resource constrained devices
to perform the operations. To show that PP-CP-ABE can
ofﬂoad most of the computation overhead from user to service
providers., we implemented and evaluated the PP-CP-ABE
on a PC with 1.6GHz Intel Atom processor running Linux
2.6.32. The computation time was measured using clock ticks
returned by clock_t clock(void) function in standard
C library. To illustrate that most of the computation overhead
is outsourced to service providers, we run the user and server
on the same platform and recorded the number of clock ticks.
In the Figure 5, we compared computation overhead incurred
on service providers and users in encryption and decryption
TABLE IV
C OMPUTING TIME OF CRYPTOGRAPHIC OPERATIONS ON EMBEDDED
DEVICES

PC (1GHZ CPU)
Pocket PC (600 MHZ CPU)
Sensor (8× 8MHZ)

Pairing
20 ms
550 ms
31250 ms

Exp G0
5 ms
177 ms
10720 ms

Mul G0
0.7 ms
26 ms
196 ms

2012 8th International Conference on Network and Service Management (CNSM 2012)

43

outsourcing. The computation overhead was calculated in
terms of 10 based logarithms, i.e., log10 , of thousands (K)
clocks ticks. As we can see from the ﬁgure, more than 90%
of encryption and more than 99% of decryption computation
are performed by the service providers.

Fig. 5. Performance evaluation of the encryption and decryption outsourcing.

VI. R ELATED W ORKS
Existing works related to our proposed schemes includes (i)
attribute based encryption and (ii) cryptographic access control
over untrusted storage.
Attribute Based Encryption (ABE) was ﬁrst proposed as a
fuzzy version of IBE in [27], where an identity is viewed as
a set of descriptive attributes. There are two main variants
of ABE proposed so far, namely Key Policy Attribute Based
Encryption (KP-ABE [16]) and Ciphertext Policy Attribute
Based Encryption (CP-ABE [3]). In KP-ABE, each ciphertext
is associated with a set of attributes and each user’s private
key is embedded with an access policy. Decryption is enabled
only if the attributes on the ciphertext satisfy the access policy
of the user’s private key. In CP-ABE [3], [7], [21], [32], each
user has a set of attributes that associate with user’s private
key and each ciphertext is encrypted by an access policy. To
decrypt the message, the attributes in the user private key need
to satisfy the access policy. CP-ABE is more appealing since
it is conceptually closer to the Role Based Access Control
(RBAC) [28] model.
Cryptographic access control over untrusted storage is investigated in both cryptography community and networking community. In cryptography community, Broadcast Encryption
(BE) was introduced by Fiat and Naor in [13]. Compared with
traditional one-to-one encryption schemes, BE is very efﬁcient.
Based on tradeoffs between key storage and ciphertext storage
overhead, existing BE schemes can be generally categorized
into the following classes: (i) constant ciphertext, linear public
and/or private key on number of total receivers [5]; (ii)
linear ciphertext on number of revoked receivers, constant (or
logarithm) public and/or private key, [10], [25], [4]; (iii) sublinear ciphertext, sub-linear public and/or private key [5]. In
this work, I proposed a new construction of attribute based
data storage (ABDS) scheme to address the deﬁciency of all 3

44

class existing works. Particularly, ABDS supports any arbitrary
number of receivers with much lower complexity of storage
and communication.
In networking community, various encrypted ﬁle systems
[20], [2], [11] were proposed to secure data over untrusted
storage. Particularly, in [2], the authors proposed a distributed
storage scheme where users outsource encryption to a semitrusted re-encryption server. However, if the server colludes
with some malicious user, the data secrecy will be compromised completely. Compared with this scheme, the proposed
PP-CP-ABE is secure even if service providers and malicious
users collude. Recently, Yu et al. [33] proposed a security
framework for cloud computing based on CP-ABE. Compared
with the proposed work, their solution requires the users to
disclose part of original private key to the cloud while the
proposed solution only send blinded private keys. Moreover,
the proposed solution specially considers mobile cloud environments and their work.
Data security in public cloud is an emerging research area
[31], [35], [8], [30], [12], [23], [34], [15], [14], [17], [26],
[22]. With the fast development of wireless technology, mobile
cloud has become an emerging cloud service model [18], in
which mobile devices and sensors are used as the information
collecting and processing nodes for the cloud infrastructure.
This new trend demands researchers and practitioners to construct a trustworthy architecture for mobile cloud computing,
which includes a large numbers of lightweight, resourceconstrained mobile devices.
While data integrity and retrievability in the cloud are also
important security requirements, they are not the focuses of
this dissertation. Readers can refer to research works in the
provable data possession (PDP) [1], [12].
VII. C ONCLUSION
In conclusion, we proposed a secure data inquiry service
architecture for mobile cloud computing. Especially, our solution enables lightweight wireless devices to securely store and
retrieve their data in public cloud with minimal cost. To this
end, we proposed a novel Privacy Preserving Cipher Policy
Attribute-Based Encryption (PP-CP-ABE) to protect users’
encrypted data. Using PP-CP-ABE, light-weight devices can
securely outsource intensive encryption and decryption operations to cloud service providers, without revealing the data
content and used security keys. Also, we proposed an Attribute
Based Data Storage (ABDS) system as a cryptographic access
control mechanism. ABDS achieve information theoretically
optimal in terms of minimizing computation, storage and communication overheads. Especially, ABDS minimize cloud costs
charged by cloud service providers as well as communication
overhead for data managements. Our performance assessments
demonstrate the security strength and efﬁciency of our solution
in terms of computation, communication, and storage.
ACKNOWLEDGEMENT
This work is supported by the Ofﬁce of Naval Research’s
(ONR) Young Investigator Program (YIP).

2012 8th International Conference on Network and Service Management (CNSM 2012)

R EFERENCES
[1] G. Ateniese, R. Burns, R. Curtmola, J. Herring, L. Kissner, Z. Peterson,
and D. Song. Provable data possession at untrusted stores. In Proceedings of the 14th ACM conference on Computer and communications
security, pages 598–609. ACM, 2007.
[2] G. Ateniese, K. Fu, M. Green, and S. Hohenberger. Improved proxy
re-encryption schemes with applications to secure distributed storage.
ACM Trans. Inf. Syst. Secur., 9(1):1–30, 2006.
[3] J. Bethencourt, A. Sahai, and B. Waters. Ciphertext-policy attributebased encryption. In SP ’07: Proceedings of the 2007 IEEE Symposium
on Security and Privacy, pages 321–334, Washington, DC, USA, 2007.
IEEE Computer Society.
[4] D. Boneh, X. Boyen, and E.J. Goh. Hierarchical identity based
encryption with constant size ciphertext. Advances in Cryptology–
EUROCRYPT 2005, pages 440–456, 2005.
[5] D. Boneh, C. Gentry, and B. Waters. Collusion resistant broadcast
encryption with short ciphertexts and private keys. In Advances in
Cryptology–CRYPTO 2005, pages 258–275. Springer, 2005.
[6] D. Boneh and B. Waters. Conjunctive, subset, and range queries on
encrypted data. pages 535–554. Springer, 2007.
[7] L. Cheung and C. Newport. Provably secure ciphertext policy abe. In
CCS ’07: Proceedings of the 14th ACM conference on Computer and
communications security, pages 456–465, New York, NY, USA, 2007.
ACM.
[8] R. Chow, P. Golle, M. Jakobsson, E. Shi, J. Staddon, R. Masuoka,
and J. Molina. Controlling data in the cloud: outsourcing computation
without outsourcing control. In Proceedings of the 2009 ACM workshop
on Cloud computing security, pages 85–90. ACM, 2009.
[9] B.G. Chun, S. Ihm, P. Maniatis, M. Naik, and A. Patti. Clonecloud:
Elastic execution between mobile device and cloud. In Proceedings of
the sixth conference on Computer systems, pages 301–314. ACM, 2011.
[10] C. Delerablée, P. Paillier, and D. Pointcheval. Fully collusion secure dynamic broadcast encryption with constant-size ciphertexts or decryption
keys. Pairing-Based Cryptography–Pairing 2007, pages 39–59.
[11] S. D. C. di Vimercati, S. Foresti, S. Jajodia, S. Paraboschi, and
P. Samarati. Over-encryption: management of access control evolution
on outsourced data. In VLDB ’07: Proceedings of the 33rd international
conference on Very large data bases, pages 123–134. VLDB Endowment, 2007.
[12] C. Erway, A. Kupcu, C. Papamanthou, and R. Tamassia. Dynamic
provable data possession. In Proceedings of the 16th ACM conference on
Computer and communications security, pages 213–222. ACM, 2009.
[13] A. Fiat and M. Naor. Broadcast Encryption, Advances in CryptologyCrypto93. Lecture Notes in Computer Science, 773:480–491, 1994.
[14] C. Gentry. Fully homomorphic encryption using ideal lattices. In Proceedings of the 41st annual ACM symposium on Theory of computing,
pages 169–178. ACM, 2009.
[15] C. Gentry. Computing arbitrary functions of encrypted data. Communications of the ACM, 53(3):97–105, 2010.
[16] V. Goyal, O. Pandey, A. Sahai, and B. Waters. Attribute-based encryption for ﬁne-grained access control of encrypted data. Proceedings of
the 13th ACM conference on Computer and communications security,
pages 89–98, 2006.
[17] F. Hsu and H. Chen. Secure ﬁle system services for web 2.0 applications.
In Proceedings of the 2009 ACM workshop on Cloud computing security,
pages 11–18. ACM, 2009.

[18] D. Huang, X. Zhang, M. Kang, and J. Luo. Mobicloud: A secure mobile
cloud framework for pervasive mobile computing and communication. In
Proceedings of 5th IEEE International Symposium on Service-Oriented
System Engineering, 2010.
[19] Dijiang Huang. Mobile cloud computing. IEEE COMSOC Multimedia
Communications Technical Committee (MMTC) E-Letter, 6(10):27–31,
October 2011.
[20] M. Kallahalla, E. Riedel, R. Swaminathan, Q. Wang, and K. Fu.
Plutus: Scalable secure ﬁle sharing on untrusted storage. In FAST
’03: Proceedings of the 2nd USENIX Conference on File and Storage
Technologies, pages 29–42, 2003.
[21] J. Katz, A. Sahai, and B. Waters. Predicate encryption supporting
disjunctions, polynomial equations, and inner products. In EUROCRYPT’08: Proceedings of the theory and applications of cryptographic
techniques 27th annual international conference on Advances in cryptology, pages 146–162, Berlin, Heidelberg, 2008. Springer-Verlag.
[22] E. Keller, J. Szefer, J. Rexford, and R.B. Lee. NoHype: virtualized
cloud infrastructure without the virtualization. In Proceedings of the
37th annual international symposium on Computer architecture, pages
350–361. ACM, 2010.
[23] J. Li, Q. Wang, C. Wang, N. Cao, K. Ren, and W. Lou. Fuzzy keyword
search over encrypted data in cloud computing. In INFOCOM, 2010
Proceedings IEEE, pages 1–5. IEEE.
[24] E.J. McCluskey. Minimization of Boolean functions. Bell System
Technical Journal, 35(5):1417–1444, 1956.
[25] D. Naor, M. Naor, and J. Lotspiech. Revocation and tracing schemes for
stateless receivers. Lecture Notes in Computer Science, pages 41–62,
2001.
[26] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage. Hey, you, get
off of my cloud: exploring information leakage in third-party compute
clouds. In Proceedings of the 16th ACM conference on Computer and
communications security, pages 199–212. ACM, 2009.
[27] A. Sahai and B. Waters. Fuzzy Identity-Based Encryption. Advances in
Cryptology–Eurocrypt, 3494:457–473.
[28] RS Sandhu, EJ Coyne, HL Feinstein, and CE Youman. Role-based
access control models. Computer, 29(2):38–47, 1996.
[29] A. Shamir. How to Share a Secret. Communications of the ACM,
22(11):612–613, 1979.
[30] C. Wang, Q. Wang, K. Ren, and W. Lou. Privacy-preserving public
auditing for data storage security in cloud computing. In INFOCOM,
2010 Proceedings IEEE, pages 1–9. IEEE, 2010.
[31] W. Wang, Z. Li, R. Owens, and B. Bhargava. Secure and efﬁcient access
to outsourced data. In Proceedings of the 2009 ACM workshop on Cloud
computing security, pages 55–66. ACM, 2009.
[32] B. Waters. Ciphertext-policy attribute-based encryption: An expressive,
efﬁcient, and provably secure realization. ePrint report, 290, 2008.
[33] S. Yu, C. Wang, K. Ren, and W. Lou. Achieving Secure, Scalable,
and Fine-grained Data Access Control in Cloud Computing. INFOCOM’1010. Conference of the IEEE Computer and Communications
Societies. Proceedings. IEEE, pages 1–9, 2010.
[34] S. Yu, C. Wang, K. Ren, and W. Lou. Attribute based data sharing
with attribute revocation. In Proceedings of the 5th ACM Symposium on
Information, Computer and Communications Security, pages 261–270.
ACM, 2010.
[35] A. Yun, C. Shi, and Y. Kim. On protecting integrity and conﬁdentiality
of cryptographic ﬁle system for outsourced storage. In Proceedings of
the 2009 ACM workshop on Cloud computing security, pages 67–76.
ACM, 2009.

2012 8th International Conference on Network and Service Management (CNSM 2012)

45

126

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

Efﬁcient Privacy-Preserving
Ciphertext-Policy Attribute Based-Encryption
and Broadcast Encryption
Zhibin Zhou, Member, IEEE, Dijiang Huang, Senior Member, IEEE, and Zhijie Wang
Abstract—Ciphertext Policy Attribute-Based Encryption (CP-ABE) enforces expressive data access policies and each policy consists of
a number of attributes. Most existing CP-ABE schemes incur a very large ciphertext size, which increases linearly with respect to
the number of attributes in the access policy. Recently, Herranz et al. proposed a construction of CP-ABE with constant ciphertext.
However, Herranz et al. do not consider the recipients’ anonymity and the access policies are exposed to potential malicious attackers. On
the other hand, existing privacy preserving schemes protect the anonymity but require bulky, linearly increasing ciphertext size. In this
paper, we proposed a new construction of CP-ABE, named Privacy Preserving Constant CP-ABE (denoted as PP-CP-ABE) that
signiﬁcantly reduces the ciphertext to a constant size with any given number of attributes. Furthermore, PP-CP-ABE leverages a hidden
policy construction such that the recipients’ privacy is preserved efﬁciently. As far as we know, PP-CP-ABE is the ﬁrst construction
with such properties. Furthermore, we developed a Privacy Preserving Attribute-Based Broadcast Encryption (PP-AB-BE) scheme.
Compared to existing Broadcast Encryption (BE) schemes, PP-AB-BE is more ﬂexible because a broadcasted message can be encrypted
by an expressive hidden access policy, either with or without explicit specifying the receivers. Moreover, PP-AB-BE signiﬁcantly reduces
the storage and communication overhead to the order of
, where
is the system size. Also, we proved, using information
theoretical approaches, PP-AB-BE attains minimal bound on storage overhead for each user to cover all possible subgroups in the
communication system.
Index Terms—Attribute-based encryption (ABE), privacy-preserving, ciphertext-policy, constant ciphertext length, broadcast encryption

1

INTRODUCTION

C

Policy Attribute-Based Encryption (CP-ABE)
has been a very active research area in recent years [2],
[4]-[6]. In the construction of CP-ABE, each attribute is a
descriptive string and each entity may be tagged with multiple attributes. Many entities may share common attributes,
which allows message encryptors to specify a secure data
access policy over the shared attributes to reach a group of
receivers. A decryptor’s attributes need to satisfy the access
policy in order to recover the message. These unique features
make CP-ABE solutions appealing in many systems, where
expressive data access control is required for a large number
of users.
One major problem of existing CP-ABE schemes is bulky,
linearly increasing ciphertext. In the CP-ABE schemes reported
in [4], [6], and [2], the size of a ciphertext proliferates linearly
with respect to the number of included attributes. For example,
the message size in BSW CP-ABE [4] starts at about 630 bytes,
and each additional attribute adds about 250-300 bytes.
Recently, Herranz et al. [1] proposed a CP-ABE that requires constant ciphertext size. However, it does not consider
IPHTERTEXT

• Z. Zhou is with Amazon, Seattle, WA 98109. E-mail: zhibin@amazon.com.
• D. Huang and Z. Wang are with the School of Computing Informatics
Decision Systems Engineering, Arizona State University, Tempe, AZ 85287.
E-mail: {Dijiang.Huang, wangzj}@asu.edu.
Manuscript received 22 Jan. 2013; revised 18 Aug. 2013; accepted 22 Sep. 2013.
Date of publication 07 Oct. 2013; date of current version 12 Dec. 2014.
Recommended for acceptance by L. Imbert.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TC.2013.200

the anonymity of data recipients and the data access policies
are attached to the ciphertext in plaintext form. Thus, passive
attackers can track a user or infer the sensitivity of ciphertext
by eavesdropping the access policies. In many environments,
it is also critical to protect the access policies as well as the data
content. For example, the access policy “General” AND
“Pentagon” disclose the recipient’s roles or positions and
implies the sensitivities of the message. On the other hand,
existing privacy preserving schemes [2], [3] protect the access
policies but require large, linearly increasing ciphertext size.
To the best of our knowledge, there is no work that can
achieve privacy-preservation and constant ciphertext size at
the same time.
In this paper, we propose a novel PP-CP-ABE construction,
named Privacy Preserving Constant-size Ciphertext Policy
Attribute Based Encryption (PP-CP-ABE), which enforces hidden access policies with wildcards and incurs constant-size
conjunctive headers, regardless of the number of attributes.
Each conjunctive ciphertext header only requires 2 bilinear
group elements, which are bounded by 100 bytes in total. The
actual size of the bilinear group depends on the chosen
parameters for the cryptosystem. In our implementation, we
use Type–D MNT curves with element compression [7]. To
support disjunctive or more ﬂexible access policies, multiple
constant-size conjunctive headers can be attached to the same
ciphertext message. It should be noted that we restricted each
ciphertext header to be conjunctive in order to avoid ambiguity while preserving the receivers’ anonymity. Moreover, PPCP-ABE supports non-monotonic data access control policy.
To the best of our knowledge, this is the ﬁrst construction that

0018-9340 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

ZHOU ET AL.: EFFICIENT PRIVACY-PRESERVING CIPHERTEXT-POLICY ABE AND BROADCAST ENCRYPTION

achieves these properties, namely: privacy-preservation and
constant-size conjunctive headers with wildcards.
Based on presented PP-CP-ABE, we further provide a new
construction named as Privacy Preserving Attribute Based
Broadcast Encryption (PP-AB-BE). In existing BE schemes,
e.g., [8], a sender encrypts a message for a speciﬁed set of
receivers who are listening on a broadcast channel. Each
receiver in the speciﬁed set can decrypt the message while
all other listeners cannot decrypt it even though they collude
together. However, in large scale systems, identifying every
receiver, and acquiring and storing their public keys are not
easy tasks. For example, to broadcast a message to all CS
students in a university, the encryptor needs to query the CS
department roster and acquire the public key of every student
in the roster; this process could be very expensive and time
consuming.
Using PP-AB-BE, an encryptor has the ﬂexibility to encrypt
the broadcasted data either with or without the exact information of intended receivers. For example, Alice can specify a
hidden access policy: “CS” AND “Student” to restrict the
broadcast message to all CS students without specifying the
receivers explicitly. Accordingly, Bob, who has attributes
{“EE”, “Student”}, cannot decrypt the data while Carol, who
has attributes {“CS”, “Student”} can access the data. Moreover, Alice can also encrypt the broadcasted message to any
arbitrary set of receivers such as {“Bob”, “Carol”}.
PP-AB-BE also signiﬁcantly reduces the storage overhead
compared to many existing BE schemes, where cryptographic
key materials required by encryption or decryption increase
linearly or sublinearly on the number of receivers. For exam,
ple, in BGW scheme [8], the public key size is
or
where
is the number of users in the system. PP-AB-BE
reduces the key storage overhead problem by optimizing the
organization of the attribute hierarchy. In a system with
users, the storage overhead is
, where
is a
constant number and
. We also proved from the
information theoretical perspective that PP-AB-BE achieves
storage lower bound to satisfy all possible subgroup formations, and thus it can be applied to storage constrained systems.
The most signiﬁcant nature of this research article is that
we present a fundamental and uniﬁed Privacy Preserving
Attribute Based solution considering constraints on both
communication and storage, and our solution is provably
secure. It is also worth noting that our proposed PP-CP-ABE
can be used to implement an identity-based encryption with
wildcards (WIBE) [9] to achieve the ﬁrst constant ciphertext
size WIBE construction with privacy preserving features. In
summary, the main contributions of this research are presented as follows:
PP-CP-ABE: We construct an efﬁcient Privacy Preserving
Constant Ciphertext Policy Attribute Based Encryption
(PP-CP-ABE) scheme that enforces hidden conjunctive
access policies with wildcards in constant ciphertext size.
To the best of our knowledge, this is the ﬁrst construction
that achieves these properties.
PP-AB-BE: Based on PP-CP-ABE, we present a Privacy
Preserving Attribute Based Broadcast Encryption (PPAB-BE) scheme. Compared with existing BE schemes,
PP-AB-BE is ﬂexible as it uses both descriptive and
non-descriptive attributes, which enables a user to specify
the decryptors based on different abstraction levels, with

127

or without exact information of intended receivers.
Moreover, PP-AB-BE demands less storage overhead
compared to existing BE schemes. We proved that our
construction requires minimal storage to support all the
possible user group formations for BE applications.
The rest of this paper is organized as follows. We ﬁrst
summarize the related work in Section 2. Then, in Section 3,
we present system models used in this paper. We give
detailed PP-CP-ABE construction in Section 4. In Section 5,
we present the construction of PP-AB-BE and the storage
analysis using an information theoretical approach. In
Section 6, the performance of PP-AB-BE is presented through
both theoretical analysis and experimental studies. Finally,
we conclude our work in Section 7.

2

RELATED WORKS

Attribute Based Encryption (ABE) was ﬁrst proposed as a
fuzzy version of IBE in [10]. In CP-ABE [4], [5], [2], [11]-[14],
each user’s private key is associated with a set of attributes
and each ciphertext is encrypted by an access policy. To
decrypt the message, the attributes in the user private key
need to satisfy the access policy. The key difference between
identity and attribute is that identities are many-to-one
mapped to users while attributes are many-to-many mapped
to users. Thus, to simulate a constant size conjunctive header,
one needs to encrypt the message using each receiver’s identity and the size of ciphertext is linearly increasing.
In [15], the authors proposed a CP-ABE scheme with
constant size conjunctive headers and constant number of
pairing operations. It must be noted that they did not seek to
address the issues of recipient anonymity. One drawback of
their scheme does not support wildcards (or do-not-care) in
the conjunctive access policies. To decrypt a ciphertext, the
decryptor’s attributes need to be identical to the access policy.
In other words, the model is still one-to-one, i.e., an access
policy is satisﬁed by one attribute list or ID, which makes the
number of access policies increase exponentially. Thus, their
scheme can be simply implemented using IBE schemes with
same efﬁciency by using each user’s attribute list as his/her
ID. We should note that in a system with attributes, the
number of attribute combinations is . As the result, without
access policies to express all
using wildcards, there needs
combinations. With wildcards, one can use a single access
policy to express many combinations of attributes. Herranz
et al. [1] proposed a more general construction of CP-ABE
with constant ciphertext independently. Their proposed
scheme achieves constant ciphertext with any monotonic
threshold data access policy, e.g. n-of-n (AND), 1-of-n (OR)
and m-of-n. However, compared with our proposed PP-CPABE, their scheme does not consider recipient anonymity as
one of the design goals.
To protect the privacy of the access policy, KSW scheme [2],
NYO scheme [3], RC scheme [13] and YRL1 scheme [16] were
proposed, where the encryptor-speciﬁed access policy is
hidden. Speciﬁcally, the attribute names in both [13] and
[16] are explicitly disclosed in the access policy, while only
the eligible attribute values are hidden. Also, YRL2 scheme
was proposed in [17] based on BSW scheme [4] as a group key
management scheme providing group membership anonymity. In [18], we proposed a novel alternative to the hidden

128

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

policy to preserve privacy efﬁciently. The main difference
between our scheme and existing hidden policy attributebased encryption schemes is PP-CP-ABE signiﬁcantly reduced the size of ciphertext to a constant size, while all existing
hidden policy solutions requires ciphertext that is linearly
increasing on the number of attributes in the hidden policy.
It must be noted that the construction in this paper is
developed from one of our earlier construction [14], where
we proposed an ABE scheme with constant size ciphertext.
The major improvements of in this paper are in 3 folds: 1) we
introduce the privacy-preserving requirements for ABE and
incorporate the privacy-preserving solutions into the previous approaches; 2) we present a PP-AB-BE with an information theoretical analysis to address its complexity; and 3) we
conduct a comprehensive performance evaluation.
ABE can be used as a perfect cryptographic building block
to realize Broadcast Encryption (BE), which was introduced
by Fiat and Naor in [19]. The encrypter in the existing BE
schemes need to specify the receiver list for a particular
message. In many scenarios, it is very hard to know the
complete receiver list and it is desirable to be able to encrypt
without exact knowledge of possible receivers. Also, existing
BE schemes [8], [20] can only support a simple receiver list.
It is hard to support ﬂexible, expressive access control policies.
A broadcast encryption with an attribute based mechanism
was proposed in [21], where an expressive attribute-based
access policy replaces the ﬂat receiver list. Also, in [22] and [5],
the authors proposed to use a CP-ABE [4], [5] and ﬂat-table
[23] mechanism to minimize the number of messages and
support expressive access policies. Compared with these
works, our proposed scheme signiﬁcantly reduces the size
of ciphertext from linear to constant.

3

MODELS

In this section, we ﬁrst describe how to use attributes to form a
data access policy, followed by the concept of the broadcast
encryption based on an attribute-based mechanism. Then we
present the bilinear map, which is the building block of ABE
schemes. Finally, we present the complexity assumption,
which will be used for our security proof.

3.1 Attributes, Policy and Anonymity
Let
be the Universe of attributes in the system.
has three values:
. When a user joins
Each
the system, is tagged with an attribute list deﬁned as follows:
,
Deﬁnition 1. A user’s attribute list is deﬁned as
and is the number of attributes in the
where
universe.
denotes the user has ;
denotes the user
Intuitively,
does not have or is not a proper attribute of this user. For
example, suppose
. Alice is a student in CS department; Bob is
a faculty in EE department; Carol is a faculty holding a joint
position in EE and CS department. Their attribute lists are
illustrated in Table I.
As the actual data access policy is hidden in the ciphertext
header, effective measures are required to avoid ambiguity. In
other words, when a decryptor receives a ciphertext header
without knowing the access policy, he/she should NOT try a

TABLE 1
Attribute Examples

TABLE 2
An Example of the Access Policies and Anonymized Policies

where ✠ represents “do not care”.

large number of access policies when performing decryption.
To this end, we adopt a AND-gate policy construction so that
each decryptor only needs to try once on each ciphertext
header.
The hidden AND-gate access policy is deﬁned as follows:
be an AND-gate access
Deﬁnition 2. Let
. We use the notation
policy, where
to denote that the attribute list
of a user satisﬁes
, as:

or
requires the exact same attribute in the user’s
, it denotes a wildcard value, which
attribute list. As for
means the policy does not care about the value of attribute .
or
fulﬁlls
Effectively, each user with either
automatically.
Accordingly, we also deﬁne an anonymized AND-gate
policy that removes all identifying attribute values, i.e.
, except do-not-care values, i.e.
. Formally, we
deﬁne an anonymized AND-gate policy as follows:
be an anonymized AND-gate
Deﬁnition 3. Let
access policy.
We note that the do-not-care attribute values are included
in the anonymized access policy. If we hide the wildcard
attributes, the decryptor will need to guess possible access
policies if there are attributes in the policy, i.e., for each
or the speciﬁc value (
or
attribute, its value can be either
) assigned to the decryptor. This would make the scheme
infeasible in terms of performance. Table II shows an example
for all CS students and an access
to specify an access policy
for all CS people:
policy
The anonymity policy is deﬁned as the state of being not
identiﬁable within a set of subjects, i.e., the anonymity set. As the
access policy is one-to-many mapped to users, we can extend
this deﬁnition of policy anonymity set of blinded policy as:
Deﬁnition 4. The anonymity set of a blinded policy is the set of
access policies which are identically blinded to .
Here, we brieﬂy analyze the anonymity level of the blinded
access policy. Firstly, if there are no wildcards in the original

ZHOU ET AL.: EFFICIENT PRIVACY-PRESERVING CIPHERTEXT-POLICY ABE AND BROADCAST ENCRYPTION

and

access policy (hidden), the blinded policy will be empty. In
this case, the size of anonymity set is , as there are possible
access policies blinded to . If there are wildcards in the
.
original access policy (hidden), the size of anonymity set is

3.2 Broadcast with Attribute-Based Encryption
A broadcast encryption is usually applied in the scenario
wherein a broadcaster sends messages to multiple receivers
through an insecure channel. The broadcaster should be able
to select a subset of users with certain policies from all
receivers, and consequently only the eligible users are able
to decrypt the ciphertexts and read the messages. It is possible
that the number of all possible receivers are inﬁnite, and the
subset of privileged receivers changes dramatically in each
broadcast based on the content of the message and the will of
the broadcaster.
The notion of Attribute-based Encryption [10] can be
utilized to address this problem. In ABE, all the possible
receivers are ascribed by an attribute set. As such, the broadcaster can specify an expressive policy and select a group of
privileged receivers deﬁned by their attributes. Consequently,
only the receivers whose attributes satisfy the policy embedded into the access structure are able to decrypt the ciphertexts
transmitted through the unsecured broadcast channel.
3.3 Bilinear Maps
A pairing is a bilinear map G
G
G , where G and G
are two multiplicative cyclic groups with large prime order .
The Discrete Logarithm Problem on both G and G is hard.
Pairing has the following properties:
Bilinearity:
G

Z

Nondegeneracy:
where is the generator of G .
Computability:
There exist an efﬁcient algorithm to compute the
pairing.

3.4 Complexity Assumption
The security of our proposed constructions is based on a
complexity assumption called the Bilinear Difﬁe-Hellman
Exponent assumption (BDHE) [24].
Let G be a bilinear group of prime order . The -BDHE
problem in G is stated as follows: given the following vector
is not in the list):
of
elements (Note that the
G
as the input and the goal of the computational -BDHE
. We can denote the the set as:
problem is to output

Deﬁnition 5. (Decisional -BDHE). The decisional -BDHE
assumption is said to be held in G if there is no probabilistic
polynomial time adversary who is able to distinguish

129

with non-negligible advantage, where
Z and
are chosen independently and uniformly at random.

4

G

PP-CP-ABE CONSTRUCTION

In this section, we present our construction of the PP-CP-ABE
scheme.

4.1 PP-CP-ABE Construction Overview
The PP-CP-ABE scheme consists of four fundamental
algorithms:
The Setup algorithm takes input of the security paramand the number of attributes in the system .
eter
It returns public key
and master key
. The public
key is used for encryption while the master key is used for
private key generation.
The KeyGen algorithm takes the public key
, the
master key
and the user’s attribute list as input.
It outputs the private key of the user.
The Encrypt algorithm takes the public key
, the
speciﬁed access policy
and the message
as input.
The algorithm outputs ciphertext
such that only a user
with attribute list satisfying the access policy can decrypt
the message. The ciphertext also associates the anonymized access policy .
The Decrypt algorithm decrypts the ciphertext when
the user’s attribute list satisﬁes the access policy. It takes
the public key
, the private key
of the user and the
ciphertext
, which only includes the anonymized
as input. It returns a valid plaintext
access policy
if
, where is the user’s attribute list and
is the
access policy hidden from the ciphertext.
Boneh et al. proposed a broadcast encryption construction
with constant ciphertext size in [8], where the broadcast
encryptor uses the public key list corresponding to intended
receivers to perform encryption. To make the ciphertext
constant, each receiver’s public key is multiplied together,
assuming a multiplicative group structure. Thus, the resulting
ciphertext is still an element on the group, i.e., the size of the
ciphertext is constant. We use a similar strategy to achieve
constant ciphertext in our proposed scheme.
In our construction, each public key is mapped to an
. To encrypt a message, the
attribute value, including
encryptor speciﬁes an access policy
by assigning an attri) for each of the attributes in the
bute value (
Universe and encrypts the message using public keys of the
attribute values in the . Each decryptor is generated as a set
of private key components corresponding to his/her attribute
list . All the private key components of the same user are tied
together by a common random factor to prevent collusion
attacks.

4.2 Setup
Assuming there are attributes
in the system, we have
attribute values since each attribute

130

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

TABLE 3
Mapping Attribute Values to Numbers

has 3 values:
. For ease of presentation, we map
the attribute values to integer numbers as depicted in the
Table 3.
Trusted Authority (TA) ﬁrst chooses 2 bilinear groups G
and G of prime order (such that is bits long) and a
G
G . TA then picks a random
bilinear map
G
Z . It computes
generator
G and a random
for
where
. Next,
G . The public
TA picks a random
Z and sets
key is:
G
The master key

Algorithm 1 Construct local guess
Initialize
for

to k do
✠ then

if

is guarded by the TA.

4.3 Key Generation
Each user is tagged with the attribute list
. The TA ﬁrst
when joining the system, where
from Z and calculate
selects random numbers
.
. For
, TA calcuThe TA computes
lates
and
.
The private key for user is computed as:

4.4 Encryption
The encrypter picks a random in Z and sets the one-time
. Suppose ANDsymmetric encryption key
gate policy is
with attributes. Each attribute is either
positive/negative or wildcards.
The encryptor ﬁrst encrypts the message using symmetric
. The encryptor also sets
. Then, it
key
as
calculates
. Also, the encryptor anonymizes the access policy
by removing all attribute values
, and outputs
except do-not-care values, i.e.
.
Finally, the ciphertext is:

where the ciphertext header

a random string which can be easily detected. Moreover,
the access policy remain unknown to the unsuccessful
decryptors.
First of all, constructs a local guess of access policy,
denoted as , as speciﬁed in Algorithm 1. Essentially, this
algorithm constructs only one guess by replacing hidden
with the correattributes in the anonymized access policy
sponding attribute values of the receiver. If the receiver
satisﬁes the access policy, the Algorithm 1 will always produce the correct guess and the decryption will succeed. On the
other hand, if a guess is not identical to the actual access
policy, the decryption will fail and the decryptor does not
need to try other guesses.

;
end if
end for
return

;

For

And if

,

calculates the

,

Else, if

and

as follows.

computes:

,

computes:

.

4.5 Decryption
Before performing decryption, the decryptor has has little
information about the access policy that is enforced over the
can successfully recover the
ciphertext. Only if
valid plaintext and access policy. Otherwise, can only get

Then, we calculate

After calculates all terms, we make a production of all
the quotient terms and get:

ZHOU ET AL.: EFFICIENT PRIVACY-PRESERVING CIPHERTEXT-POLICY ABE AND BROADCAST ENCRYPTION

calculates:

Then,

produces these two terms and gets

and decrypts the message. If the
decrypted message is valid,
and
decrypts the
ciphertext successfully. Otherwise, has no information on
does not change.
the
and the anonymity set of

4.6 Security Analysis
We reduce Chosen Plaintext Attack (CPA) security of our
proposed scheme to decisional -BDHE assumption. We ﬁrst
deﬁne the decryption proxy to model collusion attackers.
Security Game for PP-CP-ABE
A CP-ABE scheme is considered to be secure against
chosen CPA if no probabilistic polynomial-time adversaries
have non-negligible advantages in this game.
Init: The adversary chooses the challenge access policy
and gives it to challenger.
Setup: The challenger runs the Setup algorithm and gives
the adversary the PK.
Phase 1: The adversary submits for a KeyGen query,
where
. The challenger answers with a secret key SK for
. This can be repeated adaptively
Challenge: The challenger runs Encrypt algorithm to ob>
. Next, the challenger picks a random
tain <
and picks a random
with
. It sets
in G . It then gives <
>
to
same length to
the adversary.
Phase 2: Same as Phase 1.
and it
Guess: The adversary outputs its guess
.
wins the game if
Note that the adversary may make multiple secret key
queries both before and after the challenge, which results in
the collusion resistance in our proposed scheme. We also
point out this CPA security game is called as selective ID
security, because the adversary must submit a challenge
access structure before the setup phase.
Theorem 1. If a probabilistic polynomial-time adversary wins the
CPA game with non-negligible advantage, then we can
construct a simulator that distinguish a -DBHE tuple with
non-negligible advantage.
Proof of Theorem 1. We reduce CPA security of our
proposed scheme to decisional
-BDHE assumption.
We ﬁrst deﬁne the decryption proxy to model collusion
attackers.
◽
Deﬁnition 6. (Decryption Proxy). In order to model the
collusion attacks, we deﬁne
decrypting proxies in the
, where
security game. Each decrypting proxy
, i.e., a private key component
Z and
corresponding to a particular attribute value.
In collusion attacks against access policy , a user with
attribute list
collude with
decryption proxies to
attack the ciphertext. We call the colluding with decryption
proxy as -collusion. Intuitively, -collusion means the atto add to
tacker needs attributes values, say

131

his attribute list such that
. Note that
0-collusion means no decryption proxy is used and user does
not collude.
Suppose that an adversary A wins the selective game for
PP-CP-ABE with the advantage . Then, we can construct a
Simulator B that breaks decisional -BDHE assumption with
the advantage
. The simulator B takes an input a random decisional
-BDHE challenge

or a random element on G . B
where is either
now plays the role of challenger in the pre-deﬁned CPA game:
Init: A sends to B the access policy
that A wants to be
challenged.
Setup: B runs the Setup algorithm to generate
. B
chooses random
Z and generates:

The B outputs the PK as:
G
Phase 1: The adversary A submits an attribute list for a
private key query, where
. Otherwise, the simulator
quits.
Z for
The simulator B ﬁrst selects random numbers
. Then, B generates
and set

Then, for

and

Then, for

and

Note that each for each

, B generates:

, B generates:

is valid since:

and

Challenge: The simulator B sets <
>
It then gives the challenge <

> as <
to A.

>.

132

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

To see the validity of challenge,
unknown . Then:

and if
, then
.
Phase 2: Repeat as Phase 1.
Guess: The adversary A output a guess

in the private key, is the number of private key queries in
phase 1 and phase 2, is the number of calling decryption
proxy with different , and is the order of Z . Note that if
, A can use
as a valid private key component to
compromise the ciphertext.
If the A has at least advantage in breaking our scheme,
advantage in breaking
then B has at least
-BDHE.
-collusion If decryption proxies, say

for some

of . When

are used. The possibility that
, where is the random number in decryption
for the private key component ,
is the
proxy
random number generated for the A, is the number of private
key queries in phase 1 or phase 2, is the number of calling
decryption proxies with different ‘s, is the order of Z .
If the A has at least advantage in breaking our scheme,
advantage in
then B has at least
breaking -BDHE.
This concludes the proof.
◽

,

. When
, A guesses is a
A guesses that
random element.
If is a random element, then the
B
.
, we
Before considering the case when
explain how we use decryption proxy in the proof. Each
simulates a legal private key compodecryption proxy
,A
nent embedded with random number . When calling
passes a random as a guess of the , which is the random
. As a matter of
number embedded in the or , where
fact, the procedure of calling decryption proxy mimics the
collusion of multiple users, who combine their private key
components.
Lemma 1. Suppose the A has issued private queries and there is
times. The possibility
only 1 attribute
, A queries
that the none of the queries returns a legal private key component
.
of any is
Proof of Lemma 1. The possibility that the one query does not
return a legal private key component of any is
.
Thus, if none of the query succeed, the probability
, where is the random number
is the random number
in decryption proxy,
embedded in the private key, is the number of private
key queries in phase 1 and phase 2, is the number of calling
decryption proxy with different , and is the order of Z . ◽
Lemma 2. Suppose the A has issued private queries and there is
attributes violate the , A queries each of the decryption
times. The possibility that
proxy
the none of the queries returns a legal private key component of
.
any is
Proof of Lemma 2. The probability that 1 decryption proxy
. The probability that all the
fails is
decryption proxy successfully return legal components
. In the case of not all succeed, the
is
.
probability is
If
, we consider the following cases:
0-Collusion: If no decryption proxy is used, A has at least
advantage in breaking our scheme, then B has at least
advantage in breaking -BDHE, i.e.,
B
1-collusion If 1 decryption proxy, say
is used,
, where is the random number
in decryption proxy, is the random number embedded

5

PRIVACY PRESERVING ATTRIBUTE-BASED
BROADCAST ENCRYPTION

Based on our construction of PP-CP-ABE, we construct an efﬁcient and ﬂexible Broadcast Encryption (BE) scheme—Privacy
Preserving Attribute Based Broadcast Encryption (PP-AB-BE),
where the size of any single ciphertext is still constant.
Compared to existing BE schemes, using PP-AB-BE, encryptor does not need to store a large number of key materials,
i.e., public key and private key. By carefully organizing the
attributes in the system, we will show that the storage overhead of each user can be reduced from
to
,
where is the number of users in the system and
is
the number of descriptive attributes in the system.
Also, in PP-AB-BE, an encryptor enjoys the ﬂexibility of
encrypting broadcast data using either a speciﬁc list of decryptors or an access policy without giving an exact list of
decryptors.

5.1 PP-AB-BE Setup
In PP-AB-BE with users, each user is issued an -bit binary
, where
represents the ‘th bit in the user’s
ID
binary ID, where
. Accordingly, we can deﬁne bit. Each user is assigned
assignment attributes
bit-assignment attribute values according to his/her ID. If
, he/she is assigned the
, if the
, he/she is
the
. For example, in a system with 8 possible
assigned the
users, each user is assigned 3 bit-assignment attributes to
represent the bit values in their ID, as illustrated in Fig. 1.
Given the
the bit-assignment attributes, the TA
generates
attribute values, i.e., bit-assignment attribute
has
values.
In addition to the bit-assignment attributes, the TA also
chooses
descriptive attributes for the system. These descriptive attributes present the real properties or features of an
entity, which can be used to describe the decryptors’ social or
role features, e.g., “CS”, “EE”, “Student”, “Faculty”, etc. Each
of the descriptive attributes has
values.

ZHOU ET AL.: EFFICIENT PRIVACY-PRESERVING CIPHERTEXT-POLICY ABE AND BROADCAST ENCRYPTION

133

TABLE 4
Sample Policies

Fig. 1. An illustration of ID and bit-assignment attributes distribution.

With the

attribute values, the authority runs
algorithm and generate public keys and pri-

vate keys.

5.2 Broadcast Encryption
In order to control the access to the broadcasted message, the
sender needs to specify an access policy using either the
descriptive attributes or bit-assignment attributes. For example in the Table 4, if Alice wants to send a message to all CS
in the
students, she can specify the descriptive policy
following table. Or if she wants to send a message to Bob and
Carol, whose IDs are 100 and 101 respectively, she can use the
, which is equivalent to enumerating
bit-assignment policy
every receiver.
Here, we focus on how an encryptor can specify the list of
receivers explicitly using bit-assignment attributes. We ﬁrst
deﬁne some of the terms used in the following presentations:
Literal: A variable or its complement, e.g., , , etc.
Product Term: Literals connected by AND, e.g.,
.
Sum-of-Product Expression (SOPE): Product terms con.
nected by OR, e.g.,
,
Given the set of receivers , the membership functions
which is in the form of SOPE, speciﬁes the list of receivers:

, then
.
Then, the broadcast encryptor runs the Quine-McCluskey
to minimal SOPE
. The
algorithm [25] to reduce
reduction can consider do not care values on those IDs that
are not currently assigned to any receiver to further reduce the
number of product terms in the membership function. For
.
example, if
,
is in the form of SOPE, encryption is performed
Since
,
on each product term. That is, for each product term in
the encryptor speciﬁes an AND-gate access policy
using
the following rules:
, set
in the access policy .
1) For positive literal
, set
in the access
2) For negative literal
policy .
for the rest of bit-assignment attributes.
3) Set
For each
, the encryptor uses
algorithm to encrypt the message. The total number of
encrypted messages equals the number of product terms in
.
.
For example, if
,
and
are shown in the following
The access policies
table:

We can ﬁnd that
contains 2 product terms. the mesand
sage for can be encrypted into 2 ciphertexts with
respectively.

5.3 Information Theoretical Optimality
In this section, we present the optimality of PP-AB-BE through
an information theoretical approach similar to the models in
[26]. In Section 5.3.1, we proved that PP-AB-BE attains the
information theoretical lower bound of storage requirements
with
bit-assignment attributes. In Section 5.3.2, we
also compared the BGW [8] BE scheme [8] and PP-AB-BE from
information theoretical perspective.
5.3.1 Optimal Storage
To be uniquely identiﬁed, each user’s ID should not be a preﬁx
of any other user’s ID, i.e. preﬁx-free. For example, suppose a
user is issued an ID 00, which is preﬁx of with ID 000 and
with ID 001. When an encryptor tries to reach and , the
, which is also
minimized membership function is
satisﬁed by . Similarly, it is also imperative that a user’s bitassignment attributes should not be a subset of any other
user’s attribute set. The preﬁx free condition is a necessary and
sufﬁcient condition for addressing any user with their bitassignment attributes.
Theorem 2. If we denote the number of bit-assignment attributes
for a user by . For an broadcast encryption system with
users and satisfy the preﬁx-free condition, the set
satisﬁes the Kraft inequality:

For example, if the subgroup

Proof of Theorem 2. The proof is available in [27].
◽
Assuming bit-assignments are required to identify and
the probability to send a message to is , we can model the
storage overhead as:

Intuitively, this formation argues that the storage over
head from a sender’s perspective is the average number of
bit-assignments required to address to any particular receiver.
Thus, an optimization problem is formulated to minimize the
storage overhead for a broadcast encryption system:

134

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

This optimization problem is identical to the optimal code
word-length selection problem [27] in information theory.
Before giving the solution to this optimization problem, we
deﬁne the entropy of targeting one user in our system:
Deﬁnition 7. The entropy

To compare the minimalist and maximalist storage strategy, we can deﬁne The entropy of an attribute or a public key is
deﬁned as:

of targeting a user is

Theorem 3. For a system of users with preﬁx free distribution of
bit-assignments, the optimal (i.e., minimal) average number of
storage overhead required for a sender to address a receiver,
can be given by the binary entropy
written as

where as the percentage of totals users who have this
attributes or public key. We see the entropy of each attribute
in minimalist strategy as
since, for each particular
attribute, exactly half of the users have it while the other half
do not have it. On the other hand, the entropy of public key in
maximalist strategy is
< . Hence, we can conclude that minimalist strategy attains maximal binary entropy while the
maximalist strategy attains minimal binary entropy.

6
Proof of Theorem 3. The theorem is equivalent to to optimal
codeword-length selection problem and proof is available
in [27].
Since the average number of bit-assignment attributes
required for addressing one particular receiver is given by
the entropy of targeting a user, we now try to derive the upper
and lower bounds of the entropy:

and

The upper bound
is
,
, when each user
yielded when
has equal possibility to be addressed as the receiver. When
there is no apriori information about the probability distribution of targeting one of the users,
corresponds to the optimal strategy to minimize the average number of storage overhead required for each user. On
is achieved
the other hand, the lower bound
for
, which is an extreme
when
case where there is no randomness and only one user is
reachable.

5.3.2 Compare with BGW BE Scheme
If we denote our optimal bit-assignment attributes assignment to be minimalist, which requires the least number of bitassignment attributes to identify each user. We can refer BGW
scheme in [8] as maximalist. In BGW scheme, for a system
with
users, each user is mapped to a unique public key.
Given all
public keys, the number of combinations is
, which equals the number of receiver subsets in the
system. Thus, each encryptor needs maximal number of
public keys to perform broadcast encryption.

SYSTEM PERFORMANCE ASSESSMENT

In this section, we analyze the performance of PP-AB-BE and
compare it with several related solutions: subset-difference
broadcast encryption scheme (Subset-Diff) [19], BGW [8], and
FT implemented using CP-ABE (FT-ABE) [22]. We also compared some works in tree-based multicast group key distribution domain where a group controller removes some group
members by selectively multicasting key update messages to
all remaining members. Those solutions can be broadly divided into 2 categories: Flat-Table (FT) scheme [23] and NonFlat-Table schemes, including OFT [28], LKH [29], ELK [30].

6.1 Communication Overhead
The complexity analysis of communication overhead for
various schemes is summarized in Table 5. In Subset-Diff
,
scheme, the communication overhead is
with as maximum number of colluding users to compromise the ciphertext. For BGW scheme, the message size is
as reported in [8]. In ACP scheme, the size of message
depends on the degree of access control polynomial, which
equals the number of current receivers. Thus, the message
size is
.
For Non-ﬂat-table tree-based multicast key distribution
schemes such as OFT [28], LKH [29], ELK [30], etc., the
communication overhead for removing members depends
on the number of keys in the tree that need to be updated [31],
[30]. In the case of removing a single member,
messages are required since the center needs to update
auxiliary keys distributed to the removed member.
Some tree-based schemes tried to optimize the number of
messages to update all the affected keys in the case of multiple
leaves. In ELK [30], which is known to be one of the most
efﬁcient tree-based schemes, the communication overhead for
multiple leaves is
, where
is the number of
affected keys and is the number of leaving members. Thus,
the complexity can be written as
.
For ﬂat-table tree-based scheme [23], the complexity of
removing a single member is also
. The main beneﬁt
of ﬂat-table, however, is the minimal number of messages for
batch removing multiple members. In fact, our scheme requires the same number of messages compared to ﬂat-table
schemes, thus they both achieved information theoretical
optimality. However, ﬂat-table is vulnerable to collusion

ZHOU ET AL.: EFFICIENT PRIVACY-PRESERVING CIPHERTEXT-POLICY ABE AND BROADCAST ENCRYPTION

135

TABLE 5
Comparison of Communication Overhead and Storage Overhead in Different Broadcast Encryption Schemes and Group Key
Management Schemes

N: the number of group members; l: the number of leaving members; t: maximum number of colluding users to compromise the ciphertext.

attacks. In [22], the authors proposed to implement ﬂat-table
using CP-ABE [4] to counter collusion attacks.
To control a set of receivers using PP-AB-BE, the number
of messages depends on the number of product terms in the
. In [32], the authors derived an upper bound and lower
bound on the average number of product terms in a minimized SOPE. Experimentally, the average number of messages required is
[22].

6.1.1 Number of Messages: Worst Cases
We examine some cases when maximal number of messages is
required to reach multiple receivers.
Lemma 3 (Multiple Receivers Worst Case). The worst case of
reaching multiple receivers happens when both of following
conditions hold: 1) the number of distinct receivers is
;
2) the Hamming distance between IDs of any two receivers is at
least 2. In the worst case, the number of key updating messages
is
.
Proof of Lemma 3. Please refer to [23] for complete proof. ◽
In this case, the number messages is
using
PP-AB-BE. However, we can see that the worst cases happens
in extremely low probability:
Lemma 4 (Worst Case Possibility). When communicating all
subgroups with uniform opportunity, the worst case scenario
.
happens with probability
Proof of Lemma 4. In the worst case, the Hamming distance
of IDs of
receivers should be at least 2. As shown in the
Karnaugh table in Fig. 2, each cell represents an ID. For any
cell marked 0 and any cell marked 1, the Hamming
distance is at least 2. Thus, the worst cases happens in
two cases: (1) the encryptor wants to reach
receivers
marked 1 in Fig. 2; (2) the encryptor wants to reach
receivers marked 0 in Fig. 2.
We also have the worst case for communicating with the
majority of users.
Lemma 5 (Worst Case of Reaching N-2 Receivers). When
reaching
receivers, the maximal number of messages
required is
, when the Hamming distance between
2 non-receivers is .
Proof of Lemma 5. Please refer to [23].

◽

6.1.2 Number of Messages: Average Case
To investigate the average case, we simulated PP-AB-BE in a
system with 512 users and 1024 users, and the number of
messages required are shown in Figs. 3 and 4 respectively. In

Fig. 2. Worst cases of broadcast encryption to

receivers.

the simulation, we consider the cases of 0%, 5%, 25%, 50% IDs
are not assigned (i.e., do not care value). For each case, different
percentages of receivers are randomly selected from the
group. We repeat this 100 times to average the results. As
shown in Figs. 3 and 4, PP-AB-BE achieves roughly
complexity, where the number of messages is bounded by
for the 512-member group and
for the 1024member group.

6.1.3 Total Message Size
Finally, as shown in Figs. 5 and 6, we look into the message
size of PP-AB-BE, with comparison to FT-CP-ABE [22]. As
mentioned in [22], in FT-CP-ABE, the size of ciphertext grows
linearly based on the increase of the number of attributes in
the access policy [22], [4]. Experimentally, the message size in
FT-CP-ABE starts at about 630 bytes, and each additional
attribute adds about 300 bytes. In a system with 10 bit ID or
1024 users, the number of attributes using FT-CP-ABE ciphertext is at most 10 and the message size may be as large as
bytes. Since the number of attributes in
the access policy is bounded by
, we can conclude that
the communication overhead of FT-CP-ABE is in the order of
. In PP-AB-BE, every ciphertext contains exactly 2
group member on G . Empirically, the size of one element on
G is about 128 bytes. Thus, the ciphertext header in PP-AB-BE
is bounded within 300 bytes, which is signiﬁcantly smaller
than the ciphertext size reported in FT-CP-ABE [22]. Morein the ciphertext can be shared
over, since the component
by multiple messages, we can further reduce the message size
of PP-AB-BE with efﬁcient communication protocol design.
6.2 Storage Overhead
In PP-AB-BE, there are
Also, a user needs to store
Thus, the storage overhead is

elements on G in the
.
descriptive attributes.
, assuming a user

136

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

Fig. 5. Total size of messages in a system with 512 users.
Fig. 3. Number of messages in a system with 512 users.

Fig. 6. Total size of messages in a system with 1024 users.

Fig. 4. Number of messages in a system with 1024 users.

does not store any IDs of other users. Although the broadcast
encryptor may need the list of receivers’ IDs along with the list
of do not care IDs to perform boolean function minimization,
we can argue that this does not incur extra storage overhead.
The encryptors do not need to store the receiver’s IDs after
the broadcast; thus, the storage space can be released.
The TA can periodically publish the minimized SOPE of
all do not care IDs, which can be used by encryptors to
further reduce number of messages.
If IDs are assigned to users sequentially, i.e., from low to
high, TA can simply publish the lowest unassigned IDs to
all users, who can use the all higher IDs as do not care
values.
Even if a user needs to store
IDs, the space is merely
.
bits. If
If a broadcast encryptor cannot utilize do not care values to
further reduce the membership function in SOPE form,
the communication overhead might be a little higher. As
shown in Figs. 3 and 4, the curve of 0% vacancy can also be
used as number of messages required if a broadcast
encryptor does not know the do not care IDs.

6.3 Computation Overhead
In this section, we compare the computation overhead of
those asymmetric key based schemes and the summarized
results are presented in Table 6. In ACP scheme, the author
ﬁnite ﬁeld operations
reports that the encryption needs
when the sub-group size if ; in the BGW scheme, the
encryption and decryption require
operations on the
bilinear group, which are heavier than ﬁnite ﬁeld operations
[33]. In PP-AB-BE, each encryption requires
operations
pairings
on the G , and the decryption requires
and
operations on G and
operations on G . Thus, the complexities of encryption and
decryption are bounded by
. Although the problem
of minimizing SOPE is NP-hard, efﬁcient approximations are
widely known. Thus, PP-AB-BE is much more efﬁcient than
ACP and BGW when group size is large.
In Table 7, we summarize the computation overhead based
on the benchmark evaluations for PP-CP-ABE operations. The
benchmark was performed on a modern workstation which
has a 3.0 GHz Pentium 4 CPU with 2 MB cache and 1.5 GB
memory and runs Linux 2.6.32 kernel. In the performance
evaluation, the Type- D curve [7] is used in the testing. We run
each of the algorithm 100 times and the result is the average
value. Since the Encryption algorithm only requires

ZHOU ET AL.: EFFICIENT PRIVACY-PRESERVING CIPHERTEXT-POLICY ABE AND BROADCAST ENCRYPTION

TABLE 6
Comparison of Computation Complexity in Different Broadcast
Encryption Schemes

137

complete hidden access policy without needing to identify the
involved wildcard attributes.

ACKNOWLEDGMENTS

N: the number of group members; M: the number of receivers.

The authors thank anonymous reviewers for their insightful
comments to improve the quality of this article. This research
is sponsored by ONR YIP Award N00014-10-1-0714 and ARO
Research Grant W911NF-11-1-0191.

TABLE 7
Computation Overhead for 1024 and 4096 Group

REFERENCES

operations on the G group, the encryption time difference
between 1024 group and 4096 group is very small. On the
other hand, the decryption algorithm requires
expensive pairings operations, and
operations on the G group. Thus, the decryption on 4096
groups requires 4 more pairing operations than the decryption on 1024 group and each pairing requires around 20 ms in
our experiment. Overall, the experiment results are consistent
with our complexity analysis.

7

CONCLUSION

AND

FUTURE WORK

In this paper, a Constant Ciphertext Policy Attribute Based
Encryption (PP-CP-ABE) was proposed. Compared with existing CP-ABE constructions, PP-CP-ABE signiﬁcantly reduces the ciphertext size from linear to constant and supports
expressive access policies. Thus, PP-CP-ABE can be used in
many communication constrained environments.
Based on PP-CP-ABE, we further proposed an Attribute
Based Broadcast Encryption (PP-AB-BE) scheme that attains
information theoretical minimal storage overhead. Thus, a
storage restricted user can easily pre-install all required key
materials to perform encryption and decryption. Through
theoretical analysis and simulation, we compared PP-AB-BE
with many existing BE solutions and we showed that PP-ABBE achieve better trade-offs between storage and communication overhead.
The security of PP-CP-ABE is based on selective-ID attackers. One open problem is constructing constant CP-ABE that is
secure against adaptive adversaries. Another limitation of this
paper is the PP-CP-ABE is constructed and proved following
BGW [8] model. We are looking for new constructions with
equal or stronger security level. Also, in this paper, we only
proved PP-AB-BE is minimalist in terms of storage overhead.
We are working on more information theoretical analysis that
takes into account both storage-communication overhead in
BE schemes.
The future research of this work will have two directions:
First, the presented solution only supports conjunctive access
policy. An important improvement is to extend access policies
to support more ﬂexible forms, e.g., including disjunctive
normal form and non-monotonic form. Second, the wildcard
attribute is not hidden in the access policy to avoid ambiguity
for the decryptor, an interesting enhancement is to support a

[1] J. Herranz, F. Laguillaumie, and C. Ràfols, “Constant size ciphertexts in threshold attribute-based encryption,” in Proc. Public Key
Cryptography (PKC), 2010, pp. 19-34.
[2] J. Katz, A. Sahai, and B. Waters, “Predicate encryption
supporting disjunctions, polynomial equations, and inner products,” in Proc. Adv. Cryptology (EUROCRYPT), vol. 4965,
2008, pp. 146-162
[3] T. Nishide, K. Yoneyama, and K. Ohta, “Attribute-based encryption
with partially hidden encryptor-speciﬁed access structures,” in Proc.
Appl. Cryptography Netw. Security, vol. 5037, 2008, pp. 111-129.
[4] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-policy attributebased encryption,” in Proc. IEEE Symp. Security Privacy, 2007, pp.
321-334.
[5] L. Cheung and C. Newport, “Provably secure ciphertext policy
ABE,” in Proc. 14th ACM Conf. Comput. Commun. Security,
2007, pp. 456-465.
[6] D. Boneh and B. Waters, “Conjunctive, subset, and range queries on
encrypted data,” in Proc. Theory Cryptography, 2007, pp. 535-554
[7] B. Lynn, “On the implementation of pairing-based cryptosystems,”
PhD dissertation, Stanford Univ., Stanford, CA [Online]. Available:
http://crypto.stanford.edu/pbc/thesis.pdf, 2007.
[8] D. Boneh, C. Gentry, and B. Waters, “Collusion resistant broadcast
encryption with short ciphertexts and private keys,” in Proc. Adv.
Cryptology (CRYPTO). Springer, 2005, pp. 258-275
[9] M. Abdalla, D. Catalano, A. Dent, J. Malone-Lee, G. Neven, and N.
Smart, “Identity-Based encryption gone wild,” in Proc. Automata,
Languages Program., 2006, pp. 300-311.
[10] A. Sahai and B. Waters, “Fuzzy identity-based encryption,” in Proc.
Adv. Cryptology—Eurocrypt, vol. 3494, 2004, pp. 457-473
[11] R. Ostrovsky and B. Waters, “Attribute-based encryption with nonmonotonic access structures,” in Proc. 14th ACM Conf. Comput.
Commun. Security, 2007, pp. 195-203.
[12] V. Goyal, A. Jain, O. Pandey, and A. Sahai, “Bounded ciphertext
policy attribute based encryption,” in Proc. Automata, Languages
Program. Springer, 2008, pp. 579-591.
[13] S. Roy and M. Chuah, “Secure data retrieval based on ciphertext
policy attribute-based encryption (CP-ABE) system for the DTNs,”
Tech. Rep., 2009.
[14] Z. Zhou and D. Huang, “On efﬁcient ciphertext-policy attribute
based encryption and broadcast encryption,” in Proc. 17th ACM
Conf. Comput. Commun. Security, 2010, pp. 753-755.
[15] K. Emura, A. Miyaji, A. Nomura, K. Omote, and M. Soshi, “A
ciphertext-policy attribute-based encryption scheme with constant
ciphertext length,” in Proc. 5th Int. Conf. Inf. Security Practice Experience. Springer-Verlag, 2009, pp. 13-23.
[16] S. Yu, K. Ren, and W. Lou, “Attribute-based content distribution
with hidden policy,” in Proc. 4th Workshop Secure Netw. Protocols,
2008, pp. 39-44.
[17] S. Yu, K. Ren, and W. Lou, “Attribute-based on-demand multicast
group setup with membership anonymity,” Comput. Netw., vol. 54,
no. 3, pp. 377-386, 2010.
[18] D. Huang, Z. Zhou, and Z. Yan, “Gradual identity exposure using
attribute-based encryption,” in Proc. IEEE 2nd Int. Conf. Social
Comput. (SocialCom), 2010, pp. 881-888.
[19] A. Fiat and M. Naor, “Broadcast encryption,” in Proc. Adv. Cryptology
(Crypto93), vol. 773, 1994, pp. 480-491.
[20] C. Delerablée, P. Paillier, and D. Pointcheval, “Fully collusion secure
dynamic broadcast encryption with constant-size ciphertexts or
decryption keys,” in Proc. Pairing-Based Cryptography—
Pairing, 2007, pp. 39-59.

138

IEEE TRANSACTIONS ON COMPUTERS, VOL. 64, NO. 1, JANUARY 2015

Zhibin Zhou (M’11) received the BS degree from
Shanghai Jiao Tong University, China, in 2006,
and the PhD degree from Arizona State University,
Tempe, in 2011. His research interests include
applied cryptography and mobile cloud computing.
He is currently with Amazon.com.

Dijiang Huang (M’00–SM’11) received the BS
degree from Beijing University of Posts & Telecommunications, China, in 1995. He received the
MS and PhD degrees from the University of
Missouri–Kansas City, in 2001 and 2004, respectively. He is an associate professor in the School
of Computing Informatics and Decision System
Engineering at the Arizona State University,
Phoenix. His current research interests include
computer networking, security, and privacy. He is
an associate editor of the Journal of Network and
System Management (JNSM) and an editor of IEEE COMMUNICATIONS
SURVEYS & TUTORIALS. He has served as an organizer for many International
conferences and workshops. His research is supported by NSF, ONR,
ARO, NATO, and Consortium of Embedded System (CES). He is a
recipient of ONR Young Investigator Program (YIP) Award.

Zhijie Wang received the BS and MS degrees
from Beijing University of Posts & Telecommunications, China, in 2007 and 2010, respectively. He
is currently working toward the PhD degree at
Arizona State University, Phoenix. His research
interests include wireless networking, applied
cryptography, and cloud computing.

For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

▽

[21] D. Lubicz and T. Sirvent, “Attribute-based broadcast encryption
scheme made efﬁcient,” in Proc. 1st Int. Conf. Cryptology Africa
(AFRICACRYPT). Springer, 2008, pp. 325-342.
[22] L. Cheung, J. Cooley, R. Khazan, and C. Newport, “Collusionresistant group key management using attribute-based
encryption,” in Proc. 1st Int. Workshop Group-Oriented Cryptographic
Protocols, 2007.
[23] I. Chang, R. Engel, D. Kandlur, D. Pendarakis, and D. Saha, “Key
management for secure internet multicast using Boolean function
minimization techniques,” in Proc. 18th Annu. Joint Conf. IEEE
Comput. Commun. Soc. (Infocom), 1999, pp. 689-698.
[24] D. Boneh, X. Boyen, and E. Goh, “Hierarchical identity based
encryption with constant size ciphertext,” in Proc. Adv. Cryptology
(EUROCRYPT), 2005, pp. 440-456.
[25] E. McCluskey, “Minimization of Boolean functions,” Bell Syst. Tech.
J., vol. 35, no. 5, pp. 1417-1444, 1956.
[26] R. Poovendran and J. Baras, “An information-theoretic approach for
design and analysis of rooted-tree-based multicast key management
schemes,” IEEE Trans. Inf. Theory, vol. 47, no. 7, pp. 2824-2834, Nov.
2001.
[27] T. Cover and J. Thomas, Elements of Information Theory. Hoboken, NJ:
Wiley, 2006.
[28] A. Sherman and D. McGrew, “Key establishment in large dynamic
groups using one-way function trees,” IEEE Trans. Softw. Eng., vol.
29, no. 5, pp. 444-458, May 2003.
[29] C. Wong, M. Gouda, and S. Lam, “Secure group communications
using key graphs,” IEEE/ACM Trans. Networking, vol. 8, no. 1,
pp. 16-30, Feb. 2000.
[30] A. Penrig, D. Song, and D. Tygar, “ELK, a new protocol for efﬁcient
large-group key distribution,” in Proc. IEEE Symp. Security Privacy,
2001, pp. 247-262.
[31] J. Snoeyink, S. Suri, and G. Varghese, “A lower bound for multicast
key distribution,” Comput. Netw., vol. 47, no. 3, pp. 429-441, 2005.
[32] T. Sasao, “Bounds on the average number of products in the
minimum sum-of-products expressions for multiple-value input
two-valued output functions,” IEEE Trans. Comput., vol. 40,
no. 5, pp. 645-651, May 1991.
[33] D. Hankerson, S. Vanstone, and A. Menezes, Guide to Elliptic Curve
Cryptography. New York, NY: Springer, 2004.

A Double Authentication Scheme To Detect
Impersonation Attack In Link State Routing
Protocols
Dijiang Huang, Amit Sinha, Deep Medhi
{dhuang,asinha}@conrel.sice.umkc.edu, dmedhi@umkc.edu
School of Interdisciplinary Computing and Engineering
University of Missouri-Kansas City
Kansas City, MO 64110 USA
Abstract—In this paper, we present an authentication scheme to
prevent impersonation attack in link state routing protocol. The
existing authentication schemes are either simple to compute but
vulnerable to attacks or too robust against attacks but has exponential computation cost. We introduce a Double Authentication
(DA) scheme which provides authentication to the routing information data carried by the link state routing packets. In this
scheme every router needs to sign the routing data twice with two
different keys using a group keying scheme, which is based on oneway hash function. Based on our performance assessment, we
found that this scheme is simpler to implement, computationally
efﬁcient and provides the degree of robustness desired with less
communication overhead but has higher memory requirement.
Index Terms—Double Authentication (DA), Insider Attack, Impersonation Attack, Link State Routing.

I. I NTRODUCTION
Present link state routing protocols are vulnerable to security
attacks. There have been several attempts to address this issue.
Perlman proposed a link-state routing protocol that achieves
Byzantine Robustness [10]. Her protocol is highly robust but
has a high computational overhead associated with the publickey encryption. Open Shortest Path First (OSPF) [8] link state
routing protocol has provision to provide links state routing
Packet Authentication (PA) based on a shared-key using a oneway hash function [13]. This scheme does not provide authentication for the routing data carried in these packets, hence can be
very susceptible to security attacks. To overcome this, Murphy
et al proposed digital signature (DS) scheme [9] to prevent tampering of Link-State Advertisements (LSAs). This scheme too
uses some form of public-key encryption (different from that of
Perlman’s) and hence is expensive.
One of the attacks on the network routing protocol can be
carried out by the trusted entity involved in the routing information exchange. This entity can be a router that has been misconﬁgured by a naive network administrator or an outsider who
has total control on the entity because of a compromised administrative password. This type of attack is called the “insider
attack”. We classify insider attacks into two types:
1) A router originates incorrect local routing information:
This type of attack can harm the network in two ways.
First, the router may minimize the cost of the links associated with it, thereby compelling all the trafﬁc to ﬂow

through it. If the network trafﬁc engineering requirements are still fulﬁlled, there could be passive or active
attack on the trafﬁc data. This type of attack is the most
difﬁcult to detect and deal with, especially the passive
attack. Second, if the router increases the cost of the
links associated with it, the network trafﬁc will avoid going through it. In a way the router tends to isolate itself.
While we understand the potential threat posed by this attack to the network; dealing with it lies outside the scope
of this paper.
2) A router impersonates other routers and generates forged
network routing information: We refer to this attack as
Impersonation Attack (IA). This is difﬁcult to detect and
can cause huge damage to the network. Since, most of
the link state protocols provide authentication only at the
packet level, the LSA can be easily forged without getting
detected.
In this paper, we focus on the second type of attack. We refer to the router(s) responsible for IA as “bad” router(s). In our
work, we assume there exists an Intrusion Detection System
(IDS) that can sense abnormal network events like the authentication failure, network trafﬁc congestion or router ﬁght back1
(see [14]). Here, we do not discuss the coordination mechanism between IDS and network routing protocols and how IDS
makes decisions from the collected abnormal network events.
Our work is focused on the following goals: (a) present an
authentication scheme that does not suffer from the performance issues of the public key scheme, (b) expedite the detection of “bad” routers involved in IA, and (c) provide some
network design guidelines for this scheme to be effective.
In order to achieve our set forth goals, we propose a novel
Double Authentication (DA) scheme based on a group keying
scheme proposed in [4]. This involves authentication of each
LSA twice, with two different keys using a one-way hash function. The basic idea behind our approach is to provide a degree
of security as desired by a network designer at a relatively low
cost. We show that our DA scheme is able to detect (a) a “bad”
1 Fight back phenomenon: Since the link state routing uses reliable ﬂooding
to forward link state updates, the original routing information sent by a router
can travel back to the sender. As speciﬁed in OSPFv2 standard [8], if the router
ﬁnds the received routing information inconsistent with the one it sent out before, the router will resend the original routing information

0-7803-7802-4/03/$17.00 © 2003 IEEE

1723

router when there is only one of them impersonating routing
information, and (b) multiple non-colluding “bad” routers.
We present a comparative assessment for the performance of
the PA, DS and DA schemes, based on the memory requirement, CPU usage time and communication overhead. We also
analyze the degree of security robustness of the scheme, which
we deﬁne as the number of “bad” routers in the network that
needs to collude for the scheme to fail. In our analysis, we assume all routers are connected using point-to-point links.
The rest of the paper is organized as follows. In Section II
we discuss in detail the generation and working of DA. Section III provides a comparison between the existing authentication schemes for link state routing protocol and the DA scheme
based on the memory requirement, CPU usage time, security
robustness and communication overhead. Finally in Section IV
we present the conclusion.
II. D OUBLE AUTHENTICATION
Our DA scheme uses a one-way hash function instead of the
asymmetric keying scheme. Moreover unlike DS, DA does not
use the end-to-end data origin authentication. Instead, it sets up
an authentication chain that follows the LSA ﬂooding path to
provide data origin authentication. Here the router only needs
to set up trust with its neighbors. This can decrease the number of keys used by symmetric cryptographic scheme. In this
section we present the keying scheme, which forms the basis of
our proposed authentication scheme. We also discuss the functioning of the scheme in order to provide authentication to the
routing information.
A. Keying Scheme
In our scheme, the LSAs that are being ﬂooded are individually authenticated twice by two different keys, i.e., each LSA
is signed twice by every router when it ﬂoods the LSA to its
neighbor(s). Authenticated codes are appended to the individual LSAs. The ﬁrst authentication code generated by the router
can be veriﬁed by every other router except the neighbor(s) to
which the LSA is being ﬂooded. This can prevent its neighbor(s) from altering the LSA. The second authentication code
can be used by its neighbor(s) to check the integrity of both the
LSA as well as the ﬁrst authentication code. This is to ensure
that if the LSA and the ﬁrst authentication code were altered
before it reached the neighbor, it can be detected.
The keying scheme for our approach is based on Secure
Group Communication Keying Scheme (SGCKS) (see [4] for
detailed description of SGCKS). In this scheme, each router has
a set of Key Generation Seeds (KGS), which are used to generate the encryption/decryption key. A router uses its KGS to
generate the sub-group key that is shared with its neighbor, and
the sub-group key that is shared with everyone except its neighbor. The SGCKS scheme provides an efﬁcient way to generate
sub-group keys, thereby providing a way to reduce the number
of authentication codes required for each LSA.
We assume that all the routers in the routing domain belong
to the same KGS group. Group G = {xi |i = 1, 2, ..., n; i ∈
N and n ≥ 2}, where |G| = n. The group member is
represented by xi and we use Sji = {xi , xj } to represent

any sub-group communication composed of group member xi
and xj , where xi and xj ∈ G. In Sji , the superscript “i”
means, xi originates the sub-group communication Sji . The
subscript “j ” represents any sub-group member apart from xi .
In our proposed scheme, we are only interested in two types
of sub-group communication, namely, Sji and its complement
Sj̄i = {xk |k = 1, 2, ..., n, k = j, k ∈ N, and n ≥ 2}. Thus,
we have Sji , Sj̄i ⊆ G, |Sji | = 2, |Sj̄i | = n − 1, Sji ∪ Sj̄i = G,
and Sji ∩ Sj̄i = {xi }.
In this paper we use xi to represent router i and it’s individual
KGS as KGS i , The individual key is represented as K i , where
K i = F (KGS i ). Here the function F is called key generation
function. It is used to generate certain length of individual key
and it is publicly known. F can be a bitwise logical operation
or a one-way hash function depending on the implementation.
The sub-group key for sub-group Sji is represented as Kji and
the sub-group key for Sj̄i as Kj̄i .
We enforce the security beyond the packet level. In our approach, every individual routing information data is authenticated. We use traditional authentication algorithm, for example
Keyed-Hashing for Message Authentication (HMAC) [5]. The
reason why we use HMAC and not DS is because the former is
about a thousand times faster than the DS [15].
The scheme, SGCKS, is suitable for authentication because
each router has a secret KGS, which can be used to generate
sub-group key Kji for Sji communication between router xi and
its neighbor xj . This sub-group key cannot be forged by other
group members. Using SGCKS, Kj̄i can be generated, which
can be derived by every router in the group except the neighboring router, xj .
Each LSA is authenticated twice by a router using two subgroup keys discussed above. The ﬁrst authentication code generated by key Kji is used by its neighbor to verify the routing
information data. The second authentication code generated by
key Kj̄i is used to guarantee that the neighbor does not alter the
data. These authentication codes are appended at the end of
each LSA. Router xj forwards the second authentication code
to it’s neighbors so that they can verify it’s integrity. This is
a distributed scheme where each router needs to maintain the
trust-relation only between its neighbors. The trust is built up
when the router is added into the network by assigning a KGS
from key distribution center. The trust-relation among network
neighbors will tell the router what KGS group its neighbor belongs to. This helps the router to compute the sub-group keys in
advance and use them when needed. The trust build-up, KGS
generation and updates are out of scope of this paper.
B. Generating the DA
The DA generation rules are listed below:
1) When router xi creates an LSA, it sends the LSA to its
.
neighbor xj as LSAi(j),(j)
¯

2) When router xj receives an LSA from its neighbor router
.
xi , it forwards it to its neighbor xk as LSAj(k),
¯ (j),(k)
¯
We present an example shown in Fig. 1.
The superscript on LSA identiﬁes the router that ﬂooded the
LSA. In rule 1, when router xi creates the LSA, it needs to at¯ and (j)
tach two authentication codes to it. We use subscript (j)

1724

j
LSA _ _

i

LSA _

400
128-bit hash
160-bit hash
1024-bit RSA

(k) , (j) , (k)

(j) , (j)

350

k

j

i

300

_
LSA A j A j
i

i

Size (KB)

250

_
LSA A _
k Aj Ak
j

i

j

200

150

Fig. 1. The DA example

100

50

Kj̄i

Kji ,

to represent authentication codes generated by key
and
respectively. Note that authentication code Aij should authenticate both the LSA and authentication code Ai(j)
¯ . This will help

detect if the LSA and Ai(j)
¯ have been altered before reaching
the neighbor, as any change in the information will be reﬂected
in Aij . This is the reason (j) is at the rightmost side in our representation. This is same for rule 2 where the last authentication
code (Ajk ) will cover previous two authentication codes and the
LSA.
When xj receives an LSA, it ﬁrst detects that the source of
LSA is its neighbor xi . Then, router xj uses sub-group key Kji
to verify authentication code Aij . Once authenticated, router
xj uses sub-group keys Kkj and Kk̄i to generate authentication
codes for both its neighbor xk and xk ’s neighbors, before forwarding this LSA to xk . Note, as described above, authentij
cation code Ai(j)
¯ is attached after A(k)
¯ as a part of the authen-

ticated data and is forwarded to xk . This can be used by xk
to verify that xj has not altered the LSA. Authentication code
j
Ai(j)
¯ needs to be attached after authentication code A(k)
¯ . This

is because when xk forwards the LSA to further hops, authenj
tication code Ai(j)
¯ is not attached. So, authentication code A(k)
¯
should not cover it. But these two authentication codes should
be covered by code Ajk . This will help detect any active attackers who might alter the LSA and authentication codes. In our
scheme only the originator sends the LSA with two authentication codes attached to it. The intermediate routers generates
two authentication codes but forwards three codes.
to router xk .
Finally, router xj forwards the LSAj(k),
¯ (j),(k)
¯
When router xk receives this LSA, it ﬁrst veriﬁes authentication code Ajk , and then checks code Ai(j)
¯ . If authenticated,

it just follows same steps as router xj does in order to generate new authentication codes before forwarding the LSA to its
neighbors.

III. C OMPARATIVE A SSESSMENT
The two authentication schemes for link state protocols that
have been proposed are, the PA [8] and the DS schemes [9]. The
DA scheme is inspired by the DS scheme where authentication
is provided for each LSA. In this section we draw a comparison
between these schemes based on the memory requirement, CPU
usage time, communication overhead and robustness in terms of
security that each provides.

0
0

50

100

150

200

Number of Nodes

Fig. 2. Memory required to store the keys for various schemes

A. Memory Requirement
In the PA scheme, each router needs to store just one shared
key which is used for cryptographic authentication. Hence, the
memory requirement is negligible when compared to the DS
and DA schemes.
In case of DS scheme, each router needs to store its public
and private keys and the public keys of all other routers in the
network and that of the trusted entity 2 . Assuming that there
are N routers in the network and the size of the key is s, the
worst case memory required by each router is equal to s ∗ (N +
2). Thus space complexity for this scheme is O(N ). The RSA
public key scheme now suggests a 1024-bit key size, since 512bit size can be vulnerable to attacks [11] [6]. Assuming that
1024-bit RSA is being used for DS scheme, we plot the memory
size each router needs to store the keys with varying number of
nodes in the network (see Fig. 2).
The worst case space complexity for DA scheme varies as
O(N 2 ) in a network with N nodes (see [3] for details). The
memory size equals s ∗ N ∗ (N − 1)/2 for a key size of s. Fig. 2
presents the memory requirement for a router for both 128-bit
and 160-bit hash function with varying network size.
Here, we ﬁnd that the space complexity for DA scheme is
worst when compared to other schemes. Though the analysis
presented in [3] suggests dividing the network into subgroups
in order to reduce the memory requirement, the DA scheme currently does not support it. This aspect is presently being looked
into and will be outlined in future. The higher memory requirement of this scheme, which in fact is below half a megabytes
for a 200-node network, may or may not be an issue for currently available routers. For example, Cisco 7500 series router
[16] has one 32MBytes (upgradeable to 128 MBytes) DRAM,
one 64 MBytes (upgradeable to 256 MBytes) DRAM, one 16
MBytes (upgradeable to 110 MBytes) ﬂash memory. Since we
expect future generation routers to have more memory capability as with faster processors, we believe that the additional
memory requirement warranted under our approach is not too
far fetched.
2 According to Murphy [9] this can be a Certiﬁcate Server which certiﬁes the
identity of a router. We assume one such entity in the network.

1725

102

B. CPU Usage Time

C. Communication Overhead
The communication overhead is the size of the information
that has to be carried along with the packet in order to support
various schemes.
In the PA scheme, each packet carries the message digest
generated by running the one-way hash function over the link
3 Moy in his analysis [7] indicated that the average size of the LSA to be 64
Bytes. We assume the size to have doubled for our analysis.

10

1

100
CPU Usage Time (s)

We assume that the network is optimally designed in accordance with the guideline provided by Aho and Lee [1]. Therefore, the worst case complexity of the number of LSAs3 contained in a single link state update packet is O(N 4/3 ) for a network with N nodes. For comparing the DS and DA scheme,
we have used the benchmark provided in [15] for speeds of the
hashing algorithms and the encryption/decryption algorithms.
The validity of using this benchmark is discussed in [3].
In the PA scheme, a router authenticates the entire link state
packet at once. The other two schemes presented here provides
authentication for every LSA contained in the packet. Therefore, the CPU time for PA scheme is negligible as compared to
the other schemes.
In DS scheme, a router needs to sign each LSA before ﬂooding it. Each router signs its LSA by ﬁrst running a one-way
hash function on the LSA data and then using a private key to
sign the digest [9]. Therefore, the CPU usage time per LSA is
the time required by the hashing function to create the message
digest and the time needed for encrypting this digest using the
router’s private key. Now, a router can receive O(N 4/3 ) LSAs
in the worst case. Hence the router needs to ﬁrst use the relevant
public key to decrypt the message digest for each LSA. It then
has to use the keyed one-way hash function on the LSA to authenticate it with the decrypted message digest. We have used
the 1024-bit RSA public key scheme and MD5 one-way hash
algorithm, to assess the CPU usage time for this scheme. Fig. 3
presents the assessment for the above scenarios, i.e., when a
router originates LSAs, and when it receives LSAs.
In DA scheme, a router originating the LSA needs to run
one-way hash function twice with different keys, as discussed
in Section II. The same process needs to be carried out by the
router receiving the LSAs. In Fig. 3 we show the worst case
scenario for the same.
We ﬁnd that the time complexity for DS scheme is worst
as compared to the other schemes. This is obvious from the
fact that public key scheme has an exponential computation
overhead. Computation of the shortest path is known to be
the most time consuming process for a router CPU. We have
plotted the CPU usage time for shortest path calculation (SPF)
by Cisco 7513 router using the formula given by Shaikh and
Greenberg [12] in Fig. 3. We observe that the cost for our approach falls below the SPF with increasing number of nodes.
Hence implementation of the DA scheme will not require any
process upgrades. Whereas, for implementing the DS, the computational time associated with this scheme should decide the
processing power needed for the router.

DS (enc)
DS (dec)
DA
SPF-Cisco 7513

10-1

-2

10

-3

10

10-4
10

50

100

150

200

Number of Nodes

Fig. 3. CPU processing time required by various schemes

state packet. This message digest of 128 bits is appended to all
the link state routing packets [8].
For DS scheme, the signature for each LSA has a variable
size. This message size can technically vary from 0 to 1024
bits for 1024-bit RSA scheme. Assuming each size is equally
likely, we ﬁnd that on an average the length of the signature that
has to be attached for each LSA is 512 bits.
In case of DA scheme, authentication codes generated by
three different hash keys need to be attached for each LSA by
the intermediate node. The LSA originator attaches only two
authentication codes generated by two different hash keys. Assuming that we use a 128-bit hashing algorithm, the total size of
authentication codes per LSA will be 384 bits for intermediate
routers, and 256 bits for the originator.
Hence, the communication overhead is maximum for the DS
scheme. The overhead associated with PA is negligible.
D. Security Robustness
The PA scheme provides authentication to routing protocol
packet but does not provide any authentication to routing data
carried in these packets in the form of LSAs. So any faulty or
subverted router in between the source and destination router
can ﬁddle with this information and will go undetected.
The DS scheme provides a very strong authentication for
each LSA within the link state update packets. The strength
of this scheme comes from the asymmetric keying scheme implemented by it. This scheme is so robust that a “bad” router
will always get detected unless every single node in the network
has been hacked.
In order to analyze the security robustness of the DA scheme,
we classify network intrusion into three types depending on the
number “bad” routers within the network. The ﬁrst type is when
there is one or multiple “bad” routers within a network which
do not collude. The second type of intrusion is when more than
one “bad” routers in the network collude to impersonate other
routers and generate forged routing information. The third classiﬁcation is the special case of second when the “bad” routers
partition the network. This means the “bad” routers can completely control all communication among the partitioned network. In this case, the forged routing information may not
travel back to the originator.

1726

Our scheme deals with the ﬁrst class of intrusion efﬁciently
and can immediately detect the “bad” router (see Section II for
detail). For second class of intrusion, the DA can provide the
helpful information for the IDS to limit the region where the
“bad” routers located, by maintaining the record for authentication codes. In this paper, we do not discuss how to trace back
to the “bad” router. For the third class of intrusion, the DA can
not provide any useful information to intrusion detection system. That means the network is totally hacked.
In the DA scheme the network designer has to decide the
minimum number of nodes (k) that partitions the network. The
network using the DA scheme will become unsafe from IA
when these k routers go “bad” and they collude to harm the
network.

[11] M. Robshaw, “Security Estimates for 512-bit RSA”, Technical Notes and
Reports, RSA Laboratories, June 29, 1995
[12] A. Shaikh and A. Greenberg, “Experience with Black-Box OSPF Measurement”, Internet Measurement Workshop, 2001.
[13] W. Stallings, “Cryptography and Network Security: Principles and Practice, Second Edition”, Prentice Hall, 1998.
[14] B. Vetter, F. Wang and S.F. Wu,“An Experimental Study of Insider Attack
for OSPF Routing Protocol”, IEEE International Conference on Network
Protocols, pp. 293 - 300, October 1997.
[15] http://download.baltimore.com/keytools/docs/v51/
pro/j-docs/html/devguide/projdevguide-C.3.html
[16] http://www.cisco.com

IV. C ONCLUSION
In this paper we have presented the Double Authentication
scheme for link state routing protocols to detect impersonation
attack. This scheme provides authentication with two different
keys using a one-way hash function. In our approach, a single
subverted router can be easily detected by its neighbors. When
the network is partitioned by subverted routers, the DA can only
be effective within a single partition. So, our DA can be as
strong as Digital signature which provides source authentication when there is single or multiple subverted routers that do
not work together. In the case where “bad” routers creates multiple partitions in the network, DA can provide security which
is as good as PA. We should provide strong security to those
network nodes that can easily partition the network. While we
believe that link state routing protocols do require a strong authentication scheme, this should not come at the cost of computational efﬁciency. In this regard, DA scheme fairs well, with
good computational efﬁciency and low communication overhead, though it has higher memory requirement. Therefore,
DA lies in the huge gap between the PA and the DS scheme,
thereby giving some ﬂexibility in choosing the authentication
scheme to be implemented in the link state routing protocols.
Reducing the space complexity is one of the intended future
work.
R EFERENCES
[1] A. V. Aho and D. Lee. “Hierchical Networks and the LSA N-Squared
Problem in OSPF Routing”, IEEE GlobeCom, 2000.
[2] F. Harary, “Graph Theory”, Addison Wesley Publishing Company, 1969.
[3] D. Huang, A. Sinha and D.Medhi, “On Providing Conﬁdentiality in
Network Routing”, Technique Report, University Missouri Kansas City,
October 2002. Available from http://conrel.sice.umkc.edu/
HRP/.
[4] D. Huang and D. Medhi, “A Flat Group Keying Scheme to Support
‘Any to Any’ Secure Subgroup Communication”, technical report, University Missouri Kansas City, October 2002. Available from http:
//conrel.sice.umkc.edu/HRP/.
[5] H. Krawczyk, M. Bellare and R. Canetti, “HMAC: Keyed-Hashing for
Message Authentication”, RFC2104, February 1997.
[6] A. Lenstra and E. Verheul, “Selecting Cryptographic Key Sizes”, Journal
of Cryptology, 14(4): 255-293, 2001.
[7] J. Moy, “OSPF Protocol Analysis”, RFC1245.
[8] J. Moy, “ OSPF version 2”, RFC2328, April 1998.
[9] S.L. Murphy, M. Badger and W. Wellington, “OSPF with Digital Signatures”, RFC2154, June 1997.
[10] R. Perlman, “Network Layer Protocols with Byzantine Robustness”,
MIT/LCS/TR-429, October 1988.

1727

A Key Distribution Scheme for Double Authentication in Link State
Routing Protocol
Dijiang Huang

Amit Sinha Deep hiIedhi

Computer Science and Electrical Engineering Department
University of hlissouri-Kansas City
Kansas City, Missouri 64110, USA.
{ dhuang, asinha, dmedhi)@umkc.edu
Abstract

authentication. These schemes use hash raIues as
credential or a key used for keyed-hashing for message
authentication (HMAC) [7], which is computationally
efficient, but it requires a loose synchronous mechanism; thus, it can c o d i c t with the operation mode of
many routing mechanism, which may not have a synchronized framework. Furthermore, each router needs
to retain a unique precomputed hash chain.and n - 1
hash d u e s for other n- 1 routers within the link state
routing domain.
Since, current link state protocols provide authentication only at the packet level, the LSA can be easily forged, making it difficult t o detect a attack. The
double authentication (DA) scheme presented in 111
is designed to prevent impersonation attacks. DA is
based on a key distribution scheme, and it provides
authentication to each LSA carried by the link state
routing packets. It requires every router t o sign the
routing data twice with two different keys which has
been provided by a key distribution center (KDC). The
first key used is shared by every node except the nexthop' in the entire network, while the second key is
shared between the sender and its next-hop only. The
KDC generates these keys using a one-way hash function, which brings down the computational cost of the
scheme as compared to the DS scheme. However, in
the worst case, the storage complexity for the scheme
grows quadratically with the number of nodes. For a
moderate to large size network, this storage complexity
forms the bottleneck for the key distribution scheme.
In this paper, we propose a new key distribution
scheme that can be used for DA. The new scheme still
advocates the use of two different keys by the DA. But
here, the first key is shared only by the sender and all

The Double Authentication (DA) scheme presented
in /1] is designed to provide security against impersonation attack to link state muting protocol at a
lower computational cost as compared to the existing
schem,es, such as, digital signature scheme [2]. I n this
paper. we present a key distribution scheme that can
be used for genemting and distributing keys to provide
DA. This scheme leads to a storage com,plexity for each
router that varies linearly with the number of routers
in the network in the worst case (fully connected network with n nodes). Moreover, for muter with four
or less avemge number of linb, the storage complexity falls below Iog,n. This scheme also increases the
seczrity robustness of DA as the subverted routers can
collude only if they am neighbors.

1

Introduction

Security is of immense concern for link state routing protocols. One mechanism of providing security is
by authenticating the routing information being exchanged by each router. For example, open shortest path first (OSPF) standard (see FWC2328 [3]) has
provision for links state routing packet level authentication based on a shared-key using a one-way hash
function [4]. This scheme does not provide authentication for each Link State Advertisement (LSA) carried
in these packets, hence can he very susceptible to impersonation attacks, in which a subverted router impersonates other routers and generates forged network
routing information. To overcome this, hlurphy et a1
proposed digital signature (DS) scheme 121 to prevent
tampering of LSAs. This scheme uses public-key encryption which suffers from exponential computational
cost. The worst case storage complexity varies linearly
with the number of nodes. In order t o bring down the
computational complexity, researchers have proposed
hash chain based schemes 15][6] to provide data origin

0-7803-8991-3/05/$20.00 0 2005 IEEE

lNext-hop is the router to which the sender has a direct link.
This is the router through which the sender intends to forward
the routing packet.

19

'

the neighbors of its next-hop, while the second key is
shared by the sender and its next-hop. This helps in
bringing down the storage requirement from quadratic
to linear in the worst case. Besides this, the new key
distribution scheme also improves the security robustness of the DA scheme. Note that, when multiple subverted routers collude to generate the forged routing
information, the DA scheme can only provide limited
information to identify one of subverted routers. The
new key distribution scheme ensures that the subverted
routers can collude if and only if they are neighbors,
and therefore, making it easier to detect the routers responsible for the attack. In our paper, we assume that
the network topology is static and there is no addition
or r e m o d of any router/links.
The rest of the paper is organized as follows: In Section 2 we present an overview of the DA scheme. In
Section 3 we describe the new key distribution scheme
that can be used by DA. Section 4 we present the performance assessment of the key distribution scheme
from storage and security point of view. We finally
conclude the paper in Section 5 .

2

Double Authentication
Overview

V

S

~

z

K

a node, T E V
authentication key

V = (aiji = 1 , 2,...,n;i E N and n 2 Z } , where
[VI = n. We use 52 t o represent router i (group member i) and S; = { x i , d } to represent any subgroup
communication composed of group member xi and d ,
where ziand d E V. In other words, in Sj, the superscript "2' means that 22 originates the sub-group communication Sj , the subscript "j" represents another
sub-group member 51. Thus, the group members composition of Sj and S{ are the same, the difference.is
who generates the subgroup communication. In the
0 - D A scheme, only two types of subgroup communication are interesting, namely, Sj and its comple
ment S! = {x"k = 1 , 2,...,n, k # j , k E JV,and
3
n 2 21, where IS:] = 2, jS!IJ = n-1 and SjnS!J = {i}.
The group members of Sj will cover every one except
member 5 3 . For loosely connected networks, using subgroup key of s:, the 0-DA's hop-by-hop authenticating
contains much redundant information that are not necessarily involved in group membership validation. We
note that the authentication code generated by using
sub-group key of Sj can be validated only by neighbors
of router x3; However, it also can be validated by the
other routers that are not the neighbors of zj. This
redundancy introduces two problems. First, 0 - D A requires each group member to retain a set of secrets to
generate proper sub-group keys. It increases the se
crets size stored by a router, which is of the order of
O(n2>.Second, the collusion by any routers combinations with the router d ,is possible, which would go
undetected.

Scheme:

In [l]we proposed a DA scheme to provide security
to link state routing protocols against impersonation
attack. In this section we provide a brief overview that
covers the working of DA and complexity due to the
key distribution scheme. For brevity we use, 0-DA to
represent the DA scheme that uses the old key distribution approach, and N-DA for DA scheme that uses
the new key distribution mechanism that we present
in this paper.
In the 0-DA scheme, LSAs that are flooded are individually authenticated twice by two different keys,
i.e.: each LSA is signed twice by every router when
it floods the LSA to its neighbor(s). Authentication
codes are then appended to each individual LSA. The
first authentication code generated by the router can
be verified by every other router except the neighbor(s)
to which the LSA is being flooded. This can prevent
its neighbor(s) from altering t h e LSA. The second authentication code can be used by its neighbor(s) to
check the integrity of both the LSA as well as the first
authentication code. This is to ensure that if the LSA
and the first authentication code were altered before it
reaches the next-hop neighbors.
A brief description of mathematical notations used
by DA is given in Table 1.
We assume that all the.routers in the link state
routing domain belong to the same group2. Group
~

set, /VI = n
subset, S C V

3

Key Distribution Approach

The DA by itself is designed to just use the two keys
provided to it by the KDC to do the authentication.
Hence the onus lies on the key distribution mechanism
t o bring down the storage cost and also overcome the
security hole that remains unplugged in the 0-DA. In
this section we present the algorithm used by the new
key distribution scheme and how the DA can make use
of the keys in order to overcome the above issues.
state routing domain. This is because the link state advertisements are only flooded within an area.
3Refer to [8] for technical details.

~~

2For example, using OSPF, an area can be defined as a Link

20

3.1

Key Generation Algorithm

JVe use symmetric key scheme, for example, keyedhashing for message authentication (HklAC) [7], for
generating the authentication code and for its verification. We note that proper choice of group key for
known link state routing network topology can decrease the number of keys possessed by a router as well
as increase the degree of security. Here, we present an
algorithm used by a KDC t o generate the set of shared
keys to he distributed to the routers.
We assume that the network topology is known in
advance. We consider a router within the link state
routing domain as a vertex xi of and set containing
all the vertices, V = {s*liE N } , and IT// = R. r
is the set that contains the sub-groups of routers to
which the sub-group keys have, been already distributed. The pseudo code of the key generation algorithm
is described in Table 2. The complexity of the algorithm varies linearly with the number of routers within
the link state routing domain.

Figure 1: The DA example

by its neighbor to verify the routing information data.
The processing is different from 0 - D A , since the second authentication code generated by key Ii(Qi)
is
only possessed by the neighbors of router xj. This authentication code is used t o guarantee that the node
X J does not alter the routing data. The subgroup keys
K ( S j ) and K(S1;) are distributed in advance to each
group member by means of offline or any secure channel from a KDC. It requires that the KDC knows the
network topology in advance. We show the DA scheme
as fallonTs:
The DA generation rules are listed below:

Table 2: Key Generation Algorithm
St.ep I

V - {All routers in the link state routing domain};

= {4?;
distribute K(S,i) for each directly connected pair ri
and z3,where r z , z JE V ;
put each {r',rj} in r;
Step 2

1. When router xi creates an LSA, it sends the LSA

if V # {+} and 3 unmarked z' E V

I

to its neighbor

select unmarked I' and all its neighbors;
s, = {r'lneighbors of x i } , s i # {$}, s i C V;
mark r';
if si $ r

I

distribute K(nZ"')t o members of
put s, in r;

as LSAt(Q;, Sj).

2. When router xj receives an LSA from its neighbor router xi,it forwards it to its neighbor xk as

LSA(fl%,!2$,5';).

8,;

We present t h e working of DA with an example
shown in Figure 1. The superscript on LSA identifies the router that floods the LSA. In rule I, when
router xi creates the LSA, it needs t o attach two authentication codes to it. We use S1$ and Sj in the
bracket to represent authentication codes generated by
key K ( Q ; )and K ( S j ) ,respectively, Note that authentication code A ( S j ) should authenticate both the LSA
and authentication code A ( 9 : ) .This can help detect if
the LSA and/or A ( 0 ; ) have been altered. This is why
the authentication code A ( S j ) is at the rightmost side
in our representation. This is same for rule 2 where the
last authentication code A ( S i ) covers previous two authentication codes and the LSA.
N-DA processing of intermediate nodes is presented
as follows: When d receives an LSA, it first detects
that the LSA is forwarded by its neighbor xi. Then,
router aj uses subgroup key K ( S j ) to verify aut.hentication code A ( S i ) . Once authenticated, router d

1

repeat Step 2;

1

else END;

3.2

d

DoubIe Authentication using new Key
Distribution Scheme

We use the notation 9 t o represent all neighbors
of a router. Therefore subgroup
represents a set
consisting of all neighbors of I E ~except xJ, where 1 is
one of j ' s neighbor and 2 initiate the communication.
K ( S J )is the shared key for sub-group 5'; and K(t2;)
is the shared key for Q;. Note t h a t K ( S i ) = K(S:),
but K ( ! X )# K(Q2f).
The processing of N-DA is fundamentally same as
0-DA. Each LSA is authenticated twice by a router
using two subgroup keys discussed above. The first
authentication code generated by key K ( S J )is used

fli

21

uses sub-group keys K(Ri) and K ( S i ) to generate authentication codes A ( Q i ) and A(,!?:). Together with
authentication code A(W) generated by 9 , following
rule 2, three autbenticatkn codes are attached a t the
end of LSA that is forwarded to it's neighbor xk. Note
that, as described above, authentication code A(5-P)
is attached after A(R:) as a part of the authenticated
data. This can be used by xk to verify that xJ has not
altered the LSA. Authentication code A(fl5) needs t o

be attached after authentication code A(fli). This is
because when zk forwards the LSA to the next hop,
authentication code A(n;) is not attached. So, authentication code A ( Q i ) should not authenticate A ( @ ) .
However, these two authentication codes should .be
authenticated by code A(Si). In our scheme only
the originator sends the LSA with two authentication
codes. The intermediate routers generates two authentication codes but forwards three authentication codes.
Finally, router XJ forwards the LSA(fl2,flits;)to
router xk, When router xk receives this LSA, it first
verifies authentication code A(SL), and then checks
code A(Qj). If authenticated, i t just follows same steps
as router ZJ does in order to generate the new-authentication codes.

oa

a2

0.1

04

0 5 0 6

0.0

1.0

Probability oi an edge betweentwo routers

Figure 2: Number of keys needed to be stored by a
router with increasing probability

-z

4 Performance Assessment
In this section we discuss the storage requirement
due t o our proposed key management scheme. We then
discuss the security robustness of the N-DA versus 0DA scheme.
0

4.1 Storage complexity
To evaluate storage complexity, we assume there are
n routers within a link state routing domain. The
OSPF standardization report 191 states that the maximum number of routers in a single OSPF area is about
350. We use n = 350 as the maximum number of
routers within a single area. We also assume that the
probability of having an edge between two routers is p .

25

-

1

I

6

8

10

12

I4

16

10

.ZU

Average degree (numbar of Ilks) of a router

Figure 3: Number of keys needed to be stored by a
router with increasing degree

Figure 2 shows the relation between the average
number of keys possessed by a node and the probability of a link between two routers. The worst case is
p = 1, which forms a fully connected network. Based
on the Lemma 1, in the worst case, the number of keys
possessed by each router is 2(n - l), and the storage
complexity is O(n). n p is the average degree (number
of links connected to a router, which is represented by
d ) of a router. When n = 350, p = 0.2, then d = 75.
Figure 3 shows the relation between average number of
keys possessed by a router with the increased degree.
We can see that for a very dense network, a router
with average degree of 20, the average number of keys
possessed is no more than 40. In Figure 4, if the R
equals to 150, 250, and 350, and the corresponding p

Lemma 1 I n the new key distribution scheme, for a
network with n nodes, if the probability of a direct link
between any two nodes is p , then the average number
of Beys distributed to a node is 2 ( n - 1)p.

Proof 1 The average number of keys distributed to a
node includes two parts: (1) The total number of direct
link from a node x to other nodes is:
p = (n1)p; (2) The total number ofsub-group including x but
not the neighbors of z equals'to the number of neighbors
of x, which is ( n - l)p. Thus, the average number of
keys for a node is therefore 2(n - I)p. 0

22

router x3 compromises LSA received from router z',
router '5 can immediately identify changes through
authentication code A(Qi). Router 2 9 cannot deny it,

1

~,'
'

I
I

r;

a *

C

YI

im

150
m
Number of routers

264

m

550

Figure 4: Number of keys needed to be stared by a
router wit.h increasing number of routers
is 0.024258, 0.0159955, and 0.0121077, the average degree of a router is 3.6387, 3.9989, and 4.2377, respectively. IVe note that the complexity of average number
keys possessed by a router is restricted by O(Iog, n).
4.2 Security Robustness
The DA scheme is aimed to guard against impersonation attack. Here, we compare 0 - D A and N-DA
in terms of resilience to impersonation attacks in the
following scenarios:

1. There are one or multiple subverted routers and
they do not collude.
2. There are multiple subverted routers colluding to

impersonate other routers and generate forged
routing information. The colluded routers do not
partition the network.
3. There axe multiple subverted routers. These routers

collude and partition the network.

since authentication code A(s1;) proves that router 'x
is innocent and authentication code A(Si) proves that
only router x3 or xk can be the subverted router.
Second scenario: 0-DA can provide heIpful information for the intrusion detection system (IDS) to locate the attack source, A simple example is shown in
Figure 5. We assume that the subverted routers are 5 3
and xk; they substitute/spoof the LSA from/of router
xn. As the flooding feature of link state routing protocol, router sn will eventually receive the forged LSA
from router 2". Hence, router x n will notice the inconsistency of routing information. Following the routing information propagation path, the authentication
chain is set up as follows:

These three pieces of routing information are presented
by routers d,z m ,and xn, which were received from
their neighbors x k , z l . and x m , respectively. When
x1 presents the evidence of LSA(V\{Z~),v\{&},S:),
it can help IDS trace back to the source router zk.
As we discussed in the first scenario, router xk cannot
deny the generation of this forged routing information.
However, using 0-DA, the colluded routers can be any
pair (for instance, can be ;cj and x'), which can confuse IDS in locating subverted routers. For the same
example, if router ~e is subverted instead of router xj,
xi can share the K ( V \ { z k ) ) with another subverted
router xk to forge the authentication code A(V\{xk}).
In this case, IDS has no clue if router xi is subverted

or not.
In the N-DA scheme, each router only knows keys
shared with its next-hop neighbor and keys shared with
all the neighbors of its next-hop. Hence, in the above
scenario, the authentication chain would be:

Figure 5: DA robustness analysis example

1% analyze the security robustness based on these
three scenarios.
First scenario: N-DA provides the same security
robustness as 0-DA. As shown in Figure 1,if subverted

Here, only routers x3 and xi know the shared key
K(RF), and no one else. This property restricts the
subverted sources staying together, therefore making
it easier to locate them.
Third scenario: Network partition leads to two scenarios. First, the partitioning routers do not let the
routing information and traffic go through. Second,

storage requirement from quadratic to linear (in the
worst case). In the network with average degree of 4,
the complexity of number of keys possessed by a router
is close to O(log, n.). Second, the new key distribution
scheme strengthens the robustness of DA scheme by
forcing the subverted routers to stay together, which
makes it easier in locating the attack source.

the partitioning routers selectively block the routing
information and the traffic.
For the first scenario, routers x* and 5‘ collude to
partition the network into two parts PI and P2 (see
Figure 5). If Z*and IC’ stop forwarding traffic between
these two parts, it is equivalent to the network congestion happening a t the network points 2‘ and x J . IDS
can quickly locate where these problems occur. Thus,
xt and d can be easiIy identified.
For the second scenario, if x’ and xL forward data
traffic as normal and inject false routing information
regarding to themselves, i.e., they may either increase
or decrease their link metric values. In the first case,
increasing metric value, such as delay, the network traffic congestion might occur between two partitions (assuming there are no alternate routes). In the second
case, decreasing metric, such as delay, the tr&c can
be attracted to go through the partitioning routers.
This might have a local impact when this partitioned
network is subnetwork of a comparatively large system.
The attacker’s goal is to maximize the consequence
of attacks, subverted routers can impersonate a set of
routers within a partition and inject forged routing information to another partition. It can attract more
traffic to go through partitioned routers.
The O-DA scheme totally fails in the third scenario.
For example, if routers 9 and d impersonate xn and
zm in PI and inject the forged routing information
into Pz, they can prevent the forged routing informa-

References
D. Huang, A. Sinha, and D. Medhi, “A double
authentication scheme to detect impersonation attack in link state routing protocols,” in Proceedings
of IEEE International Conference on Communications (ICC), 2003, pp. 1723 - 1727.

S. Murphy, M. Badger, and B. Wellington, “Ospf
with digital signatures,” RFC2154, June 1997.

J. Moy, “OSPF version 2,“ RFC2328, April 1998.
W. Stallings, Cryptography and Network Security:
Principles and Pmctice. Prentice Hall, 2003.

S . Cheung, [‘An efficient message authentication
scheme for link state routing,” in Proceedings of
Annual Computer Security Applications Conference (ACSAC), 1997, pp. 90-98.

R. Hauser, T. Przygienda, and G . Tsudik, “Lowering security overhead in link state routing,” Computer Networks, vol. 31, no. 8, pp. 8855894, 1999.
H. Krawczyk, M. Bellare, and R. Canetti,
“HMAC: Keyed-hashing for message authentication,” RFC2104,February 1997.

tion from receiving by zR and z m . In case of N-DA,

the attackers must be located as neighbors to deploy
the attack. Thus, N-DA provides stronger protection

than O-DA. An attacker requires not only partitioning
of the network, but also that a t lease two of subverted
routers have direct link between them in order to succeed. The reason is the same as present in the second
scenario. For example, only 9 ’ s neighbors can collude
with 5%to share the authentication key K(Qy).
Besides the three scenarios we had discussed above,
N-DA eliminates more uncertainty as compared to 0DA. In O-DA, any combination of sub-group members
could forge the routing information. It is very hard for
IDS to locate the exact attack source. But in N-DA,
only the routers having links between them can forge
the routing information; this can quickly help IDS to
identify the location of the attack sources.

5

D. Huang and D. Medhi, “A key-chain based keying scheme for many-to-many secure group communication,” ACM Transactions on Information and
System Security, vol. 7, no. 4, pp. 523 552, 2004.
~

J. Moy, “OSPF standardization report,” RFC2104,
April 1998.

Conclusion

In this paper, we proposed a new key distribution
approach for the double authentication scheme to protect from impersonation attacks. This key distribution
scheme brings two-fold benefits. First, it reduces the

24

SDNIPS: Enabling Software-Defined Networking
Based Intrusion Prevention System in Clouds
Tianyi Xingl, Zhengyang Xiongl, Dijiang Huangl, Deep Medhi2

1 Arizona

State University, U.S.A,{tianyi.xing, zhengyang.xiong, dijiang}@asu.edu
2

University of Missouri-Kansas City, U.S.A, dmedhi@umkc.edu

Abstract-Security has been considered as one of the top
concerns in clouds. Intrusion Detection and Prevention Systems
(IDPS) have been widely deployed to enhance the cloud se­
curity. Using Software-Defined Networking (SDN) approaches
to enhance the system security in clouds has been recently
presented in [1] , [2]. However, none of existing works established
a comprehensive IPS solution to reconfigure the cloud networking
environment on-the-fly to counter malicious attacks. In this paper,
we present an SDN-based IPS solution called SDNIPS that is a
full Iifecycle solution including detection and prevention in the
cloud. We propose a new IDPS architecture based on Snort­
based IDS and Open vSwitch (OVS). We also compare the SDN­
based IPS solution with the traditional IPS approach from both
mechanism analysis and evaluation. Network Reconfiguration
(NR) features are designed and implemented based on the
POX controller to enhance the prevention flexibility. Finally,
evaluations of SDNIPS demonstrate its feasibility and efficiency
over traditional approaches.

I.

INTRODUCTION

Cloud computing platforms have been widely proposed and
implemented due to the flexibility, scalability, high availability,
efficiency, and so on [3], [4], [5]. Security has been regarded
as one of the most critical issues where cloud resource abuse
and malicious insiders are among top threads considered in the
current cloud computing systems [6]. Based on compromised
cloud resources, attackers may spam, disseminate malicious
codes, crack passwords and security keys, compromise vul­
nerable VMs and then deploy DDoS attacks, deploy botnet
command and control, etc. Existing countermeasures usually
provide add-on and customizable security models, and con­
sider the cloud can afford the demanded resource.
Establishing the Intrusion Detection and Prevention System
(IDPS) is a good way to protect the cloud system with both
detection and prevention capability. Traditionally, the IDS can
be configured and enabled to be an IPS. For instance, Snort
[7] can be configured as the inline mode and work with a
common firewall system, e.g., Iptables, to implement the IPS
in the cloud networking environment [8]. However, there are
several issues with such a traditional IPS: 1) Latency: in-bound
IPS requires inspection and blocking action on each network
packet, which consumes cloud system resources and increases
the detection latency; 2) Resource Consumption: running the
IDPS services usually consumes significant resources. For
instance, configuring SPAN port mirroring technology will
duplicate all traffic and forward to a port that an IDS is con­
nected; 3) Inflexible Network Reconfigurations: traditional IPS
does not have network prograrmnability feature to reconfigure

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

the virtual networking system and provide scrutinized traffic
inspection and control.
SDN based security approaches in a cloud virtual net­
working environment has been considered as the trend for
future virtual networking security solutions. Opensafe [9]
is a system utilizing both OpenFlow and Snort technology
but they focused on the area of how to route traffic to
monitoring appliances, rather than attempting to provide a
comprehensive detection and prevention solution. In [10], the
authors proposed a mechanism called OpenFlow Random Host
Mutation (OFRHM) in which the OpenFlow controller fre­
quently assigns each host a random virtual IP that is translated
to/from the real IP of the host. This mechanism can effectively
defend against stealthy scanning, worm propagation, and other
scanning-based attack, but does not work when the attackers
know the internal address of victims. In a recent work [2], the
authors presented an SDN-based IDSIIPS solution to deploy
attack graph to dynamically generate appropriate counter­
measures to enable the IDSlIPS in the cloud environment.
SnortFlow [1] is another recent work focusing on the design
and preliminary evaluation of OpenFlow [11] enabled IPS in
the cloud environment. However, to our best knowledge, none
of them address the issue below: 1) how to establish an effi­
cient SDN-based IPS solution in the cloud virtual networking
environment; 2) how does SDN-based IDSlIPS compare with
traditional one; 3) how to design the SDN-based IDSIIPS
networking architecture that provides a dynamic defensive
mechanism for clouds.
Therefore, motivated by issues above, we present the SD­
NIPS, a SDN-based IPS security solution in clouds. This paper
proposes a new design of IDSIIPS based on SDN network
management, i.e., Open vSwitch (OYS); it also introduces
a comprehensive comparative study based on the presented
SDNIPS and Snort/lptables based IPS [12] solutions to demon­
strate the advantages of the SDN-based IDSIIPS solution.
II. SDNIPS:

DESIGN AND IMPLEMENTATION

In this section, we present the designed architecture includ­
ing components and the processing flow of the SDNIPS, which
is then followed by the Network Reconfiguration (NR). The
architecture and components are presented in Fig. 1.
A. Overall Architecture and Components

Cloud Cluster is the major component hosting cloud re­
sources and the environment where the proposed SDNIPS is

308

CNSM Short Paper

daemon is implemented in the format of JSON message. The
alert information is stored in JSON message and the JSON
server is running at the controller side. Alert interpreter takes
care of parsing the alert and targets the suspect traffic. Several
information is parsed out of the raw alert data, e.g., source
IP address, destination IP address, TCP port, etc. Then, the
parsed and filtered information is passed to rules generator
that generates the rules to be injected to the OpenFlow device
to reconfigure the network.
User

Kernel

--

I - - - o;udVirWaI Networ kEn � n-;:;;-e � - - l
I

�

I
I
I

Fig. 1: The SDNIPS System Architecture.

applied. A cloud cluster can contains one or multiple cloud
servers with major cloud-based OS installed. In this paper, our
established system is based on XenServer that is an efficient
parallel virtualization solution on top of the bare metal. Open
vSwitch (OVS) is the pure software implementation of the
OpenFlow switch [11J. OVS is usually implemented in the
management domain or privilege domain of the cloud system.
In user-space of OVS, there are two modules which are ovsdb­
server and ovs-switchd. The module ovsdb-server is the log­
based database that holds switch-level configuration; while
the module ovs-switchd is the core OVS component that
supports multiple independent data-paths (bridges). As shown
in Fig. 1, ovs-switchd module is able to communicate with
ovsdb-server through management protocol, with controller
through OpenFlow protocol, and with kernel module through
netlink. In the kernel space, kernel module handles packet
switching, lookup and forwarding, tunnel encapsulation and
decapsulation. Every Virtual Interface (VIF) on each VM has
a corresponding virtual interface/port on OVS, and different
virtual interface connecting to the same bridge can be regarded
on the same switch. For example, VIF 1.0 (the virtual port
of ethO on VM from Dom 1) has the layer 2 connection
with VIF 2.0 (the virtual port of ethO on VM from Dom 2).
Snort is a multi-mode packet analysis tool dominating the
IDS/IPS market and has overall performance strength over
other products [13]. It has sniffer, packet logger, and data
analysis tools. In its detection engine, rules form signatures
to judge if the detected behavior is a malicious behavior or
not. It can be implemented in Dom 0 (privilege domain) or
Dom U (unprivileged domain) based on Xen virtualization
architecture. In this paper, we deploy the Snort in Dom 0,
which makes it natively detect the bridge in OVS and has
better performance [IJ. Controller is the component providing
a centralized view and control over the cloud virtual network.
The controller contains three major components, SDNIPS
daemon, alert interpreter, and rules generator. SDNIPS daemon
is mainly for collecting alert data generated from Snort agent
in Dom 0 of controlled SDN devices, i.e., OVS. The SDNIPS

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

Fig. 2: The SDNIPS Processing Flow.

B. SDNIPS Processing Flow

The processing flow of the SDNIPS is illustrated in Fig.
2. The network traffic is generated from the cloud resources,
i.e., VMs. Snort agent in Dom 0 has the advantage of directly
detecting through the bridge, which is more efficient than
sniffing the traffic by utilizing the SPAN technology. When
any traffic matching the Snort rules is alerted into the log file,
The SDNIPS daemon will store the alert information in JSON
format and send over to the JSON server at controller side.
After that, the alert interpreter will parse the alert information
and extract all necessary information, e.g., attack type, source
IP, destination IP, TCP port, etc. Finally, the rules generator
will generate the OpenFlow rule entries and push them to the
OVS to update the flowtable. Therefore, the following suspect
traffic matching the newly updated flowtable entries will be
swiftly handled with valid countermeasures in the data plane
of the OVS with line rate. Currently, the system described in
Fig. 1 is implemented.
C. Network Reconfiguration (NR)

NR is an approach to reconfigure the network characteristics
including topology, packet header, QoS parameters, etc. With
the SDN concept enabled in the cloud virtual networking
environment, network reconfiguration can be applied to con­
struct the countermeasure of the IPS system. Traffic redirec­
tion redirects the traffic by rewriting the destination address.
QoS adjustment adjusts the QoS parameters. Traffic isolation
isolates the traffic by using virtual networking technology
such as VLAN. Filtering filters the packets by matching any
field of the flowtable and take corresponding actions, e.g.,
drop. Block port blocks the TCPIUDP ports. Major network
reconfiguration actions are summarized in Table I.

309

CNSM Short Paper

TABLE I: Network Reconfiguration Actions

I

I

No
1
2
3

4
5

III. SDNIPS

- - �

I
I

I
I

I

Transport

Internet
User Space
Kemel Space

Ne�ork

Ne�ork

IPS

Control Packet

(SNORT/IpTABLES)

_

om
om
om
I I eslPS III
I
: I Attacker I: IIIPtabl
ler IIII:1
I I Control
t
I
II II I I IIII
II II I I IIII
I
II I
II
I I 1 ::
I I ��u� II
I
IIII
II II
IIII
II II
'I, Dom ---'=-- ---'=-�

1

1,

2

3

4

om
III SONIPS II
I
IIII I Controller III
I t
II I I
IIIIII I II
I
III
II : I : 1
II I I I I
IIII I I
IIII II I
---'---f-r-,
----l
I:
II
t
4

-

2

3

I
iI

IV.

iI

i

i
�

Data Packet

Victim

i

0
----

I

Traffic Redirection
QoS Adjustment
Traffic Isolation
Filtering
Block Port

VS TRADITIONAL

Application

bridges, even though the OVS controller is placed at Dom
U, only few control messages between OVS at Dom 0 and
controller at Dom U are generated (red line 2 & 3). After
the controller update the flowtable, all traffic with the same
pattern will be processed at OVS fast path in Dom 0 (red
line 4). From the Fig. 3, it is also obvious that packets in
Snortllptables IPS scenario need to be in and out the Dom 0
twice while the SDNIPS only needs once to fulfill the same
task. Although control message in SDNIPS has further way
to go than in Iptables IPS, the control message only updates
the flowtable at the first time when traffic is suspected and all
the traffic will be only handled by flowtable fast path at Dom
o without interaction with controller at Dom U. Thus, due
to the IPS working mechanism, SDNIPS should significantly
outperformance any other Dom U IPS solution especially in
cloud virtual networking environment.

Countermeasure

-

FlowTable

------------------------------

I

Fig. 3: SDNIPS and Snortllptables IPS Mechanisms.
Traditional IPS system is not specially designed for the
cloud virtual networking environment, but for a general net­
work environment. Two IPS solutions are different in terms
of the essence, i.e., working mechanism and operation level.
Fig. 3 indicates the scenario on how the Iptables IPS (blue
lines) and SDNIPS (red lines) prevent the attacks. The number
besides each line represents the sequence of the packet flow.
Solids lines and dot lines represent the data traffic and control
traffic respectively.
As shown in Fig. 3, when attacking packets generated from
attacker's virtual interface, all the packets need to be passed
through Dom 0 before being forwarded to the destination (blue
line 1). When Snort detects any suspect traffic, it needs to
inform the NFQUEUE, which is an Iptables and Ip6tables
target delegating the decision on packets to a user-space
software, to take the actions defined in the rules. The Iptables
IPS needs to consult its brain (controller at application level),
which then sends out control messages to issue command
(blue line 2 & 3). Finally, the suspect packet is handled
at Internet level kernel space at Dom U and will be either
forwarded to victim or dropped (blue line 4). Unlike the
Snortllptables IPS, SDNIPS stands out since both the detection
engine and the packet processing are natively deployed in Dom
0, which is dramatically efficient especially handling large
amount of traffic. When packets arrive at Dom 0 (red line
1), Snort detection engines is able to natively monitoring the

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

EVALUATION

We establish the SDNIPS prototype by using one cloud
server with OVS installed and properly configured in Dom
o which has 4 virtual CPUs. The detection engine, i.e., Snort,
in Dom 0 can directly access the virtual bridges in OVS to
monitor all tenant networks while Snortllptables-based IPS
agent in Dom U can only monitor the tenant network where
it is. The OVS controller is implemented based on the POX
controller [14]. Traditional Snortllptables IPS is implemented
in a VM (Ubuntu 12.04 Server edition, 4 virtual CPUs and
2048 MB Memory) at Dom U. All VMs at Dom U are
configured with VIF with lOGbE maximum capacity whose
actual bandwidth is around 8 Gbits/s based on our testing in the
real XenServer virtual network environment. In our evaluation,
the traffic are generated by hacking tools and packet generators
such as [15], [16], [17] to mimic the real attack scenario in
the cloud virtual networking environment.

Intrusion Detection Rate

12 0

0

• •

100

or---.....
0

0

0

0

0

0

0

0

"'......
"-,....,
.

.1 =

�p�NIPsl

'\

\

\

"-"

\

\

",

......
.. -....
..
.

\

0

'\.�()�<:P."o;:,�.,,'l()\�\'l()()��()..,,�,,�\'l()()#()b"-P(),\o;:,(,)()"'\'l(,)()<o�()q'l()�()��,,()�"()�"-P()�()�#�,,()���,,()�o;;P�
Attack Rate(packets per second)

Fig. 4: Evaluation of Intrusion Detection Rate.
In Fig. 4, we evaluate the alert generation capacity of both
IPS and SDNIPS under flood interference, which also states

310

CNSM Short Paper

how well the IPS can handle the attacking packets. To evaluate
this performance, we generate two different types of attacks,
which are DoS flooding attack acting as the stressful back­
ground traffic and ICMP flood attack acting as an potential
threat to be tested. This evaluation mainly indicates whether
IPS and SDNIPS can generate alert under high workload stress
in terms of successful alert generation rate of ICMP attack
under DoS attack interference. When the speed of the ICMP
attack reaches to 15000 packets per second, IPS can only
generate 13.72% alerts of the ICMP attack. On the other hand,
SDNIPS is able to efficiently avoid interference from DoS
flooding attack due to OVS capability, so it can successfully
alert all the threats that are sent at the speed of 15000 packets
per second. When the speed of the ICMP attack reaches to
30000 packets per second, the performance of SDNIPS start
decreasing, and when the speed of ICMP attack increases to
300000 packets per second, Snort agent in SDNIPS is not able
to capture packets and launch alerts because the snort detection
engine itself almost reached its threshold.

more packet fields to enable the spoofing feature. The default
NR, i.e., drop packets, consumes less system resource because
the OVS does not modify the matching flow and just simply
drop them (output to a non-existing virtual port in POX
controller implementation). In the QA scenario, it has the best
performance among all NRs because the rate limiting action
is performed based on OVS native mechanism, which means
excess packets will be discarded and OVS does not have to
inspect and match the packet with all kinds of fields.
V.

CONCLUSION

In this paper, we propose an SDN-based Intrusion Preven­
tion System called SDNIPS in the cloud virtual networking
environment. It inherits the intrusion detection capability from
Snort and flexible network reconfiguration from SDN. SD­
NIPS is firstly compared with traditional IPS from principle
perspective and the real world evaluation. NR actions are also
designed and developed based on OVS and POX controller.
The evaluation proves its feasibility and efficiency.
ACKNOWLEDGMENT

The presented work is sponsored by ONR YIP award and
NSF grant CNS-1029546.
REFERENCES
[I] T. Xing, D. Huang, L. Xu, c.-J. Chung, and P. Khatkar, "Snortflow: A
openflow-based system in cloud environment," in GENI Research and

50

"#

�

�

�

Educational Experiment Workshop, GREE,2013.

40

30

s:

U

20

Fig. 5: CPU Utilization Performance of Major NRs.
After the SDNIPS and traditional IPS are comparatively
evaluated, we evaluate the performance of SDNIPS NR alone
since traditional IPS does not have the NR capability. We
mainly evaluate two NR actions mentioned above, Traffic
Redirection (TR) and QoS Adjustment (QA), as well as
default drop action. Fig. 5 shows the performance of resources
consumption in term of the CPU utilization of Dom 0 for NRs.
We are using packet generator [ l5] to generate the packets
captured by Snort and processed by flowtable in order to test
the resources utilization change in the cloud system. In each
NR approach, TR is implemented by using destination IP &
MAC rewriting; while TR with spoofing reply is implemented
by rewriting not only destination IP & MAC address but also
source IP & MAC of victims. Thus, the attacking traffic can
be redirected to a security appliance that is able to spoof
the attacker by replying the packet with victims' IP & MAC
address as source address. TR with spoofing feature consumes
a little more resources than the pure TR since OVS modifies

ISBN 978-3-901882-67-8, 10th CNSM and Workshop ©2014 IFIP

[2] C.-I. Chung, P. Khatkar, T. Xing, J. Lee, and D. Huang, "Nice: Network
intrusion detection and countermeasure selection in virtual network
systems," in IEEE Transactions on Dependable and Secure Computing
(TDSC), Special Issue on Cloud Computing Assessment, 2013.
[3] T. Xing, D. Huang, D. Medhi, and S. Ata, "Mobicloud: a geo-distributed
mobile cloud computing platform," in Proceedings of 8th International
Conference on Network and Service Management, 2012.
[4] T. Xing, X. Liu, c.-J. Chung, A. Wada, S. Ata, D. Huang, and
D. Medhi, "Constructing a virtual networking environment in a geo­
distributed programmable layer-2 networking environment (g-plane)," in
Communications (ICC), 2012 IEEE International Conference on. IEEE,
2012, pp. 5879-5884.
[5] D. Huang, T. Xing, and H. Wu, "Mobile cloud computing service
models: a user-centric approach." IEEE Network, vol. 27, no. 5, 2013.
[6] c. c. S. Alliance, "Top threats to cloud computing v1.0," in White Paper,
2010.
[7] "SourceFire Inc." [Online]. Available: http://www.snort.org
[8] w. Morton, "Intrusion prevention straitegies for cloud computing," 2011.
[9] J. R. Ballard, I. Rae, and A. Akella, "Extensible and Scalable Network
Monitoring Using OpenSAFE," in INMIWREN, 2010.
[10] J. H. Jafarian, E. AI-Shaer, and Q. Duan, "Openftow random host
mutation: Transparent moving target defense using software defined
networking," in HotSDN, 2012.
[11] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson,
J. Rexford, S. Shenker, and J. Turner, "Openflow: Enabling innovation
in campus networks," in ACM SIGCOMM Computer Communication
Review, April 2008.
[12] R. U. Rehman, "Intrusion detection systems with snort," in BRUCE
PERENS OPEN SOURCE SERIES.

[13] A. Alhomoud, R. Munir, J. P. Disso, I. Awan, and A. Al-Dhelaan,
"Performance evaluation study of intrusion detection systems," in T he
2nd International Conference on Ambient System, Networks and Tech­
nologies, 2011.
[14] N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown, and
S. Shenkes, "Nox: Towards an operating system for networks," in ACM
SIGCOMM Computer Communication Review, July 2008.
[IS] R. Olsson, "pktgen the linux packet generator."
[16] hping3. [Online]. Available: http://Iinux.die.net/man/8/hping3
[17] NetPerf. [Online]. Available: http://www.netperf.org!

311

CNSM Short Paper

2222

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 61, NO. 5, JUNE 2012

An SMDP-Based Service Model for Interdomain
Resource Allocation in Mobile Cloud Networks
Hongbin Liang, Student Member, IEEE, Lin X. Cai, Member, IEEE, Dijiang Huang, Senior Member, IEEE,
Xuemin (Sherman) Shen, Fellow, IEEE, and Daiyuan Peng, Member, IEEE

Abstract—Mobile cloud computing is a promising technique
that shifts the data and computing service modules from individual devices to a geographically distributed cloud service architecture. A general mobile cloud computing system is comprised of
multiple cloud domains, and each domain manages a portion of
the cloud system resources, such as the Central Processing Unit,
memory and storage, etc. How to efficiently manage the cloud
resources across multiple cloud domains is critical for providing
continuous mobile cloud services. In this paper, we propose a
service decision making system for interdomain service transfer
to balance the computation loads among multiple cloud domains.
Our system focuses on maximizing the rewards for both the
cloud system and the users by minimizing the number of service
rejections that degrade the user satisfaction level significantly.
To this end, we formulate the service request decision making
process as a semi-Markov decision process. The optimal service
transfer decisions are obtained by jointly considering the system
incomes and expenses. Extensive simulation results show that the
proposed decision making system can significantly improve the
system rewards and decrease service disruptions compared with
the greedy approach.
Index Terms—Blocking probability, mobile cloud computing
service domain, semi-Markov decision process (SMDP), system
rewards.

I. I NTRODUCTION

C

LOUD computing is a promising platform to assist mobile devices in computing and communication. In cloud
computing, data and computing modules are located at remote
devices in a resource-on-demand and a pay-as-you-go manner

Manuscript received November 28, 2011; revised February 6, 2012; accepted
March 19, 2012. Date of publication April 14, 2012; date of current version
June 12, 2012. This work was supported by the Natural Sciences and Engineering Research Council of Canada and the National Basic Research Program of
China under Grant 2012CB316100 and Grant 2011CB302902. The review of
this paper was coordinated by Dr. P. Lin.
H. Liang is with the School of Information Science and Technology, Southwest Jiaotong University, Chengdu, Sichuan 610031, China, and also with the
Department of Electrical and Computer Engineering, University of Waterloo,
Waterloo, ON N2L 3G1, Canada (e-mail: hbliang@bbcr.uwaterloo.ca).
L. X. Cai is with the Department of Electrical Engineering, Princeton
University, Princeton, NJ 08544 USA (e-mail: lincai@princeton.edu).
D. Huang is with the School of Computing Informatics and Decision
Systems Engineering, Arizona State University, Tempe, AZ 85281-8809 USA
(e-mail: dijiang@asu.edu).
X. Shen is with the Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1 Canada (e-mail:
xshen@bbcr.uwaterloo.ca).
D. Peng is with the School of Information Science and Technology,
Southwest Jiaotong University, Chengdu, Sichuan 610031, China (e-mail:
dypeng@swjtu.edu.cn).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TVT.2012.2194748

Fig. 1.

Example of mobile cloud computing.

[1]. Mobile cloud has become a service model that allows
mobile devices to utilize the resource from the cloud without
complex hardware and software implementations at the device
side [2]–[5]. Due to the mobility of mobile users, locationbased (or geo-based) cloud resource provisioning is required to
reduce the end-to-end communication delay. As the result, the
mobile cloud system should consist of multiple cloud service
domains (i.e., partitioned by geographic locations). One cloud
service domain usually provides cloud services to local mobile
devices that are connected through local base stations or Internet access points. Although the resources of the mobile cloud
are considered as “infinite” compared with those in a single
mobile device, the available resources in one cloud service
domain are usually limited. Therefore, the service transitions
between different mobile cloud domains play a critical role in
improving the overall cloud resource utilization and quality of
experience (QoE) [6] for mobile users (e.g., less response time).
Fig. 1 shows our mobile cloud service model, which is a
geographically distributed mobile cloud system that is currently
developed by MobiCloud [7]. The mobile cloud service model
follows the mobile cloud service framework of [2], where a
virtual machine (VM) is the minimal portion of the cloud
resource that can be allocated to a cloud service. When a mobile
user sends a service request to the mobile cloud system, a
cloud service domain (i.e., confined by a geographic location)
that is close to the mobile users’ location is selected. After
connecting to the mobile cloud, one or multiple VMs are
dedicatedly assigned to each mobile device that is located in
any mobile cloud service domain. We denote the connecting
mobile cloud service domain as the home cloud domain, which
is geographically close to the mobile device’s location.
In MobiCloud, the elastic mobile cloud service model is defined as follows: To initiate the mobile cloud service, a mobile
user first initiates a request to its home cloud domain according

0018-9545/$31.00 © 2012 IEEE

LIANG et al.: SMDP-BASED SERVICE MODEL FOR RESOURCE ALLOCATION IN MOBILE CLOUD NETWORKS

to its geographical locations; if the mobile cloud service request
is new in the home cloud domain, the resource management
controller of the home cloud domain decides whether the
service request should be accepted or transferred based on the
available system resource; when a request is accepted, a VM is
or multiple VMs are allocated to the requesting mobile device
for cloud related operations; if the available resources of the
home cloud domain is not sufficient, a transfer decision will
be made, and then the service request will be transferred to an
adjacent cloud service domain.
In this paper, we study cloud resource allocation in a multidomain mobile cloud system that has the following properties:
1) Both the arrivals and departures of mobile cloud services
follow Poisson distribution; 2) the available resource of the
cloud is time varying; and 3) current resource decision may
have a big impact on the future decision. In a multidomain cloud
system, the overall system performance degrades if the mobile
cloud system does not consider the relationship between present
and future in terms of the resource allocation decisions and
outcomes [8]. To construct a comprehensive resource allocation
model for geo-based mobile cloud computing, we present a
decision support system for resource management with considering cloud system resource, profit gain, and mobile users’
QoE. The objective of this paper is to maximize the overall
rewards of the cloud system and mobile users. In our presented
model, both the arrivals and departures of mobile application
services are random and bring the state changes of the cloud’s
resource. According to the definition of semi-Markov decision
process (SMDP) [8], [9], the decision epoch of SMDP can
be chosen at the point when any random event occurs. Thus,
we first analyze the system rewards within a cloud domain
considering interdomain resource transfer based on a SMDP
model. The presented resource allocation decision model is
to obtain the optimal resource allocation among mobile cloud
service domains. We show that the presented solution can not
only improve the cloud system resource utilization but also
achieve better QoE for mobile users. To verify the performance
of our proposed model, we perform a simulation-based study
by comparing the performance of our model with the greedy
algorithm [10], where greedy algorithm always allocates as
much resource as possible to the mobile service requests. Our
extensive simulation results show that the service rejection
probability with interdomain service transfer is decreased by
20% compared with the greedy approach.
The remainder of this paper is organized as follows. The
related work is presented in Section II. The system model is
described in Section III. An SMDP model is developed in
Section IV. Based on the SMDP model, we derive the dropping
probabilities in Section V, followed by performance analysis
in Section VI. Finally, concluding remarks and future work are
given in Section VII.

2223

devices can outsource computation/communication/storage intensive operations to the mobile cloud. CloneCloud [5] focused on execution augmentation with less consideration
on user preference or device status. Elastic applications for
mobile devices via cloud computing were studied in [12].
Oberheide et al. [13] presented a framework that outsources
the antivirus services from mobile devices to a cloud. Goyal
and Carter proposed a secure cyber foraging mechanism for
resource-constrained devices [14]. In [2], Huang et al. presented a mobile cloud computing model that allows the mobile
device related operations residing either on mobile devices
or dedicated VMs in the cloud. The problem of ensuring the
integrity of data storage in cloud computing is studied in [15]
and [16]. Although resource management in wireless networks
has been extensively studied [17]–[24], it is not well studied in
mobile cloud computing. In [25], an economic cloud computing
model is presented to decide how to manage the computing
tasks with a given configuration of the cloud system, i.e., the
computing tasks can be migrated between the mobile devices
and the cloud servers.
Specialized hardware-based solutions for high availability
(HA) are expensive and may require changes on the applications [26]. Software-based solutions for HA provide virtualized execution environment (VM) for applications and fast
recovery mechanisms when physical hosts become unavailable
[27], [28]. A game theory-based resource allocation model to
allocate cloud resources according to the users’ QoS requirements is proposed in [29]. The other mobile cloud computing
solutions are limited and solely focused on the enhancement
of the individual mobile device’s capability. To the best of
our knowledge, none of the previous works addressed how to
construct a mobile cloud computing system reward model for
resource allocation considering the whole rewards of both cloud
systems and mobile users and how to select a cloud domain to
allocate system resource through interdomain service transfers.
III. S YSTEM M ODEL
In this section, we present our proposed mobile cloud resource management model for choosing the optimal adjacent
cloud domains. We first describe the optimal algorithm of our
presented mobile cloud resource management model. Then, the
system states of our proposed model and the actions of each
state are described. Finally, we describe the system reward
model, which is critical for connecting home cloud domain to
decide whether the mobile service should be accepted, rejected,
or transferred to an adjacent cloud domain. Before making a
decision, home cloud domain needs to obtain the entire system
reward for each action (i.e., accept, reject, and transfer) and
makes the optimal decision for our reward model.
A. System Description

II. R ELATED W ORK
Recent research on cloud computing has been focused on
mobile devices of cloud computing [11], which enables running applications between resource-constrained devices and
Internet-based clouds. Moreover, resource-constrained mobile

As shown in Fig. 1, we consider a mobile cloud system that
is composed by multiple service domains. Suppose there are
K-VM resource available in one cloud domain, and a service
occupies c VMs, where c ∈ {1, 2, . . . C}, C ≤ K. In each
service domain, there are two types of service requests, namely,

2224

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 61, NO. 5, JUNE 2012

TABLE I
NOTATIONS

Fig. 2. System algorithm of proposed dynamic selection adjacent mobile
cloud domain model.

new service requests initiated in the home cloud domain and
interdomain transfer service request from/to adjacent cloud domains. We assume that the arrival rates of both new service requests and interdomain transfer service requests follow Poisson
distributions with mean λn and λt , respectively. For different
services, the service time follows an exponential distribution
with different mean rates. Let µ denote the computation rate of
one VM for the requested service task. However, when a request
is admitted, computing resources (i.e., VMs) will be allocated.
Thus, the occupation time of c VMs in the cloud is 1/(cµ).
The decision-making procedure in a multidomain cloud system is shown in Fig. 2. When a new mobile cloud service request arrives, the controller of the home cloud domain evaluates
the expected system gain and the expected system expenses,
including the cost of occupying VMs during the computation
period, the communication cost between the cloud and mobile
devices, and the power consumption of the mobile devices,
to decide whether to accept, reject, or transfer the request to
adjacent cloud domains. If the home domain cannot accommodate the mobile service request, then it needs to evaluate if
the service request can be successfully transferred to another
cloud service domain. Hence, the home domain cloud sends an
interdomain transferring request to its geographically adjacent
domains. Each adjacent domain will then return a decision
by considering the expected computing resource occupation in
its own domain, the extra communication overheads between
the mobile device and the cloud, and the involved transfer

fee, if there is one. If there is no adjacent domain that can
accept the service request, the home domain should only reject
the mobile service request. Then, the mobile device has to
run the service task on the device itself, the restricted power
and computing resources of which may result in a low QoE.
While if multidomains can accept the service request, the home
cloud domain needs to decide which adjacent cloud domain the
home service request can be accepted based on the feedback
collected from its adjacent cloud domains. For instance, a home
cloud domain may select a neighboring cloud domain that
can allocate the maximum number of VMs to the requested
service
ı̃ = arg max{ci }

(1)

i

where i denotes the ith adjacent cloud domain, ı̃ denotes the
optimal adjacent cloud domain that the home cloud domain
selects, and ci is the number of VMs that the ith adjacent cloud
domain can allocate to the interdomain transfer from the home
cloud domain.
In Table I, we highlight the notations used in this paper.
Detailed formulation of the system rewards and the action
model will be described in the following sections.
B. System States
The number of service requests that have been allocated c
VMs is denoted as sc . The total number of occupied VMs in a

LIANG et al.: SMDP-BASED SERVICE MODEL FOR RESOURCE ALLOCATION IN MOBILE CLOUD NETWORKS


cloud domain is C
c=1 (sc ∗ c), where C is the maximum number of VMs that can be allocated to a service request. An and
At are the arrival of a new service request and an interdomain
transfer service request, respectively. When a service completes
and leaves the cloud system, the occupied VMs will be released,
and the available VMs in a cloud domain need to be updated.
We use Fc to denote a departure of a service with 1 ≤ c ≤ C
VMs. An event in the event set e of a cloud computing system
can be described as e ∈ e = {An , At , F1 , F2 , . . . , FC }.
The system state S of a cloud domain can be characterized
by the current services with different numbers of VMs and
an event in the system, which could be either an arrival or a
departure, i.e.,
S = {s|s = s1 , s2 , . . . , sC , e = s, e}
where s = s1 , s2 , . . . , sC , and

C

c=1 (sc

(2)

∗ c) ≤ K.

C. Actions
Upon receiving a request, three actions can be chosen from
the action set, accept with c VMs, reject, and transfer, which
can be denoted as a(s) = c, c ∈ {1, 2, . . . C}, a(s) = 0, and
a(s) = −1, respectively. When a service completes and departs the cloud domain, no other action is required except
the available VMs in the cloud should be updated, which
is denoted as a(s) = −2. Thus, the action space Acts =
−2, −1, 0, 1, 2, . . . , C, and the action set a(s) is

{−1, 0, 1, . . . C}, e ∈ {An , At }
(3)
a(s) =
−2,
e ∈ {F1 , F2 , . . . , FC }.

D. Reward Model
Based on the system state and the corresponding action, the
overall system reward of a cloud network, denoted by r(s, a),
can be evaluated as
r(s, a) = w(s, a) − g(s, a)

(4)

where s = s, e, e ∈ {An , At , F1 , F2 , . . . , FC }, w(s, a) is
the lump sum income of the cloud system by making a
decision/action a when event e occurs in state s, and g(s, a)
is the expected system cost.
The lump sum income w(s, a) is computed as

0,
a(s) = −2,



e
∈ {F1 , F2 , . . . , FC }




−
E
−
δ
β
−
δ
β,
a(s)
= −1, e = An
E

d
t
s
d


 −δs β − δd β,
a(s) = −1, e = At
w(s, a) = −Ud − θd β,
a(s) = 0, e = An



0,
a(s)
= 0, e = At



β

E
−
δ
β
−
,
a(s)
= c, e = An

d
d

cµ


β
Et − cµ ,
a(s) = c, e = At .
(5)
A system will not gain income when a service completes
and leaves the system, and we have w(s, a) = 0 for a(s) =
−2, and e ∈ {F1 , F2 , . . . , FC }. When a new service request

2225

is admitted into the system, the income of Ed is earned, and
in the meantime, the admitted service will use c VMs in the
cloud domain, which involves δd β transition expense and β/cµ
resource occupation expense. Here, the transition expense is
the cost to transfer the computing task from the mobile device
to the cloud, and the resource expense is the cost of VMs
being occupied during the service time of the request, where
δd denotes the time consumed on transmitting the new service
request from the mobile device to the cloud through wireless,
and β denotes the price per unit time, which has the same
measurement unit as the income.
For an interdomain transfer request, the home cloud domain
pays Et income to an adjacent domain, and thus, the expected
reward of the new cloud is Et minus the resource expense
Et − β/cµ for a(s) = c and e = At . If the new service request
is rejected, the computing task has to be run at the mobile
device, which causes energy expense Ud and the resource
expense θd β, where θd is the service time of a mobile device,
and θd  1/µ due to the limited computation capability of a
mobile device. There is no income to reject a transfer request
as the income has been calculated in the home cloud domain.
When a new request is transferred to an adjacent domain, the
home cloud domain earns Ed and pays Et to the transferred
adjacent domain. Similarly, there is a transition expense δd β to
transfer the computations from mobile device to the cloud. In
addition, the migration between different cloud domains also
involves an extra communication expense, which is denoted by
δs β, where δs denotes the time consumed when transferring
the service request between different cloud domains. Therefore,
w(s, a) = Ed − Et − δs β − δd β, where a(s) = −1, and e =
An . However, the reward model is different when an interdomain transfer request is transferred to an adjacent domain by
the home domain. In this case, the home domain obtains Et
from the adjacent domain that transfers the new request to the
home domain but pays Et to the transferred adjacent domain
for the interdomain transfer request. Thus, the earning of the
home cloud domain is 0. The costs δs β and δd β are the same
as that of a new request as well. Then, w(s, a) = −δs β − δd β
when a(s) = −1 and e = At .
The expected system cost g(s, a) is given by (4), i.e.,
g(s, a) = τ (s, a)o(s, a), a(s) ∈ Acts

(6)

where τ (s, a) is the expected service time when the system
transfers from the current state s to the next state when decision
a is made; o(s, a) is the cost rate of the service time, and it is
determined by the number of occupied VMs
o(s, a) =

C


(sc ∗ c).

(7)

c=1

IV. S EMI -M ARKOV D ECISION P ROCESS -BASED
M OBILE C OMPUTING M ODEL
In this section, we develop an SMDP-based mobile computing model to analyze the performance of a cloud network. Our
main objective is to make optimal decisions at decision epochs,
i.e., when a service request arrives (i.e., An or At ) or a service

2226

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 61, NO. 5, JUNE 2012

Fig. 3. State transition diagram.

completes and leaves the system (Fc ), the long-term expected
system rewards are maximized. The time duration between
two continuous decision epochs also follows an exponential
distribution. The state transition diagram with C = 2 is illustrated in Fig. 3, where the first item in the state transition
diagram represents the action, and the second item presents the
state transition probability. The three tuples in Fig. 3 represents
the system state of the mobile cloud domain. Taking 1, 0, An 
as an example, the first two items in the three tuples indicate
that the total number of services that occupy one and two VMs
is 1 and 0, respectively, and the third item An in the three tuples
denotes an arrival of a new service request.
Given the current state s and the selected decision a, we
denote the time duration from this epoch to the next epoch by
τ (s, a). Therefore, the mean rate of events for a given s and a,
denoted as γ(s, a), is the summation of the rates of all events in
the system, which is given by
γ(s, a) =τ (s, a)−1

C


 λn +λt +
sc cµ



c=1


=



C




 λn + λ t +
sc cµ + cµ,

e ⊆ {F1 , F2 , . . . , FC }
e ⊆ {An , At }, a = −1
e ⊆ {An , At }, a = 0
e ⊆ {An , At }, a = c

c=1

(8)

where λn and λt are the arrival rates of the new and transfer
requests, respectively. When a departure occurs, or an arriving
request is rejected or transferred,
the total number of existing
thus, the rate of
services in the cloud domain is C
c=1 sc , and
C
an existing service departing the system is c=1 sc cµ. When

a service request is admitted, we have C
c=1 sc + 1 services,
C
which accounts for c=1 sc cµ + cµ.
We then evaluate the expected discounted reward (denoted as
r(s, a)) during τ (s, a) based on the discounted reward model
defined in [8] and [30], i.e.,

r(s, a) = w(s, a) −

o(s, a)Esa

τ

−αt

e

	
dt

0


= w(s, a) −

o(s, a)Esa

= w(s, a) −

o(s, a)
α + γ(s, a)

[1 − e−ατ ]
α

	

(9)

where α is a continuous-time discounting factor.
q(j|s, a) is defined as the state transition probability from
state s to state j when action a is chosen. We then derive the state transition probability, as shown in Fig. 3. For

LIANG et al.: SMDP-BASED SERVICE MODEL FOR RESOURCE ALLOCATION IN MOBILE CLOUD NETWORKS

the state s = s1 , s2 , . . . , sc , . . . , sC , An , q(j|s, a) can be
obtained as

q(j|s, a) =

 λn
,

 γ(s,a)




λt



γ(s,a) ,





sc cµ



γ(s,a) ,





 (sc +1)cµ
,
γ(s,a)




sm mµ


 γ(s,a) ,






λn

,
 γ(s,a)






λt


 γ(s,a) ,

j = s1 , . . . , sC , An 
a = 0, −2
j = s1 , . . . , sC , At 
a = 0, −2
j = s1 , ., sc −1, ., sC , Fc , sc ≥ 1
a = 0, −2
j = s1 , ., sc , ., sC , Fc 
a=c
j = s1 , .sm −1, .sc +1, .sC , Fm 
sm ≥ 1, m 	= c, a = c
j = s1 , ., sc + 1, ., sC , An 
sc ≤ C − 1, a = c
j = s1 , ., sc + 1, ., sC , At 
sc ≤ C − 1, a = c
(10)

where c ∈ {1, 2, . . . , C}, m ∈ {1, 2, . . . , C}, m 	= c.
For the states s = s1 , s2 , . . . , sc , . . . , sC , At , q(j|s, a) can
be obtained as
 λn

γ(s,a) ,






λt


γ(s,a) ,





sc cµ


 γ(s,a) ,





 (sc +1)cµ

j = s1 , . . . , sC , An 
a=0
j = s1 , . . . , sC , At 
a=0
j = s1 , ., sc − 1, ., sC , Fc 
sc ≥ 1, a = 0
γ(s,a) , j = s1 , ., sc , ., sC , Fc 
q(j|s, a) =
a=c



sm mµ

,
j = s1 , .sm − 1, .sc + 1, .sC , Fm 

γ(s,a)




sm ≥ 1, m 	= c, a = c


λn


j = s1 , ., sc + 1, ., sC , An 

γ(s,a) ,



s

c ≤ C − 1, a = c


λt

,
j
= s1 , ., sc + 1, ., sC , At 

 γ(s,a)
sc ≤ C − 1, a = c
(11)
where c ∈ {1, 2, . . . , C}, m ∈ {1, 2, . . . , C}, m 	= c.
For the states s = s1 , s2 , . . . , sc , . . . , sC , Fc , when a service leaves the system, there is no special action required, and
a = −2; thus, the transition probability q(j|s, a) is
 λ
n

 γ(s,a) , j = s1 , s2 , . . . , sC , An 
λt
q(j|s, a) = γ(s,a) , j = s1 , s2 , . . . , sC , At 

 sc cµ , j = s , s , ., s −1, ., s , F , s ≥ 1
1 2
c
C
c
c
γ(s,a)
(12)
where c ∈ {1, 2, . . . , C}.
Based on the derived transition probabilities, we can obtain
the maximum long-term discounted reward using a discounted
reward model defined in [8] and [30] as





ν(s) = max r(s, a) + λ
q(j|s, a)ν(j)
(13)
a∈Acts 


Letting w = λn + λt + K ∗ C ∗ µ < ∞, q̃(j|s, a), ṽ(s), and
r̃(s, a) are defined as the uniformed transition probability, longterm reward, and reward function, respectively. We derive the
optimality equation of ν(s) after the uniformization as





ν̃(s) = max r
(s, a) + λ̃
q̃(j|s, a)ν̃(j)
(14)

a∈Ã 
j∈S

where r
(s, a) ≡ r(s, a)(1 + ατ (s, a))/((α + w)τ (s, a)), λ̃ =
w/(w + α), and

1 − [1−q(s|s,a)]
, j=s
q̃(j|s, a) = q(j|s,a)τ (s,a)w
(15)
j 	= s.
τ (s,a)w ,
V. P ERFORMANCE A NALYSIS
In this section, we analyze the performance of the proposed SMDP-based interdomain resource allocation scheme.
An important performance metric is the dropping probability
of the cloud system. When a request is rejected, there is no
system income for the mobile cloud computing system, and
the mobile user will experience a low QoE. Basically, a service
request is dropped when both the home cloud domain and any
of the adjacent cloud domains cannot accommodate it. Thus,
the dropping probability of a new service request depends on
the available resources in both the home cloud domain and the
neighboring cloud domains. In the following, we will derive the
dropping probabilities of new services and interdomain transfer
services based on the proposed SMDP model.
Let πs1 ,s2 ,...,sC ,e (or denoted by πs,e ) be the steady-state
probability of state s = s1 , s2 , . . . , sC , e in the home cloud
service domain. According to different events, i.e., an arrival
of a new service request, an arrival of an interdomain transfer
service request, or a departure of a completed service with
c VMs, πs,e can be further divided into three items, i.e.,
πs,An  , πs,At  , and πs,Fc  . Based on the transition probabilities derived in (10)–(12), we can obtain πs,An  and πs,At  as
follows:
πs,An  =

λn
λn
ρs,An  πs,An  +
ρs,At  πs,At 
γ(s, a)
γ(s, a)
C
λn 
+
ρs,An  πs,An 
γ(s, a) c=1
λn 
ρs ,A  πs−1 ,At 
γ(s, a) c=1 −1 t
C

+

λn 
πs,Fc 
(16)
γ(s, a) c=1
λt
λt
ρs,An  πs,An  +
ρs,At  πs,At 
=
γ(s, a)
γ(s, a)
C
λt 
+
ρs ,A  πs−1 ,An 
γ(s, a) c=1 −1 n
C

+

πs,At 

λt 
ρs ,A  πs−1 ,At 
γ(s, a) c=1 −1 t
C

+

j∈S

where λ = γ(s, a)/(α + γ(s, a)).

2227

λt 
πs,Fc 
γ(s, a) c=1
C

+

(17)

2228

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 61, NO. 5, JUNE 2012

where s = s1 , s2 , . . . , sC , and s−1 = s1 , s2 , . . . , sc −
1, . . . , sC . ρs,An  , ρs,At  , ρs−1 ,An  , and ρs−1 ,At  are
parameters defined as

1, as,An  = 0, −2
ρs,An  =
0, otherwise

1, as,At  = 0, −2
ρs,At  =
0, otherwise

1, as−1 ,An  = c, c = {1, 2, . . . , C}
ρs−1 ,An  =
0, otherwise

1, as−1 ,At  = c, c = {1, 2, . . . , C}
ρs−1 ,At  =
0, otherwise.
Similarly, the steady-state probability πs,Fc  is given by
πs,Fc  =

(sc + 1)cµ
ρs+1 ,An  πs+1 ,An 
γ(s, a)
+

(sc + 1)cµ
ρs,An  πs,An 
γ(s, a)

+

(sc + 1)cµ
γ(s, a)

+

+

C


ρs±1 ,An  πs±1 ,An 

TABLE II
SIMULATION PARAMETERS

Since the sum of the steady-state probabilities for all states is
equal to 1, we have


πs,An  + πs,At  + πs,Fc  = 1.
(19)
S

By solving the equation sets of (16)–(19), we can obtain
the probability of each state in the steady state. The dropping
probability of a new service request, which is denoted by P n0 ,
is the ratio of the sum probability of the rejected new services
over the total probability of new service arrivals. Similarly,
the dropping probability of an interdomain transfer service
request, denoted by P t0 , is the ratio of the sum probability
of the rejected interdomain transfer services over the totally
probability of interdomain transfer requests. Thus, we have

πs,An 
P n0 =

m=1,m	=c

(sc + 1)cµ
ρs+1 ,At  πs+1 ,At 
γ(s, a)

as,An =0



C

m=−2,m	=−1



P t0 =

(sc + 1)cµ
ρs,At  πs,At 
γ(s, a)

C


C


ρs±1 ,At  πs±1 ,At 

(20)

.

(21)

πs,At 


as,At =m

πs,At 

VI. P ERFORMANCE E VALUATION

m=1,m	=c

C
(sc + 1)cµ 
+
πs ,F 
γ(s, a) m=1 +1 m




πs,An 

as,An =m

as,At =0

m=−2,m	=−1

(sc + 1)cµ
+
γ(s, a)



(18)

where s+1 = s1 , s2 , . . . sc + 1, . . . sC , and s±1 = s1 , s2 ,
. . . sc + 1, ..sm − 1, . . . sC . ρs+1 ,An  , ρs,An  , ρs±1 ,An  ,
ρs+1 ,At  , ρs,At  , and ρs±1 ,At  are defined as

1, as+1 ,An  = 0, −2
ρs+1 ,An  =
0, otherwise

1, as,An  = c, c = {1, 2, . . . , C}
ρs,An  =
0, otherwise

 1, as±1 ,An  = m, c = {1, 2, . . . , C}
ρs±1 ,An  =
m = {1, 2, . . . , C}, m 	= c

0, otherwise

1, as+1 ,At  = 0, -2
ρs+1 ,At  =
0, otherwise

1, as,At  = c, c = {1, 2, . . . , C}
ρs,At  =
0, otherwise

 1, as±1 ,At  = m, c = {1, 2, . . . , C}
ρs±1 ,At  =
m = {1, 2, . . . , C}, m 	= c

0, otherwise.

In this section, we evaluate the performance of the proposed
interdomain resource allocation model using an event-driven
simulator written in Matlab. In the simulation, the parameters
are selected as an example for performance illustration. To
further study the relationship between these parameters, we
vary some parameters, such as the service arrival and departure
rates for performance comparison. A mobile cloud service
domain contains up to K = 10 resource units (i.e., VMs or
cloud server clusters, and we use VMs in our simulation study),
and the maximum number of VMs allocated to a service request
is C = 3, i.e., a service can be assigned 1, 2, or 3 VMs
based on the dynamic computing environments in the cloud
domain. Each interdomain transfer request will be accepted
by an adjacent domain with a certain probability pt , which
varies from 0.5 to 0.9. The arrival rates of new and interdomain
transfer services are λn = 7.2 and λt = 2.4, respectively. The
departure rate of a service using one VM is µ1 = 6.6, and thus,
the departure rate of services using c VMs is µc (c ∈ {1, 2, 3}),
if not otherwise specified. The discount factor is set to α =
0.1 to assure the convergence of the reward computation. We
collect the simulation results of each experiment over 18 000 s
and repeat each experiment for 1000 runs with different random
seeds to calculate the average. The other parameters used in the
simulation are listed in Table II.

LIANG et al.: SMDP-BASED SERVICE MODEL FOR RESOURCE ALLOCATION IN MOBILE CLOUD NETWORKS

TABLE III
DECISION TABLE OF NEW SERVICE
(λn = 7.2, λt = 2.4, µ1 = 6.6, K = 10, s3 = 0, pt = 0.5)

TABLE IV
DECISION TABLE OF NEW SERVICE
(λn = 7.2, λt = 2.4, µ1 = 6.6, K = 10, s3 = 0, pt = 0.9)

Tables III and IV tabulate the optimal resource allocation
decisions or actions for new service requests under different
interdomain transfer acceptance probabilities pt . The numbers
in the table represent actions made on the state s1 , s2 , s3 .
For example, if there are no services in the system, when a
new service request arrives, an action a = 3 is made that three
VMs are allocated to the requesting service. If there are four
users, and each user has been allocated two VMs, implying
that there are only two VMs available, an action a = 1 is made
that only one VM is allocated to the new service request. When
the remaining computing resources are sufficient, action a = 3
is usually selected to achieve a higher utility gain over a = 2
or a = 1. On the other hand, when the available computing
resources are limited, a more conservative decision is selected.
When the available VMs in the home cloud domain cannot
accommodate the requested service, the home domain will send
a request to the adjacent cloud domains. A higher probability
of pt indicates that an adjacent domain has more available
computing resources, and it is more likely to accept the transfer
requests from the home cloud domain that has insufficient
resources. It is also observed that more transfer decisions are
made with a higher pt .
Tables V and VI tabulate the optimal resource allocation
decisions or actions for interdomain transfer requests under
different request arrival rates. A higher request rate implies
that more computing resources are demanded, and thus, a
more conservative decision is made. It is also observed that
no transfer decision is made for interdomain transfer requests

2229

TABLE V
DECISION TABLE OF INTERDOMAIN TRANSFER DERVICE
(λn = 1.2, λt = 2.4, µ1 = 6.6, K = 10, s3 = 0)

TABLE VI
DECISION TABLE OF INTERDOMAIN TRANSFER SERVICE
(λn = 60, λt = 2.4, µ1 = 6.6, K = 10, s3 = 0)

Fig. 4. Action probabilities of interdomain transfer service under various
arrival rates of new services (λt = 2.4, µ1 = 6.6, K = 10).

due to the charge of transfer by the home domain and the extra
communication costs involved in transfer services.
The action probabilities for interdomain transfer services
under different arrival rates are shown in Fig. 4. When the
new request arrival rate is low, it is more likely that a request
will be admitted and allocated with three VMs. When the
arrival rates increase, the resource allocation decision becomes

2230

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 61, NO. 5, JUNE 2012

Fig. 5. Action probabilities of interdomain transfer service under various total
computing resources (λn = 7.2, λt = 2.4, µ1 = 6.6).

Fig. 7. Dropping probability of interdomain transfer service under various
VMs (λn = 7.2, λt = 2.4, µ1 = 6.6).

Fig. 8. Dropping probability of new service under various arrival rates (λt =
2.4, µ1 = 6.6, K = 10).
Fig. 6. Dropping probability of interdomain transfer service of adjacent domain under various arrival rates of new service (λt = 2.4, µ1 = 6.6, K = 10).

conservative, and the probability of allocating two and one VMs
increases accordingly. The action probability under different
numbers of VMs is compared in Fig. 5. With more available
computing resources, i.e., VMs, in a cloud domain, the dropping probability keeps at a very low level. We also compare the
dropping probability of the proposed SMDP-based model with
the greedy algorithm in Figs. 6–8. In the greedy algorithm, the
cloud system always allocates the maximum number of VMs
to the requesting service when the system can afford to achieve
the highest system reward at the decision epoch. It can be seen
that the dropping probability increases with the arrival rate of
new services in general and decreases when the total number of
VMs in a cloud service domain increases. Our proposed SMDP-

based model achieves much lower dropping probability than the
greedy algorithm because our algorithm considers not only the
current system gain but the expected long-term system rewards
as well.
We further compare the expected system rewards of the
SMDP-based model and the greedy scheme. The expected
system reward of interdomain transfer services under different
service arrival rates is compared in Fig. 9. When the arrived
service requests exceed the system capacity, more requests
will be rejected, and as a result, the expected system rewards
decrease. By increasing the number of VMs in a cloud domain,
more requests can be admitted in the cloud, and thus, a high
system reward can be achieved, as shown in Fig. 10. The
reward of new services under different service rates is shown
in Fig. 11. When the new service rate is very low, almost all

LIANG et al.: SMDP-BASED SERVICE MODEL FOR RESOURCE ALLOCATION IN MOBILE CLOUD NETWORKS

2231

Fig. 11. Reward of new service under various arrival rates of new service
(λt = 2.4, µ1 = 6.6, K = 10).
Fig. 9. Reward of interdomain transfer service under various arrival rates of
new service (λt = 2.4, µ1 = 6.6, K = 10).

VII. C ONCLUSION AND F UTURE W ORK
In this paper, we have developed an SMDP-based computing
model for interdomain services in a cloud computing system
considering both the system gain, the expenses of computing
resources, and the communication costs. The optimal decision
is made such that the overall system rewards are maximized.
In our future work, we will analyze the optimal system
resources toward the maximal system rewards under a given
dropping probability constraint for a large-scale cloud system.
R EFERENCES

Fig. 10. Reward of interdomain transfer service under different number of
VMs (λn = 7.2, λt = 2.4, µ1 = 6.6).

services can be admitted, and the system rewards increase with
the rate. However, when the computing resource of a cloud
domain is used up, some requests are rejected that degrades the
system rewards. Thus, the system reward is a concave function
of the service rates. From all figures, it can be seen that our
proposed scheme significantly outperforms the greedy scheme.
The reason is that, for the greedy scheme, a larger number of
VMs are allocated when a service request arrives, and thus, it
takes the risk of rejecting the next service request when the
available VMs are not sufficient. The proposed SMDP-based
interdomain resource allocation model is relatively conservative
for decision making by considering both the instant lump sum
income and the system expenses.

[1] M. Armbrust, A. Fox, R. Griffith, A. Joseph, R. Katz, A. Konwinski, G. Lee,
D. Patterson, A. Rabkin, I. Stoica, and M. Zaharia, “Above the clouds:
A Berkeley View of cloud computing,” Dept. Elect. Eng. Comput. Sci.,
Univ. California, Berkeley, CA, Tech. Rep. UCB/EECS-2009-28, 2009.
[2] D. Huang, X. Zhang, M. Kang, and J. Luo, “Mobicloud: A secure mobile
cloud framework for pervasive mobile computing and communication,” in
Proc. 5th IEEE Int. Symp. Service-Oriented Syst. Eng., 2010, pp. 27–34.
[3] E. Cuervo, A. Balasubramanian, D.-K. Cho, A. Wolman, S. Saroiu,
R. Chandra, and P. Bahl, “MAUI: Making smartphones last longer with
code offload,” in Proc. ACM MobiSys, 2010, pp. 49–62.
[4] M. Satyanarayanan, P. Bahl, R. Caceres, and N. Davies, “The case for
VM-based cloudlets in mobile computing,” IEEE Pervasive Comput.,
vol. 8, no. 4, pp. 14–23, Oct.–Dec. 2009.
[5] B. Chun and P. Maniatis, “Augmented smartphone applications through
clone cloud execution,” in Proc. USENIX HotOS XII, 2009, p. 8.
[6] R. Jain, “Quality of experience,” IEEE Multimedia, vol. 11, no. 1, pp. 95–
96, Jan.–Mar. 2004.
[7] Secure Networking and Computing (SNACT) Research Group, Mobicloud. [Online]. Available: http://mobicloud.asu.edu/
[8] M. Puterman, Markov Decision Processes: Discrete Stochastic Dynamic
Programming. New York: Wiley, 2005.
[9] S. M. Ross, Introduction to Probability Models, 9th ed. New York:
Elsevier, 2007.
[10] C. E. L. Thomas, H. Cormen, R. L. Rivest, and C. Stein, Introduction to
Algorithms, 3rd ed. Cambridge, MA: MIT Press, 2009.
[11] X. H. Li, H. Zhang, and Y. F. Zhang, “Deploying mobile computation in
cloud service,” in Proc. 1st Int. Conf. CloudCom, 2009, pp. 301–311.
[12] X. Zhang, J. Schiffman, S. Gibbs, A. Kunjithapatham, and S. Jeong,
“Securing elastic applications on mobile devices for cloud computing,”
in Proc. ACM Workshop Cloud Comput. Security, 2009, pp. 127–134.
[13] J. Oberheide, K. Veeraraghavan, E. Cooke, J. Flinn, and F. Jahanian,
“Virtualized in-cloud security services for mobile devices,” in Proc. 1st
Workshop Virtualization Mobile Comput., 2008, pp. 31–35.
[14] S. Goyal and J. Carter, “A lightweight secure cyber foraging infrastructure
for resource-constrained devices,” in Proc. 6th IEEE Workshop Mobile
Comput. Syst. Appl. , 2004, pp. 186–195.

2232

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 61, NO. 5, JUNE 2012

[15] Q. Wang, C. Wang, J. Li, K. Ren, and W. Lou, “Enabling public verifiability and data dynamics for storage security in cloud computing,” in Proc.
ESORICS, Saint Malo, France, Sep 2009, pp. 355–370.
[16] C. Wang, K. Ren, W. Lou, and J. Li, “Towards publicly auditably secure data storage services,” IEEE Netw. Mag., vol. 24, no. 4, pp. 19–24,
Jul./Aug. 2010.
[17] L. X. Cai, L. Cai, X. Shen, and J. W. Mark, “Resource management and
QoS provisioning for IPTV over mmWave-based WPANs with directional
antenna,” ACM Mobile Netw. Appl., vol. 14, no. 2, pp. 210–219, Apr. 2009.
[18] H. T. Cheng and W. Zhuang, “Novel packet-level resource allocation with
effective QoS provisioning for wireless mesh networks,” IEEE Trans.
Wireless Commun., vol. 8, no. 2, pp. 694–700, Feb 2009.
[19] L. X. Cai, X. Shen, and J. W. Mark, “Efficient MAC protocol for ultrawideband networks,” IEEE Commun. Mag., vol. 47, no. 6, pp. 179–185,
Jun. 2009.
[20] G. Naddafzadeh-Shirazi, P.-Y. Kong, and C.-K. Tham, “Distributed reinforcement learning frameworks for cooperative retransmission in wireless
networks,” IEEE Trans. Veh. Technol., vol. 59, no. 8, pp. 4157–4162,
Oct. 2010.
[21] H.-P. Shiang and M. van der Schaar, “Online learning in autonomic multihop wireless networks for transmitting mission-critical applications,”
IEEE J. Sel. Areas Commun., vol. 28, no. 5, pp. 728–741, Jun. 2010.
[22] A. Alshamrani, L. Xie, and X. Shen, “Adaptive admission control and
channel allocation policy in cooperative ad hoc opportunistic spectrum
networks,” IEEE Trans. Veh. Technol., vol. 59, no. 4, pp. 1618–1629,
May 2010.
[23] C. Leong, W. Zhuang, Y. Cheng, and L. Wang, “Optimal resource allocation and adaptive call admission control for voice/data integrated
cellular networks,” IEEE Trans. Veh. Technol., vol. 55, no. 2, pp. 654–669,
Mar. 2006.
[24] X. Shen, W. Zhuang, H. Jiang, and J. Cai, “Medium access control in
ultrawideband wireless networks,” IEEE Trans. Veh. Technol., vol. 54,
no. 5, pp. 1663–1677, Sep. 2005. (Invited Paper).
[25] H. Liang, D. Huang, and D. Peng, “On economic mobile cloud computing
model,” in Proc. Int. Workshop Mobile Comput. Clouds (MobiCloud in
conjunction with MobiCASE), 2010, pp. 1–12.
[26] HP, Integrity Non-Stop Computing, 2011. [Online]. Available: http://
h20223.www2.hp.com/nonstopcomputing/cache/76385-0-0-0-121.html
[27] Citrix, Xen Server High Availability, 2011. [Online]. Available: http://
support . citrix . com / servlet / KbServlet / download / 21018-102-479340 /
HA-de ep-2.pdf
[28] VMWare Inc., Vmware High Availability, 2011. [Online]. Available:
http://www.vmware.com/products/high-availability/overview.html
[29] G. Wei, A. V. Vasilakos, Y. Zheng, and N. Xiong, “A game-theoretic
method of fair resource allocation for cloud computing services,” J. Supercomput., vol. 54, no. 2, pp. 252–269, 2009.
[30] S. O. H. Mine and M. L. Puterman, Markovian Decision Process.
Amsterdam, The Netherlands: Elsevier, 1970.
Hongbin Liang (S’09) received the B.Sc. degree in
communication engineering from Beijing University
of Post and Telecommunication, Beijing, China, in
1995 and the M.Sc. degree in electrical engineering
from Southwest Jiaotong University, Chengdu,
China, in 2001. He is currently working toward the
Ph.D. degree with Southwest Jiaotong University.
From 2001 to 2009, he was a Software Engineer
with the Motorola R&D Center of China, where he
focused on system requirement analysis and ThirdGeneration Partnership Project protocol analysis.
From 2009 to 2011, he was a visiting Ph.D. student with the Department of
Electrical and Computer Engineering, University of Waterloo, Waterloo, ON,
Canada. His current research interests focus on resource allocation, qualityof-service, security and efficiency in cloud computing, and wireless sensor
networks.
Lin X. Cai (S’09–M’11) received the M.A.Sc. and
Ph.D. degrees in electrical and computer engineering
from the University of Waterloo, ON, Canada, in
2005 and 2009, respectively
She is currently a Postdoctoral Research Fellow
with Princeton University, Princeton, NJ. Her research interests include green communication and
networking, resource management for broadband
multimedia networks, and cross-layer optimization
and quality-of-service provisioning.

Dijiang Huang (M’00–SM’11) received the B.S. degree from Beijing University of Posts and Telecommunications, Beijing, China, in 1995 and the M.S.
and Ph.D. degrees from the University of MissouriKansas City, in 2001 and 2004, respectively.
He is currently an Associate Professor with the
School of Computing Informatics and Decision System Engineering, Arizona State University, Tempe.
He is an Associate Editor of the Journal of Network
and System Management. His current research interests are computer networking, security, and privacy.
Dr. Huang is an Editor of the IEEE COMMUNICATIONS SURVEYS AND
TUTORIALS. He has served as an organizer for many international conferences
and workshops. His research is supported by the National Science Foundation,
the Office of Naval Research (ONR), the Air Force Research Laboratory, HP,
and the Consortium of Embedded System. He has received the ONR Young
Investigator Award and the HP Innovation Research Program Award.

Xuemin (Sherman) Shen (M’97–SM’02–F09) received the B.Sc. degree in electrical engineering
from Dalian Maritime University, Dalian, China, in
1982 and the M.Sc. and Ph.D. degrees in electrical
engineering from Rutgers University, Camden, NJ,
in 1987 and 1990, respectively.
He is a Professor and a University Research Chair
with the Department of Electrical and Computer
Engineering, University of Waterloo, Waterloo, ON,
Canada. He was the Associate Chair for Graduate
Studies from 2004 to 2008. He is a coauthor/editor
of six books and has published more than 600 papers and book chapters in
wireless communications and networks, control, and filtering. His research
focuses on resource management in interconnected wireless/wired networks,
wireless network security, wireless body area networks, vehicular ad hoc, and
sensor networks.
Dr. Shen is an Engineering Institute of Canada Fellow and a Distinguished
Lecturer of the IEEE Vehicular Technology Society and of the Communications
Society. He served as the Technical Program Committee Chair for the 2010
IEEE Vehicular Technology Conference (VTC’10) Fall, the Symposia Chair
for the 2010 IEEE International Communications Conference (ICC’10), the
Tutorial Chair for IEEE VTC’11 Spring and IEEE ICC’08, the Technical
Program Committee Chair for IEEE Globecom’07, the General Co-Chair for
Chinacom’07 and QShine’06, the Chair for IEEE Communications Society
Technical Committee on Wireless Communications, and Peer-to-Peer Communications and Networking. He also serves/served as the Editor-in-Chief for
IEEE NETWORK, Peer-to-Peer Networking and Application, and IET Communications; a Founding Area Editor for IEEE TRANSACTIONS ON WIRELESS
COMMUNICATIONS; an Associate Editor for IEEE TRANSACTIONS ON
VEHICULAR TECHNOLOGY, Computer Networks, ACM/Wireless Networks,
etc.; and the Guest Editor for the IEEE J OURNAL ON S ELECTED A R EAS ON C OMMUNICATIONS , IEEE W IRELESS C OMMUNICATIONS , IEEE
COMMUNICATIONS MAGAZINE, ACM Mobile Networks and Applications,
etc. He received the Excellent Graduate Supervision Award in 2006 and the
Outstanding Performance Award in 2004, 2007, and 2010 from the University
of Waterloo, the Premier’s Research Excellence Award in 2003 from the
Province of Ontario, Canada, and the Distinguished Performance Award in
2002 and 2007 from the Faculty of Engineering, University of Waterloo. He
is a Registered Professional Engineer in Ontario.

Daiyuan Peng (M’05) received the M.S. degree in
applied mathematics and the Ph.D. degree in mobile
communications from Southwest Jiaotong University, Chengdu, China, in 1987 and 2005, respectively.
He is currently a Professor with Southwest
Jiaotong University. His research interests include
sequence analysis and design, algebraic coding theory, cryptography, and information security.

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 11,

NO. 2,

MARCH/APRIL 2014

181

STARS: A Statistical Traffic Pattern
Discovery System for MANETs
Yang Qin, Dijiang Huang, Senior Member, IEEE, and Bing Li, Student Member, IEEE
Abstract—Many anonymity enhancing techniques have been proposed based on packet encryption to protect the communication
anonymity of mobile ad hoc networks (MANETs). However, in this paper, we show that MANETs are still vulnerable under passive
statistical traffic analysis attacks. To demonstrate how to discover the communication patterns without decrypting the captured
packets, we present a novel statistical traffic pattern discovery system (STARS). STARS works passively to perform traffic analysis
based on statistical characteristics of captured raw traffic. STARS is capable of discovering the sources, the destinations, and the
end-to-end communication relations. Empirical studies demonstrate that STARS achieves good accuracy in disclosing the hidden
traffic patterns.
Index Terms—Anonymous communication, mobile ad hoc networks, statistical traffic analysis

Ç
1

INTRODUCTION

M

ad hoc networks (MANETs) are originally
designed for military tactic environments. Communication anonymity is a critical issue in MANETs, which
generally consists of the following aspects: 1) Source/
destination anonymity—it is difficult to identify the sources
or the destinations of the network flows. 2) End-to-end
relationship anonymity—it is difficult to identify the endto-end communication relations. To achieve anonymous
MANET communications, many anonymous routing protocols such as ANODR [1], MASK [2], and OLAR [3] (see
more in [4], [5], [6], [7], and [8]) have been proposed.
Though a variety of anonymity enhancing techniques like
onion routing [9] and mix-net [10] are utilized, these
protocols mostly rely on packet encryption to hide sensitive
information (e.g., nodes’ identities and routing information)
from the adversaries. However, passive signal detectors can
still eavesdrop on the wireless channels, intercept the
transmissions, and then perform traffic analysis attacks.
Over the past few decades, traffic analysis models have
been widely investigated for static wired networks (e.g., [9],
[10], [11], [12], [13]). For example, the simplest approach to
track a message is to enumerate all possible links a message
could traverse, namely, the brute force approach [11].
Recently, statistical traffic analysis attacks have attracted
broad interests due to their passive nature, i.e., attackers only
need to collect information and perform analysis quietly
without changing the network behavior (such as injecting or
modifying packets). The predecessor attacks [14], [15], [16]
and disclosure attacks [17], [18], [19], [20] are two representatives. However, all these previous approaches do not work
OBILE

. Y. Qin is with Facebook, 1601 Willow Road, Menlo Park, CA 94025.
E-mail: yangqin@fb.com.
. D. Huang and B. Li are with the School of Computing, Informatics,
and Decision Systems Engineering, Arizona State University, Tempe,
AZ 85287. E-mail: {Dijiang.Huang, Bing.Li.4}@asu.edu.
Manuscript received 14 May 2012; revised 20 Jan. 2013; accepted 4 Aug.
2013; published online 15 Aug. 2013.
For information on obtaining reprints of this article, please send e-mail to:
tdsc@computer.org, and reference IEEECS Log Number TDSC-2012-05-0089.
Digital Object Identifier no. 10.1109/TDSC.2013.33.
1545-5971/14/$31.00 ß 2014 IEEE

well to analyze MANET traffic because of the following three
natures of MANETs: 1) The broadcasting nature: In wired
networks, a point-to-point message transmission usually has
only one possible receiver. While in wireless networks, a
message is broadcasted, which can have multiple possible
receivers and so incurs additional uncertainty. 2) The ad hoc
nature: MANETs lack network infrastructure, and each
mobile node can serve as both a host and a router. Thus, it
is difficult to determine the role of a mobile node to be a
source, a destination, or just a relay. 3) The mobile nature: Most
of existing traffic analysis models do not take into consideration the mobility of communication peers, which make
the communication relations among mobile nodes more
complex.
In [21], Huang devised an evidence-based statistical
traffic analysis model specially for MANETs. In this model,
every captured packet is treated as an evidence supporting
a point-to-point (one-hop) transmission between the sender
and the receiver. A sequence of point-to-point traffic
matrices is created, and then they are used to derive endto-end (multihop) relations. This approach provides a
practical attacking framework against MANETs but still
leaves substantial information about the communication
patterns undiscovered. First, the scheme fails to address
several important constrains (e.g., maximum hop-count of a
packet) when deriving the end-to-end traffic from the onehop evidences. Second, it does not provide a method to
identify the actual source and destination nodes (or to
calculate the source/destination probability distribution).
Moreover, it only uses a naı̈ve accumulative traffic ratio to
infer the end-to-end communication relations (e.g., the
probability for node j to be the intended destination of
node i is computed as the ratio of the traffic from i to j to all
traffic coming out from node i), which incurs a lot of
inaccuracy in the derived probability distributions.
Reusing the evidence-based model, in this paper, we
propose a novel statistical traffic pattern discovery system
(STARS). STARS aims to derive the source/destination
probability distribution, i.e., the probability for each node to
be a message source/destination, and the end-to-end link
probability distribution, i.e., the probability for each pair of
Published by the IEEE Computer Society

182

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

nodes to be an end-to-end communication pair. To achieve
its goals, STARS includes two major steps: 1) Construct
point-to-point traffic matrices using the time-slicing technique, and then derive the end-to-end traffic matrix with a
set of traffic filtering rules; and 2) Apply a heuristic
approach to identify the actual source and destination
nodes, and then correlate the source nodes with their
corresponding destinations.
The contribution of STARS is twofold: 1) To the best of
our knowledge, STARS is the first statistical traffic analysis
approach that considers the salient characteristics of
MANETs: the broadcasting, ad hoc, and mobile nature;
and 2) most of the previous approaches are partial attacks in
the sense that they either only try to identify the source (or
destination) nodes or to find out the corresponding
destination (source) nodes for given particular source
(destination) nodes. STARS is a complete attacking system
that first identifies all source and destination nodes and
then determines their relationship.
The remainder of the paper is organized as follows:
Section 2 describes the related work. Section 3 presents the
fundamental system models and assumptions. In Section 4,
STARS is described in detail. Section 5 presents the
simulations’ setup, results, and analysis. In Section 6, we
further discuss how to take advantage of STARS with
limited attacking ability. Finally, we conclude our work and
indicate future research in Section 7.

2

RELATED WORK

Traffic analysis attacks against the static wired networks
(e.g., Internet) have been well investigated. The brute force
attack proposed in [11] tries to track a message by
enumerating all possible links a message could traverse. In
node flushing attacks (a.k.a blending attacks, n  1 attacks)
[10], the attacker sends a large quantity of messages to the
targeted anonymous system (which is called a mix-net).
Since most of the messages modified and reordered by the
system are generated by the attacker, the attacker can track
the rest a few (normal) messages. The timing attacks as
proposed in [9] focus on the delay on each communication
path. If the attacker can monitor the latency of each path, he
can correlate the messages coming in and out of the system
by analyzing their transmission latencies. The message
tagging attacks (e.g., [12]) require attackers to occupy at
least one node that works as a router in the communication
path so that they can tag some of the forwarded messages
for traffic analysis. By recognizing the tags in latter
transmission hops, attackers can track the traffic flow. The
watermarking attacks are actually variants of the message
tagging attacks. They reveal the end-to-end communication
relations by purposely introducing latency to selected
packets.
Different from the attacks mentioned above, statistical
traffic analysis intends to discover sensitive information from
the statistical characteristics of the network traffic, for
example, the traffic volume. The adversaries usually do not
change the network behavior (such as injecting or modifying
packets). The only thing they do is to quietly collect traffic
information and perform statistical calculations. The predecessor attacks are first pointed out by Reiter and Rubin [14].

VOL. 11,

NO. 2,

MARCH/APRIL 2014

Later works such as [15] and [16] extend them to all kinds of
anonymous communication systems including onion-routing [9], mix-net [10], and DC-net [22]. In a typical predecessor
attack, the attackers act exactly as legitimate nodes in the
network communications. They collectively maintain a
single predecessor counter for each legitimate node in the
system. When an attacker finds himself to be on an
anonymous path to the targeted destination, he increments
the shared counter for its predecessor node in this path. The
counters are then used for the attackers to infer the possible
source nodes of the given destination. Obviously, to launch
such an attack, a large number of legitimate nodes must first
be compromised and controlled by the attackers. This is
usually not achievable in MANETs. Moreover, in a MANET
protected by anonymity enhancing techniques, it is a difficult
task itself to identify an actual destination node as the target
due to the ad hoc nature. That is, destinations are indistinguishable from other nodes (e.g., relays) in a MANET. In
fact, they usually act as relay nodes as well, forwarding traffic
for others. The adversaries are not able to determine whether
a particular node is a destination depending on whether the
node sends out traffic. This is totally different from the
situation in traditional infrastructural networks where the
role of every node is determined. The statistical disclosure
attacks as mentioned in [17], [18], [19], and [20] are similar. A
statistical disclosure attack often targets a particular given
source node and intends to expose its corresponding
destinations. It is assumed that the packets initiated by the
source are sent to several destinations with certain probability distribution. The background (covering) traffic also
has certain probability distribution (usually assumed to be
uniformly distributed). After a large number of observations,
the attackers are able to figure out the possible destinations of
the given source. Nonetheless, the statistical disclosure
attacks cannot be applied to MANETs either, because the
attackers cannot easily identify the actual source nodes in
MANETs. Even if a source node is identified, the attacks can
only be performed when the attackers know for sure when
the targeted source is originating traffic and can observe the
network behavior in the absence of the source. However, the
attackers are prevented from being able to do so by the ad hoc
nature of MANETs, i.e., they cannot tell if the source is
originating traffic or just forwarding traffic as a relay.
Due to the unique characteristics of MANETs, very
limited investigation has been conducted on traffic analysis
in the context of MANETs. He et al. proposed a timing-based
approach in [23] to trace down the potential destinations
given a known source. In this approach, assuming the
transmission delays are bounded at each relay node, they
estimate the flow rates of communication paths using packet
matching. Then based on the estimated flow rates, a set of
nodes that partition the network into two parts, one part to
which the source can communicate in sufficient rate and the
other to which it cannot, are identified to estimate the
potential destinations. In [24], Liu et al. designed a traffic
inference algorithm (TIA) for MANETs based on the
assumption that the difference between data frames, routing
frames, and MAC control frames is visible to the passive
adversaries, so that they can recognize the point-to-point
traffic using the MAC control frames, identify the end-toend flows by tracing the routing frames, and then infer the
actual traffic pattern using the data frames. The TIA achieves

QIN ET AL.: STARS: A STATISTICAL TRAFFIC PATTERN DISCOVERY SYSTEM FOR MANETS

183

good accuracy in traffic inference, while the mechanism is
tightly tied to particular anonymous routing protocols but
not a general approach. Both [23] and [24] are analytical
strategies which heavily rely on the deterministic network
behaviors.

3

SYSTEM MODELS

In this section, we present the fundamental system models
adopted (assumed) by STARS.

3.1 Communication Model
We assume the anonymity enhancing techniques (such as
[1], [2], [3]) are used to protect the MANETs. However,
these techniques are designed to different levels of
anonymity. To focus on the statistical traffic analysis, we
assume, based on [21], that a combination of these
techniques is applied and the targeted MANET communication system is subject to the following model:
1.

2.

3.

4.
5.

The PHY/MAC layer is controlled by the commonly
used 802.11(a/b/g) protocol. But all MAC frames
(packets) are encrypted so that the adversaries
cannot decrypt them to look into the contents.
Padding is applied so that all MAC frames (packets)
have the same size. Nobody can trace a packet
according to its unique size.
The “virtual carrier sensing” option is disabled. The
source/destination addresses in MAC and IP headers are set to a broadcasting address (i.e., all “1”) or
to use identifier changing techniques. In this case,
adversaries are prevented from identifying point-topoint communication relations.
No information about the traffic patterns is disclosed
from the routing layer and above.
Dummy traffic and dummy delay are not used due
to the highly restricted resources in MANETs.

3.2 Attack Model
The attackers’ goal is to discover the traffic patterns among
mobile nodes. Particularly, we have the following four
assumptions for attackers:
1.

2.

3.

The adversaries are passive signal detectors, i.e.,
they are not actively involved in the communications. They can monitor every single packet transmitted through the network.
The adversary nodes are connected through an
additional channel which is different from the one
used by the target MANET. Therefore, the communication between adversaries will not influence the
MANET communication.
The adversaries can locate the signal source according to certain properties (e.g., transmission power
and direction) of the detected signal, by using
wireless location tracking techniques [25] such as
triangulation, nearest sensor, or RF fingerprinting.
Note that none of these techniques can identify the
source of a signal from several nodes very close to
each other. Hence, this assumption actually indicates
that the targeted networks are sparse in terms of the
node density. In other words, any two nodes in such

Fig. 1. A simple wireless ad hoc network.

4.

4

a network are distant from each other so that the
location tracking techniques in use are able to
uniquely identify the source of a wireless signal. In
the following of this paper, unless specifically denoted as
“signal source” or “source of signal,” the word “source”
indicates the source of a network flow.
The adversaries can trace the movement of each
mobile node, by using cameras or other types of
sensors. In this case, the signals (packets) transmitted by a node can always be associated with it
even when the node moves from one spot to another.

STATISTICAL TRAFFIC PATTERN DISCOVERY
SYSTEM

To disclose the hidden traffic patterns in a MANET
communication system, STARS includes two major steps.
First, it uses the captured traffic to construct a sequence of
point-to-point traffic matrices and then derives the end-toend traffic matrix. Second, further analyzing the end-toend traffic matrix, it calculates the probability for each
node to be a source/destination (the source/destination
probability distribution) and that for each pair of node to
be an end-to-end communication link (the end-to-end link
probability distribution).
To illustrate the basic idea of STARS, we use a simple
scenario shown in Fig. 1 as an example. In this network,
there are three wireless nodes (1, 2, and 3). Node 2 is
located in the transmission range of node 1, and node 3 is
located in the transmission range of node 2 (but not the
transmission range of node 1). Two consecutive packets are
detected: node 1 broadcasts a packet and then node 2
broadcasts a packet.

4.1 Traffic Matrices Construction
4.1.1 Point-to-Point Traffic Matrix
With the captured point-to-point (one-hop) traffic in a
certain period T , we first need to build point-to-point traffic
matrices such that each traffic matrix only contains
“independent” one-hop packets. Note that two packets
captured at different time could be the same packet
appearing at different locations, such as the two packets
sent by node 1 and node 2 consecutively in Fig. 1, so they
are “dependent” on each other. To avoid a single point-topoint traffic matrix from containing two dependent packets,
we apply a “time slicing” technique as shown in Fig. 2. That
is, we take snapshots of the network, and each snapshot is
triggered by a captured packet. A sequence of snapshots
during a time interval te constructs a slice represented by

184

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

Fig. 2. Slicing the time domain.

a traffic matrix We , which is an N  N one-hop traffic
relation matrix. The length of each time interval te is
determined by two criteria: 1) A node can be either a sender
or a receiver within this time interval. But it cannot be both.
2) Each traffic matrix must correctly represent the one-hop
transmissions during the corresponding time interval.
In this way, the construction of matrices Wj1e ¼
ðW1 ; W2 ; . . . ; WK Þ will automatically involve mobility in
the traffic matrices constructions. For example, traffic
matrix We ¼ ðwe ði; jÞÞNN is created for direct transmissions between nodes during time interval te . Since each
snapshot of the network is triggered by capturing a packet,
as long as potential receiver j is located within sender i’s
communication range (i.e., di;j  r), a small change of
distance di;j due to mobility will not alter the value assigned
to we ði; jÞ. If j moves out of the communication range of i
due to mobility, the value of we ði; jÞ ¼ 0. In this way, we
slice the period T into a sequence of time intervals
t1 ; t2 ; . . . ; tK , and record the captured packets into
their corresponding traffic matrices Wj1K ¼ ðW1 ; W2 ; . . . ;
WK Þ. In each traffic matrix We ¼ ðwe ði; jÞÞNN (N is the size
of the network, e ¼ 1; 2; . . . ; K), the entry we ði; jÞ is the
point-to-point traffic volume (number of packets) captured
from node i to node j during the time interval te (we define
we ði; iÞ to be 0). In addition, we use we ði; jÞ:pkt to denote the
set of all packets contributing to we ði; jÞ. The “time slicing”
has to make sure that all packets captured in any of the time
intervals are independent with each other. In other words,
two packets residing in different entries of the same matrix
must not be the same packet transmitted through multiple
hops. Note that, using the “time slicing” techniques, we also
effectively handle the nodal mobility by taking snapshots of
a sequence of relatively fixed network topologies.
In addition to the “time slicing,” we need to follow the
three rules listed below: 1) The number of captured packets
rather than the actual size of payloads is considered as the
“traffic volume,” since the size of payloads does not affect
the traffic pattern (and we assumed all MAC frames are of
the same length due to the application of padding). 2) All
nodes within the transmitting range of a packet have the
same probability to be the actual receiver. For example, if a
node i broadcasts a packet in the time interval te , and
nodes j1 ; j2 ; . . . jn are all within i’s transmitting range, then
the entries we ði; j1 Þ, we ði; j2 Þ . . . we ði; jn Þ should be all
equally increased by 1=n. This is equivalent to dividing a
packet into n subpackets and each sent to one neighboring
node. For simplicity, in the remainder of the paper, we
denote the original packet as “virtual size” 1 and each of the
subpackets as “virtual size” 1=n. 3) Each packet p in
we ði; jÞ:pkt, has three associated features: p:vsize, p:time,
and p:hop, denoting the “virtual size,” transmitting time,

VOL. 11,

NO. 2,

MARCH/APRIL 2014

and hop count of this packet, respectively. A packet’s hop
count is set to 1 when added to the point-to-point traffic
matrix.
That said, for the example given in Fig. 1, we could
derive:
2
3
2
3
0 1 0
0 0 0
W1 ¼ 4 0 0 0 5; W2 ¼ 4 0:5 0 0:5 5:
0 0 0
0 0 0
Note that in W2 , a real packet sent by node 2 is divided
into two subpackets of virtual size 0.5, which means nodes 1
and 3 are equally likely to be the actual receiver.

4.1.2 End-to-End Traffic Matrix
Given a sequence of point-to-point traffic matrices Wj1K ,
our goal is to derive the end-to-end traffic matrix R ¼
ðrði; jÞÞNN , where rði; jÞ is the accumulative traffic volume
from node i to node j, including both the point-to-point
traffic captured directly and multihop traffic deduced from
the point-to-point traffic. In this paper, we use the term
accumulative traffic matrix and end-to-end traffic matrix
interchangeably. The following Algorithm 1 (function f)
takes Wj1K as the inputs to derive the accumulative traffic
matrix R.
Algorithm 1. —fðWj1K Þ.
1: R ¼ W1
2: for e ¼ 1 to K  1 do
3:
R ¼ gðR; Weþ1 Þ þ Weþ1
4: end for
5: return R
In this algorithm, each update to R (line 3) includes the
multihop traffic derivation function g shown as in
Algorithm 2, and the addition of the point-to-point traffic
matrix which is the evidence of possible direct (singlehop) communication.
Algorithm 2. —gðR; Weþ1 Þ.
1: R0 ¼ R
2: for i ¼ 1 to N do
3:
for k ¼ 1 to N and k 6¼ i do
4:
for j ¼ 1 to N do
5:
for each x 2 weþ1 ðj; kÞ:pkt do
6:
if 9 y 2 rði; jÞ:pkt s.t. x:time  y:time < T
and y:hop < H then
7:
create z with z:time ¼ x:time
z:hop ¼ y:hop þ 1
z:vsize ¼ minfx:vsize; y:vsizeg
8:
r0 ði; kÞ:pkt ¼ r0 ði; kÞ:pkt [ fzg
9:
r0 ði; kÞ ¼ r0 ði; kÞ þ z:vsize
10:
end if
11:
end for
12:
end for
13: end for
14: end for
15: return R0
Function g takes two inputs: 1) R is an end-to-end traffic
matrix derived from point-to-point matrices W1 to We , and
2) Weþ1 is the next point-to-point traffic matrix. The output
is the end-to-end traffic matrix derived from W1 to Weþ1 .

QIN ET AL.: STARS: A STATISTICAL TRAFFIC PATTERN DISCOVERY SYSTEM FOR MANETS

For each packet x recorded in Weþ1 , the function tries to
find a packet y in R that is potentially the same packet
transmitted at x’s previous hop. If such a packet y exists,
then a multihop flow (packet) from the source of y to the
destination of x should be derived. For instance, in our
example scenario, we first let R ¼ W1 . Then gðR; W2 Þ
should derive all possible end-to-end flows. W2 contains
two packets, sent from node 2 to nodes 1 and 3,
respectively. Let p2;1 and p2;3 denote these two packets.
The current R contains only one packet p1;2 sent from
node 1 to node 2. Thus, it is possible that p1;2 and p2;3 are the
same packet appearing at different hops. In this case, a new
packet p1;3 is derived to represent a multihop flow from
node 1 to node 3. Since the volume of a multihop flow
consisting of a sequence of one-hop transmissions cannot
exceed the volume of any of the transmissions, we have
p1;3 :vsize ¼ minfp1;2 :vsize; p2;3 :vsizeg ¼ 0:5. Two constraints
are considered for reasonable traffic inference: The difference between the transmitting time of a packet at two
consecutive hops cannot be too large and the hop-count of a
packet cannot exceed a maximum value . We use T and H
to represent the timing threshold and maximal hop-count
threshold, respectively. If the network diameter is d, the
average transmission distance of a mobile node is r, we can
derive the approximated maximal hop-count threshold as:
H ¼ dd=re. The timing threshold T must be at least the
value of the maximum retransmission time. It depends on
the specification of the MAC protocol. For instance, if the
802.11 protocol is being used, T is determined by the
maximum number of retransmissions, the contention
window size, and the exponential back-off algorithm.
After executing function fðW j1K Þ, we can derive
the
P
accumulative traffic matrix R for the time period K
t
k,
k¼1
in which the ith row is the vector of the outgoing traffic
from node i and the jth column is the vector of the traffic
destining to node j.
Applying Algorithm 1, we derive the following matrix R
for our presented example. For simplicity, we assume the
timing and hop-count thresholds do not filter any packet out.
2
3
0 1 0:5
R ¼ 4 0:5 0 0:5 5:
0 0 0

185

dðiÞ (i ¼ 1 to N) represent the probability for node i to be
an actual source and destination, respectively. Note that if
the
PN total number of source nodes is m, then we should have
i¼1 sðiÞ ¼ m for S. However, since we only care about the
relative order among all possibilities (to know which nodes
are more possible to be the actual sources) but not the total
number m, we can always assume m ¼ 1. It is the same case
for D and all the probability vectors we will calculate later
in this paper. That is, all probability distribution vectors in this
paper are normalized1 and only the relative orders among the
elements of each vector actually make sense.
To derive S and D, we compute two series of vectors which
converge to S and D, respectively: the source probability
distribution vector series S ¼ ðS0 ; S1 ; . . . ; Sn ; . . .Þ, and the
destination probability distribution vector series D ¼ ðD0 ;
D1 ; . . . ; Dn ; . . .Þ.
First, both S0 and D0 should be uniform probability
distribution vectors: S0 ¼ D0 ¼ ð1=N; 1=N; . . . ; 1=NÞ, since
without any traffic information, all nodes are equally likely
to be sources and destinations.2
Second, we note that the ith row (rði; 1Þ . . . rði; NÞ) in the
matrix R is a vector of the traffic from node i to every node
in the MANET. If we multiply this vector by D0 (inner
product), we get
s0 ðiÞ ¼

N
X

rði; jÞ  d0 ðjÞ;

ð1Þ

j¼1

which is the probability for node i to be a source based on
the destination probability distribution D0 . This is intuitive,
since if a node sends a lot of packets to another node with
high probability of being a destination, the node itself has a
high probability of being a source. According to this, the
normalized inner product of R and D0 is a vector of
probabilities for nodes to be source nodes. Similarly, using
S0 to denote the vector ðs0 ð1Þ; s0 ð2Þ; . . . ; s0 ðNÞÞ resulted from
(1) and multiplying the ith row in the transpose of R (i.e.,
RT ) by S0 , we will get
d1 ðiÞ ¼

N
X

rðj; iÞ  s0 ðjÞ;

ð2Þ

j¼1

4.2 Traffic Pattern Discovery
The traffic matrix R tells us the deduced end-to-end traffic
volume between each pair of nodes. However, we still need
to perform further investigation to discover the actual
source/destination probability distribution and end-to-end link
probability distribution, that is, to figure out who are the
actual sources and destinations and who are communicating with whom.

which is the probability for node i to be a destination
derived from S0 and in turn based on D0 . This claim is
based on the fact that if a node receives a lot of packets from
a node with high probability of being a source, the node
itself has a high probability of being a destination.
Consequently, the normalized inner product of RT and S0
generates D1 as a new probability vector for nodes to be
destinations. Through this procedure, D1 is closer to the
actual destination probability distribution than D0 .
For the example scenario given in Fig. 1, we initialize
D0 to be ð1=3; 1=3; 1=3ÞT , without any prior knowledge
about the actual destinations. Then we compute S0 ¼ R 
D0 ¼ð1=2; 1=3; 0ÞT , which can be normalized to S0 ¼
ð3=5;2=5; 0ÞT . S0 indicates that node 1 is most likely to

4.2.1 Source/Destination Probability Distribution
We denote the actual source and destination probability
distribution, respectively, as two vectors S ¼ ðsð1Þ; sð2Þ; . . . ;
sðNÞÞ and D ¼ ðdð1Þ; dð2Þ; . . . ; dðNÞÞ, where sðiÞ and

1. In this paper, “normalizing” a vector means dividing each element of
the vector by the summation of all the elements, which makes the
summation of all the elements of the “normalized” vector equal to 1.
2. If there is prior knowledge available about the sources and
destinations, S0 and D0 should be set to reflect the prior knowledge.

It can be seen that, R contains not only all the one-hop
packets captured by W1 and W2 , but also a derived twohop flow of size 0.5 from node 1 to node 3.

186

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 11,

NO. 2,

MARCH/APRIL 2014

be an actual source, while node 3 is definitely not a
source. Next, we multiply RT by S0 and get the normalized D1 as: ð0:15; 0:46; 0:39ÞT , which should be closer to
the actual destination probability distribution than D0 .
According to the analysis above, we derive the following
iterative algorithm for D:

(5) and (6), we improve (3) and (4) with the following two
iterations, respectively:

Dnþ1 ¼ ðRT  RÞ  Dn ;

By introducing the vector space similarity assessment,
we ensure that, two nodes with higher probability to be
neighbors (relays of each other) have less impact on each
other’s source/destination probability distribution, which
reasonably reduces the neighborhood noise. Finally, we
propose the following Algorithms 3 and 4 to compute S
and D.

ð3Þ

and similarly that for S:
Snþ1 ¼ ðR  RT Þ  Sn :

ð4Þ

We also notice that geographically adjacent nodes may
have negative impacts on the accuracy of the algorithms
above. For example, if node j is one of the neighbors of
node i, j may frequently forward the packets originated
from node i to other nodes in the network and also
frequently forward the packets from other nodes to node i.
In this case, the high probability for node j to be a source
does not indicate the high probability for node i to be a
destination, though the traffic volume from j to i is large.
On the other hand, the high probability for node j to be a
destination and the large traffic volume from i to j do not
indicate the high probability for node i to be a source. We
call this kind of negative impacts as the “neighborhood
noise.” Especially, when the mobility is low, the negative
impacts will be substantial since the neighborhood of a
node rarely changes.
To reduce the neighborhood noise, we utilize the
vector space similarity assessment. The vector space
similarity (or cosine similarity) of two vectors V and U
is defined as follows:
SimðV; UÞ ¼ V  U=ðjVkUjÞ;
where V  U denotes the dot product of V, and U, jVj, and
jUj denote the norm of V and U. We realize that, if two
nodes have similar outgoing and incoming traffic vectors
(in the end-to-end traffic matrix R), they are likely to be
neighboring nodes (relays of each other), and so they
should have less impact on the source/destination probability distribution of each other. Thus, we rewrite (1) and
(2) by the following two formulas:
s0 ðiÞ ¼

N
X

rði; jÞ  d0 ðjÞ  cði; jÞ;

ð5Þ

Dnþ1 ¼ ðT ðRÞ  ðRÞÞ  Dn ;

ð7Þ

Snþ1 ¼ ððRÞ  T ðRÞÞ  Sn :

ð8Þ

Algorithm 3. —SrcðRÞ.
1: S0 ¼ ð1=N; 1=N; . . . ; 1=NÞ
2: n ¼ 0
3: do
4: Snþ1 ¼ ððRÞ  T ðRÞÞ  Sn
5: normalize Snþ1
6: n ¼ n þ 1
7: while Sn 6¼ Sn1
8: S ¼ Sn
9: return S
Algorithm 4. —DestðRÞ.
1: D0 ¼ ð1=N; 1=N; . . . ; 1=NÞ
2: n ¼ 0
3: do
4: Dnþ1 ¼ ðT ðRÞ  ðRÞÞ  Dn
5: normalize Dnþ1
6: n ¼ n þ 1
7: while Dn 6¼ Dn1
8: D ¼ Dn
9: return D
The iterations will converge to S and D, which are
the actual source and destination probability distribution
vectors.
Based on the proposed algorithms, we can derive the two
final vectors for the example scenario as given below. Here,
we ignore the neighborhood noise reduction for simplicity:
S ¼ ð0:77; 0:23; 0ÞT ;

j¼1

D ¼ ð0:08; 0:55; 0:37ÞT :
d1 ðiÞ ¼

N
X

rðj; iÞ  s0 ðjÞ  cðj; iÞ;

ð6Þ

j¼1

where
cði; jÞ ¼ cðj; iÞ ¼ 1 

SimðOðiÞ; OðjÞÞ þ SimðIðiÞ; IðjÞÞ
;
2

where OðiÞ and OðjÞ denote the ith row and jth row in R
(i.e., the outgoing traffic from i and j), while IðiÞ and IðjÞ
denote the ith and jth column in R (i.e., the incoming traffic
to i and j).
Define a function  such that ðRÞ ¼ ðði; jÞÞNN , where
ði; jÞ ¼ rði; jÞ  cði; jÞ. Obviously, we have ðRT Þ ¼ T ðRÞ,
in which T ðRÞ denotes the transpose of ðRÞ. According to

4.2.2 End-to-End Link Probability Distribution
Our goal in this section is to derive a probability
distribution matrix P ¼ ðpði; jÞÞNN , in which each entry
pði; jÞ represents the probability of the i ! j linkability (i.e.,
node i and node j are a pair of actual source and
destination). Again, note that only the relative order among
these entries is of interest, since we aim at discovering the
most possible communication links.
As described above, the probability for node i to be a
destination depends on two factors: the traffic from each
node j to node i and node j’s probability to be a source.
Suppose j  i is an actual source-destination pair. If we set
the total traffic coming out from j to zero, the probability

QIN ET AL.: STARS: A STATISTICAL TRAFFIC PATTERN DISCOVERY SYSTEM FOR MANETS

for i to be a destination will decrease. Similarly, if we set
the incoming traffic to node i to zero, the probability for
node j to be a source will also decrease. Thus, we can
identify a source-destination (S-D) pair by evaluating the
significance of the probability reduction due to the
elimination of the traffic sent by the source or received
by the destination. For instance, in the example scenario
shown in Fig. 1, to identify the most possible destination of
node 1, we can erase all traffic sent by node 1 from the
point-to-point traffic matrices, base on which we compute
the destination probability distribution D . By comparing
D with D (obtained using the original point-to-point
matrices), we can find out the node whose destination
probability drops most significantly due to elimination of
the traffic sent by node 1. This node is most possible to be
the destination of node 1.
That said, we propose Algorithms 5 and 6 to discover the
S-D linkability. The two algorithms are quite similar, so we
only explain Algorithm 5 here. First, we apply Algorithm 1
(function f) to the original point-to-point traffic matrices
and derive the original end-to-end traffic matrix R (line 1).
Then we apply Algorithm 4 (function Dest) to R and obtain
the original destination probability distribution vector D
(line 2). Then, the point-to-point matrices are modified by
eliminating the traffic sent by node i (line 3), and the
destination probability distribution vector D (lines 4 and 5)
is recomputed. Subtracting D from D results in a vector
L0sd ðiÞ, which indicates the level of each node to be affected
by the traffic elimination (line 6). Then the normalized
vector Lsd ðiÞ is a vector of probability for each node to be
the intended destination of i (line 7). The function SuppressSender(i) in Algorithm 5 is used to remove the traffic sent by
node i. Accordingly, Suppress-Receiver(j) used in Algorithm 6 is used to remove the traffic received by node j.
They work as follows:
Suppress-Sender(i)
W0 j1K ¼ Wj1K
for p ¼ 1 to K
for q ¼ 1 to N
w0p ði; qÞ ¼ 0
return W0 j1K

Suppress-Receiver(j)
W0 j1K ¼ Wj1K
for p ¼ 1 to K
for q ¼ 1 to N
w0p ðq; jÞ ¼ 0
return W0 j1K

Algorithm 5. Given a source node i, compute the
probability distribution vector Lsd ðiÞ for each node
to be the intended destination of i.
1: R ¼ fðW j1K Þ;
2: D ¼ DestðRÞ;
3: W0 j1K ¼ Suppress-Sender(i);
4: R0 ¼ fðW0 j1K Þ;
5: D ¼ DestðR0 Þ;
6: Calculate the probability reduction vector as:
L0sd ðiÞ ¼ D  D . If negative elements exist in L0sd ðiÞ,
increase each element by the absolute value of the
smallest negative element;
7: Normalize L0sd ðiÞ to generate the probability vector
Lsd ðiÞ for each node to be the intended destination of i;
8: Return Lsd ðiÞ.

187

Algorithm 6. Given a destination node j, compute the
probability distribution vector Lds ðjÞ for each node to
be the corresponding source of j.
1: R ¼ fðW j1K Þ;
2: S ¼ SrcðRÞ;
3: W0 j1K ¼ Suppress  ReceiverðjÞ;
4: R0 ¼ fðW0 j1K Þ;
5: S ¼ SrcðR0 Þ;
6: Calculate the probability reduction vector as:
L0ds ðjÞ ¼ S  S . If negative elements exist in L0ds ðjÞ,
increase each element by the absolute value of the
smallest negative element;
7: Normalize L0ds ðjÞ to generate the probability vector
Lds ðjÞ for each node to be the corresponding source
of j;
8: Return Lds ðjÞ.
Going back to our example in Fig. 1, let us illustrate
how Algorithm 5 computes the probability of each node
being the intended destination of node 1. We first erase all
traffic sent by node 1 from the point-to-point traffic
matrices and get
2

3
2
0 0 0
0 0
0
W 1 ¼ 4 0 0 0 5; W 2 ¼ 4 0:5 0
0 0 0
0 0
0

3
0
0:5 5:
0

Then the new end-to-end matrix can be derived as
2
3
0 0 0
R0 ¼ 4 0:5 0 0:5 5:
0 0 0
Given R0 , the new destination probability vector D can
be calculated using Algorithm 4 as
D ¼ ð0:5; 0; 0:5ÞT :
Previously, we already calculated D as ð0:08; 0:55; 0:37ÞT ,
which means L0sd ð1Þ ¼ D  D ¼ ð0:42; 0:55; 0:13ÞT
and Lsd ð1Þ ¼ ð0; 0:77; 0:23ÞT . Obviously, the destination
probability of node 2 drops most significantly by eliminating the traffic sent by node 1, and so we know that node 2 is
the most possible destination of node 1.
Now, for an arbitrary source node i, we can derive a
vector Lsd ðiÞ ¼ ðlsd ði; 1Þ; lsd ði; 2Þ; . . . ; lsd ði; NÞÞ, which
specifies the probability for each node to be the intended
destination of i. For an arbitrary destination node j, we can
derive a vector Lds ðjÞ ¼ ðlds ðj; 1Þ; lds ðj; 2Þ; . . . ; lds ðj; NÞÞ,
which specifies the probability for each node to be the
corresponding source of j. Since lsd ði; jÞ represents the
probability for j to be the destination of i (given that node
i is a source) and lds ðj; iÞ represents the probability for i to
be the source of j (given that node j is a destination), we
can derive the probability of a source-destination link
(i ! j) as follows:
pði; jÞ ¼ p0 ði; jÞ=

N X
N
X
m¼1 n¼1

p0 ðm; nÞ;

ð9Þ

188

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 11,

NO. 2,

MARCH/APRIL 2014

TABLE 1
System Parameters Configuration

(nodes 3, 6, 18, and 29). (S2) Four source nodes (nodes 2, 5, 11,
and 20) generate CBR traffic to the only destination (node 3).
(S3) CBR traffic is generated between 15 end-to-end
communication pairs: 2-3, 5-6, 5-7, 7-8, 8-9, 8-10, 9-10, 10-11,
10-12, 12-13, 12-14, 14-15, 15-16, 16-17, and 16-18. The
simulation lasts for 200 seconds for each scenario. Other
system parameters are shown in Table 1.

5.1.1 Source/Destination Probability Distribution
The first two scenarios demonstrate the ability of STARS to
identify the source and destination by calculating the
source/destination probability distribution. Figs. 4a and
4b are the source probability distribution of (S1) and the
destination probability distribution of (S2), derived by
Algorithms 3 and 4, respectively. In Fig. 4a, node 2 has
much higher probability than other nodes to be the source,
and in Fig. 4b, node 3 also has the highest probability to be
the destination, which match the simulation setup.
5.1.2 End-to-End Link Probability Distribution
Fig. 5 shows the results of applying Algorithm 5 to (S3). The
results of applying Algorithm 6 are symmetric to those
shown here, so they are not illustrated. In Fig. 5, the
Fig. 3. Work flow of STARS.

where
p0 ði; jÞ ¼ sðiÞ  lsd ði; jÞ þ dðjÞ  lds ðj; iÞ;

ð10Þ

and sðiÞ is the ith element of the S and dðjÞ is the
jth element of the D.
The work flow of STARS is shown in Fig. 3.

5

EXPERIMENTS

In this section, we present the empirical study, consisting of
two components: demonstration and evaluation. First, we
use three simple scenarios to demonstrate (partially) the
direct outputs of STARS, i.e., the probability distributions.
Then, we use the probability distributions produced by
STARS to identify the actual sources, destinations and endto-end links for a large set of simulations, and evaluate the
performance in terms of average false-positive rate (fpr) and
false-negative rate (fnr). The network environment is
simulated using Qualnet [26]. The network protocol stack
is modified so that the communication model presented in
Section 3.1 is simulated.

5.1 Demonstration
The MANET for demonstration is comprised of 30 mobile
nodes randomly deployed in an 800  800 m2 area. There are
three different scenarios: (S1) Only one source (node 2)
generates constant bit-rate (CBR) traffic to four destinations

Fig. 4. Results of (S1) and (S2).

QIN ET AL.: STARS: A STATISTICAL TRAFFIC PATTERN DISCOVERY SYSTEM FOR MANETS

189

Fig. 5. Probability distribution of being the intended destination of each source node in (S3).

probability distribution for every node to be the intended
destination is depicted for each source node. Most of these
curves tell the truth of the actual traffic pattern. For
example, in Fig. 5a, the highest peak is at node 3 (which
means node 3 is most likely to be the intended destination
of source node 2); in Fig. 5b, the highest peak is at node 6; in
Fig. 5e, the highest peak is at node 10. All these results
match the actual CBR traffic pattern perfectly. However,

some of the derived probability distributions have incorrect
indications, such as in Fig. 5d, node 28 has the highest
probability to be the destination of node 8. This is because
some of the forwarders cannot be distinguished from the
actual destination of a source or the actual source of a
destination by using STARS, which means the MANET still
has a certain level of communication relation anonymity
under STARS.

190

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

TABLE 2
Confusion Matrix

5.2 Evaluation
From the previous section, we see that the probability
distributions produced by STARS are good indicators of the
actual traffic patterns, i.e., actual sources, destinations, and
end-to-end links. Different strategies can be used to
speculate the actual traffic patterns from the probability
distributions. In this section, we evaluate the performance
of STARS based on the following two basic strategies, T1
and T2 .
[T1 ] Suppose the number of actual sources, destinations,
or end-to-end links is known to be k. We simply select the
top k items (nodes or links) with the highest probabilities.
[T2 ] Suppose the number k is unknown. We keep
selecting the top items with the highest probabilities until
both of the two criteria are satisfied: 1) the sum of the
probabilities of the selected items has reached u; and
2) the probability of the last selected item is v times larger
than the current one. u and v are two adjustable thresholds,
which are set to 0.8 and 4 in our experiments, respectively.
The simulated MANET is comprised of 80 mobile nodes
deployed in a 1,000  1,000 m2 area. Other system parameters remain the same as in the previous section. The
number of sources varies from 6 to 15 (totally 10 cases), and
each source node has a single destination. Both the sources
and destinations are randomly selected. For each of the
10 cases, we run the simulation 10 rounds. In each round,
we use T1 and T2 to identify the sources3 and end-to-end
links, and compare them with the actual traffic patterns to
calculate the false-positive rate and false-negative rate
based on the typical confusion matrix as shown in Table 2.
Assuming we identify k0 sources (end-to-end links) in
which only c of them are actual sources (end-to-end links),
the false-positive rate is defined as follows:
fpr ¼

fp
k0  c
¼
;
fp þ tn N  k

ð11Þ

and the false-negative rate is defined as follows:
fnr ¼

fn
kc
¼
;
fn þ tp
k

ð12Þ

where k is the total number of actual sources (end-to-end
links) and N is the total number of all nodes (node pairs).
The average values (over the 10 rounds for each case) of
the false-positive rate and false-negative rate are shown in
Fig. 6. From Figs. 6a and 6b, we can see that both T1 and T2
achieve reasonably good accuracy for source identification.
Using T1 , the false-positive rate is almost always less than
0.05, although it increases slightly as the number of sources
goes up; and the peak of the false-negative rate is lower
than 0.3. T2 tends to select more nodes as source nodes,
3. We skip finding the destinations since it is symmetric with finding
the sources.

VOL. 11,

NO. 2,

MARCH/APRIL 2014

which inevitably increases the false-positive rate. However,
the false-negative rate is decreased at the same time. A
valuable observation is that, T1 is not necessarily better
than T2 by knowing the number of items to be selected.
Figs. 6c and 6d confirm this observation. When the number
of actual end-to-end links is known (T1 is applied), we have
almost perfect false-positive rate (close to zero), but
unfortunately the extremely large false-negative rate is not
acceptable. This simply means that too few links are
selected and most of the actual end-to-end communication
relations are not discovered. On the other hand, T2 selects
more links, which reveals most of the actual end-toend links by slightly sacrificing the false-positive rate.
Specifically, in most cases, more than 80 percent of the
actual end-to-end links are revealed (i.e., the false-negative
rate is less than 0.2), while the false-positive rate is not more
than 0.16.
To conclude the evaluation, the hidden traffic patterns can
be discovered in good accuracy using STARS, even without
the number of actual sources, destinations, and end-to-end
communication relations known to the traffic analyzers.

6

DISCUSSION AND FUTURE WORK

The adversarial model presented in Section 3.2 assumes that
the adversaries can globally monitor the traffic across the
entire network region. This assumption is conservative
from the network users’ point of view. Usually, it is difficult
for the attackers to perform such a global traffic detection.
However, even though the adversaries are not able to
monitor the entire network, they can monitor several parts
of the network simultaneously. For example, an attacker can
deploy sensors (signal detectors) around some particular
mobile nodes to track their movements and eavesdrop all of
their traffic. These sensors may even move accordingly.
With the restricted capabilities, the attacker can take
advantage of STARS to perform traffic analysis as follows:
divide the entire network into multiple regions
geographically;
2. deploy sensors along the boundaries of each region
to monitor the cross-component traffic;
3. treat each region as a supernode and use STARS to
figure out the sources, destinations, and end-to-end
communication relations; and
4. analyze the traffic even when nodes are close to each
other by treating the close nodes as a supernode.
We call this variant of STARS as the Generalized STARS
(GSTARS). To perform GSTARS, the adversaries only need
to monitor the nodes beside the boundaries of the supernodes. The traffic inside each supernode can be ignored,
since it will not affect the inter-region traffic patterns. In
addition, GSTARS does not need the signal detectors to be
able to precisely locate the signal source. They are only
required to determine which supernode (region) the signals
are sent from. Moreover, in STARS, the actual receiver of a
point-to-point transmission is not identifiable among all the
potential receivers within the sender’s transmitting range.
This inaccuracy can be mitigated in GSTARS because most
potential receivers of a packet will be contained within one
or a few supernodes. GSTARS will be the direction of our
future research.
1.

QIN ET AL.: STARS: A STATISTICAL TRAFFIC PATTERN DISCOVERY SYSTEM FOR MANETS

191

Fig. 6. Evaluation results.

7

CONCLUSION

In this paper, we propose a novel STARS for MANETs.
STARS is basically an attacking system, which only needs to
capture the raw traffic from the PHY/MAC layer without
looking into the contents of the intercepted packets. From
the captured packets, STARS constructs a sequence of
point-to-point traffic matrices to derive the end-to-end
traffic matrix, and then uses a heuristic data processing
model to reveal the hidden traffic patterns from the end-toend matrix. Our empirical study demonstrates that the
existing MANET systems can achieve very restricted
communication anonymity under the attack of STARS.

ACKNOWLEDGMENTS
This work was supported by the US Army Research Office
Grant W911NF-11-1-0191.

REFERENCES
[1]

[2]
[3]
[4]

J. Kong, X. Hong, and M. Gerla, “An Identity-Free and OnDemand Routing Scheme against Anonymity Threats in Mobile
Ad Hoc Networks,” IEEE Trans. Mobile Computing, vol. 6, no. 8,
pp. 888-902, Aug. 2007.
Y. Zhang, W. Liu, W. Lou, and Y. Fang, “MASK: Anonymous OnDemand Routing in Mobile Ad Hoc Networks,” IEEE Trans.
Wireless Comm., vol. 5, no. 9, pp. 2376-2385, Sept. 2006.
Y. Qin and D. Huang, “OLAR: On-Demand Lightweight
Anonymous Routing in MANETs,” Proc. Fourth Int’l Conf. Mobile
Computing and Ubiquitous Networking (ICMU ’08), pp. 72-79, 2008.
M. Blaze, J. Ioannidis, A. Keromytis, T. Malkin, and A. Rubin,
“WAR: Wireless Anonymous Routing,” Proc. Int’l Conf. Security
Protocols, pp. 218-232, 2005.

[5]

[6]

[7]

[8]

[9]

[10]
[11]

[12]

[13]

[14]

[15]

A. Boukerche, K. El-Khatib, L. Xu, and L. Korba, “SDAR: A Secure
Distributed Anonymous Routing Protocol for Wireless and Mobile
Ad Hoc Networks,” Proc. IEEE 29th Ann. Int’l Conf. Local Computer
Networks (LCN ’04), pp. 618-624, 2004.
S. Seys and B. Preneel, “ARM: Anonymous Routing Protocol for
Mobile Ad Hoc Networks,” Proc. IEEE 20th Int’l Conf. Advanced
Information Networking and Applications Workshops (AINA Workshops ’06), pp. 133-137, 2006.
R. Shokri, M. Yabandeh, and N. Yazdani, “Anonymous Routing in
MANET Using Random Identifiers,” Proc. Sixth Int’l Conf.
Networking (ICN ’07), p. 2, 2007.
R. Song, L. Korba, and G. Yee, “AnonDSR: Efficient Anonymous
Dynamic Source Routing for Mobile Ad-Hoc Networks,” Proc.
Third ACM Workshop Security of Ad Hoc and Sensor Networks
(SASN ’05), pp. 33-42, 2005.
M. Reed, P. Syverson, and D. Goldschlag, “Anonymous Connections and Onion Routing,” IEEE J. Selected Areas in Comm., vol. 16,
no. 4, pp. 482-494, May 2002.
D. Chaum, “Untraceable Electronic Mail, Return Addresses, and
Digital Pseudonyms,” Comm. ACM, vol. 24, no. 2, pp. 84-88, 1981.
J. Raymond, “Traffic Analysis: Protocols, Attacks, Design Issues,
and Open Problems,” Proc. Int’l Workshop Designing Privacy
Enhancing Technologies: Design Issues in Anonymity and Unobservability, pp. 10-29, 2001.
W. Dai, “Two Attacks against a PipeNet-Like Protocol Once Used
by the Freedom Service,” http://weidai.com/freedomattacks.txt, 2013.
X. Wang, S. Chen, and S. Jajodia, “Network Flow Watermarking
Attack on Low-Latency Anonymous Communication Systems,”
Proc. IEEE Symp. Security and Privacy, pp. 116-130, 2007.
M. Reiter and A. Rubin, “Crowds: Anonymity for Web Transactions,” ACM Trans. Information and System Security, vol. 1, no. 1,
pp. 66-92, 1998.
M. Wright, M. Adler, B. Levine, and C. Shields, “The Predecessor
Attack: An Analysis of a Threat to Anonymous Communications
Systems,” ACM Trans. Information and System Security, vol. 7, no. 4,
pp. 489-522, 2004.

192

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

[16] D. Figueiredo, P. Nain, and D. Towsley, “On the Analysis of the
Predecessor Attack on Anonymity Systems,” technical report,
Computer Science, pp. 04-65, 2004.
[17] G. Danezis, “Statistical Disclosure Attacks: Traffic Confirmation in
Open Environments,” Proc. Security and Privacy in the Age of
Uncertainty (SEC ’03), vol. 122, pp. 421-426, 2003.
[18] G. Danezis and A. Serjantov, “Statistical Disclosure or Intersection
Attacks on Anonymity Systems,” Proc. Sixth Information Hiding
Workshop (IH ’04), pp. 293-308, 2004.
[19] G. Danezis, C. Diaz, and C. Troncoso, “Two-Sided Statistical
Disclosure Attack,” Proc. Seventh Int’l Conf. Privacy Enhancing
Technologies, pp. 30-44, 2007.
[20] C. Troncoso, B. Gierlichs, B. Preneel, and I. Verbauwhede, “Perfect
Matching Disclosure Attacks,” Proc. Eighth Int’l Symp. Privacy
Enhancing Technologies, pp. 2-23, 2008.
[21] D. Huang, “Unlinkability Measure for IEEE 802.11 Based
MANETs,” IEEE Trans. Wireless Comm., vol. 7, no. 3, pp. 10251034, Mar. 2008.
[22] D. Chaum, “The Dining Cryptographers Problem: Unconditional
Sender and Recipient Untraceability,” J. Cryptology, vol. 1, no. 1,
pp. 65-75, 1988.
[23] T. He, H. Wong, and K. Lee, “Traffic Analysis in Anonymous
MANETs,” Proc. Military Comm. Conf. (MILCOM ’08), pp. 1-7,
2008.
[24] Y. Liu, R. Zhang, J. Shi, and Y. Zhang, “Traffic Inference in
Anonymous MANETs,” Proc. IEEE Seventh Ann. Comm. Soc. Conf.
Sensor Mesh and Ad Hoc Comm. and Networks (SECON ’10), pp. 1-9,
2010.
[25] J. Wexler, “All About Wi-Fi Location Tracking,” Network World,
http://features.techworld.com/mobile-wireless/2374/all-aboutwi-fi-location-tracking/, 2004.
[26] Scalable Network Technologies, “QualNet Simulator,” http://
www.qualnetcomm.com/, 2008.

VOL. 11,

NO. 2,

MARCH/APRIL 2014

Yang Qin received the BS degree from the
University of Science and Technology of China
in 2006 and the PhD degree from Arizona State
University. He is currently working for Facebook.
His research primarily focuses on wireless ad
hoc networks, including anonymous communications focusing on anonymous routing protocol
design and traffic analysis attacks, ad hoc
network security, and cloud computing.

Dijiang Huang received the BS degree from
the Beijing University of Posts and Telecommunications, China, in 1995 and the MS and
PhD degrees from the University of MissouriKansas City in 2001 and 2004, respectively. He
is an associate professor at the School of
Computing Informatics and Decision System
Engineering, Arizona State University. His
current research interests include computer
networking, security, and privacy. He is an
associate editor of the Journal of Network and System Management
and an editor of the IEEE Communications Surveys and Tutorials. He
has served as an organizer for many international conferences and
workshops. His research is supported by the US National Science
Foundation, the US Office of Naval Research (ONR), the US Army
Research Office, NATO, and the Consortium of Embedded Systems.
He is a recipient of the ONR Young Investigator Program Award. He is
a senior member of the IEEE.
Bing Li received the BS degree from Shandong
University in 2008 and the MS degree from the
Beijing University of Posts and Telecommunications in 2011. He is currently working toward the
PhD degree at Arizona State University. His
research interests include ad hoc network
security and cloud computing. He is a student
member of the IEEE.

. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

J Netw Syst Manage (2011) 19:448–471
DOI 10.1007/s10922-010-9197-2

Policy Management for Secure Data Access Control
in Vehicular Networks
Dijiang Huang • Wei-Tek Tsai • Yi-hsin Tseng

Published online: 18 January 2011
 Springer Science+Business Media, LLC 2011

Abstract The state-of-the-art research in vehicular network security does not
address the need for low latency message access control in vehicular applications
with tight connection time and message delay requirements. In existing security
solutions, the major limitation is that no trust establishment mechanisms that adapt
to rapidly changing scenarios and highly mobile environments (mainly because of
key management delay, processing overhead, and changing communication peers).
To address this issue, we present a policy management framework for secure data
access control in vehicular networks. Our solution address two interrelated research
areas to achieve efficiency and scalability for data access control and policy management in highly dynamic vehicular networks. The main contributions are in
two-fold: (a) efficient key management and group-based policy enforcement using
attribute-based cryptography; and (b) dynamic security policy management
framework and methodology to manage credentials based on role, time, location and
other situation dependent attributes. Our solution utilizes efficient attribute-based
cryptography algorithm to achieve unprecedented speedups in message processing
time to meet the real-time requirement. To demonstrate the effectiveness of our
proposed solution, a systematic and comprehensive evaluation is produced to valid
our proposed solution.

D. Huang (&)
Arizona State University, 699 S Mill Ave. Suite 470, Tempe, AZ 85281, USA
e-mail: dijiang@asu.edu
W.-T. Tsai
Arizona State University, 699 S Mill Ave. Suite 404, Tempe, AZ 85281, USA
e-mail: wtsai@asu.edu
Y. Tseng
Arizona State University, 699 S Mill Ave. Suite 464, Tempe, AZ 85281, USA
e-mail: yi-hsin.tseng@asu.edu

123

J Netw Syst Manage (2011) 19:448–471

449

Keywords Vehicular networks  Data access control  Security policy
management

1 Introduction
Vehicular networks (VNETs) will enable vehicle-to-vehicle and vehicle-to-roadside
communications and are expected to greatly enhance driving safety and improve
roadway system efficiency. In many VNET applications, reporting a road situation
requires a mechanism for distributing related information to desired vehicles in an
efficient manner. In general, communications in VNETs can be classified as
Vehicle-to-Vehicle (V2V) communication and Vehicle-to-Infrastructure (V2I)
communication, where the infrastructure includes fixed Road Side Units (RSUs)
and communication backbone, such as Internet. Before VNET applications can be
deployed, many security and privacy requirements [1] have to be addressed.
Previous work has been focussed on addressing various security and privacy
requirements, such as identity trust (i.e., authentication), data trust (i.e., data
integrity and truthfulness), privacy (anonymity and location hiding), and key
management [2–5] . Very few existing solutions address how to specify and control
secure access data policies in vehicular networks. To address this limitation, we
present a systematic approach to manage the data access policies in a highly
dynamic and ephemeral communication environment. Our goal is to build a new
secure data access control policy management architecture deliver timely and
customized trust support to a broad range of vehicular applications.
To achieve our research goal, we investigate into a systematic approach that
integrates data access control and policy management using attribute-based
cryptography. Using attribute-based solution, we can integrate the policy management and key management effectively. Using attribute-based cryptography, a set of
descriptive terms is used as a security policy. Moreover, this set of descriptive terms
also serves as the public key to secure the ciphertext. The policy terms can be either
static or dynamic. By dynamic, we mean that the road-side conditions can be
changed, such as road name, direction, speed limits, etc., which can be considered as
terms to describe a policy. When the attributes (or public keys) are dynamic, their
corresponding private keys need to be allocated to each vehicle in a timely fashion.
Thus an efficient key management solution is required.
The main contributions of this article are to address the following two research
issues: (a) using attribute-based cryptography to achieve efficient key management
and group-based policy enforcement; and (b) establishing a dynamic security policy
management framework by incorporating a decentralized policy enhancement
approach to manage credentials based on role, time, location and other situation
dependent attributes.
To address the first research issue, we propose a Policy Group based Data Access
(PGDA) model to address the efficiency issues incurred by using public-key-based
solutions through establishing secure communication groups among vehicles.
In PGDA, any vehicle can form a group with its neighboring vehicles. Particularly,
PGDA effectively enables all vehicles in the group to share a group key by just

123

450

J Netw Syst Manage (2011) 19:448–471

broadcasting one message. When a vehicle has to send a message to its desired
group members, it creates an encrypted message using a policy tree (PT ) and then
broadcasts it. Group members who receive this encrypted broadcasted message can
decrypt it if they satisfy the policies enforced by the PT . These policies are usually
defined over a set of descriptive attributes. A PT is basically an access tree structure
combined by multiple attributes and logical gates, which form one or multiple data
access policies. The attributes are used to identify a group of entities who share a set
of common attributes. Compared to traditional PKI-based solutions, the message
encryption is performed using a group key rather than an individual public key, thus
the communication cost is low. Moreover, using PGDA, vehicles can form a group
without relying on a centralized group manager to construct the communication
groups.
To address the second research issue, we present a scalable policy management
framework in a decentralized fashion. For each vehicle, it needs to pre-install a set
of secrets from a Global Trusted Agent (GTA, i.e., a trusted authority—TA) with
respect to its corresponding attributes, such as types of cars, ownership (e.g.,
company or private owner), licensing state, etc. The GTA can be a vehicular
registration authority such as Motor Vehicle Division (MVD) or other trusted
organization such as a police department, etc. During the communication phase
on-road, a vehicle initiates a group communication by deriving a set of attributes
from a Local Trust agent (LTA), e.g., an RSU, to form a data access policy tree.
Vehicles owning the specified attributes can decrypt the messages enforced by the
attributes. We note that every vehicle can initiate a communication group. The set of
attributes are considered as a set of policies enforced for such a group
communication.
The rest of this paper is organized as follows: Sect. 2 highlights the related
research of this work. In Sect. 3 details the system assumptions, communication
models, and attack model. In Sect. 4, we present the formation of policy group and
its operations. The decentralized policy management framework is presented in
Sect. 5 The Security analysis is presented in Sect. 6 and performances evaluations
are presented in Sect. 7 Finally, we conclude our work and point the future research
directions in Sect. 8.

2 Related Work
Secure VNET communication protocols have been extensively studied in recent
years [6–10]. From the architectural design aspect, the published work mainly uses
traditional shared and public key management solutions addressing entity-level trust
with prime concerns on authentication and message integrity [3, 11]. Trust of the
reported data has also been studied [12, 13]. One issue unique of VNETs is vehicle
trust based on position verification [14]. Most of the security work published so far
fails to develop a real time, low latency trust evaluation and key access control
strategy.
The policy-based data access control is motivated by the capability of using
Identity-Based Encryption (IBE) [15]. Attribute-based encryption [16] extends IBE

123

J Netw Syst Manage (2011) 19:448–471

451

by incorporating multiple IDs (a.k.a., attributes or descriptive policies) using secret
sharing scheme [17]. Bethencourt et al. [18] proposed the ciphertext policy
attribute-based encryption, where encrypter specifies an access control policy to
confine who can decrypt the ciphertext. Our solution is based on ciphertext policyattribute based encryption (CP-ABE) to address the data access policies in a highly
dynamic VNET environment. The detailed description of CP-ABE is presented in
Appendix 1. In [19, 20], the authors present a basic idea of using ABE schemes to
construct a communication group for vehicular networks.
A VNET requires a flexible policy-based system that allows dynamic revision
and enforcement of the policy possibly at runtime while the application is still
running. In the past decade, a number of policy enforcement solutions have been
proposed [21–27]. Recently, security policies have been used in mobile ad hoc
networks [28–31]. However, none of existing solutions address how to handle
secure data access policy management in VNETs.

3 System and Models
In this section, we present the overview of the communication model and attack
model.
3.1 Communication Model
The communication model includes two networks: vehicular network and social
network over the existing Internet. The vehicular network model comprises physical
network components such as: on-road units, off-road units, and the interfacing layer.
The on-line trusted authority, usually managed by a local transportation department
office, uses Internet based security services through RSUs, e.g., WiFi radio [32] and
Dedicated Short-Range Communications (DSRC) radio with associated protocol
suites [33], or cellular networks for establishing trust. This approach will maximally
enable the flexibility and robustness to build up trust among vehicles. Off-road units
consist of trusted authorities (TA) which can provide identity-based public key
certificate services for users to derive their private keys and identity certificates.
Further, we assume that the global trusted agent (GTA) issues long-term
cryptographic credentials in advance, and local trusted agents (LTAs) are connected
to RSUs. These servers can be viewed as part of the infrastructure support.
The Motor Vehicle Division (MVD) or other Government organization runs the
GTA, while LTAs are hosted in roadside units and, in some cases, even vehicles.
Some cryptographic credentials can be established off-line with long lived validity;
others, more dynamic credentials are obtained as the car joins the VNET and travels
through the urban grid (e.g., via periodic location registration [34]).
3.1.1 Pre-authentication
The communication in VNETs is a two-step procedure. The first step is mandatory
for all vehicles entering a particular road segment monitored by an RSU, say Rl.

123

452

J Netw Syst Manage (2011) 19:448–471

When a vehicle i enters the controlled area of Rl, the vehicle performs preauthentication with the Rl. During the pre-authentication phase, vehicle i exchanges
its identity certificate (Certi) with Rl. To better preserve vehicles privacy, a vehicle
can use a pseudo-identity certificate issued from a trusted authority. There are a
number of schemes in literature [1, 35], which proposed solutions for achieving
vehicles privacy through pseudo-identity certificates. Thus, we assume that the
vehicles i uses pseudonym identity certificate Certi for pre-authentication.
3.1.2 Communication Model for Policy Management Framework
After the pre-authentication procedure, the next step is the secure communication
phase involving secure data access policy management. We use LTAs and GTA to
manage the data access control policies. Particularly, an LTA manage all the
vehicles within its communication range. Existing RSUs use Dedicated Short-Range
Communications (DSRC) radio with associated protocol suites [33], an DSRC
transceiver can cover a road segment about 2000 meters (with 1,000-m coverage
radius). One LTA can cover an area managed by multiple RSUs, where the number
of RSUs depends on the capability of LTA processing vehicles’ requests. In general,
the global policy may not be changed frequently, thus the GTA may not be always
online.
3.2 Attack Model
In our presented system, the GTA (i.e., the MVD) is responsible to distribute static
attributes and corresponding secrets to vehicles and LTAs (i.e., RSUs) are
responsible to distribute dynamic attributes and corresponding secrets to vehicles.
We assume that the GTA and LTA are always trusted. A trusted entity is immune to
all types of attacks and it cannot be compromised.
External malicious attackers can try to impersonate the GTA and LTAs. They can
compromise the hardware of vehicles and then derive the pre-installed secret keys.
Their goal is to compromise the pre-installed secrets and then disturb secure group
communications and access the protected data. However, we assume that
cryptographic keys are protected by tamper-proof devices for trusted entities, thus
external adversaries cannot derive their secret keys. Collusion can happen among
attackers, but not between trusted entities.
In a summary, an adversary can deploy the following attacks:
•
•
•

Collusion attacks: vehicles collude to derive arbitrarily selected static attributes
and corresponding private keys.
Impersonation attacks: a vehicle impersonates LTAs and other vehicles.
Unauthorized data access attacks: a vehicle can decrypt a message enforced by
a policy tree, in which it cannot satisfy the logic operations to the root of the
policy tree.
The security analysis of our scheme against these attacks is provided in Sect. 6

123

J Netw Syst Manage (2011) 19:448–471

453

4 PGDA: Constructing Data Accessing Policy Groups for Vehicular Networks
In general, vehicles’ roles, or passengers’ roles, or roadside devices’ roles may
determine the types of road information that can be accessed by them. Thus VNETs
need to confine the data access for designated groups of vehicles. These groups can
be classified based on their functions or roles (e.g., police vehicles, ambulances,
private cars, vehicles, commercial vehicles), or network applications (e.g., special
functions or particular networking applications). In addition, especially for safety
related applications, instantaneous environmental data like location and time should
be associated. In this section, we present how to incorporate static roles and
dynamic on-road situations, such as location, times, regulations, and events as
constraints to build secure data access policies in Appendix 2, we present how to
combine static attributes and dynamic attributes using ABE solutions.1
4.1 Policy Group
Considering a road situation example: a taxi driver wants to inform his fellow
drivers in the same company about the business opportunities restricted within a
road segment and in a certain time frame. In this situation, security policies such as
data privacy and origin integrity are required to ensure the business secret. With
SAT, the driver can broadcast the following message, where the real message M is
encrypted by a key s, and signed by a symmetric group key, shared by all drivers
belonging to companyA:
Ms ¼ T fcompanyA ^ taxi ^ Washington Street ^ 10am11am ^ northboundg ðsÞjjEs ðMÞjjsigcompanyA ;
ð1Þ
Here the most important feature is the generation of the key s and the associated
encryption/decription methods. This example indicates a situation-based key s,
which has to use a set of descriptive attributes in the form of (companyA ^ taxi ^
Washington Street ...), combined by the logic operator ^. T forms a tree rooted by
the operator ^. The tree specifies the security policy for the access permission
issued to the message M. The descriptive attributes and their combination patten are
essential to obtain the key s for encryption and decryption. For this example, all
these attributes companyA, taxi, Washington Street, 10am-11am and North-bound
must be ‘‘True’’ to access the data encrypting key (DEK) s, and then to decrypt the
message Ms. This capability is enabled by using attribute-based encryption (ABE)
[18].
Cryptography method backing up the data access tree T , is for each attribute to
be considered as a public key component. Thus, the tree T is a set of public key
components and the operators. It is sent within the message Ms. The associated
private key components should be distributed to each vehicle in companyA in a
private way. These public/private key components include both static portion, which
are not changed, e.g., companyA and taxi, and dynamic portion, which are changed
1
In Appendix 2, we present how to combine static attributes and dynamic attributes using ABE
solutions.

123

454

J Netw Syst Manage (2011) 19:448–471

Table 1 Vehicular network polices
Static attributes (SA) – ASA(x)

Dynamic attributes (DA)

Vehicle attributes (VA)

Road attributes (RA) –ARA(y) Environment attributes (EA) – AEA(z)

Vehicle category (VC)

Road direction (RD)

Emergency event (EE)

Road intersection (RI)

Hi security (HS)

Vehicle application or service (VS) Road name (RN)
Network category (NC)

Time stamp (TS)

Road segment number (RS)

Date (ED)

City name (EC)

Privacy protection (PP)

State name (ES)

Network situation (NS)

according to the road situations, e.g., Washington Street, 10am-11am and Northbound. The static attributes and corresponding keys are preinstalled by the GTA;
and the dynamic attributes and corresponding keys are distributed through LTAs.
Whoever receives this message Ms will try to calculate the key s using its stored
private keys. As a result, only the vehicles having the right set of the private keys
can legitimately recover the DEK s. Note that, more than one vehicle can use this
tree to access M. In this example, the vehicles satisfying the access tree T form a
policy group GT . We also call an access tree as a policy tree.
As we pointed out earlier, many VNET applications, especially many life-critical
safety messages and urban emergent events are intended for groups of vehicles.
The approach of attribute-based encryption and situation awareness in data access
that is illustrated here presents an efficient construction for secure data access for
groups of vehicles. The formation of secure groups is different from traditional
methods in that no group establishment phase is required. This property is extremely
useful and scalable in a highly dynamic VNET. Moreover, it is very flexible to
construct a policy tree according to different data access control requirements. In
Table 1, we present a classification of static and dynamic attributes. Their notations
and meanings are self-explained.
4.2 Construct Policy Trees Including Static and Dynamic Attributes
Formally, logical operations for combining attributes include AND, OR, numerical
relations and k-out-of-n relations, represented as: logical operator LO ¼ fLOi j^;
_; \;  ; [ ;  ; k out of ng. An example of T fðA1 ^ A2 Þ_ A3 g ðsÞ indicates AND and
OR logic operations among three attributes fA1 ; A2 ; A3 g. This access policy in fact
describes the following if-statement:
ifðownðA1 Þ ^ ownðA2 ÞÞ _ ownðA3 Þ;

then decrypt DEK s:

It says that only if a vehicle owns attributes A1 and A2, or A3, can it decrypt the DEK
s. In an access tree T the attributes are leaves and the logic operators are internal
nodes.
Several representative attributes and classifications for VNETs are given in
Table 1. ASA(x), ARA(y), and AEA(z) represent static attributes, road attributes, and
environment attributes, respectively. Variables x, y, z represent corresponding static

123

J Netw Syst Manage (2011) 19:448–471

455

Fig. 1 Policy tree examples
based on attributes

low

LO 3

s EA

Priority

2

LO 2

Encryption

... A EA (z)
s RA

A RA (y)...
LO 1

Decryption

3

s SA

1

high

A SA (x) ...
Policy tree based on attributes

and dynamic attribute values. A general policy tree (T ¼ fT i g) corresponding to
the classifications is constructed and shown in Fig. 1. The lower level trees usually
have higher priorities and are processed first. The T is enforced through a bottomup approach, i.e., only if a vehicle (or a user) possesses adequate number of
attributes and fulfills logic operators to a certain level (i.e., a logical operator
associated with a DEK sSA, sRA, and sEA), can it access the encrypted data; and the
set of vehicles that can access the data form a policy group GT .
However, vehicular networks can involve complex composition of applications
and situations; there can be many static and dynamic attributes and corresponding
public and private key components. The private key components of static and
dynamic attributes are derived from different administrative domains (e.g., GTA
and LTAs). All these call for an effective architectural solution to combine static
and dynamic attributes without exposing the secrets to different domain administrators. In a recent work [20], we presented a solution that considers the attributes
that are generated from the same management domain. However, the attack model
presented in [20] is not realistic, where all RSUs are trusted. There are two critical
issues of [20] need to be addressed: (a) how to construct a workable policy tree by
integrating static and dynamic attributes, and (b) how to prevent RSUs and vehicles
from colluding to generate valid static attributes and corresponding private keys.
In this paper, the presented protocol construction is mainly to address these issues.

5 Security Policy Management in VNETs
Our policy enforcement architecture with distributed agents is shown in Fig. 4.
This framework has a hierarchical structure with trusted global and local policy
enforcement agents (i.e., GTA and LTA, respectively) to help vehicles to generate
policy enforcement trees. A high-level policy agent issues global policies to LTAs.
The GTA is responsible to issue private keys for vehicles and users; it usually
generates private key components for static attributes. Thus, the GTA issues policy
updates less frequently than LTAs. Upon accepting the global policy update, each

123

456

J Netw Syst Manage (2011) 19:448–471

LTA that manages a particular geographical area should verify and update its policy
database to ensure compliance. In turn, each vehicle is required to comply with
policies enforced by LTAs. Furthermore, the GTA and LTAs can be connected to
VNETs through RSI, which includes LTAs, Internet, and telecommunication
networks. We must note that the process of policy management should be
performed before vehicle starting their secure communication, which is discussed in
previous section. Vehicles need to send their policy request before entering the
policy enforcement zone. In Sect. 2, we evaluate the required time before they
entering the policy enforcement zone.
5.1 Policy Management Architecture
The hierarchical structure is a key for a scalable solution as loads within a region
will be mostly handled by distributed regional or local trusted agents. Here, we
consider the regional agents are basically delegations of the GTA, which are highly
trusted entities. Global, regional and local trusted agents also synchronize with each
other either periodically or in needed basis to ensure dynamic policy updates and
consistency. Figure 2 highlights the function blocks within an LTA, where multiple
islands of grouped meta-policies and policies used to describe the constraints of
attributes given in Table 1.

Fig. 2 Policy enforcement architecture

123

J Netw Syst Manage (2011) 19:448–471

457

Dynamic Attribute-based Policy Specification: The framework uses metapolicies to simplify the creation of new policies or updates of existing policies
with constraint analysis and dependency analysis. The GTA, LTAs, as well as
individual vehicles, have their own meta-policies. For constructing the 3-level
policy tree in Fig. 1 used by a vehicle, its local policy agent (with location
proximity) will coordinate various activities including: requests received from
individual vehicles; global policies enforced by the GTA; and local road situations
monitored by LTAs. Furthermore, each vehicle can append its own policy
enforcement sub-trees at different priority levels to enable additional self-defined
policies. Policies can be specified using various policy languages such as
WS-Policy, PSM-P [27] or Boolean expressions with predicate logic and/or
temporal logic, such as Linear Temporal Logic (LTL) [36], or a combination of
them.
Dynamic Policy Registration and Deregistration: Each vehicle can register its
desired policy (by sending a policy request) when entering an enforcement zone.
The policy will be verified by the local agent first. Each policy engine, whether
global or local, will follow a policy enforcement architecture as shown in Fig. 2.
Note that this architecture is a modified Blackboard architecture [37], which has a
number of islands of grouped firing rules (policies), and a working area where the
data are stored and updated. The Blackboard architecture has three components: (1)
software modules: this is where policies are stored. In this project, not only policies
are stored, but also meta-policies; (2) blackboard: this is the place where shared data
are stored; (3) the control shell: this is the place where synchronization,
prioritization, and resolution mechanisms shown in Fig. 4. The data will be updated
whenever there is a change in the system, and a firing rule (policy) will be activated
whenever the pre-conditions of a firing rule are satisfied by the road situations. If
multiple policies can be activated, there will be coordination effort by synchronization, prioritization and/or resolution. The consistency checking can be performed
using our proposed completeness and consistency algorithms for Boolean expressions [38]. As policies are not functional specification but constraints on
functionality, policies need to be evaluated with functional code and also
dynamically to see the impact on performance and system behavior [27].
Meta-policies can play a significant role as they can constraint the kind of
permissible policies. Thus, evaluation will be based on meta-policies with
representative policies to ensure that policies are complete, consistent, and provide
the right assurance of trust.
This architecture is particularly suited to dynamic VNETs where attribute-based
policies can be naturally grouped in islands for easy management, and current data
stored and updated in the working area provide the current status of the VNET.
5.2 Policy of Motor Vehicle Division, Arizona Department of Transportation
This project uses policies enforced by Arizona State Motor Vehicle Division (MVD)
for illustration as shown in Fig. 3. The top element of the ontology is ‘‘MVD
Policies.’’ The ‘‘MVD Policies’’ comprises of policies from eight sub-domain
categories ‘‘Road Related’’, ‘‘Human Related’’, ‘‘Registration Related’’,

123

458

J Netw Syst Manage (2011) 19:448–471

Fig. 3 Ontology for registration related policy

Table 2 Policy for classes of licenses
Classes of licenses

Policy

Graduated license

A graduated driver license is issued to an applicant who is at least
16, but less than 18, years of age and valid to operate any vehicle
that does not require a motorcycle or commercial license

Motorcycle license

A motorcycle license or endorsement is required to drive a
motorcycle or motor-driven cycle. You must be at least 16 to
apply for a motorcycle license

Instruction permit

If you are at least 15 years and 7 months of age you may be issued
a graduated and/or a motorcycle instruction permit. You must be
at least 18 for an operator permit

‘‘Location’’, ‘‘Time’’, ‘‘Security’’ and ‘‘Category’’. For example, the ‘‘Human
Related’’ sub-domain contains all of the policies related to human, e.g., right-of-way
policies, entering and crossing traffic policies, whereas the ‘‘Registration Related’’
related to driver license and vehicle registration. The following diagram shows the
ontology for registration-related policies.
We present an example of licensing policy in Table 2.
5.3 Dynamic Policy Registration and Deregistration
Each vehicle can register its desired policy (by sending a policy request) when
entering an enforcement zone. The policy will be verified by the local agent first.
Each policy engine, whether global or local, will follow a modified Blackboard
architecture [37], which has a number of islands of grouped firing rules (policies),
and a working area where the data are stored and updated. The data will be
constantly updated, and a firing rule will be activated whenever the pre-conditions
of a firing rule are satisfied by the road situations. This architecture is particularly
suited to dynamic VNETs where attribute-based policies can be naturally grouped in
islands for easy management, and current data stored and updated in the working
area provide the current status of the VNET.
The consistency checking can be performed using our proposed completeness
and consistency algorithms for Boolean expressions [38]. As policies are not
functional specification but constraints on functionality, policies need to be
evaluated with functional code and also dynamically to see the impact on
performance and system behavior [27]. Meta-policies can play a significant role as
they can constraint the kind of permissible policies. Thus, evaluation will be based

123

J Netw Syst Manage (2011) 19:448–471

459

on meta-policies with representative policies to ensure that policies are complete,
consistent, and provide the right assurance of trust.
6 Security Assessment
In this section, we first present the security strength of policy group formation
schemes presented in Sect. 4 We will show that, based on the protocol construction,
a vehicle cannot derive valid private key components for dynamic attributes without
LTAs’ help. In the following security analysis, we analyze the security features of
PGDA under colluding attacks, impersonation attacks, and reply attacks based on
the attack model presented in Sect. 2.
6.1 Colluding Attacks
Vehicles cannot collude to derive valid static attributes and corresponding private
keys. This is because they do not possess the secret information a, b, and ri (see
Appendix 1). In order to generate valid private keys for static attributes, attackers
must have the private value ri (or gri ) to generate valid private key components Di,j
and D0 i,j presented in Protocol 4 presented in Appendix 1. The proof of this security
property can be found in [18].
For dynamic attributes, each vehicle uses two sets of parameters: one for static
attributes and one for dynamic attributes. The selection of system parameters ha, bi and
ha0 , b0 i makes the proposed solution against colluding attacks. However, by sharing
0
private information, LTAs and vehicles can only derive gri that can be used to derive
valid dynamic attributes (j) and corresponding private key components Di,j and D0 i,j.
This colluding attack is only restricted by the colluding entities and it does not affect
other non-colluding vehicles. This is because each non-colluding vehicle has a unique
ri selected by the MVD, which cannot be compromised through colluding attacks.
6.2 Impersonation and Illegal Decryption Attacks
Impersonation attacks do not work in our presented protocols. This is because the
pre-authentication procedure, presented in Sect. 3.1, utilizes public key schemes to
prevent vehicles from impersonating LTAs, and vice versa. In our presented system
model, we assume that the vehicular communication system uses identity-based
signature solutions, such as BLS [39]. Additionally, a vehicle impersonating other
vehicles is difficult because it does not possess required private keys for others’
identities to produce valid BLS signatures. Similarly an LTA cannot impersonate a
vehicle and generate a valid signature.
Based on the construction of Protocol 4 presented in Appendix 1, a vehicle
cannot decrypt a ciphertext without satisfying the policy tree. This is because the
private keys of dynamic attributes are eventually computed by vehicles using the
tree combination scheme presented in Appendix 2. Moreover, malicious vehicles do
not have the private key component D0i ¼ ða0 þ ri0 Þ=b0 , which makes it is impossible
for them to execute the Protocol 4.

123

460

J Netw Syst Manage (2011) 19:448–471

7 Performance Assessment
The performance assessment includes two portions: (a) the policy tree generation using
PGDA, and (b) secure policy management. The performance evaluation of PGDA
presents a comparative study based on several solutions addressing the communication
and computation efficiency incurred by group based key management during the
communication in VNETs. The performance evaluation of secure policy management
shows the capacity of the security policy management system responding the vehicles’
requests, which are usually happened before the vehicles starting the group
communication. We describe each of them in the following subsections.
7.1 Delay and Communication Performance Evaluation of Using PGDA
We evaluate the scheme on the basis of the average latency observed by the
message sender to form the policy group, the time taken by the message sender to
update the group key on member(s) addition/deletion or location change, the time
taken to perform encryption and decryption of a message, and the running time of
signature generation and verification. We also analyze the effect of traffic density on
the road, which is very important especially when group communication in
involved. This is because during group communication all messages are
broadcasted. It is possible that a vehicle may receive multiple messages originated
from different group members. If the number of neighboring vehicle increases, the
number of messages received by a vehicle during a specific time interval may
increase. As the vehicle’s computation power is limited, increasing number of
messages will increase the time required by the vehicle to process all received
messages. Therefore, it becomes essential to consider a number of messages along
with traffic density for detailed evaluation of the system performance.
To demonstrate the efficiency of PGDA, we compare it with CARAVAN [40]
and Mix-Zones [5] (referred to as MZ in the following context). Particularly, we
compare PGDA with CARAVAN and MZ for latency measurement and key update.
PGDA cryptographic algorithms are implemented in C??. For the ellipticalcurve and pairing operations, we used Pairing-Based Cryptography (PBC) Library
[41]. We also used the Crypto?? 5.4 Library [42] for routines such as the SHA-256
hash function. For ECC and also for pairing we used the Type-A curve defined in
the PBC library with the default parameters [41]. Our performance evaluation is
done on a 2 GHz PC with 2 GB memory. The results of each evaluation are
averaged over 1,000 randomized simulation runs. For PKI, we chose 1,024-bit keys,
and for ECC, we chose 160-bit keys to ensure the same level of security.
The communication model of PGDA is simulated using NS-2 [43]. In order to
replicate real-world road environments and vehicle traffic, the mobility model tool
introduce in [44] was used. This tool uses the publicly available TIGER
(Topologically Integrated Geographical Encoding and Referencing) database from
the U.S. Census Bureau. The road system in our evaluation simulation is in Tempe
area, Arizona, USA. Each vehicle is positioned randomly on the map and is driving
at the speed limit that ranges from 20 to 75 miles/h for different streets. The
simulation area is 1,000 m 9 1,000 m controlled by a single LTA.

123

J Netw Syst Manage (2011) 19:448–471

461

7.1.1 Encryption and Decryption Overhead
Figure 4 shows the encryption and decryption time with increased number of
attributes. The majority of time consumed in both encryption and decryption protocol
is the result of two point multiplication (about 1.52 ms) and one pairing operation
(about 7.3 ms). It can be seen in the Fig. 4 that the running time of encryption and
decryption operations are increased with the increasing of the number of attributes.
7.1.2 Average Message Delay
Figure 5 shows the average message delay of the system with the increases of the
number of vehicles and the number of attributes. From the figure, we can see that
the average message delay increases with the number of attributes used in the policy
tree. Moreover, another impact factor is the number of vehicles, in which more
vehicles will cause long transmission delay.
7.1.3 Comparisons of Group Key Updates Latency
Figure 6 draws the comparison of group key updates latencies between CARAVAN,
MZ, and PGDA schemes. IN CARAVAN or MZ, if the location changes or a new
vehicle joins in, the group key must be updated, where the GL uses the public key of
each vehicle to encrypt the updated group key and send them to the respective
vehicles. In our evaluation setup, this process takes 0.057 s for one-group-member
key update. For MZ, this process is followed by additional acknowledgement
process time (0.028 s). As in both schemes, this procedure is repeated for all group
members, the time taken to update key of n vehicles is 0.057n seconds in
CARAVAN and 0.085n seconds for MZ. In PGDA, as each vehicle generates their
keys, the key updates procedure is efficient. However, the time taken to generate
keys in PGDA depends upon the number of attributes for which the keys have to be
generated. In Fig. 6, we plot the time taken by the vehicle to update keys when the
10.352

Decrypt
Encrpt

Time (sec)

10.35
10.348
10.346
10.344
10.342
10.34
10

20

30

40

50

60

70

80

90

100

Number of attributes

Fig. 4 Encryption and decryption overhead of PGDA

123

462

J Netw Syst Manage (2011) 19:448–471

Average message
delay (sec)

0.25
0.2
0.15
0.1
0.05
0
100
60
40

Number of
attributes

20
0

10

20

30

40

50

60

70

80

90

100

Number of
vehicles

Fig. 5 Affect of cryptographic operations on message delay

1.2

CARAVAN
MZ

Time (sec)

1

PGDA-100
PGDA-50

0.8

PGDA-10

0.6
0.4
0.2
0
1

2

3

4

5

6

7

8

9

10

Number of vehicles

Fig. 6 Comparison of time taken for group key updates

number of attributes in a PT is 10, 50, or 100. it can be seen the PGDA is very
efficient compared to CARAVAN and MZ solutions.
7.2 Delay and Communication Performance Evaluation of the Policy
Management System
In this subsection, we present the capacity of the policy management system to
respond to the vehicles’ request. As we described in Sect. 5, vehicles need to derive
an appropriate policy tree to enforce the data access policies. This is usually done by
sending a policy request message to LTAs. Once an LTA received a request, it needs
to check if the request can be satisfied by checking its policy database and suggest the
best policy tree to the vehicle. In our experiments, we establish a policy management
system to handle vehicles’ requests. The experiment is run on a policy processing
server based on Windows XP operating system with AMD 2.1 GHz CPU.

123

J Netw Syst Manage (2011) 19:448–471

463

The global policy set is based on Arizona State MVD’s public policies. For the
local policies, we consider the following four attributes: location, time, direction,
road name.
The simulated policy enforced zone is defined as following: a road is a 2,000 m
two-lane road segment (controlled by one DSRC enabled RSU), and there is two-way
traffic. The segment set in the experiment is 3.5 m and the average vehicle length is 1
segment. If the condition of the traffic is heavy, it means the distance between each
vehicle is equal or less than 1 segment. If it is moderate traffic, it means the distance
between each vehicle is between 1 segment and up to 3 segments. If there is light
traffic, it means the distance between each vehicle is larger than 3 segments.
To demonstrate the impact of policy management system on the system
execution time, we present the delay evaluations on a sequence of vehicles’
operations: registrations, update location, update policy, and deregistration, which
are described as follows:
Event

Event description

Registration

A new vehicle enters the enforced zone and sends a request for registering

Update_location

A vehicle sends its location updating periodically

Update_policy

An LTA updates the policy tree with the vehicle

Deregistration

A vehicle which leaves the enforced zone will be deregistered

The policy requests are simulated by using Poisson Arrival Process for each
vehicle in the system:
P¼

ðktÞn kt
e ;
n!

where n is the number of vehicles in the policy enforcement zone during time t, k is
the average arriving rate or policy. We simulate the average message arriving rates
as 7.5, 10, 15, 20, and 30 per second.
The parameters used in the experiment are: the number of requests (including
location updates) fired by a vehicle p and total number of vehicles in a specific
policy enforcement zone v. Note that the presented system running time is the sum
of the delay incurred due to communication and system handling time (the vehicle
processing time incurred during the secure communication has been described in
previous subsection). We test the system handling time by different conditions in
the following three scenarios: (a) dense road traffic, frequent transmissions
(228–457 vehicles, 15 messages/vehicle), (b) moderate road traffic, moderate
transmissions (114–228 vehicles, 8 messages/vehicle), and (c) light road traffic, less
transmissions (\114 vehicles, 4 messages/vehicle).
In Figure 7, the quantitative analysis of the system delay is presented. Note that
the system handling time is not a single run of the experiment in 45 seconds. It is a
statistical result which is the average value of 10 samples instead.
In the figure, it shows that if each vehicle sends 15 requests to the LTA in 45 s
and there are 100 vehicles send requests to the LTA, the processing time to generate

123

464

J Netw Syst Manage (2011) 19:448–471

Running Time (sec)

Running time with the increased number of policies and vehicles
14
13
12
11
10
9
8
7
6
5
4
3
2
1
0

v = 100
v = 150
v = 200
v = 250
v = 300
v = 350
v = 400
v = 450

p = 2 p = 3 p = 4 p = 5 p = 6 p = 7 p = 8 p = 9 p = 10 p =11p = 12 p = 13 p = 14 p = 15

Fig. 7 Running time increases as more vehicles enter the enforced zone

required policy tree is about 3 s. On another extreme, the processing time is about
13 s when 450 vehicles send 15 requests for each of them. This figure does not show
the system delay in various road conditions. To demonstrate different road
conditions, we plot the follow results shown in Fig. 8.
Figure 8 shows the system delay with three different settings as described in the
above. The diagrams show that the system execution time under stressed, moderate,
or relaxed road condition in the defined zone. The maximum number of vehicles
could have a capacity of 457 vehicles which means the distance between each
vehicle is approximate to 0 (bumper-to-bumper). The data point shows that the
system will take 13.94 s for processing all of the vehicles in the zone and each of
them sends 15 requests within 45 s. The fastest time in this zone would be 4.26 s for
handling 228 vehicles with 9 requests per vehicle. Considering the normal
distribution of the vehicle number, the average processing time under stressed
condition will be around 8.54 s. Similarly, we can derive the system delay for
moderate and relax scenarios.
The above results showed us the minimal travel time before vehicles entering
zone and sending their policy tree generation requests. For example, if the system is
highly congested, before entering a zone controlled by an LTA, a vehicle is
expected to send its requests 8.54 s in advance. In a real system, this requirement
is not critical since vehicles can use RSI backbone to transmit requests to remote
locations in advance.

8 Conclusion and Future Work
In this paper, we first present a novel policy-based group communication scheme
using attribute-based cryptography to form on-demand dynamic vehicular groups.
Then we present a policy management frame to help vehicles to generate policy
trees for data access control. Our research shows that the groups can be formed
dynamically with little communication and group management overhead. Additionally, our solution incorporates data access control naturally and it is scalable to

123

J Netw Syst Manage (2011) 19:448–471

465

Fig. 8 System delay of policy tree generation with three traffic and requests settings: stressed, moderate,
and relaxed

handle large number of requests. The evaluation results prove that our scheme is
efficient, applicable, and effective when applied to vehicular networks.
Next, we will investigate the predictive capability of the policy management
framework to handle dynamics of vehicular networks. Additionally, in our current
solution, we do not consider that LTAs work together to reduce the amount of
information to process. Our future research will also investigate the collaborations
among LTAs to improve the performance of the policy management framework.

Appendix 1: CP-ABE Decrypt Protocol
The cryptographic construction of PGDA is based on CP-ABE. PGDA proposes
extensions of CP-ABE for vehicular networks and the system is initialized by using
a set of publicly known parameters for vehicle i:
paramsi ¼ he; G0 ; G1 ; g; p; h; f; H; S si ; SKsi ; Certi i:
The paramsi can be stored in vehicle i by the GTA at the time of registration.
We use i to represent a unique vehicle ID. The detailed explanation of params is
given in Table 3.
The Protocol 4 presents a sketch of Decrypt protocol presented in [18].
To complete the presentation of our solutions, we present the CP-ABE Decrypt
protocol in details. For correctness and security proof of CP-ABE scheme,
interested readers should refer to [18].

123

466

J Netw Syst Manage (2011) 19:448–471

Table 3 Publicly known
system parameters for vehicle i

Notation Description
e

e : G0  G0 ! G1 is a mapping from additive group G0 to
multiplicative group G1 .

g

g 2 EðF p is the generator of G0 .

p

order of the multiplicative group G1 .

h

h = gb where b 2 Zp for static attributes

f

f ¼ eðg; gÞa where a 2 Zp for static attributes

H

H : f0; 1gn ! f0; 1gn is a one-way function.

S si

the set of static attributes pre-assigned to vehicle i.

SKsi

the set of secret keys pre-assigned to vehicle i.

Certi

a certificate generated by the TA to prove the vehicle i.

We first define a function DecryptNodeðCT ; SK; xÞ that takes as input a
ciphertext CT , a private key SK, which is associated with a set S of attributes, and a
node x from the attribute tree T . If j is the attribute value of the node x and x is a leaf
node, then we can compute the following formulas for vehicle i:
DecryptNodeðCT ; SK; xÞ ¼
¼
¼

eðDi ; Cx Þ
eðD0i ; Cx0 Þ
eðgri  HðjÞrj ; gqx ð0Þ Þ
eðgrj ; HðjÞqx ð0Þ Þ
eðgri ; gqx ð0Þ Þ  eðHðjÞrj ; gqx ð0Þ Þ
eðgrj ; HðjÞqx ð0Þ Þ

¼ eðg; gÞri qx ð0Þ
We now consider the recursive case when x is a non-leaf node. The algorithm
DecryptNodeðCT ; SK; xÞ then proceeds as follows: For all nodes z that are children
of x, it calls DecryptNodeðCT ; SK; zÞ and stores the output as Fz. Let S x be an
arbitrary kx-sized set of child nodes z such that Fz 6¼ ?. If no such set exists then the
node was not satisfied and the function returns ?. Otherwise, compute
Y Dj;S0 ð0Þ
Fz x ;
Fx ¼
z2S x

¼

Y

ðeðg; gÞri qz ð0Þ Þ

Dj;S 0 ð0Þ
x

;

z2S x

¼

Y

ðeðg; gÞrqparentðzÞðindexðzÞÞ Þ

Dj;S0 ð0Þ
x

;

z2S x

¼

Y

r qx ðjÞDj;S 0 ð0Þ

eðg; gÞ i

x

;

z2S x

¼ eðg; gÞri qx ð0Þ ; ðusing polynomial interpolationÞ
where j = index(z) and S 0x ¼ findexðzÞ : z 2 S x g. We define the Lagrange coefficient Di;S for i 2 Zp and a set S, of elements in Zp :

123

J Netw Syst Manage (2011) 19:448–471

Di;S ðxÞ ¼

467

Y xj
:
ij
ðj2S;j6¼iÞ

The decryption algorithm begins by calling the DecryptNode function on the root
node R of the tree T. If the tree is satisfied by S we set f ¼ DecryptNodeðCT ; SK; RÞ ¼
eðg; gÞri qR ð0Þ ¼ eðg; gÞri s : The algorithm decrypts by computing:
Ce  DecryptNodeðCT ; SK; RÞ
eðC; Di Þ
as
k  eðg; gÞ eðg; gÞri s
¼
eðhs ; gðaþri Þ=b Þ
k  eðg; gÞas eðg; gÞri s
¼
eðgbs ; gðaþri Þ=b Þ

DecryptCipherðCT ; SK; RÞ ¼

ð2Þ

¼ k:

Appendix 2: Integration of Policy Trees
The detailed ABE key generation, encryption and decryption algorithms are
described in Appendix 9. Here, we just preset how to use them at the functional
level to describe our solutions. Using dynamic and static attributes, a vehicle can
construct versatile policies.
In Fig. 9, we present the ways to combine static and dynamic attributes, where
s tree and d tree represent policy trees formed by static and dynamic attributes,
respectively. Combining two trees side-by-side is shown in Fig. 10a. Using XOR
operator, we can derive the DEK k ¼ kd  ks . In Fig. 10b, c, we present two ways to
combine two trees in a top-down fashion. The intersection of two trees is a
combined node by integrate a leaf node in the upper tree and the root of the lower
tree. In Fig. 10d, we present an example of combining multiple static and dynamic
trees. The critical issue of combining multiple trees in a top-down fashion is how to
form a combined node from two set of attributes used for different system
parameters.
In Fig. 10, we present a method to make a combined node from two policy
trees: PT 1 and PT 2 , where the notations are presented in Table 4 of Appendix 1.
The ciphertexts produced by PT 1 and PT 2 is presented as follows:
CT 1 ¼(hPT 1 ; Ce ¼ kfs ; C ¼ hs ; 8j 2 S 1
j is not combined;
Cj ¼ gqj ð0Þ ; Cj0 ¼ HðjÞqj ð0Þ i;
:
j is combined:
C^j ¼ gqj ð0Þ  k0 ; C^j0 ¼ HðjÞqj ð0Þ  k0 i;
CT 1 is created by checking if a node in PT 1 is a combined node. If a node is not a
combined node, then the ciphertext component is computed using the normal procedure specified in the Encrypt protocol. If a node is a combined node, then the
Encrypt protocol needs to use a masking value k0 (a.k.a., one-time pad) randomly
selected to encrypt the ciphertext components Cj and C0 j. Once CT 1 is computed, the

123

468

J Netw Syst Manage (2011) 19:448–471

(a)

(b)

(c)

(d)

Fig. 9 Integration of multiple trees

Fig. 10 Integration a policy
tree to a node

Encrypt protocol needs to use the masking value k0 as the encrypted message to
construct CT 2 using a different set of public parameters following the procedure of
Encrypt protocol:
0

0

CT 2 ¼ hPT 2 ; Ce ¼ k0 fs ; C ¼ hs ; 8j 2 S 2 : Cj ¼ gqj ð0Þ ; 8j 2 S 2 : Cj0 ¼ HðjÞqj ð0Þ i:
Combining CT 1 and CT 2 , we have the integrated ciphertext:
CT ¼ hCT 1 ; CT 2 i:
The decryption procedure is straightforward. A ciphertext receiver first needs to
use the Decrypt protocol to decrypt the masking value k0 in CT 2 ; and then it
performs the following bit-wise XOR operations
Cj ¼ C^j  k0 and C0j ¼ C^0j  k0
to recover the masked values Cj and C0j in CT 1 . Finally, the receiver can use Decrypt
protocol again to decrypt the DEK encrypted in CT 1 . We must note that the system
parameters used in two decryption procedures are different. When there are multiple

123

J Netw Syst Manage (2011) 19:448–471

469

Table 4 CP-ABE protocols
Protocol 1 Setup
1. Construct bilinear map e : G0  G0 ! G1 of prime order p with a generator g;
2. Choose random numbers a; b 2 Zp;
3. Calculate the system public key PK ¼ he; G0 ; G1 ; H; g; h ¼ gb ; f ¼ eðg; gÞa i and private master key
MK ¼ hb; ga i, where H : f0; 1g ! G0 .
Protocol 2 KeyGen ðMK; SÞ
For user i ¼ 1; . . .; n:
1. Choose random numbers ri and rj 2 Zp 8j 2 attribute set S;
2. Calculate SKi ¼ hDi ¼ gðaþri Þ=b ; 8j 2 S : Di;j ¼ gri HðjÞrj ; D0i;j ¼ grj i.
Protocol3 Encrypt ðPK; k; PT Þ
1. Create access tree PT ;
2. Choose polynomial qx ð0Þ 8x 2 PT ;
3. Starting from root R of PT , choose DEK k 2 Zp and set qR(0) = s where R is the root of PT ;
4. S is the set of leave nodes of PT , calculates cipher text CT
CT ¼ hPT ; Ce ¼ kfs ; C ¼ hs ; 8j 2 S : Cj ¼ gqj ð0Þ ; 8j 2 S : Cj0 ¼ HðjÞqj ð0Þ i;
Protocol 4 Decrypt ðCT ; SKÞ
eðD ;C Þ

ri qx ð0Þ
x
; 8x 2 PT ;
1. DecryptNodeðCT ; SK; xÞ ¼ eðDi;x
0 ;C 0 Þ ¼ eðg; gÞ
i;x

x

2. Using a recursive procedure and DecryptCiphter method (2), compute the DEK
eeðg;gÞri s
DecryptCipherðCT ; SK; RÞ ¼ CeðC;D
¼ k.
iÞ
For detailed descriptions on generations of private keys SK, ciphertext CT , and function DecryptNode,
please refer to [18]

combined nodes, the above described decryption procedure will be repeated until a
message receiver can successfully reach the root and derive the DEK.

References
1. Hubaux, J., Capkun, S., Luo, S.: The security and privacy of smart vehicles. Secur. Privacy Mag.
IEEE 2(3), 49–55 (2004)
2. Gerlach, M., Festag, A., Leinmuller, T., Goldacker, G., Harsch, C.: Security architecture for
vehicular communication. In: Proceedings of the 5th International Workshop on Intelligent Transportation (WIT), March (2007)
3. Papadimitratos, P., Buttyan, L., Hubaux, J.P., Kargl, F., Kung, A., Raya, M.: Architecture for secure
and private vehicular communications. In: Proccedings of the 7th International Conference on ITS
Telecommunications (2007)
4. Doetzer, F.: Privacy issues in vehicular ad hoc networks. In: Proceedings of Workshop on Privacy
Enhancing Technologies, Cavtat, Croatia. Springer, Berlin (2005)
5. Freudiger, J., Raya, M., Félegyházi, M., Papadimitratos, P., Hubaux, J.: Mix-zones for location
privacy in vehicular networks. In: Proceedings of WiN-ITS (2007)
6. Calandriello, G., Hubaux, J., Lioy, A.: Efficient and robust pseudonymous authentication in VANET.
In: Proceedings of the Fourth ACM International Workshop on Vehicular ad hoc Networks,
pp. 19–28. ACM Press, New York (2007)
7. Raya, M., Hubaux, J.: Securing vehicular ad hoc networks. J. Comput. Secur. 15(1), 39–68 (2007)

123

470

J Netw Syst Manage (2011) 19:448–471

8. Zhang, C., Lin, X., Lu, R., Ho., P.H.: RAISE: An efficient RSU-aided message authentication scheme
in vehicular communication networks. In: Proceedings of IEEE International Conference on Communications (ICC) (2008)
9. Zhu, H., Lin, X., Lu, R., Ho, P.H., Shen, X.: AEMA: An aggregated emergency message authentication scheme for enhancing the security of vehicular ad hoc networks. In: Proceedings of IEEE
International Conference on Communications (ICC) (2008)
10. Hur, J., Park, C., Yoon, H.: An efficient pre-authentication scheme for IEEE 802.11-based vehicular
networks (2007)
11. Gerlach, M., FOKUS, F.: Trust for vehicular applications. In: Proceedings of the Eighth International
Symposium on Autonomous Decentralized Systems (ISADS), pp. 295–304 (2007)
12. Raya, M., Papadimitratos, P., Aad, I., Jungels, D., Hubaux, J.: Eviction of misbehaving and faulty
nodes in vehicular networks. Select. Areas Commun. IEEE J. 25(8), 1557–1568 (2007)
13. Raya, M., Papadimitratos, P., Gligor, V., Hubaux, J., EPFL, S.: On data-centric trust establishment in
ephemeral ad hoc networks. In: Proceedings of IEEE Infocom (2008)
14. Yan, G., Choudhary, G., Weigle, M., Olariu, S.: Providing VANET security through active position
detection. In: Proceedings of VANET’07 (2007)
15. Boneh, D., Franklin, M.: Identity-based encryption from the Weil pairing. SIAM J. Comput. 32(2),
586–615 (2003)
16. Goyal, V., Pandey, O., Sahai, A., Waters, B.: Attribute-based encryption for fine-grained access
control of encrypted data. In: Proceedings of the 13th ACM Conference on Computer and Communications Security, pp. 89–98. ACM Press, New York (2006)
17. Shamir, A.: How to share a secret. Commun. ACM 22(11), 612–613 (1979)
18. Bethencourt, J., Sahai, A., Waters, B.: Ciphertext-policy attribute-based encryption. In: Proceedings
of the 28th IEEE Symposium on Security and Privacy (Oakland) (2007)
19. Hong, X., Huang, D., Gerla, M., Cao, Z.: Sat: Building new trust architecture for vehicular networks.
In: Proceedings of the 3rd ACM International Workshop on Mobility in the Evolving Internet
Architecture (MobiArch) (2008)
20. Huang, D., Verma, M.: ASPE: Attribute based secure policy enforcement for data access control in
vehicular ad hoc networks. Ad Hoc Networks J. (Special Issue of Privacy & Security in WSNs)
(2009)
21. Burns, J., Cheng, A., Gurung, P., Rajagopalan, S., Rao, P., Rosenbluth, D., Surendran, A., Martin Jr,
D.: Automatic management of network security policy. In: DARPA Information Survivability
Conference and Exposition (DISCEX), vol. 2 (2001)
22. Dulay, N.D.N.: The ponder policy specification language. In: Lecture Notes in Computer Science.
Springer, Berlin, pp. 18–38 (2001)
23. Hoagland, J., Pandey, R., Levitt, K.: Security policy specification using a graphical approach.
Technical Report cs/9809124 (1998)
24. Mukhi, N., Plebani, P.: Supporting policy-driven behaviors in web services: experiences and issues.
In: Proceedings of the 2nd International Conference on Service Oriented Computing, pp. 322–328.
ACM, New York (2004)
25. Paul, R.: DoD towards software services. In: 10th IEEE International Workshop on Object-Oriented
Real-Time Dependable Systems (WORDS), pp. 3–6 (2005)
26. Tsai, W., Wei, X., Paul, R., Chung, J., Huang, Q., Chen, Y.: Service-oriented system engineering
(SOSE) and its applications to embedded system development. Service Orient. Comput. Appl. 1(1),
3–17 (2007)
27. Tsai, W., Zhou, X., Wei, X.: A policy enforcement framework for verification and control of service
collaboration. Inf. Syst. E-Bus. Manage. 6(1), 83–107 (2008)
28. Chadha, R., Cheng, H., Cheng, Y., Chiang, J., Ghetie, A., Levin, G., Tanna, H.: Policy-based mobile
ad hoc network management. POLICY (2004)
29. Chiang, C., Chadha, R., Cheng, Y., Levin, G., Li, S., Poylisher, A., Technologies, T.: A novel
software agent framwork with embeded policy control. In: MILCOM, vol. 5, p. 2863 (2005)
30. Chiang, C., Demers, S., Gopalarishnan, P., Kant, L., Poylisher, A., Cheng, Y., Chadha, R., Levin, G.,
Li, S., Ling, Y., et al.: Performance analysis of drama: a distributed policy-based system for manet
management. In: Military Communications Conference (MILCOM), pp. 1–8 (2006)
31. Singh, J., Vargas, L., Bacon, J., Moody, K.: Policy-based information sharing in publish/subscribe
middleware. In: Policies for Distributed Systems and Networks, 2008. IEEE Workshop on POLICY
2008, pp. 137–144 (2008)

123

J Netw Syst Manage (2011) 19:448–471

471

32. Anastasi, G., Borgia, E., Conti, M., Gregori, E.: Wi-Fi in ad hoc mode: a measurement study.
In: Proceedings of IEEE Annual Copnference on Pervasive Computing and Communications
(PERCOM), pp. 145–154 (2004)
33. Cseh, C.: Architecture of the dedicated short-range communications (DSRC) protocol. IEEE
Vehicular Technology Conference (VTC) 3, 2095–2099 (1998)
34. Liu, J., Hong, X., Zheng, Q., Tang, L.: Privacy-preserving quick authentication in fast roaming
networks. In: Proceedings of IEEE Conference on Local Computer Networks (LCN). Workshop on
Network Security, Tampa, Nov. 14–17 (2006)
35. Papadimitratos, P., Kung, A., Hubaux, J., Kargl, F.: Privacy and identity management for vehicular
communication systems: a position paper. In: Proceedings of Workshop on Standards for Privacy in
User-Centric Identity Management, Zurich, Switzerland, July (2006)
36. Holzmann, G.: The model checker SPIN. IEEE Trans. Softw. Eng. 23(5), 279–295 (1997)
37. Nii, H.P.; Stanford University: CA Knowledge Systems Lab Blackboard Systems. Department of
Computer Science, Stanford University (1986)
38. Tsai, W., Wei, X., Chen, Y., Paul, R.: A robust testing framework for verifying web services by
completeness and consistency analysis. In: IEEE International Workshop on Service-Oriented
System Engineering (SOSE), pp. 159–166
39. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the Weil pairing. In: Proceedings of the
Asiacrypt 2001, vol. 2248, pp. 514–532. LNCS (2001)
40. Sampigethaya, K., Huang, L., Li, M., Poovendran, R., Matsuura, K., Sezaki, K.: CARAVAN: providing location privacy for VANET. In: Proceedings of Embedded Security in Cars (ESCAR) (2005)
41. Pairing-based cryptography library. http://crypto.stanford.edu/pbc/
42. Crpto?? library 5.5.2: A free C?? class library of cryptographic schemes. http://www.cryptopp.com/
43. NS-2: http://www.isi.edu/nsnam/ns/
44. Saha, A., Johnson, D.: Modeling mobility for vehicular ad-hoc networks. In: Proceedings of the 1st
ACM international workshop on Vehicular ad hoc networks, pp. 91–92. ACM, New York (2004)

Author Biographies
Dijiang Huang received his B.S. degree from Beijing University of Posts & Telecommunications, China
1995. He received his M.S., and Ph.D. degrees from the University of Missouri-Kansas City, in 2001 and
2004, respectively. He is an Assistant Professor in the School of Computing Informatics and Decision
Systems Engineering (SCIDSE) at the Arizona State University. His current research interests are
computer networking, security, and privacy. He is a recipient of Office of Naval Research (ONR) Young
Investigator Award 2010.
Wei-Tek Tsai received his S.B. in Computer Science and Engineering from MIT, Cambridge, MA 1979.
He received his M.S. and Ph.D. in Computer Science from University of California at Berkeley, in 1982
and 1985, respectively. He is a Professor of Computer Science and Engineering in the School of
Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ. His
research interests are software engineering, service-oriented computing, education, testing, and
simulation.
Yi-hsin Tseng received her M.S in Computer Science and Engineering from Arizona State University,
USA 2009. Her research interests are software engineering and service-oriented computing.

123

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

1177

A Survey of Mobile VPN Technologies
Abdullah Alshalan, Student Member, IEEE, Sandeep Pisharody, Student Member, IEEE,
and Dijiang Huang, Senior Member, IEEE

Abstract—Virtual private network (VPN) is the traditional
approach for an end-to-end secure connection between two endpoints. Most existing VPN solutions are intended for wired networks with high-speed, highly reliable connections. In a mobile
environment, these network connections are less reliable. This
affects traditional VPN performance resulting in frequent application failure, data loss, and reduced productivity. Mobile VPN
bridges the gap between what users and applications expect from
a wired network and the realities of mobile computing. In this survey, we provide a taxonomy of VPN designs, present a study of
existing mobile VPN solutions, and highlight the advantages and
disadvantages and applications of these methods.
Index Terms—Virtual private network, VPN, mobile VPN,
MVPN.

I. I NTRODUCTION

G

LOBAL computing industry is quickly evolving toward
having powerful cloud computing resources aimed at
providing services over the Internet, with mobile devices behaving as the user interface into this cloud. In such an environment,
having a way to securely connect these mobile terminals to
a cloud computing resource like MobiCloud [1] is of great
importance, not just for information assurance and protection
of intellectual property, but often for regulatory and compliance
reasons.
Classical Virtual Private Network (VPN) connections establish secure connections between a remote user and a home
network by encrypting packets sent though the Internet rather
than building a true private network [2]. These VPN connections however, are best suited for stationary devices which,
unlike mobile devices tend to have a stable network connection [3]. Most mobile devices are susceptible to intermittent
connection loss while switching from one network to another
or experiencing a gap in coverage [4]. For example, a cellular phone might switch between WiFi and 4G, or between

Manuscript received October 13, 2014; revised August 11, 2015; accepted
September 29, 2015. Date of publication November 2, 2015; date of current
version May 20, 2016. This work was supported in part by the NSF Secure
and Resilient Networking (SRN) Project (1528099), in part by the NATO
Science for Peace and Security Multi-Year Project (MD.SFPP 984425), and
in part by the ONR YIP Project (N00014-10-1-0714). The work of A. Alshalan
was funded by a scholarship from King Saud University. The work of S.
Pisharody was supported by a scholarship from the NSF CyberCorps Program
(NSF-SFS-1129561).
The authors are with the School of Computing, Informatics, and
Decision Systems Engineering, Arizona State University, Tempe, AZ
85281 USA (e-mail: abdullah.alshalan@asu.edu; sandeep.pisharody@asu.edu;
dijiang.huang@asu.edu).
Digital Object Identifier 10.1109/COMST.2015.2496624

one WiFi and another. Such connection losses or connection
changes can cause the VPN connection to break causing the
mobile applications utilizing the VPN to either timeout or
crash.
Given the ever increasing popularity of remote workers and
Bring-Your-Own-Devices (BYOD) in work places along with
the ubiquitous presence of wireless networks that these devices
have access to, it is prudent to have a mobile VPN solution that
can provide a VPN experience that does not require the user to
reset and reconfigure the VPN session upon switching between
networks. According to a survey done by Dimension Data
[5], 79% of over 1600 surveyed IT and security professionals
ranked mobility as a top priority. In the same survey, 71% of the
respondents expressed that data security is the major concern of
mobility. While there have been several mobile VPN protocols
studied and several commercial mobile VPN solutions in the
market, to the best of our knowledge, there has been no survey
done that compares these protocols and solutions against each
other. Saha et al. [6] provides a survey about several mobility
protocols that support micromobility and macrombility to the IP
layer. Their survey, however, does not pertain to mobile VPNs
and only covers mobility support in the IP layer. Subsequent
work in application layer mobility and mobility based on Host
Identity Protocol are not included in that survey. Similar argument can be made against the survey done by Akyildiz et. al.
[7] which survey layer 3 and layer 2 mobility management protocols in IP wireless networks. Zhu et al. [8] provides a survey
of mobility support in the Internet, however this survey is more
generalized than our mobile-VPN-specific survey.
The goal of this survey is to explicitly state requirements
from a mobile VPN, study the various technologies that were
tailored to a mobile environment, compare their characteristics, strengths, weaknesses and applications; with an emphasis
on security and robustness in the context of a mobile device
with frequent network disruption/handover. In Section II we go
over some of the background information including network
nomenclature, underlying network protocols and classification methodologies commonly used for VPNs. We present in
Section III criteria for classification of mobile VPN. Section IV
lists the requirements that we believe are essential for a mobile
VPN. In Section V we discuss protocols that we believe are
the building blocks for an effective mobile VPN solution. In
Section VI we compare and contrast these technologies. We
discuss some commercial mobile VPN products available in
the market with two case studies in Section VII. We conclude
this survey by discussing open issues in Section VIII before we
present a summary in Section IX. For the reader’s convenience
to navigate this manuscript, we provide Table I serving as a
road-map for this survey.

1553-877X © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

1178

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

TABLE I
ROAD -M AP OF PAPER L AYOUT

B. Network Components
Several network components are common to most VPN
solutions discussed in this survey. They are briefly discussed
here:
• A mobile node (MN) is any network device that is not
tethered to one static network. In most cases, the MN can
physically move around. However, a node that has multiple network interfaces and has the capability to switch
between them is for all intents considered to be a MN.
Common examples of a MN are a cellular phone or a
tablet. Since MN is typically on the move and any time
it strays too far from the location of its access point, it
switches to another network for its connectivity, thereby
obtaining a new IP address.
• The Network which the MN originally joins the network
is called the Home Network.
• The Home Agent (HA) is a router on a MN’s home network. It maintains information about the MN’s location at
all times, and is responsible for delivering packets to the
MN when it is away from its home network.
• The Foreign Agent (FA) is a router in the MN’s visited
network that provides routing services to the MN in the
visited network.
• Correspondent Node(s) (CN) is a node with or without any mobile functionality, which communicates with
the MN.

C. Protocols
II. BACKGROUND
In this section we provide background information in an
attempt to make this survey more comprehensive and selfcontained. In the remainder of this section we briefly define
VPNs. After that, we provide definitions of network components that are used in mobile VPN solutions. We then provide a
technical background section discussing, briefly, the protocols
that are used in mobile VPN solutions and technologies. We
conclude the section with a discussion about VPN classification
for comprehensiveness.

A. Virtual Private Network (VPN)
VPNs are networks built as an overlay on the public infrastructure of one or more providers, so as to permit access
between a defined set of devices [9]. A VPN can be simply
thought to be an authenticated and encrypted tunnel to serve
as a virtual leased line over a shared public infrastructure [9],
[10]. According to the strictest definitions, a VPN does not have
to ensure encryption of data. Per the Virtual Private Network
Consortium (VPNC), a secure VPN is a user encrypted and
authenticated connection a) between two segments of the same
private network, b) from a computer to a private network, or
c) between two computers [11]. Since VPN is between authorized users/devices, strong access control is essential for a
secure VPN [12]. As is common in the industry, this survey
will use VPN and secure VPN interchangeably.

This section will briefly present the different protocols that
constitute the basis of the mobile VPN solutions discussed in
Section V.
1) Point-to-Point Protocol (PPP): PPP is used to provide a virtual direct link over a multitude of physical
mediums between two endpoints allowing encapsulation
of network-layer datagrams into frames regardless of the
nature of the physical medium. Authentication in PPP is
achieved through Password Authentication Protocol (PAP) or
Challenge-Handshake Authentication Protocol (CHAP) [13],
[14]. Encryption can be added on by configuring PPP
Encryption Control Protocol (ECP) [15] or by securing the data
using a higher-layer protocol like IPsec.
2) Layer 2 Tunneling Protocols (L2TP): There are two
main variations of the L2TP protocol: L2TPv2 and L2TPv3.
L2TPv2 is a data link tunneling protocol used to tunnel multiple PPP sessions. Multiple PPP sessions are differentiated by
using a session ID. L2TPv3 can be used to tunnel not only
PPP frames but also IP packets. This eliminates the overhead of
encapsulating IP packets within PPP frames [16]. Both L2TPv2
and L2TPv3 provide two channels within the tunnel: a reliable
control channel and an unreliable data channel [16], [17]. L2TP
does not provide any security features and relies on protocols
like IPsec for message authentication and encryption [18].
3) Generic Routing Encapsulation (GRE): GRE is a protocol used to tunnel an arbitrary network layer protocol over
any network protocol [19]. When encapsulating protocol X over
protocol Y, GRE takes a packet in format X and considers it

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

to be the payload packet. It first encapsulates this packet in a
GRE packet and then encapsulates this GRE packet in protocol
Y, which is considered the delivery protocol. RFC2890 extends
the GRE header to allow multiplexing different packet flows
within one GRE tunnel with in-order delivery of packets [20].
This allows GRE to encapsulate PPP frames [18].
4) IP Encapsulation Within IP (IPIP): IP-in-IP or simply IPIP is defined in RFC2003 to allow for encapsulating
an IP packet within another IP packet [21]. A tunnel can
be established between two endpoints, an encapsulator and a
decapsulator, in order to tunnel packets going from a source in
the network of the encapsulator to a destination in the decapsulator’s network. The inner IP header, added by the source, will
contain the original source and destination IP addresses. The
outer IP header, added by the encapsulator, will contain its IP
address as the source IP and the decapsulator’s IP address as the
destination IP. It is then the responsibility of the decapsulator to
process the IPIP packet and forward the original (inner) packet
to the destination. Minimal IPIP was introduced in RFC2004 in
response to the problem of the overhead of adding another IP
header especially to packets with small payload [22].
5) Internet Protocol Security (IPsec): IPsec consists of
guidelines for a series of protocols that secure communications
at the network layer of the OSI stack [23]. Originally developed as a security extension for IPv6, IPsec was later adapted
into working with IPv4; making it well-suited for use in both
platforms [9].
The following protocols are commonly used as part of the
IPsec suite:
• Encapsulation Security Payload (ESP) provides data
source authentication, data integrity, data confidentiality
and anti-replay protection of IP packets by encapsulating the data to be protected between the ESP header and
trailer [24], [25].
• Authentication Header (AH) supports data source authentication and data integrity, but does not offer any form of
confidentiality. This makes it a lot simpler than ESP, but
also less commercially attractive. AH authenticates the
entire datagram, unlike ESP, which does not authenticate
the leading IP header or any other information that comes
before the ESP header [9].
• Internet Key Exchange (IKE) protocol for negotiating
IPsec connection settings and authenticating the end
points. It defines the security parameters, negotiates
keys, and manages the IPsec communication channels
[10], [26].
IPsec can be implemented in two different modes: Transport
mode, and Tunnel mode. In the former, the IP payload is
encrypted, while the header is left intact. In Tunnel mode,
the entire IP packet including the headers are encrypted, and
encapsulated within new IP headers.
6) Transport Layer Security (TLS): TLS is a protocol
designed to provide security to applications communicating in a
client-server model. It is an upgrade to the commonly used SSL
protocol. Unlike IPsec, TLS resides between the Application
layer and the transport layer in the TCP/IP stack. Therefore,
it provides confidentiality and integrity only to the application data whereas IPsec, depending on the selected security

1179

Fig. 1. Mobile IP.

protocol, extends its security features to both the transport layer
header and the IP header [27].
Wireless TLS (WTLS) is an optimized version of the regular TLS protocol for a low-bandwidth wireless network with
substantial latency [28]. WTLS provides compressed data
structures to reduce packet sizes; and uses a new certificate
format that compresses the TLS certificates. WTLS enhances
TLS greatly by giving the client and server the ability to
resume a previous session instead of negotiating new security
parameters, thereby enhancing mobility.
7) Mobile IP (MIP): MIP is a popular protocol for extending mobility into IP. It enables session continuity when an
end point travels among heterogeneous networks and ensures
this mobility is transparent to applications [29]. MIP is thus
ideal for providing mobile VPN connectivity independent of
the underlying access technology.
The MN has two IP addresses: care-of address (CoA) and
home address. The home address is constant and used to
communicate with the CN. The CoA is a temporary address
assigned by the visited network, and is used to build a tunnel
from the HA to MN. The original packet is the encapsulated in
the IP packet with CoA [29]. The general structure is shown in
Figure 1.
Packets sent to the home address of the MN are intercepted
by the HA (Step 1). The HA tunnels the packets to the MN (Step
2) since it is aware of the MN’s location. After decapsulating
the packet, the MN can send all further communication directly
to the CN (Step 3). As long as the MN notifies the HA of its new
CoA when there is a change in location, this process provides
strong authentication technique for the MN [29]. However,
security in MIP has two major limitations: a) Outgoing packets from the HA to the MN may be dropped by filters in visited
network because of the use of the home address as the source
address; and b) problems arise when the FA is not capable of
reading a MN’s request to its HA. This prevents the set up of
the tunnel resulting in connectivity loss [9].
8) Session Initiation Protocol (SIP): SIP is an applicationlevel signaling protocol used for controlling sessions such as
voice and video calls. It contains design elements that are based
on a request/response transaction model, wherein each transaction consists of a client request and server response of a
particular method or function. SIP uses most of the header
fields, encoding rules and status codes of HTTP, providing a

1180

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

Fig. 2. Mobile VPN classification taxonomy.

readable text-based format. SIP works as the signaling portion
of several other protocols [30].
Each resource of a SIP network is identified by a uniform
resource identifier (URI), based on the general standard syntax
also used in Web services and e-mail. The URI scheme used
for SIP is sip : username : password@host : port. If secure
transmission is required, the scheme sips : is used as the prefix
instead of sip : to ensure that each hop over which the request
is forwarded must be secured using Transport Layer Security
(TLS) [30].
9) Real-Time Transport Protocol (RTP): RTP is a application layer protocol designed to provide end-to-end network
transport functions suitable for applications transmitting realtime data, such as audio and video over multicast or unicast
network services regardless of what the underlying network
and transport protocols are [31]. Secure RTP (SRTP) intends to
provide encryption, message authentication and integrity, and
replay protection to the RTP data [32].

D. VPN Classification
Over the years, there have been several attempts to classify
VPNs in order to gain a better understanding of their capabilities and application. We discuss a few of them briefly here,
before picking a classification criteria that suits mobile VPNs.
• Mobility - Using mobility as a classification criteria,
VPNs can be divided into Stationary VPNs and Mobile
VPNs. As the name suggests, stationary VPNs are
designed to work for nodes that do not move during a
VPN session, such as a PC or a router; with mobile VPNs
on the other hand, being able to support mobility for a MN
whose IP may change periodically due to its geographic
motion or due to it switching between available networks.
• Deployment - From a network architecture perspective,
VPNs can be categorized into the following groups:
a) Site-to-site VPN; b) Remote access VPN; and c) Peerto-peer VPN. Site-to-site VPNs are used to establish a
tunnel between two VPN gateways in order to virtually
connect two separate networks such that resources in
both networks can be available at the other end. Remote
access VPNs are set up to allow remote users to connect

to a private network through a VPN gateway. Peer-toPeer VPNs are used to enable nodes in a P2P network
to communicate amongst each other securely. P2P VPNs
can be set up either in a centralized or a decentralized
architecture [33].
• OSI Layer - Depending on what layer of the OSI stack the
VPN service is provided on, VPNs can be divided into:
a) Layer 1 VPN; b) Layer 2 VPN; and c) Layer 3 VPN.
Layer 1 and Layer 2 VPNs provide the ability to create
multiple virtual networks over the same physical network
or over Asynchronous Transfer Mode (ATM) or Frame
Relay (FR) circuits [34], [35]. Traditional VPNs such as
ATM and FR networks, enable security at the Data Link
layer (Layer 2) of the TCP/IP stack [9]. These solutions
were not designed to support mobility of the end points
[36]. Layer 3 VPN protocols such as GRE, IPsec, IPIP
and BGP/MPLS offer the VPN end points the ability to
route IP traffic between them [36]. Since mobile communications introduce problems because traffic is generally
to and from a MN, in their basic forms, L3VPNs are not
very forgiving of mobility [12].
III. M OBILE VPN C LASSIFICATION C RITERIA
Based on their inherent characteristics and use cases, there
are several criteria to classify mobile VPN technologies. In this
Section, we introduce and describe a few such classification criteria in detail. We also provide a mobile VPN taxonomy based
on these criteria illustrated in Figure 2, and we summarize the
classification criteria in Table II.
A. Classification Criteria - Tunnel Establishment
VPNs can be categorized into the following three groups
based upon tunnel establishment criteria: a) Voluntary VPN;
b) Compulsory VPN; and c) Chained VPN tunnel.
1) Voluntary VPN: In a voluntary VPN, an end-to-end tunnel between a remote node and a VPN gateway is setup
voluntarily or as dictated by need of the remote user. In this
model, no intermediate nodes or entities are involved. The
remote node has to have certain capabilities like IPsec, TLS

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

1181

TABLE II
S UMMARY OF M OBILE VPN C LASSIFICATION C RITERIA

etc. For example, when a MN sets up a voluntary VPN connection, the service provider (wireless carrier) is unaware of
this tunnel. The remote user (whether stationary or mobile)
can establish said VPN connection to any private network after
gaining Internet access from the service provider. This model
has the following advantages and challenges [18]:
Advantages:
• It is a simple client/server model of VPN. A tunnel can
be established with relative ease as long as the client has
access to a public IP network such as the Internet and
a VPN client software, and the server has a VPN server
software.
• The service provider and any intermediate nodes do not
have to be party to setup the VPN. Once the tunnel is
setup, the intermediate nodes do not have visibility into
the encrypted traffic. As a result, they do not have to be
trusted.
• Since the intermediate nodes have no visibility into
end-to-end traffic, there is no need for Service Level
Agreements (SLA) or any other legal documents ensuring
the confidentiality of the data.
Challenges:
• The remote end requires a publicly routable IP address
which can be a challenge given the limitation of available public IPv4 addressing. However, to overcome this
challenge, voluntary VPNs can utilize NAT or IPv6. It
is important to note that the NAT solution is inherently
incompatible with certain designs of IPsec, and careful
attention needs to be given to the network design before
attempting to use such a solution.
• Any kind of traffic prioritizing and shaping using Qualityof-Service (QoS) by the service provider would not work
since QoS would require packet inspection.
• Since additional encapsulation is required to setup a voluntary VPN, setting up and maintaining a VPN over

a lossy wireless channel may lead to shoddy customer
experience.
2) Compulsory VPN: A VPN established between the service provider and a private network, which is used only when
the remote user wants to access resources in the private network
is termed to be a compulsory VPN, simply because the user is
forced to use the tunnel between the carrier and the private network’s gateway. In this model, the MN does not need to support
any tunneling or security protocols such as IPsec or TLS since
it is completely unaware of the tunneling. The advantages and
challenges of this model are as follows [18]:
Advantages:
• No encapsulation is needed between the MN and the
service provider. The overhead of encapsulation and
encryption is eliminated especially over lossy radio link.
• No VPN support needed in the MN. This would save the
MN’s resources such as battery and CPU.
• Ability to provide QoS to differentiate level of service for
voice, video and data services.
Challenges:
• The lack of an end-to-end VPN connection means that
the data is partially transmitted through an insecure data
channel, and is thus open to snooping.
• The service provider has to be trusted since the radio link
connection is terminated at the service provider. Even if
some encryption is used over the radio link, traffic will be
decrypted before it is encapsulated and forwarded to the
private network through the compulsory VPN tunnel.
• There is a need for an SLA and the service provider has
to be involved, thereby leading to additional costs. This
may make it unsuitable for small businesses and academic
institutes.
3) Chained VPN Tunnel: The chained VPN tunnel model
uses concatenated tunnels provided by the service provider but
extends it past the base station to the remote user. Such a

1182

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

model allows for QoS and traffic shaping. However, the service
provider still has to be trusted. This model however eliminates
any insecure data channels that exist in the compulsory VPN
model [18].
B. Classification Criteria - Layer of Mobility
Mobile VPNs can be classified based on which layer of the
TCP/IP stack is mobility taken care of. Based on this criteria
mobile VPNs can be categorized into: a) Mobile VPNs based on
network layer mobility. These mobile VPNs address the mobility problem in the network layer. They solve the problem of
IP address change by network level means such as redirecting traffic to a HA in Mobile IP and support for mutli-homing
MOBIKE. b) Mobile VPNs based on application layer mobility.
These mobile VPNs support mobility by creating session binding above the IP layer so it is not affected by IP address changes.
SIP-based mobile VPNs and TLS-based VPNs are examples of
this category.
C. Classification Criteria - Security Protocol
Security is an essential part of VPNs. Encryption, authentication and message integrity provided by VPNs can be broadly
categorized into: a) protocols based on network layer security
such as IPsec; and b) protocols based on application layer security such as SRTP and SSL and its variants TLS, DTLS and
WTLS.
IPsec applies security to IP datagrams on network layer, so
there is IP address binding between the two endpoints of an
IPsec tunnel. However, application layer security protocol are
more suitable for mobility and more NAT-friendly since they do
not include IP addresses as part of the security association [37].
IV. M OBILE VPN D ESIGN R EQUIREMENTS
A mobile VPN is, by professional consensus, thought to have
the following requirements:
1) Seamless Network Roaming (SNR): When the MN performs a vertical handoff (MN uses a different network
interface such as switching from cellular interface to
WiFi) or horizontal handoff (MN switches from one
network to another while using the same medium; e.g.
switching from one WiFi network to another) and receives
a new IP, the VPN functionality should remain intact
without user involvement. In both scenarios, the physical
IP address for the VPN tunnel (outside address) changes.
2) Security: The mobile VPN should enforce a mechanism
for authenticating the user, providing encryption of the
data traffic along with integrity assurance.
In addition, several sources of the solutions studied make the
following demands of a mobile VPN solution:
3) Application Session Persistence (ASP): Open application
connections remain active when the network connection
changes or is interrupted, or when the user manually puts
the device in sleep mode.
4) Performance: Not all data needs to be encrypted. Split
tunneling can be employed so that data that is not

Fig. 3. VPN mobility scenario.

sensitive may be sent through unencrypted channel
enhancing the performance of the VPN as well as preserving MN battery. Moreover, encryption algorithms can
be chosen based on user requirements and device status, and may be done adaptively. Adaptive compression
techniques may also be applied. Additionally, it should
conserve system resources by providing location updates
proportional to mobility [38].
For the purpose of this survey, we assume that a mobile VPN
solution is required to maintain the VPN session between a
VPN client and a VPN server despite interruption of network
connectivity, or when the MN moves between networks and
obtains new IP addresses. Figure 3 shows how a MN connected to a home network can travel between networks, get
new network information and still appear to maintain the same
session from an application perspective. In essence, the main
goal with a mobile VPN solution is to provide the application
layer transparency to network layer disruptions so as to maintain independence of the end-to-end application sessions from
issues caused by mobility.
For conceptual models and design methodology of mobile
VPNs, the reader may find [10] useful.

V. M OBILE VPN T ECHNOLOGIES AND S OLUTIONS
Mobile VPN is a broad class of protocols that seek to deliver
secure IP mobility [3]. An ideal protocol would satisfy requirements set forth in Section IV. Of the several products and
protocols that seek to adapt VPNs for mobility, we study a few
different approaches. They are discussed in the remainder of
this section. Figure 4 shows a taxonomy of the mobile VPN
technologies discussed in this section. We also provide Table III
to compare these solutions.
A. Mobile VPN Through Network Mobility
In this section we discuss several mobile VPN technologies
that support mobility at the network layer.
1) Mobile IPv4 Based VPNs: This type of mobile VPN
relies on two protocols IPsec and MIPv4 explained in sections II-C5 and II-C7 respectively. A MN first obtains an IP
address for its Home Network and registers it with an HA.
When the MN roams and connects to a foreign network, it

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

1183

Fig. 4. Mobile VPN technologies and solutions taxonomy

obtains a new IP address and registers with a FA. As shown
in Figure 5, the FA establishes an IPsec tunnel between itself
and the HA and informs the HA that FA’s IP address is the new
CoA of MN1. All packets sent from a CN to MN1 go at first
to the HA which then send them to the FA though the IPsec
tunnel. The FA has the capability to realize which MN these
packets are destined to and therefore it will forward them to
MN1. This is the compulsory approach of this mobile VPN. A
voluntary approach is achieved by having the MN acting as its
own FA as the case for MN2 in Figure 5.
The IPsec tunnel is established between MN2 and the HA.
MN2 will register its newly obtained IP address with the HA.
Just like the compulsory approach, packets destined to MN2 has
to be routed to the HA first which causes the triangular routing
anomaly.
Authors in [39] present a benchmark for the performance of
authentication and encryption algorithms used in IPsec-based
mobile VPNs.
2) Mobile IPv4 With Two HA Based VPNs: Incorporating
MIP into IPsec based VPN gives rise to several technical issues.
When a MN moves away from its home network, it must establish an IPsec tunnel with the VPN gateway using the CoA it
received after moving. Since all packets including MIP messages are encrypted by IPsec, the FA cannot decrypt them,
thereby rendering it unable to relay the MIP messages [40].
This problem can be avoided by having a mechanism with two
HAs, one for internal and one for external networks [41]. The
MN would use the internal HA (i-HA) if it is in the home network and an external HA (x-HA) when it moves out of its home
network. This device adds another layer of MIP which is underneath IPsec as shown in Figure 6. Upon receiving a new CoA,
the IPsec tunnel will not have to be broken, and the FA would
be able to decrypt the messages as well. When the MN ventures
out to visit a network, it would follow a registration process as
in Figure 7.
This solution, proposed in IETF RFC 5265, has several merits. First, there is no modification required to the MIP and

IPsec standards. Modifications to the MN are slight [42]. The
solution, however, leads to problems determining: a) where the
x-HA should be placed; b) the trustworthiness of the x-HA;
c) how to protect traffic going to the x-HA; and d) the performance impact of having three extra headers to the payload [42].
Benenati et. al. [43] build on the work of Feder et. al. [44]
and use a variant of this IETF solution, along with multiple
tunneling protocol standards to offer a transport layer solution across 3G and WLAN. The proposed solution provides a
solution for mobility between interconnected WLAN and 3G
networks. The authors consider integration of a WLAN system with an existing 3G network either as a wireless Ethernet
extension (Tight internetworking) or as complementary to the
3G network (Loose internetworking), with the essential difference being the amount of shared infrastructure between the
3G network and the wireless providers. At a minimum, the
Authentication, Authorization, and Accounting (AAA) server is
shared between the two technologies. Further, in their solution,
the authors of [43] assume that the MN is intelligent enough
to engage the proper protocols while using a minimal set of
credentials for authentication, which are inherently different
for various 3G and WLAN technologies. The specifications in
IETF RFC 5265 can be adapted for VPN protocols other than
mobile IPsec, provided the MN has IPv4 connectivity with an
address suitable for registration. Instead of an IPsec gateway,
if an TLS gateway or SSH node was used, it could adapt into
mobile TLS or mobile SSH VPN connection [38].
In [45], Dutta et al. present a framework named Secure
Universal Mobility (SUM) that utilizes the dual HA concept.
Their framework suggests a make-before-break approach to
reduce the delay incurred while reconstructing the two MIP tunnels and the IPsec tunnel. Based on signal strength, a MN can
initialize the handover process before it actually moves from
one network to another. This includes activating the target interface and obtaining an IP from the target network. This approach
only works if the MN is in the range of both the current network
and the future network.

1184

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

TABLE III
C OMPARISON OF M OBILE VPN T ECHNOLOGIES

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

1185

Fig. 5. MIPv4 based VPN: MN1 utilizes a FA, MN2 acts is its own FA
Fig. 8. MIPv6 header

Fig. 6. Mobile IPsec packet format

Fig. 9. MPLS based mobile VPN

Fig. 7. Mobile IPsec registration

3) Mobile IPv6 Based VPNs: MIPv6 represents a logical
combination of IPv6 and MIP, with knowledge gained from the
development of MIP (or specifically MIPv4). MIPv6 shares a
lot in common with MIP, but naturally offers many improvements over MIP. IPv6 in its native state has features that support
mobility, such as the ability for a MN to use its CoA as the
source address along with carrying a home address in the IPv6
header. Since every node in an IPv6 network has the ability to
interpret this information, there is no longer any need to deploy
FA as used in MIP deployments [46]. The functions satisfied by
an FA in a MIP network, such as discovery and address configuration in foreign networks are not necessary since MNs can
operate in any location without any special support required
from its local router.
Figure 8 shows a sample header structure in a MIPv6 when
two MNs need to communicate with one another while in visited networks. Note the capability provided in an IPv6 header
to incorporate Extension Headers (EH) that can add multiple IP
addresses for mobile situations.
4) BGP/MPLS Based Mobile VPN: In a BGP/MPLS based
mobile VPN, the MN is registered and authenticated using a
Diameter server. The MN generates a MIP registration request
when it moves into a visited network [47]. In order to have

the registration request to be delivered to the Provider Network
server (PNS) in the home network, the address of VPN server
replaces the address of HA in the HA field of the MIP registration request message. The authors of [47] assume this address
to be pre-configured in the MN. A new field named Foreign
Customer Equipment (FCE) address is added to specify the
address of the MN’s gateway in the visited network so that the
PNS can determine the gateway serving the MN. Additionally,
in the extension field of the MIP registration request message,
the address of the visited network AAA is specified instead of
the home network.
When the FA receives the MIP registration request message,
it generates a message to the AAA in the visited network for
authentication. Upon successful authentication and authorization, the AAA sends a message to the PNS to obtain the address
of the HA for the MN. When the PNS receives this message,
it prepares an IPsec VPN between the visited network and the
provider. After establishing an IPsec tunnel between the PE and
the visited network CE, the PE inserts the mapping between the
address of the MN and the IPsec tunnel into the Virtual Routing
and Forwarding (VRF) table of the corresponding MPLS VPN.
The other PEs update their VRF table with the updated routing
information, and forward the information as determined by the
BGP/MPLS protocol. Figure 9 illustrates how a mobile VPN
user obtains access to a VPN from a visited network.
5) MOBIKE-Based VPNs: The IKEv2 Mobility and
Multihoming Protocol (MOBIKE) solves an inherent problem
with IKEv2 and IPsec when the IP address of a MN changes
[48]. MOBIKE provides mechanisms to enable MNs with
VPN connectivity using an IPsec tunnel mode to preserve the
Security Associations (SA) during a Layer 3 handoff [49].

1186

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

Fig. 10. NEMO network setup

With IKEv1 and IKEv2, the IPsec SAs are created implicitly
with the initial IP address of the MN. If the IP address changes,
the IPsec tunnel will be torn down and a new SA has to be
fully reestablished. MOBIKE enhances this by providing the
ability to create SAs (IKE SA and IPsec SA) that are associated with multiple IP addresses. It also provides the ability to
update such addresses without having to reestablish the SAs.
Such features are very suitable for MNs with multiple network
interfaces like cellular and WiFi. The initiator of the connection (usually the MN) and the responder (VPN Gateway) may
include one or more ADDITIONAL_IP4_ADDRESS and/or
ADDITIONAL_IP6_ADDRESS notification messages in
the IKE_AUTH exchange. During vertical handover, the MN
simply notifies the server to use another IP address already
agreed upon through the ADDITIONAL_ ∗ _ADDRESS
notification. For horizontal handover, the MN will simply send
an UPDATE_SA_ADDRESSES notification to update the IP
address. The server would then perform a “return routability”
check before accepting the new address [48].
MOBIKE helps in giving the application sessions persistence
only if a handover happens fast enough before the application session or the underlying transport layer session times
out. Therefore, applications may not survive long coverage gap
where both cellular and WiFi are not available.
6) Network Mobility (NEMO): Devarapalli et. al. [50] propose a network mobility (NEMO) protocol that treats entire
networks, and not hosts as mobile. A real-world scenario would
be a corporate bus. It is conceivable that every person on the bus
would want to VPN into the corporate network. Instead of having several individual VPNs, it would make practical sense to
have the network on the corporate bus be an extension of the
corporate intranet. The hosts in the bus are static with respect
to each other, as the network on the bus moves through different access networks. The protocol is essentially an extension of
MIPv6 and is illustrated in Figure 10.
A new network device, called a Mobile Router (MR) is introduced in NEMO. The MR registers at the HA as a MN does in
a MIPv6 network. But instead of registering one IP, the MR
registers one or many subnets. Packets with destination to the
network(s) behind the MR are intercepted by the HA forwarded
through a tunnel to the network behind the MR.
While NEMO makes minimal extensions to MIPv6, it has the
HA as a single point of failure. However, it reduces overhead
and improves performance for a few niche applications.
7) Cellular Networks - CDMA2000 Mobile VPN:
CDMA2000 is a 3G technology for cellular systems. It is
widely deployed in the Americas and in some regions in Asia

Fig. 11. Mobile VPN in CDMA2000

and East Europe [18]. The main components in CDMA2000 as
shown in Figure 11 are:
• CDMA2000 Radio Access Network (RAN). An MN
connects to RAN through radio access.
• Packet Control Function (PCF). RAN and PCF communicate through a Radio-Packet (R-P) interface.
• Home and foreign AAA servers.
• Packet Data Serving Node (PDSN) acting as a Foreign
Agent (FA). PDSN and PCF communicate through a GRE
tunnel.
• Home Agent (HA) which communicates with the FA
through a MIP/IPsec tunnel.
When a MN visits a CDMA2000 network, it establishes a
PPP session with the PDSN (FA). The PPP traffic is actually
encapsulated inside R-P traffic. When it reaches the PCF it
decapsulates the R-P traffic to obtain the PPP frames and further encapsulates them inside a GRE packet that gets transfered
to the PSDN. The PPP session is terminated at the PSDN. The
payload of the PPP frames can then be transfered from the
PSDN to the HA via a MIP/IPsec tunnel.
When a MN register with a PDSN, the PDSN delegates the
IP assignment to the HA. The HA assigns a dynamic or static IP
to that MN. When a MN roams, there are three different levels
of mobility:
• The MN leaves the range of one RAN to another. Here
a physical layer soft hand-off occurs transparent to the
above layers.
• The MN may move far enough to join a range of a new
PCF. Here, link layer mobility takes place transparent
from layer 3.
• The MN roams to another network. At this point, IP
mobility takes place. The MN will register with a new
PDSN and the HA will update the mobility binding table
resulting in all subsequent traffic being routed via the new
PDSN.
8) Cellular Networks - UMTS Mobile VPN: In cellular networks, VPN mobility is provided through the cellular access
network consisting of towers and base stations, and mobile
VPNs in cellular networks use a combination of GPRS tunnelling protocols (GTP) and IPsec [51] as shown in Figure 12.
GTP encapsulates packets over IP/UDP transport paths and
provides control messages to setup and modify tunnels.

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

Fig. 12. Mobile VPN in UMTS cellular networks

Fig. 13. SIP-based mobile VPN

A MN in such a setup obtains dynamically allocated IPs
and are authenticated by the cellular network providers by the
Gateway GPRS support node (GGSN) [51]. In non GPRS networks, a node with a different name, but similar functionalities
would replace the GGSN. IPsec tunnels are setup between the
GGSN and ISPs to transmit traffic to the final destination.
B. Mobile VPN Through Application Mobility
This section discuss mobile VPN solutions that support
mobility at the application layer of the TCP/IP protocol stack.
1) SIP-Based Mobile VPN: Huang et. al. propose a SIPbased mobile VPN solution for real time applications, tailored
to delivering security and mobility to real-time applications
[42]. Figure 13 illustrates the proposed SIP-based mobile VPN
architecture.
When a MN roams from a home network, a SIP proxy server
located within the VPN gateway authenticates the incoming
SIP messages, and routes the messages through to another
SIP proxy server which is designated as the SIP registrar.
An Application Layer Gateway (ALG) interacts solely with
a SIP Proxy server, and oversees all the traffic. When the
ALG receives an incoming RTP stream from the home network to a host in the Internet, it replaces the IP/UDP/RTP
headers with a SRTP header, and deliveries the stream to the
destination. Communication in the reverse direction is handled
by verifying the validity of the SRTP packet, and by replacing the SRTP headers with a new RTP header. The payload
remains unchanged in both directions. Every such bi-directional
communication is represented as a session in the ALG.

1187

As and when a MN enters and leaves its home network, it
registers its new location with the SIP registrar during initial
session setup. Huang et. al. use a Diameter service for the registration process. After the MN registers with the SIP registrar,
it checks whether there are active sessions in the ALG [52].
If an active session is found, the MN needs to RE−INVITE
the CN, where a RE−INVITE is essentially an INVITE message with the same call-ID as the initial INVITE message, with
the new contact address of the MN. The RE−INVITE is sent
to SIP Proxy in the VPN gateway, which in turn routes the
message to the SIP Registrar. If authentication is needed, then
the SIP registrar leverages the Diameter server. If the MN is
allowed access to the home network, the SIP Registrar uses the
ALG to allocate enough resources to guarantee session protection. At this point, the RE−INVITE message is routed to the
CN [52].
When a MN returns back to its home network, the messages
do not need to go through the SIP proxy in the VPN gateway. So, upon registering its new address with the SIP Registrar
and sending the RE−INVITE message, the SIP Registrar will
free all the resources previously allocated. The MN can then
communicate directly with the CN without going through the
ALG [52].
Since the proposed architecture is based on SIP, there is no
need to tunnel a packet three times, as is required in the IETF
mobile VPN (Section V-A2), thereby significantly reducing
overhead. Additionally, the proposed architecture is particularly
useful for real-time application as most SIP-based applications
are [52]. Performance of the SIP-based mobile VPN seems to
indicate that it is especially suitable for real-time applications
given the small payload in real-time applications [52].
The SUM framework we discussed in Section V-A2 also utilizes SIP along with MOBIKE as an alternative approach in
their mobile VPN framework [45]. The main objective is to
achieve a dynamic VPN tunnel establishment in order to use
a secure VPN tunnel on demand. For example, a secure tunnel
is not needed when the mobile client is inside the internal home
network or when it is roaming externally but is not sending
sensitive data.
2) WTLS-Based Mobile VPN: One of the most popular
commercial mobile VPN products is Columbitech [53], which
uses the idea of an application layer solution to add mobility to VPN. By addressing mobility concerns at the application layer, the product liberates the network and transport level connections from having to address mobility, and
have those layers working as they were originally designed.
The solution relies on recovery mechanisms at the transport
layer.
Columbitech [53] splits the client-server connection into
three connections as shown in Figure 14. The first connection is
a TCP/UDP connection inside the MN between the application
client and the mobile VPN client. The VPN client then establishes a session with the VPN server using reliable UDP. Similar
to the VPN client, the VPN server establishes a TCP/UDP connection with the application server. This split is used to fool
the applications in the MN into believing they are connecting
directly to the application server, when in reality, the application
client connection ends at the VPN client.

1188

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

Fig. 14. Columbitech mobile VPN setup.

When the VPN client receives an application request to connect to an application server, mobile VPN will intercept that
request and ask the VPN server to connect to the application server. After learning that the VPN server has completed
setup with the application server, the mobile VPN client will
inform the application that the end-to-end connection to the
server is completed successfully. The mobile VPN server and
client setup the VPN session using WTLS. In addition, the system supports multiple VPN servers with a multiplexer that can
distribute the load to the VPN servers. When a VPN server
experiences failure, all connected clients will lose their sessions
and will have to initiate a new connection with a different VPN
server since the system does not provide a transparent way to
hand-over the sessions of a failed VPN server to an active one.
3) MUSeS: Ahmat and Magoni [54] suggest a similar
application control mobile VPN solution. Their solution, called
MUSeS supports both the mobility and traffic security. MUSeS
allows user connections to survive disruptions caused due to
mobility. Similar to Columbitech [53], MUSeS hides the network disruptions due to mobility from the user by creating a
secure session using an application layer abstraction. MUSeS
uses a peer-to-peer overlay network called CLOAK [55] above
any IP network. Instead of using IPsec or TLS for VPN, MUSeS
relies on device identifiers called provided and managed by
CLOAK to provide encryption and authentication.
When a MUSeS node generates a packet to send to a remote
MUSeS node, the packet makes its way through the underlying
CLOAK node via a loop back TCP connection. The underlying CLOAK node routes the packet to the destination through
the P2P overlay network. The CLOAK node associated with
the destination MUSeS node intercepts the packet and locally
forwards it to B. The P2P overlay network ensures therefore
the proper routing of MUSeS secured packets over the network. The authors do not however, provide explicit details
of the security assurances of this mechanism, instead, stating
that MUSeS protects user communications from common traffic attacks because it uses standard cryptographic algorithms.
Since the communication between the MUSeS middleware and
the local applications on a machine are not secured, the security of this system appears suspect compared to more traditional
VPN solutions. Figure 15 shows how a packet is forwarded
between the source and the destination.
4) FastVPN: Zúquete and Frade [56] suggest a solution for
fast VPN mobility of OpenVPN clients across WiFi hotspots,
called FastVPN. The goal of FastVPN is to reconfigure an

Fig. 15. MUSeS Setup.

OpenVPN tunnel after a VPN client gets a new IP address post
handover to a new network without having to terminate and
reestablish the OpenVPN tunnel. This is achieved by updating the VPN tunnel context at the VPN server once the client
receives a new IP address. Normally, an OpenVPN server looks
up a tunnel context by the VPN client’s physical IP address and
UDP port. When the client obtains a new physical address due
to joining a new network, OpenVPN server will not be able to
associate this client with its original tunnel context. This leads
to two major side effects: 1) the client will have to reestablish a
new tunnel causing unnecessary overhead stemming from tunnel setup and new TLS handshake; and 2) the private IP address
obtained by the VPN client in the previous session will less
likely be maintained as it will not be released until the previous
tunnel context is eliminated by OpenVPN’s garbage collection,
which only occurs after certain period of inactivity. Reusing the
original tunnel context allows for maintaining the same private
IP address, and allows for faster tunnel resumption by avoiding
the reestablishment of the tunnel from scratch.
Fast VPN reconfigures the original tunnel context by having the client send the original session ID to the VPN server
whenever it obtains a new physical IP. Sending the session
ID is done in two ways: a lazy approach and an aggressive
approach. In the lazy approach the session ID (64 bits) is sent
in Initialization Vector (IV) field in all data messages all the
time. This works well for CBC cipher-mode as randomness of
IV does not improve CBC security [56]. For Cipher Feedback
mode (CFB) and Output Feedback mode (OBF), 128-bit IV has
to be used since randomness of the IV is a requirement. With
128-bit IV, only the first 64 bits will be constant (occupied by
the session ID) while the other 64 bits are random.
In the aggressive approach, the client sends a keep-alive message to the server padded with a clear-text session ID at the end
of the message payload. When the VPN server receives such
a message, it will not be able to find an entry for the client
with the new IP address in the tunnel context table. Thus, it
checks the size of this keep-alive message and if it is longer
that what it normally is, it detects that this is a reconfiguration message that contains a session ID. The session ID is then
used to look up the tunnel context, and if found, the physical
IP address associated with this context is updated with the new
IP address. Figure 16 shows the format of the reconfiguration

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

1189

Fig. 16. Reconfiguration message in Fast VPN [56].

Fig. 18. HIP mobile VPN

Fig. 17. HIP protocol

ping message. This approach is considered aggressive because
the client will keep sending the reconfiguration ping message
until a confirmation from the OpenVPN server is received.
Fast VPN minimizes the packet loss but does not avoid it.
In addition, there is no mechanism to maintain the application
sessions while the MN is experiencing a gap in WiFi coverage. Allowing the VPN client to maintain the same private IP
address is quite helpful but such a solution would work only if
the client was to move from one WiFi network to another immediately, without experiencing a long gap in coverage that could
trigger TCP sessions to timeout.
C. Host Identity Protocol (HIP) Based Mobile VPNs
HIP seeks to change the TCP/IP protocol stack to enhance
security, mobility and multi-homing capabilities of today’s network. A new layer is introduced between Layer 3 and Layer
4 of the protocol stack that contains cryptographic host identifiers as shown in Figure 17. HIP provides IPsec encryption and
enables authentication to a visiting network and to an intranet
firewall.
The use of HIP enables Single Sign-on (SSO) functionality in
a visited network, where the operator only has to obtain a list of
hosts authorized to use the network. During the HIP handshake,
the visited network can verify the identity of the MN [57]. As
long as the MN can authenticate with a network that has a HIP
enabled access point, a VPN can continue to operate seamlessly
(except for delay caused by the HIP handshake). Similar to the
solutions using the IETF RFC 5265, TLS and IPsec VPN solutions can be configured to run on top of an HIP stack, thereby
ensuring VPN functionality [11]. Figure 18 shows a sample
HIP based mobile VPN tunnel with the minimum required
components.
VI. C OMPARATIVE A NALYSIS
Mobile VPN based on MIPv4 and IPsec as proposed by
IETF meets the main criteria associated with a mobile VPN:
it can handle mobility, and is proven to keep data confidential and authenticate the identity of the systems participating
in the VPN. However, it adds a lot of protocol overhead. This
could potentially result in throughput degradation and adds to

configuration complexity. Throughput degradation is especially
critical in low-speed wireless networks. An additional concern, depending on the application in question is that this type
of mobile VPN does not offer application persistence through
network connection drops. Application persistence is only guaranteed if the underlying transport protocol like TCP remains
idle [58]. It also suffer from the problem of triangle routing or
two-crossing problem in which traffic sent to the MN has to
always go to the home agent first even if the MN and the corresponding node are in the same network [58]. Finally, this type of
mobile VPN suffers from a performance problem which stems
from having to reestablish the security association of IPsec.
This problem is addressed in a similar mobile VPN that uses
two HA. The IPsec tunnel between the external HA and the FA
(can be the MN itself) is persistent since the external CoA does
not change during mobility. This method however increase the
tunneling overhead by adding an extra MIP layer.
MOBIKE-based VPNs offer native support for multiple network interfaces where switching from one interface to another
cause no delays if both interfaces are active. If the interface
switched to was not active, the delay incurred is only the delay
required to obtain a layer 3 IP address. It also support updating
IP addresses during horizontal handover without tearing down
IKE and IPsec SAs. Application persistence is guaranteed when
there is at least one network available. However, there are no
guarantees that applications will survive long coverage gaps.
NEMO is an excellent mobile VPN solution for a niche
application. It does not meet many of the requirements of a
true mobile VPN solution, but can be used in association with
another mobile VPN solution to reduce overhead and enhance
efficiency.
While BGP/MPLS based mobile VPN technically makes
provisions for mobility, and has obvious VPN capabilities, it
falls short of the other solutions, since it requires specialized
equipment and configuration on part of the ISP. More than
a mobile VPN, it should be considered a stationary VPN for
nodes with limited mobility. Whenever a node moves from one
location to another, the VPN drops, and with it the application
sessions. After arriving at a new location, the VPN needs to be
setup once again, thereby causing service interruption.
The encrypted radio communication between the user and the
cellular access points in mobile VPN configurations in cellular networks are based on encryption between the user and the
mobile network provider [51]. Additionally, there is need for
specialized network devices like the GGSN which are owned by
entities other than the one the MN is seeking a tunnel to. The

1190

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

TABLE IV
C OMPARISON OF R ADIO IP’ S M ULT-IP VS . C OLUMBITECH M OBILE VPN

setup of multiple tunnels adds overhead, which could impact
performance in low bandwidth networks.
SIP-based mobile VPN [52], [42] has a centralized
client/server architecture owing to the nature of the SIP protocol. This inherently brings with it scalability issues. In addition,
the solutions are adapted for real-time applications, and may not
suitably convert over for other applications. Moreover, it suffers
from the security vulnerabilities of SIP, which have been widely
studied [59].
TLS-based mobile VPNs and its variants (WTLS, DTLS)
are more mobility-friendly than the Mobile IP based solutions.
This stems from the fact that TLS is an application protocol and
therefore a TLS session is independent to any changes to the
network layer i.e. IP changes. In order to support application
persistence, TLS-based mobile VPNs rely on establishing
a virtual interface that remains active even during network
disruption. The virtual interface maintains a fixed virtual IP
(FVIP) which an application in the MN can use as a source
address. True application persistence (TAP) is not natively
supported by TLS-based mobile VPNs. If the MN experiences
a long coverage gap, the underlying transport protocol may
time out.
Mobile VPNs based on HIP has the potential to evolve into
a universal mobile VPN solution, since HIP supports mobility
in its native form. However, it requires the use of HIP enabled
devices in all visited networks which may not always be feasible, especially in legacy systems. However, HIP VPN solutions
appear to lack maturity of other solutions discussed in this
paper.
MIPv6 or other MIP type approach which keeps the VPN
tunnels active while a MN is visiting other networks only partially solves the issues at hand. Depending on the application,

communication disruptions while a MN switches networks
might crash the application. For this reason, application session
persistence during network disruptions is very important and
several of the more accepted mobile VPN solutions like [53]
[54] offer the capability to mask network disruptions from the
application.
Mobile VPNs that have provisions for application session
persistence seem to be the most promising of all mobile VPN
options, and appear to be well established in the market. But
how these solutions will adapt to IPv6 remains to be seen.
VII. C OMMERCIAL M OBILE VPN S OLUTIONS
We surveyed the existing commercial mobile VPN solutions and found seven mobile VPNs available in the market
namely: Birdstep’s SafeMove, Radio IP’s IpUnplugged, Radio
IP’s Mult-IP, NetMotion’s Mobility XE, Columbitech’s Mobile
VPN, Motorola’s MultiNet Mobility and Cisco’s AnyConnect
Mobile. We reached out to the vendors of these products
in order to test and verify their features. We were able to
obtain a trial version of Radio IP’s Mult-IP and Columbitech’s
Mobile VPN. In the remainder of this section we briefly present
the mobility technology used in these products, and then,
we provide a case study for both Radio IP’s Mult-IP and
Columbitech’s Mobile VPN. Table IV summarizes the main
features we verified of these two products.
A. Unevaluated Commercial Mobile VPN Solutions
Birdstep provides two mobile VPNs: SafeMove Mobile
VPN which is designed for Windows [60]; and SafeMove
for Android [61]. SafeMove for Windows implements various

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

Mobile IP and IPsec RFCs. It uses IPsec to provide security,
while providing mobility through Mobile IP [60]. SafeMove
provides a module to a predictive vertical handover [62].
SafeMove for Android leverages IPsec to provide security
features and MOBIKE to support mobility [61]. Application
persistence is only achievable if a change in IP address and the
MOBIKE address update occurs before the application or the
underlying transport protocol times out.
Radio IP’s IpUnplugged utilizes IPsec for security and MIP
for mobility [63]. Packet loss during roaming is inevitable in
this solution and application sessions are not guaranteed to
survive a lengthy period of network unavailability.
Mobility XE is a proprietary mobile VPN. NetMotion does
not reveal how the mobility or security protocols are implemented. However, their product description [64] states that
Mobility XE is designed to provide true application persistence which means applications can be suspended on network
disruption and resumed upon reconnection (without any upper
bound on time limit). It also provides seamless roaming through
a proprietary protocol. However, [64] indicates that a MN
always keeps its virtual IP in order to maintain application sessions. Mobility XE employs link optimization to reduce packet
retransmission on the wireless links [65].
Cisco’s AnyConnect Mobile is implemented based on TLS
and DTLS [66]. When a the VPN client establishes a connection with a VPN server, three sessions are established: a parent
tunnel, a TLS tunnel for control traffic and a DTLS tunnel for
data traffic. During the VPN establishment phase, the server
generates a VPN session token which is then transfered securely
to the client via the TLS tunnel. The parent tunnel is inserted in
the server’s mapping table as the token. The token includes a
session ID and is mapped to the assigned private IP address.
During roaming, both the TLS and DTLS sessions are torn
down, while keeping the parent session alive. When the client
regains network connectivity, the VPN session is resumed, by
reestablishing both TLS and DTLS tunnels and then presenting
the VPN session token to the server, which will reassign the
same private IP to the client. TLS and DTLS abbreviated session resumption is not supported. AnyConnect Mobile does not
support true application persistence; only if the reconnection
occurs before the application TCP session times out.
MultiNet Mobility (MultiNet) is a mobile VPN based on
mobile IP and IPsec. It’s designed as a client-server model
where the MN acts is its own agent. It supports automatic
multi-network roaming. Unlike the previously discussed commercial MIP-based mobile VPNs, this mobile VPN provides
true application persistence functionality. It allows the VPN to
suspend applications during network interruptions and resume
them once network connectivity is recovered. MultiNet implements a vertical handover policy allowing administrators to
prioritize network selection based on speed or low-cost . It also
provide the ability to prioritize application data which can be
important for mission-critical applications [67], [68].
B. CASE STUDY I: Radio IP’s Mult-IP
We tested and verified the features on Mult-IP in a testbed
illustrated in Figure 19. Our test was conducted by observing

1191

Fig. 19. Mult-IP testbed network diagram

the survivability of the VPN session and the application sessions. We used netcat [69] to send messages between the MN
and the application server. We also used iperf [70] for a more
stressful testing by send large volume of data. We began our
testing with both WiFi and 4G interfaces enabled, then we performed network interruption events. We disabled WiFi, after
that we disabled 4G before we eventually enabled WiFi. We
installed the Mult-IP servers version 3.11.0 on Windows 2008,
and used Windows 7 for the client. Below, we discuss our
observations according the mobile VPN requirements stated in
Section IV.
1) Seamless Network Roaming (SNR): Mult-IP was able to
sustain the VPN session through all of the network disruption
events. The VPN tunnel seamlessly moved from WiFi to 4G,
and survived the duration in which both WiFi and 4G were
disabled. It automatically reconnected after enabling WiFi.
Mult-IP uses a proprietary mobility protocol that allows the
MN to keep the same virtual IP during network interruptions.
It also allows for concurrent networking in which the VPN can
utilize both WiFi and 4G at the same time. This is done to allow
for implementation of a policy by which a VPN server administrator can choose which interface a client application can use.
The concurrent networking concept allows the administrator
to define up to eight pipes. Each pipe has a pre-set roaming
profile prioritizing the network interfaces to be used, as well
as configurable timeouts. This allow the mapping of different
application to different pipes based on the nature and criticality
of the application.
The automatic reconnection does not require the VPN client
to re-register with the VPN server if the reconnection occurs
within a configurable time period.
2) Security: Mult-IP implements its own proprietary security module which provides authentication, encryption and
decryption of all data transmitted through the VPN tunnel.
It provides authentication via Windows AD, RADIUS, 801.x

1192

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

EAP or extended authentication via hard tokens, soft tokens,
smart cards etc. The encryption algorithms supported are DES,
3DES and AES.
3) Application Sessions Persistence (ASP): Mult-IP provides true application persistence by 1) allowing the MN
to keep its virtual IP despite network interruption events;
and 2) buffering application data during network unavailability, while informing the applications that their data has been
received by the intended recipient.
When we disabled both WiFi and 4G from the MN, we
sent messages from the mobile node to the application server
using netcat. Using Wireshark [71], we observed that packets
sent from the MN node were acknowledged by the application
server. Mult-IP client generates these ACK packets on behalf
of the application server. Similar behavior happens on the other
side when sending the a message from the application server to
the MN. Upon reconnection, Mult-IP sends the buffered packets to the remote end. Upon receiving them, Mult-IP on the
receiving end changes the ACK number to the last ACK number
reported to the application.
4) Performance: Mult-IP provides load balancing. A pool
of VPN servers will have one master while the rest are slaves.
When a MN tries to establish a VPN session, the request goes
to the master server which will redirect it to the server in the
pool that has the least number of connected MNs. If each VPN
server has the same number of connected MNs, the master will
serve that connection. If the master server fails, one of the slave
servers in the pool will be elected as a master.
Mult-IP also provides a failover feature by which MNs will
automatically connect to a new VPN server in case the original
VPN server fails. While this happens seamlessly, active TCP
sessions will be reset.
Mult-IP also allows for split-tunneling which allows defining which traffic can go through the VPN tunnel and which can
be routed to the Internet directly. The split-tunneling however
is controlled by the VPN server and the policy is pushed to
the client. Encryption is not adaptive but is eliminated when
the MN is inside the home network. Compression is not adaptive either but the administrator can select between LZ4 or
arithmetic compression methods for each pipe. Arithmetic compression yields better compression rate and thus recommended
for slow networks. LZ4 is recommended for fast networks since
it has better computation efficiency.
C. CASE STUDY II: Columbitech’s Mobile VPN
We tested and verified the features of Columbitech Mobile
VPN in a testbed illustrated in Figure 20. The testbed is similar to Mult-IP except for the introduction of a GateKeeper
server which is responsible for load balancing. Our testing was
done using Columbitech server version 6.5.0.300 and version
6.5.0.265 for the client. We used the same testing scenarios that
we used for Mult-IP as described in Section VII-B. We discuss
our observations in relation to the mobile VPN requirements
stated in Section IV.
1) Seamless Network Roaming (SNR): In our test, we
observed that the VPN client can switch between two 4G and
WiFi seamlessly. Unlike Mult-IP, only two physical interfaces

Fig. 20. Columbitech testbed network diagram

are supported by this VPN. The VPN session survived the network interuption events. We disabled both WiFi and 4G for 20
minutes before re-enabling WiFi, the VPN session reconnected
seamlessly with an abbreviated WTLS handshake. This mobile
VPN does not implement a vertical handover policy. The MN
can define a quota for the maximum amount of data transmitted
through a certain interface either using daily or monthly rates.
2) Security: Columbitech’s mobile VPN uses WTLS and
DTLS as its security protocol. It implements several authentication methods like Windows AD, Radius, X.509 certificates,
WTLS certificates, RSA SecurID, smartcard and biometrics.
For encryption, it uses DES (56 bit), 3DES (112 bit) or AES
(up to 256 bit). Key exchange is done using RSA (512-15000
bit), while hashing and signing is done via MD5 (40-128 bit),
SHA-1 (40-512 bit) [53].
3) Application Sessions Persistence (ASP): Our testing
confirms what we described in Section V-B2 that Columbitech
provides true application session persistence by splitting an
application’s TCP connection into three connections. The merit
behind this split is that the connections between the application
client and the mobile VPN client; the connection between the
VPN server and the application server can be easily maintained
to keep both the application client and application server believing they are always connected. This can be achieved regardless
of the condition of the TCP connection between the mobile
VPN client and the mobile VPN server, thereby maintaining
an application session intact. During network disruption events,
the VPN client sends a message to the application client indicating the TCP buffer is full and can not temporarily accept
any more data. This is achieved by sending an ACK to to the
application client with the window set to zero. The VPN server
does the same thing to the application server when it tries to
send out data. This pauses both ends of the application session until the VPN tunnel is restored. Upon resumption, we
observed that a new TCP session was opened to replace the

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

1193

TABLE V
A S UMMARY OF M OBILE VPN O PEN I SSUES

middle TCP connection (between VPN client and VPN server).
Just like Mult-IP, this mobile VPN allows the client to maintain
its virtual IP until the VPN tunnel is no longer needed by the
user.
4) Performance: This system supports multiple VPN
servers with the use of a GateKeeper (multiplexer) that can distribute the load to the VPN servers. The GateKeeper is a single
point of failure; and is not present in Mult-IP.
When a VPN server experiences failure, all connected clients
will lose their sessions and will have to initiate a new connection with a different VPN server since the system does not
provide a transparent way to hand-over the sessions of a failed
VPN server to an active one.
Columbitech allows the client to decide whether to use split
tunneling or not. Adaptive encryption is not truly implemented,
however, encryption is disabled when the MN is trusted zones.
A user can configure the MN to use compression for selected
profiles. True adaptive compression is not implemented. A
mechanism to dynamically adjust TCP buffer parameters is
implemented by observing the RTT in order to optimize TCP
performance.
VIII. F UTURE W ORK
In this section, we identify six open issues that are worthy of investigation by the research community in order to
develop a mobile VPN that meets the requirements and needs
of mobile-heavy IT environments. These issues are summarized
in Table V.
A. Software Defined Networking-Enabled Mobile VPN
Software-Defined Networking (SDN) has been used recently
to allow effective seamless operation of network infrastructure
in cloud environments and data centers. Mobile VPNs allow
mobile devices to access cloud resources and private networks.
With new trends such as BYOD, all applications in a mobile
device can access private networks and cloud resources after

establishing the VPN tunnel. This may not be desirable to
an organization that requires only certain applications to have
access to the private resources. SDN-enabled mobile VPN is
envisioned to allow the SDN controller to provide VPN on
demand by dynamically configuring the routing options a VPN
server pushes to the mobile client based on a fine-grained
policy that satisfy the MN needs and conform to the organization’s objectives. As SDN is still an emerging paradigm,
SDN-enabled VPNs are in their infancy. The authors of [73]
present a novel approach to use SDN to enhance the flexibility
of MPLS VPNs. We believe utilizing SDN in mobile VPNs is
an interesting direction for future work in mobile VPNs.
B. Application Persistence
Currently, there is a lack of research in mobile VPNs that add
persistence to applications when a mobile user experiences relatively long gap in network coverage. Application sessions most
likely will not survive long network disruption. There are a few
commercial solutions that address this problem as described in
section VII, however, to the best of our knowledge, there is no
research-based work published in this area. Open source and
free mobile VPNs that provide such feature are non-existent.
An open source mobile VPN that allows applications sessions
to survive long network coverage gaps, preferably with ability
to cache and buffer application data during network disruption
will be an interesting direction for future work.
C. Lightweight VPN Tunnel Resumption
TLS-based mobile VPNs will benefit from resuming TLS
sessions with abbreviated handshake instead of reestablishing a
new TLS session with full handshake upon network reconnection. Once again, there are some commercial solutions that take
advantage of such feature but no open source solution has taken
advantage of such feature. TLS session resumption is specified
in RFC 5077 [74] and RFC 5746 [75]. However, TLS-based
VPNs like OpenVPN do not utilize this feature due to triple

1194

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

handshake attacks [76]. We envision that developing a TLSbased mobile VPN that utilizes TLS session resumption and is
resistant to triple handshake attacks will be a good direction for
future work on TLS-based mobile VPNs.
D. VPN Tunnel Handover
The evolution of mobile VPN will give rise to new design
issues, some of which will include session handover between
clients to fully capture the confluence of mobility and cloud
computing environments. Since most of the computing power
will be in the cloud, a mobile session that could be handed
off between devices will greatly enhance features that can be
provided to a mobile user. For example, a VPN session could
be handed over from a cell phone to a tablet, when the user
requires the use of a larger screen. The challenge here is to hand
over a VPN tunnel from one device to another in a way that the
new device maintains the same virtual IP of the old device so
that migrated applications sessions can be resumed on the new
device. Another challenge is how to perform the handover in a
secure fashion that protects the VPN session from being compromised. Such feature need to be resistant to a well-defined
attack threat model.
E. Detection of Network Disruption
All mobile VPN solutions available essentially rely on dead
peer detection mechanism to detect the of unavailability of the
remote end. This is accomplished by sending control messages,
such as a ping message, periodically according to a preset timer.
This approach has three drawbacks: 1) The detection of network disruption may be delayed, resulting in avoidable TCP
retransmission timeouts which maybe interpreted as network
congestion that may lead to dropping the congestion window,
2) when the detection timer is reduced to overcome the problem
above, it leads to excessive unnecessary network traffic.
Instead of relaying on dead peer detection, adding predictive functionalities to preempt connection drops to gracefully
halt sessions and reduce retransmissions is another potential
research area. Using alternatives to dead peer detection in
mobile VPNs has been introduced in [77] [78] [79] by using
adaptive fuzzy logic and particle filter. These studies introduce mathematical models and simulation but lack empirical
evaluation.

OpenVPN [81]. This prevents the radio module from entering
the standby state as it will always toggle between low power
and full power states. This issue is not problematic for stationary computers connected to a power source. However, this
is a major concern for battery-operated mobile devices. Until
today, this remains an open issue for mobile devices that uses
IPv4. Mobile VPNs that use IPv6 suffers less from this problem
as NATing will not be required, however, dead peer detection mechanism discussed in section VIII-E cause the same
phenomenon to exist in IPv6.

IX. S UMMARY
Mobile VPN technology is a powerful information security
tool for today’s computing environment. Due to complexity of
the issues involved, and the numerous possible options available, a mobile VPN solution that custom fits the problem at
hand can be devised using a structured methodology [10].
While modifications of IPsec and TLS based client VPNs
have their place, they are not optimized for a mobile environment and fail to address the needs for application performance,
usability, and productivity.
Finding a mobile VPN solution based on current protocols
is not trivial. MIP, and its successor MIPv6, add mobility support to the IP networks. With MIPv6 an integral part of the IPv6
functionality, the narrow waist of the OSI stack is being made
friendly to mobility. However, deployments of IPv6 are still lagging behind the IPv4 Internet backbone that we have all become
accustomed to. With the inevitable movement of networking to
an IPv6 based core, incorporating session mobility based solutions to MIPv6 appears to have the greatest scope of success.
However, research on this front is lacking as of this survey. A
mobile VPN solution built on session transfer that is IPv6 compatible, we believe will usher the mobility constrained VPN into
the mobile age.
In this survey, we presented to the reader a technical background of building-block protocols used in mobile VPNs solutions. We then provided a taxonomy for classifying mobile
VPN, and stated the requirements for a true mobile VPN. We
surveyed and discussed the state-of art mobile VPN technologies with analytical comparison. We then presented two case
studies of commercial mobile VPNs before we concluded our
survey with a section that discusses the open issues of mobile
VPNs.

F. Battery Consumption and NATing Proxies
Mobile VPN clients sitting behind a NAT server , even when
the VPN tunnel is idle, requires continuous sending and receiving of control messages to keep the VPN tunnel alive. This
makes the radio module of the mobile device remain active, preventing it from hibernating which results in excessive battery
consumption. For example, the radio state machine of android
devices transitions between three states: full power, low power
and standby [80]. It transition from full power to low power
after 5 seconds of the radio being idle. 12 seconds later of idle
time, it transitions to the standby state. Most VPNs sends keepalive messages within 10-second periods by default such as

R EFERENCES
[1] D. Huang, X. Zhang, M. Kang, and J. Luo, “MobiCloud: Building secure
cloud framework for mobile computing and communication,” in Proc.
IEEE 5th Int. Symp. Serv. Orient. Syst. Eng. (SOSE’10), 2010, pp. 27–34.
[2] K. Heyman, “A new virtual private network for today’s mobile world,”
Computer, vol. 40, no. 12, pp. 17–19, 2007.
[3] V. D. Tzvetkov, “Virtual private networks for mobile environments.
Development of protocol for mobile security and algorithms for location update,” Ph.D. dissertation, Tech. Dept. Comput. Sci., Tech. Univ.
Darmstadt, Darmstadt, Germany, 2010.
[4] T. Goff, J. Moronski, D. S. Phatak, and V. Gupta, “Freeze-TCP: A
true end-to-end TCP enhancement mechanism for mobile environments,”
in Proc. IEEE 19th Annu. Joint Conf. IEEE Comput. Commun. Soc.
(INFOCOM’00), 2000, vol. 3, pp. 1537–1545.

ALSHALAN et al.: SURVEY OF MOBILE VPN TECHNOLOGIES

[5] Dimension Data. (2014). Secure Mobility Survey Report [Online].
Available: http://www.dimensiondata.com/Global/Downloadable Documents/Secure Mobility Survey Findings Report.pdf
[6] D. Saha, A. Mukherjee, I. S. Misra, and M. Chakraborty, “Mobility support in IP: A survey of related protocols,” IEEE Netw., vol. 18, no. 6,
pp. 34–40, Nov./Dec. 2004.
[7] I. F. Akyildiz, J. Xie, and S. Mohanty, “A survey of mobility management in next-generation all-IP-based wireless systems,” IEEE Wireless
Commun., vol. 11, no. 4, pp. 16–28, Aug. 2004.
[8] Z. Zhu, L. Zhang, and R. Wakikawa, “A survey of mobility support
in the internet,” RFC 6301 (Informational), 2011 [Online]. Available:
https://tools.ietf.org/html/rfc6301
[9] A. Liotta, D. H. Tyrode-Goilo, and A. Oredope, “Open source mobile
VPNs over converged all-IP networks,” J. Netw. Syst. Manage., vol. 16,
no. 2, pp. 163–181, 2008.
[10] A. V. Uskov, “Information security of mobile VPN: Conceptual models
and design methodology,” in Proc. IEEE Int. Conf. Electro/Inf. Technol.
(EIT’12), 2012, pp. 1–6.
[11] G. Pulkkis, K. Grahn, M. Mårtens, and J. Mattsson, “Mobile virtual private networking,” in Future Internet-FIS 2009. New York, NY, USA:
Springer, 2010, pp. 57–69.
[12] F. Barceló, J. Paradells, F. Setaki, and M. Gibeaux, “Design and modelling of internode: A mobile provider provisioned VPN,” Mobile Netw.
Appl., vol. 8, no. 1, pp. 51–60, 2003.
[13] B. Lloyd and W. Simpson, “PPP authentication protocols,” RFC
1334(Proposed Standard), Internet Engineering Task Force, obsoleted
by RFC 1994, Oct. 1992 [Online]. Available: http://www.ietf.org/rfc/
rfc1334.txt
[14] W. Simpson, “PPP challenge handshake authentication protocol
(CHAP),” RFC 1994 (Draft Standard), Internet Engineering Task Force,
updated by RFC 2484, Aug. 1996 [Online]. Available: http://www.ietf.
org/rfc/rfc1994.txt
[15] G. Meyer, “The PPP encryption control protocol (ECP),” RFC 1968
(Proposed Standard), Internet Engineering Task Force, Jun. 1996.
[Online]. Available: http://www.ietf.org/rfc/rfc1968.txt
[16] J. Lau, M. Townsley, and I. Goyret, “Layer two tunneling protocol–
Version 3 (L2TPv3),” RFC 3931 (Proposed Standard), Internet
Engineering Task Force, updated by RFC 5641, Mar. 2005 [Online].
Available: http://www.ietf.org/rfc/rfc3931.txt
[17] W. Townsley, A. Valencia, A. Rubens, G. Pall, G. Zorn, and B. Palter,
“Layer two tunneling protocol “L2TP”,” RFC 2661 (Proposed Standard),
Internet Engineering Task Force, Aug. 1999 [Online]. Available: http://
www.ietf.org/rfc/rfc2661.txt
[18] A. Shneyderman and A. Casati, Mobile VPN: Delivering Advanced
Services in Next Generation Wireless Systems. Hoboken, NJ, USA:Wiley,
2003.
[19] D. Farinacci, T. Li, S. Hanks, D. Meyer, and P. Traina, “Generic routing encapsulation (GRE),” RFC 2784 (Proposed Standard), Internet
Engineering Task Force, updated by RFC 2890, Mar. 2000 [Online].
Available: http://www.ietf.org/rfc/rfc2784.txt
[20] G. Dommety, “Key and sequence number extensions to GRE,” RFC
2890(Proposed Standard), Internet Engineering Task Force, Sep. 2000.
[Online]. Available: http://www.ietf.org/rfc/rfc2890.txt
[21] C. Perkins, “IP encapsulation within IP,” RFC 2003 (Proposed Standard),
Internet Engineering Task Force, updated by RFCs 3168, 6864, Oct. 1996
[Online]. Available: http://www.ietf.org/rfc/rfc2003.txt
[22] C. Perkins, “Minimal encapsulation within IP,” RFC 2004 (Proposed
Standard), Internet Engineering Task Force, Oct. 1996. [Online].
Available: http://www.ietf.org/rfc/rfc2004.txt
[23] K. Scarfone, W. Jansen, and M. Tracy, Guide to General Server Security:
Recommendations of the National Institute of Standards and Technology.
Darby, PA, USA: DIANE Publishing, 2009.
[24] S. Kent and R. Atkinson, “IP encapsulating security payload (ESP),”
Internet Engineering Task Force, RFC 2406 (Proposed Standard), Nov.
1998 [Online]. Available: https://tools.ietf.org/html/rfc2406.
[25] S. Kent, “IP encapsulating security payload (ESP),” RFC 4303 (Proposed
Standard), Internet Engineering Task Force, Dec. 2005 [Online].
Available: http://tools.ietf.org/html/rfc4303
[26] S. Frankel and S. Krishnan, “IP security (IPsec) and internet key exchange
(IKE) document roadmap,” RFC 6071 (Proposed Standard), Internet
Engineering Task Force, Feb. 2011 [Online]. Available: http://tools.ietf.
org/html/rfc6071
[27] T. Dierks and E. Rescorla, “The transport layer security (TLS) protocol version 1.2,” RFC 5246 (Proposed Standard), Internet Engineering
Task Force, updated by RFCs 5746, 5878, 6176, Aug. 2008 [Online].
Available: http://www.ietf.org/rfc/rfc5246.txt

1195

[28] Open Mobile Alliance. (2001). Wireless Transport Layer Security.
Wireless Application Protocol WAP-261-WTLS-20010406-a [Online].
Available: http://www.wapforum.org
[29] C. Perkins, “IP mobility support for IPv4, revised,” RFC 5944 (Proposed
Standard), Internet Engineering Task Force, Jun. 2010 [Online].
Available: https://tools.ietf.org/html/rfc5944
[30] J. Rosenberg et al., “SIP: Session initiation protocol,” RFC 3261
(Proposed Standard), Internet Engineering Task Force, updated by RFCs
3265, 3853, 4320, 4916, 5393, 5621, 5626, 5630, 5922, 5954, 6026,
6141, 6665, 6878, Jun. 2002 [Online]. Available: http://www.ietf.org/rfc/
rfc3261.txt
[31] H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson, “RTP: A
transport protocol for real-time applications,” RFC 3550 (INTERNET
STANDARD), Internet Engineering Task Force, updated by RFCs 5506,
5761, 6051, 6222, 7022, 7160, 7164, Jul. 2003 [Online]. Available: http://
www.ietf.org/rfc/rfc3550.txt
[32] M. Baugher, D. McGrew, M. Naslund, E. Carrara, and K. Norrman,
“The secure real-time transport protocol (SRTP),” RFC 3711 (Proposed
Standard), Internet Engineering Task Force, updated by RFCs 5506,
6904, Mar. 2004 [Online]. Available: http://www.ietf.org/rfc/rfc3711.txt
[33] D. I. Wolinsky et al., “On the design and implementation of structured
P2P VPNS.” Preprint, 2010. arXiv:1001.2575.
[34] M. Lewis, Comparing, Designing, and Deploying VPNs. Indianapolis,
IN, USA: Cisco Press, 2006.
[35] T. Takeda, I. Inoue, R. Aubin, and M. Carugi, “Layer 1 virtual private networks: Service concepts, architecture requirements, and related advances
in standardization,” IEEE Commun. Mag., vol. 42, no. 6, pp. 132–138,
Jun. 2004.
[36] P. Knight and C. Lewis, “Layer 2 and 3 virtual private networks:
Taxonomy, technology, and standardization efforts,” IEEE Commun.
Mag., vol. 42, no. 6, pp. 124–131, Jun. 2004.
[37] R. Stanton, “Securing VPNS: Comparing SSL and IPsec,” Comput. Fraud
Secur., vol. 2005, no. 9, pp. 17–19, 2005.
[38] J. J. A. Rosado, “Mobile virtual private networks,” U.S. Patent 8,544,080,
Sep. 24, 2013.
[39] A. V. Uskov, “Information security of IPsec-based mobile VPN:
Authentication and encryption algorithms performance,” in Proc. IEEE
11th Int. Conf. Trust Secur. Privacy Comput. Commun. (TrustCom’12),
2012, pp. 1042–1048.
[40] F. Adrangi and H. Levkowetz, “Problem statement: Mobile IPv4 traversal of virtual private network (VPN) gateways,” Internet Engineering
Task Force, Tech. Rep. RFC 4093, Aug. 2005 [Online]. Available:
https://tools.ietf.org/html/rfc4093.
[41] S. Vaarala and E. Klovning, “Mobile IPv4 traversal across
IPsec-based VPN gateways,” Internet Engineering Task Force,
RFC 5265 (Proposed Standard), Ju. 2008 [Online]. Available:
https://tools.ietf.org/html/rfc5265
[42] S.-C. Huang, Z.-H. Liu, and J.-C. Chen, “SIP-based mobile VPN for realtime applications,” in Proc. IEEE Wireless Commun. Netw. Conf., 2005,
vol. 4, pp. 2318–2323.
[43] D. Benenati, P. M. Feder, N. Y. Lee, S. Martin-Leon, and R. Shapira,
“A seamless mobile VPN data solution for CDMA2000,* UMTS,
and WLAN users,” Bell Labs Tech. J., vol. 7, no. 2, pp. 143–165,
2002.
[44] P. Feder, N. Lee, and S. Martin-Leon, “A seamless mobile VPN data solution for UMTS and WLAN users,” in Proc. 4th Int. Conf. 3G Mobile
Commun. Technol. (Conf. Publ. No. 494). 2003, pp. 210–216.
[45] A. Dutta et al., “Secure universal mobility for wireless internet,” ACM
SIGMOBILE Mobile Comput. Commun. Rev., vol. 9, no. 3, pp. 45–57,
2005.
[46] T. Braun and M. Danzeisen, “Secure mobile IP communication,”
in Proc. 26th Annu. Conf. Local Comput. Netw. (LCN’01), 2001,
pp. 586–593.
[47] H. Byun and M. Lee, “Network architecture and protocols for
BGP/MPLS based mobile VPN,” in Information Networking. Towards
Ubiquitous Networking and Services, T. Vazão, M. M. Freire, and
I. Chong, Eds. New York, NY, USA: Springer, 2008, pp. 244–254.
[48] P. Eronen. (2006). IKEv2 Mobility and Multihoming Protocol (MOBIKE)
[Online]. Available: http://www.ietf.org/rfc/rfc4555.txt
[49] A. Dutta and H. Schulzrinne, Mobility Protocols and Handover
Optimization: Design, Evaluation and Application. Hoboken, NJ, USA:
Wiley, 2014.
[50] V. Devarapalli, R. Wakikawa, A. Petrescu, and P. Thubert, “Network
mobility (NEMO) basic support protocol,” Internet Engineering Task
Force, Tech. Rep. RFC 3963 (Proposed Standard), Jan. 2005 [Online].
Available: https://tools.ietf.org/html/rfc3963.

1196

IEEE COMMUNICATIONS SURVEYS & TUTORIALS, VOL. 18, NO. 2, SECOND QUARTER 2016

[51] A. Shneyderman, A. Bagasrawala, and A. Casati. (2000). Mobile VPNs
for Next Generation GPRS and UMTS Networks [Online]. Available:
http://esoumoy.free.fr/telecom/tutorial/3G-VPN.pdf
[52] Z.-H. Liu, J.-C. Chen, and T.-C. Chen, “Design and analysis of SIP-based
mobile VPN for real-time applications,” IEEE Trans. Wireless Commun.,
vol. 8, no. 11, pp. 5650–5661, Nov. 2009.
[53] “Columbitech wireless VPN technical description,” Columbitech, White
Paper, Oct. 2007 [Online]. Available: http://www.columbitech.com/img/
2008/3/5/16245.pdf
[54] D. Ahmat and D. Magoni, “MUSeS: Mobile user secured session,” in
Proc. Wireless Days (WD’12), 2012, pp. 1–6.
[55] T. Tiendrebeogo, D. Magoni, and O. Sié, “Virtual internet connections
over dynamic peer-to-peer overlay networks,” in Proc. 3rd Int. Conf.
Evolv. Internet (INTERNET’11), 2011, pp. 58–65.
[56] A. Zúquete and C. Frade, “Fast VPN mobility across wi-fi hotspots,”
in Proc. 2nd Int Workshop Secur. Commun. Netw. (IWSCN’10), 2010,
pp. 1–7.
[57] A. Gurtov, Host Identity Protocol (HIP): Towards the Secure Mobile
Internet. Hoboken, NJ, USA:Wiley, 2008, vol. 21.
[58] D. Comer and D. L. Stevens, Intenetworking With Tcp/Ip. Englewood
Cliffs, NJ, USA: Prentice-Hall, 2003.
[59] D. Geneiatakis et al., “Survey of security vulnerabilities in session initiation protocol,” IEEE Commun. Surv. Tuts., vol. 8, nos. 1–4, pp. 68–81,
3rd Quart. 2006.
[60] Birdstep Technologies. (2013). “Safemove mobile VPN product sheet,”
Oslo, Norway [Online]. Available: http://www.birdstep.com/media/
177925/product-sheet-safemove-mobile-vpn-7.0_web.pdf, accessed on
Jun. 15 2014.
[61] Birdstep Technologies. (2014). “Safemove for android,” Oslo, Norway
[Online]. Available: http://www.birdstep.com/media/197107/productsheet-safemove-for-android_web.pdf
[62] “Safemove toolkit for android,” Birdstep Technol., Tech. Rep., 2012
[Online]. Available: http://www.birdstep.com/media/174709/productsheet-safemove-toolkit-for-android-web.pdf, accessed on Jun. 15 2014
[63] Radio IP. “Datasheet ipunplugged,” Montreal, Canada, 2012 [Online].
Available: http://www.radioip.com/downloadfile/?file=/imports/medias/
download/ipu-data-sheet-final-november-2012.pdf, accessed on Jun. 15
2014
[64] NetMotion Wireless. (2014). “Core functionality of netmotion mobility,”
Seattle, WA, USA [Online]. Available: http://www.netmotionwireless.
com/mobile-vpn.aspx, accessed on: Jun. 15, 2014.
[65] Sierra Communications. (2008). “Enabling seamless and secure mobility
for the enterprise, an overview of the market drivers, alternatives and birdsteps safemove mobile VPN solution,” Mariposa, CA, USA Available:
http://www.marcomconsultant.com/samples/b-wpgsm.doc, accessed on
Jun. 06, 2014
[66] Cisco. (2015). Anyconnect FAQ: Tunnels, Reconnect Behavior, and
the Inactivity Timer [Online]. Available: http://www.cisco.com/c/en/us/
support/docs/security/anyconnect-secure-mobility-client/116312-qandaanyconnect-00.html, accessed on Jul. 05, 2015.
[67] Motorola, “Mobile VPN secure connectivity on the move,” Motorola
Inc., Tech. Rep. RO-99-2157, 2008 [Online]. Available: http://
content.motorolasolutions.com/web/Business/Products/Software%
20and%20Applications/Mobility%20Software/Mobile%20Application%
20Utilities/Multi-net%20Mobility/_docs/_staticfiles/Mobile%20VPN%
20white%20paper.pdf
[68] Motorola, “Multi-net mobility mobile VPN solution,” Motorola Inc.,
Tech. Rep. R3-14-2046A, 2008 [Online]. Available: http://content.
motorolasolutions.com/web/Business/Products/Software%20and%
20Applications/Mobility%20Software/Mobile%20Application%
20Utilities/Multi-net%20Mobility/_docs/_staticfiles/Multi-net%
20Mobility_SS.pdf
[69] Hobbit. Netcat [Online]. Available: http://sectools.org/tool/netcat/
[70] J. Dugan, S. Elliott, B. Mah, J. Poskanzer, and K. Prabhu. Iperf [Online].
Available: https://iperf.fr
[71] G. Combs. Wireshark [Online]. Available: https://www.wireshark.org
[72] Y. Sheffer and H. Tschofenig, “Internet key exchange protocol version
2 (IKEv2) session resumption,” RFC 5723(Proposed Standard), Internet
Engineering Task Force, Jan. 2010 [Online]. Available: https://tools.ietf.
org/html/rfc5723
[73] G. Lospoto, M. Rimondini, B. G. Vignoli, and G. Di Battista, “Rethinking
virtual private networks in the software-defined era,” in Proc. IFIP/IEEE
Int. Symp. Integr. Netw. Manage. (IM’15), 2015, pp. 379–387.
[74] J. Salowey, H. Zhou, P. Eronen, and H. Tschofenig, “Transport layer
security (TLS) session resumption without server-side state,” RFC
5077(Proposed Standard), Internet Engineering Task Force, Jan. 2008
[Online]. Available: http://www.ietf.org/rfc/rfc5077.txt

[75] E. Rescorla, M. Ray, S. Dispensa, and N. Oskov, “Transport layer
security (TLS) renegotiation indication extension,” RFC 5746(Proposed
Standard), Internet Engineering Task Force, Feb. 2010 [Online].
Available: http://www.ietf.org/rfc/rfc5746.txt
[76] K. Bhargavan, A. D. Lavaud, C. Fournet, A. Pironti, and P. Y. Strub,
“Triple handshakes and cookie cutters: Breaking and fixing authentication
over TLS,” in Proc. IEEE Symp. Secur. Privacy, 2014, pp. 98–113.
[77] V. Tzvetkov, “Fast detection of disconnection using adaptive fuzzy logic,”
in Proc. IEEE Int. Conf. Netw. Sens. Control, 2007, pp. 828–833.
[78] V. Tzvetkov, “Optimization of update intervals in dead-peer-detection
using adaptive fuzzy logic,” in Proc. Int. Conf. Adv. Inf. Netw. Appl.
(AINA’07), 2007, pp. 266–273.
[79] V. Tzvetkov, “Optimization of mobile updates using particle filter,”
in Proc. 3rd Int. Conf. Commun. Netw. China (ChinaCom’08), 2008,
pp. 915–920.
[80] Android Open Source Project. Android Developers Training: Optimizing
Downloads for Efficient Network Access [Online]. Available: http://
developer.android.com/training/efficient-downloads/efficient-networkaccess.html, accessed on Nov. 14, 2015.
[81] OpenVPN Technologies. OpenVPN [Online]. Available: http://www.
openvpn.net, accessed on Nov. 14, 2015.

Abdullah Alshalan (S’14) received the B.S. degree
(with Hons.) in computer science from King Saud
University, Riyadh, Saudi Arabia, and the M.S.
degree in computer science from Indiana University,
Bloomington, IN, USA, in 2003 and 2009, respectively. While on leave from the College of Computer
and Information Sciences, King Saud University, he
is pursuing the Ph.D. degree in computer science at
Arizona State University, Tempe, AZ, USA. He has
9 years of combined work experience in information
security engineering, programming, web development, and teaching. His research interests include computer networks, mobility,
information security, and cloud computing.
Sandeep Pisharody (S’13) received the B.S. degree
(distinction) in electrical engineering and the B.S.
degree (distinction) in computer engineering from
the University of Nebraska, Lincoln, NE, USA, in
2004, and the M.S. degree in electrical engineering
from the University of Nebraska, in 2006. He is currently pursing the Ph.D. degree in computer science
(information assurance) at Arizona State University,
Tempe, AZ, USA. He has over 8 years experience
in designing, building, and maintaining enterprise
and carrier class networks while working in various
capacities for Sprint, Iveda, University of Phoenix, and Insight. His research
interests include secure cloud computing and software defined networking.
Dijiang Huang (M’00–SM’11) received the B.S.
degree from Beijing University of Posts and
Telecommunications, Beijing, China, and the M.S.
and Ph.D. degrees from the University of MissouriKansas City, Kansas City, MO, USA, 1995,
2001, and 2004, respectively. He is an Associate
Professor with the School of Computing Informatics
and Decision System Engineering, Arizona State
University, Tempe, AZ, USA. His research interests include computer networking, security, and privacy. He is an Associate Editor of the Journal of
Network and System Management (JNSM) and an Editor of the IEEE
C OMMUNICATIONS S URVEYS AND T UTORIALS. He has served as an organizer for many international conferences and workshops. His research was
supported by the NSF, ONR, ARO, NATO, and Consortium of Embedded
System (CES). He was the recipient of the ONR Young Investigator Program
(YIP) Award.

2015 45th2015
Annual
IEEE
IEEE/IFIP
International
International
Conference
Conference
on Dependable
on Dependable
Systems and
Systems
Networks
and Networks
Workshops
Workshops

SeReNe: On Establishing Secure and Resilient
Networking Services for an SDN-based
Multi-Tenant Datacenter Environment
1

Chun-Jen Chung1 , Tianyi Xing1 , Dijiang Huang1 , Deep Medhi2 , Kishor Trivedi3
Arizona State University, 2 University of Missouri–Kansas City, 3 Duke University

Abstract—In the current enterprise datacenter networking
environment, a major hurdle in the development of network
security is the lack of an orchestrated and resilient defensive
mechanism that uses well-established quantiﬁable metrics, models, and evaluation methods. In this position paper, we describe
an emerging Secure and Resilient Networking (SeReNe) service
model to establish a programmable and dynamic defensive
mechanism that can adjust the system’s networking resources
such as topology, bandwidth allocation, and trafﬁc/ﬂow forwarding policies, according to the network security situations. We
posit that this requires addressing two interdependent technical
areas: (a) a Moving Target Defense (MTD) framework both at
networking and software levels; and (b) an Adaptive Securityenabled Trafﬁc Engineering (ASeTE) approach to select optimal
countermeasures by considering the effectiveness of countermeasures and network bandwidth allocations while minimizing
the intrusiveness to the applications and the cost of deploying
the countermeasures. We believe that our position can greatly
beneﬁt the virtual networking system established in datacenters
or enterprise virtual networking systems that have adopted latest
OpenFlow technologies.

to investigate a Moving Target Defense (MTD) approach to
establish a defense-in-depth intrusion detection, mitigation,
and prevention framework in the enterprise hybrid cloud
networks.
Many SDN-based cloud security solutions have been
proposed [4], [5] to counter various attacks on datacenter/enterprise networks. These approaches package network security countermeasures such as intrusion detection/prevention,
deep packet inspection, vulnerability analysis, etc., as cloud
commodities for cloud security services to accommodate the
attack scenarios for both attack prevention and mitigation in
a timely and intelligent fashion. The static nature of current
computing systems has made them easy to attack and harder to
defend. Adversaries have an asymmetric advantage in that they
have the time to study a system, identify its vulnerabilities,
and choose the time and place of attack to gain the maximum
beneﬁt. In SeReNe, the idea of Moving Target Defense (MTD)
is to impose the same asymmetric disadvantage on attackers
by making systems dynamic and therefore harder to explore
and predict. With a constantly changing system and its ever
adapting attack surface, attackers will have to deal with a great
deal of uncertainty just like defenders do today. The ultimate
goal of MTD is to increase the attackers’s workload so as to
level the cybersecurity playing ﬁeld for both defenders and
attackers, leading to even tilting it in favor of the defender.
To achieve MTD within a well-controlled networking environment, security needs originate from four directions that will
be addressed in SeReNe. The ﬁrst need is to accommodate
the network security measurement and evaluation models.
For example, an attack graph has been used to construct the
attack analysis model for a cloud virtual networking system
that is constructed by Virtual Machines (VMs) and their
interconnecting Virtual Networks (VNs) [6]. Frequent attack
graph updating and searching demands signiﬁcant computing
resources based on the number of vulnerabilities and the
complexity of VN topologies. One solution is to restrict
the attack graph by conﬁning cloud VNs (which is called
zoning) to a relatively small size and restrict trafﬁc ﬂows (i.e.,
reduce the number of vulnerabilities) and then combine the
security analysis results from multiple attack graphs (as well
as simpler attack countermeasure trees [7]) in a hierarchical
manner to obtain an overall system-level view. We have
heavily used such hierarchical and ﬁxed-point iterative models

I. I NTRODUCTION
In the past few years, we have seen a surge in the cloud
computing market. Many enterprises have been migrating
their partial or entire IT infrastructure (e.g., virtual machines
and their interconnections) into datacenters. An enterprise IT
infrastructure is actually a hybrid cloud: a public cloud consists
of outsourced computing and storage in datacenters and a
private cloud consists of enterprise owned IT facilities. Thanks
to Software Deﬁned Networking (SDN) [1] technologies and
Network Function Virtualization (NFV) [2] technologies, they
break the boundaries between different clouds and make
the cloud infrastructure seamless. With such an increase in
cloud-based services, questions have arisen about the security
issues in cloud. For example, users may install vulnerable
applications in their controlled Virtual Machines (VMs) or
devices, and restriction cannot be easily imposed on such
users. The Cloud Security Alliance (CSA) survey shows that
among all security issues, abuse and nefarious use of cloud
computing is considered as the top security threat [3], in which
attackers can exploit vulnerabilities through cloud networks,
and install malicious software on the compromised VMs
or devices that essentially contributes to loopholes in cloud
security. To address these security issues, in this position
paper, we describe SeReNe (Secure and Resilient Networking)
978-1-4673-8044-7/15 $31.00 © 2015 IEEE
978-0-7695-5533-1/15
DOI 10.1109/DSN-W.2015.25

4

they are broadly classiﬁed as MTD strategy-related research
and MTD techniques-related research: (a) SDN-based security
measurement and countermeasure solutions; (b) the software
vulnerability analysis, measurement, mitigation and models;
and (c) an optimal MTD techniques deployment mode in
the form of an Adaptive Security-enabled Trafﬁc Engineering
(ASeTE) approach.
This position paper is arranged as follows. In Section II,
related work is presented. In Section III, we presented SeReNe
in a systematic fashion with a goal to towards a signiﬁcant
improvement in the security of the datacenter virtual networking environment involving cloud computing service models
so that proactive countermeasures could be deployed with
consideration of the system resource consumption, software
bugs/vulnerabilities, effectiveness of countermeasures, and impact of consumer’s running applications. SeReNe applications
require security situation-awareness variables that must be
accurately predicted at a very ﬁne level (resolution from
a few million seconds to a few seconds). This introduces
an additional challenge, namely developing new performance
models for networking, data collection, Bigdata-enabled security processing, and control. In Section IV, these research
challenges will be presented with directions of future research
work.

in the performance and dependability modeling contexts [8]
The second need is to improve security performance. For
example, Heavy Hitter [9] and Heavy Change Detections [10]
are two anomaly detection techniques based on the streaming
change detection approach [11]. Exploiting software-deﬁned
networking (SDN), we can group these two types of trafﬁc
applying different intrusion detection models according to
users’ past behaviors or application types to improve the
overall performance of anomaly detection on unknown attacks
in terms of false negative and false positive. Note that both
of the above described trafﬁc management system are driven
by security, and have not been studied in literature. The
third need is that software is a substantial part of SDN and
hence software failures due to either security or non-security
vulnerabilities need to be seriously addressed. The fourth need
is a comprehensive evaluation model taking into considerations
attacks, vulnerabilities, and network and system resources
to dynamically change the system conﬁguration so as to
maximize the datacenter network system resiliency to attacks.
To this end, a new research area ”Security-Enabled Trafﬁc
Engineering” is emerging by leveraging on the research and
development of cloud computing, security, software dependability, software deﬁned networking, and usability. Compared
to traditional Trafﬁc Engineering approaches, which focus on
mainly improving networking resource utilization considering
various QoS requirements from the corresponding networking
system, security-enabled trafﬁc engineering extends the metrics and modeling to including security.
The design of an SeReNe targets a set of basic utilities
common to the majority of virtual IaaS cloud networking
systems that are based on OpenFlow technology, which is the
current de facto implementation of the SDN concept (in the
later description, we do not differentiate them). SeReNe will
serve as the built-in security support for virtual networking
based cloud service models and datacenters. We call SeReNe
the resource-aware cloud security framework. SeReNe will
facilitate the integration of the independently developed enterprise and individual cloud-based applications that demand
high privileges on the user-controlled cloud facilities.
^ĞZĞEĞDdƌĞůĂƚĞĚ
ƌĞƐĞĂƌĐŚ

II. R ELATED W ORK
The Moving Target Defense (MTD) has received signiﬁcant attention recently. For example, recent research efforts
have been initiated by NITRD [12], DARPA CFAR [13],
and ARO MURI project [14]. Several decision models have
been proposed on when, where, and how to make changes
to counter attacks [15]. Additionally, in the literature, many
moving target defense techniques have been proposed [16].
In general, the MTD techniques can be broadly categorized
into [17]: (a) dynamic runtime environment: techniques that
change the environment presented to an application by the
operating system (OS) dynamically during execution [18], (b)
dynamic software: techniques that change application’s code
dynamically [19], (c) dynamic data: techniques that change
the format, syntax, encoding, or representation of application
data dynamically [20], (d) dynamic networks: techniques that
change network properties including protocols or addresses
dynamically [6], and (e) dynamic platforms: techniques that
change platform properties (e.g., central processing unit (CPU)
or OS) dynamically [21]. The research challenges of MTD
technologies can be viewed as [22]: (i) coverage that refers to
the movement of all elements of the attack surface defended by
the technique, (ii) unpredictability that refers to the movements
being performed in a sufﬁciently large space as to render
guessing of the outcome infeasible, and (iii) timeliness that
refers to the synchronization of movements with attacker
observations. For MTD, our initial position is to focus on
how to make the movement predictable for defenders and
unpredictable for attackers with minimal interference to users.
Network virtualization techniques can logically separate different networks on the same hardware and partition resources

KƉƚŝŵĂůDddĞĐŚŶŝƋƵĞƐ
ĞƉůŽǇŵĞŶƚ

Dd^ƚƌĂƚĞŐŝĞƐ
ƚƚĂĐŬͲŐƌĂƉŚͬĐŽƵŶƚĞƌŵĞĂƐƵƌĞ
KƉƚŝŵĂůDdƚĞĐŚŶŝƋƵĞƐĚĞƉůŽǇŵĞŶƚ
ƚƌĞĞďĂƐĞĚƐĞĐƵƌŝƚǇĂŶĂůǇƐŝƐ
ďĂƐĞĚŽŶŶĞƚǁŽƌŬĂŶĚƐŽĨƚǁĂƌĞ
ŵŽĚĞůƐ
ĐŽƵŶƚĞƌŵĞĂƐƵƌĞƐĂŶĚƵƐĂďŝůŝƚǇ
^EͲďĂƐĞĚ^ĞĐƵƌŝƚǇ
DĞĂƐƵƌĞŵĞŶƚ͕ĂŶĚ
ĐŽƵŶƚĞƌŵĞĂƐƵƌĞĚĞƉůŽǇŵĞŶƚ

^ŽĨƚǁĂƌĞǀƵůŶĞƌĂďŝůŝƚǇĂŶĂůǇƐŝƐ
ŵŽĚĞůƐĂŶĚDdƐŽůƵƚŝŽŶƐ

DddĞĐŚŶŽůŽŐŝĞƐ
ϭ͘WƌŽŐƌĂŵŵĂďůĞΘƌĞĐŽŶĨŝŐƵƌĂƚŝŽŶ
ϭ͘^ŽĨƚǁĂƌĞǀƵůŶĞƌĂďŝůŝƚǇĐůĂƐƐŝĨŝĐĂƚŝŽŶ
Ϯ͘ƚƚĂĐŬĚĞƚĞĐƚŝŽŶ
Ϯ͘^ŽĨƚǁĂƌĞďĞŚĂǀŝŽƌŵŽĚĞůŝŶŐ
ϯ͘^ĞĐƵƌŝƚǇĂƉƉůŝĂŶĐĞĚĞƉůŽǇŵĞŶƚ
ϯ͘^ŽĨƚǁĂƌĞĚŝǀĞƌƐŝĨŝĐĂƚŝŽŶ
ϰ͘ůŽƵĚƌĞƐŽƵƌĐĞŵĂŶĂŐĞŵĞŶƚ
ϰ͘^ŽĨƚǁĂƌĞƌĞũƵǀĞŶĂƚŝŽŶ

Fig. 1.

SeReNe system components.

Overall, the SeReNe framework is composed of three fundamental system components that are highlighted in Figure 1;

5

accordingly. Isolation between coexisting virtual networks can
only provide a certain level of security through the use of
secured tunnels, encryptions, and so on. However, it does
not obviate the prevalent threats, intrusions, and attacks to
the physical layer and virtual networks. OpenFlow has also
been used to create applications that provide security to the
network. Chu et al. [23] proposed a method that analyzes
the frequency of trafﬁc. If a threshold is exceeded, then the
controller considers it a DDoS attack and it starts dropping
packets. Braga et al. [24] proposed a method that gathers trafﬁc
information and uses self organizing maps to classify the trafﬁc
as normal or malicious. Yao et al. proposed VAVE [25], which
is an OpenFlow-based architecture designed to validate the
address of all incoming packets. Jafarian et al. [26] proposed
a MTD technique using OpenFlow. The proposed defense
assigns virtual IP addresses to hosts and the controller maps
virtual addresses to physical addresses. Finally, trafﬁc isolation
has been studied by Gutz et al. [27]. The authors argue that
current trafﬁc isolation techniques such as VLANs increase
the complexity of the network conﬁguration. They propose
creating network slices at a higher level. Some of the research
challenges in the existing datacenter networking security are
as follows: guaranteed performance of applications, ﬂexible
deployment of appliances (e.g. intrusion detection systems
or ﬁrewalls), software bugs and vulnerabilities’ impact to
dynamic and adaptive defense environment [28], and associated complexities to the policy enforcement and topology
dependence. Previous solutions have addressed various issues
on attack detection and responses using attack graphs and
trafﬁc engineering approaches. However, none of these can
be directly applied in dynamically changing virtual networking
environments and address the presented research challenge that
we are proposing to consider in this position paper.
Cloud datacenter networking has been receiving a lot of attention in recent years. A number of early works on datacenter
networking have focused on architectural design of datacenter
networks [29]. The main difference in our approach is that we
take an integrated trafﬁc engineering approach that considers
security requirements; furthermore, we show how an adaptive
approach in response, as countermeasures, provide different
users their service guarantees.

Fig. 2.

SeReNe system setup within one datacenter cluster.

including four major components. SeReNe leverages the SDN
network controller and cloud controller available from existing cloud management frameworks, e.g., OpenStack [31].
In the following subsections, our discussion focuses on the
following SeReNe components as highlighted in Figure 1: (a)
programmable network moving target defense, (b) software
vulnerability mitigation moving target defense, and (c) how
to integrate the network and software defense into a novel
security-enabled trafﬁc-engineering model.
A. Programmable Network Moving Target Defense and Mitigation
Network-Security-as-a-Service (NSaaS) [30] is a security
appliances allocation model according to security requirements
to be enforced in the datacenter networking environment. Similar work has been presented in the Internet environment [32],
where the authors proposed a mechanism called FireCol that
is a collaborative system detecting ﬂooding DDoS attacks on
the Internet Service Provider (ISP) network. In general, NSaaS
is deployed based on the cloud system resource management
according to the utilization of vCPU, memory, virtual hard
disk, network bandwidth, etc. In our recent work [30], we
presented how to use NSaaS framework to deploy security
appliances such as IPS, IDS, DPI, FW, in the datacenter networking environment considering system resource utilization
by scaling-up/down and scaling-out/in cloud resources; this is
highlighted in Figure 2.
In order to manage software changes such as install/uninstall, change/switch versions, the presented software changing approaches need to rely on cloud resource
management systems, such as using OpenStack Heat [33],
MAAS/JuJu [34] to handle system software and software running environment changes, and using Puppet [35] to manage
the software changes within a VM. These approaches can
be applied for handling MTD techniques such as software
diversiﬁcation and rejuvenation, which will be described in
Section III-B.
1) Attack Graph and Attack Tree based Security Quantiﬁcation and Analysis: As shown in Figure 1, our approach
includes both MTD strategies and MTD techniques. The
security analyzer shown in Figure 2 is one of the key MTD

III. S E R E N E : T HE F RAMEWORK
The SeReNe system framework is illustrated in Figure 2.
It shows the SeReNe framework in an enterprise virtual networking environment including cloud tenants running within
the datacenter’s programmable networks and edge cloud (i.e.,
customer resources such as computers or mobile devices). This
setup is to demonstrate a common enterprise’s programmable
networking environment where the IT infrastructure can be
established based on public and private clouds running within
one or more datacenters and edge clouds containing end
users’ computer/devices. In SeReNe, network and software
security services can be componentized as security appliances to provide Network-Security-as-a-Service (NSaaS) [30].
NSaaS is controlled by the cloud security service model

6

using the streaming change detection approach [11]. The heavy
hitter set is a set of ﬂows that represents a signiﬁcantly large
portion of the ongoing trafﬁc. The heavy change set is the
ﬂows that have signiﬁcant changes in trafﬁc volume from one
time period to another. By learning the cloud nodes trafﬁc
history, the cloud SDN controller can group heavy hitter trafﬁc
and heavy change trafﬁc through IDS/IPS applying different
anomaly detection models in order to reduce false positives
and false negatives.
TABLE I
P OSSIBLE C OUNTERMEASURE T YPES
Fig. 3.

Layers
Layer-2
Layer-2
Layer-2 or 3
Layer-2 or 3
Layer-3
Layer3
Layer-4
App
App
App
App/System
App/System
System
System
...

Work ﬂow of Security Analyzer.

strategic approaches to measure and evaluate the severity of
identiﬁed security vulnerability or breaches. Figure 3 shows
its workﬂows. After receiving an alert from a detection agent,
which resides on each physical cloud server, the alert analyzer
matches the alert in an Attack Correlation Graph (ACG) [5]
to correlate attackers’ behaviors. For example, if the alert
already exists in the graph and it is a known attack (i.e.,
matching the attack signature) the security analyzer performs
a countermeasure selection procedure based on both positive
impact, such as countermeasure effectiveness, and negative
impact, such as deployment cost and intrusiveness to existing
applications; and then notiﬁes the SDN network controller or
software controller to deploy countermeasures or mitigation
actions by consulting the ASeTE model that takes network
trafﬁc and QoS into the considerations; see Section III-C. If the
alert is new, the security analyzer will perform alert correlation
and analysis and update the Scenario Attack Graph (SAG)
[5]. The network controller applies a selected countermeasure
according to the severity of the security evaluation results.
The beneﬁt of this approach is to appropriately decide when
to apply network reconﬁgurations (i.e., countermeasures).
2) SDN-based Zero-day Attack Prevention: The proposed
SeReNe system is a dynamic and reconﬁgurable security
system that enables the cloud networking system to defend
attacks in a proactive and dynamic fashion. First, vulnerability inspections are based on known vulnerabilities, i.e.,
vulnerability information is generated by both on-demand
vulnerability scanning (i.e., initiated by the network controller
and SeReNe attack detection agent) and regular penetration
testing using the well-known vulnerability databases, such as
Open Source Vulnerability Database (OSVDB) [36], Common
Vulnerabilities and Exposures List (CVE) [37], and the NIST
National Vulnerability Database (NVD) [38]. SeReNe must be
able to take care of Zero-day attacks where the vulnerability
is discovered by the attacker but is not detected by the
vulnerability scanner. In such a case, the alert being real
will be regarded as false, given that there does not exist a
corresponding node in ACG.
To address the zero-day attacks, SeReNe takes anomalybased intrusion detection models. The dynamic and ﬂexible
nature of SDN allow the system to deploy various network
reconﬁguration strategies according to the applied anomaly
detection metrics. For example, Heavy Hitter [9] and Heavy
Change Detections [10] are two simple detection techniques

Countermeasure
MAC address change
Switch Reconﬁguration
Trafﬁc redirection
Trafﬁc isolation
IP address change
Network topology change
Change/Block port
Deep Packet Inspection
Software patch
Quarantine
Software Diversiﬁcation
Software Rejuvenation
Introducing VMs
Creating ﬁltering rules
...

3) SDN-based Countermeasures Deployment and Reconﬁguration for MTD: In SeReNe, a countermeasure is an action
or a serial of actions that thwarts attacks, wherein it can
change the network conﬁgurations and trafﬁc policies. Here
we consider deploying a security appliance (e.g., IPS) that
introduces a sequence of security actions in cloud virtual
networking environments, and thus, we do not differentiate
countermeasures and the security appliance in the remaining
discussion. When an attack event or a software vulnerability
has been identiﬁed, one (or a set) of effective countermeasures
needs to be chosen among many for deployment. The attributes
such as cost, time to deploy, and the potential to reduce the
performance or availability of the system resources need to be
considered. Using an attack graph to model the attackers’ behaviors and selecting countermeasures have been well-studied,
[6]. However, there is no previous work that uses attack graphs
in a highly dynamic virtualized and reconﬁgurable networking
environment and considers applying countermeasures in a
dynamic fashion. In general, there are many countermeasures
that can be applied to the cloud virtual networking system
depending on available security appliances that can be applied.
Several common virtual-networking-based countermeasures
are listed in Table I. In SeReNe, the network reconﬁguration
strategies involve several levels of actions from layer-2 to the
upper layers. At layer-2, virtual bridges (including tunnels that
can be established between two bridges) and VLANs are the
main components in the cloud’s virtual networking system to
connect two VMs directly. A virtual bridge is an entity that attaches Virtual Interfaces (VIFs). Virtual machines on different
bridges are isolated at layer 2. VIFs on the same virtual bridge

7

but with different VLAN tags cannot communicate to each
other directly. Based on this layer-2 isolation, SeReNe can
deploy a layer-2 network reconﬁguration to isolate suspicious
VMs. For example, vulnerabilities due to ARP-spooﬁng [39]
attacks are not possible when the suspicious VM is isolated to
a different bridge. As a result, this countermeasure disconnects
an attack path in the attack graph causing the attacker to
explore an alternate attack path. The layer-3 reconﬁguration is
another way to disconnect an attack path. Through the network
controller, the ﬂow table on each OpenFlow switch (e.g., both
software and physical switches) can be modiﬁed to change
the network topology. Similarly, upper-level counter measures
such as port changing/blocking, application protocol ﬁltering,
DPI, etc., can be deployed.
We must note that using the virtual network reconﬁguration
approach at a lower layer has the advantage in that upper
layer applications will experience a minimal impact. This
approach is only possible when using the software-switching
approach to automate the reconﬁguration in a highly dynamic
networking environment. Countermeasures (such as trafﬁc isolation) can be implemented by utilizing the trafﬁc engineering
capabilities of the OpenFlow switches to restrict the capacity
and reconﬁgure the virtual network for a suspicious ﬂow.
When a suspicious activity, such as network and port scanning
is detected in the cloud system, it is important to determine
whether the detected activity is indeed malicious or not.
For example, attackers can intentionally hide their scanning
behavior to prevent the network IDS from identifying their
actions. In this situation, changing the network conﬁguration
will force the attacker to perform more explorations and in
turn will make their attacking behavior stand out.

they do not change their behavior as the system state changes.
Mandelbugs activation, on the other hand, depends not only
on the workload but also on different environmental factors,
such as the state of operating system resources, concurrency
with other processes, hardware and software interactions, and
other factors. These are bugs where you might run the same
program a thousand times on similar or even identical data,
but only once might it activate. In the class of Mandelbugs,
a type of bug that has been found widely in long running
software is called software aging related bug [41], [42], [43],
[44], [45] where operating system resources get depleted
(due to software bugs) over time making the system appear
to age with time, a simple example being memory leaks.
In analogy with our work on classifying software bugs, we
have begun to classify software vulnerabilities into Bohr,
Mandel and aging-related vulnerabilities. Implications of this
could be enormous. SeReNe focuses on the mechanisms
of Mandelbugs and Mandel vulnerabilities, including their
classiﬁcation, causes, impacts and activation. By controlling
the system environmental factors at the testing time, it should
be possible to reduce the reproducibility uncertainty inherent
in the Mandelbugs and vulnerabilities, in some cases leading
to their identiﬁcation and removal. SeReNe takes these into
considerations by determining key environmental factors that
can signiﬁcantly enhance reproducibility; consequently, the
percentage of Mandelbugs and vulnerabilities are removed
prior to deployment of SDN.
The main means of software fault/intrusion tolerance in the
literature is found to be based on costly design diversity [46],
where multiple independent versions of programs are created
to solve the same problem. We advocate more affordable
environmental diversity of a single version at runtime. Here,
the same program is run in multiple copies of the computing
environment, with the expectation that rare system states that
trigger uncommon bugs/vulnerabilities will not manifest in all
copies of the environment at once [28], [47], [40]. Note that
real systems today do frequently employ the techniques of
restart, reboot, and fail-over to an identical software copy as
a means of recovery after a software failure [48]; this can be
viewed as a form of MTD in that the system is reset to a
cleaner state in the act of restarting. But scientiﬁc literature
has not addressed the real reason as to why such recovery
methods do work.
Thus, SeReNe is advocating a major shift in dealing with
software faults and failures on the one hand and software
vulnerabilities on the other: it starts from the basic level by
studying the use of fault/intrusion tolerance methods based on
environmental diversity and self-adaptation for dealing with
software failures (intrusions) caused by Mandelbugs (vulnerabilities) to support and implement SDN. For aging related
bugs/vulnerabilities, the reactive solutions (for example, restart
or operating system reboot) and proactive solutions (namely
software rejuvenation [41]) will be researched as well for
SDN. SeReNe employs failure (intrusion) data analytics [49],
recovery strategies [50], novel testing strategies for Mandelbugs and Mandel vulnerabilities [51], experimentation [52],

B. Software Vulnerability and Moving Target Defense
Software dominates most current large-scale systems including SDN. Software dependability and security are thus
critical in assuring the resilience of these complex systems.
Despite decades of work in this area, software remains a weak
link in system integrity, leading to failures that compromise
safety, security and/or impose ﬁnancial costs. The challenge
posed is at once of critical importance and immense. We
believe progress is best made through a new approach that
focuses on mitigating the types of software bugs/vulnerabilities
that are most difﬁcult to address with conventional methods. Hitherto effort in software reliability is mainly focused
on removal of bugs/vulnerabilities during testing phase as
well as during the operational phase. However, detection
and removal of all bugs/vulnerabilities from code remains a
vexingly difﬁcult problem. We must note that rarely activated
bugs/vulnerabilities is likely continue to persist even in welltested programs, and yet we must still strive to have the system
behave correctly.
Much of the effort in software dependability has been on
locating and removing software bugs known as Bohrbugs
as opposed to more-difﬁcult-to-reproduce Mandelbugs (also
called concurrency bugs or non-deterministic bugs) [40].
Bohrbugs are bugs in software that are easy to reproduce;

8

equation) that no path is chosen to unselected host m. The
bandwidth needed on link  of the cloud datacenter network
for VN tenant j to satisfy the associated demand at review
point t is given by:

stochastic models [41] and optimization [44]. In particular,
SeReNe classiﬁes vulnerabilities into Bohr, Mandel and agingrelated ones following the approach we have used in analyzing
the NASA satellite problem reports [53], [54] and open source
bugzila reports [49]. It also takes into considerations environmental factors responsible for Mandel and aging-related
vulnerabilities so as to enhance their chances of being exposed
during experimental attack campaign and thus remove them.
Furthermore, SeReNe plans to apply a combination of design
diversity and environmental diversity based defense technique
(a.k.a., defense across space and time [28]) to ﬁnd an optimal
mix using experiments, statistical analysis, stochastic models
and optimization techniques.

∑ ∑j

e ∈ E, j ∈ J.

j

j

j

j

j ∈ Me (t), e ∈ E, j ∈ J.

(3)

If the total bandwidth available on link  at review point t is
c , then the total bandwidth needed for all VN tenants must
be satisﬁed, which can be expressed as
j

∑ j∈J z (t) ≤ c (t),

 ∈ L.

(4)

Also note that each host m may serve a limited number of
virtual machines, Km (t), at review point t for all the requests
j

∑ j∈J ∑e∈E yem (t) ≤ Km (t).

(5)

For requests for tenant j at entry point e, assume that the
j
resource required at a VM (e.g., CPU resource) is re (t). Then,
we need to ensure two conditions. First, no requirements use
more resources than an upper limit for each VN j (in case,
an attack overpowers a VM), and accordingly, the total host
resources must still be satisﬁed
j

re (t) ≤ r̂v
j
j
∑ j∈J ∑e∈E re (t)yem (t)

(6)
≤ Rm (t).

(7)

In the above model, we state that for a particular VN,
a single host is chosen as given by (1). However, it is not
necessary to limit it to just one host. Certainly, multiple hosts
can be used - in this case, this equation changes, where the
right hand side is set J j as the number of hosts associated with
VN tenant j. We also introduce a generic index called entry
point e. This can be generalized to consider either multiple
entry points at a speciﬁc datacenter, or multiple datacenters
that are geographically distributed. For multiple datacenter
locations, SeReNe needs to consider how the mobile location
of the end users may be taken into account so that the
most optimal datacenter may serve the end users of particular
tenants. In the above model, the notion of review points is
generic. The frequency of review points is up to the provider
of SeReNe. It is a trade-off between high and low frequent
review points that are invoked and its relation to adaptiveness
to incoming tenant’s requirements. This will also address the
issue of any instability that might be instantiated if the review
points are too close to each other as one of the goals of
SeReNe is to avoid any instability in the IPS system.

(1)

If a particular host m is selected, then a path needs to be
selected from entry point e to m from a list of possible paths,
j
Pem (t), through the datacenter network. This can be shown as
follows:
x (t) = yem (t),
j
∑ p∈Pem
(t) emp

j
δemp, (t) xemp
(t)dej (t)

= z (t),  ∈ L, j ∈ J.

Adaptive Security-enabled Trafﬁc Engineering (ASeTE) is
to support and regulate different tenants’ requirements and
situations in providing an effective IPS for all. For this
purpose, resources must be allocated efﬁciently and adaptively.
In order to achieve efﬁcient management, SeReNe operates
at two different time scales. One is a regularly scheduled
window when the virtual network (VN) provisioning for new
tenants is done based on SDN technologies; we refer to time
instances for this schedule as review points. The second is that
an on-demand action may be needed due to addressing attack
countermeasures when vulnerabilities are identiﬁed. Based on
the attack graph and the scope of SeReNe, we have determined
a number of potential scenarios, each of which has a different
virtual network provisioning problem (in term of goals and
scope) to solve. For example, one may require new VMs for
a tenant for IPS, and another may require new paths and
IPS resources. The reason for having different ASeTE models
ready is to be able to provide effective and efﬁcient adaptive
virtual network provisioning for the problem at hand. This also
reduces the complexity of SeReNe in terms of invocation and
execution on demand.
In ASeTE model, at review point t, each tenant’s requirement is to be met by having an IPS image at the datacenter.
These are to be assigned through the network and virtual
j
machines if resources are available. Thus, consider de (t) to
be the bandwidth demand for VN tenant j entering at entry
j
point e at time t. Me is the set of hosts that can serve entry
point e for virtual network tenant j at review point t. We can
j
model this by deﬁning a binary variable yem (t) that satisﬁes
the following requirement:
j

j

e∈E m∈M (t) p∈P (t)
e
em

C. Security-Enabled Trafﬁc Engineering

∑m∈Mej (t) yem (t) = 1,

∑j

IV. S UMMARY AND O PEN R ESEARCH C HALLENGES
SeReNe relies on network reconﬁguration, software aging
and diversifying strategies to prevent, detect and mitigate
attacks. In order to select the most effective or optimal
countermeasure, attack mitigation strategies in response to
vulnerability explorations and providing users’ QoS guarantees
need to be further studied. A few performance metrics that

(2)

Note that since only one m is chosen for each request entering
e for VN tenant j at review point t, then all other ys will be
set to zero, which will automatically ensure (from the above

9

objective will be considered if we were to incur a cost for
establishing new tenants. Furthermore, there are additional
goals that can be addressed such as network load balancing,
VM load balancing, and availability. We anticipate that when
objectives with differing goals are considered, there is a
potential for conﬂict among goals. One of research challenges
is how to address this conﬂict. One possible research directions
is borrowing ideas from multi objective optimization, where
it can take a utility function based approach and determine
Pareto optimal solution.
Another research challenge for ASeTC is how to consider
system adaptivity between review points. In such cases, no
new tenants may be added, but we may consider addition, of
say, an increase in CPU resources or new VMs, for existing
tenants due to a surge in demand. While this may look like a
local action that may result in a suboptimal result, we are at
an advantage when we consider an SDN-based environment
since the SDN controller has a global view of system resource
uses. Thus, another optimization can be performed between
review points to do system allocation that can still take a global
view. Certainly, there are additional stability issues when such
short-term optimization is invoked. Our research will explore
understanding this system dynamics and stability issues at the
ﬁnal granularity level.

impact security countermeasure selections considering above
described strategies need to be studied: (a) Cost describes the
expenses required to apply the countermeasure in terms of resources and operational complexity such as CPU computation,
memory and storage space, bandwidth consumption, and number of VMs, etc.; (b) Intrusiveness is the negative effect that
a countermeasure brings to the SLA, such as the percentage
change of bandwidth after applying the countermeasure, which
includes network delay, jitter, and bandwidth reduction; and (c)
Consequence is the percentage of attack probability changes
after deploying a countermeasure. Here we highlight a few
future research challenges related to the SeReNe approach.
A. Open Research Challenges
1) SDN-based MTD Approaches: The main research challenge of deploying the security analyzer procedure presented
in Figure 2 is that attack graph based approaches usually have
scalability issues. The scalability issues can incur during attack
graph generation, representation, evaluation, and modiﬁcation.
When network topology changes, or a new vulnerability is
discovered, SeReNe requires an attack graph based analysis
to perform and thus a centralized analysis model cannot scale
with the realtime constraints (e.g., at a sub-second level). In
SeReNe, we plan to explore the attack graph scalability issues
based on two approaches. First, we consider the attack graph
processing is data-intensive and can apply parallel computing
framework such as a Hadoop MapReduce environment [55],
Giraph [56], or Spark [57] to share the computing workload. Second, partitioning the cloud virtual networking system
into multiple virtualized virtual network zones to reduce the
computation overhead should be explored. Each zone may
dedicate an attack graph analysis work node in the parallel
processing framework. In this way, the attack graph analysis
can be conﬁned within relatively small scope to reduce the
analysis overhead. Additionally, using SDN approaches, trafﬁc
between different virtual zones can be restricted by deploying
a security-ﬁltering appliance between virtual zones to further
reduce the complexity when combining attack graph analysis
results from different zones.
2) Software Vulnerabilities for MTD: The defense of software vulnerability in both space and time approaches requires
a deeper investigation to better understand the nature of
vulnerabilities and the triggers that produce security violations
so that we can devise a comprehensive testing strategy on
the one hand and employ the most appropriate MTD based
intrusion tolerance on the other. Furthermore how to optimize
software system availability (or minimize downtime) using
the combination of testing techniques most appropriate for
Mandelbugs [51] and aging-related bugs [45] as well as
runtime recovery techniques most suited to the failures caused
by each of these types of bugs.
3) Secure Trafﬁc Engineering for MTD: In the presented
ASeTE model, a potential objective is the use of the least
number of network resources at current review point t. On
the other hand, there might be a system cost to establish
a new tenant at a review point. Thus, a variation in this

ACKNOWLEDGMENT
This research has been supported in part by NATO Science
for Peace and Security project number 984425 and National
Science Foundation Grant No. CNS-1217736.
R EFERENCES
[1] “Openﬂow.”
[Online].
Available:
http://www.openﬂow.org/wp/
learnmore/
[2] “Network Function Virtualization,” available at http://en.wikipedia.org/
wiki/Network Functions Virtualization.
[3] Coud Sercurity Alliance, “Top threats to cloud computing v1.0,” https:
//cloudsecurityalliance.org/topthreats/csathreats.v1.0.pdf, March 2010.
[4] C.-J. Chung, J. Cui, P. Khatkar, and D. Huang, “Non-intrusive processbased monitoring system to mitigate and prevent VM vulnerability
explorations.” ICST, 2013.
[5] C.-J. Chung, P. Khatkar, T. Xing, J. Lee, and D. Huang, “NICE: network
intrusion detection and countermeasure selection in virtual network
systems,” IEEE Transactions on Dependable and Secure Computing,
vol. 10, no. 4, pp. 198–211, 2013.
[6] ——, “Nice: Network intrusion detection and countermeasure selection in virtual network systems,” IEEE Transactions on Dependable
and Secure Computing (TDSC), Special Issue on Cloud computing Assessment: metrics, algorithms, policies, models, and evaluation
techniques, pre-print, avaialble at http://dj.eas.asu.edu/snac/document/
tdsc-vinice-v8.pdf, 2012.
[7] A. Roy, D. S. Kim, and K. S. Trivedi, “Scalable optimal countermeasure
selection using implicit enumeration on attack countermeasure trees,”
in IEEE/IFIP International Conference on Dependable Systems and
Networks, DSN 2012, Boston, MA, USA, June 25-28, 2012, 2012, pp.
1–12.
[8] R. Ghosh, F. Longo, F. Frattini, S. Russo, and K. S. Trivedi, “Scalable
analytics for iaas cloud availability,” IEEE T. Cloud Computing, vol. 2,
no. 1, pp. 57–70, 2014.
[9] G. Cormode, F. Korn, S. Muthukrishnan, and D. Srivastava, “Finding
hierarchical heavy hitters in data streams,” in Proceedings of the 29th
International Conference on Very Large Data Bases - Volume 29, ser.
VLDB ’03. Berlin, Germany: VLDB Endowment, 2003, p. 464475.

10

[30] T. Xing, Z. Xiong, D. Huang, and D. Medhi, “Cloud security,” in
Cloud Services, Networking and Management (eds. N. Fonseca and R.
Boutaba). IEEE and Wiley, 2015.
[31] “OpenStack Open Source Cloud Computing Software,” available at http:
//www.openstack.org, 2011.
[32] J. Francois, I. Aib, and R. Boutaba, “FireCol: a collaborative protection network for the detection of ﬂooding DDoS attacks,” IEEE/ACM
Transactions on Networking, vol. PP, no. 99, p. 1, 2012.
[33] “OpenStack Heat,” available at https://wiki.openstack.org/wiki/Heat.
[34] “OpenStack MAAS/JuJu,” available at https://maas.ubuntu.com/docs/
juju-quick-start.html.
[35] “Puppet Software,” available at http://puppetlabs.com/.
[36] O. Database, “Open source vulnerability database (OVSDB),” http:
//osvdb.org/.
[37] Mitre Corporation, “Common vulnerabilities and exposures, CVE,” http:
//cve.mitre.org/.
[38] NIST, “National vulnerability database, NVD,” http://nvd.nist.gov.
[39] K. Kwon, S. Ahn, and J. Chung, “Network security management using
ARP spooﬁng,” in Computational Science and Its Applications – ICCSA
2004, ser. Lecture Notes in Computer Science.
Springer Berlin /
Heidelberg, 2004, vol. 3043, pp. 142–149.
[40] M. Grottke and K. S. Trivedi, “Fighting bugs: Remove, retry, replicate,
and rejuvenate,” Computer, vol. 40, no. 2, pp. 107–109, Feb. 2007.
[41] K. Vaidyanathan and K. Trivedi, “A comprehensive model for software
rejuvenation,” Dependable and Secure Computing, IEEE Transactions
on, vol. 2, no. 2, pp. 124–137, April 2005.
[42] M. Grottke and B. Schleich, “How does testing affect the availability of
aging software systems?” Perform. Eval., vol. 70, no. 3, pp. 179–196,
2013.
[43] J. Zhao, Y. Wang, G. Ning, K. S. Trivedi, R. M. Jr., and K. Cai, “A
comprehensive approach to optimal software rejuvenation,” Perform.
Eval., vol. 70, no. 11, pp. 917–933, 2013.
[44] J. Zhao, Y. Jin, K. S. Trivedi, R. M. Jr., and Y. Wang, “Software
rejuvenation scheduling using accelerated life testing,” JETC, vol. 10,
no. 1, p. 9, 2014.
[45] R. Matias, A. Andrzejak, F. Machida, D. Elias, and K. Trivedi, “A
systematic differential analysis for fast and robust detection of software
aging,” in 33rd Int. Symp. on Reliable Distributed Systems, October
2014.
[46] M. Malaika, S. Nair, and F. Coyle, “N-version architectural framework
for application security automation (nvasa),” in CrossTalk, The Journal
of Defense Software Engineering (DoD), 2014.
[47] J. Gray, “Why do computers stop and what can be done about it?”
in Proc. 5th Symposium on Reliability in Distributed Software and
Database Systems, 1986, pp. 3–12.
[48] K. Trivedi, D. Wang, D. J. Hunt, A. Rindos, W. E. Smith, and B. Vashaw,
c
c in De“Availability modeling of sip protocol on ibmwebsphere
,”
pendable Computing, 2008. PRDC ’08. 14th IEEE Paciﬁc Rim International Symposium on, Dec 2008, pp. 323–330.
[49] D. Cotroneo, M. Grottke, R. Natella, R. Pietrantuono, and K. Trivedi,
“Fault triggers in open-source software: An experience report,” in
Software Reliability Engineering (ISSRE), 2013 IEEE 24th International
Symposium on, Nov 2013, pp. 178–187.
[50] K. Trivedi, R. Mansharamani, D. Kim, M. Grottke, and M. Nambiar,
“Recovery from failures due to mandelbugs in it systems,” in 2013 IEEE
19th Paciﬁc Rim International Symposium on Dependable Computing,
vol. 0, Los Alamitos, CA, USA, 2011, pp. 224–233.
[51] D. Cavezza, R. Pietrantuono, J. Alonso, S. Russo, and K. Trivedi, “Reproducibility of environment-dependent software failures: an experience
report,” in Int. Symp. on Software Reliability Engineering, 2014, pp. 1–9.
[52] J. Alonso, M. Rivalino, E. Vicente, A. Maria, and K. Trivedi, “A
comparative experimental study of software rejuvenation overhead,”
Perform. Eval., vol. 70, no. 3, pp. 231–250, 2013.
[53] M. Grottke, A. Nikora, and K. Trivedi, “An empirical investigation of
fault types in space mission system software,” in Dependable Systems
and Networks (DSN), 2010 IEEE/IFIP International Conference on, June
2010, pp. 447–456.
[54] J. Alonso, M. Grottke, A. Nikora, and K. Trivedi, “The nature of the
times to ﬂight software failure during space missions,” in Software Reliability Engineering (ISSRE), 2012 IEEE 23rd International Symposium
on, Nov 2012, pp. 331–340.
[55] “Apache hadoop.” [Online]. Available: http://hadoop.apache.org/
[56] “Apache giraph.” [Online]. Available: http://giraph.apache.org/
[57] “Apache Spark,” available at https://spark.apache.org/.

[10] C. Callegari, S. Giordano, M. Pagano, and T. Pepe, “Detecting anomalies
in backbone network trafﬁc: a performance comparison among several
change detection methods,” International Journal of Sensor Networks,
vol. 11, no. 4, pp. 205–214, Jan. 2012.
[11] C. Callegari, A. Coluccia, A. DAlconzo, W. Ellens, S. Giordano,
M. Mandjes, M. Pagano, T. Pepe, F. Ricciato, and P. Zuraniewski,
“A methodological overview on anomaly detection,” in Data
Trafﬁc Monitoring and Analysis, ser. Lecture Notes in Computer
Science, E. Biersack, C. Callegari, and M. Matijasevic, Eds.
Springer Berlin Heidelberg, Jan. 2013, no. 7754, pp. 148–
183. [Online]. Available: http://link.springer.com.ezproxy1.lib.asu.edu/
chapter/10.1007/978-3-642-36784-7 7
[12] “The networking and information technology research and development program,” available at http://www.whitehouse.gov/sites/default/
ﬁles/microsites/ostp/NITRD FY15 Final.pdf, 2014.
[13] “Darpa cyber fault tolerant recovery program,” available
at
https://www.fbo.gov/index?s=opportunity&mode=form&id=
43b09e88c3b8289cb4cbf63b402f46c5&tab=core& cview=1, 2014.
[14] “Adversarial and uncertain reasoning for adaptive cyber defense: Building the scientiﬁc foundations,” available at http://csis.gmu.edu/pages/
projects/ACD-MURI.html, 2013.
[15] R. Zhuang, S. A. DeLoach, and X. Ou, “Towards a theory of moving
target defense,” in Proceedings of the First ACM Workshop on Moving
Target Defense. ACM, 2014, pp. 31–40.
[16] S. Jajodia, A. K. Ghosh, V. Subrahmanian, V. Swarup, C. Wang, and
X. S. Wang, Moving Target Defense II. Springer, 2013.
[17] J. Xu, P. Guo, M. Zhao, R. F. Erbacher, M. Zhu, and P. Liu, “Comparing
different moving target defense techniques,” in Proceedings of the First
ACM Workshop on Moving Target Defense. ACM, 2014, pp. 97–107.
[18] J. H. H. Jafarian, E. Al-Shaer, and Q. Duan, “Spatio-temporal address
mutation for proactive cyber agility against sophisticated attackers,” in
Proceedings of the First ACM Workshop on Moving Target Defense.
ACM, 2014, pp. 69–78.
[19] S. B. Mark Murphy, Per Larsen and M. Franz, “Software proﬁling
options and their effects on security based code diversiﬁcation,” in
Proceedings of the First ACM Workshop on Moving Target Defense.
ACM, 2014.
[20] P. E. Ammann and J. C. Knight, “Data diversity: An approach to
software fault tolerance,” Computers, IEEE Transactions on, vol. 37,
no. 4, pp. 418–425, 1988.
[21] K. M. Carter, J. F. Riordan, and H. Okhravi, “A game theoretic approach
to strategy determination for dynamic platform defenses,” in Proceedings
of the First ACM Workshop on Moving Target Defense. ACM, 2014,
pp. 21–30.
[22] T. Hobson, H. Okhravi, D. Bigelow, R. Rudd, and W. Streilein, “On
the challenges of effective movement,” in Proceedings of the First ACM
Workshop on Moving Target Defense. ACM, 2014, pp. 41–50.
[23] C. YuHunag, T. MinChi, C. YaoTing, C. YuChieh, and C. YanRen, “A
novel design for future on-demand service and security,” in 2010 12th
IEEE International Conference on Communication Technology (ICCT),
2010, pp. 385–388.
[24] R. Braga, E. Mota, and A. Passito, “Lightweight DDoS ﬂooding attack
detection using NOX/OpenFlow,” in 2010 IEEE 35th Conference on
Local Computer Networks (LCN), Oct. 2010, pp. 408 –415.
[25] G. Yao, J. Bi, and P. Xiao, “Source address validation solution with
OpenFlow/NOX architecture,” in 2011 19th IEEE International Conference on Network Protocols (ICNP), Oct. 2011, pp. 7 –12.
[26] J. H. Jafarian, E. Al-Shaer, and Q. Duan, “Openﬂow random host
mutation: transparent moving target defense using software deﬁned
networking,” in Proceedings of the ﬁrst workshop on Hot topics in
software deﬁned networks, ser. HotSDN ’12. New York, NY, USA:
ACM, 2012, pp. 127–132.
[27] S. Gutz, A. Story, C. Schlesinger, and N. Foster, “Splendid isolation:
A slice abstraction for software-deﬁned networks,” in Proceedings of
the First Workshop on Hot Topics in Software Deﬁned Networks, ser.
HotSDN ’12. New York, NY, USA: ACM, 2012, pp. 79–84.
[28] M. Platania, D. Obenshain, T. Tantillo, R. Sharma, and Y. Amir,
“Towards a practical survivable intrusion tolerant replication system,”
in Proc. 33rd Symposium on Reliabbe and Distributed Systems, 2014,
pp. 242–252.
[29] C. Guo, G. Lu, H. J. Wang, S. Yang, C. Kong, P. Sun, W. Wu, and
Y. Zhang, “SecondNet: a data center network virtualization architecture
with bandwidth guarantees,” in Proceedings of ACM Co-NEXT’2010,
Philadelphia, Pennsylvania, 2010, pp. 15:1–15:12.

11

J Netw Syst Manage (2010) 18:244–264
DOI 10.1007/s10922-010-9170-0

Low-latency Mix Using Split and Merge Operations
Dijiang Huang • Vinayak Kandiah

Published online: 5 June 2010
Ó Springer Science+Business Media, LLC 2010

Abstract One of the methods to maintain the anonymity of communicating nodes
in a network is the mix technique. Mix networks have been subject to various traffic
analysis attacks that aim at compromising the identities of these communication
nodes. Our focus in this paper is to propose mix network schemes that are more
robust against these attacks. To this end, we propose using traffic re-distribution
techniques. Traffic re-distribution involves changing the number and size of messages in the network by splitting and merging the messages at network nodes and
using variable size messages to confuse the attacker. The security and anonymity of
the proposed techniques are evaluated against traffic analysis attacks. Performance
analysis is provided to determine the effectiveness of the proposed techniques.
Keywords

Security  Anonymity  Onion routing  Watermark attack

1 Introduction
One class of solutions that achieve anonymity of communicating parties is modeled
based on the idea provided by the Chaumian Mix node [1]. A mix network uses mix
nodes which serve as forwarding nodes that perform some special cryptographic and
reordering techniques to provide user anonymity. The operation of a mix network is
described by Onion Routing [2].
Attacks on a mix network can be broadly classified as active attacks or passive
attacks (similar to conventional networks). Active attacks are those in which the
D. Huang (&)
Arizona State University, Suite 470, 699 S Mill Ave. Tempe, Arizona 85281, USA
e-mail: dijiang@asu.edu
V. Kandiah
Arizona State University, Suite 553, 699 S Mill Ave. Tempe, Arizona 85281, USA
e-mail: vinayak.kandiah@asu.edu

123

J Netw Syst Manage (2010) 18:244–264

245

attacker interferes with the process by altering the normal functioning of a mix
network. This may mean dropping, adding or modifying messages on a network.
Passive attacks are more subtle forms of attack where the attacker merely reads the
messages on the communication link and uses traffic analysis techniques to gain
valuable information from them. Though most implementations of mix networks try
to provide a mechanism to foil attacks, electronic communication is still vulnerable
to various kinds of attacks [3–17].
Our goal is to design a low-latency1 mix network scheme that makes it harder for
the attacker to carry out the various active and passive attacks. In our threat model,
we address passive traffic analysis attack, blending attack, and watermarking attack.
Using passive traffic analysis attack, adversaries try to infer possible peer partner
relations by just observing the number of messages sent and received by the users
of a mix network. Blending attack is an active attack where the attacker tries to
identify the receiver of a targeted message. Watermark attacks inject artificial delay
as watermarks between packets at the sender’s outgoing link, and then at the
receiver side, the adversary can identify the same watermark. Detailed discussion on
these attacks in our threat model is given in Sect. 2. To this end, we propose two mix
schemes—split and merge mixes—in this paper which can be used to achieve
greater anonymity against attacks. We describe how the scheme can defeat a passive
traffic analysis attack and how split & merge mixes can be used together to mitigate
the blending attack.
Both these techniques are based on Traffic Re-distribution. The main idea behind
traffic re-distribution is to modify the traffic flow within the network, in terms of the
path/route followed and the traffic volume along these paths. Since passive attackers
perform some form of traffic analysis, traffic re-distribution is effective in confusing
the adversary and makes it harder for the attacker to compromise the anonymity.
Active attacks involve introduction and manipulation of traffic by the adversary.
Briefly stated, split mix tries to hide the correlation in the traffic by splitting
messages and routing them through different paths. This is similar to the route
splitting mechanism described as garlic routing in [18]. However, the effect of using
garlic routing for defeating attacks has not been studied in detail and the split mix
technique described in this paper provides a more detailed description and analysis
of this technique. Also, we do not use any padding in our schemes and avoid any
additional overhead. Merge mix is a new technique which changes traffic patterns
by combining messages with a common next hop at intermediate mix nodes.
The main contribution of our paper is to formally analyze splitting and merging
of messages in intermediate nodes against out threat model and propose split mix
technique as a measure to defeat end to end traffic analysis attack in mix networks
(without use of dummy messages) and blending attack.
The rest of the paper is organized as follows. Section 2 deals with attack and mix
models used in this paper. The description and working of the split and merge mix is
described in Sect. 3. Section 4 deals with using these techniques to defeat attacks.
The experimental analysis of the split and merge mix technique under traffic
1

Low-latency mix means that the intermediate nodes do not pool a large number of received messages to
prevent timing correlations between senders and receivers, and then send to next hop.

123

246

J Netw Syst Manage (2010) 18:244–264

analysis and watermarking attacks is provided in Sect. 5. The last section (Sect. 6)
concludes the work presented in this paper and summarizes the goals of ongoing
research work in this topic.

2 Background
2.1 Traffic Analysis Attack
A basic approach to traffic analysis is to try and infer possible peer partner relations
by just observing the number of messages sent and received by the users of a mix
network. This attack is more effective when used in synchronous mix networks that
operate in distinct rounds. It is assumed that the attacker can identify which users
participate as senders and receivers for each round. There are various tools available
to observe the traffic in the communication links [19, 20]. This is one of the attacks
against which the proposed schemes are evaluated.
In general, the attacker may observe any portion of the network. However, a
special case of the traffic analysis attack based on the work in [13] involves
observing only the links connected to the end users. If all n users in the network take
part in each round the attacker can only infer how many sender peers each receiver
has, but if only m \ n senders take part in every round it is possible to determine the
exact sender peers for a receiver.
A detailed theoretical discussion is presented in this section. The attacker
observes several rounds of communication and establishes receiver multisets for
each of these rounds. (A multiset is a generalization of a set which can contain the
same element multiple times, \A, A, B, C[for example). This is the basic principle
on which the attack is based. For example, consider a simple mix network with three
senders and four receivers. If in a particular round of communication all three
senders {S1, S2, S3} participate and receivers R1, R3 and R4 receive messages; the
receiver multiset for this round is hR1, R3, R4i which has a cardinality of 3 and each
of the elements have a multiplicity of 1. The attacker can observe every round of
communication and come up with a mapping function which specifies the set of all
actual receiver multisets for each sender set. The mapping function for the sender
set S1, S2, S3 is the set of all receiver multisets observed in rounds of
communication where all these 3 senders took part. For example, one possible
mapping for sender set S1, S2, S3 could be:
MðfS1;S2;S3gÞ ¼ fhR1;R1;R4i;hR1;R2;R4i;hR2;R2;R4i;hR1;R3;R4i;hR2;R3;R4ig:
Notice that this mapping has the receiver multiset hR1, R3, R4i that was specified
as an observation of a round along with other multisets (observations in other
rounds). Similarly, the attacker will form mappings for each sender subset (i.e.
{S1}, {S2}, {S3}, {S1, S2}, {S1, S3} etc.). The peer relationships between senders
and receivers can be captured by a bipartite graph. A bipartite graph is a type of
graph where the vertices are divided into two disjoint sets. All edges originate in one
set and terminate in the other set. In the analysis of this attack, the two disjoint sets

123

J Netw Syst Manage (2010) 18:244–264

247

will be used to denote senders and receivers and the edges denotes the peer
relationships. The bipartite graph in turn can be transformed into a matrix. Each of
the columns of the matrix are represented by one of the senders and the rows are
represented by subsets of receiver set. Each subset of the receiver set must represent
a row of the matrix. Each entry in the matrix has a weight of either 0 or 1. For an
element weighted 1, the sender representing the corresponding column has its peer
receivers represented by the subset representing that row. The matrix has the
property that the sum of each column is 1.
There are 2 scenarios that need to be considered in this attack—closed and open
sender groups. If every sender takes part in each round of communication it is a
Closed Sender Group. For a closed sender group, the attacker can only identify the
structure of the bipartite graph and not the actual peer relationship. However, this is
sufficient to obtain valuable information such as the number of peer senders for each
receiver. The other case in which less than the maximum number of senders
participate in each round of communication is called Open Sender Group. In this
case, it is possible to deduce the actual peer partner relationship in the network.
Using the observed multisets the attacker can identify the peer partners for each
receiver.
Figure 1a shows a possible outcome where the peer relations of four receivers in
a mix network are deduced. By combining the branches shown in Fig. 1a, the
bipartite graph which captures the complete sender-receiver peer relationship for the
mix network can be constructed, as shown in Fig. 1b.
It is important to note that the multisets serve as the basic data required to
perform all these calculations. Split and merge mix techniques target this aspect of

(a)

(b)

Fig. 1 Bipartite Graph obtained from open sender group calculations

123

248

J Netw Syst Manage (2010) 18:244–264

the attack. Split and merge mixes introduce error in the attackers calculations by
preventing him/her from detecting the correct multiset for each round. As a result,
the calculations yield a set of several possible peer relationships from which the
attacker cannot identify the correct relationship matrix (bipartite graph) with
complete certainty.
2.2 Blending or n - 1 attack
This is a powerful global attack where the attacker tries to identify the receiver of a
targeted message. This attack model is used in the analysis of split & merge mixes.
Blending attack is classified as an active attack as the attacker inserts messages into
the network and delays messages generated by senders. A Pool/Block mixing mode
where a fixed number of messages are output from the mix nodes in distinct time
intervals is assumed for this attack. This fixed number of messages is determined by
the capacity of the mix node’s buffer n. The attacker starts off by first identifying the
message whose recipient is to be tracked. Then the attacker delays this targeted
message along with other messages from entering the next mix node on the path (the
attacker can identify this by observing the link on which the target message was
transmitted). The attacker then generates some pseudo messages which all have a
common destination as their next hop. The mix node’s buffer is filled with these
generated messages along with the target message. But the remaining genuine
messages are still delayed (hence, n - 1 attack). When the node outputs all the
messages only the target message will be routed to a node which is different from
the the predetermined next hop of the attacker messages. This attack can be carried
out repeatedly at each mix node on the target message’s path to continuously
identify the next hop until the message reaches its destination.
2.3 Watermark Attack
Watermarking attacks in anonymous networks have been adapted from watermarking techniques used for multimedia. Watermark attack exploits a fundamental
limitation of low-latency anonymous communication systems—the packet timing
correlation between the anonymized flow and the original flow cannot be obfuscated
easily. The watermarking attack transparently watermarks the packet flow by
slightly adjusting the timing of selected packets. If the embedded unique watermark
survives various flow transformations, the watermarked network flow can be
uniquely identified and thus linked to it original sender and receiver.
The attacker observes the links connected directly to sender nodes in a network
and introduces a specific timing delay pattern between messages sent out of each
sender (transparent watermark) using an encoder. This timing delay pattern is then
shared to the decoders that observe the links connected to the receiver nodes in the
network. These decoders then try to match the time pattern between packets
observed in each of these receiver links to the patterns shared from the encoders. A
match in time delay patterns would identify possible sender–receiver pairs. Such an
attack model where the timing delays are shared between the watermark encoder
and the detector is the private watermarking model [21]. This network flow

123

J Netw Syst Manage (2010) 18:244–264

249

watermarking technique can be used to attack low latency anonymous communication systems without global monitoring capability, i.e., only at the traffic ingress
and egress links.
2.4 Garlic Routing
A useful technique where multiple messages from a single sender are disguised as a
single message is Garlic Routing [18, 22]. The message structure of garlic routing is
similar to onion routing with one exception. The payload upon decryption may
actually contain two or more onion messages instead of a single onion. So, one of
the mix nodes will decrypt the packet and obtain the information from the header
that the payload contains two or more onion messages. These onion bulbs can be
routed to the destination from this intermediate node. The previous hops in the path
will not know that there are multiple messages in the payload. Conceptually, it is
possible to extend this technique and each layer of encryption in the onion can have
multiple onion bulbs.
Garlic routing improves delivery reliability and robustness as multiple branching
paths can be formed to the destination at the possible cost of redundancy. If the final
destinations of the garlic bulbs are different from each other, then the sender saves
on the number of encryptions performed (compared to setting up completely
individual paths). However, if the sender uses garlic routing for redundancy (same
destinations for garlic bulbs) the number of encryptions increase. This technique of
splitting messages within mix nodes is also useful when trying to defeat passive and
active attacks and is one of the traffic re-distribution techniques used in this paper.
Garlic routing has not been studied in detail and this paper is the first to focus on and
study the use of message splitting to defeat attacks in mix networks.
2.5 System Model for Split and Merge Mixes
The mix model chosen is a conventional decryption network like the one described
in onion routing [2]. Also, the routing mode is source routing where the sender
decides the entire path to the destination before forwarding the message to the mix
network. The operations of the split and merge mixes are independent of the type of
framework used. Hence, these techniques can be deployed in both asynchronous and
synchronous frameworks. However, some of the attacks against mix networks are
specific to a particular framework. A timing model to achieve synchronous
communication is described a bit later. Dummy traffic and padding are not allowed
because they introduce a lot of extra overhead into the network. Instead the split and
merge mix techniques use variable size messages. Although the message size can be
variable, they cannot be truly random. The sizes of the messages are constrained by
certain requirements which are explained as follows. A block size B is defined so
that the size of each message which leaves the sender or a mix node is some
multiple of B.
Size of a Message ¼ kB

ð1Þ

123

250

J Netw Syst Manage (2010) 18:244–264

where k C 1 is an integer. The initial value of k chosen by a sender is determined by
a probability distribution. A higher probability means that the maximum value of k
that can be chosen by a sender is higher. Note that the probability value only
determines the maximum value for k and a sender could choose a smaller value if
desired.
When performing splitting and merging at the mix nodes, the resulting
message(s) should still satisfy the constraint in (1). Senders which transmit larger
messages will have the ability to split more. Mix networks utilize symmetric key
encryption after the virtual circuit has been set up. At an underlying level
neighboring nodes establish symmetric key pairs between them for a Transport
Layer Security (TLS) connection as specified in Tor [23]. In merge mixing, each
node encrypts using this neighbor key before transmitting the message into the
communication link. These keys are needed to ensure that additional header
information can be supplied to the next hop when transmitting a merged message.
2.6 A Timing Model for Synchronous Framework
In order to accomplish well defined communication rounds, a timing model similar
to the one presented in [24] can be adopted. All nodes in the network have
approximately synchronized clocks, such that each node deviates from the global
time T by a maximum of Dt either way (i.e. lagging or leading). Senders transmit
messages in a particular time period tx. Each message bears this information tx as a
timestamp denoting the period in which it was transmitted. Every intermediate mix
node will check to see if it is the intended receiver and if not the message must be
forwarded to the next node at the start of the next time period. Finally the
destination node receives the message in a time period ty (and obviously ty [ tx).
The route lengths of the transmitted messages are to be uniform. This means
messages transmitted in time period tx will reach their respective destinations
around the time period ty, messages transmitted in period tx ? 1 will reach the
destination in time period ty ? 1 and so on. This constitutes communication in
distinct rounds.
From the attacker’s perspective, he/she can maintain two tables, one for the
senders (STab) and one for the receivers (RTab). STab contains an entry for every
sender that was detected sending a message. For each of these senders, the attacker
can record the timestamps during which it transmitted a message. So, a typical entry
would be: S1:t1 ; t3 ; t4 ; t9 . Similarly, the attacker stores in RTab an entry for each
receiver that ever received a message. For each receiver, the timestamp in which
messages were received along with the number of messages (multiplicity) for each
round is stored. An example of an entry in RTab would be R2:ðt3 ; 2Þ; ðt5 ; 1Þ; ðt14 ; 1Þ:
(Note that as per the attack model, a sender cannot send more than one message in a
round and so multiplicity information is not needed in STab). The attacker can take a
ty0 value (the time period in which a receiver got the message) and try to obtain the
time period tx0 in which it was sent:
tx0 ¼ ty0  Dt  ttrans ;

123

ð2Þ

J Netw Syst Manage (2010) 18:244–264

251

where tx0 is the time period when message was sent, ty0 is the time period when
message was received, Dt is the error adjustment for unsynchronized clocks, and
ttrans is the time taken for a message to make its way through the mix network. The
attacker can use these details to perform further traffic analysis.

3 Split and Merge Mixes
3.1 Split Mix
In this section, the model for implementing the split mix is described. Messages that
are transmitted by the user are split at certain intermediate nodes and forwarded
onto the next node. This splitting and its associated details are known only to the
node performing the split and the sender. These messages are reassembled at the
receiver’s node. For example, consider a message transmission that takes place as
shown in Fig. 2. For simplicity, only the message transmitted by sender s1 in that
round of communication is shown. The message is being split twice, first at m5 and
then at m2. Hence receiver r2 gets 3 messages which are all splits of the same
message which will be reassembled upon arrival.
The messages sent by each sender is in the form of an onion. So, it is not possible
to just split the message into smaller pieces at the mix node. This would ruin the
encryptions performed by the sender and hence the successive hops would not be
able to read the headers correctly. Hence, the sender of the message is actually
required to prepare a message that can be split at intermediate mix nodes without
affecting the cryptographic operations that need to be performed on the message.
Before performing any encryptions the sender first splits the message (plain text)
into several smaller messages. Each of these smaller messages is referred to as a

Fig. 2 Split mixing example

123

252

J Netw Syst Manage (2010) 18:244–264

Message split (MS). The sender decides the number of message splits, Nms needed
for the transmission. Each of these messages are pre-pended with a header which
contains some sequencing information for the receiver to reassemble the message.
The message splits are all encrypted with the public key of the receiver. These are
then repeatedly encrypted using the public keys of mix nodes. However, all message
splits are not encrypted with the same mix nodes’ public keys. Each message split
can be encrypted using different keys depending on the path they are supposed to
follow. At some point, two or more of these encrypted message splits are treated as
one entity and encrypted with the public key of a single mix node which is chosen to
perform the message splitting. For the example shown in Fig. 2, the sender would
have to split the message into three message splits say MS1 ; MS2 and MS3
(Nms = 3) and encrypt all of them using the pubic key of r2. Then the following
encryptions would take place:
MS1 ¼ ffMS1 gr2 gm3 ; MS2 ¼ ffMS2 gr2 gm4
MS3 ¼ fffMS3 gr2 gm4 gm7 ; MS4 ¼ fMS1 ; MS2 gm2 ;
MS5 ¼ fMS4 ; MS3 gm5 ;
where MSn denotes encrypted message splits which may be subject to further
encryptions and fgx denotes encryption using the public key of x.
Figure 3 shows how the final encrypted message to be transmitted would look like.
Notice that this resembles the structure of onions contained within other onions. This
is the structure of the Garlic message [18]. The message would then be forwarded to
m5 which can decrypt the message and will notice that there are two messages. m5 in
turn forwards these two messages to m2 and m7 respectively. Upon decryption m2 will
find a further 2 messages and forward them accordingly. In this fashion, mix nodes
identify the number of messages after decryption and forward them.
The receiver will then need to assemble the Nms message splits to retrieve the
original message. In order to assemble the message splits the receiver needs to know
the sequence of the messages. Hence, a sequence number needs to be added to each
MS by the sender before transmitting the garlic message. This sequence number

Fig. 3 Garlic Message for Split Mixing

123

J Netw Syst Manage (2010) 18:244–264

253

would be available only to the receiver. Since the communication itself takes place
in distinct rounds, all the message splits would arrive at the receiver at
approximately the same time. A receiver rx before performing decryption would
perceive each message split it receives as:
fNo: of Bits; Seq No:; Split Payloadgrx ;
where No. of Bits denotes some size information for the message split, Seq. No.
denotes the sequence number of this message split to be used in assembly and Split
Payload is the actual fragment of the data message itself. The header information to
be included before the other encryptions are performed contain standard information
such as the next hop and a time to live (TTL) field. The next hop will be used by mix
nodes to determine the node to which the message is to be forwarded. The TTL
value ensures that the route specified by the sender actually exists and that the
message can be delivered to the destination in a finite time duration.
Notice that the virtual circuit created by the split mix is not a simple end to end
path. Instead the circuit branches in the middle but terminates with the same
receiver. However, this does not affect the way in which the intermediate nodes
handle the mix operations. The mix nodes assign their own virtual circuit identifiers
when the circuit is being created. The mix nodes which perform the split however,
will have two or more output interfaces and hence will need to assign virtual circuit
identifiers accordingly to each of the output interfaces. A message split will also
have only one header like a regular message and hence there is no need for any
additional information to be generated by the mix node that performs the split
operation.
3.2 Merge Mix
The idea behind split mix is simple—alter the correspondence between the
messages being sent and messages being received by a mix node or user (i.e. traffic
redistribution). Using the same principle, it is also possible to combine two or more
constituent messages resulting in a Merged Message MMx, where x denotes the
number of constituent messages involved in the merge. However, the sender cannot
decide which messages are to be merged at which mix nodes (unlike splitting
messages). This is due to the following reasons: (1) The mix node that performs
merging would need to know which messages to merge (i.e. messages destined to
the same recipient) to use the appropriate public key and (2) The transmission routes
of two messages that can be potentially merged (intended for the same receiver) can
be disjoint. So they cannot be merged at a particular mix node unless the senders of
the appropriate messages collaborate and share their routing decisions. However,
both these requirements go against the very purpose of mix networks—anonymity.
Hence, an alternative hop-by-hop approach to merging messages is chosen as
opposed to the end-to-end splitting techniques. In this section, we describe the
merge mix model. The merging of messages is done at the mix nodes on a per hop
basis. It means each mix node individually makes the decision to merge messages
with a common next hop value. At the next hop, the original fragments from the

123

254

J Netw Syst Manage (2010) 18:244–264

merged message will be obtained. Then, depending on the next hop value of these
constituent messages, they may be merged again or transmitted separately. In
contrast, split mix performs end-to-end splitting: the source decides which messages
to split and a message once split can only be split further. Figure 4a shows a simple
example of merge mixing, where the messages with next hop M4 are merged at mix
node M2. At M4, the two messages are transmitted individually to their respective
next hops. As a result, there is no way for the mix nodes to ensure that two or more
messages originating from different source nodes and destined to the same receiver
will be merged and propagated as a single message to the destination. However, this
is possible if the last hop(s) of all these messages are the same. In other words,
consider the route of a message from sender S to be expressed as a string (Rs) made
up of the hops in the route. Two or more of the messages which are destined to the
same receiver will be delivered in a merged form if their respective routes share a
suffix of some non-zero length, as shown in Fig. 4b. Here the suffix: M4 M6 R1 of
length 3 is shared between RS1 and RS2.
The mechanism used to merge multiple messages and make them appear as a
single message is a very simple one. When the mix node decides to perform a merge
operation, the messages with the same next hop are considered as a single unit. The
mix node then adds a header to the merged message. This header will have a flag set
to indicate that the message is merged, the size of each constituent message (i.e.

S1
S2

(a)

S1
S2

(b)
Fig. 4 Merge Mixing Example

123

J Netw Syst Manage (2010) 18:244–264

255

number of blocks occupied by each message) and some virtual circuit identifier
information. However, it is ensured that net size of the messages and header
conforms to the block/size regulations described earlier. This single entity is
encrypted using the symmetric key shared between neighboring mix nodes x and y.
In effect what the header information of each merged message accomplishes is that
it informs the next hop where each of the headers of the constituent messages start.
This virtual circuit information will contain the details of the virtual circuits of the
original constituent messages. The messages will be treated as a single entity and
transmitted contiguously to the common next hop. Though this scheme is very
simple, it is effective against attackers. Since the individual messages which were
merged are all encrypted (i.e. onions), an attacker who observes the merged
message will only perceive it as a sequence of random bits. Even if a message is not
merged, the mix node must add a header and reset the flag to indicate that the
message is not merged. It will then encrypt the message with the newly added
header using the shared symmetric key and send it through the appropriate virtual
circuit.
The next hop (mix node or receiver) will receive the merged message and start
decrypting it using the shared symmetric key. It will obtain information about the
merged messages and decrypt the header blocks by using the appropriate
cryptographic keys. In this way, the node can identify that multiple messages are
actually merged as one. If the message received was not merged, the node simply
chooses the cryptographic key for that virtual circuit to decrypt the only header in
the message. If this node is a mix node, it may perform merging again and forward
the messages or if the node is a receiver, it will identify that it is the destination and
process the packets appropriately.

4 Defeating Attacks Using Split and Merge Mixes
4.1 Defeating Blending Attack by Using Split and Merge Mixes
In this section, it is shown that the blending attack can be made harder or foiled by
using the split and merge mix techniques concurrently in the same network. As
explained previously, the blending attack is an active attack and is usually carried
out in an asynchronous framework. However, the blending attack is an external
attack and so the adversary cannot see the operations performed inside the mix
node. The attacker carries out the blending attack by first identifying a target
message Messtarg and then by filling the mix node with induced messages and
Messtarg. All induced messages will be routed to a mix node known to the attacker
Mattack and so the attacker can track the next hop of Messtarg by scanning the
output communication links of the mix node. Hence, the key to foiling the attack
lies in ensuring that the attacker cannot pinpoint the next hop of the target
message.
At first glance, it would seem that the split mix technique, when used alone, can
foil the attack. If the target message is split at the node being attacked, more than
one output message will be routed to a next hop other than Mattack. This has the

123

256

J Netw Syst Manage (2010) 18:244–264

potential to confuse the attacker as it seems that he/she will now need to track
more than one message. However, if the attacker knows that the mix network only
deploys split mix, it actually becomes easier for the attacker to carry out the
blending attack. This is because in split mix, even if messages are split at the
intermediate nodes, these various splits will eventually reach the actual receiver of
the message. In a blending attack, splitting a message actually allows the attacker
to pick and track any one of these split messages that lead to the receiver. In this
way, even if the attacker previously could not examine certain links and access
certain nodes he/she could possibly switch to an alternative link followed by
another split.
On the other hand, using merge mixes by itself in a mix network has the
potential to confuse the attacker in the case of a blending attack. This is because in
merge mix when two or more messages in a mix node’s buffer have the same next
hop they are merged into one message and then transmitted. If the attacker picks a
merged message as Messtarg and the mix node under attack detects that the
constituent messages have different next hops, the attacker will see more than one
message routed to nodes other than Mattack. Now the attacker needs to track both
these messages (which may split further depending on the original composition of
the merged message) in order to identify a set of users who are potential recipients
of the message of interest to the attacker. The attack will in the end lead the
attacker to (x C 1) distinct receivers. So the attacker can only obtain the
knowledge that only one of these x nodes is the recipient of the original target
message.
Obviously, using split and merge mix techniques in the same network will also
offer resistance to the blending attack following the same reason explained above.
In fact, the combined use of split and merge mixes has greater potential to make it
harder for the attacker to carry out the attack. When more than one packet is
transmitted out, the attacker cannot determine if this is the result of source-intended
message splitting or the separation of previously merged messages as the attacker
cannot observe the internal operations of the mix node. As a result, the attacker has
to track all the paths of all the packets even if only splitting was performed at the
mix node. If these packets are merely message splits, then they will eventually lead
to a single destination which the attacker seeks. However, to be sure of this, the
attacker must track all paths which is not easy. Also, there is a possibility that any of
these message splits will be involved in a merge along the path which would result
in additional potential receivers for the attacker.
Hence, by using merge mix or the combination of merge and split mixes, it is
possible to confuse the attacker and make it harder to carry out the blending attack.
If the attacker is made to track several paths, he/she may run out of resources
resulting in the failure of the blending attack. However, if the attacker is not seeking
any particular information about the transmission of messages within the network
(i.e. attacker is looking for any information rather than the receiver of a specific
message), the proposed techniques will not affect the attacker. The split and merge
mixes can be used along with detection techniques like Heart Beat traffic [25] to
ensure that the anonymity of the network is preserved.

123

J Netw Syst Manage (2010) 18:244–264

257

4.2 Defeating Message Counting/Traffic Volume Attack Using Split Mix
Attackers may use packet sniffing tools [19, 20] to count the number of messages
that are being transmitted over a communication link. In this case, during the normal
operation of a mix network in any round of communication, the number of messages
sent will be equal to the number of messages received. As a result, it is possible to
come up with the receiver multiset for the particular sender set. But using split mix
it is possible to ensure that the number of messages being received are not the same
as the number of messages sent, making the problem harder to solve. Two cases
need to be considered when using split mix in this attack model: Case (a)—where
the multiplicity of each receiver in the actual multiset would be 1, Case (b)—when
the multiplicity of at least one receiver in the actual multiset would be greater than
1. Case (a) is simply a communication round where no two senders send messages
destined for the same receiver node. The splitting of messages may be performed by
any of the mix nodes along the route to the receiver.
To illustrate the two cases consider an example mix network which has 3 senders
S: {s1, s2, s3} and 4 receivers R: {r1, r2, r3, r4}. This is all the information that the
attacker needs and will examine all communication links that are connected to any
of these 7 user nodes. However, to explain how splitting messages can foil the attack
it is necessary to consider the number of mix nodes and their actual connectivity in
the network. One such mix network with 7 nodes is presented in Fig. 5 and used in
all examples in this section.
4.2.1 Case (a): Receiver Multiplicity is Equal to 1
In this case, consider rounds of communication where each receiver obtains only
one message each. As a result, a receiver multiset that has the following form can be
obtained:
½hr1 ; r2 ; r3 ; . . .; rn i s:t: Mulðri Þ ¼ 1 and 1  i  n;
where Mul(ri) is the multiplicity of the receiver ri, and n is the number of messages
sent. Note that the attacker does not know this detail beforehand. Consider a

Fig. 5 Case (a)—Communication round with receiver multiplicity = 1

123

258

J Netw Syst Manage (2010) 18:244–264

communication round where the senders try to send messages to the following
receivers:
s1 ! m1 ! m2 ! m4 ! r2;
s2 ! m1 ! m2 ! m4 ! r3
s3 ! m6 ! m7 ! m4 ! r1:
The message transmissions for both the conventional mix network and the split
mix network are shown in Fig. 5a and b, respectively. In the split mix network, the
message sent by s1 is being split at m2 and then forwarded to r2 via m3 and m4.
For the mix network in Fig. 5a, the number of messages sent equals the number
of messages received which is 3. Hence the attacker can easily come up with the
receiver multiset for this round of communication as: hr1, r2, r3i for the sender
subset {s1, s2, s3}.
For the mix network in Fig. 5b however, the attacker will detect 4 messages
received while only 3 were sent. The attacker knows that the cardinality of the
receiver multiset must be 3 to match that of the sender subset. The attacker must
decide if the receiver r2 must have a multiplicity of 1 or 2 in the multiset. If the
attacker decides to give r2 a multiplicity of 2, then the remaining element of the
multiset would be either r1 or r3. However, as no dummy traffic is used it is not
possible for either r1 or r3 to be excluded from the multiset. As a result the attacker
deduces that the message to r2 must have been split and hence identifies the correct
multiset as hr1, r2, r3i.
4.2.2 Case (b): Receiver Multiplicity is Greater Than 1
Now consider the second case where it is possible for at least one receiver from a
multiset to have a multiplicity greater than 1. So the receiver multiset will have the
following form:
½hr1 ; r2 ; . . .; rn0 i s:t: Mulðri Þ  1 ; 1  i  n0 and n0 \n;
where Mul(ri) is the multiplicity of the receiver ri, n0 is the number of distinct
receivers, and n is the number of messages sent. Consider an example with the
following transmissions:
s1 ! m1 ! m2 ! m4 ! r1;
s2 ! m5 ! m4 ! m7 ! r3;
s3 ! m5 ! m6 ! m7 ! r3:
Figure 6 shows the paths selected by the senders both in the traditional network
and in the network with split mixing. In Fig. 6a, finding the multiset is trivial and is
hr1, r3, r3i for the sender subset {s1, s2, s3}. In Fig. 6b, the message intended for r1 is
split at m2 and sent through m3 and m4. Here the attacker can detect 3 messages sent
and 4 received. As a result the attacker must decide whether r1 or r3 must be given a
multiplicity of 2 in the multiset. In this case the attacker cannot make an assured
decision as either of these 2 receivers could have a multiplicity 2. So the attacker

123

J Netw Syst Manage (2010) 18:244–264

259

comes up with two possible multisets, hr1, r1, r3i or hr1, r3, r3i. If the attacker
chooses hr1, r1, r3i for the final mapping it would lead to erroneous calculation. In
this case, the attacker had to choose from only two possible multisets.
4.2.3 Combining Multisets to Determine Mapping Function
The splitting of messages has the capability to prevent the attacker from deducing
the correct multiset only when the multiplicity of at least one receiver is greater than
one. However, when trying to determine the peer relationships between senders and
receivers the attacker needs to come up with a mapping for each unique sender
subset similar to the example in Sect. 2.1. In a Case (b) scenario, the multisets
observed will induce errors in both closed and open sender group calculations as
some of the multisets which the attacker would have observed are not correct.
Hence, message splitting has benefits with defeating the attacker from determining
either the actual peer partner relationships or simply the number of sender peer
partners per receiver.
4.2.4 Maximum Number of Receiver Multisets
Split mix defeats passive traffic analysis described in Sect. 2.1 by forcing the
adversary to consider various possible receiver multisets for each communication round. For example, in Fig. 6 the attacker has to consider two possibilities
\r1, r1, r3[ and \r1, r3, r3[. The maximum number of possible choices for a round
of communication is determined as follows. Let the number of distinct receivers for
a round be ndr. Every receiver that received a message in the communication round
must appear at least once in the multiset. Let the number of unfilled positions in the
multiset, after this condition is satisfied, be called slots remaining (slotsrem).
Obviously, slotsrem = cardinality of multiset - number of distinct receivers (where
cardinality = number of senders).
Given the values ndr and slotsrem, the maximum number of receiver multisets
(Maxrm) will be achieved when the number of messages received by each receiver is
at least slotsrem ? 1. In this case, each receiver can appear at the least 0 times and at

Fig. 6 Case (b)—Communication round with receiver multiplicity [1

123

260

J Netw Syst Manage (2010) 18:244–264

most slotsrem times in the unfilled positions of the receiver multiset. This is the
widest possible range and hence the number of receiver multisets obtained is
maximum when this condition is satisfied. In a scenario where ndr = slotsrem, the
maximum number of receiver multisets can be derived as:


ndr 
X
ndr
ndr  1
Maxrm ¼
:
ð3Þ
:
k1
k
k¼1
The simplest way to understand (3) is to analyze the problem by considering the
number of ways the remaining slots can be partitioned such that each partition is
occupied by only one receiver. As a lower limit, the remaining slots may be
considered as a single partition (i.e. all slots occupied by same receiver) while as an
upper limit they may be partitioned into ndr partitions (each slot is occupied by a
different receiver). Hence the summation for k from 1 to ndr. For each value of k, we
need to determine the number of permissible receiver combinations. The value of k
determines the number of partitions and hence the number of receivers to be chosen
from the maximum ndr to fill the slots. Thedifferent
 combinations of receivers
 that

ndr
ndr
: And for each subset of
satisfy this constraint can be obtained as
k
k
there are (n -k) slots that could belong to any of the k partitions. This is
ndr  1
determined by
. By combining the summation and the product of the two
k1
terms we arrive at (3).

5 Experimental Evaluation on Traffic Analysis Attack and Watermarking
Attacks
In this section, some experimental results are presented to determine the
effectiveness of the split mixing scheme against traffic analysis attack and
watermarking attack. We are currently working on simulation and experimental
results for the split and merge mix techniques, respectively. The simulations
performed, consider various scenarios where messages are destined to receivers and
various amount of splitting was applied. The simulation code was written in C??
and compiled using Microsoft Visual Studio 2005. There are five senders and five
receivers in the scenarios chosen and the minimum size of the message that can be
transmitted is B. For each simulated round, the sender picks a receiver and chooses
the size of the message that it intends to transmit. There are two varying parameters
in the simulation: the maximum size of the message and the size of split messages.
The maximum size of the message that can be picked by a sender is varied for
different scenarios as 2B, 5B and 10B. Also two types of splitting are considered. In
one case, the sender must split its messages such that all messages observed at the
receivers are of the same size B. The other case, is where the sender may arbitrarily
choose how to split its messages as long each split message is some integer multiple
of B (i.e. each message received is kB, where k is some positive integer such that
kB\maxsize:) Considering all combinations of the two varying parameters, we get

123

J Netw Syst Manage (2010) 18:244–264

261

six different scenarios. Several rounds of communication were simulated for each of
these six scenarios and for each round the number of possibly correct receiver
multisets were identified. The results showing the percentage of rounds where 1 or
more multisets were identified is presented in Fig. 7.
The results obtained provide two key insights regarding the choice of maximum
message size and amount of splitting. First, it can be seen that in general the
percentage of rounds with more than one correct multiset is greater for type (a)
where all messages are split so that the receivers only obtain messages of size B.
This is true for all permitted maximum message sizes. Second, for both type (a) and
type (b) the best results are obtained when the maximum permitted size of the
message is 2B. For type(b) 30% of the rounds have more than one correct multiset
when the max size is 2B. For type (a) 55% of the rounds have more than one
multiset for max size 2B, which is also the maximum achieved result for all
scenarios.
The above result does not mean that the attacker will be successful in 45% of the
attempts. Recall that the actual open and closed sender calculations involve taking
into consideration all multisets that were observed in all rounds. So a higher number
of rounds with more than one correct multiset increases the number of multisets that
the attacker needs to consider when performing the calculations. The watermarking
attack proposed in [14] would not work effectively on a mix network, which enables
split or merge options. To test the performance of merge performance under
watermarking attack, we conduct the real world testing using Tor, where the size of
the packet changes depending on cell size of the mix. Tor can take up to 498 bytes
of data. If there is data in the incoming buffer, Tor decides whether to pad it or not
depending on the data size. The cell which Tor sends out has a strict payload of 498
bytes. After this the cells are on the OR connection where they are treated as a
sequence of bytes and passed onto OpenSSL. OpenSSL again groups these bytes

Fig. 7 Rounds with Multiple Correct Multisets in Split Mix for Various Scenarios (as a percentage)

123

262

J Netw Syst Manage (2010) 18:244–264

Fig. 8 Analysis of watermark encoding on Tor

into TLS segments. The grouping is again based on several factors. The packets
after these transformations are finally sent as TCP packets with the packet size of
1,380 bytes.
We conducted experiments with sufficiently large flows on the Tor network to
match the watermark introduced at the senders end by analyzing the packets at the
receivers end as shown in Fig. 8, where the y-axis represents the percentage of
matching to ingress traffic and egress traffic. We found that matching was not
accurate due to the merging transformations explained above. Even increasing the
redundancy of the watermarking bits along with a Hamming Distance of 8 for a
watermark length of 24 bits did not yield satisfactory results which could uniquely
identify flows. We had tested 16 flows, the average detection was around 54 percent,
which is close to random guessing and is not sufficient to co-relate the flow.

6 Conclusion
The main goal of the work presented in this paper is to defeat passive and active
attacks in mix networks by using traffic re-distribution. Two main techniques are
proposed to achieve this are: split mix which breaks messages into smaller
fragments and merge mix which combines messages to larger fragments. The mix
model chosen for our evaluation uses a synchronous framework. The split mix is
end-to-end and the sender determines the number and size of the split messages.
Merge mix is more difficult to manipulate and it is performed on a hop by hop basis
by the mix nodes. These two techniques can be used in the same network to mitigate
the blending attack. Also, the split mix can be used to defeat end-to-end traffic
analysis attacks. Also, since padding or dummy messages are not used, the

123

J Netw Syst Manage (2010) 18:244–264

263

computational and communication efficiency is maintained in these techniques.
The effect of merge mixing on watermarking attacks was also studied on Tor. It was
determined that merge mixes can reduce the accuracy of watermarking attacks in
large flows.
There is further research to be performed with Split and Merge Mixes. It is
possible to use variable size messages which will make it harder for the the attacks
to be carried out. Experimental results need to be obtained to study the impact of
using variable size messages. In addition, the application of split and merge
techniques in more recent anonymizing networks like Torsk [26] need to be
evaluated. Also, the mix model used for traffic analysis attacks to deduce the peer
relationships do not consider any probabilistic information about the network. Some
recent work has shown that the peer partner relationships are not completely random
and have some probabilistic information [27, 28].

References
1. Chaum, D.: Untraceable electronic mail, return addresses, and digital pseudonyms. Commun. ACM
24(2), 84–88 (1981)
2. Goldschlag, D., Reed, M., Syverson, P.: Hiding routing information. Lect. Notes Comput. Sci. 1174,
137–150 (1996)
3. Diaz, C.: Anonymity and privacy in electronic services, Ph.D. thesis, Katholieke Universiteit Leuven,
Leuven, Belgium (2005)
4. Kesdogan, D., Pimenidis, L.: The hitting set attack on anonymity protocols. In: Proceedings of 6th
information hiding workshop (IH), pp. 326–339, Springer (2004)
5. Danezis, G., Serjantov, A.: Statistical disclosure or intersection attacks on anonymity systems. In:
Proceedings of 6th information hiding workshop (IH), pp. 293–308, Springer (2004)
6. Raymond, J.: Traffic analysis: protocols, attacks, design issues, and open problems, Lecture Notes in
Computer Science (2001) 10–29
7. Serjantov, A., Dingledine, R., Syverson, P., et al.: From a trickle to a flood: active attacks on several
mix types. In: Proceedings of information hiding workshop (IH) (2003) 36–52
8. Danezis, G.: Statistical disclosure attacks: traffic confirmation in open environments. In: Proceedings
of security and privacy in the age of uncertainty, (SEC2003), Citeseer, pp. 421–426 (2003)
9. Back, A., Moller, U., Stiglic, A.: Traffic analysis attacks and trade-offs in anonymity providing
systems. In: Proceedings of information hiding workshop (IH) (2001) 245–257
10. Levine, B., Reiter, M., Wang, C., Wright, M.: Timing attacks in low-latency mix systems. In:
Proceedings of financial cryptography: 8th international conference (FC 2004): LNCS 3110
11. Zhu, Y., Fu, X., Graham, B., Bettati, R., Zhao, W.: On flow correlation attacks and countermeasures
in mix networks. In: Proceedings of privacy enhancing technologies workshop (PET 2004), LNCS,
May (2004) 207–225
12. Gogolewski, M., Klonowski, M., Kutylowski, M.: Local view attack on anonymous communication.
Lecture notes in computer science (book chapter) 3679 (2005) 475–488
13. Kesdogan, D., Agrawal, D., Pham, V., Rautenbach, D.: Fundamental limits on the anonymity provided by the MIX technique. In: Proceedings of the 2006 IEEE symposium on security and privacy
(S&P’06)-Volume 00 (2006) 86–99
14. Wang, X., Chen, S., Jajodia, S.: Network flow watermarking attack on low-latency anonymous
communication systems. In: Proceedings of the 2007 IEEE symposium on security and privacy, pp.
116–130 (2007)
15. Borisov, N., Danezis, G., Mittal, P., Tabriz, P.: Denial of service or denial of security? In: Proceedings of the 14th ACM conference on computer and communications security, ACM, pp. 92–102
(2007)
16. Danezis, G., Syverson, P.: Bridging and fingerprinting: epistemic attacks on route selection. Lect.
Notes Comput. Sci. 5134, 151–166 (2008)

123

264

J Netw Syst Manage (2010) 18:244–264

17. Hopper, N., Vasserman, E., Chan-Tin, E.: How much anonymity does network latency leak? In:
Proceedings of the 14th ACM conference on computer and communications security, ACM, pp. 82–
91 (2007)
18. Freedman, M.: Design and analysis of an anonymous communication channel for the free haven
project. Online: http://www.freehaven.net/doc/comm.ps
19. Ethereal: A network protocol analyzer, http://www.ethereal.com
20. SoftPerfectTM Network protocol analyzer—network sniffer for windows—http://www.softperfect.
com/products/networksniffer/
21. Houmansadr, A., Coleman, T., Kiyavash, N., Borisov, N.: On the channel capacity of network flow
watermarking
22. I2P Design Documents: Garlic Routing—http://www.i2p.net/how_garlicrouting
23. Dingledine, R., Mathewson, N., Syverson, P.: Tor: the second-generation onion router. In: Proceedings of the 13th USENIX security symposium 2 (2004) 303–320
24. Dingledine, R., Freedman, M., Hopwood, D., Molnar, D.: A reputation system to increase MIX-net
reliability, information hiding (IH) (2001) 126–141
25. Danezis, G., Sassaman, L.: Heartbeat traffic to counter (n-1) attacks. In: Proceedings of the workshop
on privacy in the electronic society (WPES) (2003) 89–93
26. McLachlan, J., Tran, A., Hopper, N., Kim, Y.: Scalable onion routing with Torsk
27. Shmatikov, V., Wang, M.: Measuring relationship anonymity in mix networks. In: Proceedings of the
5th ACM workshop on privacy in electronic society, ACM, pp. 59–62 (2006)
28. Feigenbaum, J., Johnson, A., Syverson, P.: Probabilistic analysis of onion routing in a black-box
model. In: Proceedings of the 2007 ACM workshop on privacy in electronic society, ACM (2007)

Author Biographies
Dijiang Huang received his B.S. degree from Beijing University of Posts & Telecommunications, China
1995. He received his M.S., and Ph.D. degrees from the University of Missouri–Kansas City, in 2001 and
2004, respectively. He is an Assistant Professor in the Computer Science & Engineering Department at
the Arizona State University. His current research interests are computer networking, security, and
privacy.
Vinayak Kandiah received his B.Tech degree in Information Technology from Anna University,
Chennai, India in 2005. He obtained his M.S. Computer Science degree from Arizona State University in
2007. His research interests include network anonymity and privacy. He is currently employed with
Cerner Corporation as a Software Engineer.

123

RFID Keeper: An RFID Data Access Control Mechanism
Zhibin Zhou
Arizona State University

Dijiang Huang
Arizona State University

zhibin.zhou@asu.edu

dijiang@asu.edu

Abstract—Access control for RFID tags is challenging due to
the limited computational and energy capability of RFID tags.
To solve this problem, we propose RFID Keeper – an RFID
data access control mechanism based on RFID media access
control protocols. RFID Keeper is designed to detect and counter
unauthorized accesses to RFID tags.

I. I NTRODUCTION
Information exposure of RFID tags has been identified as
a major problem holding back users’ confidence in adopting
RFID technologies. This problem is critical especially for
passive RFIDs that have limited computational capability and
lack of cryptographic protections. Passive RFID tags energize
themselves by absorbing radio wave emitted from readers and
they usually do not have access control abilities. Thus, a tag
will broadcast its stored information without authenticate the
readers.
To prevent unauthorized readers from accessing the secret
information stored in passive tags, we propose a secure access
control mechanism, i.e., RFID Keeper, in a hospital environment. RFID Keeper access control mechanism provides
security protections such as reader authentication and data
access control. RFID Keeper architecture is shown in Fig. 1.
An RFID Keeper Server (RKS) maintains a database that
contains legitimated users’ information. A Room Watch Dog
(RWD) is installed in every protected room. We assume that
an RWD is connected to the RKS via a secure channel. An
RWD consists of an authentication module and an access
detection and control module. The authentication module is
to authenticate a user’s read requests. The access detection
and control module is to detect and control unauthorized tagreading operations. In summary, RFID Keeper provides two
security services: (1) user identity authentication service: a
user should be authenticated by RKS and authenticated users
are authorized to perform read operations, and (2) data access
control service: unauthorized read operations of RFID tags are
blocked by RWD.
The rest of paper is arranged as follows: in section II, we
present related works; in section III, we show the network
model and the attack model used in this paper; then we
describe two main services provided by RFID Keeper in
sections IV and V; in section VI, we evaluate the security
performance of the proposed solutions; finally, we conclude
our work in section VII.
II. R ELATED W ORKS
In [5], the author presented a survey on privacy and security
research issues for RFID tags. In particular, the access control
of passive RFID is a critical but unsolved issue. In [10], the

Data Access Control
(Detection & Control) Service

Services
User Identity
Authentication
Service

Room
Watch
Dog

Fig. 1.

Access
Detection &
Control
Module

Authentication
Module

RFID
Keeper
Server

User
information
database

The system architecture of the RFID Keeper.

authors presented various collision resolution protocols for
multi-access communications between RFID tags and readers.
Access control through blocking techniques has been proposed
in [6] based on multi-access control protocols. The authors
claimed that their approach can be also used to block the
reader-driven TDMA singulation algorithms. However, the
research in [9] pointed out that the straight forward implementation of RFID blocking is vulnerable to the Differential Signal
Analysis (DSA). If the responses from RFID blocker tags are
always the same, the analog signals received from the RFID
blocker tags will also be identical. As a result, blocking signals
can be mathematically average out from the total recorded
waveforms and the leftover signals will be the genuine RFID
tag responses. Thus, blocking techniques should consider DSA
when using TDMA based multi-access control protocols.
III. S YSTEM M ODELS
In this section, we present the network model and attack
model that support the proposed RFID Keeper architecture.
A. Network Model
The network model of RFID Keeper is illustrated in Fig. 2.
The RWD in each room is connected to the RKS through secure channels. We assume that the communication between the
RWD and RKS cannot be compromised by attackers. During
the authentication process, RWD exchanges data with RKS
using the authentication protocol presented in next section.
B. Attack Model
Attackers can be either hospital personnel or outsiders who
are not authorized to collect data from RFID tags. The main
goal of attackers is to access the data stored in RFID tags.
Since passive tags have short reading distance, the readers
need to get to the physical proximity to read the tags [4]. We
assume that the attackers can deploy the following attacks:
(1) session hi-jacking attacks; (2) eavesdropping attacks; and

4570
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

RFID Keeper Server
Secure Communication Channels
Room Watch
Dog

1:A
p 2:

Block

Ste

Ste
p

Reader
Ste

Room Watch
Dog

p1
:A

uth
e

uth
e

n ti

nti
c

at i

on

cat
ion

Room Watch
Dog

Re a

Reader
St
ep

d

Tags on the
Instrument
Authorized
User Room 1

Fig. 2.

2:

Reader
Re a
Aut d with
o
hor
izat ut
ion

Re
ad

Tags
Authorized
User

Patient
Room 2

Unauthorized
User

Room 3

Network model for the RFID Keeper.

(3) denial-of-service attacks. Section VI evaluates the security
performance of RFID Keeper under these attacks.
C. Notations
Notations used in the rest of paper are presented in the
following table.
Symbols
RW D
RKS
U id
Rid
Pw
Req
T
Sq
Rp
Ps
Dn
Cr
Bye

Descriptions
Room Watch Dog
RFID Keeper Server
User Identification
Room Identification
Symmetric Password shared by the user and RKS
Scan Purpose and Tag Selection Request
Security Token
Sequence Number
Room Policy
Authentication Passed
Authentication Denied
Challenge Request
Logout Request

IV. U SER I DENTITY AUTHENTICATION S ERVICE
User Identity Authentication (UIA) service includes three
components: authentication protocol, authentication module of
RWD, and RKS. The authentication protocol consists of three
processes that are shown in Fig. 3. A user is firstly required to
pass the authentication by RKS before he/she can use RFID
readers to interact with RFID tags. Otherwise, the user will be
blocked by the RWD (see descriptions in Section V). During
the login process, a user needs to provide his/her Uid, Pw, and
Req to pass authentication. To do this, the reader generates
a security Token HashP w (U id, Sq) and then sends message
< U id, T, Req, Sq > to RWD. RWD forwards the message
together with the room ID to RKS through a secure channel.
RKS needs to process the following validations in sequence:
1) It looks for the < U id, P w > in the user-information
database;
2) It verifies the Token by computing HashP w (U id, Sq).
a) If the verification is passed, RKS replies the pass
message (Ps), the room policy (Rp), and the increased sequence number (Sq+1) to the RWD and
handhold reader.

Fig. 3. Information flow of authentication protocol. Three phases: login,
challenge, and logout. Note that the dashed arrows stand for the information
flow when the authentication failed.

b) Otherwise, RKS returns a denial message (dn).
After the authentication procedure, RWD needs to challenge
the users periodically to prevent session hijacking attacks (will
be addressed in details in section VI). The challenge process
is similar to the login process except that RWD first sends the
challenge of < Cr, U id >.
After the user extracts data from the tags, she/he needs to
go through logout process that gracefully closes the communication session.
V. DATA ACCESS C ONTROL S ERVICE
The data access control service protects information stored
in tags from unauthorized accesses by injecting interference
into wireless communication channels. The injected inference
signals will prevent unauthorized users from correctly receiving the messages sent by RFID tags. To this end, the data
access control service must include both intrusion (unauthorized access) detection and access control capabilities. The
basic components and functions are presented in the following
table:
Components
Intrusion Detector
RFID Simulator Group
Signal Modulation Randomizer

Functions
No Reading Command();
No Power Field()
Randomly Choose Simulator Subset();
Send Noise()
Randomly Modulate Signal()

A. Tag Access Detection
In our presented authentication protocol, the readers have
to be authenticated by RKS before accessing the information.
Otherwise, any reading activity without being authenticated is
considered as an intrusion. The data access control contains an
intrusion detector that can detect read operations specified in
reader-tag protocols. For example, most reader-tag protocols
require the reader to send a read command to a tag first. If an
RWD detects an unauthorized read command, it will send out
blocking signals, i.e., a random noise in the same frequency
band. Thus, the response time of RWD is very critical for the
access control. This is because lagged blocking signals cannot

4571
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

Polling

Reader Driven
TDMA
Tree Search
I-Code
Mothod
Protocol
Collision Set
Query Tree
Tree
Algorithm
Algorithm
Fig. 4.

Contact-less
Protocol

Taxonomy of Reader Driven TDMA.

prevent adversaries from reading the information replied by
tags.
B. Data Access Control
Most of multi-access protocols are based on TDMA. In
this paper, we only consider how to blocking TDMA-based
protocols. In order to counter unauthorized accesses of data,
RWD has to perform blocking functions once an unauthorized
data access is detected. Using TDMA-based access control
protocols, a reader can only communicate with one tag at a
time. Thus, if multiple tags response to a reader simultaneously, the access fails. Extensive research [10] has been done
to identify each individual participating tag from one another.
To block the data access (i.e. the read function), RWD needs to
make it difficult for unauthorized readers to differentiate tags’
responses. To this end, we propose a set of blocking methods
to disable RFID multi-access schemes [10]. In addition, we
need to randomize the injected blocking signals to prevent
attackers from using Differential Signal Analysis (DSA) [9]
to filter out the injected blocking signals.
To perform blocking, RWD randomly chooses a group
of RFID Simulators. The selected RFID Simulators simulate the RFID tags’ signal and perform blocking functions
based on specific multi-access control protocols (see later this
section for detailed descriptions of blocking functions). In
addition, the Signal Modulation Randomizer (SMR) changes
the strength of simulators’ signals and introduces randomly
generated noises to the signal sent by the RFID Simulators.
The signal strength and signal to noise ratio keep varying, and
thus, the DSA attackers cannot filter out blocking signals.
In TDMA, the available channel capacity is divided for
participants chronologically. There are two classes of TDMA
technologies for RFID multi-access control: (1) tag-driven
TDMA and (2) reader-driven TDMA. Tag-driven TDMA functions asynchronously without relying on the control of readers.
For instance, using ALOHA [8], a tag starts to transmit its ID
once it is in the power field and has data to transmit. The tag
will continuously retransmit data in random time intervals.
Once there is a collision, the tag can either mute or reduce
the retransmission frequency.
To block ALOHA TDMA approaches, RWD is required to
send randomly generated IDs in very high frequency. Since
the blocking signal is randomly generated, it is impossible for
the attackers to differentiate the blocking signal from the real
signal. This blocking method can either cause collision with
the real tags’ signals or overwhelm unauthorized readers in a
short time by filling their memory space.

The pseudo codes for blocking the tag-driven TDMA are
given as follows:
Normal Condition
While(No Power Field( ));
Jump to Blocking Condition;

Blocking Condition
While(block time interval){
Randomly Choose Simulator Subset( );
Randomize Modulate Signal( );
Send(ID);
Decrease(block time interval);
}
Jump to Normal Condition;
Using reader-driven TDMA, the readers and RFID tags
work in a synchronous manner, i.e., the readers and tags all
work in constant time intervals (a.k.a., time splits). In Fig. 4,
we present the taxonomy of reader-driven TDMA presented
in [10]. Here, we explain each of them based on the proposed
blocking techniques.
Using polling approach, the reader first identifies each tag
in the range by differentiating the prefix of its serial number.
For example, the reader first ask: “Does anyone have prefix
A?” If some tags reply with “yes!”, the reader will ask: “Is
there anyone with the prefix Aa?” where a is either 0 or 1. The
reader interrogates each tag one-by-one until the reader repeats
this process recursively to identify each tag. The proposed
blocking technique should prevent an unauthorized reader
from identifying each tag. To this end, RWD can randomly
select a group of RFID Simulators and reply the reader with
randomly modulated signal “yes”. As a consequence, the
multiple random replies force the reader to try every the
possible serial number prefix. In RFID GEN2 standard, each
RFID tag contains a unique 92-bit serial number and the size
of entire possible tag serial number will be 292 . This set is
very large and it is impractical in terms of time and memory
for the readers to query every prefix or store the identified
serial numbers. Therefore, the reader may be expected to stall
after querying thousands of prefix.
The tree search method [1] can be divided into two classes:
(i) collision set tree algorithm [2] and (ii) query tree algorithm
[7]. The collision set tree algorithm splits the group of colliding tags into A disjoint subsets, where |A| > 1. The subsets get
smaller and smaller until the number of tags within a subset
equals to 1, and each tag will be uniquely identified. Once
a subset is completely resolved, waiting subsets are resolved
in a first-in last-out order. When several tags collide in the
same time split, each tag randomly selects to which subgroup
it should belong. Thus, it is the tag’s responsibility to track
the current position in the stack so that the individual tag
can decide the time to retransmit the signal. To block this
algorithm in each time split, RWD can randomly select a group
of the RFID Simulators, which transmits randomly modulated
response to the reader. Thus, the subset is never decreased to
1 and the reader will never identify the real RFID tags.
Normal Condition

4572
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

While(No Reading Command( ));
Jump to Blocking Condition;

Blocking Condition
While(block time interval){
Randomly Choose Simulator SubsetA( );
Randomly Choose Simulator SubsetB( );
Randomize Modulate Signal( );
SubsetA Send(”1”);
SubsetB Send(”0”);
Decrease(block time interval);
Wait for Next Time Slot();
}
Jump to Normal Condition;
I-code protocol [12], [11] uses a random seed to randomize
each tag’s response time split and uses an estimated flexible
size of frame to minimize the probability of collisions. To
block the I-code protocol, RWD can use a similar strategy of
blocking the query tree algorithm.
Contact-less protocol [3] works similar to the combination
of collision subset tree algorithm and query tree algorithm.
The reader queries the specific bit position one-by-one and
separates the colliding tags into subsets. To block contact-less
protocols, RWD can act similarly as blocking the query tree
algorithm.

RFID
Keeper Server
Secure Communication Channels
Room Watch
Dog
Block

Room Watch
Dog

Denial of
Reading

Denial of
Authentication

ck
Blo

Blocking Condition
While(block time interval){
Randomly Choose Simulator Subset( );
Randomize Modulate Signal( );
Send(ID);
Decrease(block time interval);
Wait for Next Time Slot();
}
Jump to Normal Condition;
The query tree algorithm consists of several rounds of
queries and responses. In each round, the reader asks tags
whether their serial numbers contain a certain prefix B. Then,
the tags compare the prefix B with their serial numbers. If a tag
has the queried prefix, it replies with the B1 or B0, where 1 or
0 is the bit in its serial number next to the prefix. If only one
tag replies, this tag is identified since no collision occurred;
otherwise, the reader will add a bit to the prefix and continue
its queries. In [6], the authors proposed a blocking approach
by replying both B1 and B0 to block the reader. Similarly,
in our approach, RWD randomly chooses a group of RFID
Simulators and transmits randomly modulated responses, i.e.,
B1 and B0 to the reader. Similar with the polling approach,
RKS will overwhelm the reader by forcing it to try every
possible prefix. The pseudo codes for blocking the query-tree
algorithm are given as follows:
Normal Condition
While(No Reading Command( ));
Jump to Blocking Condition;

Reader
Reader

legal User

Reader
Attacker

Fig. 5.

ut
itho n
dw
Rea orizatio Tags
h
Aut

Attacker

Read

Tags on the
Instrument

Denial of Reading and Denial of Authentication.

VI. S ECURITY A SSESSMENT AND E NHANCEMENT
In this section, we evaluate the security of the RFID Keeper
under session hi-jacking attacks, eavesdropping attacks, and
deny-of-Service attacks.
A. Counter Session Hijacking Attacks
In session hijacking attacks, an attacker reads the tags after
a user was authenticated. One attacking scenario is the attacker
extracts the data while the authenticated users are reading the
tags. In this case, if RWD can not differentiate the authorized
and unauthorized readings or detect multiple read commands,
the attack can be successfully deployed. To counter this attack,
RWD needs to detect the number of working readers in the
protected rooms. If the number of readers is larger than the
authenticated readers in the same room, RWD will block all
the readers and give alert to the system administrators.
Another attacking scenario happens when an authorized
user leaves the protected room without logging out and the
attacker masquerades the authorized user to read the tags. The
periodical challenge initialized by RWD can effectively reduce
the information leakage. The attacker, who is unaware of the
password of previous logged in user, will fail the challenge
and RWD will send blocking signals. Moreover, RKS will log
this event and the user who forgot to logout will be notified.
B. Counter Eavesdropping
Communications between RFID tags and readers are vulnerable to the eavesdropping since very few passive tags use
cryptographic protections. However, due to the short reading
range of passive tags, the eavesdroppers need to be the physical
proximity of RFID tags, which will be notified by authorized
users.
C. Counter Deny-of-Service Attacks
There are two types of DoS attacks to the proposed
approaches: (1) denial of reading: prevent authorized users
from reading RFID tags; and (2) denial of authentication:

4573
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

prevent RWDs from authenticating users. These DoS attacks
are illustrated in Fig. 5.
1) Denial of Reading: In order to prevent authorized users
from reading RFID tags, the attackers can keep on sending
read commands without being authenticated. As a result, RWD
will send blocking signals, which will also block authorized
readers. To overcome this problem, RWD should report to system administrators after several consecutive read commands
without authentications.
2) Denial of Authentication: To perform the denial of
authentication attacks, attackers can block the RWD from
detecting reader’s signals by covering the RWD with a metal
shield to block the signals (as illustrated in Fig. 5). Then,
attackers can read RFID tags without being detected by the
RWD. To counter this attack, we propose three approaches:
(1) passive listening, (2) active scanning, and (3) interactive
challenging.
By deploying a metal cover over an RWD, attackers can
block read commands from reaching the RWD. However,
this cover will also block the random signals and noises in
surroundings. The RWD can monitor the noise level its room.
If the RWD is blocked, the noise level will decrease and
then the RWD can detect the attack. The Fig. 6 illustrates
the change of noise before and after blocking. The data is
collected every 0.01 second and we collect 25 samples for
analysis.
We can differentiate two data series by computing their
standard deviations. The following table shows the results of
standard deviations of the noise level before and after blocking
the RWD.
Data Series
before blocking the RWD
after blocking the RWD

Standard Deviation
4.2454
0.2769

In the experiment, we collect 25 samplings and the sampling
frequency is 100Hz. It takes 0.25 seconds to collect the data
series.
In active scanning approach, RWD periodically sends Cosine signals and collects the reflected signals. The reflection
changes the phases of the signals. This approach utilizes the
multi-path phenomenon of wireless channel properties.
In interactive challenging approach, at least two RWDs are
required to be installed in each room. An RWD periodically
challenges other RWDs by sending a random number. After
receiving a challenge, the responding RWD uses a secret
random function to derive the response and replies to the
requestor. This approach can prevent attackers from simulating
RWDs.
We note that all presented three approaches are vulnerable
to active attackers who can artificially generate ambient noise,
simulate phase changes, or deploy man-in-the-middle attacks.
However, we consider these activities are difficult since the
attacks are required to set up sophistic devices to block RWDs.

Time split

0
-10

1

3 5 7

9 11 13 15 17 19 21 23 25

before
blocking

-20
-30
d
B
-40

after
blocking

-50
-60
-70

Fig. 6.

The strength of noise before and after blocking the RWD.

access. The RFID Keeper can provide reader authentication,
data access detection and control. We also evaluate the security
performance of the RFID Keeper. We find that the RFID
Keeper is vulnerable to some sophisticated attacks, such as
man-in-the-middle DoS attacks. Our future work should be
concentrated on countering this attack.
R EFERENCES
[1] Capetanakis. Tree Algorithms for Packet Broadcast Channels. IEEE
Transactions on Information Theory, 25:505–515, 1979.
[2] D. Hush and C. Wood. Analysis of Tree Algorithms for RFID Arbitration. In Proceedings of IEEE International Symposium on Information
Theory, page 107, August 1998.
[3] M. Jacomet, A. Ehrsam, and U. Gehrig. Contactless Identification
Device with Anti-collision Algorithm. In Proceedings of IEEE Computer
Society, Conference on Circuits, Systems, Computers and Communications, Athens (CSCC), July 1999.
[4] A. Juels. Minimalist Cryptography for Low-Cost RFID Tags. In
C. Blundo and S. Cimato, editors, Proceedings of International Conference on Security in Communication Networks (SCN), volume 3352
of Lecture Notes in Computer Science, pages 149–164, Amalfi, Italia,
September 2004. Springer-Verlag.
[5] A. Juels. RFID Security and Privacy: A Research Survey. IEEE Journal
on Selected Areas in Communications, 24(2):381–394, 2006.
[6] A. Juels, R. Rivest, and M. Szydlo. The Blocker Tag: Selective Blocking
of RFID Tags for Consumer Privacy. In Proceedings of ACM Conference
on Computer and Communications Security (CCS), pages 103–111,
Washington, DC, USA, October 2003.
[7] C. Law, K. Lee, and K. Siu. Efficient Memory-less Protocol for Tag
Identification. In Proceedings of the 4th International Workshop on
Discrete Algorithms and Methods for Mobile Computing and Communications, pages 75–84, August 2000.
[8] M. Liard and V. D. Corporation. The Global Markets and Applications
for Radio Frequency Identification and Contactless Smartcard Systems.
Venture Development Corp, 2003.
[9] M. Rieback, B. Crispo, and A. Tanenbaum. Keep on Blockin’ in
the Free World: Personal Access Control for Low-Cost RFID Tags.
In Proceedings of the International Workshop on Security Protocols
(IWSP), Lecture Notes in Computer Science, Cambridge, England, April
2005. Springer-Verlag.
[10] D.-H. Shiha, P.-L. Suna, D. C. Yenb, and S.-M. Huangc. Taxonomy and
survey of RFID anti-collision protocols. Computer Communications,
29:2150–2166, 2006.
[11] H. Vogt. Efficient Object Identification with Passive RFID Tags. In
Proceedings of International Conference on Pervasive Computing, pages
98–113, April 2002.
[12] H. Vogt. Multiple Object Identification with Passive RFID Tags. In
Proceedings of IEEE International Conference on Systems, Man and
Cybernetics, volume 3, page 6, October 2002.

VII. C ONCLUSION AND F UTURE W ORK
In this paper, we describe the RFID Keeper as an RFID
data access control mechanism to counter unauthorized data
4574
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

2013 IEEE Seventh International Symposium on Service-Oriented System Engineering

Secure Web Referral Services for Mobile Cloud
Computing
Le Xu* , Li Li† , Vijayakrishnan Nagarajan* , Dijiang Huang* , and Wei-Tek Tsai*
*

Arizona State University, Email: {le, dijiang, vnagara5, wtsai}@asu.edu
† Wuhan University, Email: lli@whu.edu.cn

Abstract—Security has become a major concern for mobile
devices when mobile users browsing malicious websites. Existed security solutions may rely on human factors to achieve
a good result against phishing websites and SSLStrip-based
Man-In-The-Middle (MITM) attack. This paper presents a
secure web referral service, which is called Secure Search
Engine (SSE) for mobile devices. The system uses mobile
cloud-based virtual computing and provides each user a
Virtual Machine (VM) as a personal security proxy where all
Web trafﬁcs are redirected through it. Within the VM, the SSE
uses web crawling technology with a set of checking services to
validate IP addresses and certiﬁcate chains. A Phishing Filter
is also used to check given URLs with an optimized execution
time. The system also uses private and anonymously shared
caches to protect user privacy and improve performance.
The evaluation results show that SSE is non-intrusive and
consumes no power or computation on the client device, while
producing less false positive and false negative than existing
web browser-based anti-phishing solutions.

potentially breached web site.
In SSLStrip attack, attackers explore the vulnerability
that a user may request a secure web site by initiating
an insecure HTTP request. The attacker can intercept the
request through ARP spooﬁng [5] or DNS poisoning [6]
attacks and then impersonate the user to send the request.
Once received the request, the secure web server usually
sends an HTTP 302 message to ask the user to initiate
an SSL session instead. The attacker then intercepts the
HTTP 302 redirect message and initiate an SSL session to
the web sever without forwarding the redirect message to
the user. After setting up an SSL connection to the web
server, the attacker sends un-encrypted web page to the
user. It is quite common for users overlooking the protocol
name, which should be changed from HTTP to HTTPS,
and a small lock logo should appear in the bottom of the
web browser. This problem becomes even severe when
lightweight small-screen mobile devices are used. If the
user types his username and password in the web page,
which is usually required by most ﬁnancial web sites for
authenticating the user, the username and password will be
transmitted to the attacker un-encrypted.
Phishing is another way to explore the human weakness
by using fake web sites. Similar to SSLStrip attack, Phishing attacks also present the exact same web content and
page layout to users, except the web address is different
and the lock logo does not appear in browser’s status bar.
To counter phishing attacks, many existing web browsers,
e.g., Firefox, incorporate anti-phishing ﬁlters by checking
several phishing-web site repositories, and then send alerts
to users if they happen to visit a phishing web site.
However, based on our testing, the false negative rate is very
high. This is due to several reasons. First, as cost of hosting
sites has come down and there are tools like dyndns.org,
which can map the dynamic changes of an IP address with
a domain name, attackers can easily change their domain
name and corresponding IP address. In addition, most of
phishing-site repositories require users to send reports to
them for phishing inspections, which introduces long delay
and makes the information in repositories obsolete quickly.
More severely, many phishing sites may not be detected
previously, and thus cannot be detected by web browser’s
Phishing Filter.
To address the presented problems, this paper presents a

Keywords: Mobile Cloud, Security, Web
I. I NTRODUCTION
World Wide Web (WWW) and the hyper linked web
pages along with services like online chatting, electronic
mail, and Internet services based on Cloud computing [1]
have made web browser as a universal information portal
for end users. Hyper Text Transfer Protocol (HTTP) [2]
has become the most popular application-layer protocol to
deliver information through Internet.
Using mobile devices, the web-based communications
have become easy targets for attackers to compromise
end-to-end communications, e.g., using Man-in-the-Middle
(MITM) attacks (e.g., SSLStrip [3]) and deploy malicious
phishing web sites to delude Internet users to expose
their private information. Cryptography-enhanced Internet
protocols (e.g., Secure Socket Layer [4] based HTTP, or
HTTPS) have been widely used to protect Internet users
from being attacked. However, strong cryptography-based
algorithms could not prevent security protocol designers
from overlooking the weakness of human beings in the
human-in-the-loop types of security protocols. SSL supported web browsing is an example of this kind. In this
paper, our research focuses on two major security problems
incurred due to human errors: e.g., SSLStrip MITM attack
and web based phishing attack, which require users to be
involved to make decisions on accepting or rejecting a
978-0-7695-4944-6/12 $26.00 © 2012 IEEE
DOI 10.1109/SOSE.2013.94

583
584

secure web referral system, named Secure Search Engine
(SSE), for mobile devices. The system uses mobile cloudbased virtual computing [7], [8], [9] and provides each
user a VM as a personal security proxy where all Web
trafﬁcs are redirected through it. Each VM is isolated
from other VMs to protect the user’s privacy. Within the
VM, the SSE checks the Web trafﬁcs for potential MITM
or phishing attacks. SSE is designed as an automatic
web referral service involving minimal interventions from
humans for security decisions. SSE returns deterministic
answers of security inspections to either accept or reject
the Web request, and thus it can remove potential human
errors. SSE also includes a Phishing Filter that can check
several existing phishing-site repositories, and validate site
certiﬁcates to identify a phishing site.
The rest of this paper is organized as follows. Section II
describes related works. Section III describes the detailed
designs of the system. Section IV shows testing results from
the implemented system. Finally, section V concludes and
describes future work.

53 hours [16] that cannot be crawled by Google’s search
engine immediately.
To address the MITM and phishing issues, a number of
proxy-based security models have been proposed. Tahoma
[17] uses a browser OS running on top of a client-side
Xen-managed virtual machine to serve as a local proxy to
scan web applications. Flashproxy [18] targeted the performance and security of Flash object browsing on mobile
devices. WebShield [19], SpyProxy [20], AjaxScope [21]
and BrowserShield [22] proposed similar proxy-based web
security models where they use a sandbox on the remote
proxy to execute and render the web application while
detecting security threats by monitoring the application behaviors. These approaches incur overheads when switching
from one virtual machine to another. Moreover, since they
share virtual machines among users, the user’s privacy may
be an issue. The system is deployed on centralized server
and may suffer from single-point-failure problems. Zscaler
[23] proposed a policy-based, secure Internet access model
for mobile device that is built upon cloud services. It allows
administrators to enforce user level policies without any
software or hardware deployment on the devices. However,
Zscaler lacks the data isolation and privacy protection for
individual users.

II. R ELATED W ORK
In [10], authors proposed solutions for countering a
web-based MITM attack by introducing context sensitive
certiﬁcate veriﬁcation and speciﬁc password warning-aware
browsers. This technique validates a certiﬁcate and also
checks if a password is sent in an unsecured way. In
[11]. Jackson et al proposed ForceHTTPS, which forces
the browser to open a secure connection to the destination.
If the destination does not support an SSL connection, then
the user needs to manually set a policy in ForceHTTPs. This
approach does not prevent MITM attacks since attackers
can intercept the HTTPS request and return a “no-HTTPSsupport” message and force the web browser to initiate
HTTP sessions.
Researchers in [12] developed an anti-phishing toolbar
for web browsers. However, studies showed in [13], 23%
of the people do not look at the address bar, status bar, and
security indicator when they browsing web sites, and let
alone the small screen size when using mobile devices. In
[14], the authors compared the effectiveness of using different phishing tools such as Firefox2, IE7, Spoofguard [12],
etc. Their results showed that all evaluated tools are less
90% effective in identifying phishing web sites. Zhang et
al, in [15], proposed a Phishing Filter “CANTINA”, where
they make use of robust hyperlinks and term-f requency inverse document f requency (tf − idf ), where tf − idf
is a technique to give less importance to the common
occurring words. When a URL is fed into CANTINA, it
ﬁrst calculates the tf − idf scores for the page, then it
calculates the lexical signature using the top-5 tf −idf , and
ﬁnally it uses Google Search engine to check if the web site
is in the top N results. The drawback with this technique
is that CANTINA depends on the Google’s Crawler. When
a new web site is up, it can stay online for approximately

III. A RCHITECTURE AND I MPLEMENTATION
This section presents the architecture and components
of the mobile cloud-based SSE system. The terminology
and description are based on [24], which describes the
basic components and models to establish an efﬁcient and
scalable search engine.
The overall system architecture is shown in Fig. 1. The
major components of the system are described as follows.
• Xen Server Cluster: The Xen server cluster is a set of
Xen servers [25] that provisions VM resource pools. The
Xen platform provides XenAPIs, which are used by the
web server to provide VM management and conﬁguration
functions to the mobile users.
• Web Server: The web server hosts a website to provide
a management portal for users and system administrators. A
database within the web server manages the DNS names, IP
addresses and VM software conﬁgurations. The web server
also works with Xen other servers in the cloud to perform
system instructions. For instance, it works with DNS/DHCP
servers to assign domain names and IP addresses to the
newly created VMs.
• Mobile User VM: Each mobile cloud user has a
dedicated VM that incorporates several components to
provide features such as http proxy, caching and logging.
The VM also works with the SSE service to detect and
counter MITM and phishing attacks. Fig. 2 shows the
components of a mobile user VM.
• Portal Gateway & Portal Network: The Portal
Gateway is the access point for mobile users to access
internal VMs and web services. The Portal Network serves
as a data exchanging channel between internal servers.

585
584


		 

!&		%	$	'!(	


	

	


 	





 

 

	










	



	

	

	



	
!	"	 #$$	
%		

Fig. 1.

System Components of the SSE Mobile Cloud System.

• SSE & Management Server: SSE server provide the
SSE service proposed in this article, and the Management
Server is in charge of the system resource allocation.
• Data Network & Data Gateway: The networks that
are used by VMs and SSE fetch web data from the Internet
and send to the user mobile devices.




*

	+





)


	


,





	!"	#$

-







 , 
'

+




"


*

%&&$
$'()
%#$

Fig. 2.

$ 



Fig. 3.
'

SSE Service Models.

• SSL veriﬁer: SSL veriﬁer is one of the core services
in SSE. The SSL veriﬁer module picks up an URL, collects
the certiﬁcates for one or multiple domains running on the
server. It also validates the certiﬁcate chain and stores the
validation results in the certiﬁcate repository maintained by
the SSE.
• Phishing Filter: Phishing Filter is another core service
in SSE, in which it inspects each web page linked through
the inspecting URL. Using the learning algorithm explained
in Section III-C, the Phishing Filter checks if a web site is
a legitimate site or a phishing site
• SSE Crawler: The SSE Crawler is an automatic
computer program that collects security and web page
information of URLs for SSL veriﬁer and Phishing Filter.
In general, the Crawler starts with a list of URLs (such as
URLs for Banks) to visit, which are called “seeds”. As
the SSE Crawler visits these URLs, it identiﬁes all the
hyperlinks in the page and adds them to the list of URLs.

Components of the user VM.

A. Secure Search Engine
1) Secure Search Engine Architecture: The SSE is a
cloud service that can be used by each mobile user VM.
To provide web proxy and caching functions, a mobile user
VM incorporates multiple components, as shown in Fig. 2.
The implementation of SSE is through a layered service
architecture, where the higher layer services make use of
the services at its immediate lower layer. Fig. 3 shows the
main services of the SSE architecture.
• SSE service: SSE service answers all the user queries
generated by web browsers. Replies of the SSE service are
made from the inspection results from the SSL veriﬁer and
the Phishing Filter.
586
585

The SSE Crawler collects all the security information from
each URL, such as public key certiﬁcates.
• DNS service: DNS service is critical for a search
engine as mentioned in [26], where about 87% of web
crawling trafﬁc is just due to DNS trafﬁc. The DNS
service is a caching mechanism to make the Crawler more
efﬁcient without causing too much repeated DNS trafﬁc.
The DNS service is also used by Phishing Filter to get the
IP addresses of inspecting domain names.
• URL service: The URL service records URLs visited
by the Crawler including both visited URLs and to be
visited ones. Additionally, to make the Crawler scalable and
allow recovery from crashes, the URL service is responsible
for restoring the state of the Crawler in case of the system
crashes.
• Storage service: The storage service stores all the
information from SSE Crawler and link inspection results.


	



))





*

+

1




Fig. 5.

	



)*

)0

 


,

$"
-

.

)/




Dataﬂow within the Secure Search Engine.

!"


certiﬁcates. (9 & 10) The Phishing Filter runs the algorithm
to ﬁnd out whether a web site is a phishing site or not.
(11) The user VM requests the SSE to verify a web site.
(12 & 13) The SSE service uses the storage service to get
the corresponding data to evaluate. (14) The SSE service
answers the query.
Initially, the URL service is populated with a set of
seed URLs. The Crawler picks up an unprocessed URL
from the URL service and sends an HTTP request. In this
process, the Crawler uses the DNS service to retrieve the IP
address of the given domain name in the URL. The Crawler
collects new URLs from the HTTP responses and passes
them to the storage service. The stored web site information
will shorten the search responding time when the searched
web sites have been already inspected. Crawling services
are usually operated periodically based on a certain time
interval. Thus, between the crawling time window, new
phishing web sites can be issued. To handle the phishing
sites that have not been crawled, the SSE needs to process
a real-time security inspection.
3) SSE Processing Algorithm: Algorithm 1 presents the
SSE service processing algorithm. Lines 2-4 represent the
inspection based on cached information, which is explained
in Section III-D. The browser redirects all new URL
requests, including both inputs from the address bar and
clicks from the browser window, to the SSE service. URLs
are sent through pre-established HTTPS connections when
a web browser connects to the Internet. SSE service checks
with its database through the storage service to see (i) if the
site is already previously evaluated as a phishing site, and
(ii) if the site supports SSL and has a valid certiﬁcate. If
the requested URL does not exist in the SSE’s database,
SSE calls SSL veriﬁer and Phishing Filter processes to
inspect if the user encounter MITM or phishing attacks. The
evaluation results will be sent to the browser and it is up to
the user to discard the HTTP request or ignore the Warning





#
 
#
$
% 

Fig. 4.

0

$&







 


'
'
	
'

)
(

)1

Steps involved between a VM and the SSE service.

2) Procedures of Using SSE Service: The Fig. 4 explains
the data ﬂow among the user, the SSE, and the web
request destination. When the SSE receives a web request, it
inspects whether the requested URL links to a phishing site
or not. The inspection includes two procedures through two
ﬁlters: (a) SSL veriﬁer validates if the web server provides
valid certiﬁcates and supports HTTPS for the requested domain; and (b) Phishing Filter identiﬁes phishing properties
of the inspected web page. The inspection result is sent to
the user for decisions: (i) sending an HTTPS request if the
web server provides valid certiﬁcates and SSL is enabled,
(ii) sending an HTTP request if the web server does not
provide a valid certiﬁcate and the web site had passed the
inspection of Phishing Filter, and (iii) sending an access
denial webpage to the user if the web site does not pass
any one of ﬁlters of the SSE server.
Fig. 5 presents the data ﬂows within the SSE server.
Steps: (1) Crawler gets the unprocessed URLs from the
URL service. (2 & 3) Crawler requests and gets the
rewritten URL(with the corresponding IP-Address) (4 &
5 ) After crawling the new URL, Crawler updates the DNS
cache and URL service with the extracted URL. (6) The
collected results are persisted using the storage service. (7
& 8) The SSL veriﬁer collects, validates, and then stores the

587
586

Algorithm 1 SSE Processing.
1: The browser retrieves U RL = getT heU RL();
2: if The U RL is available in VM’s cache and the cache
expiration timer is not expired then
3:
Take actions based on the cached attributes;
4: else
5:
The browser sends a request message msg =
redirectT oSSEService(U RL) to SSE;
6:
if SSE checks msg is a phishing site in its cached
database then
7:
SSE sends a Warning message to the browser;
8:
if The user ignores warning then
9:
The
browser
sends
normal
HT T P Request(U RL) to the web server;
10:
else
11:
The browser drops the HTTP request;
12:
end if
13:
else if SSL veriﬁer returns “the web server supports
HTTPS” AND Phishing Filter returns “the web
server is not a phishing site” then
14:
SSE sends the certiﬁcate information to the
browser;
15:
The
browser
sends
secure
HT T P SRequest(U RL) to the web server;
16:
else if SSL veriﬁer returns “the web server supports
HTTP“ AND Phishing Filter returns “the web server
is not a phishing site“ then
17:
SSE informs the browser;
18:
The
browser
sends
normal
HT T P Request(U RL) to the web server;
19:
else
20:
SSE sends a Warning message to the browser;
21:
the browser goes to Step 8;
22:
end if
23: end if

Algorithm 2 SSL Veriﬁer
1: urls = extractAllHttpsU rls();
2: for each URL in urls do
3:
certChain = getCertif icate();
4:
if certChain is valid then
5:
for each certif icate in the certChain do
6:
params = extractCertP arameters();
7:
store(params, certif icate);
8:
end for
9:
else
10:
mark invalid certiﬁcate against the URL;
11:
end if
12: end for

to a remote web site. For example, a mobile user usually
just types usbank.com in the address bar. By default, the
browser will interpret the request as an HTTP request,
i.e., http://www.usbank.com, which sets the destination web
server’s port number to 80. By intercepting the user’s
request, the attacker can establish an SSL session to the
web server and replies to the user with an unencrypted
web page using HTTP protocol. To counter the described
SSLStrip MITM attack, the SSE automates the security
inspection procedure and the user will be notiﬁed only if
potential MITM attacks are detected. This minimizes the
human factors in the process.
The SSL veriﬁer algorithm (Algorithm 2) can be used
to illustrate the steps involved in countering an MITM
attack. The Crawler collects information about the web
site and stores it using the storage service. The SSL
veriﬁer gets the unprocessed URLs from the storage (use
function extractAllHttpsU rls()). For each URL, the SSL
veriﬁer checks for an SSL connection to the server. If an
SSL connection request is accepted by the server, then it
inspects the certiﬁcate chain and validates each certiﬁcate
in the chain towards the site certiﬁcate. The validation
includes checking the certiﬁcate expiration date, and the
basic constraint ﬁeld specifying if the certiﬁcate can be
used to sign other certiﬁcates. If the web site rejects the
HTTPS request, or the web site does not have a valid
certiﬁcate, and thus no support for HTTPS. Additionally,
the IP addresses used by the web site is also cached in the
DNS service. This would serve two purposes: (i) protects
from DNS spooﬁng as we send the trusted IP address of
the web-site (ii) helps improving the time taken to load
the page as there is no need of DNS requests. Finally, the
browser initiates an HTTPS connection if it learns from the
SSE that web site supports HTTPS connections.
Once an HTTPS connection is initiated, the HTTPS protocol will enforce an SSL connection with requested port
number 443. When initiating an HTTPS connection, a user
expects to receive a valid certiﬁcate and uses its public key
to derive a shared key for securing future communications.
Since MITM attackers do not have a valid private key of
the web server’s certiﬁcate, they cannot derive the shared

when receiving a negative reply. The corresponding HTTP
or HTTPS request then will be sent out. If the requested
web site information does not exist in SSE’s database, SSE
will start a real-time inspection which is straightforward,
and the inspection steps are illustrated from line 13 to line
21.
B. Countering SSLStrip MITM Attacks
The goal of an MITM attacker is to get personal private
information, such as a bank account associated username
and password, etc. In the following presentations, the paper
considers an example of a user accessing a banking web
site, e.g., www.usbank.com, and illustrate how SSE works
to defend the SSLStrip MITM attack. In this example, the
basic problem incurred by SSLStrip attack is originated by
a human who uses a browser to access his/her bank account.
The awareness of using security protocols to support onlinebanking system is very low for general users. It is the
human nature to type as less number of letters to get access
588
587

from a training set given about the phishing sites and uses
words commonly existing in phishing sites as the features
for Bayes classiﬁcation. The training samples are extracted
from phishing databases such as PhishTank.com. The Basis
of Bayes classiﬁcation is presented in [28].
Apart from the Bayes classiﬁcation, the Phishing Filter
checks with the SSE database and see if the IP address
has hosted any phishing site in the past. The ﬁlter also
checks if the site has a valid certiﬁcate and its Google page
rank. These components are chosen for following reasons.
(i) Phishing sites usually do not provide valid certiﬁcates
since the process for obtaining a certiﬁcate is not desired
for phishing attackers. (ii) Google page rank is calculated
using many parameters to evaluate the popularity of a web
page. One important parameter is the propagation of trust
among web sites. A trusted web page should always refer to
other trusted web pages. Intuitively, this would bring down
the rank of a phishing web site since no trusted web pages
refer to it. More importantly, phishing sites are hosted for
a short span of time and the probability of crawling the
web page would be less. In our established prototype, a
weighted average based on the presented four parameters
is calculated and normalized to a range of [0,10]. If the ﬁnal
value, conf idence, is less than an allowable threshold then
the web page is reported as phishing web site.
As shown in Algorithm 3, ﬁrst, the information of phishing site is collected from phishing banks and the Bayes
classiﬁer is trained based on these inputs. During training,
we remove the common occurring words using tf − idf
values (illustrated in [15]). All tf − idf values which are
less than 0.5 are not considered for further processing. The
remaining words in a page are used to train the Bayes
classiﬁer. Based on the training results, we calculate the
P (i) (probability of a page i being a phishing site) of each
crawled web page.
For each web page i, the system also gets the corresponding Google page rank, which is normalized in scale
of 0 to 1 and the value of GPR is assigned. From the SSL
Veriﬁer we also get the certiﬁcate information, whether a
domain has a valid certiﬁcate or not.
Finally to get the value of IP (i) we use the following
computation. Let t represent the number of days that an IP
address has not hosted a phishing site. The value of IP (i)
can be computed using the following formula:
⎧
⎨1 − 1 , if t > 1;
log t
IP (i) =
(1)
⎩0,
otherwise.

Algorithm 3 Phishing Filter
for web page i do
Bayes classiﬁer will return with a probability
of a web site being a phishing site P (i) =
getP robabilityF orP hishing(U RL);
Cert(i) = hasV alidCertif icate(U RL), checks if
the URL has a valid certiﬁcate;
GP R(i) = getGoogleP ageRank(U RL), gets the
Google page rank which will be normalized to 0-1
scale;
1
Compute IP (i) = 1 −
, which is illustrated in
log t
(1);
Compute (2) to get the conﬁdence value for page i;
if Conf idence(i) ≤ conf idenceT hresholdτ then
return phishing site found;
else
return trustable site;
end if
end for

key. As a result, MITM attackers cannot intercept and
decrypt the ciphertext sent to U.S. Bank’s web site. Thus,
the MITM attack fails. Although the MITM attacker can
cause a Denial-Of-Service attack by not forwarding the
intercepted packets, this still prevents the attackers from
compromising the users’ private information.
C. Countering Web-based Phishing
At present, many browsers incorporate phishing ﬁlters
that utilize existing phishing-site databases like PhishTank
www.phishtank.com. In these databases, phishing sites are
manually fed by users who come across them during web
surﬁng. Phishing sites usually appear for only short span
of period, and thus most of listed phishing sites in these
databases are expired, which make them less effective.
To address the described problem of existing phishing
ﬁltering techniques, the paper presents a real-time Phishing
Filter as part of SSE to inspect phishing sites. The solution
is highlighted in Algorithm 3, which includes four independent components: IP checker IP (i), Bayes classiﬁer
P (i), Certiﬁcate checker Cert(i), and Google page rank
GP R(i).
The phishing sites often resemble like a ﬁnancial web
site and the content of the web page is also similar to the
ﬁnancial web page. Thus, a Phishing Filter must take a
comprehensive and systematic approach, which is adaptable
to their changes. To this end, we utilize machine-learning
techniques that could learn phishing site properties based
on the changes of phishing sites. In Algorithm 3, we
use a supervised learning-based classiﬁcation technique
to improve the accuracy of detecting phishing sites. This
supervised learning technique adapts to the changes made
by the phishing sites to get a better result. The supervised
learning is based on Bayes classiﬁcation [27], which learns

When IP (i) is calculated for the ﬁrst time, t is set to a
large number greater than 30 for a non-phishing site, or
t is set to 1 for a phishing site collected from different
phishing repositories. As the t increases the log1 t decreases
and the value of IP (i) increases. Thus, increase in value
of IP (i) would increase the value of conf idencei .
To take a comprehensive consideration for the four
evaluation components, the Conf idence(i) is computed by

589
588

exceeds the expiration time, the VM requests the SSE
service to re-evaluate the site. This step is illustrated from
lines 2 to 4 of Algorithm 1.

Algorithm 4 Crawler
1: while Get an unprocessed U RL from URL service
(U RL = getU RLF romU RLservice())! = N U LL
do
2:
U RL = replaceDomainW ithIP (U RL), rewrite
the domain name with IP address(es).
3:
pageContent = getP age(U RL), send and receive
the content of the URL.
4:
U RLS = extractU RLS(page), extract all the URL
links in the web page with new domain names.
5:
DN SService(U RLS), update the DNS service
with the extracted URLs. The DNS service would try
to cache the IP Address(es) of the un-cached domain
name.
6:
setN ewU rlsInU RLService(U RLS), update the
extracted URLs to URL Service, which maintains the
state by having visited and not visited URLs classes.
7: end while

IV. P ERFORMANCE A SSESSMENT
This section presents the effectiveness of SSE to counter
MITM and phishing attacks and computations and delay
performance.
A. System Setup
1) SSE Crawler: The SSE crawler is developed as a
multi-threaded application as shown in Algorithm 4. It
fetches web pages from Internet, extracts the URLs present
in the page and iterates them while checking. To start with,
the Crawler is fed with a few seed URLs from banking web
sites. The Crawler gets an unprocessed URL from the URL
service. Then, the Crawler gets the IP address(es) of the
domain from the DNS Service. The DNS Service returns
the IP address(es) of the domain if it has already cached the
IP address(es). If the IP address(es) is not available in the
DNS Service’s cache, the DNS Service sends out a request
to get the IP address(es) of the domain. The Crawler then
starts fetching the web pages. For each fetched web page,
the Crawler parses the page to extract the new URLs in
it. The new URLs that contain new domains are given to
DNS service and URL service to repeat the process. The
URL service classiﬁes these new URLs into visited and notvisited categories comparing with both the categories. The
DNS service will check if new URLs domain-IP addresses
mapping is available in its cache. If not available, the DNS
service tries to cache the IP Address of the un-cached
domain name. The content of the page, received from web
server through the crawler, will be persisted in the local
storage.
To obtain the optimized results, the crawler is conﬁgured
with certain parameters like maximum depth to crawl for
a given domain, number of concurrency, how often the
crawler should take back-ups, size of the cache storage
for DNS service and URL service, etc. Both the URL
service and the DNS service make use of Least Recently
Used (LRU) algorithm [31] for caching the data. The URL
service makes use of Bloom Filter[30] to store the URL.
The URL service also takes backup at regular intervals,
which can also be conﬁgured.
2) User Trafﬁc Generator: Table I lists the notations that
will be used in the user trafﬁc generator.
The theoretic trafﬁc models are used to generate mobile
user trafﬁc for load and delay experiments. Particularly, the
experiment is based on the theoretical queuing model using
little’s law to generate user requests to the SSE server.
Little’s law states that the long term average number of
customers (L) in a stable system is equal to the long-term
average arrival rate (λ) multiplied by the average time taken
to service (W ), which is described as follows:

the following weighted function:
Conf idence(i) = α·P (i)+β·Cert(i)+γ·IP (i)+δ·GP R(i),
(2)
where α, β, γ, δ are constants and we set α + β + γ +
δ = 10, P (i) is probability of URL being a phishing site
derived from the Bayes classiﬁer and P (i) ∈ [0, 1], Cert(i)
is a boolean value whether the checking of SSL veriﬁer is
passed or not, IP (i) is calculated from (1), and GP R(i) ∈
[0, 1] is the value of Google page rank for the corresponding
URL i.
To obtain the values of α, β, γ and δ, SSE uses
an approach based on linear classiﬁcation [29]. If the
conf idence value is less than the threshold τ , then the site
is phishing site. To determine the values of four constants
and τ , we used 100 phishing web sites and 100 nonphishing web sites as the training sample to derive the
following values for SSE Phishing Filter: α = 4, β = 3,
γ = 1, δ = 2, and τ = 3.
D. Use Caching to Reduce the Delay incurred by SSE
Service
Using SSE, additional delay will be added into the
browsing processes while the SSE Service is checking
the web URL. To reduce it, two levels of caching are
maintained at both the VM side and the SSE server side.
At the SSE server side, history for checked phishing sites
are maintained in database. The SSE uses Bloom ﬁlter
[30] data structure to efﬁciently store the phishing sites
information. The paper has conﬁgured the bloom ﬁlter to
have 5% false positive for about one million URLs.
At the VM side, the http proxy can cache previously
visited phishing site information derived from SSE service
for later use. Before sending a URL to the SSE, the VM
checks whether the URL is present in the cache and its
timestamp is not expired. Only when the current time

L = λW.

590
589

TABLE I
U SER T RAFFIC G ENERATOR N OTATIONS

N otations
λ
u
RTti
RT DN Sti
RT W Sti
RTt

noted separately for the SSE service request/response and
web service request/response, RT SSEti and RT W Sti
respectively. As our SSE service accepts only secure connection, the RT SSEti also comprises of the SSL overhead. A modiﬁed version of our SSE service and client
uses unsecured connection to ﬁnd out the overhead caused
due to SSL connection. The secure SSE round-trip time
can be represented as RT SSEsecti and RT SSEti , for
unsecured connection. The time taken for a DNS request is
not taken into consideration, as the SSE service will rewrite
the requested URL with the corresponding IP addresses.
Using this user trafﬁc generation model the performance
overhead induced by the framework can be measured.

List of notations used
N ame
arrival rate.
total number of URLs in pool.
round-trip time of ith request.
round-trip time of ith DNS request.
round-trip time of ith web service request.
summation of the time spent by each packet in
network and the service time.

The arrival rate in the system is the number of requests
arrived at SSE server per second. Let the average arrival
rate be λ per second. Assuming that the arrival rate λ
follows Poisson distribution, the experiment approximately
generates one request every t = 1/λ seconds. In other
words, a request would be generated t − Δt or at t + Δt,
which would average out close to t over a long period
of time. In this way, the experiment can emulate the real
scenarios with multiple SSE service requests sent from
different users.
To compare the current browsing behavior with SSE
model, a client in Python is developed using multi-threaded
programming to generate SSE service requests. The client
can be conﬁgured to simulate the current browsing behavior
and also the SSE Model. For comparison purpose, client 1
represents the current browsing model simulation and client
2 represents the SSE model simulation.
Client 1 picks up a random URL from a pool of URLs
and sends out an HTTP request and waits for the response.
After receiving the response from the web server, client 1
waits for t seconds before sending another request. The total
number of requests sent by a client or the number of URLs
in the pool is represented as u. For each request, represented
by i, the client records the time ti1 when the request was
sent, and the time ti2 when the client receives the response,
and then we can calculate the round-trip time RTti = ti2 −
ti1 . RTti comprises of two entities: RTti = RT DN Sti +
RT W Sti , where RT DN Sti is the round-trip time for
the DNS request and RT W Sti is the round-trip time for
a web service request, and the RTt is summation of roundtrip time of all the i requests. The total round-trip time for
all requests is represented as follows:

RTt =

u


RTti ,

B. Performance Evaluation of Phishing Filter

$
'**



'**



Two parameters are used to evaluate the Phishing Filter:
false positives and false negatives. If a non-phishing site is
blocked as a phishing site, then it is a false positive; and if a
phishing site is not blocked, then it is a false negative. Both
false positive and false negative value should be low for
a good Phishing Filter. Generally speaking, false negative
of detecting phishing sites is more important than a false
positive for web browsing.

)*

%%/

).

	0

$

*



.
-.

Fig. 6.

1.

2.

Percentage of the False Negative.

To show the effectiveness of SSE Phishing Filter, the
paper compares it with built-in phishing ﬁlters of Firefox
3.5, Chrome 2.0, and IE 8.0. All these browsers update
their local phishing cache every 30 minutes from their
own phishing sites repositories. In the experiment, newest
reported phishing sites from www.phishtank.com are collected with respect to different time frames: 30 minutes, 60
minutes, and 90 minutes. 1000 URLs are collected for each
time frame and are tested using the compared browsers. The
expected behavior of each browser is to warn the mobile
user before he/she can access those phishing sites. If the
page gets loaded without any warning messages, then it
is considered a false negative. The results are compared
with the SSE Phishing Filter on calculated percentage of
false negatives of each system in Fig. 6. The x-axis of
the graph shows the time frame and the y-axis is the
percentage of false negatives. The graph shows that the
percentage of false negatives of the browser reduces as

(3)

and the average RTtavg for each request is
RTt
.
u

,.

-'
-


.*..


i=1

RTtavg =

$
'* 
,


,*

(4)

Client 2 sends the request to the SSE service, conﬁrms
if it is a trusted site and then sends a request to the
URL by the mobile user. Again, the URL is randomly
picked up from the pool of URLs and round-trip time is
591
590

the time frame increases (from 30 minutes to 90 minutes).
This is because more reported phishing sites are entered in
phishing site repositories with time going. The percentage
of false negative of the SSE Phishing Filter remains a low
level, and it is lower in all time frames compared to the
evaluated browsers. This performance evaluation shows that
SSE ﬁlter achieves the best performance through active
phishing scan. The false negatives of SSE Phishing Filter
are mainly from phishing sites using ﬁgures to present
statements.

3

'
-
.'.-'

1

&.'

*
+


-

$	

,

(	

$

)
.
.

$
'* 
$'


)..

,..

-..
+..
*..
,''*'


1..

3..

/'**
-'


-*

Fig. 8. A comparison between current web browsing loading time and
the presented SSE solution.

,*
,
)*
)

shows the number of concurrent users in the system and the
y-axis is the delay of a user from requesting the web site
to loading the requested web page. The blue curve is the
normal scenario that takes place without using SSE service,
where the average time taken to load a page is about 4
seconds. The red curve shows the experiment results with
SSE service. Initially, the SSE service takes more time to
respond and builds up the cache. The successive requests
for validation take less time as the URLs have already been
veriﬁed and cached.
The average time saved by rewriting the IP-address with
domain name was around 9%. The graph shows the roundtrip time taken with rewriting IP address is shown in green
color. During the experiment, the average overhead caused
by the secure connection to the SSE service is approximately 12% of the entire round-trip time including the
processing and communication delay of SSE requests, SSE
responses, web server requests, and web server responses.

.*
.
%%/

	0


$



$*



Fig. 7.

Percentage of the False Positive.

To evaluate the false positives of SSE Phishing Filter and
the compared browsers, the paper randomly collects 100
non-phishing sites that are close to a phishing site. These
URLs were from unknown category of www.phishtank.
com, which have been veriﬁed manually as non-phishing
sites. It is expected that the SSE Phishing Filter does
not identify these web sites as phishing sites. The paper
calculates the percentage of URLs that are identiﬁed as
phishing sites by the SSE Phishing Filter. As shown in the
Fig. 7, the false positives of all the techniques are low and
the results from SSE Phishing Filter are the lowest. Most of
the phishing web sites are based on banking sites. Almost
all of these banking sites have a proper certiﬁcate through
which they prove their genuineness. Once a web site has a
proper certiﬁcate the SSE Phishing Filter will have β = 3
which is enough to cross the threshold, i.e., τ = 3. This is
the reason why the SSE’s false positive is less.

$*'.'*


.-

&.'

.,*

C. Performance Evaluation of Delay and Resource Consumption

.,
	
&
	


.)*
.)
..*
.
.*
.
.

This section discusses the percentage of the delay of the
SSE service for a web request and analyzes how much load
SSE system can withstand with a given system setup.
The experiment allows each mobile user using the trafﬁc
generator to send 50 SSE requests every 15 seconds. Out of
those 50 URLs, some are banking sites where an SSL connection to these banking sites is mandatory. The experiment
is performed after clearing the cached URLs at SSE server.
The paper emulates 100 to 600 users’ behaviors and studies
the round-trip time taken with different models. The results
obtained are shown in the Fig. 8. The x-axis of the graph

,..

+..

1..

0..

)...

),..

,''*	'


Fig. 9.

Processing time taken by the SSE service.

Using the same experiment settings, the paper also
calculates the performance of the SSE, particularly, the
processing time taken by the SSE service to respond after
getting a validation request. The average time to respond
is calculated by increasing the number of mobile users
accessing the SSE service. Fig. 9 shows the values of
average time taken by the SSE service to respond, with the
592
591

x-axis representing the number of concurrent users and yaxis representing the time taken to process in seconds. The
experiment was started with 100 users and the cache at the
SSE server was cleared initially. With time going, the SSE
will cache the inspected web sites. The ﬁgure shows that
the processing time is high at the beginning that conﬁrms
the advantage of using caching to handle large amount of
trafﬁc, where the processing time drops down due to many
requests can be answered latterly by using SSE caching.
The SSE system distributes the workload among 3
servers: The crawler, DNS service, and URL service. The
SSE service and Storage service, SSL veriﬁer and Phishing
Filter run on two different machines. Based on the current
set-up, SSE is able to support about 5,000 concurrent users
simultaneously.

[13] R. Dhamija, J. Tygar, and M. Hearst, “Why phishing works,”
in Proceedings of the SIGCHI conference on Human Factors in
computing systems. ACM New York, NY, USA, 2006, pp. 581–590.
[14] Y. Zhang, S. Egelman, L. Cranor, and J. Hong, “Phinding phish:
Evaluating anti-phishing tools,” in Proceedings of the 14th Annual
Network and Distributed System Security Symposium. Citeseer,
2007.
[15] Y. Zhang, J. I. Hong, and L. F. Cranor, “Cantina: a content-based
approach to detecting phishing web sites,” in Proceedings of the 16th
international conference on World Wide Web. New York, NY, USA:
ACM, 2007, pp. 639–648.
[16] G. Aaron and R. Rasmussen, “Anti phishing working
group - global phishing survey: Trends and domain name
use in 2h2008,” http://www.antiphishing.org/reports/APWG
GlobalPhishingSurvey2H2008.pdf, 2008.
[17] R. Cox, J. Hansen, S. Gribble, and H. Levy, “A safety-oriented
platform for web applications,” in Security and Privacy, 2006 IEEE
Symposium on, may 2006, pp. 15 pp. –364.
[18] A. Moshchuk, S. D. Gribble, and H. M. Levy, “Flashproxy:
transparently enabling rich web content via remote execution,”
in Proceeding of the 6th international conference on Mobile
systems, applications, and services, ser. MobiSys ’08. New
York, NY, USA: ACM, 2008, pp. 81–93. [Online]. Available:
http://doi.acm.org/10.1145/1378600.1378611
[19] Z. Li, Y. Tang, Y. Cao, V. Rastogi, Y. Chen, B. Liu, and C. Sbisa,
“Webshield: Enabling various web defense techniques without client
side modiﬁcations,” in NDSS, 2011.
[20] A. Moshchuk, T. Bragin, D. Deville, S. D. Gribble, and H. M. Levy,
“Spyproxy: execution-based detection of malicious web content,”
in Proceedings of 16th USENIX Security Symposium on USENIX
Security Symposium. Berkeley, CA, USA: USENIX Association,
2007, pp. 3:1–3:16. [Online]. Available: http://dl.acm.org/citation.
cfm?id=1362903.1362906
[21] E. Kiciman and B. Livshits, “Ajaxscope: a platform for remotely
monitoring the client-side behavior of web 2.0 applications,”
SIGOPS Oper. Syst. Rev., vol. 41, pp. 17–30, October 2007.
[Online]. Available: http://doi.acm.org/10.1145/1323293.1294264
[22] C. Reis, J. Dunagan, H. J. Wang, O. Dubrovsky, and S. Esmeir,
“Browsershield: Vulnerability-driven ﬁltering of dynamic html,”
ACM Trans. Web, vol. 1, September 2007. [Online]. Available:
http://doi.acm.org/10.1145/1281480.1281481
[23] Zscaler Inc., “Zscaler cloud services overview,” July 2011. [Online].
Available: http://www.zscaler.com/cloudservicesoverview.html
[24] S. Brin and L. Page, “The anatomy of a large-scale hypertextual
Web search engine,” Computer networks and ISDN systems, vol. 30,
no. 1-7, pp. 107–117, 1998.
[25] Xen, “Xen Virtualization Open Source Project.” [Online]. Available:
http://xen.org
[26] A. Heydon and M. Najork, “Mercator: A scalable, extensible
web crawler,” World Wide Web, vol. 2, pp. 219–229, 1999,
10.1023/A:1019213109274. [Online]. Available: http://dx.doi.org/
10.1023/A:1019213109274
[27] T. Mitchell, “Bayesian learning,” Machine learning, pp. 154–200,
1997.
[28] P. Langley, W. Iba, and K. Thompson, “An analysis of bayesian
classiﬁers,” in Proceedings of the National Conference on Artiﬁcial
Intelligence. JOHN WILEY & SONS LTD, 1992, pp. 223–223.
[29] C. Bishop et al., Pattern recognition and machine learning. Springer
New York:, 2006.
[30] B. H. Bloom, “Space/time trade-offs in hash coding with allowable
errors,” Commun. ACM, vol. 13, no. 7, pp. 422–426, 1970.
[31] T. Johnson and D. Shasha, “2Q: A Low Overhead High Performance
Buffer Management Replacement Algorithm,” in Proceedings of the
20th International Conference on Very Large Data Bases. Morgan
Kaufmann Publishers Inc. San Francisco, CA, USA, 1994, pp. 439–
450.

V. C ONCLUSION AND F UTURE W ORK
This paper presents a mobile cloud-based secure web
referral service to counter web-based MITM and phishing
attacks on the mobile devices. In the central of the system,
SSE serves as the foundation of the presented secure web
referral framework and involves minimum interventions
of humans for security decisions. SSE Phishing Filter
produces low false positives and false negatives. In the
future, SSE can be extended to counter other web attacks,
such as Cross-site Scripting (XSS) attacks.
ACKNOWLEDGEMENT
This work is supported by Ofﬁce of Naval Research
(ONR) Young Investigator Program (YIP) award.
R EFERENCES
[1] B. Hayes, “Cloud computing,” Commun. ACM, vol. 51, no. 7, pp.
9–11, 2008.
[2] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach,
and T. Berners-Lee, “Hypertext transfer protocol – http/1.1,” 1999.
[3] M. Moxie, “Sslstrip software,” http://www.thoughtcrime.org/
software/sslstrip, 2009.
[4] A. Freier, P. Karlton, and P. Kocher, “The SSL protocol version 3.0,”
1996.
[5] S. Whalen, “An introduction to arp spooﬁng,” Node99 [Online
Document], April, 2001.
[6] D. Sax, “DNS spooﬁng (malicious cache poisoning),” URL:
http://www.sans.org/rr/ﬁrewall/DNS spoof.php November, vol. 12,
2000.
[7] Dijiang Huang et. al., “Mobile cloud computing,” http://mobicloud.
asu.edu, 2010.
[8] D. Huang, “MobiCloud: A Secure Mobile Cloud Computing Platform,” E-Letter of Multimedia Communications Technical Committee
(MMTC), IEEE Communications Society (invited paper), 2011.
[9] D. Huang, Z. Zhou, L. Xu, T. Xing, and Y. Zhong, “Secure data
processing framework for mobile cloud computing,” in Computer
Communications Workshops (INFOCOM WKSHPS), 2011 IEEE
Conference on, april 2011, pp. 614 –618.
[10] H. Xia and J. Brustoloni, “Hardening web browsers against man-inthe-middle and eavesdropping attacks,” in Proceedings of the 14th
international conference on World Wide Web. ACM New York, NY,
USA, 2005, pp. 489–498.
[11] C. Jackson and A. Barth, “ForceHTTPS: Protecting high-security
web sites from network attacks,” 2008.
[12] N. Chou, R. Ledesma, Y. Teraguchi, D. Boneh, and J. Mitchell,
“Client-side defense against web-based identity theft,” in Proceedings of the 11th Annual Network and Distributed System Security
Symposium (NDSS04), San Diego. Citeseer, 2005.

593
592

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

Establishing Secure Virtual Trust Routing and
Provisioning Domains for Future Internet
Dijiang Huang1 , Shingo Ata2 , and Deep Medhi3
1 Arizona State University, USA
2 Osaka City University, Japan
3 University of Missouri–Kansas City, USA

Abstract—Secure virtualization is the enabling technique to
protect both network providers and user services. Particularly,
secure routing in the virtualized service domains is one of the key
research areas that have not been explored in literature. In this
paper, we present a new secure routing framework to address
both network-centric and user-centric networking service models
for the future Internet. We aim to provide a flexible network
routing framework that has the capability to route traffic with
different service requirements and constraints. In other words, it
could be highly desirable that two types of network traffic should
be isolated either physically or logically and trustworthy services
should be avoided to share the bandwidth with normal traffic
that may be prone to security attacks. To achieve this capability,
we present how to establish a virtual trust routing framework
to handle both network-centric routing and user-centric routing
simultaneously by using attribute-based cryptography that can
provide information-level protection for virtual routing domain
isolation. Our performance evaluation on prioritized services
through virtual routing domains and cryptography performance
analysis demonstrates the viability of the proposed solution.
Index Terms—Secure routing, virtualization, attribute based
cryptography.

I. I NTRODUCTION
As growth of the Internet infrastructure spreads worldwide,
the current Internet has many problems regarding trust communication. For example, there is no fundamental protection
mechanism against traffic from untrusted nodes such as malicious traffic, spams, attacks, and scans. Also, end users always
have to worry about a risk for drain on information to untrusted
parties. These facts make the general public think that the
Internet is unsafe. Thus, trustworthiness is a fundamental
research issue to be solved for the future Internet.
One of the major pitfalls of current Internet trustworthiness
is that the routing infrastructure has limited built-in capabilities
to address trustworthiness in both the Internet control plane
and the data plane. Current Internet routing is designed to
maintain a single packet forwarding table for information
flows for all sources and destinations. This all-depends-on-one
routing nature has two major inherited drawbacks to respond
to attacks.
The first drawback is that the current paradigm makes the
network filtering function complicated and prone to errors. For
example, to protect routing information at the control plane,
IPsec tunnels between routers can be set up to communicate
trusted routing information among routers, i.e., a single routing
table is established for all-pair traffic. In other words, there is

no way to isolate the routing information for trusted data traffic
from others. Of course, in the current Internet technology, data
traffic from/to an untrusted IP prefix can be blocked by using
packet filters configured in routers, to differentiate traffic from
various sources and destinations, in the data plane. However,
these filters are local functions, i.e., drop/forward packets can
be performed only based on the local rules at routers without
global traffic engineering capabilities. They can be deployed
before and/or after the routing function in the router, which
may be very complicated and unable to provide prioritized
traffic management at the network level. This nature makes
it difficult to provide protection for critical services when the
network is under stress.
The second drawback of the current Internet routing is
that it is incapable of protecting user traffic for new userdriven service models. Current Internet networking services
are network-centric, in which network routing treats packets
equally without considering their content. However, in future
networks, networking functions, including routing, need to
be designed as user-centric in such a way that users have
the ability to manage and/or control their packets according
to their service requirements. The current cloud computing
based services are good examples to demonstrate this trend.
Users can request network resources to build their own service
domains with fully controlled networking functions – ideally,
a user-centric routing paradigm is preferable for this purpose.
This is definitely true if we consider the trustworthiness in
the function of network routing because trustworthiness is a
typical user-oriented metric, i.e., users may require different
levels of trustworthiness though traffic flows have the same
source and destination nodes. Thus, both user-centric network
routing and network-centric routing would need to co-exist in
the future Internet.
To address the above described drawbacks, major research
challenges are 1) how to construct a trustworthy routing
framework at the control plane and 2) how to effectively
address both user-centric routing and network-centric routing
in order to satisfy different end-users’ service level agreements
in the data plane. To address this challenge, a trustworthy
routing framework is needed. For example, network routing
is planned to have the capability to route traffic with different
service requirements and constraints. Trustable services should
be avoided to share bandwidth with normal traffic that may be
prone to security attacks. Secondly, we consider the mechanism to address security requirements for both network-centric

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

routing and user-centric routing simultaneously. The traditional approach is to use overlay (or peer-to-peer) networks
to satisfy the users’ requirements. However, this approach
has three main drawbacks: (i) The failure (or attacks) at
the network layer usually create significant impact at the
overlay networks, (ii) The overlay networks usually have a
good chance to share the same link due to the shortest path
routing at the network layer due to shared risk link groups,
and (iii) The trustworthiness of peers is not secured, i.e.,
there is no way to validate whether all peers in the overlay
networks are trustable or not. Thus, an attack on the underlying
network usually will impact more than one overlay network. In
addition, different network service domains may have different
trustworthy requirements; thus, some form of traffic regulation
may be warranted based on the level of trustworthiness.
This paper positions the current research status and proposes
a new future Internet routing infrastructure. An important
fundamental question we address is: can we build an integrated
routing and trustworthy framework at the network layer level
for the future Internet to satisfy both network-centric and
user-centric routing requirements? This means that we want
to consider a built-in robust approach to trustworthiness at
the network layer that is integrated with routing, rather than
trustworthiness being ad hoc or an afterthought. Toward this
end, we present VTRouPD (Virtual Trust Routing and Provisioning Domain) and µVTRouPD, where the former takes the
network-centric view while the latter takes the user-centric
view in our overall approach. To this end, we propose a
basic notion in future Internet routing: “To architect in a
way that virtualizes the network so that different services
are clustered into different virtual, adaptive partitions for
different services according to their trustworthy requirements”.
In considering this notion, it is important to note that a service
offering can span the entire spectrum from complete sharing to
physically dedicated partitioning. Moreover, different services
may be partially overlapped or dependent. Furthermore, even
without a shared environment, prioritization is also possible,
for example, in packet scheduling for different service classes
with multiple trust levels at a router.
The rest of the paper is arranged as follows: In Section
II, we presented the distinctions between our approach and
previous virtualization solutions. In Section III, we present
the system and models for the virtual trust routing. In Section
IV, we describe the details of each component of the proposed
VTRouPD framework. We present a proof-of-the-concept evaluation in Section V. Finally, in Section VI, we conclude our
work and point out our future research directions.
II. C OMPARISON TO E XISTING V IRTUAL N ETWORKING
M ANAGEMENT A PPROACHES
Several recent researches have shown that the research of
network management in virtualized networking environments
is very active. In [1], the authors presented a programmable
hardware platform to construct virtual data planes, which
focuses on hardware implementation. In [2], the authors presented VROOM (virtual ROuters On the Move), which is a
new network-management primitive that avoids unnecessary

Content-awareness risk management/Intrusion detection and response.
Isolation: resource, information flow, services, software, and application
Mobile routing: provide a reliable and survivable automatic routing platform for future trustworthy
network routing.
Routing Service Provisioning
RSN

RSN

RSN

RSN

NM

NM

NM

NM

Trust
Management
Service (TMS)

VTRouPD i
VTRouPD j
VTRouPD k

Virtualization

Programmable
Routes

Network Router Cloud

Fig. 1.

Resource/
Application
Manger (RAM)

Virtual Trust
Routing and
Provisioning
Domain
(VTRouPD)
Manager

Notations:
RSN: Routing Service Node
Direct link or control
Indirect link or control

VTRouPDs Architecture.

changes to the logical topology by allowing (virtual) routers
to freely move from one physical node to another. The research
presented in [3] focuses on the accountability in the virtualized
hosting environments.
Our presented approach is different from previous approaches in that we focus on building multiple virtualized
routing domains through a two-level virtualization approach:
(i) using logical virtual routers to partition the physical networking environment into multiple virtual private networks,
(ii) using cryptographic methods to further partition a logically virtual network into multiple flow-level virtual routing
environments. Our approach provides a fine-grained virtualization for user-centric networking services, and can respond
to attacks quickly by using cryptographic approaches. In an
earlier work, the basic idea of VTRouPD was introduced
[4]; however, this did not consider µVTRouPD, and more
importantly, the inter-play between the network-centric and
the user-centric considerations.
III. S YSTEM AND M ODELS
Our thesis is to address the following features in this work:
(a) the network needs to operate in a semi-reservation-oriented
mode to allow multiple routing domains to be constructed
according to the trust levels of services and they can coexist
sharing networking resource, (b) trust management needs to
be a built-in factor at the network level to handle security
policy federation and enforcement, and (c) entry points to the
network have the ability to do authorization checks and/or
control traffic when necessary, so that higher trust services
can have priority (under stress). In the following two sections,
we present our system models at the network service level and
information flow level, respectively.
A. Virtual Trust Routing and Provisioning Domain
Our goal is to divide the entire routing domain into multiple
routing/provisioning sub-domains. We refer to such a subdomain as a virtual trust routing and provisioning domain
(VTRouPD). The framework may not need/imply the division
of the administrative domain into VTRouPDs. Every node
that belongs to a particular VTRouPD will have complete

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

routing information of its own VTRouPD, but not others.
Typically, from a systems perspective, traffic management
and network resource management components are necessary
for monitoring and managing a network. For a trustable
environment, there are three additional components involved
as shown in Fig. 1: Trust Management Service (TMS), and
VTRouPD Domain Manager, and Resource and Application
Manager (RAM).
In each VTRouPD, one or multiple Router Instances (RIs)
are used for every Routing Service Node (RSN). A Node
Manager (NM) is responsible for managing the RIs’ loading
and unloading in the RSN. The RAM is the resource manager
directed by the VTRouPD manager and TMS to construct
VTRouPDs. The VTRouPD manager plays the key role in
the new routing framework. TMS is the Trust Authority
(TA) for the system. It handles the cryptographic key and
parameters distribution and revocation. It also provides identity
search and federation services for RSNs belonging to multiple
administrative domains, and policy checking and enforcement
functions to provide a unified trust management system.
B. Fine-grained Routing Domain Isolation
Here, we present a new, secure, extended node/link update
(ENLU) framework by extending a link state routing framework through a secure group communication approach for
enabling network virtualization. This scheme allows dissemination of ENLU messages to be encoded in such a way that
only nodes with the proper key can take advantage of the
encoded information for trustable or prioritized services. We
invoke a many-to-many group communication keying scheme
presented in [5] to virtualize network resources to support
multiple service domains.

Routing
Header

RM1

RM2

ENLUn

RMn

Packet Level (PL): routing
packet or IP packet

IP
ENLU1 ENLU2
Header

Information Level (IL):
(multiple routing metrics (RMs) are encapsulated within
one extended node/link update (ENLU) packet)

Fig. 2.

Granularity of attributes at the packet level and information level.

Our approach considers two preventive cryptographic countermeasures: confidentiality and authentication. These two
countermeasures can provide protection at either the packet
level (PL) or the information level (IL), shown in Fig. 2. If
we assume a routing packet to be a bus filled with a group
of passengers, PL and IL represent the cryptographic countermeasures being provided for the bus and each individual
passenger, respectively.
To deploy the information level confidentiality (ILC), routing information (i.e., metric) is categorized by multiple groups.
By carefully assigning group keys to nodes, we can partition
network resources into multiple routing domains. For example,
consider a node with several outgoing links; it can encrypt
routing metrics (RMs) for some links using one key and

encrypt RMs for other links using another key. Thus, only
nodes that have the correct key can decrypt the routing
information. This strategy can also be applied to a single
link, i.e., a node can partition the bandwidth of a link into
multiple portions and create/encrypt an RM for each portion.
This approach has several benefits:
• It prevents outsiders’ sniffing attacks (we assume that the
crypto key length is long enough to prevent brute force
attack within a maintenance cycle, i.e., periodic updating
window of the crypto keys).
• It mitigates outsiders’ traffic-analysis attacks: Since extended node/link attributes are encrypted and a node may
or may not possess the decrypting key, nodes can maintain different network topology information and shortest
path tree or other provisioned paths. Thus, the data flow
may not follow the same shortest path that can prevent
attackers from deriving the correct network topology or
traffic allocation pattern.
• An insider has limited information of the network that can
mitigate routing analysis and deliberate exposure attacks.
The above advantages are ideal for our encrypted, extended node/link update (ENLU) approach since it allows
us to disseminate ENLU messages in a way that is meant
only for a subgroup of nodes. In this paper, for simplicity,
we demonstrate our approach by initially considering two
services, normal services and trustable services, with the important requirement that trustable services encompass normal
services as well. This can be accomplished by defining two
subgroups for extended node/link state dissemination using the
many-to-many secure group communication scheme we have
developed. Note that although there are only two subgroups
in this case, which are mapped to two categories of services,
the formations of subgroups can be changed frequently with
respect to the use of different subgroup keys. This means that
if a network wants to define multiple trustable service levels
dynamically, our approach allows it with the added advantage
that a node can be in different prioritized groups and yet, it
cannot become an undesirable node (that is to move to a higher
prioritized service class).
IV. E STABLISH V IRTUAL T RUST ROUTING AND
P ROVISIONING D OMAINS
We now present the enabling techniques to establish
VTRouPDs (virtual trust routing and provisioning domains)
that uses a systematic approach to build VTRouPDs. We focus
our description in the following areas: (a) the establishment
of two levels of VTRouPDs, (b) cryptography-based solution
to create fine-grained information-flow level VTRouPDs, and
(c) the trust management in VTRouPDs.
A. The Establishment of VTRouPDs
The VTRouPDs architecture is presented in Fig. 1. To
establish VTRouPDs, we require network routers to be programmable, i.e., we can create multiple virtual routers (VR)
on the same physical router and each VR is responsible for a
particular VTRouPD. We present two levels of approaches to
deploy the VRs. A the first level, we virtualize independent

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

router virtual images, where each VR has its own protocol
stack and independent IP addresses associated with virtualized
interfaces. In this way, traffic can be differentiated at the
IP layer through routing functions. For example, the routing
table in each VR can mark who the next hop virtual router
is. This approach, however, faces certain roadblocks. First,
the number of VTRouPDs on each router is restricted by
the router’s hardware configuration. This restriction usually
makes it impractical to support a large number of VRs
running on the same router that further restricts the number
of supported VTRouPDs. Second, it is difficult to allow interVTRouPDs traffic when services provided by two VTRouPDs
are highly correlated and may need merging partial traffic from
two VTRouPDs. Thus, the approach using the entire routing
function virtualization is only appropriate for network-centric
virtualization.
To address the restriction of network-centric routing virtualization, we introduce also a fine-grained routing virtualization
at the second level that can take care of users’ service level
demands. To this end, we present a complementary concept,
virtual trust routing and provisioning sub-domain (noted as
µVTRouPD), is introduced. A VTRouPD may contain multiple µVTRouPDs. In comparison to the VTRouPDs, the
boundary of µVTRouPDs is not established through virtualizing router functions; instead, we consider virtualization
of µVTRouPDs through a set of techniques: (a) We use
cryptographic packet marking techniques to allow each VR
to recognize the traffic flows for different µVTRouPDs, (b)
We invoke efficient secure group communication solutions to
isolate traffic flows that belong to different µVTRouPDs. This
approach provides us a fine-grained traffic management and
filtering capability to identify malicious traffic and reduce the
impact to other services when the malicious traffic flows are
blocked. Moreover, through secure group-based communication, we can further merge or diverge traffic belonging to
different µVTRouPDs through super- or sub-group communications. (c) We use an efficient security data access control
solution that provides trust party verification, traffic access
control, and data privacy protection for µVTRouPDs. This
capability allows us to provide versatile user-centric network
routing services with assured data access policy enforcement and privacy protection. The first level virtualization is
straightforward. In the following subsection, we focus on our
description on the second level virtualization, and the enabling
techniques that will be explored to achieve the above described
research.

(b) security and privacy policy enforcement for accessing networking information and data within a µVTRouPD, and data
sharing among multiple µVTRouPDs. We use an attributebased data access control mechanism to achieve the described
group-based communication system.
S

Data
Encrypting Key

AND

Secret Sharing
Threshold Gates

S’
AND

Private Key
Components
Attributes

Fig. 3.

S’’
OR

S1
S1
S1

S2
S2
S2

A1

A2

S3

S4
S4
S3

A3

A4

u1
u2
u3

Attribute-based Encryption.

In Fig. 3, we present an illustration using attributed-based
encryption (ABE) [6] for data encryption and decryption. In
this example, attributes A1 − A4 are arranged as leaf nodes
of the attribute tree, where each attribute can have multiple
secret components for different users. We must note that users
can share an attribute; however, the corresponding private key
components for that attribute are different, and are represented
by different colors. Thus, u1 has private key components
{red : S1, S2, S3, S4}, u2 has private key components
{green : S1, S2, S4}, and u3 has private key components
{blue : S1, S2, S3}. The internal nodes of the attribute tree
are logical gates, such as AN D, OR that are implemented
using the threshold secret sharing scheme [7]. The secret
S can be derived from S  and S  using the secret sharing
scheme. At the bottom level, the encryption is performed using
similar construction of identity-based encryption (IBE) [8].
When the message is decrypted, the decrypter must satisfy
the AN D gate, the decrypter must have all the secrets under
it to reconstruct the higher level secret; to satisfy the OR gate,
the decrypter is only required to have one of the secrets under
it to reconstruct the higher level secret. In this case, based on
the pre-distributed secrets, u1 − u3 can decrypt the secret S
and thus they can access the data encrypted by using the DEK
S.

B. Cryptography-based approaches to create fine-grained
µVTRouPDs
Here, we focus on providing information flow isolation
for multiple µVTRouPDs. Users belonging to the same
µVTRouPDs can “see” the data and the network. A router
may belong to multiple µVTRouPDs. Thus, an efficient encryption/decryption scheme must be provided. There are two
main issues: (a) establishment of secure group-based communication among µVTRouPDs members and group membership
maintenance such as when group members join and leave, and

Fig. 4.

An example of ABE for secure group communication.

To present how to use the ABE scheme in secure group communication, we present a simple example consisting of 8 group
members in Fig. 4, where each group member (i.e., a router)
is associated with a unique binary ID: b0 b1 . . . bn−2 bn−1 ,
where n = log N . The cryptography construction is based

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

on our recent work [9]. We can use a logic literal, called bitassignment, Bi and Bi to indicate the binary value at position
i in an ID. Bi indicates the i’th bit of an ID is 1; B i indicates
the i’th bit of an ID is 0. For a group with N group members,
the length of an ID is n = log N and the total number of bitassignments is 2n; that is, two binary values are mapped to
one bit position (one for value 0 and one for value 1). We call
the set of all possible bit-assignments to be Universe U that
contains 2n bit-assignments. A group member u is uniquely
identified by the set of bit-assignments Su associated with
u’s ID. Also, multiple group members may have a common
subset of bit-assignments. For example, in Fig. 4, a GM u1 ’s
ID is 000 and a GM u2 ’s ID is 001,
 Su1 = {B 0 , B 1 , B 2 }
and Su2 = {B 0 , B 1 , B2 } and Su1 Su2 = {B 0 , B 1 }. In a
VTRouPD, the group member’s ID (i.e., the router’s ID) can
be derived from a hash operation on his unique identifier such
as its IP address. Each bit in the ID can be mapped to a
predefined attribute (can be a random number), and the user
can derive corresponding private key components that mapped
to each attribute from a trusted authority.
To form an arbitrary communication group (i.e.,
µVTRouPD), suppose a subgroup with L members, a
group member can use the Boolean membership functions
M (B0 , B1 , . . . , Bn−2 , Bn−1 ), which is in the form of
Sum-of-Product Expression (SOPE), can determine the
membership of the subgroup. That is, only if group member
u belongs to the subgroup, M (IDu ) = 1. Formally, the
following properties of membership functions hold:

0 iff u ∈ G \ L,
u u
u
u
M (b0 , b1 , . . . , bn−2 , bn−1 ) =
1 iff u ∈ L.
For example, if the subgroup L = {000, 001, 011, 111},
then M = B 0 B 1 B 2 + B 0 B 1 B2 + B 0 B1 B2 + B0 B1 B2 .
Using this approach, we can freely construct a super group
or subgroups without the key agreement phase, which significantly reduces communication delay. Moreover, this solution
achieves the optimal solution that both the communication
overhead and storage overhead are O(log N ) in comparison
to existing group communication keying schemes.

of the destination VTRouPD has sufficient trust level However,
the trust level is not an absolute value, but a relative (human
dependent) value. For example, when two clients communicate
with the same server through two different µVTRouPDs, and
their trust levels for the server in their µVTRouPDs may be
different. The node is required to send the data through an
appropriate VTRouPD according to its trust level that needs
to be satisfied.
The trust level of a µVTRouPD is also highly related to the
privacy requirements, i.e., what types of private information
should be contained within a µVTRouPD or shared among
multiple µVTRouPDs? To regulate the trust management
among multiple µVTRouPDs, we can build the following two
levels of mappings:
• Mapping between the privacy sensitivity of the
µVTRouPD information and corresponding trust levels.
• Mapping trust levels among multiple administrative domains.
Another trust management issue is how to initiate trust.
To address the trust initialization issue, a reputation based
approach can be used. As shown in Fig. 1, the trust management service (TMS) can collect feedback from the system
to rank the trust of a router, µVTRouPD, VTRouPD, and
the entire domain of an Internet service provider. Then, TMS
can calculate the trust ranking, and provide a recommended
trust level for the corresponding party as the initial trust level.
The trust level can be measured using the following example
metrics:
• Percentage of good traffic transited;
• Reliability of the routing system;
• Trust levels of ingress and egress neighboring domains.
V. P ERFORMANCE E VALUATIONS
In this section, we first present a prototyping evaluation
when constructing two prioritized network routing domains
based on our proposed solution. Then we present the cryptography performance evaluation.
A. Evaluations of Prioritized VTRouPDs

C. Trust Management in VTRouPDs
Next, consider trust management in VTRouPDs. We first
address how to negotiate trust when the virtual routing spans
multiple administrative domains, and then we describe the
monitoring and attack response system of a VTRouPD.
1) Trust Management among Multiple Administrative Domains: Usually, the trust management is independently managed in different network service administrative domains.
Thus, different administrative domains can have different
compositions of VTRouPDs. To federate the trust management among VTRouPDs created by different administrative
domains, we need to construct a trust negotiation system to
address the incurred inconsistency and incompatibility issues.
Another issue due to multiple administrative domains is
that a µVTRouPD can belong to multiple VTRouPDs with
different trust levels. Before sending data across multiple
VTRouPDs, the system needs to check whether the trust level

An important question is: can we quantify the benefit
in a network that trustable services get allocated prioritized
provisioning in a network virtualization framework based on
secure encryption? To be able to quantify such a benefit, we
have conducted a preliminary simulation.
In our simulation model, we have incorporated protected
and dynamic network virtualization by allowing for different
service classes, such as a trustable service class over the
normal service class. In our preliminary prototype, we have
implemented a rudimentary version of the extended node-link
update (ENLU) message passing for different service classes.
In our current implementation, virtualization is performed on
a per link basis; that is, to simulate the affect, a user can
decide which links to be considered for virtualization. If this
is not considered for virtualization, then all services share the
link equally. For activating network virtualization, attributes
values of a link are encoded differently for the prioritized

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

service on a link basis compared to the normal services;
this is done so that ENLU messages are recorded by nodes
as appropriate for different services in computing routes and
service provisioning.
0.4

Priority Traffic
Normal Traffic

0.35
Service Blocking

0.3
0.25
0.2
0.15
0.1
0.05
0
0

1

2

3

4

5

6

7

8

9

Number of Prioritized Links

Fig. 5.

Service blocking ratio for normal service and prioritized service.

For our preliminary study, we have considered an 8-node
example network. Traffic load was considered in such a way
that the network is in a stressed situation where the prioritized
service requires better performance than the normal service
while both have the same amount of offered load. In Fig. 5, we
plot service blocking performance for prioritized and normal
services. At the left end is the case when all links in the
network are considered as fully shared by both service classes;
thus, both service classes naturally have the same performance.
Then we increase the number of links virtualized (one at
time), and plot service blocking for both classes. Thus, using
our simulation model, we can observe that service blocking
performance is significantly lower for the prioritized class
over the normal service class as more and more links are
virtualized. This result confirms our promise of using virtual
routing domains to provide prioritized services.
B. Cryptography Performance Evaluation
Cryptography plays a key role in our presented new secure
routing system. We first evaluate the delay performance with
a given number of attributes vs. the number of routers in the
system, which is shown in Fig. 6.

Number of
routers

Fig. 6.

Encryption and decryption delay overhead.

Fig. 6 shows the encryption and decryption time with an
increased number of attributes. The majority of time consumed
in both encryption and decryption protocol is the result of two
point multiplication (about 1.52ms) and one pairing operation
(about 7.3ms) in the ABE scheme. It can be seen from the
figure that the run time of encryption and decryption operations increases with the increase in the number of attributes,
in which the introduced delay is not significant.

VI. D ISCUSSION AND F UTURE W ORK
In this work, we present a routing perspective for a secure
routing network architecture in which services with differences
in trustworthiness, guarantees and priorities can co-exist in
a virtualized environment. More importantly, we present a
general framework for secure and resilient routing that can be
conducive to providing secure traffic engineering in the future
Internet. Our approach is forward thinking in that instead
of starting with what we require or assume in the network
architecture, we start with the need for the service requirement
for different levels of trustworthiness in a prioritized environment and work backward to identify what are the different
components desirable in the network architecture to support
this service paradigm. Implicit in our approach is the basic
understanding that we do not necessarily assume that the
components are identified to be efficient nor do we claim that
all components or solutions have been identified; at times,
we expect that some problems identified will remain open,
research problems. Thus, an important goal of this paper is to
address the fundamental issues in order to arrive at a better
understanding of this entire framework.
In future work, we will implement our solution through an
education/research platform, such as using NetFPGA [10], and
deploy our approach in our GpENI testbed environment [11].
ACKNOWLEDGEMENT
The presented work is supported by US NSF grants CNS1029562 and CNS-1029546, and Japan NICT grant program
“Early-concept Grants for Exploratory Research on Newgeneration Network”.
R EFERENCES
[1] M. Anwer and N. Feamster, “Building a fast, virtualized data plane with
programmable hardware,” in Proceedings of the 1st ACM workshop on
Virtualized infrastructure systems and architectures. ACM, 2009, pp.
1–8.
[2] Y. Wang, E. Keller, B. Biskeborn, J. van der Merwe, and J. Rexford,
“Virtual routers on the move: live router migration as a networkmanagement primitive,” ACM SIGCOMM Computer Communication
Review, vol. 38, no. 4, pp. 231–242, 2008.
[3] E. Keller, R. Lee, and J. Rexford, “Accountability in hosted virtual
networks,” in Proceedings of the 1st ACM workshop on Virtualized
infrastructure systems and architectures. ACM, 2009, pp. 29–36.
[4] D. Medhi and D. Huang, “Secure and resilient routing: Building blocks
for resilient network architectures,” in Information Assurance: Dependability and Security in Networked Systems. Elsevier, 2008, pp. 417–457,
Y. Qian, D. Tipper, P. Krishnamurthy, and J. Joshi (Eds.).
[5] D. Huang and D. Medhi, “A Key-chain Based Keying Scheme For
Many-to-Many Secure Group Communication,” ACM Transactions on
Information and System Security, vol. 7, no. 4, pp. 523 – 552, 2004.
[6] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-Policy AttributeBased Encryption,” Proceedings of the 28th IEEE Symposium on Security and Privacy (Oakland), 2007.
[7] A. Shamir, “How to Share a Secret,” Communications of the ACM,
vol. 22, no. 11, pp. 612–613, 1979.
[8] D. Boneh and M. Franklin, “Identity-based encryption from the weil
pairing,” SIAM Journal of Computing, vol. 32, no. 2, pp. 586–615, 2003.
[9] Z. Zhou and D. Huang, “An Optimal Key Distribution Scheme for
Multicast Group Communication,” in IEEE Infocom (mini coference),
2010.
[10] “NetFPGA.” [Online]. Available: http://www.netfpga.org/
[11] “GpENI: Great Plains Environment for Network Innovation.” [Online].
Available: http://www.GpENI.net

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the ICC 2008 proceedings.

SRK: A Distributed RFID Data Access Control Mechanism
Dijiang Huang

Zhibin Zhou
Abstract— Extremely limited in computational and energy
capability, RFID tags, especially passive tags, can hardly authenticate the scanning readers. Thus, information leakage for RFID
tags is one of the most challenging open problems holding back
users’ conﬁdence in adopting RFID technologies. To solve this
problem, we propose Smart RFID Keeper (SRK) – a distributed,
off-tag RFID data access control Mechanism, which is installed
in RFID enabled environments to regulate RFID scanning.
To solve the information leakage threat, SRK is designed to
(1) authenticate the user; (2) detect and counter unauthorized
accesses to RFID tags and (3) enforce ﬁne grained access policy.

I. I NTRODUCTION
RFID tags, as the successor of widely used optical bar code,
are tiny, wireless microchips that help identify objects and
people. It can be expected that RFID tags will proliferate
into billions and eventually into trillions in the near future.
Information leakage of RFID tags has been identiﬁed as a
major problem holding back users’ conﬁdence in adopting
RFID technologies. This problem is critical especially for
passive RFIDs that have limited computational capability and
lack of cryptographic protections. Possessing a few thousands
of gates, passive RFID tags energize themselves by absorbing
radio wave emitted from readers, and they usually do not
have access control abilities. Since a tag will broadcast its
stored information without authenticating the readers, auxiliary
policy enforcement and access control mechanisms are needed
to secure the system.
Many novel research works have been proposed to solve
the information leakage problem by integrating light-weighted
cryptographic algorithms into the tag architecture and using
Tag-Reader authentication protocols to control the access to
RFID tags. We call these solutions as on-tag access control
mechanism, and we argue that on-tag solutions have the following drawbacks: (1) complicating the architecture of RFID
tags violates the minimalist design principle and increase the
cost of individual tags; (2) light-weight cryptographic algorithms and protocols are vulnerable to sophisticated attacks;
(3) scalability of complicated RFID architectures is not clear.
On the other hand, off-tag solutions [6], [19], [14] use devices
to regulate the access of readers to RFID tags and require little
change to the architecture of RFID tags. Thus, universally used
passive RFID tags such as EPC tags can be protected by these
solutions.
Our contribution in this paper is proposing SRK (Fig. 1),
a distributed solution to the information leakage issues in
RFID-deployed environments. A Room Watch Dog (RWD),
which is a device installed in every protected room, consists
of an authentication module and an access control module. The
authentication module authenticates the users’ identity without
an on-line authentication server. The access control module is
to detect and control unauthorized tag-reading operations. If

a user got authenticated by authentication module, he/she is
authorized to read the tags; otherwise, his/her reading operation will be blocked by access control module. Furthermore,
with an (optional) RFID Keeper Policy Server (RKPS), ﬁne
grained access control can be enforced. SRK provides three
security services: (1) user identity authentication service: a
user should be authenticated by RWD and authenticated users
are authorized to perform read operations; (2) data access
control service: unauthorized read operations to RFID tags are
blocked by RWD, and (3) (optional) access policy enforcement
service: ﬁne grained policy can be enforced to the access of
RFID tags with help of RKPS. We also provide performance
and security analysis of SRK in this paper.
Access Policy Enforcement
Service

Services

Data Access Control
Service
User Identity
Authentication Service

Room
Watch
Dog

Fig. 1.

Access
Control
Module

Authentica
tion
Module

Policy
Database

RFID
Keeper
Policy
Server

The system architecture of the SRK.

The rest of paper is arranged as follows: in section II, we
present related works; in section III, we show the system
model of SRK; then we describe three main services provided
by RFID Keeper in sections IV, V and VI; in section VII, we
evaluate the security performance of the proposed solutions;
ﬁnally, we conclude our work in section VIII.
II. R ELATED W ORKS
Researchers have recognized privacy problems with RFID
systems for a few years [5], [10], [15], [7]. Due to the page
limitations, we just mention some of the newest works to the
best of our knowledge. We can classify these solutions into
on-tag solutions [17], [8] and off-tag solutions [6], [19], [14].
In [16], the authors presented various collision-resolution
protocols for multi-access communications between RFID tags
and readers. Access control through blocking techniques has
been proposed in [6] based on multi-access control protocols.
However, the research in [13] pointed out that the straight
forward implementation of RFID blocking is vulnerable to
the Differential Signal Analysis (DSA). In [19] we proposed
RFID keeper to address the access control problems in RFID,
which blocking the unauthorized reading based on various
RFID singulation protocols. We note that researchers in [14]
independently proposed a similar system to our SRK.

978-1-4244-2075-9/08/$25.00 ©2008 IEEE

2854

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the ICC 2008 proceedings.

III. S YSTEM M ODELS
In this section, we present preliminaries of Pairing, network
model and attack model that support the proposed SRK
architecture.
Preliminaries of Pairing
Pairing is a bilinear map function e in the following form:
e : G1 × G1 → G2 ,

(1)

where G1 and G2 are groups with large prime order q . Pairing
has the following properties:
• Bilinearity:
e(aP, bQ) = e(P, Q)ab ,

∀P, Q ∈ G1 , ∀a, b ∈ Z∗q . (2)

Nondegeneracy: e(P, Q) does not always equal to 1.
Computability: There exists efﬁcient algorithms to compute the Pairing.
Discrete Logarithm Problem (DLP) is hard for G1 and G2 1 .
Moreover,
Network Model
The network model of SRK is illustrated in Fig. 2.
•
•

RFID Keeper Policy Server

Trusted Authority

Secured Channel

ion

Room Watch
Dog

Block

Au
the
nt
1:

:Au
the
nt

Ste
p

Ste
p1

ReaderS
tep2
:R

Room Watch
Dog

ica
t

ica
tio
n

Room Watch
Dog

Reader
Ste
p

ead

Tags on the
Instrument
Authorized
User Room 1

Reader
Rea
Auth d with
oriz out
atio
n

2:
Re
ad

Tags
Authorized
User

Patient
Room 2

Unauthorized
User

well guarded by TA. The TA is responsible to generate the
private key corresponding to speciﬁc ID of users and RWD.
For simplicity, we denote user (i.e. a staff reading the RFID)
with capitalized letter. An ID of user A IDA is a structure of
employment information of A, and private key sA is computed
as sA = g · H1 (IDA ). Since TA is signiﬁcantly critical, TA
should be protected and isolated to the public network.
Attack Model
We assume that minimalist design of RFID tags, i.e. the
passive RFID tags without cryptographic functions, are used in
our environment. The attackers, i.e. attack source, can be either
insider or outsiders who are not authorized to collect data
from RFID tags. The attack method includes (1) unintentional
mis-operations of insiders, e.g. a nurse fails to follow the
required authentication process before her scanning RFID
tags attached to patients; (2) intentional, unauthorized reading
RFID tags from insiders or outsiders, e.g. a malicious attacker
tries to harvest patients’ healthcare records held in the RFID
tags. We assume that the attackers cannot compromise the
AS and RKPS. We also assume that the attackers do not
have unbounded computational capability to break DLP [11]
problems.
It should be noted that the communication between passive
tags and readers are in plain text and thus vulnerable to passive
eavesdropping attacks. How to prevent passive eavesdropping
attacks is a still open problem in this work. In the [4], the
authors argue that , due to limitation of RFID tags response
distance, the eavesdropping attackers need to get physical
proximity to RFID tags, which is a sporadic activity in general
RFID working environments.

Room 3

IV. U SER I DENTITY AUTHENTICATION S ERVICE
Fig. 2.

Network model for the RFID Keeper.

A Room Watch Dog is installed in each protected room to
authenticate the identity of users and control the data access
to the tags. The authentication module of RWD independently
(without on-line authentication server) authenticates the users
following a challenge-response based authentication protocol
(Section IV for more details). The access control module can
detect and blocking unauthorized scanning of RFIDs (Section
V for more details).
The RFID Keeper Policy Server is an optional component to
provide ﬁne grained access control policy along with RWD.
We assume that the communication between the RWD and
RKPS cannot be compromised by attackers.
Prior to the setup of network, a Trusted Authority (TA)
ﬁrst determines the Pairing parameters {
e, G1 , G2 , H1 , H2 }.
H1 and H2 are collision-resistant hash functions: H1 , mapping strings to non-zero elements in G1 and H2 , mapping
arbitrary inputs to ﬁxed-length outputs, e.g. SHA-1. TA also
selects a system-wise master key g ∈ Zq /0. The parameters
{
e, G1 , G2 , H1 , H2 } are preloaded to each device, while g is
1 It is computationally infeasible to extract the integer x ∈ Z∗ = {i|1 ≤
q
i ≤ q − 1}, given P, Q ∈ G1 (respectively, P, Q ∈ G2 ) such that Q = xP
(respectively, Q = P x ).

User Identity Authentication (UIA) service is provided by
the authentication module of a RWD. The RWD and RFID
readers need to be equipped with required cryptographic
functions to follow the protocol. The authentication protocol
consists of three phases, namely Login, Challenge, and Logout. Notations used in the rest of paper are presented in the
following table.
Symbols
ID
Ph
Pw
Req
N
V
K
Ps
Dn
Cr
Bye

Descriptions
Identiﬁcation of user of RWD
Secured hardware card storing users private key
Password only known to user
Scan Purpose and Tag Selection Request
Nonce Number
Validation of Identity
Shared Key between User and RWD
Authentication Passed
Authentication Denied
Challenge Request
Logout Request

Without loss of generality, authentication process between
User A and RWD is shown below, where || denote concatenation.
Login
A → Reader
: IDA , P h, P w, Req

2855

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the ICC 2008 proceedings.

Reader
Reader
Reader
Reader

→ RW D
← RW D
→ RW D
← RW D

: IDA , Req, N1
: IDRW D , N2
: V = H2 (N1 ||N2 ||0||K)
: P s(Dn)

User A starts the protocol by input his/her IDA , password
P w and requested operation Req to the RFID reader. Also, A
may need to insert a secure hardware key, which storing the
A’s private key sA , protected by password of A. Then, reader
sends IDA , Req and a random nonce number N1 to RWD.
Upon receiving the request, RWD replies its ID IDRW D
and another random nonce number N2 . RWD also compute
a master shared key K  = e(H1 (IDA ), sRW D ) as well as
an expected validation of identity V  = H2 (N1 ||N2 ||0||K  ).
Upon reception of reply from RWD, reader calculate the master shared key K = e(H1 (IDRW D ), sA ) and the validation of
identity V = H2 (N1 ||N2 ||0||K). According to equation (2),
if and only if user input the right password, V = V  and we
can have:
K  = e(H1 (IDA ), sRW D )
= e(H1 (IDA ), gH1 (IDRW D ))
= e(H1 (IDA ), H1 (IDRW D ))g
= e(gH1 (IDA ), H1 (IDRW D ))
= e(sA , gH1 (IDRW D )) = K
After a successful three way hand shake, A and RWD
authenticated each other and shared the same master key K.
Using the master key K, A and RWD can derive Γ pairs of
shared session key (Skey) and key index (Kid) as:

Skeyγ = H2 (N1 ||N2 ||2 · γ||K)
(3)
Kidγ = H2 (N1 ||N2 ||2 · γ + 1||K)
After the authentication procedure, RWD needs to challenge
the users periodically to prevent session hijacking attacks. The
challenge process is as follows:
Challenge
RW D ← Reader
Reader → RW D

: Cr, Kidi , N3 0 ≤ i ≤ γ
: H2 (Skeyi ||N3 )

After the user extracts data from the tags, she/he needs to
go through logout process that gracefully closes the communication session.
Logout
A → Reader
: Bye
Reader → RW D : Bye, Kidi , N4 , H2 (Skeyi ||N4 )
Reader ← RW D : Bye
We brieﬂy analyze the security of this protocol here.
•

•

If the attacker does not know the private key gH1 (IDA ),
the probability that attacker can derive K is 1/p, where p
is the group size of G1 and G2 . In practice, p is supposed
to be large prime numbers (larger than 160 bits), so we
can see that 1/p is negligible.
If the attacker compromise one or more private key
gH1 (IDA ), the probability that attacker can compromise the system-wise master key is equivalent to the

probability that attacker break DL problems in G1 2 or
G2 3 According to our assumption in attack model, this
probability is negligible.
V. DATA ACCESS C ONTROL S ERVICE
In our presented authentication protocol in section IV, the
readers have to be authenticated by RWD before accessing the
information. Otherwise, any reading activity without being authenticated should be blocked. The data access control service
protects information stored in tags from unauthorized accesses
by (1) detecting unauthorized access to RFID tags and (2)
injecting interference into wireless communication channels.
The injected inference signals will prevent unauthorized users
from correctly identifying the responding RFID tags.
The basic components and functions are presented in the
following table:
Components
Intrusion Detector
RFID Simulator Group
Signal Modulation Randomizer

Functions
No Reading Command()
Randomly Choose Simulator Subset();
Send Noise()
Randomly Modulate Signal()

In our previous work [19], we described how to block
various RFID multi-access protocols. Since most of multiaccess protocols are based on TDMA, we only consider
the reader driven TDMA Tag multi-access protocols in this
paper. In these protocols, the RFID readers initiate the reading
process with a protocol dependent read command and reader
regulate the process of singulation interrogation. Thus, it is
easy to detect the readers’ access to RFID tags. The data access
control contains an intrusion detector that can detect read
operations speciﬁed in multi-access protocols. For example,
most multi-access protocols require the reader to send a read
command to a tag ﬁrst. If an RWD detects an unauthorized
read command, it will send out blocking signals.
Using TDMA-based access control protocols, a reader can
only communicate with one tag at a time. Thus, if multiple
tags response to a reader simultaneously, the access fails.
To perform blocking, RWD randomly chooses a group of
RFID Simulators. The selected RFID Simulators simulate
the RFID tags’ signal and perform blocking functions based
on speciﬁc multi-access control protocols. In addition, the
Signal Modulation Randomizer (SMR) changes the strength of
simulators’ signals and introduces randomly generated noises
to the signal sent by the RFID Simulators. The signal strength
and signal to noise ratio keep varying, and thus, the DSA [13]
attackers cannot ﬁlter out blocking signals.
The tree search method [2] can be divided into two classes:
(i) query tree algorithm [9], and (ii) collision set tree algorithm
[3]. The query tree algorithm consists of several rounds of
queries and responses. In each round, the reader asks tags
whether their serial numbers contain a certain preﬁx B. Then,
the tags compare the preﬁx B with their serial numbers. If a tag
has the queried preﬁx, it replies with the B1 or B0, where 1 or
2 extract
3 extract

G1 .

g given gH1 (IDA ) and H1 (IDA ).
g given e(A, B)g and e(A, B) where A and B are members in

2856

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the ICC 2008 proceedings.

0 is the bit in its serial number next to the preﬁx. If only one
tag replies, this tag is identiﬁed since no collision occurred;
otherwise, the reader will add a bit to the preﬁx and continue
its queries. In [6], the authors proposed a blocking approach
by replying both B1 and B0 to block the reader. Similarly,
in our approach, RWD randomly chooses a group of RFID
Simulators and transmits randomly modulated responses, i.e.,
B1 and B0 to the reader. In RFID GEN2 standard, each RFID
tag contains a unique 92-bit serial number and the size of
entire possible tag serial number will be 292 . This set is very
large, and it is impractical in terms of time and memory for
the readers to query every preﬁx or store the identiﬁed serial
numbers. Therefore, the reader may be expected to stall after
querying thousands of preﬁx.
The collision set tree algorithm splits the group of colliding
tags into A disjoint subsets, where |A| > 1. The subsets get
smaller and smaller until the number of tags within a subset
equals to 1, and each tag will be uniquely identiﬁed. Once
a subset is completely resolved, waiting subsets are resolved
in a ﬁrst-in last-out order. When several tags collide in the
same time split, each tag randomly selects to which subgroup
it should belong. Thus, it is the tag’s responsibility to track
the current position in the stack so that the individual tag
can decide the time to retransmit the signal. To block this
algorithm, in each time split, RWD can randomly select a
group of the RFID Simulators, which transmits randomly
modulated response to the reader. Thus, the subset is never
decreased to 1 and the reader will never identify the real RFID
tags.
VI. ACCESS P OLICY E NFORCEMENT S ERVICE
As we have mentioned before, the RFID Keeper Policy
Server is optional in our design. We propose in this section,
with the help of RKPS, ﬁne grained policy can be enforced to
the access control of RFID readers to RFID tags. Up to now in
this paper, SRK can authenticate the ID of users prevent unauthorized users from reading the tags in the protected rooms.
However, ﬁne grained access control is still not available, that
is, SRK cannot differentiate authenticated users from each
other and grant different access privileges to users in different
roles. However, ﬁne grained access control to RFID tags is
not just interesting Add-Ons in some environments. Consider
the following example:
EXAMPLE-1: In a hospital, patients’ healthy information may
include highly private data such as prescriptions for antidepressants, cancer, long-ago abortions, AIDS or HIV, testing
for the Alzheimer gene, sexual impotency prescriptions. These
private information may be stored in some RFID tags to
facilitate data collecting performed by corresponding nurses
or doctors. Suppose this hospital use same RFID tags to
manage and track the properties (medical equipments) and
another group of staffs are responsible to scanning the tags on
properties. However, possible information leakage can occur
when one corrupted staff member scans the tags of a patient.
Without ﬁne grained access control, the hospital can hardly
differentiate the staffs from doctors, neither to protect the

patients’ privacy.
Now, we are ready to present the design details of this
service. Remember in the user authentication protocol, users
are required to provide his/her ID to RWD. Here, we deﬁne
the structure of ID to be: {Department, EmployeeID}.
Once, after a user submits the ID, the RWD will forward
the ID to RKPS. In RKPS, policies may be structure of the
following items:
RoomNumber(s)
Department
EmploymentID(s)
Preﬁx[a...]

one or multiple numbers of target rooms
department regulated by this policy item
(optional) one or more employee id(s) regulated by this policy item
RFID binary preﬁx allowed to be scanned

If RKPS ﬁnd an entry in the policy database, allowing a staff
member from property control department to scan the RFID
tags with preﬁx [000]. RKPS will return ”allow to scan preﬁx
[000]” to RWD. In [6], the authors propose a reader friendly
selective blocking protocol, which is based on the query tree
algorithm mentioned in section V. In this protocol the socalled blocker tag announces the predeﬁned privacy zones
(sub-tree of RFID serial numbers with certain preﬁx) to the
RFID readers, which should avoid reading tags in these zones.
In SRK, we modify this protocol to let the RWD announce the
privacy zone to readers. After RKPS returns ”allow to scan
preﬁx [000]” to RWD , RWD will send P s and announce
the allowed preﬁx [000] to the reader. Afterward, RWD can
watch over the scanning activity of user and enforce the access
policy; that is, if the reader follows the policy, RWD will not
block it and, if not, RWD will block the reader.
We give a possible example of application of access policy
enforcement service:
EXAMPLE-2 A hospital makes use of RFID tags to tag the
property whose preﬁx is [000] and each patient bears an RFID
tag whose preﬁx is [111]. Property control staffs can only read
the tags start with [000] and the doctors can read the tags
start with [111]. If a property control staff’s read tries to read
tags start with [111], RWD can detect the protocol dependent
reading command (see section V) and block the readers.
VII. P ERFORMANCE A SSESSMENTS
Computation Performance Assessments
In this section, we assess the timing performance of user
identity authentication protocol (section IV . In this protocol,
RWD and RFID readers are required to computing some
cryptographic functions, such as Pairing and hash functions.
RWD and RFID readers are light weighted embedded devices,
which is limited in computing capability. As a consequence,
we need to make sure that such cryptographic functions can
be computed efﬁciently in such light weight devices. We [12]
evaluate the timing of computing Pairing[1] and hash functions
in Intel based PDA in the following table:
Processor
OS
Memory

Time

32 bit-624 MHz Intel Bulverde technology-based
RISC processor
Microsoft Windows Mobile 2003 Second Edition
software for Pocket PC
92 MB total memory (128 MB ROM and 64 MB
SDRAM) Up to 135 MB user available memory
that includes 80 MB iPAQ File Store
550 ms

2857

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the ICC 2008 proceedings.

The above data shows that Pairing can be computed efﬁciently in the RWD and RFID readers.
SRK against DoS Attacks
In this section, we evaluate the security of the SRK under
two types of deny-of-Service attacks. (1) denial of reading:
prevent authorized users from reading RFID tags; and (2)
denial of authentication: prevent RWDs from authenticating
users.
In order to prevent authorized users from reading RFID tags,
the attackers can keep on sending read commands without being authenticated. As a result, RWD will send blocking signals,
which will also block authorized readers. To overcome this
problem, RWD should report to system administrators after
several consecutive read operations that violate the security
policy.
To perform the denial of authentication attacks, attackers
can block the RWD from detecting reader’s signals by covering the RWD with a metal shield to block the signals. Then,
attackers can read RFID tags without being detected by the
RWD. To counter this attack, we propose three approaches:
(1) passive listening, (2) active scanning, and (3) interactive
challenging.
By deploying a metal cover over an RWD, attackers can
block read commands from reaching the RWD. However,
this cover will also block the random signals and noises in
surroundings. The RWD can monitor the noise level its room.
If the RWD is blocked, the noise level will decrease greatly.
The following table shows the results of standard deviations
of the noise level before and after blocking the RWD.
Data Series
before blocking the RWD
after blocking the RWD

Standard Deviation
4.2454
0.2769

In the experiment, we collect 25 samplings and the sampling
frequency is 100Hz and the data series are collected in 0.25
seconds. We can expect RWD to detect the blocking in less
than 1 second.
In active scanning approach, RWD periodically sends Cosine signals and collects the reﬂected signals. The reﬂection
changes the phases of the signals. This approach utilizes the
multi-path phenomenon of wireless channel properties.
In interactive challenging approach, at least two RWDs
challenge each other. An RWD periodically challenges other
RWDs by sending a random number. After receiving a challenge, the responding RWD uses a secret random function to
derive the response and replies to the requestor.
We note that all the three presented approaches are vulnerable to sophisticated attackers who can artiﬁcially generate
ambient noise, simulate phase changes, or deploy the manin-the-middle attacks. However, we consider these activities
are difﬁcult since the attacks are required to set up sophistic
devices to block RWDs.
VIII. C ONCLUSION AND F UTURE W ORK
In this paper, we describe the Smart RFID Keeper as an
RFID data access control infrastructure. The SRK can provide
user authentication, data access control and ﬁned grained
policy enforcement. We also evaluate the performance and

security of the SRK. We ﬁnd that the SRK is vulnerable
to some sophisticated attacks, such as the man-in-the-middle
attacks. Our future work should be concentrated on countering
this attack.
R EFERENCES
[1] P. Barreto, H. Kim, B. Lynn, and M. Scott. Efﬁcient Algorithms
for Pairing-based Cryptosystems. Advances in Cryptology–Crypto,
2442:354–368, 2002.
[2] Capetanakis. Tree Algorithms for Packet Broadcast Channels. IEEE
Transactions on Information Theory, 25:505–515, 1979.
[3] D. Hush and C. Wood. Analysis of Tree Algorithms for RFID Arbitration. In Proceedings of IEEE International Symposium on Information
Theory, page 107, August 1998.
[4] A. Juels. RFID Security and Privacy: A Research Survey. IEEE Journal
on Selected Areas in Communications, 24(2):381–394, 2006.
[5] A. Juels and R. Pappu. Squealing euros: Privacy protection in RFIDenabled banknotes. In R. N. Wright, editor, Financial Cryptography –
FC’03, volume 2742 of Lecture Notes in Computer Science, pages 103–
121, Le Gosier, Guadeloupe, French West Indies, January 2003. IFCA,
Springer-Verlag.
[6] A. Juels, R. Rivest, and M. Szydlo. The Blocker Tag: Selective Blocking
of RFID Tags for Consumer Privacy. In Proceedings of ACM Conference
on Computer and Communications Security (CCS), pages 103–111,
Washington, DC, USA, October 2003.
[7] M. Langheinrich. Rﬁd and privacy. In M. Petkovic and W. Jonker,
editors, Security, Privacy, and Trust in Modern Data Management,
chapter 28, pages 433–450. Springer, Berlin Heidelberg New York, July
2007.
[8] M. Langheinrich and R. Marti. Practical minimalist cryptography for
rﬁd privacy. IEEE Systems Journal, Special Issue on RFID Technology,
1(2):115–128, Dec. 2007.
[9] C. Law, K. Lee, and K. Siu. Efﬁcient Memory-less Protocol for Tag
Identiﬁcation. In Proceedings of the 4th International Workshop on
Discrete Algorithms and Methods for Mobile Computing and Communications, pages 75–84, August 2000.
[10] D. McCullagh. RFID tags: Big Brother in small packages. CNET News.
com, 13:2010–1069, 2003.
[11] A. Menezes. Handbook of Applied Cryptography. CRC Press, 1997.
[12] A. Ramachandran, Z. Zhou, and D. Huang. Computing Cryptographic
Algorithms in Portable and Embedded Devices. Portable Information
Devices, 2007. PORTABLE07. IEEE International Conference on, 2529:1–7, 2007.
[13] M. Rieback, B. Crispo, and A. Tanenbaum. Keep on Blockin’ in
the Free World: Personal Access Control for Low-Cost RFID Tags.
In Proceedings of the International Workshop on Security Protocols
(IWSP), Lecture Notes in Computer Science, Cambridge, England, April
2005. Springer-Verlag.
[14] M. Rieback, G. Gaydadjiev, B. Crispo, R. Hofman, and A. Tanenbaum.
A Platform for RFID Security and Privacy Administration. Proceedings
of the 20th conference on Large Installation System Administration
Conference-Volume 20 table of contents, pages 8–8, 2006.
[15] S. Sarma, S. Weis, and D. Engels. RFID systems and security and
privacy implications. In B. Kaliski, c. Kaya ço, and C. Paar, editors,
Cryptographic Hardware and Embedded Systems – CHES 2002, volume
2523 of Lecture Notes in Computer Science, pages 454–469, Redwood
Shores, CA, USA, August 2002. Springer-Verlag.
[16] D.-H. Shiha, P.-L. Suna, D. C. Yenb, and S.-M. Huangc. Taxonomy and
Survey of RFID Anti-collision Protocols. Computer Communications,
29:2150–2166, 2006.
[17] C. C. Tan, B. Sheng, and Q. Li. Severless search and authentication protocols for RFID. In International Conference on Pervasive Computing
and Communications – PerCom 2007, New York, USA, March 2007.
IEEE, IEEE Computer Society Press.
[18] S. Weis, S. Sarma, R. Rivest, and D. Engels. Security and privacy
aspects of low-cost radio frequency identiﬁcation systems. In D. Hutter,
G. Müller, W. Stephan, and M. Ullmann, editors, International Conference on Security in Pervasive Computing – SPC 2003, volume 2802 of
Lecture Notes in Computer Science, pages 454–469, Boppard, Germany,
March 2003. Springer-Verlag.
[19] Z. Zhou and D. Huang. RFID Keeper: An RFID Data Access Control
Mechanism. to apprear at Proceedings of IEEE Global Communications
Conference, 2007.

2858

2010 Fifth IEEE International Symposium on Service Oriented System Engineering

MobiCloud: Building Secure Cloud Framework for Mobile Computing And
Communication
Dijiang Huang
Computer Science Engineering, ASU
Tempe, USA

Xinwen Zhang
Samsung R&D Center
San Jose, USA

development of secure MANET technologies. Furthermore, we
will identify a number of open research issues that will provide
guidance for the cloud computing and MANET research
communities to developing new solutions for secure mobile
computing.
Building a trustworthy MANET communication system
is one of the most challenging research issues of mobile
computing. This is caused mainly by two inter-related research
issues: (1) the security of existing MANET infrastructure
lacks inter-operability support in a heterogeneous communication environment. Communication devices belonging to
different administrative domains with different communication
and computation capabilities make protocol design extremely
difficult. This issue is usually caused by the uncertainty
in the security setup of communications peers during trust
establishment. For example, mobile entities may use different
identity space, cryptographic parameters, and reside in different administrative domains. (2) MANET mobility has a significant impact on the security and communication performance
relating to location tracking, communication privacy, reliability
and survivability. Uncertainty introduced by mobility produces
unpredictable inter-meeting duration, transmission rates, and
locations. Therefore, the MANET operations require a comprehensive approach focusing on risk assessment with respect
to security and communication requirements.
MobiCloud transforms traditional MANETs into a new
service-oriented communication architecture. MobiCloud
transforms each mobile node from a traditional strictly layerstructured communication node into a service node (SN).
Each SN can be used as a service provider or a service
broker according its capability, e.g., available computation
and communication capabilities to support a particular service.
This approach takes maximum advantage of each mobile node
in the system by utilizing cloud computing technologies. To
reduce the uncertainty caused by mobility, we incorporate
every SN into the MobiCloud as a virtualized component.
Each SN is mirrored to one or more Extended Semi-Shadow
Images (ESSIs) in the cloud in order to address the communication and computation deficiencies of mobile device. We
note that ESSI can be differentiated from a virtual image”
in that an ESSI can be an exact clone, a partial clone, or an
image containing extended functions of the physical device. In
addition, the ESSIs create a virtualized MANET routing and
communication layer that can assist the physical mobile nodes

Abstract—Cloud services can greatly enhance the computing
capability of mobile devices. Mobile users can rely on the cloud to
perform computationally intensive operations such as searching,
data mining, and multimedia processing. In this paper, we
propose a new mobile cloud framework called MobiCloud. In
addition to providing traditional computation services, MobiCloud also enhances the operation of the ad hoc network itself
by treating mobile devices as service nodes. The MobiCloud
framework will enhance communication by addressing trust
management, secure routing, and risk management issues in
the network. A new class of applications can be developed
using the enhanced processing power and connectivity provided
by MobiCloud. Open research issues for MobiCloud are also
discussed to outline future research directions.
Keywords-Mobile Ad Hoc Network, Cloud Computing,
Context-awareness, Security.

I. I NTRODUCTION
The use of mobile devices to establish ad-hoc communication systems is a viable solution that provides global connectivity to support a broad range of applications. With the development of wireless access technologies such as 3/4G, LTE,
and WiMax, mobile devices can gain access to the network
core over longer distances and larger bandwidths. This allows
for very effective communication between mobile devices
and the cloud infrastructure. A new service architecture is
necessary to address the requirements of users in their unique
operational environment and create new mobile applications.
In general, mobile users can benefit greatly from cloud services for computationally intensive information processing and
collection such as information search, data processing, data
mining, network status monitoring, field sensing, etc. However,
existing mobile cloud service model operates mostly onedirectional. For example, consumer electronics (CE) devices
can use the cloud as a computing and information resource.
Operations can be outsourced to the cloud, but the cloud has
little control over the CE devices.
The objective of our research is to use a systematic approach to investigate both cloud computing and mobile ad hoc
networks (MANETs) technologies in order to understand the
capability of cloud computing for securing MANET applications. This research article is presented as a position paper
to highlight research directions and possible solutions for
enhancing secure mobile computing using cloud computing.
We present a new MANET communication framework named
MobiCloud that will fundamentally change the research and
978-0-7695-4081-8/10 $26.00 © 2010 IEEE
DOI 10.1109/SOSE.2010.20

Myong Kang, Jim Luo
Naval Research Lab
Washington DC, USA

27

SA: Software Agent
Notation:
Direct link or control SC: Software Container
Indirect link or control NM: Node Manager
SDR: Software Defined Radio
MobiCloud
Trust Management
Server (TMS)
MobiCloud Service/

Identity/key/policy management.
Content-awareness risk management/Intrusion detection and response.
Scenario simulation and prediction.
Service composition, advising, and commanding.

MobiCloud Service Provisioning
SC

VTaPD i

SC
SA

SC
SA

VTaPD j

SA

SA

SA

VTaPD k

SA
NM

SA
NM
Virtualization

Application Store (MSAS)

SC
SA

SA
NM

SA
NM

Security-as-a-Service
(SeaaS)

MobiCloud
Virtual Trust and
Provisioning Domain
(VTaPD) Manager

SDR

MobiCloud
Resource/Application
Manger (RAM)

Mobile Ad Hoc
Network

SC

&
Sensing

Application Manager

Programmable
Routers
SSL connections

SDR
SC

Hardware
Farm

MobiCloud
Application Interface
(MAI)

Fig. 1.

•

•

•

Application Manager

Reference Model of MobiCloud.

and maximize availability of pervasive computing services for
each mobile user. The main contributions of this research paper
are summarized as follows:
•

&
Sensing

II. R ELATED W ORK
In this section, we presented related work in two areas: security in cloud computing and secure MANET communication
using cloud computing.
Cloud computing is a new business model focusing on resource-on-demand, pay-as-you-go, and utilitycomputing [1]. Cloud computing can be broadly classified as infrastructure-as-a-service (IaaS), platform-as-a-service
(PaaS), and software-as-a-service (SaaS). Critical research
issues for cloud computing such as computation offloading,
remote execution, and dynamic composition have been extensively discussed in previous literature. Several approached
have been proposed on enhancing security of Clouds themselves, such as infrastructure security [2] based on TCG/TPM
[3], secure outsourcing [4], [5], [6], [7], cloud web security
[8], [9], resource management and isolation [10], [11], and
privacy [12], [13].
Recent research have been focused on cloud computing
for mobile devices [14], [15], [14], [16]. Cloud computing
for mobile devices has a major benefit in that it enables
running applications between resource-constrained devices and
Internet-based Clouds. Moreover, resource-constrained devices
can outsource computation/communication/resource intensive
operations to the cloud. CloneCloud [17] focuses on execution
augmentation with less consideration on user preference or
device status. Samsung has proposed the concept of elastic
applications which can offload components of applications
from mobile devices to cloud [18]. Oberheide et al. [19]
present a framework that outsources the anti-virus services
from mobile devices to a cloud. Goayl and Carter propose
a secure cyber foraging mechanism for resource-constrained
devices [20]. Existing mobile cloud solutions are limited and

MobiCloud supports the MANET functions of information dissemination, routing, localization, and trust management.
MobiCloud adopts cloud computing technology to create
a virtualized environment for MANET operations in
multiple service provisioning domains according to the
criticality of MANET services and corresponding security
requirements.
MobiCloud provides a fundamental trust model including
identity management, key management, and security data
access policy enforcement that can be used to develop
future mobile applications.
MobiCloud supports the MANET operations through
research on context-aware risk assessment using communication and performance metrics of each mobile
node under corresponding security requirements. This
will allow us to use the MobiCloud to inspect various
performance and security issues of MANET and generate
useful data.

The rest of this paper is arranged as follows: In Section
II, we present recent research in both cloud computing and
secure MANET communication. The detailed description of
MobiCloud is presented in Section III. In Section IV, we
present new applications that can be supported by using
MobiCloud. Finally, we summarize the proposed solution and
present open research issues in Section V.

28

focuses solely on enhancing the capability mobile device on
an individual basis.

MobiCloud. We introduce programmable routers that can be
used to create multiple VTaPDs. VTaPDs are created mainly
for isolating information flow and access control by creating
multiple virtual domains. There are two main reasons for
multiple virtual domains: (1) security, a user’s device may
run multiple applications at different security domains, e.g.,
its simultaneous communication with two individuals with
from administrative domains; and (2) context-awareness, it
may be necessary to separate services for different local and
network settings. For example, MobiCloud can simulate the
operations of the MANETs using different system parameters
or routes selection algorithms to compare different approaches
for utilizing cloud computing and communication resources.
This approach provides a comprehensive overview of MANET
operations and provides information to mobile devices and
system managers for decision making.
In each VTaPD, one or more SAs are used for every ESSI. A
Node Manager (NM) is responsible for managing the loading
and unloading of SAs in the ESSI. The ESSI also provides
additional capabilities beyond the functions of a mobile device.
For example, the cloud will be able to run services that are
not available in MANETs, such as search, data mining, media
processing, trust pre-establishment (e.g., credential exchange
and establishing security keys in advance), etc. The MobiCloud Resource and Application Manager (RAM) constructs
VTaPDs when it is directed by MobiCloud VTaPD manager
and MobiCloud Trust Manager Server (TMS). They form
the core for providing Security-as-a-Service (SeaaS). With
SeaaS, MobiCloud can offer security service composition
capability according to requests from mobile applications.
In our SeaaS service model, the VTaPD manager plays the
central role since it collects context-awareness information
from the MANET (such as device sensing values, location, and
neighboring device status) and used it for intrusion detection
and risk management. The MobiCloud TMS is the Trust
Authority (TA) for MobiCloud. It handles the attribute-based
key distribution and revocation. It provides identity search and
federation services for mobile devices belonging to multiple
administrative domains. It also performs policy checking and
enforcement functions to provide a unified trust management
system for MobiCloud.
Finally, the MobiCloud Service and Application Store
(MSAS) serves as the repository for SAs and applications.
When service composition is needed, the MSAS will install the
required SAs or applications through the MAI. For example,
when a mobile device needs to talk to another device using
different frequency bands, the Software Defined Radio (SDR)
needs to install a new driver and the node needs another
authentication module. In this scenario, the SAs for the new
drivers and authentication module will be installed. This
operation needs collaborations between TMS and MSAS.
2) Secure Isolation through VTaPDs: VTaPDs are established to provide data access control and information protection. We must note that the framework may not need/imply
the division of the administrative domain into VTaPDs. In
the following subsection, we will address the cloud resource

III. M OBI C LOUD A RCHITECTURE
In this Section, we first describe the MobiCloud architecture
(shown in Figure 1) and its support for security service provisioning, resource and security isolation, and the integration
of processing and operations of cloud and MANETs. We then
describe several services that can help both cloud and MANET
to achieve the proposed system-level functionalities, such as
identity management, key management, policy enforcement,
and context-aware routing and risk assessment.
A. MobiCloud Security Services Architecture
1) MobiCloud Architecture: Figure 1 shows the conceptual infrastructure for MobiCloud. Similar to existing cloudbased computation and storage outsourcing [18], a mobile
node can leverage hardware farms on cloud to augment its
computing capabilities. Beyond this, we introduce a new type
of service named ”virtual trusted and provisioning domain
(VTaPD)” to isolate information flows belonging to different
security domains using programmable router technologies
[21]. Moreover, we provide fine-grained trust management and
feedback/command capability to mobile users. In summary,
MobiCloud is designed to provide the following cloud services
for MANETs:
• Serve as an arbitrator for identity, key, and secure data
access policy management.
• Provide security isolations to protect mobile users’ information.
• Monitor MANET status for risk assessments, intrusion
detection and response.
• Simulate scenarios and predict future MANET situations
for decision making.
• Provide service composition and applications for mobile
devices.
Now, we describe the functionality and properties of each
component of Figure 1. MobiCloud uses Software Agents
(SAs) (i.e., application components) to link the cloud services
and mobile devices. The same SA can run on both the
mobile device and the cloud platforms correspondingly. Each
device can have multiple SAs for different cloud services
or MANETS, which are managed by application manager of
the device. Each device also provides sensing data about the
device itself (such as processor type, utilization, battery state,
and location with GPS support), and about the neighboring
mobile nodes (such as neighbor’s identity or addresses, link
quality, neighboring durations, etc.), which are managed by
the sensor manager.
On the cloud side, the MobiCloud Application Interface
(MAI) exports services that can be consumed by to mobile devices. In addition, the MAI also provide interfaces
to VTaPD manager and Resource and Application Manager
(RAM). Middle-ware based solutions are required when the
cloud components do not use web-based interfaces. Several
unique cloud components and constructions are proposed for

29

nism. Therefore, there is no need to leverage an additional
common delegated account across tenants.

isolation and security isolation.
Resource isolation: The actual administrative work is handled by the MobiCloud VTaPD manager. Every node that
belongs to a particular VTaPD will have the complete routing
information for VTaPD in which it resides, but not others.
Each node can reside a different physical system. Each node
would have to support our communications framework which
includes secure group communication to sending data to
all the ESSIs in the same VTaPD. The bandwidth for a
communication link can be divided by using different encryption/decryption/authentication keys. An advantage of the
MobiCloud framework that provides network virtualization
through multiple VTaPDs is that it facilitates prioritization of
critical/emergency services in a network. For example, using
the proposed virtualization approach, prioritized and normal
service classes can be defined using different VTaPDs. They
can share the same physical MANET but prioritized based on
the VTaPD. MANET operations and communications can be
migrated into the cloud when peer-to-peer communication is
under stress either from insufficient bandwidth or attacks.
Data access control: In addition to the isolation provided
by VTaPD service domain, MobiCloud also needs to integrate data access control and information isolation using a
cryptography based approach. Besides the traditional security
concerns (i.e., authentication, authorization, audit etc.), additional security risks are introduced by mobile users who share
the same application instance and resources. In cloud related
literature, this referred to as multi-tenant environments. Each
mobile user’s ESSI can be considered as his/her tenancy in
the MobiCloud. In the multi-tenant environment, data access
control is one of the most critical security concerns that
need to be addressed. Data isolation mechanisms prevent
users from accessing resources belonging to other tenants.
There are generally two kinds of access control isolation
patterns: implicit filter and explicit permission. Chong et al.
[22] introduced how to apply these two patterns into a multitenant data model. We further generalize the two patterns to
provide access control for other resources:
• Implicit Filter Based Access Control Isolation: In this
pattern, when one tenant requests to access shared resources, a common platform level account (i.e., the ESSI
identity with corresponding SA and cloud resource requests) is delegated to handle this request. The delegated
account is shared by all tenants and has the privileges
to access resources of all tenants. However, the key of
this mechanism is to implicitly compose a tenant-oriented
filter that will be used to prevent one user from tapping
into resources of other tenants. This can be achieved
by using a cryptography-based solution, i.e., group key
management based solutions to secure information flow
through different VTaPDs that share the same physical
system.
• Explicit Permission Based Access Control Isolation: In
this pattern, access privileges for the resources have
been explicitly pre-assigned to the corresponding tenant
accounts by using the Access Control List (ACL) mecha-

B. MobiCloud Trust Management
Several interrelated components of trust management in
MobiCloud will be addressed including identity management, key management, efficient data access control, and
security context-aware-based risk assessment. Moreover, we
will present an approach to incorporate cloud computing
techniques to address several research issues considered very
difficult problems for MANETs.
1) MobiCloud Identity Management: The user-centric identity management, which is also frequently referred to as
identity 2.0, allows an individual to have multiple identifiers.
For example, the identifier carried on a national ID card
becomes just one of many of an individual’s identifiers, which
can also include passport ID, club card ID, military ID, email
ID, unique MAC/IP address, etc. There are many research
problems may in this area. How to provide convenient secure
single sign-on to multiple distinct entities? How to give individuals fine-grained control for the sharing specific personal
identities between entities when it is to their advantage to do
so? How do we know what identity information to share when
two users meet? To address these questions, we propose a
novel Attribute-Based Identity Management (ABIDM).

Entity

Default

PoNP A
Type

A1
T

V

A2
T

V

PoNP B

Value

Type

Value

PoNP X
Type

Value

PoNP Y
Type

Value

An
T

V

Fig. 2.

Identity representation scheme.

The basic identity representation of ABIDM is shown in
Figure 2. Using ABIDM, we first need to define the point
of network presence (PoNP). A mobile node’s relationship
can be thought of as lines radiating from the PoNP to the
various counterparties. Each line is distinct and tagged with
the attribute used by a particular counterparty. In particular, we
define a default PoNP (i.e., native PoNP) for each individual.
The default PoNP has to be linked by a unique native ID.
The uniqueness of the native ID is not difficult to achieve.
Indeed, any user can have a unique native ID by simply
hashing any one of his/her unique identifiers, such as military
ID, SSN, etc. It is not necessary to use identifiers from the
same administrative domain. Each PoNP has two properties:

30

type and value. Each PoNP is associates with one or multiple
attributes (A1...An), and each attribute has type and value
properties.
The major benefit of using this identity representation is
the standardization” of identity management. In practice, the
numbers of PoNPs for every mobile node should not be many.
They can be assigned to mobile users as predefined attributes
that that do not changed frequently. We call these attributes
as static attributes. To differentiate PoNPs, we will be able to
narrow down the numbers of attributes that can be potentially
used for later secure communications.
S

Data
Encrypting Key

AND

Secret Sharing
Threshold Gates

S’
AND

Private Key
Components
Attributes

S’’
OR

S1
S1
S1

S2
S2
S2

A1

A2

Fig. 3.

Existing key management solutions usually consider the key
management and Identity Management (IDM) as different issues. We use a novel key management solution, i.e., ABKM, to
integrate key management and IDM. In ABKM, we can simply
consider all the attributes belong to an entity as its public key.
Each attribute can be considered as a public key component,
and each of the attributes is also paired with a private key
component. The private key, which is in turn is formed by
multiple private key components, is distributed from a TA.
We must note that ABKM is basically an extended version
of identity-based cryptography, in which the identity can be
considered multiple descriptive attributes and the attributes
can be used to represent descriptive policies through logical
operators such as “AND” and “OR”. Compared to traditional
PKI based key management solutions where a user’s private
key is only known to the public owner, using ABKM, the
TA generates private key components for each user according
to his/her public attributes. This approach delivers a major
benefit in that the private key can be generated for descriptive
terms or statements instead of using a large random number
(e.g., RSA). The descriptive terms can be used to specify
data access control policies, which is very efficient in terms
of security policy management. For example, traditional data
access control approaches usually use a key exchange protocol
to distribute the Data Encrypting Key (DEK) to a user to decrypt the ciphertext. However, using ABKM, the key exchange
protocol is not needed. The sender can just simply select a set
of attributes according to required security policies to generate
the ciphertext. This property is very useful in delay tolerant
MANETs since a source usually does not need to talk with
the destination before sending him/her the data. Moreover,
the data access can be very flexible, where the data sender
does not need to know the identities of receivers. In fact, this
approach is very effective for secure group communication,
where a group of receivers may satisfy the specified data
access policies. Furthermore, a policy tree can be used for
secure group communication since attributes can be used to
specify a group of users, which make the ABKM approach
appealing in large-scale communication systems.
3) Context-aware Risk Management in MobiCloud: Risk
management calls for the identification, assessment, and prioritization of risks followed by a coordinated and economical
application of available resources to minimize, monitor, and
control the probability and/or impact of unfortunate events or
to maximize the realization of opportunities [26]. The methods, definitions, and goals vary widely in MANETs according
to whether the risk management method is in the context of
the mission supporting functions, operations, or security. Here,
we focus on two important components of risk management:
context-aware routing and intrusion detection/response.
Context-aware Routing: Context awareness is a concept
with a broad range of meaning. Literally, it means taking
into account the context” while making decisions. However,
the definition of context varies depending on the applications,
the decisions, as the environments. In MANETs, contextawareness usually means to give consideration to the systems

S3

S4
S4
S3

A3

A4

u1
u2
u3

Attribute-based Encryption.

2) Efficient Key Management for Secure and Private Data
Access Control: In Figure 3, we present an example to
illustrate using ABE [23] for data encryption and decryption.
In this example, attributes A1 − A4 are arranged as leaf
nodes of the attribute tree. Each attribute can have multiple
secret components for different users. We must note that users
can share an attribute; however the corresponding private key
components for that attribute are different. This is represented
by different colors of the keys. Thus, u1 has private key
components {red : S1, S2, S3, S4}, u2 has private key
components {green : S1, S2, S4}, and u3 has private key
components {blue : S1, S2, S3}. The internal nodes of the
attribute tree are logical gates, such as AN D, OR. They
are implemented using threshold secret sharing scheme [24].
The secret S can be derived from S ′ and S ′′ using the
secret sharing scheme. At the bottom level the encryption
is performed using a construction similar to identity-based
encryption (IBE) [25]. During encryption, in order to satisfy
the AN D gate, the decrypter must have all the secrets under
it to reconstruct the higher level secret; to satisfy the OR
gate, the decrypter is only required to have one of the secrets.
The encryption algorithm of ABE is performed in a top-down
manner by constructing the ciphertext at the bottom level of the
attribute tree. The decryption algorithm of ABE is performed
in a bottom-up manner using the users’ pre-distributed secrets
to reconstruct higher level secrets until they reach the root. In
this presented example, based on the pre-distributed secrets,
u1 − u3 can decrypt the secret S and thus they can access the
data encrypted by using the DEK S.

31

parameters of the devices (e.g., battery level, CPU power), the
networking parameters (e.g., bandwidth, delay, connectivity),
the content (e.g., the mission specified goals), and the security
(e.g., privacy, location, attacks) when using the network. This
is because such environments often have highly dynamic
characteristics that can significantly affect applications. In
order to provide continuous services in such a highly dynamic
network, context-aware service migrations are required so
that the applications can be adaptive to volatile contexts. For
instance, when a node providing a certain service is running
out of battery, the framework should be aware of such context
change, and migrate the service (and the entire executing
contexts) to another available node.
To achieve context-awareness capability, a mobile node
needs to collect its local context information (such as device
properties, communication parameters, and security) and periodically send them its ESSI. Comprehensive risk assessment
can be performed on the MobiCloud since the status of
the entire system (such as end-to-end communication delay,
reachability to the destination, security status of each mobile
node, etc) is available. If the cost (computed through a utility
function) of using ad hoc communications is higher than the
cost of sending the information through the cloud, the cloud
communications is preferred. The utility functions need to be
well designed to operate under various situations in which the
mission goals of the tactical MANETs and their corresponding
context-related measurement metrics can be different.
Using cloud services, the data collection and processing
will be handled in a centralized. As a result, the complexity of context-awareness operations will be greatly reduced.
Moreover, simulations can be performed on the MobiCloud
to evaluate different modes of operation for the MANETs
and then provide better recommendations to mobile nodes.
This will reduce the uncertainty of mobile system and thus
improve the performance of MANET communications. Particularly, positioning, network topology maintenance, and routing
functions can be performed by using cloud services. Each
node can get this information from the cloud. In this way, the
information dissemination among mobile nodes will become
one-to-one communication between the physical device and
its shadow image in the cloud, instead of one-to-many communications in traditional MANETs. This will greatly reduce
the communication and management overhead among mobile
nodes. In addition to the context-based routing, MobiCloud
also needs to take into account the contents of messages
when making the routing decisions. The MANET mission
information is usually contained in the transmitted content. For
example, the following content can affect the routing decision:
(a) the minimum spanning tree from the message sender, (b)
the content predicates of neighbors (e.g., the neighbors’ role,
processing function on the received data, security clearance
level, etc.), and (c) how long each neighbor has been apart
from the destination.
MobiCloud Risk Management: Many existing MANET security solutions have tried to protect MANETs using preventive approaches. Although preventive approaches can signifi-

cantly reduce potential attacks, they cannot counter malicious
insiders (from mis-configured or node malfunction). Previous
work [27], [28] have proposed to counter identified malicious
mobile nodes by isolating uncooperative nodes. From the risk
management perspective, the major drawback of the isolation
approach is that they do not take into account the negative
side effects of the isolation. In some cases, countermeasures
to intrusions may cause more damage than the actual identified
attacks (e.g. by isolating the entire network). To make a
comprehensive risk assessment, centralized data collection and
processing is more effective. In the cases of malicious nodes
partitioning the networks, the distributed approach will suffer
a high false negative rate since attackers can manipulate information within different partitions. MobiCloud can identify
malicious nodes and make risk assessment with full knowledge
of the entire MANET communication system.
IV. N EW M OBI C LOUD A PPLICATION S CENARIOS
Based on the presented MobiCloud framework, we highlight
several application scenarios that traditionally are considered
to be difficult in MANETs.
Inter-operable scenario: A search team is searching for a
lost individual in an area, where they have located equipment
that might belong to the missing person. Due to security
protection, the search team cannot read the identification stored
in the RFID tag affixed to the equipment. Here, they can
proxy the communication between the tag and the back end
server running in MobiCloud. In this scenario, interoperability
is the major problem, which is caused by two separate issues:
(1) two wireless devices running two different protocols (or
different versions of software), and (2) two wireless devices
belonging to two different administrative domains and thus
using different security parameters (e.g., cryptographic keys).
To address this problem, the search team’s wireless devices
may not be preprogrammed to read the RFID tag. However,
with software defined radios, the search teams can download
the necessary software components from the MobiCloud to
enable communications. In the meantime, the cloud can also
help the search team set up a secret key between the tag and
reader. As another example, if the rescue team needs to locate
the individual’s location based on the signal transmitted from
a wireless device that he/she carries, the rescue team may
need new services for location tracking. Localization usually
requires a synchronized environment to run a triangulation algorithm. The MobiCloud can compose a time synchronization
service and software on wireless devices to enable the ad-hoc
positioning capability for rescue team members.
Efficient Communication scenario: Communications overhead due to MANET routing contributes a great portion of
MANET bandwidth consumption. To demonstrate the routing
overhead, in Figure 4, we present a simulation-based study
using the group mobility model [29] for two on-demand
routing protocols, AODV [30] and DSR [31], where we deploy
60 mobile nodes and each randomly selects its moving velocity
between 10m/s and 30m/s. It shows that the routing traffic
ratio to overall traffic increases when less data are transmitted

32

tended destination when they are back online. The uncertainty
of this communication model is very high due to unpredictable
mobility and storage status of neighboring devices. MobiCloud
will reduce the uncertainty by functioning as an information
repository. Thus, the message originator, forwarder, and receiver know that the MobiCloud is the repository for sending,
forwarding, and retrieving information.
Cloud computing has a great potential to bring more application scenarios than the above mentioned ones for mobile
computing applications. Based on the presented new MANET
infrastructure, we expect more MobiCloud applications can be
identified and developed in near future.

0.45

Routing Overhead ratio

0.4
0.35
0.3
0.25
0.2

AODV

0.15

DSR

0.1
0.05
0
10

100

1000

Data Transmission Interval (ms)

Fig. 4. MANET routing overhead. (a) Routing overhead of overall transmitted
data. (b) Number of links broken due to mobility.

V. D ISCUSSIONS AND F UTURE R ESEARCH D IRECTIONS

(i.e., data packets are sent for every 1 second). This study
demonstrates that overall ratio of routing overhead can be even
greater when the MANET is under stress, e.g., communication
speed is reduced due to poor communication channel quality
or frequent link changes among mobile nodes. This will
make the MANET data communication more congested. With
MobiCloud support, mobile nodes do not need to perform
path searching and maintenance for routing purposes; instead,
each mobile node only needs to monitor the connectivity and
channel quality to its neighboring nodes and updates this
information to its ESSI in the cloud. The cloud will perform
routing and inform the node on how to forward packets.
Security and service isolation scenario: With the development of wireless technology, a smart phone can serve as a
personal information gateway. It can communicate with a variety of wireless devices belonging to different administrative
domains. Running more applications will increase the threats
of malware that can be installed in the smart devices and then
jeopardize the critical information processed in the device.
Using MobiCloud, we can initiate one or multiple ESSIs
running multiple services on different physical computing
systems in the cloud for a mobile device. In this way, attackers
can be prevented from manipulating caching operations [32]
to steal users’ private information in the cloud. Moreover, the
system complexity of wireless devices is reduced by running
simple and trusted software, and hence the chance of being
compromised is also reduced. The isolation of services can
also help commanders decide on effective methods to operate
the MANET. For example, context-aware routing [33], [34]
needs to consider the situations of MANET using a set of
predefined parameters (such as battery status, communication
channel qualities, previous communication and neighboring
history of a node, etc.) to determine a packet forwarding
strategy. To this end, the cloud can create a virtual routing
domain to emulate the routing behaviors of the MANET and
then provide suggestions to commanders for decisions.
Delay tolerance communication scenario: Traditional delay
tolerance networks consider each mobile device as both a
communication device and a storage device. They maintain
received information and deliver this information to the in-

In this paper, we presented a new mobile cloud framework
for MANETs called MobiCloud’. We presented a comprehensive framework focusing on important and inter-related
system components including virtual trust and provisioning
domain construction, resource and information flow isolations,
trust management (i.e., identity management and attributebased data access control), context-aware routing, intrusion
detection, and context-aware risk management. Apart from
system components discussed, there are several research and
implementation issues need to be addressed. They are discussed in the following subsections:
Damage Recovery: The mobile devices such as consumer
electronics (CEs) can be lost or stolen. Using MobiCloud, the
user’s information can be recovered through the corresponding
ESSI that stores the data and processing status information.
The research challenge is how to prevent malicious attackers
from using the mobile devices. Intuitively, biometrics based
identification techniques on the CE devices such as voice
recognition, fingerprints, etc., can be used as a second authentication method to protect the mobile devices. However,
biometrics enabled devices will increase the device cost,
and protecting the biometrics’s information of a mobile user
becomes another issue. Thus, the research question is that can
we use MobiCloud to protect user’s data, even if the mobile
devices are lost or compromised?
Fine-grained Resource and Security Isolation: VTaPD provides a coarse level of isolation, which can be established
based on available network resource or totally independent
services. However, one service may depend on another service,
and two services may share partial data. Thus, it is possible
that multiple VTaPDs may share some common resources or
data. To address this issue, we should take a fine-grained
resource and security isolation approach. One possible solution is to develop an efficient secure many-to-many secure
group communication system, where any SA can talk to a
subgroup of SAs at the same time based on their service
and security requirements. Thus, a fine-grained data access
control mechanism is required to construct instant and partially
joint VTaPDs. We use µVTaPD to represent such a VTaPD,
where µ is used to specify the resource, security, and life-span
constrains. In other words, a µVTaPD can be considered as

33

a supporting VTaPD. How to construct and delete a µVTaPD
should be investigated.
Real-time performance issue: Operation delay will be a
major evaluation metric for designing MobiCloud applications.
This is because interactive MANET communication usually
imposes stringent real-time requirements. Thus, the MobiCloud services must not introduce long delays. Particularly,
MobiCloud service delay needs to be further investigated by
considering three types of MobiCloud services: (i) Monitoring
service: the cloud collects node and MANET status information from mobile devices and predicts appropriate actions to
be taken for mobile devices. (ii) On-demand service: the cloud
serves as a server, e.g., assisting a mobile node to establish
trust with another node controlled in different administrative
domains. (iii) Advising service: the cloud duplicates/emulates
the actions of MANETs for post-event analysis.

[15] K. Lyons, T. Pering, B. Rosario, S. Sud, and R. Want, “Multi-display
Composition: Supporting Display Sharing for Collocated Mobile Devices,” in Proceedings of the 12th IFIP TC 13 International Conference
on Human-Computer Interaction: Part I, 2009.
[16] H. XuhuiLi and Y. Zhang, “Deploying Mobile Computation in Cloud
Service?” in Proceedings of the First International Conference for Cloud
Computing (CloudCom), 2009.
[17] B. Chun and P. Maniatis, “Augmented Smartphone Applications
Through Clone Cloud Execution,” in Proceedings of USENIX HotOS
XII, 2009.
[18] X. Zhang, J. Schiffman, S. Gibbs, A. Kunjithapatham, and S. Jeong,
“Securing elastic applications on mobile devices for cloud computing,”
in Proceedings of the ACM workshop on Cloud computing security,
2009, pp. 127–134.
[19] J. Oberheide, K. Veeraraghavan, E. Cooke, J. Flinn, and F. Jahanian,
“Virtualized in-cloud security services for mobile devices,” in Proceedings of the First Workshop on Virtualization in Mobile Computing, 2008,
pp. 31–35.
[20] S. Goyal and J. Carter, “A lightweight secure cyber foraging infrastructure for resource-constrained devices,” in Proceedings of the 6th IEEE
Workshop on Mobile Computing Systems and Applications, 2004, pp.
186–195.
[21] J. Lockwood, N. McKeown, G. Watson, G. Gibb, P. Hartke, J. Naous,
R. Raghuraman, and J. Luo, “NetFPGA-an open platform for gigabitrate network switching and routing,” in IEEE International Conference
on Microelectronic Systems Education, 2007.
[22] F. Chong, G. Carraro, and R. Wolter, “Multi-Tenant Data Architecture,”
Microsoft MSDN Document, available at http://msdn.microsoft.com/
en-us/library/aa479086.aspx, 2006.
[23] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-Policy AttributeBased Encryption,” Proceedings of the 28th IEEE Symposium on Security and Privacy (Oakland), 2007.
[24] A. Shamir, “How to Share a Secret,” Communications of the ACM,
vol. 22, no. 11, pp. 612–613, 1979.
[25] D. Boneh and M. Franklin, “Identity-based encryption from the weil
pairing,” SIAM Journal of Computing, vol. 32, no. 2, pp. 586–615, 2003.
[26] D. Hubbard, The Failure of Risk Management: Why It’s Broken and
How to Fix It. Wiley, 2009.
[27] M. Refaei, V. Srivastava, L. DaSilva, and M. Eltoweissy, “A Reputationbased Mechanism for Isolating Selfish Nodes in Ad Hoc Networks,” in
in Proceedings of the IEEE Annual International Conference on Mobile
and Ubiquitous Systems: Networking and Services (MOBIQUITOUS),
2005.
[28] T. View, “Information theoretic framework of trust modeling and evaluation for ad hoc networks,” Selected Areas in Communications, IEEE
Journal on, vol. 24, no. 2, pp. 305–317, 2006.
[29] S. A. Williams and D. Huang, “Group force mobility model and its
obstacle avoidance capability,” Journal of the International Academy of
Astronautics, Acta Astronautica, vol. 65, no. 7-8, pp. 949–957, OctoberNovember 2009.
[30] C. E. Perkins, E. M. Belding-Royer, and I. Chakeres, “Ad Hoc On
Demand Distance Vector (AODV) Routing,” IETF RFC3561, October
2003.
[31] D. B. Johnson, Y.-C. Hu, and D. A. M. and, “The dynamic source routing
protocol (dsr) for mobile ad hoc networks for ipv4,” IETF RFC4728,
2007.
[32] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, You, Get
Off of My Cloud: Exploring Information Leakage in Third-Party Compute Clouds,” in ACM Conference on Computer and Communications
Security, 2009.
[33] M. Musolesi and C. Mascolo, “CAR: Context-Aware Adaptive Routing
for Delay-Tolerant Mobile Networks,” IEEE Transactions on Mobile
Computing, vol. 8, no. 2, pp. 246–260, 2009.
[34] C. Mascolo and M. Musolesi, “SCAR: context-aware adaptive routing
in delay tolerant mobile sensor networks,” in Proceedings of the 2006
international conference on Wireless communications and mobile computing. ACM, 2006, p. 538.

ACKNOWLEDGEMENT
The research described in this paper was supported by NSF
DUE-0942453.
R EFERENCES
[1] M. Armbrust, A. Fox, R. Griffith, A. Joseph, R. Katz, A. Konwinski,
G. Lee, D. Patterson, A. Rabkin, I. Stoica, et al., “Above the clouds:
A berkeley view of cloud computing,” EECS Department, University of
California, Berkeley, Tech. Rep. UCB/EECS-2009-28, 2009.
[2] N. Santos, K. Gummadi, and R. Rodrigues, “Towards trusted cloud
computing,” Proceedings of USENIX HotCloud, 2009.
[3] “Tcg specification architecture overview.” Available at https://www.
trustedcomputinggroup.org.
[4] K. Bowers, A. Juels, and A. Oprea, “Proofs of retrievability: Theory
and implementation,” in Proceedings of the ACM workshop on Cloud
computing security, 2009.
[5] W. Wang, Z. Li, R. Owens, and B. Bhargava, “Secure and efficient
access to outsourced data,” in Proceedings of the ACM workshop on
Cloud computing security, 2009, pp. 55–66.
[6] A. Yun, C. Shi, and Y. Kim, “On protecting integrity and confidentiality
of cryptographic file system for outsourced storage,” in Proceedings of
the ACM workshop on Cloud computing security, 2009, pp. 67–76.
[7] R. Chow, P. Golle, M. Jakobsson, E. Shi, J. Staddon, R. Masuoka,
and J. Molina, “Controlling data in the cloud: outsourcing computation
without outsourcing control,” in Proceedings of the ACM workshop on
Cloud computing security, 2009, pp. 85–90.
[8] P. Lam, E. Bursztein, and J. Mitchell, “TrackBack Spam: Abuse and
Prevention,” in Proceedings of the ACM workshop on Cloud computing
security, 2009.
[9] J. Sobey, T. Whalen, R. Biddle, P. V. Oorschot, and A. Patrick, “Browser
Interfaces and Extended Validation SSL Certificates: An Empirical
Study,” in Proceedings of the ACM workshop on Cloud computing
security, 2009.
[10] J. Wei, X. Zhang, G. Ammons, V. Bala, and P. Ning, “Managing security
of virtual machine images in a cloud environment,” in Proceedings of
the ACM workshop on Cloud computing security, 2009, pp. 91–96.
[11] M. Christodorescu, R. Sailer, D. Schales, D. Sgandurra, and D. Zamboni,
“Cloud security is not (just) virtualization security: a short paper,” in
Proceedings of the ACM workshop on Cloud computing security, 2009,
pp. 97–102.
[12] M. Chase, K. Lauter, J. Benaloh, and E. Horvitz, “Patient Controlled Encryption: patient privacy in electronic medical records,” in Proceedings
of the ACM workshop on Cloud computing security, 2009.
[13] M. Raykova, B. Vo, S. Bellovin, and T. Malkin, “Secure Anonymous
Database Search,” in Proceedings of the ACM workshop on Cloud
computing security, 2009.
[14] T. Pering, R. Want, B. Rosario, S. Sud, and K. Lyons, “Enabling
pervasive collaboration with platform composition,” Proceedings of
Perviasive, 2009.

34

Scalable Network Intrusion Detection
and Countermeasure Selection
in Virtual Network Systems
Jin B. Hong1(B) , Chun-Jen Chung2 , Dijiang Huang2 , and Dong Seong Kim1
1

2

Department of Computer Science and Software Engineering,
University of Canterbury, Christchurch, New Zealand
jin.hong@pg.canterbury.ac.nz, dongseong.kim@canterbury.ac.nz
Department of Computer Science, Arizona State University, Arizona, USA
{chun-jen.chung,dijiang}@asu.edu

Abstract. Security of virtual network systems, such as Cloud computing systems, is important to users and administrators. One of the
major issues with Cloud security is detecting intrusions to provide timeeﬃcient and cost-eﬀective countermeasures. Cyber-attacks involve series
of exploiting vulnerabilities in virtual machines, which could potentially
cause a loss of credentials and disrupt services (e.g., privilege escalation
attacks). Intrusion detection and countermeasure selection mechanisms
are proposed to address the aforementioned issues, but existing solutions
with traditional security models (e.g., Attack Graphs (AG)) do not scale
well with a large number of hosts in the Cloud systems. Consequently,
the model cannot provide a security solution in practical time. To address
this problem, we incorporate a scalable security model named Hierarchical Attack Representation Model (HARM) in place of the AG to improve
the scalability. By doing so, we can provide a security solution within a
reasonable timeframe to mitigate cyber attacks. Further, we show the
equivalent security analysis using the HARM and the AG, as well as to
demonstrate how to transform the existing AG to the HARM.

Keywords: Attack graphs
detection · Network security

1

· Countermeasure
· Scalability

selection

·

Intrusion

Introduction

Adopting virtual network systems, such as the Cloud systems (i.e., Cloud), provides better service and resource utilizations for users, while the cost of operations for service providers is also reduced [9]. However, security is one of the
major concerns for users to migrate to the Cloud [16]. Since virtual machines
(VMs) can be controlled by the Cloud users rather than the network administrator (e.g., an Infrastructure-as-a-Service (IaaS) Cloud), addressing vulnerabilities
of the Cloud system may not be feasible and also a possible violation of the servicelevel agreement (SLA). To address this problem, one approach is to prevent VMs
c Springer International Publishing Switzerland 2015

G. Wang et al. (Eds.): ICA3PP 2015 Workshops, LNCS 9532, pp. 582–592, 2015.
DOI: 10.1007/978-3-319-27161-3 53

Scalable Network Intrusion Detection and Countermeasure Selection

583

being compromised and reused for cyber-attacks, by means of improving the intrusion detection (ID) [5,10,13,14,18–20,24]. Here, the ID identiﬁes invalid access in
the network (e.g., privilege escalation attacks). However, solely depending on the
ID cannot provide a comprehensive security overview of the Cloud, as it is diﬃcult
to assess the potential attack scenarios of a cyber-attack.
To improve the security assessment and countermeasure selection based on
the ID for the Cloud system, security models are incorporated into the framework [2,15,22]. For example, Chung et al. [2] incorporated an Attack Graph (AG)
[17] in a defense-in-depth intrusion detection framework named NICE, which formulates eﬀective countermeasures based on the security analysis of the AG when
cyber-attacks are detected. The AG is a graphical security model that is capable of
computing all possible attack scenarios and evaluate the security postures associated with them, which are used by security experts to enhance security. However,
traditional security models, such as the AG, do not scale well when the size of
the networked system becomes large [3,7]. On the other hand, Wang et al. [22]
incorporated an Attack-Defense Tree (ADT) [6] to assess both attack and defense
aspects of Cloud security. Tree-based security models such as ADTs can be generated automatically such as in [21], but the capability to adapt to dynamic changes
of the Cloud in those security models are not well deﬁned.
In this paper, we focus on improving the NICE framework by incorporating a
scalable security model, namely the Hierarchical Attack Representation Models
(HARMs) [4]. The HARM provides better scalability than the AG in various
network environments [3], as well as an ability to adjust to changes when there
are updates in the Cloud system [4]. First, we incorporate the HARMs into the
NICE framework, and we demonstrate the computation of equivalent security
metric values using the same methods described in the NICE framework (e.g.,
probability of an attack success [2]). Second, we describe how to transform an
AG in the form of the HARMs. Third, we conduct security analysis of the Cloud
with additional security metrics (e.g., probability, impact, risk, and Return-onInvestment). The contributions of this paper are as follows:
– Incorporate the HARMs into the NICE framework, and demonstrate an equivalent security analysis using the HARMs and the existing AG;
– Transform AG into HARM and HARM to AG;
– Conduct security analysis by utilizing various security metrics.
The rest of the paper is as organized as follows. The HARM is deﬁned and incorporated into the Cloud security framework in Sect. 2. The security analysis with
various security metrics is shown in Sect. 3, and we conclude our paper in Sect. 4.

2
2.1

A Scalable Security Model and a Cloud Security
Framework
Cloud Security Framework

The abstract view of the NICE framework consists of three components; (i) the
Cloud domain (CD), (ii) the attack analyzer (AA), and (iii) the network controller (NC) as shown in Fig. 1. The NICE-A (Network-based Intrusion Detection

584

J.B. Hong et al.
Table 1. Vulnerabilities in the example Cloud

Host

Vulnerability

CVE ID

Base Score

VM hosts

LICQ BoF
ActiveX Stack BoF
GNU C Library loader ﬂaw

CVE-2001-0439 0.75
CVE-2008-0015 0.93
CVE-2010-3847 0.69

Admin Server

MS SMB service Stack BoF

CVE-2008-4050 0.93

Gateway Server OpenSSL predictable random var
CVE-2008-0166 0.78
Heap corruption in OpenSSH
CVE-2003-0693 1.00
Improper Cookie Handler OpenSSH CVE-2007-4752 0.75
Mail Server

Remote code in SMTP
Squid port scan

CVE-2004-0840 1.00
CVE-2001-1030 0.75

Web Server

WebDAV vulnerability in IIS

CVE-2009-1535 0.76

System agent) and the VM Proﬁling components are merged as both of their
tasks are operated in the CD. Each of the NICE framework component contains procedures (e.g., IDS, Alert analyzer ) and modules (e.g., Security Model,
VMs Profile), where procedures are depicted as boxes and modules as disks.
The CD provides the AA with the events in the Cloud via the IDS and the VM
Profile. The AA processes the information from the CD to generate a security
model, which is then analyzed to formulate countermeasures. The NC deploys
the countermeasure in the CD via the Network Controller and the VM State
Updater.
The vulnerability information in the example virtualized system is shown in
Table 1. The Base Score (BS) from the National Vulnerability Database (NVD)
[11] will be used as the probability of vulnerability exploitation as described in
[2]. Previously, the NICE framework incorporated an AG using the tool MulVAL
[12], but there are limitations such as scalability and adaptability [3]. To cope
with the dynamic nature and scalability of the Cloud, a HARM is used instead,
where it is formally deﬁned in [4].
2.2

Equivalent Security Analysis with an AG and a HARM

This section demonstrates the equivalence of the security analysis between the
HARM and the AG. First, an example Cloud is used as shown in Fig. 2. The
security information is gathered by the node controller (e.g., Xenserver [23]), network controller (e.g., OpenFlow [8]), and vulnerability scanners (e.g., NESSUS
[1]) and databases (e.g., NVD [11]). Figures 3 and 4 show the AG and the HARM
of the example Cloud respectively. Although the same information is stored, the
structural properties are largely diﬀerent (e.g., the number of edges, nodes, density etc.).
Using the vulnerability information from Table 1, we can compute the probabilities of attack success as follows:

Scalable Network Intrusion Detection and Countermeasure Selection

585

Fig. 1. An overview of the Cloud security framework

Fig. 2. An example Cloud

– The probability of attack success for any attack-step node n in the AG with
immediate predecessors set W = parent(n),

(1 − P r(s | W ))
P rn|W = 1 −
(1)
s∈W

For example, the probability of an attack success of compromising the guest
privilege of the Admin Server is 0.525 as shown in Equation (2).

586

J.B. Hong et al.

Fig. 3. The AG of the example Cloud

P rAdmin guest privilege = 1 −



P r(s | W )

s∈W

= 1 − (1 − 0.75 × 0.7)
= 0.525

(2)

The condition probability of an attack success to compromise the root privilege of the Admin Server using the above calculation with an AG is 0.9366 [2].
Using the HARM, we can compute the same result as the following (in terms of
the probability of an attack success to compromise):
1. gaining (a) the guest privilege of VM through OpenSSH improper cookie
vulnerability in the NAT Gateway Server and then (b) the user privilege of
the VM by remote login has the P r = 0.42.
2. gaining (a) the guest privilege of VM through WebDAV vulnerability in the
Web Server and then (b) the user privilege of the VM through by LICQ
remote to user has the P r = 0.399.
3. gaining the user privilege of the VM by LICQ buﬀer overﬂow has the P r =
0.525.
4. Steps 1 to 3 result in gaining the user privilege of the VM with the P r =
0.8347 (Step 1 or Step 2 or Step 3).
5. gaining the root privilege of the Gateway Server by OpenSSH heap corruption
has the P r = 0.834.
6. gaining the guest privilege of the Admin Server by the squid scan has the
P r = 0.525.

Scalable Network Intrusion Detection and Countermeasure Selection

587

Fig. 4. The HARM of the example Cloud

7. with guest privilege of the Admin Server and the root privilege of the Gateway
Server, gaining the root privilege of the Admin Server by MS SMB BoF has
the P r = 0.333.
8. gaining the root privilege of the Admin Server via ActiveX Stack BoF has
the P r = 0.776 and through GNU C library loader ﬂaw has the P r = 576.
9. combining the probability of gaining the root privilege of the Admin Server
is 0.9366 (i.e., 1 − (1 − 0.766 × 0.576 × 0.333)).
2.3

Transforming an AG to a HARM

The AG can be transformed into the HARM, as the structure of the HARM
consists of those AG components in multiple layers. Steps are as follows:
1. The vulnerability information can be grouped based on the vulnerability scan
results, as we already know which vulnerabilities belong to diﬀerent hosts.
2. The upper layer HARM nodes (i.e., the hosts) are created and each vulnerability group is assigned to the belonging hosts.
3. based on the vulnerability connections in the AG, the upper layer HARM
nodes establish connections between them.
4. separated vulnerability information is now only associated with its belonging
host information in the upper layer.
For example, three vulnerabilities belongs to the NAT gateway server (i.e.,
CVE-2003-0693, CVE-2007-4752 and CVE-2008-0166). The CVE-2008-0166 and

588

J.B. Hong et al.

Fig. 5. Transforming an AG to a HARM

CVE-2007-4752 only require the guest privilege, whereCVE-2003-0693 requires
the VM user privilege. Therefore, those vulnerabilities requiring diﬀerent privileges can be separated but still under the same host (i.e., multiple entry and exit
points in the lower layer model). Once, all lower layer vulnerability information
is grouped, then the upper layer host can be connected based on the privilege
requirements (e.g., Gateway root privilege is required to exploit vulnerability in
the Admin Server, and the VM guest privilege is acquired exploiting the CVE2007-4752, so the NAT gateway node connects to the VM and Admin Server
nodes in the upper layer). These steps are shown in Fig. 5.

3

Security Analysis Using Various Security Metrics

In this section, we demonstrate the analysis process of the HARM with various
security metrics. Similarly with the conditional probability calculation described

Scalable Network Intrusion Detection and Countermeasure Selection

589

Fig. 6. Pseudo code of LRAwFPC
Table 2. ROI of countermeasures applied in the example Cloud
CVE-2008-4050 CVE-2003-0693 CVE-2008-0015 CVE-2010-3847
CM1 NA

NA

5.03

1.97

CM2 0.28

0.28

9.5

3.72

CM3 0.15

NA

8.94

3.5

CM4 0.09

0.09

3.91

1.53

in Sect. 2.2, the cumulative probability of an attack success can be calculated
using the Equation (3).

(1 − P r(s))
P rn = 1 −
(3)
s∈W

The beneﬁt and return on investment (ROI) are calculated on the basis of
four commonly used virtual networking based countermeasures; (a) CM1: Traﬃc
isolation (intrusiveness: 4, cost: 2, eﬀectiveness: 0.90), (b) CM2: Create ﬁltering
rules (intrusiveness: 1, cost: 2, eﬀectiveness: 0.85), (c) CM3: MAC address change
(intrusiveness: 2, cost: 1, eﬀectiveness: 0.80), and (d) CM4: Network Reconﬁguration (intrusiveness: 1, cost: 5, eﬀectiveness: 0.70). The values of those countermeasures are randomly assigned to demonstrate the computations of the beneﬁt
and ROI. When a countermeasure is applied, the change in probability of an
attack success measures the beneﬁt of the countermeasure. In addition, the ROI
measures the ratio between the beneﬁt with cost and intrusiveness of the countermeasure. On the basis of ROI, the optimal countermeasure can be selected
with the algorithm shown in Fig. 6 using the HARM.

590

J.B. Hong et al.

For example, we assume that the attacker has gained the VM user privilege
(i.e., the probability of attack success to compromise the VM user privilege
equals to one). Then the model computes the possible attack paths from the
given information. The attacker can exploit (i) CVE-2008-0015, or (ii) CVE2010-3847, or (iii) compromise NAT gateway root privilege (CVE-2003-0693),
admin server guest privilege via the mail server (CVE-2004-0840 and CVE-20011030) to exploit CVE-2008-4050 to compromise the admin server root privilege.
At the current state without any countermeasures applied, the probability of
an attack success to compromise the root privilege of the admin server is 0.912
(calculations omitted due to space limitations).
If we apply MAC address change to the admin server (i.e., CM3), then the
probability of an attack success at the HARM lower layer node CVE-2008-4050
reduces from 0.071 to 0.014 (i.e., the original probability × (1 - the eﬀectiveness
of MAC address change) = 0.071 * (1-0.8) = 0.014). Then, ﬁnal probability of an
attack success becomes 0.906 as shown in Equation (4) (i.e., taking into account
two other attack paths through exploiting CVE-2008-0015 or CVE-2010-3847).
Hence, the beneﬁt of applying the MAC address change to the admin server is
0.596 % (i.e., the change in probability), and the ROI is 0.1986. Table 2 shows
the ROI of other example countermeasures applied. The optimal solution in
the example is to apply CM2 on the VM host to mitigate attacks exploiting
CVE-2008-0015 vulnerability.
P rCM 3 = 1 − ((1 − P rCV E−2008−4050 ) × (1 − P rCV E−2008−0015 )×
(1 − P rCV E−2010−3847 ))
= 1 − ((1 − 0.014) × (1 − 0.776) × (1 − 0.576))

(4)

= 0.906

4

Conclusion

Various security frameworks are proposed to strengthen the security of the virtual network systems such as the Cloud. One of the major challenges of the
Cloud security framework is to provide time-eﬃcient and cost-eﬀective countermeasures to mitigate cyber attacks, and previous work incorporated security
models to address this problem. However, traditional security models do not scale
for a large number of hosts in the Cloud, as well as not capable of dynamically
adjusting to changes.
To address these problems, we incorporated a scalable security model named
the HARM in the NICE Cloud security framework. First, we demonstrated the
equivalent security analysis to an AG and second, we described methods to
transform the existing AGs into the HARM. Lastly, we showed security analysis
using various security metrics. In conclusion, this work provides a step closer
towards scalable network intrusion detection and countermeasure selection in
the virtual network systems.

Scalable Network Intrusion Detection and Countermeasure Selection

591

Acknowledgments. This research was sponsored by NSF grant #1528099, and also
supported by the NATO Science for Peace & Security Multi-Year Project (MD.SFPP
984425).

References
1. Beale, J., Deraison, R., Meer, H., Temmingh, R., Walt, C.: The NESSUS Project.
Syngress Publishing (2002). http://www.nessus.org
2. Chung, C., Khatkar, P., Xing, T., Lee, J., Huang, D.: NICE: network intrusion
detection and countermeasure selection in virtual network systems. IEEE Trans.
Dependable Secure Comput. 10(4), 198–211 (2013)
3. Hong, J.B., Kim, D.S.: Performance analysis of scalable attack representation models. In: Janczewski, L.J., Wolfe, H.B., Shenoi, S. (eds.) SEC 2013. IFIP AICT, vol.
405, pp. 330–343. Springer, Heidelberg (2013)
4. Hong, J., Kim, D.: Scalable security models for assessing eﬀectiveness of moving target defenses. In: Proceedings of the 44th Annual IEEE/IFIP International
Conference on Dependable Systems and Networks (DSN 2014), pp. 515–526, June
2014
5. Khan, A., Kiah, M.M., Khan, S., Madani, S.: Towards secure mobile cloud computing: a survey. J. Future Gener. Comput. Syst. 29(5), 1278–1299 (2013)
6. Kordy, B., Mauw, S., Radomirović, S., Schweitzer, P.: Foundations of attack–
defense trees. In: Degano, P., Etalle, S., Guttman, J. (eds.) FAST 2010. LNCS,
vol. 6561, pp. 80–95. Springer, Heidelberg (2011)
7. Lippmann, R., Ingols, K.: An Annotated Review of Past Papers on Attack Graphs.
ESC-TR-2005-054 (2005)
8. McKeown, N., Anderson, T., Balakrishnan, H., Parulkar, G., Peterson, L., Rexford,
J., Shenker, S., Turner, J.: OpenFlow: enabling innovation in campus networks.
SIGCOMM Comput. Commun. Rev. 38(2), 69–74 (2008)
9. Mell, P., Grance, T.: SP 800–145. The NIST Deﬁnition of Cloud Computing. Technical report, NIST, Gaithersburg, MD, United States (2011)
10. Modi, C., Patel, D., Borisaniya, B., Patel, H., Patel, A., Rajarajan, M.: A survey of
intrusion detection techniques in Cloud. Netw. Comput. Appl. 36(1), 42–57 (2013)
11. National Institute of Standards and Technology: National Vulnerability Database.
https://nvd.nist.gov/
12. Ou, X., Govindavajhala, S.: MulVAL: a logic-based network security analyzer. In:
Proceedings of the 14th USENIX Security Symposium (USENIX Security 2005),
pp. 113–128 (2005)
13. Patel, A., Taghavi, M., Bakhtiyari, K., JúNior, J.C.: An intrusion detection and
prevention system in cloud computing: a systematic review. J. Netw. Comput.
Appl. 36(1), 25–41 (2013)
14. Pham, C., Estrada, Z., Cao, P., Kalbarczyk, Z., Iyer, R.: Reliability and security monitoring of virtual machines using hardware architectural invariants. In:
Proceedings of IEEE/IFIP International Conference on Dependable Systems and
Networks (DSN 2014), pp. 13–24 (2014)
15. Poolsappasit, N., Kumar, V., Madria, S., Chellappan, S.: Challenges in secure
sensor-cloud computing. In: Jonker, W., Petković, M. (eds.) SDM 2011. LNCS,
vol. 6933, pp. 70–84. Springer, Heidelberg (2011)
16. Popovic, K., Hocenski, Z.: Cloud computing security issues and challenges. In: Proceedings of the 33rd International Convention on Information and Communication
Technology, Electonics and Microelectronic (MIPRO 2010), pp. 344–349, May 2010

592

J.B. Hong et al.

17. Sheyner, O., Haines, J., Jha, S., Lippmann, R., Wing, J.: Automated Generation
and Analysis of Attack Graphs. Technical report, CMU (2002)
18. Subashini, S., Kavitha, V.: A survey on security issues in service delivery models
of cloud computing. J. Netw. Comput. Appl. 34(1), 1–11 (2011)
19. Vaquero, L., Rodero-Merino, L., Moran, D.: Locking the sky: a survey on IaaS
cloud security. J. Comput. 91(1), 93–118 (2011)
20. Vieira, K., Schulter, A., Westphall, C., Westphall, C.: Intrusion detection for grid
and cloud computing. IT Prof. 12(4), 38–43 (2010)
21. Vigo, R., Nielson, F., Nielson, H.: Automated Generation of Attack Trees. In:
Proceedings of IEEE Computer Security Foundations Symposium (CSF 2014), pp.
337–350, July 2014
22. Wang, P., Lin, W., Kuo, P., Lin, H., Wang, T.: Threat risk analysis for cloud
security based on attack-defense trees. In: Proceedings of the 8th International
Conference on Computing Technology and Information Management (ICCM 2012),
vol. 1, pp. 106–111, April 2012
23. Williams, D., Harland, J.: Virtualization with Xen(tm): Including XenEnterprise,
XenServer, and XenExpress, 1st edn. Syngress Publishing, Rockland (2007)
24. Zhu, Y., Hu, H., Ahn, G., Huang, D., Wang, S.: Towards temporal access control
in cloud computing. In: Proceedings of Annual IEEE International Conference on
Computer Communications (INFOCOM 2012), pp. 2576–2580 (2012)

Secure Pairwise Key Establishment in
Large-Scale Sensor Networks: An Area
Partitioning and Multigroup Key
Predistribution Approach
DIJIANG HUANG
Arizona State University
and
DEEP MEDHI
University of Missouri–Kansas City

Existing pairwise key establishment schemes for large-scale sensor networks are vulnerable to various passive or active attacks. We classify attacks as selective node capture attacks, node fabrication
attacks, and insider attacks. In order to improve the security robustness of random key predistribution and pairwise key establishment schemes against these attacks, we propose a five-phase
pairwise key predistribution and pairwise key establishment approach by using area partitioning and multigroup key predistribution. Our security performance studies show that our proposed
approach is resilient to selective node capture and node fabrication attacks, and restricts the consequence of any insider attack to a minimal level.
Categories and Subject Descriptors: C.2.0 [Computer-Communication Networks]: General—
Security and protection (e.g., fire walls); C.2.4 [Computer-Communication Networks]: Distributed Systems—Distributed applications
General Terms: Security
Additional Key Words and Phrases: Sensor, selective node capture, node fabrication, insider attack
ACM Reference Format:
Huang, D. and Medhi, D. 2007. Secure pairwise key establishment in large-scale sensor
networks: An area partitioning and multigroup key predistribution approach. ACM Trans.
Sens. Netw. 3, 3, Article 16 (August 2007), 34 pages. DOI = 10.1145/1267060.1267064
http://doi.acm.org/10.1145/1267060.1267064

Authors’ addresses: D. Huang, Computer Science and Engineering Department, Arizona State
University, 699 S. Mill Ave. Suite 470, Tempe, AZ 85287-8809; email: dijiang@asu.edu; D. Medhi,
Computer Science and Electrical Engineering Department, University of Missouri–Kansas City,
550F Flarsheim Hall, 5100 Rockhill Road, Kansas City, MO 64110; email: dmedhi@umkc.edu.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is
granted without fee provided that copies are not made or distributed for profit or direct commercial
advantage and that copies show this notice on the first page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior specific
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn
Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org.

C 2007 ACM 1550-4859/2007/08-ART16 $5.00 DOI 10.1145/1267060.1267064 http://doi.acm.org/
10.1145/1267060.1267064
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

16

Article 16 / 2

•

D. Huang and D. Medhi

Fig. 1. Sensor network architecture.

1. INTRODUCTION
Large-scale distributed sensor networks are composed of a large number of
low-power sensor devices, for example, SmartDust [Kahn et al. 1999] and
WINS [Pottie and Kaiser 2000]. Typically, these networks are installed to collect sensed data from sensors deployed in a large area, as shown in Figure 1.
Sensor networks often have one or more centralized controllers called base stations or sinks. A base station, usually many orders of magnitude more powerful
than a sensor, is typically a gateway to other networks or data centers via
high-bandwidth communication links (either leased lines or broadband wireless links). They can be used as a nexus to disseminate control information into
the network or extract data from it. Sensors are constrained to lower-power
and lower-bandwidth usage; thus most deployed sensors may not be able to
communicate with the base station directly requiring sensed data to be aggregated at some forwarding nodes. As a result, communication types should
be either one-to-many to disseminate control commands from the base station to each sensor, or many-to-one to collect sensed data from each sensor to
the base station. For example, as shown in Figure 1, double-head lines form
up/down stream wireless links which connect all aggregation nodes. Aggregation nodes can be dynamically selected, for example, using an election protocol
(e.g., LEACH [Ganesan et al. 2001], TEEN [Manjeshwar and Agrawal 2001],
and PEGASIS [Lindsey and Raghavendra 2002]) where each aggregation node
collects sensor readings from surrounding nodes and forwards a single message
containing aggregated information. In this way, a multihop wireless network
is formed to allow sensors to communicate to the nearest base station. Thus, in
large-scale distributed sensor networks, a critical security service is to provide
direct secure communication channels or links among sensors.
As specified in Akyildiz et al. [2002], the number of sensor nodes deployed
for studying a phenomenon may be on the order of hundreds of thousands.
Depending on the application, the number may reach an extreme value of millions. Due to inherent storage constraints, it is infeasible for a sensor device
to store a unique shared key for every other sensor in the system. A naı̈ve
solution is to use a common key between every pair of sensors which can overcome storage constraints, but offers weak security. In this case, if just a single
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 3

node is compromised, the entire system is compromised. Recently, random key
predistribution (RKP) schemes were proposed [Eschenauer and Gligor 2002;
Chan et al. 2003; Liu and Ning 2003a; Liu et al. 2005c; Du et al. 2003, 2005]
for large-scale distributed sensor networks. These schemes randomly select a
subset of keys from a large key pool for each sensor. Since the RKP schemes
preinstall a limited number of keys in each sensor, after being deployed, a sensor is not guaranteed to share a key with each of its neighbors. Thus a sensor
can establish pairwise keys via those neighbors with which it already shares
preinstalled keying materials. For RKP, a Pairwise Key Establishment (PKE)
protocol is needed to set up shared keys with neighbors.

1.1 Issues of Existing RKP Schemes
For current RKP schemes, analyses of the security strength are done on the
basis of the number of communication links that can be compromised due to
compromised sensors in the network; furthermore, compromised nodes are randomly captured in existing security analysis models. To mitigate the random
node capture attack, Du et al. [2004] and Liu and Ning [2003b, 2005] proposed
using deployment information (sensor location information) to improve the resilience to the node capture attack. However, in practice, the open or hostile
deployment environment of sensor networks makes it easier for attackers to
locate and selectively capture sensors. Moreover, due to the lack of node authentication, attackers can easily fabricate nodes by using the secrets which
are preinstalled in the captured nodes.
It may be noted that PKE protocols are vulnerable to insider attacks, in
which the attacker can fabricate captured sensors, implant malicious codes,
and deploy the fabricated sensors back into the sensor networks. These fabricated sensors can malfunction the PKE protocol by sniffing the encrypted key
message, dropping, forging, and redirecting the key message, etc.

1.2 Overview of Proposed Approach
In this work, we propose a comprehensive solution for the RKP-PKE scheme
to prevent and mitigate various types of attacks. We present our scheme in
five phases. In our scheme, a sensor deployment area is first partitioned into
multiple small square areas (zones) and then sensors deployed in each zone
form a group. This design can restrict the consequence of attacks (such as insider attacks) within a small range. We utilize the unconditionally secure and
λ-collusion resistant properties of the group keying scheme proposed in Blundo
et al. [1998] to construct key spaces and restrict the number of deployed secrets
of a key space to no more than λ. In this way, we can effectively prevent attackers from sniffing traffic and fabricating new sensors via captured keys. To
improve resilience to insider attacks, we propose a source routing-based multipath PKE protocol. This multipath PKE protocol utilizes (n, k) Reed-Solomon
error correcting codes to set up pairwise keys and it is resilient to t = (n − k)/2
paths are faulty.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 4

•

D. Huang and D. Medhi

1.3 Main Contributions
Our main contributions are in two directions:
(1) We propose a λ-restricted area partitioning and multigroup key predistribution scheme to scale the network size due to the key storage constraints
of sensors. Compared to previous work, our scheme can completely prevent
selective node capture attacks. In addition, attackers cannot fabricate new
sensors to set up pairwise keys with uncompromised sensors in our scheme.
Our scheme also restricts the node replication attack within the partitioned
zone where the node is captured. Thus it is more difficult for attackers to
duplicate captured sensors and to distribute them in other zones in order
to compromise the entire sensor network.
(2) We use the multiple node-disjoint-path pairwise key establishment protocol and fault-tolerance coding scheme (Reed-Solomon codes) to improve
resilience to insider attacks, such as stop forwarding and cheating. With
our scheme, a sensor would be able to recover the key establishment message due to packet dropping as well as to identify faulty paths that alter a
forwarded key message.
1.4 Organization
The rest of the article is organized as follows: in Section 2, we present the related work. In Section 3, we highlight the proposed five phases of our pairwise
key setup scheme and attack model. The details of our scheme are presented
in Section 4. From Section 5 to Section 7, we discuss the performance of our
scheme against selective node capture attacks, node fabrication attacks, and
insider attacks. The operational performance assessments such as communication, storage, and computation, are presented in Section 8. In Section 9, we
present a summary of our approach and the security challenges for RKP-PKE
schemes. In the Appendices, we present the mathematical foundations of structured key pool schemes, multipath algorithms, and area partition approaches.
2. RELATED WORK
We broadly classify the random key predistribution (RKP) schemes for sensor
networks into two groups: purely random key predistribution (P-RKP) schemes
and structured key-pool random key predistribution (SK-RKP) schemes. The
P-RKP scheme was first proposed by Eschenauer and Gligor [2002], and we
refer to it as the basic scheme. Several schemes have been developed, all
based on the basic scheme, which improve the basic scheme in five aspects:
(1) shared keys threshold: q-composite scheme [Chan et al. 2003]; (2) key
pool structure: SK-RKP schemes [Liu and Ning 2003a; Liu et al. 2005c; Du
et al. 2003, 2005]; (3) path-key establishment protocol: k-path key establishment schemes [Chan et al. 2003; Zhu et al. 2003]; (4) location awareness
schemes [Liu and Ning 2003b, 2005; Du et al. 2004]: key predistribution
and sensors’ deployment based on known sensors deployment information; (5)
shared keys discovery schemes [Di Pietro et al. 2004; Mehta et al. 2005]: oneway function schemes proposed to reduce the communication overhead during
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 5

the key discovery phase in order to improve resilience to a node fabrication
attack.
Note that the above discussed schemes assume that the attacker randomly
captures sensors in order to compromise the sensor network. However, we argue
that, in reality, attackers are often very smart and might be able to figure
out attacking strategies to maximize gains with minimal attacking efforts. To
analyze more sophisticated attacks, a preliminary analysis of selective node
capture attack and node fabrication attack was presented in Huang et al. [2004].
Before we discuss additional related work, we note a few terms from the
existing literature: if two neighbors share a preinstalled key, the key is called
a direct key. If two neighbors do not share a preinstalled key, they need to
find a path that is protected by direct keys to establish a pairwise key. The
established pairwise key is called an indirect key. To safeguard the indirect
key, multiple key-path schemes have been proposed in Chan et al. [2003] and
Zhu et al. [2003] to prevent faulty sensors from deriving indirect keys. In Chan
et al. [2003], multiple physically link-disjoint paths between two nodes are used
to set up an indirect key. When two nodes u and v want to set up an indirect key
via multiple (say j > 1) link-disjoint paths, the source node, u, selects j secrets,
s1 , . . . , s j , and sends each of these secrets onto a unique key establishment path.
To secure a secret message, s1 , via a key establishment path, u → x → v, the
following key establishment steps are performed:
u → x : {s1 }kux ; x → v : {s1 }kxv ,
where kux and kxv are direct keys shared between pair (u, x) and pair (x, v),
respectively. Upon receiving all the secrets, node v simply uses bitwise XOR
operation to derive the indirect key, that is,
indirect key = s1 ⊕ . . . ⊕ s j .

(1)

In Zhu et al. [2003], multiple logical link-disjoint paths between two nodes
are used for setting up an indirect key. A logical path means that there exists a
key sharing relation among source, destination, and intermediate nodes along
the key establishment path. For example, source node u shares t1 direct keys
with intermediate node x, and node x shares t2 direct keys with destination node
v; note that u and v do not share a direct key. Since a direct key can be only
used for one logical path, there can be z x = min(t1 , t2 ) key establishment paths
between u and v via intermediate node x. The secrets selection and transmission
proposed in Zhu et al. [2003] is similar to that described in Chan et al. [2003].
The difference is the use of physical or logical key establishment paths in the
corresponding proposed schemes.
Both proposed multipath key establishment schemes are efficient to guard
against outsider node capture attacks and insider attacks that passively learn
the forwarded messages. However, they are vulnerable to active insider attacks,
that is, an attacker can stop forwarding secrets or alter the forwarded secrets
which can prevent the receiver from deriving the right indirect key. In order to
counteract insider attacks, we have earlier proposed a Reed-Solomon code and
multipath key establishment protocol to enable a sensor to identify the faulty
key establishment paths in a preliminary study [Huang and Medhi 2005].
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 6

•

D. Huang and D. Medhi

Fig. 2. A taxonomy of RKP-PKE schemes.

The local key-graph connectivity is important for evaluating the communication overhead and storage overhead of a RKP-PKE approach. Random graph
theory-based approaches [Spencer 2001] have been adopted by existing RKPPKE solutions such as that in Eschenauer and Gligor [2002]. In Huang et al.
[2007], it has been shown that the random graph-based solutions introduce
errors when the group size is either big or small. Moreover, the random graphbased solution is unable to provide the key-path length information. These
problems are solved by using a modified binomial distribution in a hop-by-hop
fashion to evaluate the local key graph connectivity for a key path within h
hops. However, multipath key graph connectivity (within 2 hops) and predistribution approaches were not addressed in Huang et al. [2007]—the scope of
this article is to address these aspects along with providing a comprehensive
analysis of node fabrication and node capture attacks.
3. SYSTEM MODELS OF OUR SCHEMES
3.1 A Generalized RKP-PKE Model
Our approach involves five phases, as shown in Figure 2. Here we highlight the
functionalities for each of these five phases:
1. Predeployment phase: A sensor deployment area is first partitioned into multiple subareas. A group of sensors is predetermined for deployment in a
subarea.
2. Key predistribution phase: A centralized key server generates a structure
key pool for each sensor group. A structure key pool is composed of multiple key spaces (key matrices). The key predistribution is described later in
Section 4.2. After key predistribution, each sensor is assigned a unique key
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 7

Fig. 3. A local key graph for sensor 1. kx y represents a direct key between x and y and the dot
circle represents the communication range of sensor 1. In this key graph, node 1 can set up indirect
keys with all its communication neighbors within 3 hops.

ring id. The key ring id can identify the sensor’s position in each key space,
and thus it helps to establish pairwise keys with other sensors in the key
discovery phase and the pairwise key establishment phase.
3. Sensor deployment phase: Sensors are deployed in a two-dimensional plane.
Based on group partitions, each group of sensors are uniformly1 deployed in
each subarea.
4. Key discovery phase: Once sensors are deployed, three steps are involved in
the key discovery phase.
Step 1: Each sensor broadcasts its key-ring id to all its neighbors.
Step 2: Based on the received key-ring id, a sensor can determine
its neighbor-reachability list, and then it broadcasts its neighborreachability list.
Step 3: Based on the received neighbor-reachability list, a sensor can
build a local key graph (shown in Figure 3) which represents the nodeconnectivity from the view of each individual node. We note that, in the
local key graph, if two sensors share a direct key, we refer to it as a link
connecting two sensors directly.
5. Pairwise key establishment phase: In a local key graph, if there is no link
between two sensors, that is, they do not share a direct key, the PKE protocol
will be used to set up an indirect key via multiple hops (i.e., a key path) in
the local key graph. The established pairwise key is called an indirect key.
The indirect key establishment includes two phases:
(a) The key establishment within a zone.
(b) The key establishment among adjacent zones.
In order to counter insider attacks, such as an insider broadcasting
incorrect neighbor-reachability list and dropping and/or altering the
1 For

a discussion on why we emphasize on using uniform distribution, see Section 4.3.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 8

•

D. Huang and D. Medhi

key establishment packets, a multipath key establishment protocol is
proposed.
3.2 Attack Model
As classified in Karlof and Wagner [2003], a laptop-class attacker can have more
powerful devices, like laptops or their equivalents. Thus they have advantages
over legitimate nodes: they may have greater battery power, a more capable
CPU, a high-power radio transmitter, or a sensitive antenna. We assume that
the goal of attackers is to compromise the pairwise keys established or to be
established between any two sensors. Furthermore, the following capabilities
of an attacker are assumed:
—The attacker has unlimited energy and computing power.
—The attacker knows all the information stored in a sensor once the sensor is
captured.
—The attacker can listen to and record all the traffic in the network.
—The attacker has the ability to physically locate a given sensor by listening
to the traffic.
—The attacker has the ability to fabricate similar nodes, and to deploy and
control them.
We classify attacks to RKP-PKE schemes into three categories:
—Selective node capture attack: attacking a communication link2 . Most previous security analysis for RKP-PKE schemes assumes that attackers randomly capture sensors to compromise preinstalled keys. However, the random node-capturing assumption is weak. For example, an attacker can purposefully locate active sensors and compromise the sensors, which can give
her or about him more information the sensor networks; that is, the attacker
wants to capture the minimal number of sensors to compromise the maximum number of preinstalled keys. To evaluate the resilience to selective node
capture attack of a RKP-PKE scheme, we measure its security performance
by computing the fraction of the number of compromised network links by
capturing x nodes, where the compromised network links do not include the
links connected to x compromised nodes.
—Node fabrication attack: attacking authenticity. The attacker can insert new
nodes into the network after obtaining some secret information. This is a
serious attack since the compromise of even a single node might allow an
attacker to populate the network with clones of the captured node to such an
extent that legitimate nodes could be outnumbered and the attacker could
thus gain full control of the network. We evaluate the resilience toward node
fabrication by estimating the fraction of total uncompromised sensor nodes
that can set up communication links with the fabricated nodes by capturing
x nodes.
2 We

consider a communication link as a direct communication channel between two neighboring
sensors protected by a pairwise key. Once the pairwise key is compromised, the corresponding
communication link is compromised.

ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 9

Table I. Notations
a
r
(i, j )
Z (i, j )
Nb (i, j )
nz
u, v
[(i, j ), u]
n
N
P
P(i, j )
P
m
λ
ω
τ
D
G
A
K
p1
Cx
x
R(x)

Notations for sensor deployment
Size of a zone
Sensor communication radius
Zone indexed by i and j
Zone (i, j )
Number of neighbors of sensor b deployed in Z (i, j )
Number of nodes in a group
Sensors u and v
Sensors u’s id
Number of neighbors of a sensor
Total number of deployed sensors
Notations for probabilities of key predistribution
A large key pool
Key spaces associated with group G(i, j )
Size of the key pool, P = |P|
Number of keys preinstalled in a sensor
Distribution threshold of a key space
Number of key spaces
Number of subkey spaces selected for each sensor
A secret matrix size of (λ + 1) × (λ + 1)
A publicly know matrix size of (λ + 1) × N
A secret matrix = (D · G)T
A key matrix = A · G
Probability that two sensors share a preinstalled key
Notations for attacks
Number of compromised keys by compromising x nodes
Number of compromised nodes
Fraction of compromised links among uncompromised nodes

—Insider attack: attacking the PKE protocol. Since the indirect keys are established via multiple key paths set up during the key discovery phase, the
attacker can capture the indirect keys by helping uncompromised nodes to
set up pairwise keys. Before the attacker deploys this attack, it itself must
be a valid node (an insider) in the system (e.g., via node fabrication attack).
We evaluate this attack in terms of the probability that an indirect key is
compromised due to x compromised nodes. Resilience to insider attacks can
be achieved by using our proposed multiple node-disjoint-path PKE scheme
discussed in Section 7.
Note that existing RKP-PKE approaches are all vulnerable to the above
attacks.
4. USING AREA PARTITIONING, MULTIGROUP KEY PREDISTRIBUTION,
AND MULTIPATH PKE
In this section, we elaborate on our five-phase pairwise key establishment
scheme. The proposed area partitioning, group partitioning, and SK-RKP
scheme will be able to determine the size of a zone (subarea) and the maximum
number of sensors deployed within a zone. The security goals of our approach
are to counter any selective node capture attacks, node fabrication attacks, and
insider attacks. The notations used in the following sections are given in Table I.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 10

•

D. Huang and D. Medhi

Fig. 4. Sensor deployment in a grid structure.

4.1 Phase 1: Area Partitioning and Group Partitioning
We assume that the sensor deployment area is a two-dimensional rectangular region with the size (i · a)( j · a) square meters. The rectangular region can
be further divided into (i × j ) deployment areas, each of size a2 square meters. We denote each small deployment area as a zone Z (i, j ). An example of a
deployment region is shown in Figure 4, where i = j = 6.
We use G(i, j ) to denote the group of sensors deployed in the zone Z (i, j ).
We assume that the sensors are uniformly distributed over the deployment
area for each group, and the number of sensors in a group is nz . We denote the
total number of sensors in the entire deployment region by N . Thus, we have
N = nz · i · j . A sensor is identified by [(i, j ), u], where (i, j ) is the group id ,
and u is the unique node id, where u = 1, . . . , N . We use ρ = nz /a2 , where ρ
is a constant under the assumption of uniform distribution, to represent the
density of the sensor deployment within a zone. If the density ρ is given (based
on the manufacture’s information), the size of a zone must fulfil the inequality
a2 ≤ nz /ρ.

(2)

In phase 2, we will use the SK-RKP scheme for the key predistribution
scheme within a zone (the detailed description of SK-RKP scheme is given
in Appendix A). To achieve the noncolluding3 property, no more than λ sensors
3 The

noncolluding feature of the proposed pairwise key scheme is described as follows: for all
pairwise keys kuv , where kuv is the pairwise keys that can be derived from the secrets possessed
by sensors u, v ∈ S, where S is the set of all sensors deployed in the system, all sensors in the set
S \ {u, v} cannot derive the pairwise key kuv .

ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 11

are allowed to choose a given key space, where λ is a parameter of the SK-RKP
scheme and λ restricts the size of a key matrix.
According to Blundo et al. [1998], for each key space, the key matrix A is an
N × (λ + 1) matrix. If an attacker has knowledge of more than λ rows, the entire
matrix A can be derived. Thus we restrict the number of rows distributed to
sensors for each key matrix A to be no more than λ. Under this restriction, we
have the relation
nz ≤ λω/τ,

(3)

where ω is the total number of key matrix within a key pool, and τ is the number
of key matrices selected by a sensor. Once ω and τ are determined, the zone size
increases linearly with the increase of λ. From (2) and (3), we can derive the
relation between zone size a2 and key matrix parameters:
a2 ≤ λω/(τρ).

(4)

4.2 Phase 2: Key Predistribution
The key predistribution scheme used within a group is called the I-Scheme
and the key predistribution scheme used between two neighboring groups is
called the E-Scheme. The schemes are presented as follows:
4.2.1 I -Scheme.
(i) Key pool P is composed of multiple subkey pools. Each subkey pool is
associated with a small partitioned area and a subkey pool is represented
as P(i, j ). By using the SK-RKP scheme, each subkey pool is divided into
ω key spaces. A key space is an N × (λ + 1) key matrix A. Each element of
A is a unique key.
(ii) Divide the N sensors in groups. According to the partitioned area, a group
is represented by G(i, j ).
(iii) Assign unique identifiers to the sensors. For each sensor, assign the id =
[(i, j ), u], where (i, j ) is the group id, and u = 1, . . . , N .
(iv) For sensor [(i, j ), u], randomly select τ key spaces from ω key spaces in
P(i, j ) while making sure that the selected subkey space is not already
selected λ times; load the sensor with the uth row of matrix A for each
selected subkey space.
For details about the SK-RKP scheme, refer to Appendix A.
4.2.2 E-Scheme. For the E-Scheme, as shown in Figure 4, a zone can have
the maximum of eight neighboring zones; for example, the bidirectional arrows
are shown around zone Z (3, 3). The key predistribution scheme (E-Scheme) for
sensors in two adjacent zones is given as follows:
(i) For a sensor u in group G(i1 , j 1 ), randomly select one sensor, say v, from
one of its neighboring groups, say G(i2 , j 2 ). Groups G(i1 , j 1 ) and G(i2 , j 2 )
are neighbors if |i1 − i2 | ≤ 1 or | j 1 − j 2 | ≤ 1.
(ii) Install the duple, kuv , id v , in u and the duple, kuv , id u , in v, where key
kuv is unique and id u , id v are the identifiers of node u, v, respectively. Once
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 12

•

D. Huang and D. Medhi

node u selects a peer node v in group G(i2 , j 2 ), it cannot select another node
in the same group.
(iii) If every sensor has selected a node in each of its neighboring groups, stop;
otherwise go to (i).
Using the E-scheme, each sensor maintains a unique key shared with a single
node in each of its neighboring zones.
4.3 Phase 3: Sensor Deployment
We assume that sensors in group G(i, j ) are uniformly deployed within the zone
Z (i, j ). However, we note that the sensor distribution pattern in the real-world
may not follow any pattern due to manual distribution, helicopter drop, and
so on. On the other hand, uniform sensor distribution is an ideal scenario and
should be achieved as the goal via many deployment methods. Due to its simplicity and uniform density within the sensor deployment area, it significantly
simplifies the analysis of many sensor network applications, such as environmental sensing, positioning, and so on. For the scenarios in which obstacles exist
in the deployment area and irregular distribution patterns (cannot be simply
described by one or several probability distribution functions) exist, simulation
is the best way to study the proposed key management scheme. In this article,
we will assume uniform distribution and present an analytical approach for
our proposed key management scheme; consideration of irregular distribution
(as well as which kinds to consider) and its study through simulation is not
within the scope of this article and will be investigated separately and reported
elsewhere.
4.4 Phase 4: Key Discovery
The purpose of key discovery is to set up a local key graph for each sensor (see
Section 3.1, phase 4, and the local key graph example shown in Figure 3). After
deployment, each sensor, say [(i, j ), u], initiates this phase by broadcasting its
identifier [(i, j ), u] and the list of the key spaces selected for sensor [(i, j ), u]. If
two sensors have selected the same key space, they can establish a direct key.
After receiving all neighbors’ ids and establishing the direct keys, sensor u
builds a local key graph that contains all its neighbors as vertices. In a local
key graph, a logical link is created between u and any of its neighbors if they
share a direct key. Then sensor u creates a neighbor list that contains all the
neighbors that the direct keys have set up between them. The neighbor list is
then encrypted by the direct keys and sent to all the nodes in u’s neighbor list.
When a neighbor v receives the neighbor list, it repeats the process, that is, v
encrypts the neighbor list by using the direct key shared between v and each
of the nodes in v’s neighbor list, and then the encrypted neighbor list is sent
out. This process is continued until a node discovers that it is not a neighbor of
the original node u; then the node drops the neighbor list. After receiving the
neighbor list, if v is both listed in u’s neighbor list and the receiver’s neighbor
list, the receiver updates its local key graph by adding a link between the source
node u and the node v; and after receiving all the neighbors’ lists and updating
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 13

the local key graph, the sensor constructs its local key graph that will be used
in pairwise key establishment phase to set up indirect keys.
4.5 Phase 5: Pairwise Key Establishment Protocol
Our proposed PKE protocol consists of two subphases: (1) the key establishment
within a zone, and (2) the key establishment between adjacent zones.
—Key establishment within a zone: For key establishment within the same
zone, using the derived local key graph in the key discovery phase, a sensor can use source routing [Huang et al. 2005], by explicitly specifying the
key path (by listing hops), to send requests and then to establish indirect
keys. The number of neighbors located within the same zone of a node is
determined by the location of the node. Figure 9(a) shows the number of
neighbors within the same zone for a sensor located in Z (i, j ). We need to
have some guarantee that a sensor can establish pairwise keys with the majority of its neighbors; using the probability that a sensor can set up pairwise
keys with n of its neighbors within h hops (for details, refer to Huang et al.
[2007]), we can determine how many keys are required to be preinstalled in a
sensor.
—Key establishment between adjacent zones: After the first phase of key establishment, the system goes into the second phase of the key establishment
process to set up indirect keys with nodes located in the adjacent zones. We
assume that sensors have established pairwise keys with their neighbors in
the same zone. When a sensor wants to set up indirect keys with its neighbors in the adjacent zones, it broadcasts the desired node list. A neighbor
of the requestor within the same zone that already shares a direct key with
the nodes in the requestor’s list acts as a proxy and does the following: (1) it
selects an indirect key for the pair, (2) it encrypts the selected indirect key
by using the pairwise keys already set up between itself and the requestor
and the direct key already shared between itself and the destination node,
(3) it sends the two encrypted messages to the requestor. Upon receiving the
response, the requestor forwards the encrypted pairwise key to the destination node. Note that, during the first phase of PKE, nodes have already set
up pairwise keys to all their neighbors within the same zone; thus, during
the second phase of PKE, as long as there exists one node that has a link to
the neighboring zone, it then can be used as a bridge to set up pairwise keys
to the neighboring zone for all its neighbors. For performance assessments
on PKE protocol, refer to Section 8.
4.5.1 Multipath Pairwise Key Establishment. During the pairwise key establishment phase, an intermediate node may have already been compromised,
that is, it has become an inside attacker. Basically, the target of insider attack
is the PKE protocol. The attacker wants to prevent the sensors from establishing indirect keys or sniffing indirect keys established among uncompromised
nodes. The insider node can behave just like a normal node and record all
passing-through information; this type of an insider attack is called a passive
key-establishment attack. Note that the insider node can also change, drop, or
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 14

•

D. Huang and D. Medhi

Table II. t-Faulty Resilient Multipath Key Establishment Scheme
Preinstalled secrets for each sensor
generator polynomial g (x), 2t roots α1 , . . . , α2t , where n − k = 2t; see; Algorithm B.1 in Appendix B
Key establishment procedure, (n, k) RS codes, multipath scheme
Sender u
Receiver v
(1) Generates p node-disjoint paths between u (1) Uses majority rule to eliminate
bad codeword(s).
and v
(2) Generates key message polynomial m(x); see (2) Composes received key polynomial r(x).
(3) Uses Algorithm B.2 step 2, to identify faulty
Algorithm B.1.
path(s).
(3) Creates k codewords mi	 , i = 1, . . . , k; see
(4) Uses Forney’s algorithm to derive error
Algorithm B.1.
polynomial e(x).
(4) Uses source routing to send at most t
codewords on each path where t = (n − k)/2. (5) Recovers the original message
Polynomial; see Algorithm B.2, step 3.
Properties of proposed multipath key establishment scheme
(1) Resilient to t = (n − k)/2 faulty paths when (n, k) Reed-Solomon [1960] codes are used.
(2) Receiver can identify the faulty key establishment paths.
(3) No interactive communications are required, which is communication efficient.
(4) Reed-Solomon [1960] error correcting codes are computationally efficient: On the order of O(n log2 n);
see Sarwate [1977].

forge PKE messages to malfunction PKE protocol; this type of attack is called
an active key-establishment attack.
In order to counter insider attacks, multipath pairwise key establishment
schemes have been proposed [Chan et al. 2003; Zhu et al. 2003]. However, these
schemes are vulnerable under active key-establishment attacks (see discussion
in Section 2).
To counter active insider attacks, such as stop forwarding and cheating attacks, we propose a multipath pairwise key establishment scheme by using
multiple node-disjoint paths and Reed-Solomon error correcting codes [Reed
and Solomon 1960]. The properties and operational procedures of the proposed
scheme are shown in Table II. The related algorithms are given in Appendix B.
A sensor applies the Reed-Solomon [1960] encoding scheme to partition an
indirect key seed into n codewords.4 Each codeword is transmitted via a different node-disjoint path. Note that, on each hop, the keyword is encrypted by a
pairwise key. The receiver applies the Reed-Solomon [1960] decoding scheme
to identify the faulty key establishment paths and then recovers the original
indirect key seed. The receiver can derive the indirect key based on correctly
receiving at least k codewords, where k ≤ n. The main benefits of our proposed
scheme are as follows:
—The proposed scheme is resilient to t faulty paths. If (n, k) Reed-Solomon
[1960] codes are used, then t = (n − k)/2.
—The receiver can identify faulty key establishment paths.
—No interactive communications are required to identify the faulty key establishment paths, which is communication efficient.
4 A sender uses (n, k) Reed-Solomon[1960] codes to partition a message to n codewords. The receiver

can correctly recover the original message if he/she can correctly receive (n − k)/2 number of
codewords.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 15

The security and performance analysis of our proposed multipath pairwise
key establishment protocol is presented in Section 7.
5. SECURITY PERFORMANCE ANALYSIS I: AGAINST SELECTIVE NODE
CAPTURE ATTACK
In selective node capture attacks, the attacker targets at compromising the
communication links among uncompromised sensors. The consequence of this
attack is the exposure of information transmitted on the compromised communication links. To achieve this goal, the attacker can mount a node capture
attack on a deployed sensor and read secret information (keys) from its memory. These keys may be used among uncompromised sensors; thus we use the
fraction of compromised links among uncompromised sensors to evaluate our
scheme.
In our scheme (described in Section 4.2), we limit the number of distributed
key rows in the key matrix to λ. Thus no matter how many sensors are captured by attackers, they cannot derive the pairwise keys used between uncompromised sensors. We compare our scheme with existing RKP approaches. We
use Rcap (x) to represent the fraction of compromised links among uncompromised nodes, where x is the number of compromised nodes. Thus 1 − Rcap (x)
represents the resilience to selective node capture attacks.
We model the selective attack to the P-RKP scheme by using a heuristic technique (described below). Below, Cx is the cardinality of the set of compromised
keys when x nodes are compromised, and i is a variable. We use B to represent
the value that an attacker uses to inspect and then to decide which sensor to
capture next. Then

 
B =


where

P −Cx
m−i



 
P
m

Cx
i

P −Cx
m−i

 
P
m

Cx
i

(N − x),

(i = 0, . . . , m),

(5)



is the probability that there exists uncompromised nodes and

each of them has m−i keys not already compromised; N − x is the total number
of uncompromised nodes in the system.
The heuristic method is as follows. Initially, when i = 0, an attacker can
arbitrarily capture a sensor and derive m keys preinstalled in the captured
sensor, and then Cx = m. Then, he/she inspects B: if B ≥ 1, he/she continuously captures the nodes with m − i keys that are not already compromised,
and for each capture, Cx is increased by m − i; if B < 1, he/she increases i
by 1 until B ≥ 1. He/she then captures the sensors with m − i keys that are
not already compromised. The attacker continues this process until the condition m = i is fulfilled or the entire key pool is compromised. The condition
B > 1 means there exist uncompromised sensors that have m − i keys which
are not already compromised. Figures 5(a) and 5(b) show the comparison between the selective-node-capture attack (SA) and random-node-capture attack
(RA) to P-RKP schemes when m = 50 and m = 200. The comparative studies show that the selective node capture attack can gain more information
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 16

•

D. Huang and D. Medhi

Fig. 5. Selective attack for RKP schemes.

than the random node capture attack with the same number of captured
sensors.
In the SK-RKP scheme, the attacker can selectively capture sensors that
possess keys within the same key space. Once λ + 1 sensors in a key space
are compromised, all the keys in that key space are compromised. In this fashion, an attacker can incrementally capture the sensors that use the same key
space. Since sensors possess keys from more than one key space, the number
of sensors required to be captured to compromise subsequent key spaces is
less. We use c(i) to represent the average number of additional sensors to be
captured in order to compromise a key space when i − 1 key spaces are already compromised. In order to compromise the first key space, the attacker
needs to capture at least λ + 1 nodes (i.e., c(1) = λ + 1). Since each sensor is
allocated τ key spaces (τ ≥ 2), a captured node also uses an uncompromised
τ −1
key space with probability p	 = ω−1
. Thus, to compromise ith key space, we
have
c(i) = λ + 1 −

i−1


c(k) · p	 ,

2 ≤ i ≤ ω.

k=1
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

(6)

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 17

In Figure 5, we use (6) to show SK-RKP schemes [Liu and Ning 2003a, Liu et al.
2005c; Du et al. 2003, 2005] under the selective node capture attack (SA) and
the random node capture attack (RA). As shown in the figure, the threshold of
the SK-RKP scheme decreases dramatically under the selective node capture
attack. In the figure, the threshold values under SA are 17 with ω = 27, τ = 3,
and m = 50; 67 with ω = 27, τ = 3, and m = 200.
In summary, the security performance under the selective node capture attack of existing RKP and SK-RKP approaches drops dramatically comparing to
the security performance under random node capture attack. However, using
our area partitioning and multi-group deployment approaches (as described
in Section 4), we can completely prevent any selective node capture attacks,
i.e., the attackers cannot compromise any pairwise keys that are used between uncompromised sensors (the performance lines of our scheme should
be Rcap (x) = 0.
6. SECURITY PERFORMANCE ANALYSIS II: AGAINST NODE
FABRICATION ATTACK
The compromised sensors cannot be easily detected since they can set up pairwise keys with uncompromised sensors.5 The sensor network is vulnerable to
this attack due to the lack of an authentication mechanism for large-scale sensor networks. This attack is more severe compared to just replicating captured
nodes as the attacker may have enough information to fabricate sensors with
more than one identity with a single compromised sensor.
If there is a unique and one-to-one verifiable connection between node id and
preinstalled keys, the preinstalled keys can be used as the authentication keys
among sensors. In this section, we will conduct a comparative study of resilience
to node fabrication attacks. The comparative candidates are the key discovery
approaches for P-RKP schemes proposed in Di Pietro et al. [2004] and Mehta
et al. [2005] and our SK-RKP solution.
6.1 Fabricate Compromised Nodes—Nodes Replication
The attacker compromises a sensor and clones the sensor. In fact, the attacker
does not need to clone many sensors but to deploy a Sybil attack [Douceur
2000] by fabricating sensor ids. The Sybil attack is equivalent to deploying
many cloned sensors; note that we do not differentiate the difference between
a Sybil attack and a node-fabrication attack. Due to the lack of a priori knowledge of postdeployment configuration, uncompromised sensors cannot detect
the cloned sensor as an anomalous sensor. This attack can have more severe
consequences compared to the passive listening attacks on communication links
between uncompromised nodes, since the attacker can implant malicious codes
in replicated sensors to cause the PKE protocol to malfunction. This is a typical
form of an insider attack which will be discussed further in Section 7.
5 Several

anomaly detection approaches to malicious sensors [Parno et al. 2005; Du et al. 2006;
Liu et al. 2005a] have been recently proposed. However, this article does not focus on anomaly
detection.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 18

•

D. Huang and D. Medhi

6.2 Fabricate Uncompromised Nodes
In this attack, the attacker compromises only a few sensors and uses the captured keys to fabricate sensors with new identities. Then the attacker can deploy the fabricated nodes in the network. The uncompromised sensors in the
network cannot detect the fabricated nodes as anomalous nodes as long as they
can set up pairwise keys with them. This attack is more severe compared to a
passive eavesdropping attack as the attacker may have enough information to
fabricate many sensors with many different identities and possibly outnumber
the original set of sensors.
6.2.1 Node Fabrication Attack on the P-RKP Scheme. The attacker can
launch the node fabrication attack on the P-RKP scheme by capturing only a
few sensors. Since there is no identity authentication in the P-RKP scheme
[Eschenauer and Gligor 2002; Chan
 et al. 2003], by capturing two nodes, the
attacker can fabricate and deploy 2m
new nodes without being detected. These
m
fabricated nodes are apparently good nodes, since they all have valid keys.
Thus the fabricated nodes can quickly outnumber the uncompromised nodes.
To mitigate the node fabrication attack, Di Pietro et al. [2004] and Mehta et al.
[2005] proposed using a one-way function to distribute and discover the shared
keys. The basic idea behind their approaches is to use a node id as the input to a
one-way function multiple times and the generated chain values modulo the size
of key pool can be used to identify the key id in the key pool. Using an one-way
function to identify the keys can be used in both the key predistribution phase
and the key discovery phase. Mehta et al. [2005] used simulation to prove this
method is equivalent to randomly selecting keys from a large key pool. In this
way, a connection is built between the node id and preinstalled keys via the oneway function. As a result, attackers cannot arbitrarily fabricate sensors since
they must possess the preinstalled keys that are identified by the hash-chain
values.
Although one-way function-based key discovery approaches can mitigate the
node fabrication attack, the attackers can still fabricate sensors without being
detected. To fabricate a sensor, the attacker must compromise enough sensors
to find a node id that can be used to set up communication links with uncompromised nodes. In order to connect to the network via an uncompromised node,
the fabricated node needs to satisfy the following conditions: (a) it should share
the required number of keys with the uncompromised node when q-composite
scheme is used; (b) if condition (a) is satisfied, all shared keys not only must be
known to the attacker, but they must also be in the right sequence. The probability that a fabricated node satisfies the above two conditions with x captured
nodes is computed as
 P m P −m  i
m

Cx
1
m i
m−i
p f (x) =
,
(7)


2
P
pconnect i=q
P
m

−m
	m (mP )(mi)( Pm−i
) is the probability that i keys are shared between two
where i=q
P 2
(m)
nodes, Cx = [1 − (1− m
)x ]P is the number of keys compromised due to capture
P

ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 19

Fig. 6. Node fabrication attack to one-way function key discovery approach and SK-RKP approach:
m = 200, ω = 27, τ = 3, p1 = 0.3.

of x nodes, and x is the number of captured nodes. Thus (Cx /P )i = ([1−(1− m
)x ])i
P
is the probability that all i keys are compromised due to x captured nodes, and
pconnect is the probability of node connectivity for q-composite schemes given in
(8):
pconnect = p(q) + p(q + 1) + · · · + p(m),

(8)

where p(q) is the probability that two nodes have exactly q keys in common.
The probability p(q) is presented in Chan et al. [2003] and is given as
 


p(q) =

P
q

P −q
2(m−q)

 2
P
m

2(m−q)
m−q

.

Using (7) we draw Figure 6. It shows the fraction of uncompromised nodes that
can be used by fabricated nodes to connect to the system when q = 1, 2, 3.
Since the one-way function key discovery approach cannot totally prevent the
attacker from fabricating new nodes and the derived shared key is not unique,
we cannot use the direct key of the P-RKP scheme for authentication purposes.
6.2.2 Node Fabrication Attack on the SK-RKP Scheme. The SK-RKP
scheme is also vulnerable to the node fabrication attack. However, there are
some restrictions on the attacker. First, the attacker is required to capture
more than λ sensors in order to compromise a key space. Second, the attacker
cannot arbitrarily generate new id’s for the fabricated sensors, since the id’s
indicate the rows of the key matrix A. The wrong id cannot set up the pairwise
key between the fabricated sensor and the uncompromised sensor. If we restrict
the number of distributed rows of a key matrix A to no more than λ, we can
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 20

•

D. Huang and D. Medhi

prevent the node fabrication attack. Even if the attacker can compromise all
deployed sensors, she/he cannot derive new rows of any key matrix. The previous proposals [Liu and Ning 2003a; Liu et al. 2005c; Du et al. 2003, 2005]
cannot fulfil this requirement due to the large size of sensor networks. For example, if we stay with the restriction that no more than λ rows of any key space
are allowed to be distributed to sensors, for a given ω, τ , and λ, the maximum
number of sensors that can be deployed is λ·ω
. We can easily derive that the
τ
supported network size nz is linearly increased with respect to the increase of
the λ.
6.3 Countermeasures to Node Fabrication Attack
In Figure 6, using the SK-RKP scheme, zero fraction of the network is compromised when x = 0–67. This property of the SK-RKP scheme allows us to
design an authentication protocol for the key discovery phase. Recall from Section 6.2.2 that, to restrict the number of sensors that are allowed to install keys
from a given key space, the size of supported network is also restricted. Thus,
if we partition a large sensor network into multiple small areas, we can utilize
the perfect security property of the SK-RKP scheme within each zone.
Note that, in Section 4, we have proposed to use a unique structured key pool
for each zone and to restrict at most λ rows of a key space that are distributed
to sensors. Our scheme is resilient to node fabrication attacks (including node
replication attacks) due to the following two facts: (a) since no more than λ
key rows are distributed to sensors within a zone, attackers cannot fabricate
uncompromised sensors. Thus, attackers can only replicate captured sensors.
(b) Since the key matrix used for one zone is different from those used for other
zones, the attacker cannot deploy the replicated sensors to the other zones.
Thus, the replication attack is restricted within a relatively small area, that is,
the replicated nodes can only setup pairwise keys with uncompromised sensors
within the zone where it was captured.
7. SECURITY PERFORMANCE ANALYSIS III: AGAINST INSIDER ATTACK
An important question that we want to answer is: in what scenarios do we
want to use multipath routing instead of single-path routing? In other words,
what is the condition when multipath routing is preferred over single-path
routing? To see this, we need to evaluate the multipath success probability
Psucc , given the single-path success probability q and the number of paths. We
have found an evaluation model developed by Tsirigos and Haas [2004] to be
applicable to our scenario. When uniform codeword allocation is applied, we
have
n  

n i
Psucc =
p (1 − p)n−i ,
(9)
i
i=k
where (n, k) is the Reed-Solomon [1960] coding scheme and p is the probability
that a receiver successfully receives a codeword from a path.
In our analysis, we assume that each path has the same success probability
q = 0.1, . . . , 0.9, and that exactly one codeword is sent through a path; we
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 21

Fig. 7. Evaluating multipath success probability Psucc where the number of faulty paths is up to
1, 2, 3, and 4.

consider the number of faulty paths to be 1, 2, 3, and 4. In Figures 7 through 7(d),
we plot success probabilities Psucc of the total number of paths from three paths
to 10 paths. We have the following observations:
—Using Reed-Solomon codes, we can use the majority rule to filter out
bad parity codes. Thus a four-path multipath routing does not give any
benefit compared to a three-path multipath routing. We observe similar
behavior with six and five paths, eight and seven paths, 10 and nine
paths. This is since faulty nodes on different paths can collude to generate the same parity codes, and it can create uncertainty at the destination
node.
—The success probability of the even number of paths is always lower than
that for the corresponding odd number of paths. Thus we use odd numbers
of paths in our schemes.
—Using our (n, k) Reed-Solomon multipath coding scheme, we observe that
bigger the value of n results in Psucc to be higher when the number of paths
k is fixed.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 22

•

D. Huang and D. Medhi

Fig. 8. Success probabilities for (17, 9), (13, 7), (9, 5), and (5, 3) RS multipath coding schemes.

In order to decide whether to apply multipath routing or single-path routing, we plot the success probabilities for (17, 9), (13, 7), (9, 5), and (5, 3)
Reed-Solomon multipath coding schemes in Figure 8. When Psucc ≥ q, the performance of multipath routing is better than single-path routing. For example,
if the (5, 3) Reed-Solomon coding scheme is used, we observe that the success
probabilities q of single-path routing are always greater than the corresponding multipath success probability Psucc when q < 0.5. The same behavior is observed in the cases of (17, 9), (13, 7), (9, 5), and (5, 3) Reed-Solomon multipath
coding schemes. Thus, in the case of uniform block allocation and uniform success probability distribution, we conclude that multipath routing is preferred
to single-path routing when the number of paths increases and path success
probability q > 0.5.
It may be noted that the adversaries can intentionally capture sensors located at area borders to compromise the PKE procedures. However, based on our
analysis in Section 8.1.2, the border sensors can also have high probabilities to
set up multiple 2-hop paths to the neighbor zone. In addition, our proposed multipath PKE scheme can relieve the insider attacks due to compromised nodes.
8. OPERATIONAL PERFORMANCE ASSESSMENTS
8.1 Local Key Graph Connectivity
We now present the local key graph connectivity analysis for sensors located
within the same zone and in adjacent zones. Our analysis is based on the following assumptions:
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 23

—The area covered is a two-dimensional Cartesian plane. A zone is represented
by an area x ∈ [0, a], y ∈ [0, a], where (x, y) is a point in the two-dimensional
Cartesian plane.
—All sensors have equal communication radius, R, and hence cover the same
size of area, where R ≤ a/2.
—The sensors are uniformly distributed in a deployment region and the average
number of neighbors for each sensor is n	 . The density of the deployed sensors
	
is ρ = πnR 2 .
According to the assumption presented above, the number of deployed sensors
2 	
within each zone is nz = a2 ρ ≈  πa Rn2 
. For our analysis, we consider R = 40 m,
and a = 100 m.
—Sensor coverage—within the same zone. We first consider the coverage of
sensor [(i, j ), b] in its zone Z (i, j ). Given a position (x, y) for sensor [(i, j ), b],
the sensor coverage is given as follows:



Cb1 (i, j )|(x, y) , 0 ≤ x 2 + y 2 ≤ R;

Cb(i, j )|(x, y) =
Cb2 (i, j )|(x, y) , R < x 2 + y 2 ≤ a/2.
The expressions for Cb1 (i, j ) and Cb2 (i, j ), along with the proofs are given in
Appendix C. From these results, the number of neighbors of sensor [(i, j ), b]
within the zone Z (i, j ) can be obtained as:
Nb(i, j ) = ρ · Cb(i, j ),

(10)

where Nb(i, j ) is the number of neighbors of sensor [(i, j ), b] within the zone
Z (i, j ). In Figure 9, we show the contour curves of the average number of
neighbors of sensor [(i, j ), b] within the zone Z (i, j ).
—Sensor coverage—in different zones. In Figure 9(a), we show that there are
eight possible zones surrounding zone Z (i, j ). We use superscripts + and −
to represent the area coverage and sensor coverage between two neighboring zones. For example Cb(i + , j − ) and Nb(i + , j − ) represent the area coverage and sensor coverage of sensor [(i, j ), b] in zone Z (i + 1, j − 1). Similarly,
Cb(i, j − ) and Nb(i, j − ) represent the area coverage and sensor coverage of sensor [(i, j ), b] in zone Z (i, j − 1). The number of neighbors that node [(i, j ), b]
covers in a neighboring zone is given as
Nb(i ∗ , j ∗ ) = ρ · Cb(i ∗ , j ∗ ),

(11)

where * represents −, +, or none. The representations and proofs of neighboring zone coverage Cb(i ∗ , j ∗ )|(x, y) are given in Appendix D.
8.1.1 Local Key Graph Connectivity Within the Same Zone . The number
of keys preinstalled in each sensor is represented by m. According to the deployment pattern shown in Figure 4, we select a unique key pool for each zone,
that is, P(i, j ) for Z (i, j ). To determine the size of key pool (i.e., |P(i, j )|) and
the number of keys selected (i.e., m = (λ + 1)τ , which will be discussed in Section 8.3) from the key pool for sensor [(i, j ), b], we use the equations of P-RKP
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 24

•

D. Huang and D. Medhi

Fig. 9. In this example, sensors are deployed in a 100 × 100-m2 area and all sensors have the same
transmission radius (40 m).

scheme proposed by Eschenauer and Gligor [2002] and further modified for the
SK-RKP scheme by [Du et al. 2003]:
ωω−τ 
((ω − τ )!)2
p1 = 1 − τ  2τ = 1 −
,
(12)
ω
(ω − 2τ )!ω!
τ

where p1 is the probability that a given two sensors share at least one key.
For sensor [(i, j ), b] in zone Z (i, j ), the number of neighbors within its zone
is Cb(i, j ). As shown in Figure 9(a), if the average number of neighbors of a
sensor, n	 , is 50, the zone has a total of nz = (n	 a2 )/(π R 2 ) sensors and there
are approximately 11 nodes in the zone with fewer than 25 neighbors from the
same zone. If we assume the number of neighbors of a sensor is 25, using the
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 25

local key graph6 connectivity presented in Huang et al. [2007], we derive the
probability p1 = 0.5. When p1 ≥ 0.5, the local key graph is connected with
probability greater than 0.996 within 3 hops. In the worst case, the sensor is
located at the corner of the square area, and has approximately 12 neighbors
within the same zone. In this case, the probability that the local key graph is
connected within 5 hops is 0.8736.
8.1.2 Local Key Graph Connectivity Between Two Adjacent Zones. The
node [(i, j ), b] may be located close to the boundary of two neighboring zones,
Z (i, j ) and Z (i ∗ , j ∗ ). The number of neighbors of node [(i, j ), b] located within
these two zones can be represented by Nb(i, j ) and Nb(i ∗ , j ∗ ). Node [(i, j ), b]
is considered to be connected to the neighboring zone as long as it can find at
least one neighbor, b	 , located in Cb(i, j ) that shares a key with at least one of
nodes, b		 , located in Cb(i ∗ , j ∗ ). Using (10) and (11), we can derive the probability
p(i ∗ , j ∗ ) that sensor [(i, j ), b] can connect to the neighboring zone with the help
of all its neighbors:



nz − Nb(i, j )
nz − Nb(i ∗ , j ∗ )
∗
∗
Nb(i, j )
Nb(i , j )



p(i ∗ , j ∗ ) = 1 −
.
(13)
nz
nz
∗
∗
Nb(i , j ) Nb(i, j )
Note that (10) and (11) are derived from Cb(i, j ) and Cb(i ∗ , j ∗ ), which are the
functions of two-dimensional Cartesian coordinates with the position (x, y).
Thus p(i ∗ , j ∗ ) is the function of (x, y). Using (13), we draw the probability contour curves in Figure 9(b), where a node in Z (i, j ) can connect to its neighboring
zones Z (i, j − ) and Z (i + , j − ) with parameters a = 100 m, R = 40 m, n	 = 50,
nz = 100.
8.1.3 Multipath Connectivity Between Neighboring Zones. Figure 9(b)
shows the contour curves of the probabilities that a node in Z (i, j ) can connect to its neighboring zones Z (i, j − 1) and Z (i + 1, j − 1). The probability that
a node can connect to neighboring zones with the help of exactly k neighbors is
given as follows:


 
nz − Nb(i, j )
nz − Nb(i ∗ , j ∗ )
nz
∗
∗
k
Nb(i, j ) − k
Nb(i , j ) − k



pk (i ∗ , j ∗ ) =
.
nz
nz
∗
∗
Nb(i , j ) Nb(i, j )
The probability that a node can connect to neighboring zones with the help of
at least q neighbors is denoted by pq̂ (i ∗ , j ∗ ) and is given as follows:


pq̂ (i ∗ , j ∗ ) = 1 − p0 (i ∗ , j ∗ ) + · · · + pq−1 (i ∗ , j ∗ ) .
(14)
Figure 9(c) shows the range in which a sensor can connect to its neighboring
zones with at least q links via its neighbors, where q = 1, 2, 3 and the connectivity probability is 0.8. Thus a sensor can randomly select q neighbors that

6 Here,

the local key graph is composed by the sensors within the same zone.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 26

•

D. Huang and D. Medhi

Table III. Relation Between Neighborhood Size and Length of
Key Path
# of Neighbors
50
40
30
25
20
15

# of Hops
2
2
3
3
3
4

Local Key Graph Connectivity
0.9957
0.9806
0.9996
0.9980
0.9893
0.9583

respond to the requests and send the responses to the destination nodes. The
selected q destination nodes can help the sensor set up q paths to any of the
neighbors in the adjacent zone. Thus we can apply our proposed multipath PKE
scheme (see Section 4.5.1) to set up the pairwise keys.
Comparing Figure 9(a) and 9(c), almost all sensors that have fewer than 20
neighbors and some of sensors that have fewer than 25 neighbors can set up
at three connections to the diagonal neighboring zones. The sensors that have
fewer than 35 neighbors within the same zone may set up at three connections
to the horizontal and vertical neighboring zones.

8.2 Communication Overhead Analysis
Here we will derive the mathematical expressions for the probability that a
sensor can set up key paths with all its neighbors within h hops in Huang et al.
[2007]. Since our key establishment procedure includes two phases, the key
establishment within a zone and the key establishment between two adjacent
zones, we analyze the communication overhead for each phase separately.
During the first phase of key establishment, the closer the sensor is to the
center of a zone, the smaller the communication overhead due to key establishment. For example, for τ = 2, ω = 7, Table III shows the number of hops
and the corresponding local key graph connectivity probabilities: As shown in
Figure 9(a), most pairwise keys can be set up within 3 hops. Since the communication overhead is proportional to the number hops of a path, the communication overhead is amplified due to the multipath PKE scheme. As we can
see in Table III, the denser the network, the shorter the key paths when the
probability (i.e., p1 ; see (12)) of sharing preinstalled keys is given.
During the second phase of key establishment, between two adjacent zones,
as shown in Figure 9(c), a sensor can set up q paths to the neighboring zones
with the probability of 0.8. Each path is a 2-hop path. A sensor applies (n, k)
Reed-Solomon coding and partitions a pairwise key in q portions (where n = q),
and then sends them via q key paths. If the destination correctly receives l codewords where l ≥ k or l ≤ (n − k)/2, the pairwise key can be successfully set
up, since all multipaths to the neighboring zone are restricted by 2 hops. Thus
the communication overhead is only doubled compared to 1-hop communications. In addition, the total communication overhead is also proportional to the
number of paths.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 27

8.3 Storage Overhead
Our proposed RKP-PKE scheme utilizes the key predistribution scheme proposed by [Blom 1985] (for a detailed description, see Appendix A). The scheme
is built on two matrices: a publicly known matrix G of size (λ + 1) × N ; a secret
matrix D of size (λ + 1) × (λ + 1) created by key distribution center. The matrix
A of size N × (λ + 1) is then created as A = (D · G)T . Each row of A is the
keys distributed to a sensor and the row number can serve as a sensor’s id.
Our approach requires each sensor to select τ key spaces (see Section 4.2.1).
Thus a sensor is required to store m = (λ + 1)τ keys that are used to set up
pairwise keys within its zone, where λ is restricted by nz = λω/τ . For example,
if τ = 2, ω = 7, and nz = 100, then λ = 29. In addition to the keys selected
from the key matrix A, each sensor is required to install at least one shared key
with a unique sensor in each of its neighboring zones. The maximum number
of neighboring zones is eight. Thus the total number of keys that are needed to
be preinstalled in a sensor is given as
 n τ 

z
m=
+ 1 τ + γ α,
ω
where γ is the number of neighboring zones and α is the number of keys preinstalled for each pair of neighboring zones for a sensor. For all our analysis, we
use the following parameter settings: γ = 8, α = 1. Thus the storage requirement for a sensor is m = 68.
Unlike the P-RKP scheme proposed in Eschenauer and Gligor [2002], which
requires m = 272 to fulfil p1 = 0.5238, our scheme requires m = 68, which
is much less. For the scheme specified in Du et al. [2004], to achieve the p1 =
0.5238, it requires 72 keys preinstalled for each sensor, which is a marginally
higher than our scheme.
Our approach is similar to the group key based solution proposed by Liu
et al. [2005b]. In Liu et al. [2005b], the key predistribution was based on
a two-dimensional group structure where two instances of key distributions
D and D 	 are applied to the vertical structure and horizontal structure, respectively. Thus the storage requirement equals to the summation of key
storage required by both D and D 	 ; and we have |D| + |D 	 | = m, where m
is the maximum storage allocated for storing keys. In our approach, we assume D is the SK-RKP scheme and D 	 is a deterministic key predistribution approach which requires the constant number of keys (i.e., ≤ 8) to be
installed; and we have the relation |D| + 8 = m. Since |D| ≈ |D 	 | in Liu et al.
[2005b], our approach saves approximately 50% space when the group size is
large. This advantage is due to the preknown deployment information of our
approach.
8.4 Computational Overhead Analysis
The computational overhead arises mainly from the secure group key scheme
introduced by the SK-RKP scheme. In our schemes, we reduced the computational overhead significantly as compared to the SK-RKP schemes proposed
in Liu and Ning [2003a], Liu et al. [2005c], and Du et al. [2003, 2005] that do
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 28

•

D. Huang and D. Medhi

not use the location information. For example, by using the SK-RKP scheme
without using location information, for m = 200, τ = 2, and λ = 100, to derive
a pairwise key, the total number of required modular multiplication operations
is 200 (for the detailed description of pairwise key establishment scheme refer to Liu and Ning [2003a], Liu et al. [2005c], and Du et al. [2003, 2005]). In
our scheme, we only need to guarantee the local connectivity within a zone.
We reduce the number of keys preinstalled in a sensor (see the analysis presented in Section 8.3). If we restrict the number of sensors within a zone to
nz = 100, then λ = nz τ/ω
 = 29 where ω = 7, τ = 2. Thus the number of
required modular multiplication operations to derive a pairwise key is only
58.
Finally, we note that public key cryptography algorithms (such as ECC and
RSA) have been implemented in sensors. A general technique to improve the
performance of public key algorithm is to reduce the Hamming weight of a
multiplier (an exponent in RSA). According to Koç [1994], the average number of multiplications involved by the RSA scheme is 32 (k − 1), where k is
the number bits of an exponent. Thus, for the 1024-bit RSA scheme, it requires about 1535 modular multiplications. According to Gura et al. [2004],
in a projective coordinate system, a point addition requires nine multiplication and five squaring operations, and point doubling requires four multiplication and four squaring operations as the most expensive operations. If we
assume that the average number of multiplications of a point addition requires five multiplications, for a 160-bit ECC point multiplication operation,
3
(k − 1) · 5 = 1193 modular multiplications are required. Thus public key2
based schemes involve more computational overhead compared to our proposed
approaches.
9. CONCLUSION
We have proposed a five-phase RKP-PKE solution to counter various sensor network attacks. Our approach has benefitted from three schemes: the λ-restricted
SK-RKP scheme, multiple group/zone sensor deployment, and a Reed-Solomon
code-based k-path PKE protocol. We utilize the initial threshold of the SKRKP scheme and the unique relation between key ring id and predistributed
keys to guard against selective node capture and node fabrication attacks.
RKP-PKE schemes are vulnerable to insider attack. We utilize the multiple
groups/zones to restrict the insider attacks within a relative small range; and
we use the multiple node-disjoint-path PKE protocol and fault-tolerance coding
scheme (Reed-Solomon [1960] codes) to improve the system resilience to insider
attacks.
RKP-PKE schemes have been studied extensively in recent years, but those
studies are still in their infancy since many security and implementation problems have not been solved yet. For example, an insider attack is still the biggest
threat for RKP-PKE schemes and no efficient solutions have been found to
prevent it: a comprehensive study of multipath coding schemes is required;
anonymity issues of wireless sensor networks must be solved; secure rekeying and node replenishment need to be studied; various sensor deployment
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 29

methods—hybrid sensor distribution patterns—need to be studied; no PKE
protocol prototype has been built, and the security services of the PKE protocol
such as confidentiality, integrity, and authenticity are still unclear. It is hoped
that this work can serve as an elicitation for researchers interested in further
investigation into this vital area.

APPENDIX
A. STRUCTURED KEY-POOL RANDOM KEY PREDISTRIBUTION SCHEME
SK-RKP scheme is a modified version of P-RKP scheme. The main differences
are the key pool structure and key discovery method. Unlike in P-RKP schemes,
in the SK-RKP scheme, each sensor is preloaded with a unique set of keys in
its memory. The key discovery is not simply finding a shared key with the
neighboring sensor, but using a set of polynomial variables (constructed by
the keys possessed by the sensor) to derive the shared key. In addition, the
key id can serve as the sensor id which is linked to the set of preinstalled
keys.
The SK-RKP scheme uses the key predistribution scheme proposed by Blom
[1985]. This scheme allows any pair of nodes in a network to find a pairwise
key in a secure way as long as no more than λ nodes are compromised. The
scheme is built on two matrices over a finite field GF(q): a publicly known
matrix G of size (λ + 1) × N ; a secret matrix D of size (λ + 1) × (λ + 1) created
by key distribution center. The matrix A of size N × (λ + 1) is then created as
A = (D · G)T over the finite field GF(q). Each row of A is the keys distributed to
a group member and the row number can serve as a sensor’s id. Since K = A· G
is a symmetric matrix, nodes i and j can generate a shared key (K i j or K j i )
from their predistributed secrets, where K i j is the element in K located in the
ith row and j th column.
A key pool is constructed by many key spaces, represented by A(t) , where
t = 1, . . . , ω. Each sensor randomly selects τ key spaces out of ω key spaces,
where τ < ω. If sensor k selects key space A(t) , the kth row of A(t) and kth
column of G are preinstalled in the sensor (note that the G matrix is unique).
The SK-RKP scheme has following properties:
—Once two nodes i and j have keys preinstalled from the same key space A(t) ,
(t)
they can derive a shared key K i(t)
j = K ji .
—If x rows of a key space A(t) are predistributed to x sensors and x ≤ λ, any
subset of the x sensors cannot collude to derive the secrets in other sensors.
—The id of a sensor is represented by the row number of the key matrix A.
No other sensor can impersonate this sensor, since the row of A is uniquely
distributed to this sensor.
The technical details refer to Liu and Ning [2003a], Liu et al. [2005c], and
Du et al. [2003, 2005].
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 30

•

D. Huang and D. Medhi

B. MULTIPATH ALGORITHMS
Algorithm B.1 Encoding of RS Codes
(1) let m(x) = m0 + m1 x + · · · + mk−1 x k−1 be the message polynomial to be encoded,
where mi ∈ GF (2q ) and k = n − 2t.
g (x) = (x + α)(x + α 2 ) · · · (x + α 2t ) is a publicly known generator polynomial,
where g i ∈ G F (2q ) and g (x) has α, α 2 , . . . , α 2t as roots.
(2)

Dividing x 2t m(x) by g (x), we have x 2t m(x) = a(x) g (x) + b(x), where b(x) =
b0 + b1 x + · · · + b2t−1 x 2t−1 and b(x) is the parity check polynomial.
Then c(x) = b(x) + x 2t is the codeword polynomial for the message m(x)

Algorithm B.2 Decoding of RS Codes
(1) c(x) = c0 + c1 x + · · · + cn−1 x n−1 ,
r(x) = r0 + r1 x + · · · + rn−1 x n−1 ,
e(x) = e0 + e1 x + · · · + en−1 x n−1 ,
where ci , ri , ei ∈ G F (2q ), r(x) is received codeword, and e(x) = r(x) − c(x)
is the error polynomial, where ei = ri − ci is a symbol in G F (2q ).
(2)

Suppose e(x) has v errors at the locations; then e(x) = e j1 x j1 +e j2 x j2 +· · ·+e jv x jv .
Faulty path can be identified by evaluating Si = r(x)|x=αi = r(α i ), i = 1, . . . , 2t,
if Si = 0.
The error-location numbers are X j1 = α j1 , X j2 = α j2 , . . . , X jv = α jv
Using Forney’s algorithm [Wicker 1995], the error values are Y l = e jl , l =
1, . . . , v.

(3)

To recover the the original message c(x), we have c(x) = r(x) − e(x).

C. SENSOR COVERAGE—WITHIN THE SAME ZONE
The covering area of sensor [(i, j ), b] in its zone Z (i, j ) is shown in Figure 10(a).
We can further divide the zone into four areas. The sensor coverage in these
four areas are horizontally and vertically mapped to each other. Within a small
area, there are two scenarios that are shown in the Figure 10(a).
In the first scenario (showing the sensor as located
 at the position (x1 , y 1 )),

the distance between the origin and the sensor is x12 + y 12 ≤ R. The coverage
is composed of a sector with the angle θ1 plus two triangles
 (the shaded areas).

− y1
The θ1 = 32 π −sin−1 B1R−x1 −sin−1 A1 R
, where A1 − y 1 = R 2 − x12 and B1 −x1 =

R 2 − y 12 .
The coverage (the shaded area) of sensor [(i, j ), b] in zone Z (i, j ) is represented as Cb1 (i, j ) and it is computed as follows:

1
θ1
[x1 (A1 − y 1 ) + y 1 (B1 − x1 )] + R 2 .
2
2
In the second scenario (showing the sensor as located
at the position (x2 , y 2 )),

Cb1 (i, j )|(x1 , y1 ) = x1 y 1 +

the distance between the origin and the sensor is x22 + y 22 > R. The coverage
is composed by two triangles (A2 A3 o, B2 B3 o) and two sectors with angles
3
3
− sin−1 y2 −A
. θ3 is given as θ3 =
θ2 and θ3 . θ2 is given as θ2 = π2 − sin−1 x2 −B
R
R
−1 B2 −x2
−1 A2 − y 2
− y2
3
π − sin
− sin
. θ4 and θ5 are given as θ4 = 2 sin−1 A2 R
and
2
R
R

−1 B2 −x2
2
θ5 = 2 sin
, respectively. We note that y 2 − A3 = A2 − y 2 = R − x22
R
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 31

Fig. 10. Zone coverage among differentzones.

and x2 − B3 = B2 − x2 =



R 2 − y 22 . The coverage (the shaded area) of sensor

[(i, j ), b] in zone (i, j ) is represented as Cb2 (i, j ) and it is computed as follows:
⎧
1
3
⎪
[x (A2 − A3 ) + y 2 (B2 − B3 )] + θ2 +θ
R 2 , x ≤ R, y ≤ R
⎪
2 2
2
⎪
⎪
⎨ 1 x (A − A ) + 2π −θ4 R 2 ,
x ≤ R, y > R
2
3
2 2
2
Cb2 (i, j )|(x2 , y2 ) =
2π −θ5
1
2
⎪
y (B2 − B3 ) + 2 R ,
x > R, y ≤ R
⎪
2 2
⎪
⎪
⎩
π R 2,
x > R, y > R.
D. SENSOR COVERAGE—IN DIFFERENT ZONES
D.1 Zone Coverage C(i, j − )
This is shown in Figures 10(b)(a). We first compute the √
area of the triangle A3 A1 b = 12 (|A1 A2 | + |A2 A3 |)|A2 b|, where |A1 A2 | = R 2 − x 2 , |A3 b| =

x
= √ x R , |A2 A3 | = √ x y , and |A2 b| = |A3 b|2 − |A2 A3 |2 .

cos( A3 bA2 )

R2− y 2

R2− y 2
The area of triangle A3 oB1 = 12 |B1 o||A3 o|, where |B1 A3 | = R−|A3 b|, |A3 o|

y − |A2 A3 |, and |B1 o| = |B1 A3 |2 − |A3 o|2 .
 

bA1 = A12bB1 R 2 , where  A2 bA3 = sin−1 Ry ,  A2 A1 b
The area of sector B1


sin−1 Rx ,  A1 bA2 = π2 −  A2 A1 b, and  A1 bB1 =  A1 bA2 +  A2 bA3 .
−

=
=

Thus the shaded area C(i, j ) is given as

Cb(i, j − )|(x, y) = B1
bA1 + B1 A3 o − A3 A1 b
y
 x 
2 
R π
=
+ sin−1
− sin−1
2 2
R
R

x
xy
−
R2 − x2 + 
2
R2 − y 2

 




1
xR
xy
xy

+
R−
− y−
.
y−
2
R2 − y 2
R2 − y 2
R2 − y 2
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 32

•

D. Huang and D. Medhi

D.2 Zone Coverage C(i + , j − )
This is shown in Figure 10(b)(b). We first compute the area of sector B4
bA4 =
π R2

.
Then
we
can
derive
the
following
relations:
the
area
of
sector
B
bA
1
4 =
4

sin−1 ( Ry ) 2
R ; the area of triangle bB1 B3 = 12 R 2 − y 2 y; the area of sector
2
√
sin−1 ( Rx ) 2
B4
bA3 =
R ; the area of triangle bA1 A3 = 12 R 2 − x 2 x. The shaded
2
area C(i + , j − ) is given as
Cb(i + , j − )|(x, y)
= B4
bA4 − B1
bA4 − bB1 B3 − B4
bA3 − bA1 A3 + x y


y
 x  1  
2
2 
πR
R
=
−
sin−1
+ sin−1
−
x R 2 − x 2 + y R 2 − y 2 +x y.
4
2
R
R
2
D.3 Zone Coverage C(i + , j )
This is shown in Figure 10(b)(c). We first
compute the area of triangle B3 B1 b =
1
(|B
B
|+|B
B
|)|B
b|,
where
|B
B
|
=
R 2 − y 2 , |B3 b| = cos( By bB ) = √ y 2R 2 ,
1 2
2 3
2
1 2
2
3
2
R −x

|B2 B3 | = √ x2y 2 , and |B2 b| = |B3 b|2 − |B2 B3 |2 .
R −x

The area of triangle B3 o A1 = 12 |A1 o||B3 o|, where |A1 B3 | = R−|B3 b|, |B3 o| =

x − |B2 B3 |, and |A1 o| = |A1 B3 |2 − |B3 o|2
 B1 bA1

The area of sector A
π R 2 = B12bA1 R 2 , where  B2 bB3 =
1 bB1 =
2π




sin−1 Rx ,  B2 B1 b = sin−1 Ry ,  B1 bB2 = π2 −  B2 B1 b, and  B1 bA1 =  B1 bB2 +
 B2 bB3 .
Thus the shaded area C(i + , j ) is given as follows:
Cb(i + , j )|(x, y) = A
1 bB1 + A1 B3 o − B3 B1 b
x
 y 
R2  π
=
+ sin−1
− sin−1
2 2
R
R

y
x
y
−
R2 − y 2 + √
2
R2 − x2
 
 


1
yR
xy
xy
+
R−√
− x−√
.
x−√
2
R2 − x2
R2 − x2
R2 − x2
REFERENCES
AKYILDIZ, I. F., SU, W., SANKARASUBRAMANIAM, Y., AND CAYIRCI, E. 2002. A survey on sensor networks.
IEEE Commun. Mag. 40, 102–114.
BLOM, R. 1985. An optimal class of symmetric key generation systems. In Proceedings of
EUROCRYPT’84. Lecture Notes in Computer Science, vol. 209. Springer-Verlag, Berlin, Germany, 335–338.
BLUNDO, C., SANTIS, A. D., HERZBERG, A., KUTTEN, S., VACCARO, U., AND YUNG, M. 1998.
Perfectly-secure key distribution for dynamic conferences. Inform. Computat. 146, 1, 1–
23.
CHAN, H., PERRIG, A., AND SONG, D. 2003. Random key predistribution schemes for sensor networks. In Proceedings of the 2003 Symposium on Security and Privacy. IEEE Computer Society
Press, Los Alamitos, CA, 197–215.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secure Pairwise Key Establishment in Large-Scale Sensor Networks

•

Article 16 / 33

DI PIETRO, R., MANCINI, L. V., AND MEI, A. 2004. Efficient and resilient key discovery based on
pseudo-random key pre-deployment. In Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS). 217.
DOUCEUR, J. R. 2002. The Sybil attack. In Proceedings of the First International Workshop on
Peer-to-Peer Systems (IPTPS). 251–260.
DU, W., DENG, J., HAN, Y. S., CHEN, S., AND VARSHNEY, P. K. 2004. A key management scheme for
wireless sensor networks using deployment knowledge. In Proceedings of the IEEE Information
Communications Conference (INFOCOM). 586–597.
DU, W., DENG, J., HAN, Y. S., VARSHNEY, P., KATZ, J., AND KHALILI, A. 2005. A pairwise key predistribution scheme for wireless sensor networks. ACM Trans. Inform. Syst. Sec. 8, 2, 228–258.
DU, W., DENG, J., HAN, Y. S., AND VARSHNEY, P. K. 2003. A pairwise key pre-distribution scheme for
wireless sensor networks. In Proceedings of the 10th ACM Conference on Computer and Communications Security (CCS’03). 42–51.
DU, W., FANG, L., AND NING, P. 2006. LAD: Localization anomaly detection for wireless sensor
networks. J. Parall. Distrib. Comput. 66, 7, 874–886.
ESCHENAUER, L. AND GLIGOR, V. D. 2002. A key-management scheme for distributed sensor networks. In Proceedings of the 9th ACM Conference on Computer and Communication Security
(CCS-02). 41–47.
GANESAN, D., GOVINDAN, R., SHENKER, S., AND ESTRIN, D. 2001. Highly-resilient, energy-efficient
multipath routing in wireless sensor networks. Mobile Comput. Commun. Rev. 4, 5, 11–25.
GURA, N., PATEL, A., AND WANDER, A. 2004. Comparing elliptic curve cryptography and rsa on 8-bit
cpus. In Proceedings of the 2004 Workshop on Cryptographic Hardware and Embedded Systems
(CHES). 119–132.
HUANG, D. AND MEDHI, D. 2005. A Byzantine resilient multi-path key establishment scheme and
its robustness analysis for sensor networks. In the 5th IEEE International Workshop on Algorithms for Wireless, Mobile, Ad Hoc and Sensor Networks. 240b.
HUANG, D., MEHTA, M., AND MEDHI, D. 2005. Source routing based pairwise key establishment protocol for sensor networks. In Proceedings of the 24th IEEE International Performance Computing
and Communications Conference. 177–183.
HUANG, D., MEHTA, M., MEDHI, D., AND LEIN, H. 2004. Location-aware key management scheme
for wireless sensor networks. In Proceedings of the ACM Workshop on Security of Ad Hoc and
Sensor Networks (SASN). 29–42.
HUANG, D., MEHTA, M., VAN DE LIEFVOORT, A., AND MEDHI, D. 2007. Modeling pairwise key establishment for random key predistribution in large-scale sensor networks. IEEE/ACM Trans. Netw.
In Press.
KAHN, J. M., KATZ, R. H., AND PISTER, K. S. J. 1999. Next century challenges: Mobile networking
for “Smart Dust” . In Proceedings of the International Conference on Mobile Computing and
Networking (MOBICOM). 271–278.
KARLOF, C. AND WAGNER, D. 2003. Secure routing in wireless sensor networks: Attacks and countermeasures. AdHoc Netw. J. (Special issue on Sensor Network Applications and Protocols) 1, 2–3
(Sept.), 293–315.
KOÇ, C. K. 1994. High-speed RSA implementation. Tech. rep. 201, RSA Laboratories, Bedford,
MA.
LINDSEY, S. AND RAGHAVENDRA, C. S. 2002. Pegasis: Power efficient gathering in sensor information
systems. In Proceedings of the IEEE Aerospace Conference. 1125 –1130.
LIU, D. AND NING, P. 2003a. Establishing pairwise keys in distributed sensor networks. In Proceedings of the 10th ACM Conference on Computer and Communications Security (CCS’03). 52–
61.
LIU, D. AND NING, P. 2003b. Location-based pairwise key establishments for static sensor networks. In Proceedings of the 1st ACM Workshop on Security of Ad Hoc and Sensor Networks
(CCS’03). 72 – 82.
LIU, D. AND NING, P. 2005. Improving key pre-distribution with deployment knowledge in static
sensor networks. ACM Trans. Sens. Netw. 1, 2(Nov.) 204–239.
LIU, D., NING, P., AND DU, W. 2005a. Detecting malicious beacon nodes for secure location discovery in wireless sensor networks. In Proceedings of the the 25th International Conference on
Distributed Computing Systems. 609–619.
ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Article 16 / 34

•

D. Huang and D. Medhi

LIU, D., NING, P., AND DU, W. 2005b. Group based key predistribution in wireless sensor networks.
In Proceedings of the ACM Workshop on Wireless Security (WiSe). 11–20.
LIU, D., NING, P., AND LI, R. 2005c. Establishing pairwise keys in distributed sensor networks.
ACM Trans. Inform. Syst. Sec. 8, 1, 41–77.
MANJESHWAR, A. AND AGRAWAL, D. P. 2001. TEEN: A routing protocol for enhanced efficiency in
wireless sensor networks. In Proceedings of the 15th International Parallel and Distributed Processing Symposium Workshops (IPDPS). 30189a.
MEHTA, M., HUANG, D., AND HARN, L. 2005. RINK-RKP: A scheme for key predistribution and
shared-key discovery in sensor networks. In Proceedings of the 24th IEEE International Performance Computing and Communications Conference. 193–197.
PARNO, B., PERRIG, A., AND GLIGOR, V. 2005. Distributed detection of node replication attacks in
sensor networks. In Proceedings of the IEEE Symposium on Security and Privacy. 49–63.
POTTIE, G. J. AND KAISER, W. J. 2000. Wireless integrated network sensors. Commun. ACM 43, 5
(May), 51 – 58.
REED, I. S. AND SOLOMON, G. 1960. Polynomial codes over certain finite fields. SIAM J. Appl.
Math 8, 300–304.
SARWATE, D. V. 1977. On the complexity of decoding goppa codes. IEEE Trans. Inform. Theor. 23, 4,
515–516.
SPENCER, J. H. 2001. The Strange Logic of Random Graphs (Algorithms and Combinatorics).
Springer Verlag, Berlin, Germany.
TSIRIGOS, A. AND HAAS, Z. J. 2004. Analysis of multipath routing part I: The effect on the packet
delivery ratio. IEEE Trans. Wireless Commun. 3, 1, 138–146.
WICKER, S. B. 1995. Error Control Coding for Digital Communication and Storage. Prentice-Hall,
Englewod Cliffs, NJ.
ZHU, S., XU, S., SETIA, S., AND JAJODIA, S. 2003. Establishing pair-wise keys for secure communication in ad hoc networks: A probabilistic approach. In Proceedings of the 11th IEEE International
Conference on Network Protocols (ICNP). 326–335.
Received October 2005; revised September 2006; accepted March 2007

ACM Transactions on Sensor Networks, Vol. 3, No. 3, Article 16, Publication date: August 2007.

Secret-sharing Based Secure Communication
Protocols for Passive RFIDs
Harsh Kapoor and Dijiang Huang
Arizona State University

Abstract—With increase in applicability of RFID technology,
there is ever growing demand for security. The popularity of
RFID applicability lies in its ability for automatic identification
and low-cost of RFID tags. Most of the recent security protocols
for RFID technology are based on cryptographic hash-based
function which currently cannot be implemented on low-cost
RFID tags. In this paper, we present a lightweight protocol
based on key transportation and authentication using threshold
secret sharing scheme which provides strong security on low-cost
RFID tags without the need to connect to the backend server.
Our solution is based on an asymmetric computation strategy
allocating mathematical operations such as modular addition
and XOR on passive RFID tags and move the computational
complexity to the RFID interrogators. We believe a secure
protocol on low-cost RFID tags would make RFID technology
ubiquitous.

I. I NTRODUCTION
Radio Frequency Identification (RFID) tags are tiny,
wireless microchip that can be used to identify objects
they are attached to. It can be expected that RFID tags
will proliferate into billions and eventually into trillions in
the near future, as the successor of widely used optical
bar code. As the universal deployment of passive RFID
systems in medicare, asset management, supply chain and
many other areas, transported goods may be vulnerable to
clandestine inventorying by business competitors. Thus, the
information leakage of passive RFID tags to unauthorized
users has been identified as a major challenge to the RFID
technologies [1] [2]. The information leakage threat is
mainly due to the low-cost, low energy, and low computational capability of passive RFID tags, which cannot
perform heavy cryptographic algorithms. It is reported that
EPC [3] tags cost several US cents apiece [4] [5] in
2006. In the quest for minimal cost, the passive RFID tags
possess only a couple of thousand gates and no battery. The
passive RFID tags, such as EPC class-1 generation-2 tags,
energize themselves by absorbing radio wave emitted from
interrogators and communicate with interrogators upon
interrogation, mostly without authenticating the identities
of interrogators due to limited computational abilities.
Current approaches for protecting RFID against attempted attacks have been concentrating on developing
secure protocol using cryptographic hash based function
as building block [1] [6] [7] [8]. For example, in [9],
authors presented analysis on the number of gates required

for performing common hash functions like MD4, SHA1 and SHA-256 and showed how such protocols requires
7350 to 10868 additional gates for security. As a result,
due the size and power limitations of RFID tags, currently
such protocol cannot be implemented on low-cost RFID
tags [10]. To respond to this challenge, we take a novel
approach to minimize the computational requirements on
passive RFID as well as maintain a strong level of security
protection to the information stored on passive RFID tags.
Our solution is based on an asymmetric computation strategy allocating mathematical operations such as modular
addition and XOR on passive RFID tags and move the
computational complexity to the RFID interrogators, e.g.,
polynomial interpolations. Based on our proposed protocol,
we analyze that number of gates required for our solution is
1,850 which clearly is implementable on current low-cost
RFID tags.
We evaluate and prove the security provided by our
protocol by considering privacy, mutual authentication and
untraceability against strong adversary capable of launching
active attacks such as active information leakage attack as
well as passive attacks such as eavesdropping and tracking.
The attacks considered for the security analysis of the
proposed solution are the ones aimed at compromising the
authentication and privacy of the reader-tag communication.
Other attacks such as denial-of-service attack are out of
scope of the attack model considered for the analysis in
this paper since main focus of proposed solution is in providing privacy and security using computationally efficient
scheme. Rest of the paper is organized as follows. In next
section, we discuss related work in the field of RFID secure
protocols. In section III, we outline our requirements.
In section IV, we explain how Polynomial interpolation
based secret sharing scheme can be used for authentication
followed by proposed protocol in section V. In section VI
and VII, we do security, computational and communication
analysis of our proposed solution respectively. We conclude
this paper in section VIII.
II. R ELATED W ORK
In [8] [7], author proposes a scheme in which each RFID
tag stores a unique metaID. Upon receiving query from the
reader, tag responds with its metaID. Reader forwards this

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

metaID to a secure server which gives the reader real tag ID.
To avoid tracking of the tag by an adversary eavesdropping
communication between the reader and the tag, the authors
proposed a randomized hash lock scheme. In this scheme,
each time a tag is queries, it replies back with payload
generated using a pseudorandom function, random number
and some shared key. Secure server searches its database
to identify the response from the tag and replies back
with the real tag ID to the reader. This scheme avoids
the problem of tracking but introduces another security
problem. The attacker can retain the payload to impersonate
later as a tag. In [1], authors propose a scheme for offline
reader-tag authentication using a access list. The reader
upon authentication receives a access list for the tags
it’s authorized to read from secure server. The scheme
authenticates both the tag and the reader without a need
for central database and introduces a problem of secure
search for tags. The authentication is based on a challengeresponse scheme where the reader and the tag exchange
random numbers. The messages sent between the reader
and the tag is generated using a pseudorandom function
and only an authentic reader and tag have capabilities
to generate correct messages. The important contribution
of this scheme is introduction of secure search where
the reader issues a query that only authentic tags can
understand and only required tags responds to query in such
a manner that only an authentic reader can understand.
In [6], authors introduce the problem of forward untraceability and propose a solution to prevent attacker who
knows the RFID tags current secret from tracking it in
the future. The low-cost RFID tags have no protection
capability of the tag memory and hence adversary may be
able to access tags secret. Also transfer of ownership of the
RFID tags should prevent previous owner who had access to
the tags secret from tracking it in the future. The proposed
solution is based on using two one-way key chains; forward
key chain to evolve a tag secret in response to every query
request and updating the key chain value in the backend
server and backward key chain for server validation which
triggers a refresh of tag secret. These protocols presented
to prevent forward untraceability are based on updating the
secret in the RFID tags upon each successful reader. We
believe forward untraceability is an important problem but
we do not focus on it in this paper.
III. S ECURITY R EQUIREMENTS
In this section, we outline the security requirements for
RFID reader-tag communication. RFID tags store information about the product it is attached to. This information
is considered to be a secret and should not be exposed to
an unauthorized readers. We condiser three security goals,
1. prevent unautheorized reading of RFID tags. 2. Prevent
tracking of RFID tags.

First security requirement is securing RFID tags from
an unauthorized reader. This can be achieved by making
RFID tags transmit an encrypted message. Second security
requirement is to prevent tracking of RFID tags by an adversary. Tracking is possible when an unauthorized reader
is able to distinguish between messages from different tags.
Sending the same encrypted message every time RFID
tag is interrogated leads to tracking, as even though an
adversary doesn’t know what secret is being transmitted,
it can still identify messages coming from same RFID tag.
Tracking can be prevented by ensuring the RFID tags send
different message each time it is interrogated preventing
attacker from identifying the messages from RFID tags.
TABLE I
L IST OF S YMBOLS

Symbol
Ri
Tj
TA
β
Rβ
Tβ
yinit (x)
yα (x)
payload(n∗ )
ni
nj
||
Kshared(j)
(y(L) ∗ bα(L) )
Data
h(Data)
L
(x(i)(j) , y(i)(j) ,
binit(i)(j) )
xα(L+1)

Description
Authentic Reader i
Authentic Tag j
Backend Server
Adversary
Unauthentic Reader
Unauthentic Tag
Polynomial used for generate secret shares
New polynomial generated using secret as yintercept
Payload generated using n∗ as y-intercept
Random number generated by Reader i
Random number generated by Tag j
Concatenation operation
Data stored on Tag
Shared secret key stored on tag j
Pre-computed secret share stored on tag j
Secret data stored on tag
Hash of secret data stored on tag
Data obtained by reader
Access List obtained by reader from backend
server
∀i = 1 to L, secret shares obtained by reader
from backend server
x-coordinate at which L+1 point is calculated
by reader i for tag j

IV. T HRESHOLD S ECRET S HARING S CHEME
In this section we start by giving brief explanation of
polynomial interpolation based secret sharing scheme. We
then illustrate how threshold secret sharing scheme can be
used for key transportation and authentication in the RFID
reader-tag communication.
A. Polynomial Interpolation based secret sharing
A Polynomial Interpolation based secret sharing scheme
[11] has been proposed to share a secret among Nusr
entities such that any L ≤ Nusr entities can recover the
secret but any L < L entities know no more about the
secret than any non-participating entity. In this scheme, the
secret S is the coefficient a0 of a random(L − 1)-degree
polynomial over the finite Galois Field GF (p), where p is

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

TABLE II
L IST OF K NOWN AND U NKNOWN VARIABLE

Symbol
K1

K2

K3

K4

U1
U2
U3
U4
U5
U6

Variable Name
Description
Known Variables
payload(ni )
message sent by Ri to securely transmit random number ni to Tj using secret sharing scheme
challengej
message sent by Tj to securely transmit random number nj to Ri using shared
secret key
payload(nij )
message sent by Ri to securely transmit authentication
message nij to Tj using secret sharing scheme
(Data||h(Data))
message sent by Tj to se⊕ ni
curely transmit secret data
Data||h(Data) to Ri
Unknown Variables
ni
Random number generated by
Ri
nj
Random number generated by
Tj
Kshared(j)
Secret key shared between
T A, Tj and Ri
nij
Authentication message generated using ni and nj
bα(i) . y(i) (where, Pre-computed Secret Share
i = L)
added by Tj
(Data||h(Data))
secret data stored on Tj along
with its hash

a prime number larger than both S and n. Each of the
n shares (xi ,yi ) is a point on the curve defined by the
polynomial y(x) computed over the finite field Zp . For rest
of the paper, we assume all calculations made in polynomial
interpolation based secret sharing scheme are computed
over the finite field Zp and is not mentioned explicitly.
This scheme is based on the interpolation property of
polynomials according to which, a polynomial equation
y(x) of degree (L − 1) can be reconstructed only if at
least L points that lie on y(x) are available. A degree L−1
polynomial of the form

y(x) = a0 + a1 x + a2 x2 + a3 x3 + . . . + aL−1 xL−1 (1)
is constructed, where a0 equals the secret S (i.e., the
y -intercept of the curve) and the other coefficients a1 ,
a2 , . . . , ak−1 are chosen randomly. Now, Nusr points
(xj , yj ) ∀j = 1 to Nusr on the curve are obtained
and distributed to the participating entities. Any L of
these Nusr entities can combine their points to reveal the
secret. The polynomial y(x) can be reconstructed using
the Lagrange Interpolation formula. If the points available
are represented as {(x1 , y1 ), (x2 , y2 ), . . . , (xL , yL )}, the
Lagrange Interpolation formula is given by:

y(x) =

L

i=1

bi yi where, bi =

L


x − xk
.
xi − xk
k=1,k=i

(2)

The traditional secret sharing scheme is operated in a

centralized system, i.e., all participants submit their points
to a server which computes the secret. In proposed scheme,
the secrets shares are distributed between RFID reader and
RFID tag. The Backend Server, generates a random value
INIT and chooses a polynomial yinit (x) of degree L − 1
which has INIT as the y -intercept:

yinit (x) = IN IT + a1 x + a2 x2 + a3 x3 + . . . + aL−1 xL−1
(3)
The curve yinit (x) has degree L − 1 and server now
determines L points that lie on it as {(x1 , y1 ), (x2 , y2 ) . . .,
(xL−1 , yL−1 ), (xL , yL )} Now, in order to recompute the
INIT value, x = 0 can be substituted in (2) to obtain these
new equations:
L


L


xk
.
x
k − xi
i=1
k=1,k=i
(4)
Now, the server calculates the values (binit(i) ∀i = 1
to L). The triplets of the form (xi ,yi , binit(i) ) ∀i = 1
to L is secret shares. The server gives triplets {(x1 , y1
, binit(1) ) , (x2 , y2 , binit(2) ), . . . , (xL−1 , yL−1 , binit(L−1) ),
(xL , yL , binit(L) )} to RFID reader and stores triplet (xL
, yL ,binit(L) ) on an RFID tag. The xi , yi and binit(i)
values is a secret share and hence should not be disclosed.
To authenticate the RFID reader to the RFID tag, the
threshold secret sharing scheme can be used in form of
challenge-response. The RFID tag sends a random challenge n to RFID reader. The RFID reader takes n as y intercept (0, n) along with the points {(x1 , y1 ), (x2 , y2 ),
. . . , (xL−1 , yL−1 ), (xL , yL )} to compute a polynomial
yα (x) of degree L using polynomial interpolation. The
RFID reader can now identify a new point {xα(L+1)
, yα(L+1) } that lies on the polynomial yα (x). The construction of the curve yα (x) and its relationship with the initial
curve yinit (x) are shown in Figure 1.
The RFID tag already has (xL , yL ) point on yα (x) and
if RFID reader uses only points {(x1 , y1 ), (x2 , y2 ), . . . ,
(xL−1 , yL−1 )} together they have potential to recalculate
(0, n) using the following equations which are derived from
(4).
yinit (0) =

yα (0) =

L+1


binit(i) yi , where binit(i) =

bα(i) yi , where, bα(i) =

i=1

L+1


xk
. (5)
xk − xi
k=1,k=i

For triplets i = 1 . . . L (i.e. i = 1 . . . L − 1 at RFID
reader and i = L at RFID tag), bα(i) can be calculated as:

bα(i) = binit(i)

xα(L+1)
.
xα(L+1) − xi

(6)

One drawback of using proposed method for authentication is the RFID tag sends challenge which is used as
y -intercept by RFID reader in plain text. An adversary can

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

Fig. 1.
tion.

Relationship between curves generated using polynomial interpola-

determine value of secret share added by the RFID tag as
value of payload and y -intercept is known. To overcome
this, tag sends challenge to reader as an encrypted message
details of which is explained in the section V.
It can be seen from (6) that RFID reader and RFID tag
can calculate the bα(i) values (∀i = 1 to L + 1) from
binit(i) , xi and xα(L+1) . For each triplets, its binit(i) and
xi are known, and hence only xα(L+1) value is required.
If value of xα(L+1) is uniquely pre-determined for each
RFID tag by server, then bα(i) values (∀i = 1 to L) can be
pre-computed. Hence, instead of storing triplets ((xL , yL
, binit(L) ) on an RFID tag, the server stores (yL ∗ bα(L) ) on
the RFID tag and also provides RFID reader with xα(L+1) .
Now, in order to recomputed n (i.e. y -intercept), following
procedure is followed.
1) The RFID reader uses (5) to obtain bα(L+1) from
which bα(L+1) . yα(L+1) can be calculated (Note that
the RFID reader can calculate bα(L+1) as it has stored
all the points on the curve yα (x))
2) The RFID reader now adds bα(L+1) . yα(L+1) with
bα(i) . y(i) (∀i = 1 to L − 1) to generate a payload
and transmits it to the RFID tag. (Note the payload
generated is represented as payload(x) if x is used
as the y -intercept)
3) The RFID tag upon receiving the payload from RFID
reader adds bα(i) . y(i) (where, i = L) to it to get back
y -intercept.
V. P ROPOSED S OLUTION
In this section we present the protocol for secure RFID
reader-tag communication. We begin with describing the
setup for our scheme followed by detail explanation of
secure reader-tag communication protocol.
A. Setup
We consider the RFID tag denoted as T stores secret
Data An RFID reader, R gets an access list, L from
backend server, T A after authenticating itself to read Data
from T . We assume communication channel between T A
and R to be secure. We distinguish between different RFID
readers and RFID tags using subscripts. Thus, RFID reader

i will be Ri and RFID tag j will be Tj . The T A is
responsible for storing the secret Data on all RFID tags
and authorizing all RFID readers. For Tj , T A generates
a polynomial y(x)j using equation of degree L − 1, and
finds L points on y(x). The T A selects a random xL+1
coordinate and pre-computes the secret share for Tj as
explained in section IV. Information about what data is
stored on Tj and what data is obtained by Ri to read
secret data from Tj is given in Table I. We assume the
RFID reader knows the RFID tag it is interrogating and
associates the secret shares and shared key with it.
We consider payload generated by Ri using n∗ as y intercept along with (x(i) , y(i) ) points (∀i = 1 to L) to be
denoted as payload(n∗ ) . We consider || to be concatenation
operation.
B. Secure reader-tag communication protocol
Algorithm 1 RFID Authentication protocol
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:

Ri → Tj : payload(ni )
Ri ← Tj : challengej = Kshared(j) ⊕ nj
Ri : nij = ni ⊕ nj
Ri → Tj : payload(nij )

Tj : ni = nij ⊕ nj

if ni = ni then
Ri ← Tj : (Data||h(Data)) ⊕ ni
else
Ri ← Tj : nrand
end if

Initially, Ri generates a random number ni and uses
ni as y -intercept along with secret shares (x(i) , y(i) )
(∀i = 1 to L) to generate yα (x) using polynomial
interpolation as explained in section IV. Ri then determines
new point using xα(L+1) as x-coordinate (which it received
from T A for Tj ). Ri then generates payload(ni ) using
(xα(L+1) , yα(L+1) , bα(L+1) ) and (x1 , y1 , bα(1) ) , (x2
, y2 , bα(2) ) , . . . , (xL−1 , yL−1 , bα(L−1) ) as explained in
section IV and sends payload(ni ) to Tj . Tj upon receiving
payload(ni ) adds pre-computed secret share i.e. (yL ∗
bα(L) ) to get back ni . Tj generates a random number
nj and responds back to Ri with challengej . Ri uses
Kshared(j) to get back nj from challengej . At this point,
both Ri and Tj have exchanged random numbers which
is used for authentication using challenge-response. To
authenticate itself Ri computes nij and sends payload(nij )
to Tj . nij is used as authentication message since only
authentic Ri has Kshared(j) to get nj sent by Tj . After

obtaining nij from Ri , Tj computes ni by performing nij

⊕ nj . Tj verifies that ni is same as ni . Only Ri has
knowledge of ni , nj and secret shares to generate correct
payload(nij ) . If authentication is successful, Tj sends ni ⊕
Data||h(Data) to Ri otherwise Tj sends random number
nrand to Ri . Only Ri has ni to back Data||h(Data).

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

Authenticity of message from Tj is verified by Ri since
only Tj has knowledge of ni to send back message which
on performing XOR with ni gives Data||h(Data).
VI. S ECURITY A NALYSIS
In this section, we analyze proposed solution against
each attack, we explain the nature of attack, capabilities
of attacker and strength of proposed protocol against the
attack along with common assumptions. The attacks considered for the security analysis are the ones aimed at
compromising the authentication and privacy of the readertag communication. We consider adversary to be denoted
as β , authentic RFID reader, Ri , authentic RFID tag,
Tj , unauthentic RFID reader, Rβ ,fake RFID tag, Tβ and
backend server, T A. We assume Kshared(j) and (y(L) ∗
bα(L) ) is stored on Tj and is not disclosed to β . Similarly,
we assume Kshared(j) , xα(L+1) and triplets (x(i)(j) , y(i)(j) ,
binit(i)(j) ) (∀i = 1 to L) is stored on Ri and is not
disclosed to β .
A. Eavesdropping
Under this attack, β is able to observe all information
exchanged between Ri and Tj . We consider β can observe
both Reader-to-Tag and Tag-to-Reader communication. In
our scheme, β obtains payload(ni ) , Kshared(j) ⊕ nj ,
payload(nij ) and (Data||h(Data)) ⊕ ni by eavesdropping communication between Ri and Tj . As shown in Table
II, we consider this information as known variables Ki
(∀i = 1 to 4) . β doesn’t know ni , nj , Kshared(j) , nij
and bα(i) . y(i) (where, i = L). We consider unknown
information as unknown variables Uj (∀j = 1 to 6). β
can try to use the equations give below along with known
variables to determine unknown variables. As there are 5
equations and 6 unknown variables, β cannot determine
value for unknown variables. Thus, β is unable to get
any valuable information by eavesdropping communication
between Ri and Tj .
1) K1 + U 5 = U 1
2) K2 = U 3 ⊕ U 2
3) U 4 = U 1 ⊕ U 2
4) K3 + U 5 = U 4
5) K4 = U 6 ⊕ U 1
B. Active information leakage Attack
Active information attack is one where β can actively
participate in a communication with Ri or Tj . Under
this attack, β can interrogate Tj by sending messages
pretending to be Ri and β can responds to the query from
Ri pretending to be Tj .
β generates a message nβ and sends it to Tj . Tj


adds (y(L) ∗ bα(L) ) to nβ . β doesn’t know nβ . Tj now
generates random number nj and sends nj ⊕ Kshared(j)

to β . β doesn’t know Kshared(j) and hence cannot obtain


nj . β is excepted to perform nβ ⊕ nj to generate nβj

and use nβj to generate and send payloadn to Tj as
βj
authentication response. On receiving incorrect payloadn
βj
from β , authentication of β by Tj fails. Tj sends random
number as response. All β receives is random numbers,
nj ⊕ Kshared(j) and nrand . Thus, β is unable to get any
valuable information from Tj .
In other case, Ri chooses random number ni and generates pay− load(ni ) . Ri sends payload(ni ) to β . In response, β sends random number nβ to Ri . Ri on receiving

nβ XOR’s it with Kshared(j) to get nbeta . β does not



know nβ . Ri then performs ni ⊕ nβ to generate nβj and

uses nβj to generate and send payloadn to Tj . β is
βj
expected to send the message XORing with ni in form
(data||h(data). As β doesn’t know ni , it is unable to
generate correct message for Ri . β authentication fails and
Ri considers β as tag its not authenticated to read or fake
tag. All β receives is payload(ni ) and payloadn . Without


βj

knowledge of secret shares, ni and nβj . These messages
reveal nothing about secret information stored on Ri . Thus,
β is unable to get any valuable information from Ri .
C. Tracking
Under this attack, β tries to identify two or more response
from Tj . β can eavesdrop communication between Ri and
Tj . β is also capable of interrogating Tj using messages
obtained from eavesdropping previous communication between Ri and Tj .
In our proposed protocol, the following information is exchanged between Ri and Tj , 1. payload(ni ) 2. Kshared(j)
⊕ nj 3. payload(nij ) 4. (Data||h(Data)) ⊕ ni . All of
these mentioned information is dependent upon ni and nj .
As ni and nj is chosen randomly each time Ri interrogates
Tj , β is unable to distinguish messages sent by Tj from
messages sent by T∗ .
In second case, when β interrogates Tj by using
payloadni obtained from eavesdropping previous communication between Ri and Tj . In response , Tj sends
Kshared(j) ⊕ nj where nj is randomly generated. As β
cannot predict nj and doesn’t have Kshared(j) , it is unable
to compute nij . In addition, β doesn’t know shared secret
to generate payload(nij ) . As a result β is unable to pass
the authentication and hence Tj sends random number
nrand instead of (Data||h(Data)) ⊕ ni . β obtains random
numbers, Kshared(j) ⊕ nj and nrand . Thus, β is unable to
distinguish messages sent by Tj from messages sent by T∗ .
VII. C OMPUTATIONAL AND C OMMUNICATION
A NALYSIS
In this section, we analyze the computational and communication overhead of the proposed protocol. We compare

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

TABLE III
P ERFORMANCE A SSESSMENTS
(b) Gate Count Comparison with Hash Functions
Algorithm
Gate Count
SHA-256
10,868
SHA-1
8,120
MD-5
8,400
MD-4
7,350
AES
3,400
Proposed Solution
1,850

(a) Gate Count for different Arithmetic Block
Operation
Gate Count
Adder
640 (5*128)
Subtractor
768 (6*128)
Multiplexer
442 (2 * ((18*12) + 5)
Total
1,850

the computational analysis of the proposed solution in
terms of number of logical gates required to perform each
operation on passive RFID tag with the number of gates
required to perform hash functions from the SHA family.
As per the proposed solution, XOR and modular addition
operation is required to be performed on the RFID tag.
XOR is a bitwise operation and number of gates required to
implement it is insignificant compared to modular addition.
Modular addition of two number x and y belonging to
{0,...,p − 1} is defined by:



x + y if x + y < m
x + y − m if x + y > m
This can be implemented using an adder, subtractor and
comparator. Other techniques to perform modular addition are suggested in [12]. We use simple Ripple carry
adder implemented using series of full adders for 128bit addition. For subtraction, we use Ripple carry adder
in Two’s complement form which uses invertor block. For
128-bit addition and subtraction the estimated number of
gates required is listed in Table III(a). For Comparator,
simple bitwise digital comparator can be used which makes
use of Multiplexer’s to provide one bit starting MSB of
x and y to the digital comparator. We consider 128:1
multiplexer designed using eighteen 8:1 multiplexer and
one 2:1 multiplexer. Two 128:1 multiplexer are required
for two numbers being compared. Since gates required for
one bit digital comparator is insignificant we don’t consider
it’s gate count and focus on multiplexer’s only. The total
number of gates required for multiplexer’s is also listed in
Table III(a). We do not claim this is the best design in
terms of number of gates or performance and we believe
better optimized designs are possible. Our result of gate
count are based solely on estimations and not on synthesis.
The Table III(b) compares the gate count for hash functions
from the SHA family and AES as mentioned in [9] with our
proposed solution. Clearly, the number of gates required
for our proposed solution is much less making it more
suitable for low-cost RFID tags. In terms of communication
overhead, four messages are transmitted in the proposed
solution. The first three messages are used to authenticate
RFID reader to the RFID tag, verifying that the RFID
reader has the correct secret shares to read the RFID tag.
(x + y) mod p

The fourth message is used for sending the encrypted data
from the RFID tag to the RFID reader. Like most of the
challenge-response authentication approaches, the proposed
solution uses just three messages for authentication.
VIII. C ONCLUSION
In this paper, we present lightweight protocol for secure
reader-tag communication for passive RFID tags. We introduce how threshold secret sharing scheme can be used
as basic building block for reader-tag authentication instead
of hash-based functions. The advantage of our scheme over
other schemes lies in its applicability for current low-cost
RFID tags based on performance and security requirements.
We analyze the security and performance efficiency of our
protocol.
R EFERENCES
[1] C. Tan, B. Sheng, and Q. Li, “Severless search and authentication
protocols for rfid,” IEEE Intern. Conf. on Pervasive Computing and
Communications (PerCom 2007), 2007.
[2] A. Juels and R. Pappu, “Squealing euros: Privacy protection in rfidenabled banknotes,” Financial Cryptography: 7th International Conference, FC 2003, Guadeloupe, French West Indies, January 27-30, 2003:
Revised Papers, 2003.
[3] E. Inc, “Class 1 generation 2 uhf air interface protocol standard version
1.0. 9,” EPCglobal Inc, 2004.
[4] S. Sarma, “Towards the five-cent tag,” Technical Report MITAUTOID-WH-006, MIT Auto ID Center, 2001. Available from
http://www.autoidcenter.org, Tech. Rep.
[5] A. Juels, “Rfid security and privacy: a research survey,” Selected Areas
in Communications, IEEE Journal on, vol. 24, no. 2, pp. 381–394, 2006.
[6] C. Lim and T. Kwon, “Strong and robust rfid authentication enabling
perfect ownership transfer,” Conference on Information and Communications Security, 2006.
[7] D. Molnar and D. Wagner, “Privacy and security in library rfid: issues,
practices, and architectures,” Proceedings of the 11th ACM conference
on Computer and communications security, pp. 210–219, 2004.
[8] S. Weis, S. Sarma, R. Rivest, D. Engels, and A. Center, “Security and
privacy aspects of low-cost radio frequency identification systems,” Security in Pervasive Computing: First International Conference, Boppard,
Germany, March 12-14, 2003: Revised Papers, 2004.
[9] M. Feldhofer and C. Rechberger, “A case against currently used hash
functions in rfid protocols,” Workshop on RFID Security, pp. 13–14,
2006.
[10] M. Rieback, B. Crispo, and A. Tanenbaum, “The evolution of rfid
security,” IEEE Pervasive Computing, vol. 5, no. 1, pp. 62–69, 2006.
[11] A. Shamir, “How to share a secret,” Communications, 1979.
[12] J. Beuchat, “Some modular adders and multipliers for field programmable gate arrays,” Proceedings of the 17th International Parallel
and Distributed Processing Symposium. IEEE Computer Society, 2003.

978-1-4244-4148-8/09/$25.00 ©2009
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE "GLOBECOM" 2009 proceedings.

736

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 12, NO. 3, SEPTEMBER 2011

PACP: An Efficient Pseudonymous
Authentication-Based Conditional Privacy
Protocol for VANETs
Dijiang Huang, Senior Member, IEEE, Satyajayant Misra, Member, IEEE,
Mayank Verma, Member, IEEE, and Guoliang Xue, Fellow, IEEE

Abstract—In this paper, we propose a new privacy preservation
scheme, named pseudonymous authentication-based conditional
privacy (PACP), which allows vehicles in a vehicular ad hoc
network (VANET) to use pseudonyms instead of their true identity
to obtain provably good privacy. In our scheme, vehicles interact
with roadside units to help them generate pseudonyms for anonymous communication. In our setup, the pseudonyms are only
known to the vehicles but have no other entities in the network. In
addition, our scheme provides an efficient revocation mechanism
that allows vehicles to be identified and revoked from the network
if needed. Thus, we provide conditional privacy to the vehicles in
the system, that is, the vehicles will be anonymous in the network
until they are revoked, at which point, they cease to be anonymous.
Index Terms—Conditional anonymity, pseudonym, vehicular
ad hoc networks (VANETs).

I. I NTRODUCTION

V

EHICULAR ad hoc networks (VANETs) have recently
become a popular direction for research, with specific
attention to improving driving experience and road safety [1].
VANETs generally consist of vehicles, infrastructure units such
as roadside units (RSUs), and a centralized trusted authority.
Each vehicle that is part of a VANET contains an onboard
wireless computing unit, which is commonly known as the
onboard unit (OBU). Vehicles may communicate with the
RSUs, which are online, and with other vehicles in their neighborhood. Recent studies on VANETs have identified several
issues, including those in security and privacy, which need to
be addressed for widespread adoption.
Security issues in VANETs have been studied in great detail
(see [2]–[4]). However, the issue of privacy still has a lot of
Manuscript received July 31, 2009; revised August 16, 2010 and
March 16, 2011; accepted April 22, 2011. Date of publication August 12, 2011;
date of current version September 6, 2011. This work was supported in part
by the U.S. Army Research Office under Grant W911NF-09-1-0467, by the
National Science Foundation under Grant 0901451, Grant 0942453, and Grant
1029546, and by the Office of Naval Research under the Young Investigator
Program Award. The work does not reflect the position or the policy of the
federal government. The Associate Editor for this paper was C. T. Chigan.
D. Huang and G. Xue are with the School of Computing, Informatics, and
Decision Systems Engineering, Arizona State University, Tempe, AZ 85287
USA (e-mail: dijiang@asu.edu; xue@asu.edu).
S. Misra is with the Department of Computer Science, New Mexico State
University, Las Cruces, NM 88003 USA (e-mail: misra@cs.nmsu.edu).
M. Verma is with Brocade Communications, Encinitas, CA 92024 USA
(e-mail: verma.mayank@gmail.com).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TITS.2011.2156790

open questions. With the latest advancement in tracking mechanisms and the potential increase in communication among
vehicles, an adversary can track a vehicle by observing its communication and movement patterns. However, if a completely
anonymized vehicle turns malicious, then there is no way to
identify and revoke it. Thus, a privacy scheme needs to provide
privacy to the vehicles while at the same time being able to
track and revoke rogue vehicles. In other words, the vehicles in
a VANET need conditional privacy, that is, the vehicles should
have privacy that is contingent on them behaving appropriately
in the system. If the vehicle does not perform the protocols
correctly or is malicious, then its privacy is revoked, and it can
no longer be anonymous. These requirements have served as
the motivation for many researchers, leading to the formulation
of various schemes, e.g., [5]–[7]. These schemes advocate the
use of pseudonym-based approaches for anonymous communication, which helps maintain a vehicle’s privacy. Most of the
schemes designed for anonymity in VANETs utilize a public
key infrastructure (PKI). The RSA-based PKI and the elliptical
curve cryptosystem (ECC)-based PKI [8] are two commonly
used infrastructures. In general, the ECC-based anonymity
schemes are better than the RSA-based schemes because of the
smaller key size and lower computation costs [9]. However, all
of the existing schemes suffer from a common drawback, that
is, the authorities involved in the pseudonym generation process
also know the pseudonyms used by the vehicles. Thus, these
schemes are not truly anonymous.
Based on the aforementioned presentation, there is a need for
a strong privacy-preserving scheme in VANETs that has properties such as low pseudonym generation latency, high scalability,
easy revocation, and ability to perform with sparsely distributed
RSUs. To achieve these desired properties, our research goal
is to design a new anonymity scheme, named pseudonymous
authentication with conditional privacy (PACP), for generating
pseudonyms. PACP is based on four security requirements:
1) The privacy provided to the vehicles is conditional privacy.
2) The construction of PACP is based on pairing [10], which is
a mathematical structure based on ECC assumptions. 3) PACP
does not rely on storing multiple pseudonym certificates issued
from a centralized authority or on providing identity certificates
to the RSU for generating on-the-fly pseudonym certificates.
Instead, a node generates its pseudonyms with assistance from
the RSU in its neighborhood in a way that the RSU gains no
information about the node’s real identity. 4) In case of any

1524-9050/$26.00 © 2011 IEEE

HUANG et al.: PACP PROTOCOL FOR VANETs

dispute, our scheme allows trusted authorities to successfully
de-anonymize a misbehaving node to reveal its identity and
possibly revoke it with the use of revocation lists (RLs).
The main contribution of this paper is to allow vehicles
to generate provably anonymous and computationally efficient pseudonyms to ensure conditional privacy. The presented performance studies and comparisons with other popular
anonymity schemes [2], [6] demonstrate that our scheme is
effective and efficient.
The rest of this paper is organized as follows. Section II
presents the related work. Section III details the system and
attack model and provides preliminary definitions. Section IV
describes the presented PACP scheme in detail. Section V
describes the security and privacy performance analysis.
Section VI presents the simulation results that demonstrate the
effectiveness of our scheme. Section VII concludes our work
and provides directions for future work.

737

Fig. 1. Network model for VANETs.

III. S YSTEM OVERVIEW
II. R ELATED W ORK
In the area of security and privacy of VANETs, majority of
the research works have focused on authentication to ensure
security [2]–[4], [11]. To protect the privacy of vehicles, existing research has mainly focused on location privacy [12],
[13] problems, anonymizing sensed data [14], and pseudonymbased schemes to anonymize vehicles’ actions [5]–[7].
Previous solutions have shown that, to maintain a vehicle’s
privacy, pseudonym-based approaches are most effective. However, to thwart privacy-related breaches, frequent change of
pseudonyms is essential. The Vehicle Safety Communication
(VSC) project [15] was one of the first projects to work on
privacy in VANETs. It proposed the use of a list of shortlived pseudonym certificates for guaranteeing privacy through
anonymity. Raya and Hubaux [16] proposed a scheme similar
to VSC, which required using certificates for vehicle-to-vehicle
communication. However, the scheme requires many public key
operations and, hence, is expensive for deployment.
Several privacy schemes that use ECC as their fundamental
building block have been proposed in the literature. Lu et al. [6]
proposed an ECC-based scheme, named efficient conditional
privacy preservation protocol (ECPP), using bilinear maps to
achieve conditional privacy for the vehicles. In ECPP, a vehicle
uses multiple anonymous keys obtained from an RSU to prevent
its communication from being traced. In addition to the provided anonymity features, the ECPP scheme suffers from three
main drawbacks. First, it is not efficient due to two reasons:
1) It has fairly high latency for generation of pseudonym keys
by the RSUs, and 2) it requires ubiquitous presence of RSUs
to assist vehicles to derive their pseudonyms and corresponding
keys at any given road location. Second, ECPP requires that the
issued pseudonyms are known to the issuing authorities (i.e.,
RSUs) beforehand. Since RSUs are distributed in open areas
along roads, they are usually vulnerable to physical attacks.
Thus, they usually cannot be fully trusted. Third, there is no
clear revocation mechanism of using ECPP. Since vehicles can
derive their pseudonyms from every RSU, even a compromised
one, malicious vehicles cannot be revoked.

Here, we present the system assumptions, the network
model, the attack model, and some mathematical models used
by our solutions.
A. Assumptions
We assume that all vehicles are registered with a central trusted authority (TA), i.e., the Motor Vehicles Division
(MVD), before they are approved for driving on the road.
Registration of a vehicle includes registration of the vehicle’s
license plate number, identity, owner’s address, and any other
information needed to uniquely identify the vehicle and its
owner. Since the MVD is assumed to be trusted and cannot
be compromised, the initial security parameters and keys are
issued by the MVD. RSUs are not fully trusted since they
are usually exposed in open unattended environments, which
are subject to physical breaches. However, we assume that the
functions of RSUs are monitored and that their compromise
can be detected in a bounded time period. Consequently, at a
given time, very few RSUs are compromised. Because RSUs
can be compromised, we assume that the security keys and
corresponding identity information cannot be directly generated
by RSUs. Other vehicles are not trusted.
B. Network Model
The network model for our anonymity scheme is shown
in Fig. 1. It comprises on- and off-road units. The on-road
units consist of the vehicles, the RSUs, and the communication
network. The RSUs are managed and regularly monitored by
a local transportation department office such as the MVD. The
RSUs and the MVD are connected via the Internet. Existence
of a central trust authority such as the MVD helps expedite
revocation as all RSUs can contact it for updated vehicle RLs.
Each vehicle is assumed to be equipped with an OBU, which is
a tamper-proof device (TPD) that stores the secret information,
an event data recorder (EDR), and a Global Positioning System.
The RSUs and the vehicles are equipped with network cards
that can provide support for the dedicated short-range communication (DSRC) [17] service or WiFi access, hence enabling

738

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 12, NO. 3, SEPTEMBER 2011

TABLE I
N OTATIONS U SED IN PACP

high-data-transfer rates with minimal latency. Vehicles and the
nearby RSUs are assumed to be time synchronized, which can
be used to validate the expiration date of a pseudonym.
C. Attack Model
The attackers in a VANET may be classified as either internal
attackers or external attackers. External attackers are powerful
attackers that can observe and analyze the traffic in the network.
They are not part of the system; hence, they cannot decrypt
the messages, but they can obtain related information from the
messages and use it for traffic and data analysis. We assume
that the external attackers are more powerful than the vehicles
or the RSUs; however, their powers are bounded. Usually, it
takes multiple colluding external attackers to observe the whole
system. Internal attackers are compromised vehicles. Internal
attackers are potent as well since they are part of the system
and have access to shared secrets.
Here, we present all possible attack scenarios in a VANET.
An attacker can (a) modify or replay existing messages,
(b) inject fake messages, (c) impersonate a legitimate node
(RSU or vehicle), (d) compromise an RSU or a vehicle, or
(e) perform a denial-of-service attack. The attacks may be
performed by a single attacker or a group of colluding attackers.
We note that, of the aforementioned attacks, attacks (c), (d), and
(e) are those that result in loss of privacy. In our study, we do
not consider attack (e) as they have been addressed in [18]. Our
scheme handles the rest of the attack scenarios and ensures that
the anonymity of communication is preserved. In the following
section, we present our scheme PACP in detail.
D. Background Concepts
We first formally define the term conditional privacy.
Definition 1—Conditional Privacy: Given a set of vehicles
V = {V1 , . . . , Vm , . . . , Vp }, a set of RSUs R = {R1 , . . . , Rq },
and a trusted MVD, the conditional privacy of a vehicle Vm
ensures that its real identity is only known to the MVD. If
the vehicle is identified as compromised or malicious, then its
privacy can be revoked by the MVD, and its identity will be
known to other vehicles and RSUs.

Here, we present some concepts that form the basis for
the design of our PACP scheme and the proof of its security.
Our protocol uses bilinear mapping, which uses pairing-based
construction to map a pair of elements in a given group to
another element in the same or a different group. The following
definition states some properties of bilinear mapping.
Definition 2—Properties of Bilinear Mapping: Given two
groups G1 and G2 with same order p, where p = q n , q is prime
and n ∈ Z+ , G1 is an additive group, and G2 is a multiplicative
group, the bilinear mapping ê : G1 × G1 → G2 satisfies three
properties.
1) Bilinearity: The mapping ê : G1 × G1 → G2 is said to
be bilinear if ê(aP, bQ) = ê(P, Q)ab , ∀P, Q ∈ G1 and
∀a, b ∈ Z∗p , where Z∗p = [1, . . . , p − 1].
2) Nondegeneracy: If ê(P, Q) = 1 for all Q ∈ G1 , then
ê(P, P ) is a generator of G2 , and P is the identity element
in G1 .

TABLE II
P UBLICLY K NOWN S YSTEM PARAMETERS

3) Computability: The bilinear map ê : G1 × G1 → G2 can
be efficiently computed.

Definition 3—Elliptical Curve Discrete Logarithmic Problem
(ECDLP): Given P, Q ∈ E(Fq ), find the value of λ, if it exists,
such that Q = λP .

The ECDLP had been proved to be a hard problem [19].
IV. P SEUDONYMOUS AUTHENTICATION -BASED
C ONDITIONAL P RIVACY
Here, we present our PACP scheme that provides
pseudonym-based anonymity to vehicles in VANETs. Before
presenting our scheme in detail, we first give a general
overview. A vehicle that uses our PACP scheme registers with
the motor vehicle department using its identity and gets a
ticket. It uses the ticket to communicate with an RSU in its
neighborhood to obtain tokens. The tokens are used by the
vehicle to generate pseudonyms for anonymous broadcast
communication with other vehicles. In what follows, we will
present the scheme in detail. Table I illustrates the notations
used in the presentation of our scheme.
A. System Setup
The scheme uses a set of publicly known system parameters
params = G1 , G2 , e, P, H, H1 , H2 , which are stored in each
vehicle by the MVD at the time of registration. The detailed
explanation of parameters is given in Table II. The MVD
generates its public key as PMVD = αP , where α ∈ Z∗p is the
private key of the MVD.
Our scheme uses the identity-based encryption (IBE) scheme
proposed by Boneh and Franklin [20] for secure communication. All signatures generated in our scheme utilize the BLS
short signature scheme proposed by Boneh et al. because of

HUANG et al.: PACP PROTOCOL FOR VANETs

739

4:Store the mapping mapaMVD = δa , IDa  in the database.
5:Store the 3-tuple Qa = δa , SIG(δa ; PMVD ), Sa  with
params in the vehicle’s OBU.

Fig. 2.

State transition diagram for pseudonym generation in PACP.

its efficiency and low computation cost [21]. In the following
section, we present our PACP scheme in detail.
B. PACP Protocols
In our scheme, pseudonym generation for a vehicle requires
three types of entities, namely, the vehicle, the MVD, and the
RSU. The interaction between these three entities is shown in
Fig. 2. A vehicle Va provides the required identity information
to the MVD as part of the registration process. Then, the MVD
issues Va a ticket. The ticket uniquely identifies Va ; however,
it does not reveal Va ’s true identity. When moving on the
road, Va authenticates itself with the nearest RSU and obtains
a pseudonym token. Then, Va uses the token to generate its
pseudonyms. Here, we must note that the RSU only provides
the credential (i.e., signature) and restrictions (i.e., a time
stamp) for the vehicle to generate its pseudonyms, and it does
not learn any private information of the vehicle. As a result, the
RSU is unaware of the vehicle’s true identity, which is mapped
to the pseudonym that the vehicle will generate using the token.
We note that the RSU can map a ticket to a pseudonym token
and the generated pseudonym. However, this mapping cannot
review the real identity of the vehicle. The only information
possessed by the RSU is the token, which will be used in
the revocation phase. We will discuss more about the resultant
improvement in security in the security analysis section. Our
system consists of three building blocks, namely, registration,
generation, and extraction. Each block is a protocol in itself. In
what follows, we present the three protocols.
1) Registration Protocol: The registration procedure requires Va to be physically present at the MVD. The vehicle
registers with the MVD and obtains a ticket δa . The MVD loads
δa and params, i.e., the system parameters, into the vehicle’s
TPD. Algorithm 1 illustrates the complete registration process
executed by the MVD.
Algorithm 1: Registration Protocol executed by the MVD
Require: IDa .
1:Choose a random number rnd ∈ Z∗p .
2:Use H2 to compute Sa = H2 (IDa , rnd) ∈ {0, 1}n , and Sa
is Va ’s private key.
3:Compute ticket δa = Sa P ∈ G1 and sign δa with SMVD
to obtain SIG(δa ; SMVD ), and δa is Va ’s public key.

Identity IDa is the true identity of vehicle Va , and Sa is the
master secret key of Va . We note that ticket δa does not reveal
any information about Va . However, in case of misconduct,
the MVD can obtain IDa by looking up the mapping mapaMVD
(line 4), which is stored in a hash table in its database, in O(1)
time. The signature performed by the MVD (line 5) utilizes
the lightweight BLS scheme [21]. The MVD signs δa with its
private key. The 3-tuple Qa is Va ’s private information that
is stored in the OBU and can only be modified by the MVD.
Once Va has successfully obtained δa , it can initiate anonymous
communication on the road.
2) Generation Protocol: After obtaining a ticket δa from the
MVD, Va has to communicate with a nearby RSU(s), e.g., Ri ,
to generate pseudonyms. Ri periodically broadcasts its identity
certificate CertRi derived from the MVD, where Ri serves as
both the identity and the public key for the RSU. Table III
illustrates this procedure, which is known as the generation
protocol. Vehicle Va creates the 3-tuple Δa by concatenating its
ticket, the signature of the ticket, and a symmetric key K(a,i) .
For encryption, the vehicle uses the IBE scheme with Ri as the
ID to generate C. When Ri receives C, it uses its private key SRi
to decrypt C and then verifies SIG(δa ; SMVD ) using PMVD . On
successful verification, Ri computes a pseudonym token τ(a,i) .
RSU Ri also obtains expiration time t(a,i) for the token. It then
creates the message




M = τ(a,i) , t(a,i) , SIG τ(a,i) , t(a,i) ; SRi , γ(a,i)
which is also shown in Table III. Ri encrypts it using secret
key K(a,i) in C and transmits it to Va as C  . RSU Ri also
stores the mapping between the ticket and the tuple (mapaRi )
in a hashed map for O(1) time retrieval. Vehicle Va decrypts
C  and generates its pseudonym by using τ(a,i) . Encryption and
decryption in the generation protocol are symmetric.
Our scheme allows Va to obtain multiple tokens from a
k
single RSU by using the same ticket δa . In this setup, τ(a,i)
k
represents the kth token issued to vehicle Va by Ri . Token τ(a,i)
is used by Va in the extraction protocol to generate the kth
pseudonym. The value of k is upper bounded by a threshold
value RTH , which is a tunable system parameter. The value of
RTH determines the extent of anonymity, with higher values of
RTH , resulting in a higher number of pseudonyms and, thus,
better anonymity. We do not perform analysis to obtain the
best value for RTH under different settings. However, we note
that it is easy to calculate an RTH value for a given anonymity
requirement based on a threshold on the probability of correct
identification of a token.
3) Extraction Protocol: A vehicle Va uses the extraction
protocol, which is illustrated in Algorithm 2 to generate a
pseudonym. Let Va obtain n tokens from RSU Ri . As illustrated
in the protocol, Va chooses one of the n tokens. Without loss
j
j
of generality, let this token be τ(a,i)
. The value γ(a,i)
(which
j
is obtained from Ri ) is the private key component of τ(a,i)
.

740

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 12, NO. 3, SEPTEMBER 2011

TABLE III
S CHEMATIC OF THE G ENERATION P ROTOCOL I NVOLVING Va AND Ri

Successful completion of the extraction protocol outputs a
pseudonym PNj(a,i) for Va , as shown in the algorithm. The
vehicle can use pseudonym PNj(a,i) to
communication. Certificate CertRi is part

perform anonymous
of the pseudonym to
allow another vehicle that receives pseudonym PNj(a,i) from Va
to verify Va ’s authenticity by verifying the signature.
Algorithm 2: Extraction Protocol performed by Va
j
1:Randomly selects τ(a,i)
(1 ≤ j ≤ n).
2:Chooses a random value raj ∈ Z∗p .
3:Computes σaj = raj Sa .
j
j
, tj(a,i) , SIG(τ(a,i)
, tj(a,i) ; SRi ),
4:PNj(a,i) = σaj P, τ(a,i)
j
CertRi  is the pseudonym, and τ(a,i)
is the public key.
j
j
5:Stores S(a,i)
= γ(a,i)
Sa as the private key.

C. Anonymous Communication in PACP
Here, we illustrate anonymous communication using PACP.
We use two vehicles, namely, Va and Vb , for our illustration.
Consider a scenario where Va needs information about the road
conditions. Va sends a broadcast request for the information
using its pseudonym PNj(a,i) . Vehicle Vb that has the information uses pseudonym PNj(a,i) to encrypt it in a message
and sends it to Va . On receiving the encrypted message, Va
j
decrypts the message using private key S(a,i)
. In another scenario, vehicle Va can itself initiate a road conditions broadcast.
When Va broadcasts a message with road conditions in its
vicinity, other vehicles can use the public key of its pseudonym
j
j
= γ(a,i)
Sa P to verify the BLS signature generated by Va
τ(a,i)
j
using private key γ(a,i)
Sa . In what follows, we describe the
encryption and decryption procedures.

Algorithm 3: Encryption Protocol performed by Vb
Require: Pseudonym PNj(a,i) of Va and message M.
j
1:Verify SIG(τ(a,i)
, t(a,i) ; SRi ) and compute λj(a,i) =
j
e(τ(a,i)
, σaj P ).
2:Choose k ∈ {0, 1}n randomly.
3:Compute ρ = H2 (k, M).
4:Compute ciphertext as
C = H(ρP ) ⊕ (λj(a,i) )k , e(P, σaj P )k , M ⊕
H1 (e(σaj P, H(ρP )P )).
5:Transmit C to Va .

Encryption Protocol: Algorithm 3 illustrates the encryption protocol used by Vb to send a message to Va . Vehicle
Vb receives the pseudonym of Va and first verifies signature
j
, t(a,i) ; SRi ) to ensure that Va is a genuine member
SIG(τ(a,i)
of the system and has been authenticated by an RSU. For
verification, Vb first verifies CertRi using PMVD and then uses
j
, t(a,i) ; SRi ). If
Ri from CertRi to verify signature SIG(τ(a,i)
verification is successful, Vb computes


j
λj(a,i) = e τ(a,i)
, σaj P .
To encrypt the plain-text message M ∈ {0, 1}n for Va with
pseudonym PNj(a,i) , Vb performs Steps 2–4 of Algorithm 3.
Symbol ⊕ stands for the XOR operation.
Decryption Protocol: To decrypt ciphertext C sent by Vb ,
Va performs the decryption protocol given in Algorithm 4.
We denote ciphertext C using the tuple C = U, V, W , where
U = H(ρP ) ⊕ (λj(a,i) )k , V = e(P, σaj P )k , and W = M ⊕
H1 (e(σaj P, H(ρP )P )). The protocol is fairly self-explanatory.
j
.
The decryption of C is done using private key S(a,i)

HUANG et al.: PACP PROTOCOL FOR VANETs

741

Algorithm 4: Decryption Protocol performed by Va
j
Require: C = U, V, W , S(a,i)
.

1:Compute Γj(a,i) = U ⊕ V


2:Retrieve M = W ⊕

j
S(a,i)

.

H1 (e(σaj P, Γj(a,i) P )).

Now, we will show the correctness of the encryption and
decryption protocols. We first demonstrate the correctness of
hash operation H1 that is used in the encryption and decryption
protocols (see Algorithms 3 and 4). To prove the correctness of
the encryption and decryption protocols, we need to show that
j
XOR-ing of W with H1 (e(σaj P, Γ(a,i) P )) recovers message M,
as shown in the equation at the bottom of the page. From the
preceding derivations, we have
 

 

= H1 e σaj P, H(ρP )P . (1)
H1 e σaj P, Γj(a,i) P
Using (1), it is easy to prove that XOR-ing W with
H1 (e(σaj P, Γj(a,i) P )) recovers message M. We note that, in
[20], Boneh and Franklin proved that the hash functions in
the FullIndent scheme are secure against the chosen ciphertext
attack under the random oracle model. Hash function H1 that
is used in the PACP scheme possesses this property. Next, we
present the revocation protocol.

D. Revocation Protocol
Revocation is a critical issue for an anonymous communication system. In VANETs, revocation is required to prevent
malicious vehicles from launching security attacks against legitimate vehicles. Fig. 3 shows our revocation protocol.

If a vehicle has performed a violation, other vehicles in its
vicinity would have observed the violation and will report the
violator to the nearest RSU. The reporting vehicles will use the
pseudonym of the violating vehicle to identify it. The violation
events are recorded by the EDR of the vehicles. The EDR of a
reporting vehicle Va instructs the OBU to create a violation rea
a
). The OBU creates MVR
= VIO(Type), PNj(m,i) ,
port (MVR
where VIO(Type) is the type of violation, and PNj(m,i) is the
pseudonym used by the alleged malicious vehicle Vm . Designing the violation message is trivial; hence, we do not discuss
it in this paper. When Va enters the communication range of an
a
) is encrypted using the RSU’s identity
RSU, the message (MVR
and transmitted to it. All vehicles reporting the event will report
their violation report to the nearest RSU. For instance, let the
RSU closest to Va be denoted by Rt . Vehicle Va and other
vehicles in the vicinity send their violation report to Rt . RSU
Rt decrypts all messages received from the vehicles (including
Va ) and determines the severity of the violation by analyzing
the messages. Then, RSU Rt sends pseudonym PNj(m,i) used
by Vm to the MVD for revocation. The MVD identifies RSU
Ri that had given Vm the token by using CertRi contained in
the pseudonym. The MVD contacts Ri and obtains δm , i.e., the
vehicle’s ticket, from Ri . The MVD then looks up the mapping
mapm
MVD and extracts IDm the identity of vehicle Vm using the
ticket. Once Vm is identified, the MVD transmits the ticket of
Vm to all the RSUs in the network in the form of an updated
RL. If Rt is compromised in the presented revocation protocol,
in which it may collude with Vm , then Vm cannot be revoked.
However, we note that an easy fix to this problem is to have the
reporting vehicle transmit revocation reports to multiple RSUs.
Since we assume that only a few RSUs can be compromised, as
long as one revocation report reaches the MVD, the malicious
vehicle Vm can be identified. If a vehicle Vm is in the RL, then
the RSUs do not help it in generating tokens for anonymous

 
 
 


Sj
H e σaj P, Γj(a,i) P
= H1 e σaj P, U ⊕ V (a,i) P
⎛
⎛ ⎛
⎞ ⎞⎞
⎜
⎜ ⎜
⎟ ⎟⎟
j

kS(a,i)
⎜
⎜ ⎜
⎟ ⎟⎟
= H1 ⎜e ⎜σaj P, ⎜H(ρP ) ⊕ (λj )k ⊕ e P, σaj P
⎟ P ⎟⎟
⎝
⎝ ⎝

 

⎠ ⎠⎠
U
V

S

j
(a,i)

 
 

kγ j
S σj
= H1 e σaj P, H(ρP ) ⊕ (λj )k ⊕ e(P, P ) (a,i) a a P

 
 

k
j
j
kγ(a,i)
S a σa
j
j
j
= H1 e σa P, H(ρP ) ⊕ e τ(a,i) , σa P ⊕ e(P, P )
P

 
 

k
j
j
kγ(a,i)
S a σa
j
j
j
= H1 e σa P, H(ρP ) ⊕ e γ(a,i) δa , σa P ⊕ e(P, P )
P

 
 

k
kγ j
S σj
j
= H1 e σaj P, H(ρP ) ⊕ e γ(a,i)
Sa P, σaj P ⊕ e(P, P ) (a,i) a a
P
 
 

kγ j
S σj
kγ j
S σj
= H1 e σaj P, H(ρP ) ⊕ e(P, P ) (a,i) a a ⊕ e(P, P ) (a,i) a a P
 

= H1 e σaj P, H(ρP )P

742

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 12, NO. 3, SEPTEMBER 2011

Fig. 3. Schematic of the revocation protocol. Vehicle Vm is the vehicle to be revoked, and Va is the reporting vehicle.

communication. This effectively revokes Vm once its current
pseudonyms expire. In a more proactive mechanism, the RSUs
can broadcast the pseudonym of Vm to the other vehicles to
incorporate revocation. The revocation cost is negligible since
checking is performed between an RSU and the MVD, which
we assume to be connected using the Internet.
V. P ERFORMANCE A SSESSMENTS OF
S ECURITY AND P RIVACY
Here, we first analyze the security and anonymity strength
of our PACP scheme with reference to the attack scenarios
presented in Section III-C. Then, we compare the security
performance between PACP and ECPP.
A. Security and Anonymity Analysis
In the PACP scheme, signature and encryption are fundamental security protections to counter modification, eavesdropping,
replay, and injection and impersonation attacks. To modify a
message sent by vehicle Vb to vehicle Va , the adversary has to
decrypt the message, modify it, and then encrypt it using Va ’s
pseudonym. To decrypt the message, the adversary needs the
private key corresponding to the pseudonym of Va , which is not
available to the adversary, thus making it impossible to modify
the message. Without going into the details, we note that replay
attacks can be easily prevented with the use of authentication
and sequence numbers. Using PACP, an external attacker cannot
generate a valid signature using other vehicles’ pseudonym. As
a result, it cannot inject fake messages into the system.
Theorem 1: The PACP scheme is semantically secure
against the impersonation attack.
Proof: Our proof is based on sematic security. In general,
a semantic security proof assumes that the attackers are passive.
The sematic security proof is usually done by reducing the

solution to a well-known hard problem, such as the ECDLP
used in this paper.
To perform an impersonation attack, the adversary must be
able to derive the secret, i.e., Sa , owned by a legitimate vehicle
Va . To assess the security strength of the PACP scheme, we
use the fact that the ECDLP is computationally hard. The proof
of hardness of ECC is also based on the fact that the ECDLP is
computationally hard. We show that either the adversary cannot
attack a building block of the PACP scheme or those that it can
attack are semantically secure. The registration protocol cannot
be compromised by the adversary as it is performed offline,
whereas the extraction protocol cannot be compromised by an
adversary as it has no message exchanges.
We now consider the encryption protocol. An adversary
cannot impersonate a legitimate noncompromised vehicle Va
as the message encrypted using Va ’s pseudonym cannot be
decrypted without using Va ’s private key, which the adversary
does not possess. Since k is randomly chosen, ρ is also random.
Consequently, the contents of C are random for the adversary.
The generation and decryption protocols are the only protocols that an adversary could attack to break down the system.
In what follows, we show that these protocols are semantically
secure.
• Generation protocol: The adversary will want to attack
the generation protocol to obtain Sa . However, even if
the adversary compromises an RSU Ri and obtains ticket
δa (= Sa P ), obtaining Sa from δa is at least as hard as
solving the ECDLP. Hence, it cannot obtain the true identity of Va . In addition, if Va uses multiple tickets obtained
from the MVD, every time it interacts with Ri , it can use a
randomly chosen ticket; thus, the ticket itself cannot lead
to the compromise of Va ’s secret Sa . The communication
between an uncompromised RSU and Va is also secure
since the traffic is protected by the encryption using K(a,i) .
In addition, γ(a,i) is random, making C  random as well.

HUANG et al.: PACP PROTOCOL FOR VANETs

j
• Decryption protocol: Parameters P , σaj P , and τ(a,i)
are
publicly known. To decrypt a message, the adversary
j
j
to obtain S(a,i)
(correspondattempts to reduce τ(a,i)
ing private key). Another direction of attack may be
for the adversary to attempt to unmask the XOR value
H1 (e(σaj P, H(ρP )P )) associated with the message. The
adversary cannot generate the private key as it is equivalent
to solving the ECDLP. In addition, the adversary cannot
unmask the hash value because the unmasking operation
requires the computation of a pairing on H(ρP )P and
σaj P . In addition, the adversary also does not possess M
and random number k. All these ensure that the adversary
cannot decrypt the message.

This proves that the PACP scheme is semantically secure
and the attackers cannot derive any secrets of vehicle Va . As
a result, the adversary cannot use a pseudonym for vehicle Va
to generate a valid signature for impersonation attacks.

Theorem 2: PACP is secure against colluding attacks to
discover the vehicle’s identity.
Proof: The goals of using pseudonyms are twofold:
1) preventing attackers from linking actions from the same
vehicle and 2) preventing attackers from discovering the real
identity of the vehicle (or discover the private key). Preventing
attackers (including colluding attackers) from linking actions
performed by the same vehicle can be achieved by using
multiple pseudonyms for each communication session, road
segment, or time period. This can be achieved by deriving
multiple pseudonyms from RSUs, which has been proposed
by many previous solutions. PACP can achieve a similar level
of anonymity using the same approaches. However, the trust
model of using PACP is different from previous solutions,
as we will discuss in Section V-B. Preventing attackers from
discovering the real identity of a vehicle has been discussed
in Theorem 1. Thus, PACP achieves its desired anonymity
properties.

B. Comparative Study With ECPP
Now, we compare the security of our PACP scheme with
the ECPP scheme [6]. We compare PACP with ECPP as both
of them aim to achieve anonymous and unlinkable communication for the vehicles and both are based on ECC. ECPP
provides mutual authentication between RSUs and vehicles,
and its protocol that generates the anonymous keys forms the
basis for anonymity. ECPP has been demonstrated (using the
hardness of the ECDLP) to be secure against impersonation and
compromised RSUs. In PACP, the generation algorithm uses
the same basis for anonymity. We have proved in Theorem 1
that it is computationally hard for the adversary to compromise
the generation protocol or impersonate either the vehicle or the
RSU. The ECPP protocol aims at designing a secure privacy
protocol for transmission of safety messages while at the same
time allowing for fast revocation of the malicious vehicles.
PACP provides the same security and privacy features with a
faster revocation mechanism. Particularly, the search for the
malicious vehicles in the RSUs and the MVD’s databases has
an asymptotic time complexity of O(M ), in comparison with

743

O(M log N ) for ECPP, where M is the number of vehicles to
be revoked, and N is the total number of vehicles. This is due to
the use of hash maps to store two mappings between the token
and the ticket at the RSU, and the ticket and the ID at the MVD,
which allow O(1) lookup for each revoked vehicle.
The operation model is different in that the pseudonym
generation of PACP is done by the vehicles, which is better
than their generation at the RSUs, as is done in ECPP. This
puts less burden on an RSU and allows it to be more effective
in handling denser traffic. The aforementioned analysis shows
that PACP will scale better than ECPP.
VI. E VALUATION R ESULTS AND A NALYSES
Here, we present our evaluation results. The schemes proposed in the literature can be broadly categorized into those
based on elliptical curve cryptography and those based on RSA.
We compare our PACP protocol with the best schemes in each
category. The schemes we compare with are the ellipticalcurve-based VANET standard named ECIES [22], the ECPP
scheme [6], and the RSA-based schemes in [11]. In Theorem 1,
we proved that our PACP protocol is secure against the presented attack scenarios. Here, we show that our protocol can
be implemented in current generation vehicular networks and
that it admirably performs in comparison with the existing
schemes. We compare the schemes on the basis of average
latency experienced at the RSUs for pseudonym generation, the
time taken to perform the encryption and decryption protocols
that ensure anonymity, and the running time complexity of
revocation. The latency experienced at the RSU has to be as
small as possible because high latency results in a few number
of vehicles obtaining their tokens in a given time period. Not
all schemes can be compared with PACP on the aforementioned
comparison criteria. For the latency measurements, we compare
with ECPP; for encryption and decryption, we compare with the
ECIES- and RSA-based schemes; and for complexity analysis
of revocation, we compare with the ECPP scheme. For the
RSA-based schemes, the basic building block is RSA; hence,
instead of comparing with each scheme, we compare PACP
with only RSA.
All the schemes were implemented on our simulator written in C++. We do not use currently available simulators for
VANETs because the results of the performance measurements
are independent of the simulator used. For the elliptical curve
and pairing operations, we used the Pairing-Based Cryptography (PBC) Library [23]. We also used the Crypto++ 5.4 Library
[24] for the ECIES implementation, as well as routines such
as the SHA-1 hash function. For ECC and pairing, we used
the Type-A curve defined in the PBC library with the default
parameters [23].
All our implementations were done on a 2-GHz machine
with 2-GB memory, running Cygwin 1.5.25–15 [25] with the
gcc version 3.3. All the results of analyses were averaged over
1000 randomized simulation runs. For RSA and ECC, we chose
key sizes of 1024 and 160 bits, respectively, to ensure the same
level of security.
Table IV presents the time taken to execute basic operations
such as signing, encryption, and decryption for the various

744

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 12, NO. 3, SEPTEMBER 2011

TABLE IV
E XECUTION T IME OF BASIC O PERATIONS PER B LOCK

schemes. All the timings reported in Table IV are averaged over
1000 randomized runs.
Fig. 4 shows the time taken by RSA (RSA-based schemes),
ECIES, and our PACP scheme to perform encryption and decryption. We ignore the other aspects of the corresponding protocols as they will take negligible time in comparison. The RSA
protocol is much faster in comparison with ECIES and PACP in
encryption; this is because in RSA, encryption generally uses a
small prime number for exponentiation, which is very fast. The
ECC scheme on which ECIES and PACP are based does not
have this advantage; hence, the running time of encryption is
higher in ECIES and PACP. We note that the performance of encryption in PACP is, on average, 18% better than that in ECIES.
This is because the PACP protocol uses only two pairings and
one-point multiplication operation, whereas ECIES uses threepoint multiplications and one expensive map-to-point operation
to provide the same level of security. For decryption, RSA has
the worst execution time of the three schemes. Here, PACP outperforms RSA by 71.65% and ECIES by 60.80%, taking only
8 ms for decryption. In VANETs, having a small decryption
time is highly desirable as it reduces the protocol overhead
at the vehicles receiving the message. A smaller decryption
time allows the vehicles receiving a message to decrypt the
message faster, hence allowing more time for an appropriate
response. The ciphertext size is similar for each of the presented solutions. However, PACP has the least payload size in
comparison with the other schemes. This is because PACP uses
the BLS signature scheme [26], in which the authors showed
that a BLS signature of length 154 bits has security comparable with a 320-bit digital signature algorithm or a 320-bit
elliptic curve digital signature algorithm.
Fig. 5 shows the comparison between the total time taken
by an RSU for token generation when the RSA-based, ECPP,
and PACP schemes are used. We study the total time for token

Fig. 4.

Protocol comparison.

Fig. 5.

Protocol latency comparison.

generation at the RSU because it is also an overhead of the
anonymity protocols, and the lower the total time required, the
more desirable the protocol. The number of vehicles communicating with the RSU was increased from 10 to 100, and for
each vehicle, ten tokens were requested. As we have pointed
out before, low latency at the RSU is desirable as it allows
more vehicles to obtain tokens from the RSU. The latency
at the RSU for the generation of a single token using each
l
l
= 29.6 ms, TECPP
=
of the three schemes is given as TRSA
l
l
154.3 ms, and TPACP = 58.86 ms. For RSA, TRSA is dominated by the sum of the time taken by the RSU to verify
the vehicle’s identity certificate, the time required to sign the
new pseudonym, and, finally, the time required to encrypt the
pseudonym with the public key of the vehicle. For ECPP,
the latency is computed as the total time taken by the RSU
to perform 13-point multiplication and six pairing operations
[6]. The time consumed by other operations such as random
number generation is ignored. In our PACP scheme, the latency
is the sum of the time taken by the RSU to decrypt the message,
verify the signature of the ticket, perform a point multiplication,
and generate the signature of the token. The time taken for
performing symmetric key encryption is negligible. We ignore
the time taken for communication between the vehicle and
the RSU, as our objective is to demonstrate the latency of
computation of the tokens. The communication latency does
not depend on our scheme but instead depends on factors such
as the number of vehicles communicating with the RSU, the
number of tokens per vehicle, and the medium-access control
protocol. This latency affects all protocols in the same way.
From the figure, it is clear that the RSA-based solutions have
the least latency, followed by the PACP and ECPP schemes.

HUANG et al.: PACP PROTOCOL FOR VANETs

Fig. 6.

745

Protocol latency analysis of PACP.
Fig. 7. Comparison of search times for revocation.

The reason for low latency in RSA is because of the efficiency
of the public key operations for encryption.
However, the RSA-based schemes have their own drawbacks.
First, the decryption at the vehicle is generally very slow and,
hence, may not be applicable in a practical setting. Second,
and more importantly, the existing RSA-based schemes do not
provide the same level of security as PACP. In these schemes,
when an RSU issues a pseudonym, it also gets to know the
pseudonym. If the RSU is compromised, all the pseudonyms
issued by the RSU will be known to the attacker. As a result, the attacker can easily track all the vehicles that use the
pseudonyms issued by the compromised RSU. In comparison,
in our PACP scheme, the pseudonyms are unknown to the
RSUs; hence, PACP provides improved security. When compared with the popular ECPP scheme, our PACP scheme has
less than half the latency. This is because of the use of fewer
pairing and multiplication operations. Hence, PACP is more
secure and efficient when compared with the existing RSAbased schemes and ECPP in terms of RSU latency. Fig. 6 shows
the time taken by a single RSU for token generation when the
number of vehicles increases from 1 to 100 and the number
of pseudonyms required by each vehicle increases from 1 to
10. With an increase in the number of vehicles or the number
of pseudonyms, the latency at the RSU increases because the
RSU has to generate more tokens. We note that our scheme
scales pretty well. Even when the number of vehicles is 100
and the number of pseudonyms required is 10, the latency for
pseudonym generation is less than 60 s.
Fig. 7 shows the comparison of the time taken by an RSU and
the MVD to search for a vehicle to revoke it from the system.
We compare our scheme with the ECPP scheme as it is the
only scheme in the literature that studies node revocation in any
significant detail. In our PACP scheme, the MVD and the RSUs
take much less time to search the revoked node, in comparison
with that in the ECPP scheme. This is because of the difference
in the asymptotic complexity of search operation as discussed
in Section IV-C. Hence, our scheme is faster.
The simulation results and the security analyses demonstrate
the effectiveness and efficiency of our PACP scheme. Our
scheme has a protocol latency that is comparable to the faster
schemes based on RSA while having much lower search and
revocation times when compared with the ECPP scheme; this
shows that it will scale well with the increase in the number of
vehicles in the network. Hence, PACP provides high security
and better scalability.

VII. C ONCLUSION AND F UTURE W ORK
In this paper, we have proposed a novel PACP protocol for
the vehicles in VANETs. Our protocol not only provides the
desired level of anonymity to the vehicles but also is efficient
in computation and storage. It also performs better than other
state-of-the-art schemes. In the future, we would like to evaluate
PACP on a large-scale VANET testbed with varying vehicle
mobility models.
R EFERENCES
[1] J. Blum, A. Eskandarian, and L. Hoffman, “Challenges of intervehicle ad
hoc networks,” IEEE Trans. Intell. Transp. Syst., vol. 5, no. 4, pp. 347–
351, Dec. 2004.
[2] M. Raya and J. Hubaux, “Securing vehicular ad hoc networks,” J. Comput.
Security, vol. 15, no. 1, pp. 39–68, Jan. 2007.
[3] C. Zhang, R. Lu, X. Lin, P. Ho, and X. Shen, “An efficient identity-based
batch verification scheme for vehicular sensor networks,” in Proc. IEEE
INFOCOM, Apr. 2008, pp. 246–250.
[4] H. Zhu, X. Lin, R. Lu, P. Ho, and X. Shen, “AEMA: An aggregated
emergency message authentication scheme for enhancing the security of
vehicular ad hoc networks,” in Proc. IEEE ICC, May 2008, pp. 1436–
1440.
[5] J. Hubaux and S. Luo, “The security and privacy of smart vehicles,” IEEE
Security Privacy, vol. 2, no. 3, pp. 49–55, May/Jun. 2004.
[6] R. Lu, X. Lin, H. Zhu, P. Ho, and X. Shen, “ECPP: Efficient conditional
privacy preservation protocol for secure vehicular communications,” in
Proc. IEEE INFOCOM, Apr. 2008, pp. 1229–1237.
[7] P. Papadimitratos, A. Kung, J. Hubaux, and F. Kargl, “Privacy and identity
management for vehicular communication systems: A position paper,”
in Proc. Workshop Standards Privacy User-Centric Identity Manage.,
Zurich, Switzerland, Jul. 2006.
[8] I. Blake, G. Seroussi, and N. Smart, Advances in Elliptic Curve Cryptography. Cambridge, U.K.: Cambridge Univ. Press, 2005, ser. London
Mathematical Society Lecture Note Series 317.
[9] N. Koblitz, “Elliptic curve cryptosystems,” Math. Comput., vol. 48,
no. 177, pp. 203–209, 1987.
[10] I. Blake, V. Murty, and G. Xu, “Refinements of Miller’s algorithm for
computing the Weil/Tate pairing,” J. Algorithms, vol. 58, no. 2, pp. 134–
149, Feb. 2006.
[11] M. Raya, P. Papadimitratos, and J. Hubaux, “Securing vehicular communications,” IEEE Wireless Commun., vol. 13, no. 5, pp. 8–15, Oct. 2006.
[12] X. Lin, X. Sun, P. Ho, and X. Shen, “GSIS: A secure and privacypreserving protocol for vehicular communications,” IEEE Trans. Veh.
Technol., vol. 56, no. 6, pp. 3442–3456, Nov. 2007.
[13] A. Wasef and X. Shen, “PPGCV: Privacy preserving group communications protocol for vehicular ad hoc networks,” in Proc. IEEE ICC,
May 2008, pp. 1458–1463.
[14] H. Xie, L. Kulik, and E. Tanin, “Privacy-aware traffic monitoring,” IEEE
Trans. Intell. Transp. Syst., vol. 11, no. 1, pp. 61–70, Mar. 2010.
[15] U.S. Department of Transportation, National Highway Traffic Safety
Administration, Vehicle Safety Communications Project—Final Rep.,
Apr. 2006. [Online]. Available: http://www.nhtsa.gov/DOT/NHTSA/
NRD/Multimedia/PDFs/Crash%20Avoidance/2005/CAMP3scr.pdf
[16] M. Raya and J.-P. Hubaux, “The security of vehicular ad hoc networks,” in
Proc. 3rd ACM Workshop Security Ad Hoc Sens. Netw., 2005, pp. 11–21.

746

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 12, NO. 3, SEPTEMBER 2011

[17] C. Cseh, “Architecture of the Dedicated Short-Range Communications
(DSRC) protocol,” in Proc. 48th IEEE VTC, May 1998, vol. 3, pp. 2095–
2099.
[18] A. Studer, F. Bai, B. Bellur, and A. Perrig, “Flexible, extensible, and
efficient VANET authentication,” J. Commun. Netw., vol. 11, no. 6,
pp. 574–588, 2009.
[19] A. Menezes, S. Vanstone, and T. Okamoto, “Reducing elliptic curve logarithms to logarithms in a finite field,” in Proc. 23rd Annu. ACM STOC,
1991, pp. 80–89.
[20] D. Boneh and M. Franklin, “Identity-based encryption from the Weil
pairing,” in Proc. 21st Annu. Int. Cryptology Conf. Adv. Cryptology, 2001,
pp. 213–229.
[21] D. Boneh, B. Lynn, and H. Shacham, “Short signatures from the Weil
pairing,” in Proc. Asiacrypt, vol. 2248, LNCS, 2001, pp. 514–532.
[22] Unapproved IEEE Draft Trial-Use Standard for Wireless Access in Vehicular Environments—Security Services for Applications and Management
Messages Replaced by Approved Draft, IEEE Std. P1609.2/D7, 2006.
[23] Pairing-Based Cryptography Library. [Online]. Avaialble: http://crypto.
stanford.edu/pbc/
[24] Crpto++ Library 5.5.2: A Free C++ Class Library of Cryptographic
Schemes. [Online]. Avaialble: http://www.cryptopp.com/
[25] Cygwin: Linux Environment Emulator for Windows. [Online]. Available:
http://www.cygwin.com/
[26] D. Boneh, B. Lynn, and H. Shacham, “Short signatures from the Weil
pairing,” J. Cryptol., vol. 17, no. 4, pp. 297–319, 2004.

Dijiang Huang (M’00–SM’11) received the B.S. degree from Beijing University of Posts and Telecommunications, Beijing, China, in 1995 and the M.S.
and Ph.D. degrees from the University of MissouriKansas City in 2001 and 2004, respectively.
In 2005, he joined Arizona State University,
(ASU), Tempe, as an Assistant Professor. He is
currently an Associate Professor with the School
of Computing, Informatics, and Decision Systems
Engineering, ASU. His current research interests
are computer networking, security, and privacy. His
research has been supported by federal agencies, including the National Science
Foundation, the Office of Naval Research (ONR), the Air Force Research
Laboratory, and the U.S. Army Research Office.
Prof. Huang is an Editor of the IEEE C OMMUNICATIONS S URVEYS AND
T UTORIALS and an Associate Editor of the Journal of Network and Systems
Management. His recent conference services include being a Technical Program Committee Cochair of the 2011 IEEE Globecom Communication and
Information System Security Symposium and a Symposium Cochair of the
2012 Mobile Computing and Vehicle Communications of the International
Conference on Computing, Networking, and Communications. He was a recipient of the 2010 ONR Young Investigator Award.

Satyajayant Misra (M’04) received the integrated
M.Sc. (Tech.) information systems and M.Sc.
(Hons.) physics degrees from Birla Institute of Technology and Science, Pilani, India, in 2003 and the
Ph.D. degree in computer science from Arizona State
University, Tempe, in 2009.
He is currently an Assistant Professor with the
Department of Computer Science, New Mexico State
University, Las Cruces. His research interests include
algorithm and protocol design for security, privacy,
reliability, and efficient energy harvesting in wireless
networks.
Prof. Misra serves on the Editorial Board of the IEEE C OMMUNICATIONS
S URVEYS AND T UTORIALS. He has served on the Executive Committee of
the 2011 IEEE Communications Society Conference on Sensor, Mesh, and
Ad Hoc Communications and Networks and on the Technical Program Committee of several conferences. He will serve as the Vice Chair for Information
Systems for the 2012 IEEE Conference on Computer Communications.

Mayank Verma (M’06) received the M.S. degree
from Arizona State University, Tempe, in 2008.
He is currently a Security and Networking Engineer with Brocade Communications, Encinitas, CA.

Guoliang Xue (M’96–SM’99–F’11) received the
B.S. degree in mathematics and the M.S. degree in
operations research from Qufu Normal University,
Qufu, China, in 1981 and 1984, respectively, and the
Ph.D. degree in computer science from the University of Minnesota, Minneapolis, in 1991.
He is currently a Professor of computer science and engineering with Arizona State University,
Tempe. He has been continuously supported by federal agencies, including the National Science Foundation (NSF) and the U.S. Army Research Office.
His research interests include survivability, security, and resource allocation
issues in networks, ranging from optical networks to wireless mesh and sensor
networks. He has published more than 180 papers in the aforementioned areas.
Prof. Xue is an Associate Editor of the IEEE/ACM T RANSACTIONS ON
N ETWORKING and IEEE Network Magazine, as well as an Editorial Advisory
Board Member of the IEEE T RANSACTIONS ON W IRELESS C OMMUNI CATIONS . He served as an Associate Editor of the IEEE T RANSACTIONS
ON W IRELESS C OMMUNICATIONS and of the Computer Networks journal.
His recent conference services include being a Technical Program Committee Cochair of the 2010 IEEE Conference on Computer Communications, a
Symposium Cochair of the 2009 IEEE International Conference on Communications, and a General Cochair of the 2008 IEEE International Conference on
High Performance Switching and Routing. He is a Distinguished Lecturer of
the IEEE Communications Society. He was a recipient of the NSF Research
Initiation Award in 1994, the Best Paper Award at the IEEE Global Communications Conference in 2007, and the Best Paper Runner-up Award at the IEEE
International Conference on Network Protocols in 2010.

Source Routing Based Pairwise Key Establishment Protocol for
Sensor Networks
Dijiang Huang

Manish Melita

Deep Medhi

Computer Science and Electrical Engineering Department
University of Missouri-Kansas City
Kansas City, Missouri 64110, USA.
{dhuang, manish.mehta, dmedhi}@umkc.edu
Abstract

(RKP) schemes ([3, 4, 5, 6, 71) have been proposed t o
provide flexibility for the designers of Sensor networks
to tailor network design to the available storage and
the security requirements. After deployment of sensors, each sensor discovers key sharing relations among
all its neighbors. The shared key discovery protocols
has been described in [a] and [4). Since RKP schemes
have limited number of keys pre-installed in sensors, a
sensor may not share a key with all of its neighbors. In
this case, a Pairwise Key EstabIishment (PKE) protocol is required to set up pairwise keys with all its neighbors. In all recent proposals, during the PKE phase,
the intermediate nodes may not necessarily be located
within the source node’s communication range. Thus,
the source may not be able to determine paths to set
up pairwise keys with its neighbors. In other words,
the key setup requests must be flooded instead of using chosen paths. Consequently, the communication
overhead invoked by the pairwise key requests can be
prohibitively high. Studies in [l]show that the key
path length (number of forwarding hops) for PKE is
longer when the key graph (is defined in Section 2.1.
connectivity is low. Thus, flooding the key setup requests results in high communication overhead.

Sensor networks are composed of a large number of
low power sensor devices. For secure communication
among sensors, secret keys must be established between
them. The establishment of secret keys after deployment of sensors requires wireless communication. Because of the energy constraints, an efficient key establishment scheme cannot be designed without considering the power consumption factor in wireless communication. I n order to reduce the communication overhead, we propose a source routing based paimise key
establishment protocol for large-scale sensor networks.
W e then use a probability model proposed in [l] to analyze the communication overhead, and security strength
of the scheme.

1

Introduction

Sensor networks are composed of a large number of
low-power sensor devices. Typically, these networks
are installed to collect sensed data from sensors deployed in a large area. Within a network, sensors
communicate among themselves to exchange data and
routing information. Because of “wireless” nature of
communications among sensors, sensor networks are
vulnerable to various active and passive attacks on
communication protocols. This demands secure communication among sensors.
Typically, sensor networks are deployed with large
quantities of sensor devices. According to [2], the number of sensor nodes deployed in studying a phenomenon may be in the order of hundreds or thousands;
depending on the application, the number may reach
millions. Due to inherent storage constraints, it is infeasible for a sensor device to store a shared key for
every other sensor in the system. Also, because of
the lack of post-deployment geographic configuration
information of the sensors, keys cannot be selectively
stored in sensor devices. Random Key Predistribution

0-7803-8991-3/05/$20.00 0 2005 IEEE

Studies in [8] show that the energy consumption due
to communication in sensors is several orders higher
than that due t o coinputation overhead. In order to reduce the communication overhead, we propose a source
routing based PKE protocol in which the sensors set
up pairwise keys using only their neighbor nodes. In
other words, each sensor can choose paths to set up
pairwise keys with its neighbors. This design significantly reduces the communication overhead involved
in the PKE phase. Similar to the recent schemes in
[3, 4, 5, 6, 71, our model is based on networks with
uniformly distributed sensors. We give an analysis
of communication overhead due to the proposed PKE

177

_-- - - - _-.

Figure 1: Key graph example (centered with node 1)
protocol.
The rest of the paper is organized as foliows: An
energy-efficient pairwise key establishment protocol is
described in Section 2. A performance analysis addressing communication overhead, security strength,
and energy consumption for the protocol is given is
Section 3. Section 4 concludes the work and provides
future research directions.

2

2.1

An Energy-efficient Pairwise Key Establish Protocol
Key Graph

Defini?;ciri 1 (Key Graph) A key graph muinf 0 : i : d by node i is defined as G, =
E,) where, V , =
{ j l j 2s a neighbor o f i and j = i}, E, = ( e 2 k 1 j , k E V,
and k is a neighbor of j , and j is a neighbor Of k , and
j shares at least one key after the shared key discovery
phase with k}.

In Figure 1, we present an example of key graph,
which is centered by node 1. The dash line represents
the communication range of node 1 and the solid line
represents the shared key relation between nodes.
2.2 Protocol Overview
In [4, 6 , 3, 5 , 71, the authors assume that there exists a key discovery protocol (hello protocol) that a
sensor can rely on to discover all its neighbors and the
shared key relations among its neighbors. After using the key discovery protocol, a node, say i , knows
(1) all nodes located within its range (set Wi),
we call
them W-neighbors of z; (2) all its W-neighbors n-ho
share at least one key with it (set Qi),
we call them Qneighbors of i; (3) all its W-neighbors who do not share
key with it (set Ri),
we call t.hem R-neighbors of i; and
(4)a key graph derived from W iand Q i . We assume
that all sensors are uniformly deployed in a given twodimensional area. After the key discovery phase, each

Figure 2: Illustration of pairwise key establishment
protocol, w-here E i s encryption algorithm and k,, represents the pairwise key shared by nodes x and y.
sensor has n’ W-neighbors and (n’
Q-neighbors,
where pl is the probability that two sensors share at
least one key [3]. Initially, f =
= p l . The goal of
our proposed PKE protocol is to achieve f > c, where
f is greater than a threshold value. This means that,
on an average, a sensor will set up pairwise key with
c% percent of all its W-neighbors, where the d u e of
c depends an type of applications.
Due to physical limitations of sensors, we assume
that the sensors itre stateless for all the communication related to pairwise key setup. A sensor who helps
other sensors to set up pairwise key will not maintain
the state of the connections. Only the source of the
request message maintains a timer t and retry threshold T for a subset or all of its R-neighbors. During
the PKE procedure, a sensor sends out the pairwise
key setup requests and waits for responses. If no r&
sponse is received for a request before timer t expires,
the sensor will resend the request until it reaches the
retry threshold T .

2.3

Pairwise Key Setup Request And Response

During the PKE phase, a sensor sends key setup requests asking its Q-neighbors to help establish pairwise
keys with its R-neighbors.
We illustrate the process of our proposed PKE protocol using the example scenario shown in Figure 1
and we draw the shortest path tree in Figure 2. In
this example, node 1 has 8 neighbors. The links and
nodes represent the shortest path tree that node 1 derives from its key graph. The link directions represent
the propagation direction of pairwise key requests and
responses (node 9 does not have offsprings in the tree;

178

’

thus, it cannot help node 1t o set up painvise key with
other nodes). The encrypted messages for all transmissions are shown on the left side in Figure 2. In the
example, node 3 receives the request from node 1; the
request ({4,6), {5,8}} is encrypted under the pairwise
key k13 used by the pair (1,3 ) ; node 1 requests for setting up pairwise keys with node 4, 5, 6 , and 8. Since
every node broadcasts its Q-neighhor list during the
key discovery phase, node 1 knows the exact paths to
reach its R-neighbors. Since other nodes, for example,
node 3, may not maintain the same shortest path tree
as that of node 1, node 1 needs t o inform the nodes in
the key paths1 in which directions they can forward the
requests. For example, node 1 requests node 3 to set
up pairwise keys with nodes 4 and 5, and then forwards
the pairwise key request (6) to node 4 and request (8)
t o node 5. To achieve this goal, node 1 simply generates right node id sequence for node 3 to recognize.
In the given example, node 3 recognizes that its Qneighbors in the request are 4 and 5; the i d 6 follows
4, and hence is sent to node 4 along with the key k14;
the id 8 follows 5, and hence is sent to node 5 with the
key k15. In order to generate right request sequence for
every Q-neighbor, ((2, 7) (3, {{4,6}{5,8})}},
node 1
can simply perform a depth first search on its shortest
path tree constructed from the key gmph. After generating the sequence, node 1 sends { 73 to node 2 and
{{4,6}{5,8}) to node 3. Node 3 then forwards the requests ( 6 ) and (8) to nodes 4 and 5 respectively. After
node 4 and 5 receive the requests, node 4 generates the
response E k I 4 ( k 1 6 } , E k , , { k 1 6 } and sends t o node 1, 6
respectively; node 5 generates the response E k 1 5{kls},
( k l s } and sends to node 1, 8 respectively, Following the same procedure, node 2 helps node 1 and 7 to
set up a pairwise key. Note that for each pair of nodes,
both nodes can initiate the PKE process. For example, node 1 and node 7 can both send out requests for
PKE. Since the intermediate node 2 does not maintain
the state of previous requests, node 2 may send node
1 and node 7 two responses each. If a sensor receives
two responses, it just simply XOT the received keys t o
derive a new painvise key.
2.4 Message Format
In this section, we present a message format that
involves three preliminary functions: addressing, authenticity, and data confidentiality. The message format is shown in Figure 3.
The message format is proposed based on the com] A key path between node A and B is defined as a sequence
of nodes A, N I , N z , .. ., N,, B,such that, each pair of nodes
( A , N i ) , ( N I : & ) , ..., ( N t - l , N i ) , ( N , , B ) has at least one
shared key after the key discovery phase. The length of the
key path is the number of pairs of nodes in it.

h

controf
bits

.

&dresses:
fixed length

i

content:

: variable lenglh

MAC:

fired length

header:
fixed length

Figure 3: Message format
munication involved in pairwise key setup requests and
responses. Both requests and responses should be included in a formatted message. The message includes
a header, content, and message uuthenticution code
(MAC). The header and MAC have fixed length. To
find the communication overhead due t o the fixed part,
of the message, we can multiply the total length of
header and MAC by the number of messages transmitted during the key setup phase. The heuder CORtains control bits and at Ieast three address fields: src
specifies the requestor, dst specifies the next hop of
the message, and f., specifies the forwarding node id
Note that, when the source initiates the first request
message, the fields fw and sm should both be set to
the initiator's id. During the entire process of pairwise
key setup, SE always remains the same, fields fw and
dst change in transit on every hop. At each hop, a
node uses src and the node list within the contents to
identify the pairwise keys SE has requested.
We define three type of messages. As shown in Figure 2, the request message ( Type 1 ); pairwise key setup
request (for example, messages <1> and <2>); response message (Type 2 ) : pairwise key setup response,
included the encrypted pairwise key (for example, messages <3>, <4>, and <7>-<12>); responses&request
message (Type 9 ) . When the number of forwarding
hops is greater than or equal to 3, intermediate nodes
on the key path send the messages that include both
the response t o pairwise key request from previous hop
and the requests forwarded t o the next hop (for example, messages <5> and < 6 > ) .
The message is authenticated using the pairwise key
that has already been set up. To prevent eavesdropping, sn: id and contents are encrypted using the pairwise key.

3

Performance Analysis

In this section, we present performance analysis
based on the number of messages transmitted during

the PKE procedure, the energy consumption due to the
transmission, and security issues due to the PKE procedure. Our analysis is based on the following probabiIities introduced in El]:(1)t.he probability p,(h) that
two sensors can set up pairwise keys with exact h hops;
(2) the probability p,.( 5 H ) that two sensors can set up
pairwise keys within H hops, where H is the maximum
number of hops allowed to establish pairwise keys; and
(3) the probability pc,,,,(H) that a sensor can set up
pairwise keys with d l its neighbors within H hops.

3.1

Requests

Communication Overhead

Requests
.

_--_

Requests
.
,-

Figure 4: Pairwise key requests

We assume that all sensors behave correctly and the
communication overhead due to retransmissions and
lost messages is out of scope of this paper. In order to
reduce the communication overhead, a sensor always
prefers the shortest paths (with minimal number of
hops) to set up pairwise keys with its R-neighbors. If
there exists multiple shortest paths to an R-neighbor,
one of them is randomly picked. We use nh t o repre
sent the average number of nodes on hop h and n' to
represent the average number of neighbors of a node.
A node on hop h may or may not help to reach nodes
at hop h -t1. Thus, the average number of nodes that
can be reached with exactly h hops is given as:

messages as requests) that will be involved in the pairwise key setup phase. After the key discovery phase,
the pairwise key setup phase i s needed for sensor i if the
set of R-neighbors within h hops of i is non-empty. The
pairwise key(s) are established with R-neighbor(s) via
Q-neighbor(s). The average number of R-neighbor(s)
that can be reached via exactly h hops is given in (1).
We use Nh t o represent the number of requests that
are sent t o nodes on hop h. We illustrate this using
Figure 4. A request is sent from a node on hop h - 1to
a node on hop h for setup of pairwise keys with nodes
that can be reached with h+ 1 or more hops. Whether
or not a node on hop h can serve as an intermediate
node between node on hop h - f and node(s) on hop
h -t 1 is a selection problem. A node on hop h is said
t o be selected if a node on hop h - 1 selects it as the
intermediate node to reach at least one of the nodes on
hop h 1. If a node on hop h is selected, the node on
hop k - 1 sends a request message t o it. We now solve
the selection problem as follows: the probability that a
node on hop h is not selected as the intermediate node
to a node on hop h + l is l - l / n h ; the probability that a
node on hop h is not selected as the intermediate node
to any of the nodes on hop h 1 is (1 - l/n,)nh+l;
the probability that a node on hop h is selected as the
intermediate node t o at least one of nodes on hop h 1
is 1- (1 - l/nh)nl+l ; the probability that a t lease one
node on hop h is selected as the intermediate node to
nodes on hop h i 1 i s 1- (1- l / n h ) n h n h + l ; finally, the
probability (Ph)that a node on hop h is selected as the
intermediate node t o at least one node on hop h 1
given that at least one of nodes on hop h is selected is
Ph = (1 - (1 - l / ~ ~ , ~ ) ~ h-(I
+ l )-( ll / ~ ~ , ) ~ " ~ h + i Then
) .
we have expected number of request messages on hop
h as:

In the example shown in Figure 2, node I sends two
requests, messages <1> and <2> to set up pairwise
keys with nodes 4, 5, 6 , 7,.and 8. The intermediate
nodcs (node 2 and node 3) help to setup the pairwise
keys. For each pairwise key, the intermediate node
m-ill send either two Type 2 messages, or, one Type 6
message and one Type 3 message. Thus, the number of
transmitted keys is twice the number of nodes that can
be reached with 2 or more hops from the source node
1 (10 messages <3>-<12> in the example). We use
Nkea,to represent the number of transmitted pairwise
keys during the PKE phase invoked by a sensor. Then
we have:

+

+

+

h=2

The number of keys counted by (2) includes the number of keys sent back to the source and the number
of keys sent to the destination. The key messages sent
back to source are always Type 2 messages and the key
messages sent to the destination can be either Type 2
or Type 3. If the destination node is a leaf node in the
shortest path tree of the source node, the key message
is Type 2 message; it is
3 otherwise.
?ie now compute the average number of Type 1 and
Type 3 messages (we jointly call these two types of

+

Thus, the total number of request messages invoked

I80

by a sensor is given as:
n'-1
h=l

For 2 5 h 5 n', the number of W-neighbors of a
sensor that can be reached within h hops, is given by
n'p,.(+h). The number of ids transmitted from hop h
is n,&less than that transmitted from hop h - 1. Thus,
on average, the total number of ids in the request messages transmitted during the PKE phase for one node
is given as:

Numbe;of hops

Number of h o p

Figure 5: Sensor network key establishment communication overhead distribution for pr(d 4) 0.99999

>

where H is the maximum number of hops allowed to
establish pairwise key and H 2 nf.
The total number of messages transmitted during
the PKE is:
Nmessage = N k e y

-k NI

(5)

N I is the average number of nodes on hop 1 that help
to set up pairwise keys. It may be noted that NI is
also the number of Q p e 1 messages sent by a sensor
during the PKE phase. NkeVincludes both ripe 2 and
Q p e 3 messages.
On average, the communication overhead (C) invoked by a sensor during the PKE phase is given as:

C

=

2

3

Number af h o p

(number of ids in the requests) x Std

+(number of keys) x

Skey

+(number of headers and MACS)

tNmesaageSheade+&MAC

where

1

Number of hms

X Sheader&MAC

(6)

Skeyis the size of a encrypted pairwise key,

Figure 6: Sensor network key establishment communication overhead distribution for p r ( 5 8) 2 0:5
the majority communication overhead is spread out up
t o 8 hops (shown in Figure 6 ) . Thus, with the decreases
in the probability pr(3 H ) , the total communication
overhead is distributed on more hops.

is the t o t d size of the header and MACS
for each message, and Sid is the size of a node id.
Sheader&JAC

In Figure 5, we compute the communication overhead invoked by a sensor using (2) and (3). We analyze
four scenarios for a sensor with number of neighbors
( 7 2 ' ) equal to 10, 30, 50, and 70. Using p,(h), we derive
pl = p,(l) that allows a node to reach 99.999% of its
neighbors (p,(5 H ) 2 0.99999). The derived values
of p1 for the four scenarios are 0.9973, 0.649, 0.446,
and 0.34, respectively. For small size of neighborhood,
for example, n' = 10 ,-+30, a high percentage of connected neighbors requires large p1. We notice that the
majority of the communication overhead is distributed
within 2 hops when p T ( d IT) 2 0.99999. When the
percentage of connected neighbors is greater than SO%,

3.2 Security Analysis
Many kinds of attacks can be launched on sensor
networks. SpecificaIly, such attacks can disrupt the
PKE procedure; for example, wormhole attack, sinkhole attack, selective forwarding, Sybil attacks, and so
on. [9]. In this paper, we do not address how to guard
against these types of attacks during PKE procedure.
In this Section, we analyze the security vulnerabilities
due to the PKE procedure. In particular, our focus is
to study the number of keys that,can be compromised
during the PKE procedure due t o a malicious node in a

181

Figure 7: PossibIe locations of source and destination
nodes for a pairwise key established via a malicious
node.

Figure8: The average

of pairwise keys corn=
by an &tacker during the pKE phase
50, p,,,(H) > 0.99; H = 2 , p l = 0.501,H = 3 , p l =
0.286,H=4,pl =0.264, a n d H = 5 , p l = 0 . 2 6 3 .

neighborhood and the area in which the compromised
keys will be used by uncompromised nodes. Here, we
assume a malicious node behaves exactly like a normal
node. We compute the number of pairwise keys that
are set up via the malicious node.
In our PKE protocol, a malicious node may be 10cated on key paths between nodes. Any pairwise key
set up via this node is considered as a compromised
key. First, we study the area in which the compromised key(s) will be used between two uncompromised
nodes. Let us say that node b is malicious. Figure 7
shows the possible area in which the compromised keys
will be used in the system. When the length of key p d h
is less than 3, the compromised key will be used by two
uncompromised nodes both located within the circular area with radius T and node b as the center. When
the length of the key path is greater than or equal to
3,..source nodes should be located within the circular
area wit.h radius r and node b as the center (for example. nodes a and c); the destination nodes should
be located within the circular area with radius 2r and
node b as the center (for example, nodes a, c, d, and

h as:
pr(h)

(”> (

pr(5H)n’Nh
-

E%,n k

n?l
=

’

P&W

-P

JiN

Thus, the average number of pairwise keys that a malicious node can help an uncompromised node to set
up is given as:
H--l
k=l

Finally, because each sensor has n‘ neighbors, we d+
rive the average of total number of compromised pairwise keys (Ncomp)that can be set up via a malicious
node:

e.)
From (l),a node can connect to n, number of nodes
with exactly h hops. The probability that the maiicious node is one of the h-hop nodes is p,(h). Now, the

(7) shows the average number of keys that can be
compromised due to one malicious node during the
PKE procedure. Figure 8, shows the average number
of pairwise keys compromised by a malicious node during the PKE phase. En this figure, we analyze the scenarios with nf = 50,p,,,(H) > 0.99, and 2 5 H 5 5.
The derived values of p l for H = 2 , 3 , 4 , 5 to satisfy
the probability p,,,, ( H ) > 0.99 are 0.501, 0.286, 0.264,
and 0.263, respectively. For H 2 4, wit.h increase in
the maximum number of hops, the number of compromised keys increase a t relatively slower rate.

probability that an attacker is one of h-hop nodes and
helps to set up pairwise keys is p p ( h ) ( N h / n , ) where
,
N h is derived from (3). On hop h, the average number
of pairwise key requests processed by a malicious node
is ( p , ( + H ) n ‘ - Ciy,n,)/yh,
where H is the maximum number of hops allowed to set up pairwise keys
in the system. Thus, we derive the average number of
pairwise keys that an attacker can compromise on hop

182

4

PI D.

W. Carman, P. S. Kruus, and B. J .
Matt, ‘Constraints and approaches €or distributed
sensor network security,” NAI Lab, Tech. Rep.,
September 2000.

Conclusion

In this paper, we propose an energy-efficient PKE
protocol to reduce the communication overhead involved in pairwise key establishment for large-scale
sensor networks. Using the proposed PKE protocol,
each sensor selects bey paths to set up pairwise keys.
We then use the model proposed in [l]to analyze its
communication overhead, and security vulnerabilities.
The modelling of PKE for wireless sensor system is
in its preliminary stage. We aim t o propose a multiple
key paths PKE protocol in our future work.

191 C . KarIof and D. Wagner, “Secure routing in

wireless sensor networks: Attacks and countermeasures,” Elsevier’s AdHoc Network Journal,
Special Issue on Sensor Network Applications and
Protocols, vol. 1, no. 2-3, pp. 293-315, September
2003.

References
D. Huang, M. Mehta, D. Medhi, and L. Ham,
“Modeling pairwise key establishment for random
key predistribution in large-scale Sensor networks,” submitted for publication and available at
http://wnrel. sice.umkc.edu/HR P/model ling pairwise key establishment schemes-&@f, 2004.

I. F. Akyildiz, W. Su, Y. Sankarasubramaniam,
and E. Cayirci, “A survey on sensor networks,’’
IEEE Communicatio& Magazine, vol. 40, pp. 102
- 114, August 2002.

L. Eschenauer and V. D. Gligor,

“A keymanagement scheme for distributed sensor networks,” in Proceedings of 9th ACM Conference on
Computer and Communication Security (CCS-OZ),
November 2002, pp. 41-47.
H. Chan, A. Perrig, and D. Song, %“om
key
predistribution schemes for Sensor networks,” in
Proceedings of 2003 Symposium on Security and
Privacy, Los AIamitos, CA: IEEE Computer
Society, 11-14 2003, pp. 197-215.

D. Liu and P. Ning, “Establishing pairwise keys
in distributed sensor networks,” in Proceedings
of 10th ACW Conference o n Computer and
Communications Security (CCS’O3), October 2003,
pp. 52-61.
W. Du, J. Deng, Y. S . Han, and P. K. Varshney, “A
pairwise key predistribution scheme for wireless
sensor networks,’’ in Pmceedings of 10th ACM
Conference on Computer and Communications
Security (CCS’O3), October 2003, pp. 42-51.
S. Zhu, S. Xu, S . Setia, and S. Jajodia, “ E s t a b
lishing pair-wise keys for secure communication in
ad hoc networks: A probabilistic approach,” in
Proceedings of 1Ith IEEE International Conference
on Network Protocols (ICNP), November 2003.

183

2016 International Conference on Computing, Networking and Communications, Wireless Networks

MobiVPN: A Mobile VPN Providing Persistency
To Applications
Abdullah Alshalan

Sandeep Pisharody

Dijiang Huang

Arizona State University
Tempe, AZ
Email: Abdullah.Alshalan@asu.edu

Arizona State University
Tempe, AZ
Email: Sandeep.Pisharody@asu.edu

Arizona State University
Tempe, AZ
Email: Dijiang.Huang@asu.edu

Abstract—Virtual Private Network (VPN) is the traditional
approach for an end-to-end secure connection between two
endpoints. But conventional VPN solutions are intended for wired
networks with high-speed, highly reliable connections. In a mobile
environment, connections are less reliable. This affects traditional
VPN performance resulting in frequent application failure, data
loss and reduced productivity. MobiVPN bridges the gap between
what users and applications expect from a wired network and
the realities of mobility. In this work, system design for a caching
model is developed, and modifications to the OpenVPN software
is implemented to make disruptions in the VPN transparent
to the applications. MobiVPN is able to provide 1) persistency
to application despite long unavailability of network connection using caching and freeze TCP techniques; with negligible
throughput penalty when there is no disconnections due to extra
computation overhead, and 2) improved TCP performance when
disconnections occur up to 9.88% increase in throughput.
Index Terms—VPN, OpenVPN, Mobility, Security, Mobile
Security, Mobile VPN, Secure Communication

I. I NTRODUCTION
The global computing industry is quickly evolving toward
having powerful cloud computing resources for businesses
and end-users. Users no longer employ just their computers,
but utilize their mobile devices like smart phones and tablets
to interface with the cloud. MobiCloud [1] for instance, is
a framework where users connect with their mobile devices
to a dedicated Virtual Machine (VM) in the cloud as well
as use it to access other cloud services. In an environment
like MobiCloud establishing a secure and reliable connection
between a mobile device and the cloud is essential, not just
for information assurance, but often for regulatory compliance
reasons.
One very widely used solution to connect to cloud or internal resources is Virtual Private Networks (VPN). However,
conventional VPNs are designed to work best for stationary
devices which, unlike mobile devices, have a stable network
connection [2]. Mobile devices are susceptible to intermittent
connection loss while switching from one network to another
or experiencing a gap in coverage and could remain disconnected for any lengths of time. Such events can cause the
VPN connection to break. As a result, applications utilizing
the VPN to communicate with resources in the cloud either
terminate or crash. In addition to data loss, this produces an
inconvenient user experience due to the user possibly having
to redo incomplete jobs.

978-1-4673-8579-4/16/$31.00 ©2016 IEEE

OpenVPN implements a persistence feature that can reestablish a VPN tunnel maintaining the virtual IP, if the VPN client
can provide the right session information. While this may
help in maintaining the applications’ sessions, a more robust
system would implement a caching mechanism that hides the
disconnections and the reestablishment of the VPN tunnels
from the applications [3].
In this work we modify OpenVPN 2.2.2 to be suitable
for mobile clients by introducing a scheme to overcome the
problem of client’s network unavailability. We handle the loss
of a VPN session in a way to make both application client
and application servers unaware of the VPN disconnection by
engaging the VPN to cache unacknowledged packets which
prevents data loss and suspend applications when needed to
ensure session survivability, and avoid TCP slow-start which
degrades TCP throughput.
In the remainder of this paper, we presents other related
work in this area in Section II. We discuss the requirements
and assumptions in more details in Section III. Section IV discusses MobiVPN system model, followed by Section V which
presents a detailed design of our MobiVPN. In Section VI
we provide the outcome of the persistency and performance
evaluation. Finally in Section VII we provide the conclusion
of our current work.
II. R ELATED W ORK
There are several commercial mobile VPN products that are
available in the market. Popular amongst them is Columbitech
[4], which uses the idea of splitting the client-server connection into three connections. The first connection is a
TCP/UDP connection inside the mobile device between the
application client and the mobile VPN client. The VPN client
then establishes a session with the VPN server using reliable
UDP. Similar to the VPN client, the VPN server establishes a
TCP/UDP connection with the application server. This split
is used to fool the applications in the mobile phone into
believing they are connecting directly to the application server,
when in reality, the application client session ends at the VPN
client. When the VPN client receives an application request
to connect to an application server, mobile VPN will intercept
that request and ask the VPN server to connect to the application server. After learning that the VPN server has completed
setup with the application server, the mobile VPN client will

III. M OBI VPN R EQUIREMENTS
MobiVPN is required to maintain the VPN session between
a VPN client and a VPN server despite interruption of network connectivity, or when the mobile device moves between
networks and possibly obtains new IP addresses. Network
disruptions and network changes due to mobility should not
affect an application session. Figure 1 shows how a mobile
device connected to the cloud can travel between networks,
get new network information and still appear to maintain the
same session from an application perspective.
In essence, our main goal with MobiVPN is to provide
the application layer transparency to network layer disruptions
so as to maintain independence of the end-to-end application
sessions from issues caused by mobility.
We formally define MobiVPN to have the following requirements:
1) Network Roaming: The virtual connection remains connected when the device switches to a different network,







	
























































	








	






















inform the application that the end-to-end connection with the
server is completed successfully. The mobile VPN server and
client setup the VPN session using Wireless Transport Layer
Security (WTLS). For all its advantages, Columbitech cannot
be used for research and educational purposes as it is closedsource and commercial.
Fast VPN [5] provides seamless mobility of OpenVPN
clients moving across WiFi hotspots. The goal of this solution
is to reconfigure an OpenVPN tunnel after the client gets a new
IP address post handover to a new network. This is achieved
by updating the VPN tunnel context at the VPN server once
the client receives a new IP address. This approach minimizes
the packet loss but does not avoid it. In addition, there is
no mechanism to maintain the application sessions while the
mobile client is experiencing a gap in WiFi coverage. Such a
solution would work if the client was to move from one WiFi
network to another immediately, without experiencing a long
gap in coverage that could trigger TCP sessions to time out.
Mobility of SSH and TLS protocols is proposed in [6] and
[7]. In [6] extensions of SSH and TLS protocol have been
added to allow application sessions to survive long network
disconnectivity. The extension allows applications running
over SSH or TLS protocols to resume a previously established
connection. However, the TCP sockets are not maintained and
new TCP sockets are created after reconnection. The buffer
of the old TCP socket is copied before the old socket closes,
and retransmitted over the new socket. The provided mobility
is not completely transparent to the application. In order for
this to work, after the original socket closes, the application
has to keep trying to reconnect and not decide to quit which
is what the application would normally do. An application
using this modified TLS can then be designed to keep trying to
connect until a new socket is created. While this can work, we
argue that a total transparency is not achieved. Mobile VPN
presented in [7] introduces a session resumption concept in
order so as to resume sessions without having to renegotiate
new session keys.

Fig. 1.

Overview of the network infrastructure

hence getting a new IP address.
2) Persistence: Open application connections remain active
when the network connection changes or is interrupted,
or when the user manually puts the device in sleep mode.
3) Security: MobiVPN should enforce a mechanism for
authenticating the user, providing encryption of the data
traffic along with integrity assurance.
MobiVPN inherits the network roaming and security requirements from OpenVPN and aims to add the persistence
requirement.
IV. M OBI VPN S YSTEM M ODEL
MobiVPN is modeled to work in three possible states:
1) Normal state: Here the VPN tunnel is healthy and
the applications’ TCP sessions are behaving normally.
MobiVPN behaves as OpenVPN normally would, with
the exception that the caching module will intercept and
cache a copy of all packets being sent. These copies will
be discarded when ACKs corresponding to the packets
are received.
2) Suspend state: The VPN enters this state when the VPN
tunnel fails due to network disruptions. MobiVPN caches
and acknowledges packets from the applications and
eventually suspends the application sessions when the
cache is full.
3) Resume state: The VPN enters this state when the VPN
tunnel is restored. The packet resending module sends
out cached packets to the intended recipients until the
cache is cleared at which point it resumes the suspended
applications.
The specifics of each of the states above are detailed in
Section V-C.
V. M OBI VPN D ESIGN AND I MPLEMENTATION
A. Design Overview
Instead of an actual three-way TCP-split of the application
sessions as [4], we opted for, what we believe, is a less complicated design in which the application clients have direct endto-end connection with the application servers. MobiVPN does
not interfere with the end-to-end connection while the VPN

tunnel is intact, thereby reducing unnecessary overhead that
goes into setting up three different TCP sessions. MobiVPN
is designed to intervene only when the VPN tunnel fails due
to network disruption.
In a nutshell, when a VPN tunnel fails due to network
unavailability; MobiVPN enters the Suspend state in which
it maintains the application session by involving both the
VPN client and the VPN server. The VPN client ensures
the persistency of application clients, while the VPN server
prevents application servers from terminating TCP sessions
when the mobile client is unreachable. Since the VPN client
and server maintain the applications’ TCP sessions in a similar
fashion, we will refer to the applications as either local or
remote for the remainder of this paper.
The VPN (both client or server) starts caching packets sent
from a local application to a remote application, and send
acknowledgments on behalf of the remote application when
disconnection with the remote VPN is detected. Once its cache
is full, the local VPN sends a Zero Window message (ZWM)
on behalf of the remote application. This leads the local
application to believe that the remote application is busy rather
than being unreachable. MobiVPN is designed to respond to
Zero Window probes (ZWP) from local applications on behalf
of remote applications.
When network connectivity is restored, MobiVPN enters
the Resume state. It is likely that the mobile device has
obtained a new physical IP address by this time. In traditional
VPN connections this can be problematic, but protocols like
MobileIP have been used to solve this problem. However,
mobile VPNs that rely solely on MobileIP do not guarantee
the persistency of TCP sessions especially when the period
of network disconnection is long enough for TCP to time
out. Even during short disconnections, TCP throughput will
degrade due to the congestion window shrinking down to its
minimum size, as well as TCP entering slow-start phase upon
restoration of the connection [3]. We leverage a feature in
OpenVPN that allows the VPN client to maintain the same
virtual IP once it reconnects by providing information like
the previous session ID to authenticate the client. Since the
mobile device can maintain the same Virtual IP, we are able
to maintain the application sessions as long as we handle
the TCP timeouts. MobiVPN now starts sending the cached
packets to the remote end and verifies that these packets are
acknowledged before flushing them from the cache. MobiVPN
synchronize the ACK field of the replies to match the highest
ACK seen by the local application.
B. System Modules
MobiVPN consists of several inter-related modules added
to the open source OpenVPN product to achieve our requirements. These modules as shown in Figure 2 are: a) Caching
module whose main functionality is to cache unacknowledged
packets and suspend local applications if necessary; b) Connection Monitor which informs the other modules of the status
of the network connection; c) Packet Resending module which
sends out the cached packets; d) Verification module which

Connection
Monitor

consults

packet /
mark

triggers

retrieve

Data Cache
flush

Caching
Module

Packet
Resending
Module

Verification
Module

invokes

packet

packet

VPN Module

packet

packet

encrypted packet
packet

Virtual NIC

Fig. 2.

Physical NIC

Module relations in MobiVPN

determines what actions to do with return traffic from the
remote VPN, and is responsible for flushing out the cache;
and e) VPN module which is the original OpenVPN that
encapsulates, signs and encrypts outgoing packets as well as
decapsulates, decrypts and verifies incoming packets.
1) Caching Module: This module is the brains behind
MobiVPN functionality. It intercepts packets coming from
the Virtual NIC and stores it in cache. Next, it checks with
Connection Monitor module to determine whether the VPN
connection is available. Upon receiving an affirmative, it
forwards the packets through to the VPN module for delivery
to the destination. However, if the Connection Monitor reply
indicates that the VPN is unavailable for traffic, the caching
module sends the application an ACK for all packets remaining
in the cache, in lieu of the destination to confirm receipt.
When the caching module determines that the cache is
full, it sends a control message to tell the applications to
pause sending data [3]. This is done by sending a ZWM (by
setting the window size to 0 in the TCP header) to the local
application through the virtual tun interface. This informs
the application that the destination is busy and cannot handle
any more data. The application then pauses sending data and
will only send control packets (keepalives, ZWPs, ACKs, etc)
which the caching module responds to. Figure 3 illustrates the
packet processing logic of the caching module.
Figure 4 shows the 17-byte cache reference
record
used
in
MobiVPN.
The
4-tuple
<
SourceIP, DestinationIP, SourceP ort, DestinationP ort >
is used to uniquely identify to which local application the
packets stored in the cache belong. Adding the sequence
number field uniquely distinguishes the packets. A one-byte
Mark field is set to 0 when a packet is initially stored into
the cache. When the caching module learns that the VPN is
unavailable, it sends the local applications an ACK for all
packets remaining in the cache, and increments their Mark
by 1. Additionally, the Mark field is incremented by 1 every
time the cached packet is sent out by the packet resending

Packet
processing
start

Is cache
full?

Store to cache

Send ACK to
local App

N

Increase Mark
to 1

N
Y
Is VPN up?

Send
ZeroWindow
message to
application

Fig. 3.
0

4
Seq#

8
Dst IP

Forward
packet to VPN
module

Packet
processing
end

Caching module

12

Src IP

Y

14
Src Port

16
Dst Port

17
Mark

Packet

17 bytes

Fig. 4.

Start

Is cache
empty?

N

Cache Reference Record

Is VPN up?

Y

Get next
packet

Increment
Mark by 1

N
End

Y

Fig. 5.

Forward
packet to
VPN module

N

Mark > 3?

Y

Terminate
App

Packet resending module

4) Verification Module: The verification module deals with
the packets received by MobiVPN from the remote end. The
module verifies if the packets it has received are ACKs in
response to a packet that had been cached, by observing Seq#
of the packets in cache. If so, then the packet is inspected to
determine if there is any piggybacked data. If the packet has
any data present, it is forwarded to the local application and
during the RESUME state, the ACK is modified to match the
highest ACK seen by the application. If there is no data, then
the ACK is forwarded to the local application only if Mark =
0. The marked packet is then cleared from the cache.
5) VPN Module: The VPN module responsible for the core
VPN functionality as provided by OpenVPN. It implements
a Transportation Layer Security (TLS) based VPN tunnel
between the mobile device and the VPN server. It receives
packets from the caching module, formulates the packet by
encrypting, signing and encapsulating before sending the
packet to the remote end through the physical NIC. The
only modification made to this module is added logic that
directs packets received from the remote end to the verification
module instead of directing them to the Virtual NIC.
C. System Workflow

module. The packet itself is appended to a cache record
following the Mark field.
Although caching packets requires enhancing storage resources for the MobiVPN, mathematical models for similar
projects have predicted an overall improvement in communication performance [9]. The size of cache is configurable by
the user. In case of MobiVPN handling multiple tunnels, we
allocate one cache per VPN tunnel. This is especially helpful
since a single VPN tunnel going down would not affect other
VPN tunnels.
2) Connection Monitor Module: This module checks on
the connectivity between the local MobiVPN and the remote
MobiVPN, and reports its status to the other modules. Once
the network is unavailable it allows MobiVPN to enter the
Suspend state. Likewise it allows MobiVPN to enter the
Resume state once network connectivity is restored. The connection monitor module is consulted by the caching module
to determine if the VPN is up. Once the connection monitor
determines the VPN is back up, it triggers the packet resending
module.
3) Packet Resending Module: When the VPN tunnel comes
back online, as determined by the connection monitor, MobiVPN sends out the packets in the cache that were not
delivered due to the VPN tunnel being unavailable. It retransmits the cached packets if not acknowledged by the remote
application for at most times according to a timer. Figure 5
illustrates the how this module operates.
If there are multiple tunnel instances (as is usually the case
at least on the MobiVPN server), MobiVPN keeps track of
the interfaces each cached packet needs to be sent out of.
As discussed in Section V-B1, this is done by maintaining a
separate packet cache for each interface.

In a MobiVPN setup, the connection between the application client and the application server is as shown in Figure 1.
When the VPN tunnel is up, the connection is end-to-end.
However, when the connection between the MobiVPN client
and the MobiVPN server is down, the connection is virtually
split into three, with one connection between the application
client and MobiVPN client, one between the MobiVPN client
and MobiVPN server, and one between MobiVPN server and
the application server. In effect, the logical connection between
the application client and the application server is broken down
into these three sub-connections. As long as the connection
between the application client and the MobiVPN client stays
up, the application client can be fooled to believe that the
entire end-to-end connection is up. Similarly, as long as the
application server does not lose its connection to the MobiVPN
server, it can be made to believe that its end-to-end connection
to the application client is up.
Figure 6 illustrates the different MobiVPN states, with the
transitions between them being controlled by three binary
inputs to the system; namely Tunnel_Down, Cache_Full
and Cache_Empty.
1) Normal State: MobiVPN is in the Normal state when the
application client sends data to the application server while the
VPN tunnel is up and operational.
When a data packet from a local application reaches the
local MobiVPN, the caching module intercepts the packet,
and caches it. The caching module then checks with the
connection monitor module to determine if the VPN link to
the remote MobiVPN is up and operational. Upon receiving
confirmation that the VPN is up, the caching module forwards
the packet to the VPN module, which proceeds to send
the traffic through the tunnel to the remote MobiVPN. The
remote MobiVPN then relays the traffic through to the remote

Tunnel_Down = 0

Normal
Operation

Tunnel_Down = 0
Cache_Empty = 1
Tunnel_Down = 0
Cache_Empty = 0

Tunnel_Down = 1

Tunnel_Down = 1
Cache_Full = 0

Resume

Tunnel_Down = 0

Suspend
store in
cache
Tunnel_Down = 1
Cache_Full = 0

Tunnel_Down = 1 Tunnel_Down = 0
Cache_Full = 1

Tunnel_Down = 1
Cache_Full = 1

ZeroWindow
sent

Tunnel_Down = 1 when tunnel is down.
Cache_Empty = 1 when the cache is empty.
Cache_Full = 1 when the cache is full.

Fig. 6.

State transitions in MobiVPN

application. Acknowledgment from the remote application gets
to the remote MobiVPN and is returned to the VPN module
of the local MobiVPN in a similar fashion. The VPN module
would forward the packet to the verification module, which
would then forward the packet onto the local application. Since
the VPN tunnel is healthy and the application sessions are
behaving normally, MobiVPN behaves as OpenVPN normally
would, with the added robustness of packet caching.
The caching feature in MobiVPN helps mitigate scenarios
where the tunnel breakdown happens after a packet has been
forwarded by the VPN module to the remote MobiVPN. If the
packet is not acknowledged, the local MobiVPN can retransmit
it.
2) Suspend State: MobiVPN is in the Suspend state when
the local application sends data to the remote application, but
the connection monitor module detects the VPN tunnel to be
broken. First, it sends an ACK to the local applications for all
packets in the cache, and increments their Mark to 1. Later,
when the traffic reaches the caching module, it gets stored
in the packet cache with a Mark of 1. Since the caching
module knows that the VPN tunnel is down, it does away
with forwarding the packet to the VPN module. The caching
module sends ACKs in lieu of the remote application. When
the cache is full, the caching module sends a ZWM to the
local application.
While in the suspend state, traffic between the application
server and application client has halted, but the TCP session
between them is still active.
3) Resume State: When the connection monitor module
detects the VPN tunnel has reestablished, MobiVPN enters the
resume phase. At this point, the connection monitor module
triggers the packet resending module. The packet resending
module retrieves packets from the cache, and forwards them
to the VPN module, until the cache is emptied.

The ACKs received by the VPN module from the remote
MobiVPN are forwarded to the verification module, which
determines whether to discard it if a) it had no data, and b)
was not acknowledging the packet with the highest sequence
number in the cache for the corresponding application; or
forward it to the local application with the TCP window set to
0 if there is accompanying data. A received packet from the
remote end is forwarded as-is to the local application if the
ACK field acknowledges the cached packet with the highest
sequence number for that application. Forwarding the packet
as-is means the remote window will be whatever the remote
application was advertising, which means that traffic exchange
may resume. All acknowledged cached packets are flushed
from the cache. When the cache is empty the VPN enters the
normal operation state.
If the verification module does not receive return ACK for
packets that were sent out in the suspend state, the cached
packets will be retransmitted by the packet resending module.
After three unsuccessful retransmissions, the packet resending
module would send a TCP FIN to the application client to tear
down the suspended session.
D. Implementation
We implemented our MobiVPN design by modifying OpenVPN 2.2.2. The new modules mentioned above were implemented from scratch along with modifying some of OpenVPN modules to interact with the new added modules. Our
implementation was performed for Linux environment. We
omitted the details of the algorithms we developed due to
space constraints.
VI. P ERSISTENCY AND P ERFORMANCE E VALUATION
MobiVPN provides two advantages: 1) keeping application
session persistent while the mobile device is out of coverage,
2) TCP throughput improvement by preventing TCP slowstart, allowing fast recovery upon reconnection by immediately sending out cached packets instead of waiting for the
retransmission timer which is an exponential back-off timer.
We evaluate both features in the following sub-sections.
A. Persistency Evaluation
Applications can lose their underlying TCP sessions when:
1) TCP does not receive an ACK for a data packet
that has been retransmitted tcp_retries2 times, or 2)
when TCP keep-alive messages are not answered within
(tcp_keepalive_time + [tcp_keepalive_intvl ×
tcp_keepalive_probes]) seconds. The TCP protocol of
the mobile device or the application server may drop the
session based on the TCP configuration mentioned above.
Notice, even if the mobile client sets high values for these
options to avoid losing the TCP session while being out of
coverage, it has no control over the TCP settings of the
application server, hence the TCP session persistence is not
guaranteed. MobiVPN overcomes this problem.
To test this feature, we conducted an experiment that
includes 3 virtual machines: client, VPN server and application

server. The client VM contains an application client and a
VPN client. All VMs run a Ubuntu 12.04 with 2 GB RAM
and were hosted in the same physical machine. We wrote
a basic file transfer application that sends 1 GB text file
from the client to the application server and every scenario
we alternated OpenVPN and MobiVPN. We performed three
scenarios: 1) No network disconnection, 2) a disconnection
event long enough for the client to drop the TCP session after
tcp_retries2 failed retransmission, and 3) a disconnection event long enough for the server to drop the session after
keep-alive timeout.
In the first case, the file was transfered completely using
MobiVPN and OpenVPN. In the second and third cases,
the file was transfered completely using MobiVPN, however,
using OpenVPN approximately 0.24 GB of the text file was
received by the application server.
B. Performance Evaluation
We conducted another experiment to evaluate the performance of MobiVPN compared to OpenVPN. Our experiment
was set up similar to the setup in Section VI-A, however it
was conducted in three scenarios: 1) All VMs are hosted in
one machine, 2) the VPN server and the application server
hosted remotely in Tempe, AZ; and 3) the servers are hosted
in Asia. In cases 2 and 3, the client is located in Chandler,
AZ.
We used iperf to measure the throughput of OpenVPN vs.
MobiVPN by streaming 1GB of data from the client to the
application server using three scenarios: 1) no disconnections,
2) one disconnection of 30 seconds; and 3) three disconnections of 30 seconds each. The disconnections are done by
disabling/enabling the physical network interface using a shell
script. For every measurement, we average out the results of
three runs. Table I summarizes the outcome of this experiment.
Server’s
location

RTT
ms

same host

1.8

Tempe

52.9

Asia

319.4

Discon.
0
1
3
0
1
3
0
1
3

Throughput
(Mbps)
OpenVPN
149.50
85.10
49.08
5.09
4.14
3.48
0.84
0.69
0.60

Throughput
(Mbps)
MobiVPN
145.50
85.15
50.58
5.04
4.28
3.63
0.83
0.74
0.66

Throughput
differential
-2.68%
+0.06%
+3.62%
-1.02%
+3.29%
+4.02%
-1.47%
+6.48%
+9.88%

TABLE I
P ERFORMANCE EVALUATION : O PEN VPN 2.2.2 VS M OBI VPN.
D ISCONNECTIONS LAST FOR 30 SECONDS WITH 10 SECONDS BETWEEN
EACH DISCONNECTION EVENT

The results shows that OpenVPN outperformed MobiVPN
when there is no disconnections. This is apparent when the
RTT is very small. The degradation of the throughput is
due to the overhead of the caching and verification modules.
However, this penalty decreases with the increase of the RTT
as the processing time required by the caching and verification
module becomes a very small factor compared to the value of
the RTT.

The throughput turns in favor of MobiVPN when there are
disconnections and becomes more apparent with higher RTTs.
This is due to the fact that MobiVPN prevents the TCP session
from entering a slow-start phase due to the prevention of TCP
retransmission and timeouts.
VII. C ONCLUSION
We have developed a robust system design for caching,
session resumption and packet retransmitting which hides the
breakdown of the VPN connection from the application. OpenVPN source code has been modified to work in accordance
with said design. TCP sessions tunneled through MobiVPN
can be kept alive no matter how long it takes to recover the
VPN tunnel.
In addition, our performance results are encouraging, and
we believe they can be improved once we conclude our future
work which includes light-weight VPN tunnel reestablishment.
MobiVPN solution built on our design, we believe will usher
the mobility constrained VPN into the mobile age.
VIII. ACKNOWLEDGMENTS
This research is supported by NSF Secure and Resilient
Networking (SRN) Project (1528099), NATO Science for
Peace & Security Multi-Year Project (MD.SFPP 984425), and
ONR YIP project (N00014-10-1-0714). A. Alshalan is funded
by a scholarship from King Saud University and S. Pisharody
is supported by a scholarship from the NSF CyberCorps
program (NSF-SFS-1129561).
R EFERENCES
[1] D. Huang, X. Zhang, M. Kang, and J. Luo, “MobiCloud: building secure
cloud framework for mobile computing and communication,” in Service
Oriented System Engineering (SOSE), 2010 Fifth IEEE International
Symposium on. IEEE, 2010, pp. 27–34.
[2] A. Bakre and B. Badrinath, “I-TCP: Indirect TCP for mobile hosts,” in
Distributed Computing Systems, 1995., Proceedings of the 15th International Conference on. IEEE, 1995, pp. 136–143.
[3] T. Goff, J. Moronski, D. S. Phatak, and V. Gupta, “Freeze-TCP: A
true end-to-end TCP enhancement mechanism for mobile environments,”
in INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE
Computer and Communications Societies. Proceedings. IEEE, vol. 3.
IEEE, 2000, pp. 1537–1545.
[4] “Columbitech
wireless
VPN
technical
description,”
Columbitech, White Paper, Oct. 2007. [Online]. Available:
http://www.columbitech.com/img/2008/3/5/16245.pdf
[5] A. Zúquete and C. Frade, “Fast vpn mobility across wi-fi hotspots,” in
Security and Communication Networks (IWSCN), 2010 2nd International
Workshop on. IEEE, 2010, pp. 1–7.
[6] T. Koponen, P. Eronen, M. Särelä et al., “Resilient connections for ssh
and tls.” in USENIX Annual Technical Conference, General Track, 2006,
pp. 329–340.
[7] J. Schonwalder, G. Chulkov, E. Asgarov, and M. Cretu, “Session resumption for the secure shell protocol,” in Integrated Network Management,
2009. IM’09. IFIP/IEEE International Symposium on. IEEE, 2009, pp.
157–163.
[8] Y. Matsuhashi, T. Shinagawa, Y. Ishii, N. Hirooka, and K. Kato,
“Transparent vpn failure recovery with virtualization,” Future Generation
Computer Systems, vol. 28, no. 1, pp. 78–84, 2012.
[9] M. N. Al-Ameen and R. Hasan, “The mechanisms to decide on caching
a packet on its way of transmission to a faulty node in wireless sensor
networks based on the analytical models and mathematical evaluations,”
in Sensing Technology, 2008. ICST 2008. 3rd International Conference
on. IEEE, 2008, pp. 336–341.

2013 IEEE Military Communications Conference

Modeling Anonymous MANET Communications
Using Super-nodes
Bing Li and Dijiang Huang
School of Computing Informatics and Decision Systems Engineering
Arizona State University, Tempe, AZ, USA
{bingli5, dijiang}@asu.edu
Abstract—In mobile ad hoc networks (MANETs), how to
measure communication anonymity is a crucial issue. In our
previous work [1], a theoretic approach based on evidence
theory was proposed with detailed analysis. However, localization
errors and scalability issues were not considered in the system
assumption. In this paper, we further develop our work to
incorporate localization errors in anonymity analysis. We propose
the concept of super-nodes to model group based mobility. Time
domain is sliced into intervals. In each interval, our proposed
approach categorizes mobile nodes into clusters based on a novel
metric that integrates geographical distances, historical distance
records, and communication hops. We then provide the algorithm
to generate super-nodes based on cluster formations from each
interval. Evaluation results exhibit a satisfactory accuracy to
recover group formation using super-nodes.

Thus, instead of modeling the communication patterns for
individual nodes, we focus on group-based communications.
In this way, the scalability issue can be reduced and controlled
in our solution.
Following this idea, we propose to model anonymous communications using super-nodes. In brief, super-nodes are used
to model the formation of node groups. Our approach consists
of two steps: (1) In each time interval, we divide all the
nodes into multiple clusters using a novel distance metric
we propose. (2) We generate super-nodes based on cluster
formations in all the intervals.
The main contributions of our work are: (i) We use supernodes to solve the issues caused by localization errors and
present an approach to generate super-nodes based on trafﬁc
information collected from network. (ii) We propose a new
metric for measuring the distance between nodes and clusters
so that both geographical and communicational factors are
used to improve the accuracy of clustering algorithms.
The rest of this paper is organized as follows: Section II
describes MANET models, provides assumption of the trafﬁc
monitoring system, and introduces our previous work. Section
III gives details of our proposed approach. We evaluate the
performance and the complexity of our approach in Section
IV and conclude the work in Section V.

I. I NTRODUCTION
Mobile Ad hoc Networks (MANETs) can be widely applied
in real world such as military, rescue, and disaster response
scenarios. All these critical ﬁelds demand high-level security
and privacy guarantees. Existing solutions provide a wide protection from routing anonymity [2] to content conﬁdentiality,
from trust establishment [3] to Byzantine failure protection
[4] [5]. However, certain amount of information could still be
acquired from the amount of trafﬁc generated by individual
nodes.
In [1], we proposed to measure the unlinkability for
MANETs based on evidence collected from trafﬁc statistics.
This is carried out by slicing time domain into multiple
intervals so that each node can be either a sender or a
receiver in one interval. Then a point-to-point trafﬁc matrix
is constructed for each interval which records the amount of
trafﬁc sent from one node to another. After this step, a trafﬁccommunication relation matrix is created so that accumulative
trafﬁc amount from one node to another can be calculated for
discovering trafﬁc patterns.
This method is effective when individual nodes can be
differentiated without error. However, localization errors can
hardly get eliminated in practice. Therefore, how to model network communications when localization errors exist is crucial
for applying our previous works in practice. Another issue with
this method is scalability. In large scale networks, it requires
a large amount of resources to generate and store trafﬁc
information in matrices. We observe that in the application
scenarios mentioned above, nodes are likely to move in groups.
978-0-7695-5124-1/13 $31.00 © 2013 IEEE
DOI 10.1109/MILCOM.2013.31

II. S YSTEM M ODEL
In this section, we provide detailed information on the network models, the trafﬁc monitoring system, and our previous
work. The general scenario is that a MANET consisting of
a number of nodes is deployed in an area. Data transmitted
in it is encrypted so that packet contents are well protected.
A trafﬁc monitoring system exists in the area. It includes a
network of passive receivers that capture signals transmitted
in the MANET channel. These receivers are connected through
communication channels that are different from the one used
by the target MANET.
A. Network Model
The communication model of the MANET is based on
802.11b protocol. It can be extended to other protocols as
needed. According to [1], the transmission range d of a node
has a relation with the data transmission rate r as d ∝ 1r .
r is included as part of the Physical Layer Convergence
125

Procedure (PLCP) header, which is part of 802.11b physical
layer, for decoding purpose. Therefore, potential receivers of
a signal can be identiﬁed using location of the source and its
transmission rate.
Some features in MAC layer can leak useful information to
adversarial eavesdroppers. To avoid such leaks, some settings
are changed: (1) Both source and destination addresses in a
frame are set to broadcasting value, i.e. all 1’s. Addressing
can be handled by upper layers using pairwise shared keys.
(2) Virtual carrier sensing, a.k.a. Network Allocation Vector
(NAV), mechanism [6] is disabled because it only allows
the receiver of a message to send out messages in a period
of time. Thus, the receiver could easily be identiﬁed by an
eavesdropper.
As mentioned before, nodal movements exhibit group patterns in MANETs. Therefore, we assume the mobility model
of the target MANET is group based. But neither the group
size nor the group distribution is publicly known. Single nodes
can be modeled as groups with size of 1.
From above observations, we summarize our communication model in MANETs:
• Source and destination addresses in MAC frame are set
to broadcast value;
• Frame contents are securely protected;
• Upper layer protocols (including network layer routing
protocol) are unknown to attackers;
• Virtual carrier sensing option is disabled;
• Device speciﬁcation and transmission range of the nodes
are known to attackers;
• Nodes’ transmission ranges are not necessarily equal;
• Localization errors are far smaller than transmission
ranges;
• Nodes’ movement is group-based.

the monitoring system is that it can differentiate senders of
different signals but cannot get senders’ identities. In this way,
each node can be represented by its radio ﬁngerprint but cannot
be correlated to its real identity.
The ability of trafﬁc monitoring system can be summarized
as:
• Monitoring system can capture all the communication
trafﬁc of the MANET;
• Monitoring system does not emit signal in the communication channel of the MANET;
• Individual nodes can be located with an error e when they
send out signals;
• Signals sent from different devices can be distinguished.
C. Previous Work
The goal of our previous work in [11] is to measure the
anonymity of end-to-end communication relationships under
anonymous communication environment in MANETs. In order
to achieve this goal, we slice the time domain into multiple
intervals (Δt1 , Δt2 , . . . , ΔtK ). In each interval, a network
node can only be either a message sender or a message
receiver. The amount of messages sent from every node in
one interval is stored in a Point-to-Point Trafﬁc Matrix Wi
so that we can have totally K such matrices (W1 , W2 , . . .,
WK ). Based on this collection of information, we proposed
a series of algorithms to derive an End-to-End Trafﬁc Matrix
R, which can be used for calculating the source/destination
probability distributions and the end-to-end link probability
distribution. However, all this work is based on the assumption
that the information acquired in each Point-to-Point Trafﬁc
Matrix is accurate, i.e., the localization errors can be ignored.
This assumption is too strong in practice that the original work
could not be widely used in real world. To solve this problem,
we propose our solution in the following section.

B. Trafﬁc Monitoring System

III. P ROPOSED S OLUTION

The trafﬁc monitoring system can passively collect trafﬁc
information. It is able to locate the source of a signal with a
certain localization error e. Locating a wireless node based
on the Received Signal Strength (RSS) has been proposed
and studied for a long time [7]. It requires collaboration from
multiple receivers. To improve location detection performance,
using temporal link signature for location distinction is proposed in [8]. It constructs temporal link signatures using multipath phenomenon and differentiates node locations based on
normalized link signatures. Using this technique, a node can
be located when the trafﬁc monitoring system receives a signal
from it. We assume that the trafﬁc monitoring system is able
to locate each node in the network as long as it receives a
signal from the node.
Another feature of the trafﬁc monitoring system is distinguishing hardware. This can be achieved based on research
results in radio ﬁngerprinting [9] [10]. The idea is that signals
from any two hardware devices are slightly different in terms
of timing, frequency, and so forth due to the imperfection
of manufacturing. However, linking radio ﬁngerprints with
the source’s identity is difﬁcult. Thus, our assumption for

Monitoring and analyzing individual nodes’ communication
trafﬁc is desirable but costly in the sense of computation
overhead and control complexity when network scale is large.
In this section, we propose a clustering algorithm based on
the system model. It aims to solve two urgent issues with
trafﬁc analysis in MANETs: localization errors and scalability.
Localization errors make it impossible to locate the source
of a signal when several nodes are too close to each other.
For example, when the distance between two nodes is less
than twice of the localization error e as shown in Figure
1, the monitoring system cannot ﬁnd out which node sends
out a signal from the overlapping area A. When a group
of nodes are moving together, details such as individual
nodes’ communication do not provide much more information
than the entire group communication. Therefore, a monitoring
system can only monitor inter-group communications instead.
In other words, it ignores inner-group communications and
only focuses on signals transmitted around group borders.
To analyze group communication, we propose to divide the
nodes into small groups and treat each individual group as an

126

TABLE I
N OTATIONS
Terms

Unlike traditional agglomerative hierarchical clustering algorithms such as single-linkage clustering and completelinkage clustering, we use a new distance metric in our
algorithm. In single-linkage clustering, the distance between
the closest nodes in two clusters is used as the distance metric
to determine how close two clusters are. Clusters are merged
recursively. A Proximity Matrix (PM) is used for merging the
closest clusters together. Elements in PM is proportional to
the inverse of linkage criteria metric. That is to say, when
the distance between two clusters is small, the corresponding
element value is large. Thus, they are more likely to be merged
in the next round. In our application scenario, we can use the
same metric because the shortest route between two clusters
is likely to include the two closest nodes in them. However,
geographical distance is not sufﬁcient enough to represent
the relationship between clusters. As stated before, clusters
are used to represent the close relationship between nodes in
network. If two nodes are geographically close while their
transmission ranges are too short for them to communicate
directly, then they are not closely related in this interval. (As
shown in Figure 2A, a third node is needed to relay their communication.) To the contrary, if two nodes are geographically
distant from each other but the transmission ranges can make
direct communication possible, they are closely related (Figure
2B). Based on this observation, communication distance in
hops is included as a factor in our deﬁnition of Distance.
Another possible situation is that in one interval the distance
between two clusters may be short for some reason while the
overall node formation history exhibits a distant relationship
between these clusters. In this situation, it would be better
to assign a longer distance between them for that interval.
Following this idea, we propose to modify the distance metric
with records from history.
To add communication distance into the metric, we need to
calculate the hops between any two nodes in an interval. Since
no information regarding the routing protocols is known, we
can use any shortest path algorithm for directed graph instead.
If one node a locates in another node b’s transmission range
as shown in Figure 3A, then there is a directed edge from
b to a. The weight assigned to this edge is one. However, b
is out of a’s transmission range. Hence, there is no directed
edge from a to b. When two nodes cannot be connected
through a series of edges, the communication distance is ∞.
The communication distance in one interval is recorded in a
matrix called Communication Distance Matrix (CDM) where
CDM (i, j) represents the number of hops between node Ni
and Nj .
As stated in our assumption, the nodes are moving in group
based models. If two nodes are close to each other in history,
they are likely to belong to the same group. To model this
property, we deﬁne a matrix called Accumulative Distance
Matrix (ADM). In this matrix, each element ADM (i, j) represents the accumulative average geographical distance between
node Ni and node Nj . Initially, all the elements are set to 0.
When a new interval is created, the distances between nodes
in this interval are recorded in a matrix called Geographical

Meaning

Proximity Matrix

a matrix for hierarchical clustering

Communication
Distance Matrix

a matrix representing the number of hops
between individual nodes

Accumulative
Distance Matrix

a matrix representing accumulative average
distances between individual nodes

Geographical
Distance Matrix

a matrix representing the distances between
individual nodes

Dendrogram

a data structure recording cluster formations

Accumulative
Cluster Matrix

a matrix recording cluster formation inform-ation

Super-node
Formation Array

an array recording super-node formation

integrated node which we call a super-node. The monitoring
system then can focus on communication relations between
super-nodes instead of individual nodes. Nodes that move
around singly can be treated as a super-node with size of 1.

A
e

Fig. 1.

e

Localization error inﬂuences trafﬁc analysis.

To generate super-nodes, we follow the idea of slicing time
domain to form multiple time intervals in [11]. In each interval,
closely related nodes are grouped into clusters. The metric for
this close relationship is represented as Distance. Within each
interval, the formation of every cluster is considered to be
static. Cluster formation can be different in different intervals.
The process for creating an interval consists of two steps:
(1) Take a snapshot of the network whenever a data packet
is captured; (2) Concatenate the snapshots to form a single
interval. The criteria for forming a single interval in step (2)
are:
•
•

A super-node can be either a sender or a receiver within
one interval, but it cannot be both;
The formation does not change for any cluster within one
interval.

Following these criteria, interval lengths are not necessarily
equal. Control and management frames are excluded from
triggering a snapshot since they are not closely related to
communication relations. Super-nodes can be generated based
on the node relationship information stored in clusters.
A. Clustering Algorithm
Before going into details of the clustering algorithm, we
give a summary of notations in Table I.

127

A

Fig. 2.

Algorithm 2 Modiﬁed Clustering Algorithm
1: Assign: clusters Ci = Ni , i = 1, 2, ..., M ;
// M is the number of nodes in network, Ni denotes the
i-th node in network
2: counter c = M ;
3: DO:
4:
c = c − 1;
5:
Find the nearest clusters Cs and Ct ;
6:
IF(Distance(Cs , Ct ) < (α + β)S(Cs , Ct ) + γT
&& |Between(Cs , Ct )| > R)
7:
Merge Cs and Ct ;
8:
ELSE
9:
Skip merging Cs and Ct ;
10:
END-IF-ELSE
11: UNTIL: c == 1.

B

Different transmission distances change connectivities.

b2

a2
a

b

A

a1

b1

individual nodes scattering between the two clusters when they
are merged. When two distant clusters are connected with a
line of sparse nodes, they will not be merged (rectangle area
in Figure 4). S(Cs , Ct ) is a conditional function: if no node
in Cs can perform as b in Figure 3A to set up a directional
one-hop link with any node in Ct or no node in Ct can do
the similar thing, then returns 0; otherwise, return the smaller
one of the longest directional geographical distances between
Cs and Ct . For instance, if b1 → a1 is the longest one-hop
link from any node in Cs to any node in Ct and a2 → b2
is the longest from Ct to Cs as shown in Figure 3B, then
S(Cs , Ct ) = min(|b1 → a1 |, |a2 → b2 |). When the distance
between two clusters is greater than the transmission range
of nodes and no intermediate nodes can forward the trafﬁc,
they are not able to establish communications. Therefore, it is
meaningless to merge them together as one single cluster. The
threshold T represents an upper bound on the communication
hops between two clusters when merging them. If they are too
far away in hops, then they are not merged as well.

B

Fig. 3.
Asymmetric communication relations inﬂuence communication
distances.

Distance Matrix (GDM).
The Distance in our solution then can be deﬁned
as: Distance(i, j) = αGDM (i, j) + βADM (i, j) +
γCDM (i, j), where α, β, and γ are chosen according to
the MANET mobility. Elements of PM can be generated and
updated according to Algorithm 1.
Algorithm 1 PM Generation and Update
1: In the k-th time interval, each element P M (i, j) =
1/Distance(i, j) ;
2: Update
ADM (i, j)
=
(ADM (i, j) × k +
GDM (i, j))/(k + 1), here k starts from 2.
Based on the distance metric and the system assumption,
the hierarchical clustering algorithm can be modiﬁed as in
Algorithms 2. The function Distance(Cs , Ct ) represents the
distance under our metric between cluster Cs and cluster Ct , which can be expressed as: Distance(Cs , Ct ) =
min(Distance(i, j)), Ni ∈ Cs , Nj ∈ Ct . Note that the
amount of nodes in different intervals may not be the same
since some nodes may not emit any signal during one or
several intervals. But the monitoring system is able to acquire
the total number of distinct nodes in network based on radio
ﬁngerprints from all the intervals.
Here, R is a predeﬁned threshold. Between(Cs , Ct ) =
{Ni ||GeoDistance(Ni , Cs ) − GeoDistance(Ni , Ct )| <
δ, |GeoDistance(Ni , Cs )| + |GeoDistance(Ni , Ct )| < },
where δ and  are predeﬁned thresholds. It returns a set of
nodes. Everyone in this set satisﬁes that the distances between
the node itself and the two clusters respectively are very
close. (The difference between the two distances is less than
δ.) Meanwhile, every node is very close to both clusters.
(The sum of the two distances is less than .) The condition
|Between(Cs , Ct )| > R makes sure that there are sufﬁcient

Fig. 4.

Sparse node connections cannot be used for merging clusters.

Outputs from hierarchical clustering algorithms are normally represented in dendrograms (Figure 5). The y axis
represents at what distance two clusters are merged. As in
the example of Figure 5, y1 is the distance between cluster
{A,B} and cluster {C}. y2 is the distance between cluster
{A} and {B}. It is easy to see that {A} and {B} are closer
than either {A} and {C} or {B} and {C}. Dendrograms can
accurately record the hierarchy of cluster generation as the
distance grows.
B. Super-node Generation
Clusters constructed from Algorithm 2 cannot be directly
used as super-nodes. This is because in some intervals two

128

Y

Algorithm 4 SFA Generation
1: FOR j = 0; j < M ; j + +
//M is the amount of nodes in network
2:
IF Super(Nj ) == N U LL
//Node Nj doesn’t belong to any super-node
3:
Create a super-node for Nj ;
4:
END-IF
5:
FOR t = 0; t < M, t = j; t + +
6:
IF ACM (j, t) > γK
//K is the total number of time intervals
7:
Add Nt to Super(Nj );
//So that Super(Nt ) == Super(Nj )
8:
Set Nt .P rocessed = T rue;
9:
END-IF
10:
END-FOR
11: END-FOR
12: FOR j = 0; j < M ; j + +
//To process nodes that are not visited in the previous FOR
loop
13:
IF Nj .P rocessed! = T rue
14:
Set l s.t. ACM (j, l) = M AX(ACM (j, t)), 1 ≤
t ≤ N;
15:
Set h s.t. ACM (j, h) = M AX(ACM (j, t )), 1 ≤

t ≤ N, t = l;
16:
IF ACM (j, l) − ACM (j, h) > δ
17:
Add Nj to Super(Nl );
18:
ELSE
19:
Create a super-node for Nj ;
20:
END-IF-ELSE
21:
END-IF
22: END-FOR

ABC

y1
AB

y2
A

B

C

X

Fig. 5.

A dendrogram is used to record the cluster formations.

or more groups may merge together as one cluster while in
other intervals they are separate. Also, if a node emits a signal
in one interval and keeps silent for several intervals before
sending out another signal, even if it stays in the same group,
the cluster formations are changed. Therefore, it is necessary
to extract super-nodes from clusters in multiple time intervals.
We use a matrix to record the frequency that any two nodes
locate in the same cluster. This matrix is called Accumulative
Cluster Matrix (ACM). The method for generating an ACM
is illustrated in Algorithm 3. It traverses through all intervals
to record in ACM (j, t) the number of intervals in which two
nodes Nj and Nt are grouped in the same cluster.
Super-node formation can be deduced from ACM. The
formation is represented in an array, which is named Supernode Formation Array (SFA). The method to create an SFA
from ACM is depicted in Algorithm 4. In these algorithms,
function Cluster(Nj ) and Super(Nj ) respectively return the
cluster and the super-node that node Nj belongs to. SizeOf
returns the amount of nodes in a cluster or a super-node.
Algorithm 3 ACM Generation
1: FOR i = 0; i < K; i + +
//K is the total number of time intervals
2:
FOR j = 0; j < M ; j + +
//M is the amount of nodes in network
3:
FOR t = 0; t < M, t = j; t + +
4:
IF Cluster(Nj ) == Cluster(Nt )
5:
ACM (j, t) + +;
6:
END-IF
7:
END-FOR
8:
IF SizeOf (Cluster(Nj )) == 1
9:
ACM (j, j) + +;
10:
END-IF
11:
END-FOR
12: END-FOR

will be categorized as a super-node of itself.
IV. E VALUATION
In this section, we evaluate the proposed algorithms in terms
of effectiveness and complexity. To analyze the effectiveness,
we apply our solution in a trace using OMNeT++ [12]. For
complexity analysis, we give complexity estimations under the
worst case scenario.
In evaluation setup, two groups are created with 4 nodes
each in an area of 3000 × 3000m2 . Every node in a group
is moving in the same direction with the same velocity
(10m/s). For simplicity, we assume the same transmission
power (100mW ) on all the nodes. The estimated transmission
range is 150m. Two scenarios are chosen for evaluation. In
Scenario 1, the groups initially locate at distant locations and
are moving toward each other. In Scenario 2, they initially locate together and then move in opposite directions. These two
scenarios represent typical cases concerning the relationship
between two groups: merging and separating. Other possible
moving scenarios between two groups can be represented by
modifying and combining these two scenarios. To test the
worst case on our algorithm, the ﬁrst criterion for determining
the length of an interval, which relates to packet sending,

In Algorithm 4, γ and δ are predeﬁned thresholds. γ restricts
on the number of intervals in which any two nodes need to be
in the same cluster so that they can be treated as in the same
super-node. δ represents that if a node Nj locates in the same
cluster with Nl for much more time intervals than it locates
with any other node in the network, then it is treated as in the
same super-node with Nl . If no such property exists, a node

129

complexity of O(M 3 ), our solution provides an effective modeling method without greatly increasing the overall complexity.

is disabled during the entire process. Thus, fewer intervals
are created. A single interval, instead of multiple intervals, is
used to represent the fact that nodes stay in their respective
groups for a long period of time. However, our algorithm can
overcome this problem by setting the value γ in Algorithm 4.
Our evaluation results show that the proposed approach
can successfully generate two super-nodes corresponding to
the two groups respectively. The minimum number of time
intervals needed for Scenario 1 is 1. This is because initially
two groups are separate. During the ﬁrst interval, the clustering
algorithm can easily generate one cluster for each group. As
the groups are merging, cluster formations in the following
intervals do not provide more accurate information than the
ﬁrst interval until they separate. For Scenario 2, the minimum
number of time intervals needed is 5.
Additional, we calculate the percentage that correct clusters
are generated hierarchically in each interval using the geographical distance and our proposed distance metric respectively for Scenario 1. A cluster is correct if all its members
belong to the same group. The results are shown in Figure 6.
As shown in the graph, only two intervals are generated using
the proposed metric. If we do not use Algorithm 4 to integrate
the cluster formation in different intervals together, it is almost
impossible to infer the group formation solely based on the
cluster formation in a single interval in Scenario 1 since the
correct cluster ratio is less than 90% in 3 out of 7 intervals.

V. C ONCLUSION
In this paper, we propose to solve the problem of localization errors and scalability with trafﬁc analysis in MANETs by
using super-nodes. Super-nodes are used to recover the group
formation of network nodes. By slicing the time domain and
grouping the nodes in each interval, information about geographical location and communication distance is recorded in
clusters. Super-nodes are generated based on this information
to represent the closeness between nodes. Our method provides
an accurate approach for modeling MANET communication
relations with a polynomial complexity.
For the future research, several issues need to be worked on
with depth:
• The choice of intervals for clustering can be ﬂexible. It is
worthwhile exploring mechanisms on selecting intervals
to further reduce the complexity;
• Distance metric improvement. It is desirable to explore
factors other than geographical and communication distances that inﬂuence our clustering algorithm.
ACKNOWLEDGMENT
This research is sponsored by ONR YIP Award N0001410-1-0714 and ARO Research Grant W911NF-11-1-0191.
R EFERENCES

'ĞŽŐƌĂƉŚŝĐĂůŝƐƚĂŶĐĞKŶůǇ

WƌŽƉŽƐĞĚŝƐƚĂŶĐĞDĞƚƌŝĐ

[1] D. Huang, “Unlinkability measure for ieee 802.11 based manets,”
Wireless Communications, IEEE Transactions on, vol. 7, no. 3, pp.
1025–1034, 2008.
[2] Y. Zhang, W. Liu, W. Lou, and Y. Fang, “Mask: anonymous on-demand
routing in mobile ad hoc networks,” Wireless Communications, IEEE
Transactions on, vol. 5, no. 9, pp. 2376–2385, 2006.
[3] L. Eschenauer, V. Gligor, and J. Baras, “On trust establishment in mobile
ad-hoc networks,” in Security Protocols, ser. Lecture Notes in Computer
Science, 2004, vol. 2845, pp. 47–66.
[4] B. Awerbuch, R. Curtmola, D. Holmer, C. Nita-Rotaru, and H. Rubens,
“Odsbr: An on-demand secure byzantine resilient routing protocol for
wireless ad hoc networks,” ACM Trans. Inf. Syst. Secur., vol. 10, no. 4,
pp. 6:1–6:35, Jan. 2008.
[5] M.-Y. Su, “Warp: A wormhole-avoidance routing protocol by anomaly
detection in mobile ad hoc networks,” Computers and Security, vol. 29,
no. 2, pp. 208 – 224, 2010.
[6] S. Sharma, “Analysis of 802.11b mac: A qos, fairness, and performance
perspective,” 2003.
[7] D. B. Faria and D. R. Cheriton, “Detecting identity-based attacks in
wireless networks using signalprints,” in Proceedings of the 5th ACM
workshop on Wireless security, 2006, pp. 43–52.
[8] N. Patwari and S. K. Kasera, “Robust location distinction using temporal
link signatures,” in Proceedings of the 13th annual ACM international
conference on Mobile computing and networking, 2007, pp. 111–122.
[9] T. Kohno, A. Broido, and K. C. Claffy, “Remote physical device
ﬁngerprinting,” IEEE Trans. Dependable Secur. Comput., vol. 2, no. 2,
pp. 93–108, Apr. 2005.
[10] K. B. Rasmussen and S. Capkun, “Implications of radio ﬁngerprinting on
the security of sensor networks,” in Proceedings of IEEE SecureComm,
2007.
[11] Y. Qin and D. Huang, “A statistical trafﬁc pattern discovery system for
manets,” in Military Communications Conference, 2009, pp. 1–7.
[12] “Omnet++ network simulation framework,” in http://www.omnetpp.org/,
Accessed Sep. 2013.
[13] D. B. Johnson, “Efﬁcient algorithms for shortest paths in sparse networks,” J. ACM, vol. 24, no. 1, pp. 1–13, Jan. 1977.

ϭϬϬ͘ϬϬй
ϵϬ͘ϬϬй
ŝŽ
Ăƚ ϴϬ͘ϬϬй
Z
ƌ ϳϬ͘ϬϬй
ƚĞƐ ϲϬ͘ϬϬй
Ƶ
ů ϱϬ͘ϬϬй
 ϰϬ͘ϬϬй
ƚĐ
ƌĞƌ ϯϬ͘ϬϬй
Ž ϮϬ͘ϬϬй

ϭϬ͘ϬϬй
Ϭ͘ϬϬй
ϭ

Ϯ

ϯ

ϰ

ϱ

ϲ

ϳ

dŝŵĞ/ŶƚĞƌǀĂů

Fig. 6.

The correct cluster ratios are different using different metrics.

For complexity evaluation, the worst case scenario is the
geographical position and the transmission coverage area of
every node change during every interval. Therefore, all the
data stored in the matrices need to be updated. We use M
to denote the amount of nodes in network and K as the
amount of intervals. The complexity for calculating GDM is
O(M 2 ). ADM update operation is also O(M 2 ). CDM can be
calculated using Johnson’s algorithm [13] in O(M 2 log M ).
The complexity of Between() function is less than O(M 2 ).
This is because the worst case is that the number of nodes
left between two clusters is at the same order as M while the
size of the two clusters are at the same order as well. Thus,
Algorithm 2 is O(M 3 log M ). The complexity of Algorithm
3 and Algorithm 4 are O(M 2 K) and O(M 2 ) respectively.
It is clear that Algorithm 2 is the most complex algorithm.
Considering normal hierarchical clustering algorithms have a

130

Secure Web Referral Service
Vijayakrishnan Nagarajan and Dijiang Huang
Arizona State University

financial web sites for authenticating the user, the username
and password will be transmitted to the attacker un-encrypted.
To address the sslstrip attack, we present a new secure
web referral service, which is powered by a Secure Search
Engine (SSE). Particularly, SSE checks the users’ typed or
clicked URLs for potential MITM or phishing attacks. SSE
is designed as an automatic web referral service involving
minimal interventions from humans for security decisions.
SSE returns deterministic answer of security inspections, “Yes
or No”, to the user’s browser, and thus it can removes potential
human errors. To use SSE, a user just simply installs a browser
plug-in. After enabling the plug-in, the browser will establish
an SSL connection to the SSE. This process is performed
during the initiation phase of a web browser to establish a
secure channel between the browser and the SSE. Once the
browser is up, any typed in URLs or clicked links will be sent
through the encrypted connection for security checking. Once
the security checking is passed, SSE will inform the browser
to initiate an SSL connection to the requested link if the web
server supports HTTPS. In this way, the MITM attacker cannot
intercept the user’s secrets and the worst the MITM attacker
can do is dropping the connection.
The rest of this paper is organized as follows. In Section
II, we describe the related work on MITM attack. In Section
III, we present the attack model for this paper. Section IV
describes the detailed designs of SSE to counter MITM
attacks. In Section V, we show how testing results from our
implements. Finally, in Section VI, we conclude our work and
describe the future work.

Abstract—Security has become a major concern while browsing as the number of malicious sites keeps increasing with the
cost for hosting a site decreasing. Though most of the web servers
use Secure Socket Layer (SSL) over HTTP (Hyper Text Transfer
Protocol) to ensure trust between consumers and providers,
SSL is vulnerable to Man-In-The-Middle (MITM) attack and
becoming very common these days. Phishing is another major
problem, which has increased rapidly over the years. In this
paper we present a novel secure web referral service using Secure
Search Engine (SSE), which would resolve phishing and MITM
attacks for web based applications. SSE is based on web crawling
technology with a set of checking services to validate IP addresses
and certificate chains. Additionally, we present a novel phishing
filter that can be used to check any given URLs with minimal
delay. Our solution is non-intrusive and reduces human factors,
which are commonly in existing web-based services, in security
verification processes. Our evaluation shows that our solutions
produce less false positive and false negative than existing web
browser-based anti-phishing solutions.

I. I NTRODUCTION
World Wide Web (WWW) and the hyper linked web
pages along with services like online chatting, electronic
mail, and Internet services based on Cloud computing [8]
have made web browser as a universal information portal
for end users. We usually encounter problems such as using
strong cryptography-based algorithms but constructing weak
security protocols. Particularly, security protocol designers
often overlook the weakness of human beings in the humanin-the-loop types of security protocols. SSL supported web
browsing is an example of this kind. In this paper, our research
focuses on two major security problems incurred due to human
errors: SSLStrip MITM attack [11] and web based phishing
attack, which require users to be involved to make decisions
on accepting or rejecting a potentially breached web site.
In SSLStrip attack, attackers explore the vulnerability that
a user may request a secure web site by initiating an insecure
HTTP request. The attacker can intercept the request through
ARP spoofing [14] or DNS poisoning [13] attacks and then
impersonate the user to send the request. Once received the
request, the secure web server usually sends an HTTP 302
message to ask the user to initiate an SSL session instead. The
attacker then intercepts the HTTP 302 redirect message and
initiates an SSL session to the web server without forwarding
the redirect message to the user. After setting up an SSL
connection to the web server, the attacker sends un-encrypted
web page to the user. It is quite common for users overlooking
the protocol name, which should be changed from HTTP to
HTTPS, and a small lock logo should appear in the bottom
of the web browser. If the user types his username and
password in the web page, which is usually required by most
978-1-4673-0250-0/12/$31.00 ©2012 IEEE

II. R ELATED W ORK
In [6], the authors explained how an MITM attack takes
place, and they proposed three ways to counter ARP spoof
based MITM attacks. Among all existing MITM attacks,
SSLStrip [11] is the most powerful attack that exploits the
security vulnerabilities of HTTPS protocol procedures. It first
uses ARP spoof or DNS poisoning attacks to intercept users’
traffic. Then it partitions the end-to-end connection into two
segments: one is un-encrypted from the victim to the attacker
and another is an SSL connection between the attacker and
a secure web server. Victim users usually do not notice the
HTTPS key word in the address bar or the security logo in
the status bar, and send their private information unencrypted
to the attacker. To counter MITM attacks, authors of [12] used
session-aware user authentication techniques to prevent MITM
attacks, which allows a server to authenticate users based on
their session information. In [15], authors proposed solutions
for countering a web-based MITM attack by introducing
context sensitive certificate verification and specific password
53

ICOIN 2012

warning-aware browsers. This technique validates a certificate
and also checks if a password will be sent in an unsecured way.
In [10]. Jackson et al proposed ForceHTTPS, which forces the
browser to open a secure connection to the destination. If the
destination does not support a SSL connection then the user
should manually set a policy in ForceHTTPs. This approach
does not prevent MITM attacks since attackers can intercept
the HTTPS request and return a “no-HTTPS-support” message
and force the web browser to initiate HTTP sessions.










III. ATTACK M ODELS

Fig. 1.

SSE is designed to identify unsafe web sites injected by
using MITM attacks. In this section, we describe the webbased attack models of SSLStrip MITM attack.







Overview of the SSE architecture.

and description of SSE architecture is based on [5], which
describes the basic components and models to establish an
efficient and scalable search engine.

A. SSLStrip Man-In-The-Middle (MITM) Attack

A. Secure Search Engine
1) Secure Search Engine Architecture: The implementation
of SSE is through a layered service architecture, where the
higher layer services make use of the services at its immediate
lower layer. Fig. 1 shows the main services of the SSE
architecture.
SSE service: SSE service answers all the user queries
generated by web browsers. Replies of the SSE service are
made from the inspection results from the SSL verifier and
the Phishing filter.
SSL verifier: SSL verifier is one of the core services in SSE.
The SSL verifier module picks up an URL and collects the
certificates for one or multiple domains running on the server.
It also validates the certificate chain and stores the validation
results in the certificate repository maintained by the SSE.
Phishing filter: Phishing filter is another core service in
SSE, in which it inspects each web page linked through the
inspecting URL. Using the learning algorithm explained in
Section IV-C, the phishing filter checks if a web site is a
legitimate site or a phishing site.
SSE Crawler: The SSE Crawler is an automatic computer
program that collects security and web page information of
URLs for SSL verifier and phishing filter. In general, the
Crawler starts with a list of URLs (such as URLs for Banks) to
visit, which is called as “seeds”. As the Crawler visits these
URLs, it identifies all the hyperlinks in the page and adds
them to the list of URLs to visit, and collect all the security
information from each URL, such as public key certificates.
DNS service: DNS service is very critical for a search
engine as mentioned in [9], where about 87% of web crawling
traffic is just due to DNS traffic. The DNS service is actually
a caching mechanism to make the Crawler more efficient
without causing too much repeated DNS traffic. The DNS
service is also used by phishing filter to get the IP addresses
of inspecting domain names.
URL service: The URL service records URLs visited by the
Crawler including both visited URLs and to be visited ones.
Additionally, to make the Crawler scalable and allow recovery
from crashes, the URL service is responsible for restoring the
state of the Crawler in case of the system crashes.
Storage service: The storage service stores all the information from SSE Crawler and link inspection results.

SSLStrip MITM attack [11] explores the vulnerability of
the initialization procedure of HTTPS, and it tries to hijack
into the user’s SSL connections by partitioning an end-toend SSL connection into two segments: one is encrypted and
another is unencrypted. The attacker first deploys an ARP
spoof attack [14] or DNS poisoning attack [1], [3], [2] to direct
the user’s traffic through the attacker. Once the user initiates
an insecure HTTP request to an SSL-enabled web server, the
attacker can intercept the request, and then establish an SSL
connection to the server by authenticating the server through
its certificate. When receiving the user-side authentication
request from the server, the attacker decrypts the encrypted
traffic and sends the unencrypted web pages to the user’s
browser. Since most secure web servers require their users to
provide usernames and passwords for user-side authentication,
the user will then send them unencrypted to the attacker. The
problem is originated from the negligence of users since they
should check if the HTTP is changed to HTTPS in the address
bar and the security lock should appear in the status bar after
loading the received web pages. However, studies showed in
[7], 23% of the people, including security professionals, do not
look at address bar, status bar, and security indicators when
they browsing a secure web site.
B. Assumptions of Attackers Capabilities
Attackers can perform the described SSLStrip MITM attack.
We assume that attackers do not have a valid SSL certificate to
impersonate an existing secure web site, and thus attackers do
not have the corresponding private key of a valid certificate of
the spoofed web site. Our solution require the web browser to
initiate an SSL connection to the SSE server, thus the attacker
cannot compromise the secure connection between the web
browser and the SSE server. Additionally, the attacker cannot
compromise the security validations between the SSE server
and any inspected web sites.
IV. D ESCRIPTION OF S ECURE S EARCH E NGINE
In this section, we first present the architecture and functionalities of each component to build an SSE. Latterly, we
explain the data flow in the SSE system. The terminology
54







we populate the URL service with a set of seed URLs. The
Crawler picks up an unprocessed URL from the URL service
and sends an HTTP request. In this process, the Crawler uses
the DNS service to retrieve the IP address of the given domain
name in the URL. The Crawler collects the new URLs from the
HTTP responses and passes them to the storage service. The
stored web site information will shorten the search responding
time when the searched web sites have been already inspected.
Crawling services are usually operated periodically based on a
certain time interval. Thus, within the crawling time window,
new phishing web sites can be issued. To handle the phishing
sites that have not been crawled, SSE needs to process a realtime security inspection.










Fig. 2.

Steps involved between a browser and the SSE service.

2) Procedures of Using SSE Service: The Fig. 2 explains
the data flow among the user, SSE, and the web server. An
SSE add-on component (or plugin/extension) must be installed
for a browser at the client side to use SSE services. When
the user types a URL or clicks on a web link, the browser
extension sends a URL inspection request to SSE through a
pre-established SSL tunnel. SSE processes the URL inspection
request, and inspect whether the requested URL links to a
phishing site or not. The inspection includes two procedures
through two filters: (a) SSL verifier validates if the web
server provides valid certificates and supports HTTPS for the
requested domain; and (b) phishing filter identifies phishing
properties of the inspected web page. The inspection result is
sent to the user for decisions: (i) sending an HTTPS request if
the web server provides valid certificates and SSL is enabled,
(ii) sending an HTTP request if the web server does not
provide a valid certificate and the web site had passed the
inspection of phishing filter, and (iii) a visual popup alert will
be shown to the user if the web site does not pass any one of
filters of the SSE server.




















Algorithm 1 SSE Processing.
1: The browser retrieves U RL = getT heU RL();
2: if The U RL is available in browser’s cache and the cache
expiration timer is not expired then
3:
Take actions based on the cached attributes;
4: else
5:
The browser sends a request message msg =
redirectT oSSEService(U RL) to SSE;
6:
if SSE checks msg is a phishing site in its cached
database then
7:
SSE sends a Warning message to the browser;
8:
if The user ignores warning then
9:
The browser sends normal HT T P Request(U RL)
to the web server;
10:
else
11:
The browser drops the HTTP request;
12:
end if
13:
else if SSL verifier returns “the web server supports
HTTPS” AND phishing filter returns “the web server
is not a phishing site” then
14:
SSE sends the certificate information to the browser;
15:
The browser sends secure HT T P SRequest(U RL)
to the web server;
16:
else if SSL verifier returns “the web server supports
HTTP“ AND phishing filter returns “the web server is
not a phishing site“ then
17:
SSE informs the browser;
18:
The browser sends normal HT T P Request(U RL)
to the web server;
19:
else
20:
SSE sends a Warning message to the browser;
21:
the browser goes to Step 8;
22:
end if
23: end if























Fig. 3. Dataflow within the Secure Search Engine. Steps: (1) Crawler gets
the unprocessed URLs from the URL service. (2 & 3) Crawler requests and
gets the rewritten URL (with the corresponding IP-Address). (4 & 5) After
crawling the new URL, Crawler updates the DNS cache and URL service with
the extracted URL. (6) The collected results are persisted using the storage
service. (7 & 8) The SSL verifier collects, validates, and stores the certificates.
(9 & 10) The phishing filter runs the algorithm to find out a web site is a
phishing site or not. (11) The browser extension request for verification of
a web site. (12 & 13) The SSE service uses the storage service to get the
corresponding data to evaluate. (14) The SSE service answers the query.

3) SSE Processing Algorithm: In Algorithm 1, we present
the SSE service processing algorithm. Lines 2-4 represented
the inspection based on cached information. The browser
redirects all new URL requests, including both inputs from
the address bar and clicks from the browser window, to the
SSE service. URLs are sent through pre-established HTTPS
connections when a web browser connects to the Internet. SSE
service checks with its database through the storage service
to see: (i) if the site is already previously evaluated as a

Fig. 3 presents the data flows within the SSE server. Initially,
55

verifier gets the unprocessed URLs from the storage (use
function extractAllHttpsU rls()). For each URL, the SSL
verifier checks for an SSL connection to the server. If an SSL
connection request is accepted by the server, then it inspects
the certificate chain and validates each certificate in the chain
towards the site certificate. The validation includes checking
the certificate expiration date, and the basic constraint field
specifying if the certificate can be used to sign other certificates. If the web site rejects the HTTPS request, or the
web site does not have a valid certificate and thus no support
for HTTPS. Additionally, the IP addresses used by the web
site are also cached in the DNS service. This would serve
two purposes: (i) protects from DNS spoofing as we send the
trusted IP address of the web-site (ii) helps improving the time
taken to load the page as there is no need of DNS requests.
Finally, the browser initiates a HTTPS connection if it learns
from the SSE that web site supports HTTPS connections.
Once an HTTPS connection is initiated, e.g., https://www.
usbank.com, the HTTPS protocol will enforce an SSL connection with requested port number 443. When initiating an
HTTPS connection, a user expects to receive a valid certificate
and uses its public key to derive a shared key for securing later
communication. Since MITM attackers do not have a valid
private key of the web server’s certificate, they cannot derive
the shared key. As a result, MITM attackers cannot intercept
and decrypt the ciphertext sent to U.S. Bank’s web site. Thus,
the MITM will fail. We also note that the MITM attacker can
still cause a Denial-Of-Service attack by not forwarding the
intercepted packets. However, this will not provide any help
for attackers to derive the users’ private information.

phishing site; and (ii) if the site supports SSL and has a valid
certificate. If the requested URL does not exist in the SSE’s
database, SSE calls SSL verifier and phishing filter processes
to inspect if the user encounter MITM or phishing attacks.
The evaluation results will be sent to the browser and it is up
to the user to discard the HTTP request or ignore the Warning
when receiving a negative reply. The corresponding HTTP or
HTTPS request then will be sent out. If the requested web
site information does not exist in SSE’s database, SSE will
start a real-time inspection which is straightforward, and the
inspection steps are illustrated from line 13 to line 21.
B. Countering SSLStrip MITM Attacks
The goal of an MITM attacker is to get personal private
information, such as a bank account associated username and
password, etc. In the following presentations, we consider
an example of a user accessing a banking web site, e.g.,
www.usbank.com, and illustrate how SSE works to defend the
SSLStrip MITM attack. In this example, the basic problem
incurred by SSLStrip attack is originated by a human who
uses a browser to access his/her bank account. The awareness
of using security protocols to support online-banking system
is very low for general users. It is the human nature to type as
less number of letters to get access to a remote web site. For
example, a user usually just types usbank.com in the address
bar. By default, the browser will interpret the request as an
HTTP request, i.e., http://www.usbank.com, which sets the
destination web server’s port number to 80. By intercepting
the user’s request, the attacker can establish an SSL session
to the web server and replies to the user with an unencrypted
web page using HTTP protocol.
To counter the described SSLStrip MITM attack, a user
can refer to a trusted web site information source, i.e., SSE
in this paper, and check whether the destination web server
supports HTTPS or not. SSE automates the security inspection
procedure and the user will be notified only if potential MITM
attacks are detected. In this way, we can maximally avoid
human errors.

C. Countering Web-based Phishing
At present, most browsers incorporate phishing filters that
utilize existing phishing-site databases like PhishTank www.
phishtank.com. In SSE the phishing filter first checks with
the SSE database and see if the IP address has hosted any
phishing site in the past. The filter also checks if the site has
a valid certificate and its Google page rank. These components
are chosen for following reasons. (i) Phishing sites usually do
not provide valid certificates since the process for obtaining
a certificate is not desired for phishing attackers. (ii) Google
page rank is calculated using many parameters to evaluate
the popularity of a web page. One important parameter is the
propagation of trust among web sites. A trusted web page
should always refer to other trusted web pages. Intuitively,
this would bring down the rank of a phishing web site since
no trusted web pages refer to it. More importantly, phishing
sites are hosted for a short span of time, and the probability
of crawling the web page would be less. In our established
prototype, a weighted average based on the presented four
parameters is calculated and normalized to a range of [0,10]. If
the final value, conf idence, is less than an allowable threshold
then the web page is reported as phishing web site.
To take a comprehensive consideration for the three evaluation components, the Conf idence(i) is computed by the
following weighted function:

Algorithm 2 SSL Verifier
1: urls = extractAllHttpsU rls();
2: for each URL in urls do
3:
certChain = getCertif icate();
4:
if certChain is valid then
5:
for each certif icate in the certChain do
6:
params = extractCertP arameters();
7:
store(params, certif icate);
8:
end for
9:
else
10:
mark invalid certificate against the URL;
11:
end if
12: end for
We illustrate the steps involved in countering an MITM
attack using the SSL verifier algorithm that is presented in
Algorithm 2. The Crawler collects information about the
web site and stores it using the storage service. The SSL

Conf idence(i) = β · Cert(i) + γ · IP (i) + δ · GP R(i), (1)
56

www.phishtank.com with respect to different time frames.
The time frames, which we used in our evaluation are the
phishing sites reported in last 30 minutes, 60 minutes, and 90
minutes. We collected 100 URLs from each time frame. We
tried visiting those reported phishing sites using the compared
browsers. The expected behavior of each browser is to warn
the user before he/she accesses those phishing sites. If the page
gets loaded without any warning messages, then we considered
it as a false negative. Next, we use SSE phishing filter to
evaluate the phishing sites, and then calculate the percentage
of false negatives of each system considered. The Fig. 4 shows
the percentage of false negative of each browser vs. the SSE
phishing filter. The x-axis of the graph shows the time frame
and the y-axis is the percentage of false negatives. In each
time frame, we compare the false negative results obtained.
The graph shows that the percentage of false negatives of the
browser reduces as the time frame increases (from 30 minutes
to 90 minutes). This is because more reported phishing sites
are entered in phishing site repositories with time going. The
percentage of false negative of the SSE phishing filter remains
a low level, and it is lower in all time frames compared to
the evaluated browsers. This performance evaluation shows
that SSE filter achieves the best performance through active
phishing scan. The false negatives of SSE phishing filter are
mainly from phishing sites using figures to present statements.

where β, γ, δ are constants and we set β +γ +δ = 10, Cert(i)
is a Boolean value whether the checking of SSL verifier is
passed or not. IP (i) is calculated from (2) to evaluate an IP
address for website i. Let t represent the number of days that
an IP address has not hosted a phishing site. The value of
IP (i) can be computed using the following formula:

1 − 1 , if t > 1;
log t
IP (i) =
(2)
0,
otherwise.
When IP (i) is calculated for the first time, t is set to a
large number greater than 30 for a non-phishing site, or
t is set to 1 for a phishing site collected from different
phishing repositories. As the t increases the log1 t decreases
and the value of IP (i) increases. Thus, increase in value of
IP (i) would increase the value of Conf idence(i). Finally,
GP R(i) ∈ [0, 1] is the value of Google Page Rank (GPR) for
the corresponding URL i. For each web page i, we get the
corresponding GPR, which is normalized in scale of 0 to 1
and the value of GPR is assigned. From the SSL Verifier we
also get the certificate information, whether a domain has a
valid certificate or not.
To obtain the values of β, γ and δ, SSE uses an approach
based on linear classification [4]. If the conf idence value
is less than the threshold τ , then the site is phishing site.
To determine the values of four constants and τ , we used
100 phishing web sites and 100 non-phishing web sites as
the training sample to derive the following values for SSE
phishing filter: β = 5, γ = 2, δ = 3, and τ = 3.

Percentage of False Positive
3.5
% of false positive

3

V. P ERFORMANCE A SSESSMENT OF SSE
In this section, we present the performance evaluation of
SSE. First, we present the effectiveness of using SSE to
counter MITM and phishing attacks; and then, we present the
performance issues of SSE such as computations and delay.

2.5
2
1.5
1
0.5
0
firefox

ie 8

chrome

SSE

Phishing filter

A. Performance Evaluation of Phishing filter
Fig. 5.

Percentage of False Positive.

Percentage of false negative

Percentage of False Negative
25

To evaluate the false positives of SSE phishing filter and the
compared browsers, we randomly collected 100 non-phishing
sites that are close to phishing site, from www.phishtank.com.
These URLs were from unknown category of www.phishtank.
com, which have been verified by us as non-phishing sites.
We expected that the SSE phishing filter do not identify these
web sites as phishing sites. We calculated the percentage of
URLs that are identified as phishing sites by the SSE phishing
filter. As shows in the fig 5, the false positives of all the
techniques were very low. However, the percentage of false
positives of SSE phishing filter is the lowest. Most of the
Phishing web sites are based on some banking sites. Almost
all of these banking sites have a proper certificate through
which they prove their genuineness. Once a web site has a
proper certificate the SSE Phishing filter will have β = 3
which is enough to cross the threshold, i.e., τ = 3. This is the
reason why the SSE’s false positive is less.

20
15

firefox

10

ie 8
chrome

5

SSE

0
30

60

90

Reported phishing sites in the timeframe (in minutes)

Fig. 4.

Percentage of False Negative.

To show the effectiveness of SSE phishing filter, we compared it with built-in phishing filters of Firefox, Chrome, and
IE. All these browsers update their local phishing cache every
30 minutes from their own phishing sites repositories. In our
experiment, we collected newest reported phishing sites from
57

SSL-related information, such as certificates, of a web site
can be stored in the DNSSEC server’s info field. In this way,
the browser can initiate a request with port 443 directly to
avoid MITM attacks. However, the major drawback of using
DNSSEC service is that DNSSEC is not widely used by most
of existing computer systems.
Our current implementation is a prototyping, which is just
running on several computers. To support large amount web
searching traffic, we need to scale the computing resource and
bandwidth. A clustering computing environment is required.
Additionally, a data center should be established to archive the
searched web pages. To this end, we can use cloud computing
based solution to address the scalability issue.
SSE builds the foundation of the presented secure web
referral framework. It provides supports to counter different
types of web-based attacks. At present, we just focus on
MITM and phishing attacks. We will extend its secure referral
services to help users’ browsers to counter many other web
attacks. For example, we will explore the capability of using
SSE to provide referral services to identify potential Crosssite Scripting (XSS) attacks, in which XSS is code injection
by malicious user into a web page viewed by others. SSE can
run a vulnerability checking against the XSS codes embedded
in web sites, and notify both the users and the web-server
managers.

B. Performance Evaluation of Delay and Resource Consumption
7

Round trip time comparison

6

Time in Seconds

5
4
normal

3

with SSE

2

dns caching

1
0
0

100

200

300
400
500
No of concurrent users

600

700

Fig. 6. Comparison of current web browsing loading time and SSE approach.

In our experiment, we allow each user using the traffic
generator to send 50 SSE requests for every 15 seconds. Out
of those 50 URLs, some URLs were banking sites where
an SSL connection to these banking sites is mandatory. The
experiment was performed after clearing the cached URLs
at SSE server. We emulated 100 to 600 users’ behavior and
studied the round-trip time taken with different models. The
results obtained are shown in the Fig. 6. The x-axis of the
graph shows the number of concurrent users in the system and
the y-axis is the delay of a user from requesting the web site to
loading the requested web page. The blue curve is the normal
scenario that takes place without using SSE service, where the
average time taken to load a page is about 4 seconds. The red
curve shows the experiment results with SSE service. Initially,
the SSE service takes more time to respond and builds up the
cache. The successive requests for validation take less time as
the URLs have already been verified and cached.
The average time saved by rewriting the IP-address with
domain name was around 9%. The graph shows the roundtrip time taken with rewriting IP address is shown in green
color. During our experiment, we discovered that the average
overhead caused by the secure connection to the SSE service
was approximately 12% of the entire round-trip time including
the processing and communication delay of SSE requests, SSE
responses, web server requests, and web server responses.

ACKNOWLEDGEMENT
This research is sponsored by Office of Naval Research
Young Investigator Program (ONR-YIP).
R EFERENCES
[1] R. Arends, R. Austein, M. Larson, and D. Massey. DNS Security
Introduction and Requirements, 2005.
[2] R. Arends, R. Austein, M. Larson, D. Massey, and S. Rose. Protocol
Modifications for the DNS Security Extensions, 2005.
[3] R. Arends, R. Austein, M. Larson, D. Massey, and S. Rose. Resource
Records for the DNS Security Extensions, 2005.
[4] C.M. Bishop et al. Pattern recognition and machine learning. Springer
New York:, 2006.
[5] S. Brin and L. Page. The anatomy of a large-scale hypertextual Web
search engine. Computer networks and ISDN systems, 30(1-7):107–117,
1998.
[6] T. Chomsiri. HTTPS Hacking Protection. In Proceeding of the 21st
International Conference on Advanced Information Networking and
Applications Workshops, volume 1, 2007.
[7] R. Dhamija, JD Tygar, and M. Hearst. Why phishing works. In
Proceedings of the SIGCHI conference on Human Factors in computing
systems, pages 581–590. ACM New York, NY, USA, 2006.
[8] B. Hayes. Cloud computing. Commun. ACM, 51(7):9–11, 2008.
[9] A. Heydon and M. Najork. Mercator: A scalable, extensible web crawler.
World Wide Web, 2(4):219–229, 1999.
[10] C. Jackson and A. Barth. ForceHTTPS: Protecting high-security web
sites from network attacks. 2008.
[11] M. Moxie. Sslstrip software. http://www.thoughtcrime.org/software/
sslstrip, 2009.
[12] R. Oppliger, R. Hauser, and D. Basin. Ssl/tls session-aware user
authentication. Computer, 41(3):59–65, 2008.
[13] D. Sax.
DNS spoofing (malicious cache poisoning).
URL:
http://www.sans.org/rr/firewall/DNS spoof.php November, 12, 2000.
[14] S. Whalen. An introduction to arp spoofing. Node99 [Online Document],
April, 2001.
[15] H. Xia and J.C. Brustoloni. Hardening web browsers against manin-the-middle and eavesdropping attacks. In Proceedings of the 14th
international conference on World Wide Web, pages 489–498. ACM New
York, NY, USA, 2005.

VI. C ONCLUSION AND F UTURE W ORK
In this paper we have proposed a secure web referral
service framework, which is designed to counter web-based
MITM and phishing attacks. This service can be accessed
by downloading the browser extension from https://www.
wreferral.com. The SSE involves minimum interventions of
humans for security decisions. The performance of the SSE
phishing filter has low false positives and false negatives. We
will extend the browser extension by providing support for
those websites which starts HTTPS request from a Javascript.
We note that, to counter sslstrip MITM attack, it is intuitive
to extend existing DNSSEC [1],[3], [2] by informing users
whether the remote web server supports SSL or not. The
58

IEEE TRANSACTIONS ON EDUCATION, VOL. 57, NO. 3, AUGUST 2014

145

Cloud-Based Virtual Laboratory for Network
Security Education
Le Xu, Dijiang Huang, Senior Member, IEEE, and Wei-Tek Tsai, Member, IEEE

Abstract—Hands-on experiments are essential for computer
network security education. Existing laboratory solutions usually
require significant effort to build, configure, and maintain and
often do not support reconfigurability, flexibility, and scalability.
This paper presents a cloud-based virtual laboratory education
platform called V-Lab that provides a contained experimental
environment for hands-on experiments using virtualization technologies (such as Xen or KVM Cloud Platform) and OpenFlow
switches. The system can be securely accessed through OpenVPN,
and students can remotely control the virtual machines (VMs) and
perform the experimental tasks. The V-Lab platform also offers
an interactive Web GUI for resource management and a social
site for knowledge sharing and contribution. By using a flexible
and configurable design, V-Lab integrates pedagogical models
into curriculum design and provides a progressive learning path
with a series of experiments for network security education. Since
summer 2011, V-Lab has served more than 1000 students from six
courses across over 20 experiments. The evaluation demonstrates
that the platform and curriculum have produced excellent results
and helped students understand and build up computer security
knowledge to solve real-world problems.
Index Terms—Collaborative learning, network security, virtual
laboratory.

I. INTRODUCTION

H

ANDS-ON experiments are essential when educating
network security specialists. However, it is difficult for
computer security education to keep pace with rapidly changing
computer security issues to mimic real-world scenarios in a
contained environment. This paper presents an innovative
cloud-based virtual laboratory platform called V-Lab that utilizes open-source virtualization technologies such as Xen and
KVM, and software defined networking (SDN) solutions such
as OpenFlow switches to construct a scalable, reconfigurable,
and contained experimental environment for network security
education. The design of V-Lab is based on our previous
work [1] with the following improved features:
1) a contained network security experimental environment
providing dedicated virtual machines (VMs) and virtual
networks to students;
Manuscript received January 09, 2013; revised June 15, 2013; accepted July
23, 2013. Date of publication October 17, 2013; date of current version July 31,
2014. This work was supported by the NSF CCLI under Grant DUE-0942453.
The infrastructure of V-Lab is based on support by the ONR Young Investigator
Program (YIP) Award and the Ira A. Fulton School of Engineering, Arizona
State University.
The authors are with the School of Computing, Informatics, and Decision
Systems Engineering, Arizona State University, Tempe, AZ 85287 USA
(e-mail: Le.Xu@asu.edu; Dijiang.Huang@asu.edu; wtsai@asu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TE.2013.2282285

2) a reconfigurable networking environment with the flexibility to mimic various real-world computer networks;
3) a collaborative laboratory environment with resource
sharing and access control;
4) a Web portal for user-centric resource management with
knowledge sharing.
V-Lab empowers a three-phase pedagogical model that is described in [2]:
• Phase I: learn basic knowledge;
• Phase II: acquire and practice skills and abilities;
• Phase III: collaborate and share knowledge.
This model is extended with six factors (Motivation, Knowledge, Creativity, Collaboration, Demonstration, and Feedback)
to develop a series of progressive experiments to achieve the following pedagogical achievements:
1) a progressive curriculum that builds a private network
system, from introductory to advanced levels;
2) a contained environment, in which all kinds of real-world
network security experiments are performed without affecting external systems;
3) a collaborative model that encourages knowledge innovation and contribution through a Web-based social platforms
and virtualized resource sharing approaches.
The rest of the paper is arranged as follows. Section II
presents the related work. The V-Lab system architecture is
presented in Section III. The applied pedagogical model and
the corresponding case studies are presented in Sections IV
and V, respectively. In Section VI, we discuss the educational
results. Finally, the conclusion and future work are presented
in Section VII.
II. RELATED WORK
This section categorizes a few existing virtual laboratories for
hands-on experiments as shown in Table I.
1) Virtual Application Laboratories: This type of laboratory
uses desktop virtualization, in which the simulation and problem
solving are restricted by predefined algorithms of the underlying software. Additionally, hands-on laboratories do not usually allow students to keep application data or states on remote
servers, and as a result, this may require students to finish an
experiment in a single session.
2) Shared-Host Laboratories: These laboratories are built on
a fixed pool of computers with remote desktop accesses. Each
computer can support several students logged in concurrently.
However, a host is usually shared between multiple concurrent
users at same time, which restricts the shared host to be used
for different purposes. Moreover, the shared system may not

0018-9359 © 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

146

IEEE TRANSACTIONS ON EDUCATION, VOL. 57, NO. 3, AUGUST 2014

TABLE I
VIRTUAL LABORATORY FEATURE COMPARISON

support load balancing or may not provide sufficient isolation to
prevent potential performance and security issues among users.
3) Single-VM Laboratories: These laboratories provide predefined VMs (or templates) for students. A VM can be requested
and released by students, or students can establish their own
VMs. The single-VM approaches usually do not have a management portal that creates virtual resources customized for each
user. Moreover, VMs are usually running on common desktops
or laptops, and they cannot support complicated multi-VM networking environments.
4) Multi-VM Laboratories: These laboratories provide multiple VMs that can either run in the cloud [25] or on a student’s
PC [24]. The multi-VM environment allows students to construct complex system configurations for experiments. However, these laboratories may not provide flexible networking,
sufficient isolation, or reconfiguration capacities. Usually, these
features are needed to perform network security experiments.
Moreover, these systems often do not support isolated interserver communication, and thus require all VMs to reside within
one physical server.
5) Multi-VM and Multinetwork Laboratories: These laboratories fully utilize the virtualization capacities of cloud virtualization capabilities to provide dedicated and contained experimental environment with multiple VMs and multiple virtual networks. The system offers a Web-based management portal for
instructors and students to manage and create virtual resources
in a user-friendly fashion. The virtual resources can be reconfigured throughout the course to introduce new experiments. Compared to [28] and [29], the V-Lab system provides an interactive Web GUI for network constructions and reconfigurations
and experiments deployments.
III. SYSTEM ARCHITECTURE
A. Overview
The overview of the V-Lab system architecture is shown
in Fig. 1. Currently, the physical V-Lab system consists of a
cluster of cloud servers with high-performance capabilities and
virtualization support, an HP OpenFlow switch, an array of

Fig. 1. Overview of V-Lab system architecture.

iSCSI storage area network (SAN) servers that provide VM
storage and backup redundancy, and an uninterruptible power
supply (UPS) system capable of 10 h of battery time for the
entire system. The system allows up to 1000 VMs running
various operating systems from Windows XP/7/Server to
Ubuntu/CentOS/Redhat. The descriptions for each component
follow.
B. V-Lab Front-End User Web Portal
The front-end Web portal uses a real-time visual editor on
the Web site to manage the virtual resources for experiments.
Instructors can drag-n-drop multiple VM hosts into the canvas
and configure them as various network devices. Once the configuration is complete, it can be submitted to the back-end virtual resource (VR) engine to allow enrolled students to perform
experiments.

XU et al.: CLOUD-BASED VIRTUAL LABORATORY FOR NETWORK SECURITY EDUCATION

147

TABLE II
THREE-PHASE PEDAGOGICAL MODEL FOR COMPUTER NETWORK SECURITY
CURRICULUM DESIGN

Fig. 2. Experimental environment for BNCE.

C. V-Lab Back End
The major components of the V-Lab back-end systems are
established based on Xen Cloud Platform (XCP) and OpenStack. Both XCP and OpenStack are open-source virtual computing platforms. The V-Lab platform allows students to work
with special kernels or drivers of the VMs running in the cloud
system. The system also uses open virtual switches (OVS) over
generic routing encapsulation (GRE) through OpenFlow protocols with a network controller, e.g., a NOX/POX network controller [30], to provide isolated virtual networking experiments.
The back end also contains various internal services for administration and management purposes.
IV. PEDAGOGICAL MODEL
To achieve the pedagogical goals, the paper presents a progressive three-phase teaching model, shown in Table II, which
is evaluated by six factors, shown in Table III.
Teaching I focuses on transferring basic networking and
cryptography knowledge to students and preparing them for
advanced experiments. During this phase, students learn to use
V-Lab and to set up the experimental environment with a small
number of VMs and networks that will serve as building blocks
for the next phase.
Teaching II allows students to build upon the knowledge
gained previously and apply it in more realistic and complex
experiments. This phase requires students to work in groups
and utilize various applications and techniques to build up a
working solution for experimentation. The solution will be
demonstrated and shared with other students during or after
experiments.
Teaching III provides a list of advanced-topic projects that
require students to research existing network security systems
and build their own systems. During the evaluation process, students are split into groups to challenge others’ systems while
defending their own. This allows students to increase and consolidate their own knowledge and contribute to that of others.

Fig. 3. Experimental environment for man-in-the-middle attack.

V. V-LAB CASE STUDIES
A. Teaching I: Basic Network Configuration Experiments
(BNCE) With Knowledge Learning and Sharing
In the Teaching I phase, the V-Lab curriculum offers a series
of experiments that cover a wide range of basic networking
knowledge, such as using SSH and VNC to access remote hosts,
configuring IP addresses, subdividing networks, using network
commands such as Ping and Ifconfig, and configuring Web
servers, DNS servers, and IPTables rules. In these experiments,
a student is provided with three VMs interconnected with two
virtual networks, as shown in Fig. 2. After each experiment, a
lab teaching assistant (TA) can login remotely to each student’s
environment to perform grading, without requiring the student
and the TA to be physically present in the laboratory. This flexible grading process allows TAs to manage their TA hours more
efficiently and focus on answering questions and debugging
the students’ systems remotely. When the student encounters
a problem during the experiment, the TA can remotely login
and see the screen of the student’s VMs. Using the V-Lab
embedded peer-to-peer video conferencing capability, the TA
and the student can work on the lab experiments remotely
without needing to meet in person.
B. Teaching II: Intermediate Network Security Experiments
(INSE) With Collaborations and Demonstrations
The Teaching II phase begins by expanding and reconfiguring the three-VM system from the Teaching I phase to solve
more complex networking security problems, such as SSL-stripbased MITM attack (Fig. 3), IPTables-based packet filtering,
and Snort-based intrusion detection. For each experiment, the
V-Lab system dynamically changes the current experimental

148

IEEE TRANSACTIONS ON EDUCATION, VOL. 57, NO. 3, AUGUST 2014

TABLE III
SIX-FACTOR PEDAGOGICAL MODEL FOR EXPERIMENT EVALUATION AND GRADING (SAMPLE SIZE: 212)

environment by adding new VMs and VLANs to fit new requirements. In addition to discussing the knowledge base of the
experiment, instructors also need to give students a comprehensive lecture about the problem at hand, such as the various attack
or defense mechanisms, with appropriate references. To gain a
good grade for the experiment, students must not only achieve
the expected results, but also write a report presenting the techniques and applications used in the experiment.
Hands-on experiments can greatly expand students’ knowledge. For instance, instructors can show that an MITM attack
can only happen within a client network by assigning a new
VM on the server’s network and allowing students to attempt
the MITM attack with the new VM. Experiments in Teaching II
usually blend multiple levels of networking knowledge and thus
are good test beds for practicing and exploration.
C. Teaching III: Advanced Network Security Experiments
(ANSE) With Researches and Creativities
The Teaching III phase allows students to collaborate on research into real-world network system design. Students also
learn how to follow a requirement-driven industrial design and
development process and to construct the system with evaluation, attack model, and risk analysis. For example, some research conducted in V-Lab was published in [31] and [32].
VI. RESULTS AND DISCUSSIONS
Since the summer of 2011, V-Lab has hosted 2892 VMs
to serve 604 graduate and 530 undergraduate students across

TABLE IV
COURSES USING V-LAB

six computer science and engineering courses (as shown in
Table IV) in over 20 hands-on experiments. Two types of student surveys were collected from 212 of a total of 278 students,
for a participation rate of 76.3%. The first survey evaluated the
experiment elements (Table III), and the second one focused
on each teaching phase (Table V) with satisfactory results.
Compared to the same set of courses for each semester year
since 2009, the V-Lab curriculum and resources helped produce
more hands-on experiments [Fig. 4(a)], reduced training hours
[Fig. 4(b)], and resulted in a higher completion rate [Fig. 4(c)].
The results also showed a positive feedback in Fig. 5. The paper

XU et al.: CLOUD-BASED VIRTUAL LABORATORY FOR NETWORK SECURITY EDUCATION

149

TABLE V
V-LAB EXPERIMENT SURVEY RESULTS (SAMPLE SIZE: 212)

Fig. 4. Benefits of using V-Lab system: (a) increased number of hands-on experiments, (b) reduced hours for lab setup and configure, and (c) increased percentage
of students finishing the experiments on time.

Fig. 5. Positive feedback of V-Lab benefits.
Fig. 7. Correlation between grades in progressive experiments and final grades.

progressive experiments also affected their grades (Fig. 7).
Both grades were on a range from 0 to 100 plus a 20-point
bonus. The Pearson correlation on these two sets of data is 0.72
and is statistically significant at the 0.01 level. Thus, students
who performed better in progressive experiments also get better
grades with 99% confidence.
Fig. 6. Comparison of grade distributions for students participating traditional
experiments versus progressive V-Lab experiments.

compares student grades from the network security course before and after using V-Lab. The results showed that students
using V-Lab achieved better grades (Fig. 6), compared to traditional laboratories. Grade data for 42 students from a network
security course in 2012 showed that course performance in

VII. CONCLUSION AND FUTURE WORK
This paper has presented V-Lab, a cloud-based virtual laboratory education platform that provides a contained and private
experiment environment for each student using the Cloud Platform and SDN approaches. V-Lab also provides an interactive
Web GUI for virtual resource management and a social site for
knowledge sharing and contribution. The virtual resources created can be securely accessed through OpenVPN. The system
transcends the time and space limits of traditional laboratories

150

IEEE TRANSACTIONS ON EDUCATION, VOL. 57, NO. 3, AUGUST 2014

and provides experiments that not only allow flexible schedules, but also enable students to focus on content rather than
the setting up of the environment. The system incorporates a
three-phase teaching model with progressive hands-on experiments that encourage collaboration and sharing and help students gain more knowledge and better grades.
In the future, the system can deploy high-availability and redundancy features to provide a more reliable platform. By incorporating crowdsourcing from communities, the system can
benefit from user-contributed curricula and feedbacks and eventually become an open crowd-learning ecosystem.
REFERENCES
[1] L. Xu, D. Huang, and W. T. Tsai, “V-Lab: A Cloud-based Virtual Laboratory Platform for Hands-on Networking Courses,” in Proc. 17th
Annu. ACM ITiCSE, 2012, pp. 256–261.
[2] P. Baumgartner and F. I. Hagen, “The Zen art of teaching communication and interactions in education,” in Proc. Interactive Conf. Comput.
Aided Learning, 2004, pp. 1–18.
[3] D. Ramalingam, “Practicing computer hardware configuration and network installation in a virtual laboratory environment: A case study,” in
Proc. 37th Annu. Frontiers Educ. Conf., 2007, pp. F3G-21–F3G-24.
[4] Y. Liu, L. Zhang, and F. Jiao, “Teaching computer networking experiment in the realistic network laboratory,” in Proc. Int. Conf. Comput.
Intell. Softw. Eng., Dec. 2009.
[5] T. A. Yang and T. A. Nguyen, “Network security development process:
A framework for teaching network security courses,” J. Comput. Small
Coll., vol. 21, pp. 203–209, April 2006.
[6] Rochester Institute of Technology (RIT), Rochester, NY, USA,
“Rochester Institute of Technology (RIT) NSSA Labs,” Apr. 2012
[Online]. Available: http://www.rit.edu/gccis/computingsecurity/
[7] L. DeLooze, P. McKean, J. Mostow, and C. Graig, “Incorporating simulation into the computer security classroom,” in Proc. 34th Annu.
Frontiers Educ. Conf., Oct. 2004, vol. 3, pp. S1F/13–S1F/18.
[8] Y. Tateiwa, K. Kurachi, J. Zhang, T. Yasuda, and S. Yokoi, “LiNeS:
Virtual network environment for network administrator education,” in
Proc. 3rd Int. Conf. Innov. Comput. Inf. Control, Jun. 2008, pp. 1–4.
[9] A. Ferrero and V. Piuri, “A simulation tool for virtual laboratory experiments in a www environment,” in Proc. IEEE Instrum. Meas. Technol.
Conf., 1998, pp. 102–107.
[10] State University of New York, Geneseo, NY, USA, “State University
of New York Geneseo Virtual Computer Lab,” Apr. 2012 [Online].
Available: http://www.geneseo.edu/cit/virtual_computer_labs
[11] ASU, Tempe, AZ, USA, “ASU My Apps,” Apr. 2012 [Online]. Available: http://www.asu.edu/myapps
[12] Duke University, Durham, NC, USA, “Duke University Virtual Computing Lab,” Apr. 2012 [Online]. Available: http://oit.duke.edu/compprint/labs/vcl/index.php
[13] Pennsylvania State University, University Park, PA, USA, “Penn
State University Virtual Lab,” April 2012 [Online]. Available:
http://psbeh8b.psu-erie.bd.psu.edu/academicservices/virtuallab.htm
[14] Illinois Security Lab, Urbana, IL, USA, “Illinois Security Lab,” Apr.
2012 [Online]. Available: http://seclab.illinois.edu/
[15] I. Gustavsson, K. Nilsson, J. Zackrisson, J. Garcia-Zubia, U. Hernandez-Jayo, A. Nafalski, Z. Nedic, O. Gol, J. Machotka, M.
Pettersson, T. Lago, and L. Hkansson, “On objectives of instructional
laboratories, individual assessment, and use of collaborative remote
laboratories,” IEEE Trans. Learning Technol., vol. 2, no. 4, pp.
263–274, Oct.–Dec. 2009.
[16] M. Chirico, A. Scapolla, and A. Bagnasco, “A new and open model to
share laboratories on the Internet,” IEEE Trans. Instrum. Meas., vol.
54, no. 3, pp. 1111–1117, Jun. 2005.
[17] J. Prieto-Blazquez, J. Arnedo-Moreno, and J. Herrera-Joancomarti,
“An integrated structure for a virtual networking laboratory,” IEEE
Trans. Ind. Electron., vol. 55, no. 6, pp. 2334–2342, Jun. 2008.
[18] W. Du and R. Wang, “Seed: A suite of instructional laboratories for
computer security education,” J. Educ. Resources Comput., vol. 8, no.
1, 2008, Art. no. 3.
[19] H. E. Schaffer, S. F. Averitt, M. I. Hoit, A. Peeler, E. D. Sills, and M. A.
Vouk, “NCSU’s virtual computing lab: A cloud computing solution,”
Computer, vol. 42, no. 7, pp. 94–97, Jul. 2009.

[20] W. Sun, V. Katta, K. Krishna, and R. Sekar, “V-NetLab: An approach
for realizing logically isolated networks for security experiments,” in
Proc. Conf. Cyber Security Exper. Test, 2008, pp. 1–6.
[21] V. J. H. Powell, C. T. Davis, R. S. Johnson, P. Y. Wu, J. C. Turchek, and
I. W. Parker, “VLabNet: The integrated design of hands-on learning in
information security and networking,” in Proc. 4th Annu. InfoSecCD,
2007, pp. 9:1–9:7.
[22] University of New Mexico (UNM), Albuquerque, NM, USA, “University of New Mexico (UNM) IA Lab,” Apr. 2012 [Online]. Available:
http://ia.mgt.unm.edu/labintro.asp
[23] Idaho University, Moscow, ID, USA, “Idaho University VRAD Lab,”
Apr. 2012 [Online]. Available: http://seniordesign.engr.uidaho.edu/
index.html
[24] P. Li and T. Mohammed, “Integration of virtualization technology
into network security laboratory,” in Proc. 38th Annu. Frontiers Educ.
Conf., Oct. 2008, pp. S2A-7–S2A-12.
[25] M. Wannous and H. Nakano, “NVLab, a networking virtual Web-based
laboratory that implements virtualization and virtual network computing technologies,” IEEE Trans. Learning Technol., vol. 3, no. 2,
pp. 129–138, Jun. 2010.
[26] M. Anisetti, V. Bellandi, A. Colombo, M. Cremonini, E. Damiani, F.
Frati, J. Hounsou, and D. Rebeccani, “Learning computer networking
on open paravirtual laboratories,” IEEE Trans. Educ., vol. 50, no. 4,
pp. 302–311, Nov. 2007.
[27] A. Kara, E. Aydin, M. Ozbek, and N. Cagiltay, “Design and development of a remote and virtual environment for experimental training in
electrical and electronics engineering,” in Proc. 9th ITHET, 2010, pp.
194–200.
[28] C. Yan, “Build a laboratory cloud for computer network education,” in
Proc. 6th ICCSE, Aug. 2011, pp. 1013–1018.
[29] USC ISI, Los Angeles, CA, USA, U. C. Berkeley, Berkeley, CA, USA,
“The DETER Project,” Apr. 2012 [Online]. Available: http://www.
deter-project.org/
[30] N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown,
and S. Shenker, “NOX: Towards an operating system for networks,”
Comput. Commun. Rev. vol. 38, no. 3, pp. 105–110, Jul. 2008.
[31] D. Huang, Z. Zhou, L. Xu, T. Xing, and Y. Zhong, “Secure data processing framework for mobile cloud computing,” in Proc. IEEE INFOCOM Workshop Cloud Comput., 2011, pp. 614–618.
[32] C. Chung, P. Khatkar, T. Xing, J. Lee, and D. Huang, “NICE: Network intrusion detection and countermeasure selection in virtual network systems,” IEEE Trans. Depend. Secure Comput., vol. 10, no. 4,
pp. 198–211, Jul. 2013.

Le Xu is currently pursuing the Ph.D. degree at the School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe,
AZ, USA.
His research areas include service-oriented computing, network security, and
education.

Dijiang Huang (M’00–SM’11) received the B.S. degree in telecommunications
from Beijing University of Posts and Telecommunications, Beijing, China, in
1995, and the M.S. and Ph.D. degrees in computer science and telecommunications from the University of Missouri–Kansas City, Kansas City, MO, USA, in
2001 and 2004, respectively.
He is currently an Associate Professor with the School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe,
AZ, USA. His current research interests are computer networking, security, and
privacy.
Dr. Huang is an Associate Editor of the Journal of Network and System Management and an Editor of IEEE COMMUNICATIONS SURVEYS AND TUTORIALS.
His recent research is supported by the ONR, ARO, NSF, and HP.

Wei-Tek Tsai (M’13) received the Ph.D. degree in computer science from the
University of California, Berkeley, CA, USA, in 1985.
He is a Professor with the School of Computing, Informatics, and Decision
Systems Engineering, Arizona State University, Tempe, AZ, USA. He is interested in service-oriented computing, education, testing and simulation and has
written four books in related fields.

Globecom 2013 - Communication and Information System Security Symposium

An Efficient and Anonymous Attribute-Based
Group Setup Scheme
Bing Li, Zhijie Wang, and Dijiang Huang
Arizona State University, Tempe, AZ, USA

Abstract—In many secure application scenarios, establishing a
temporary group without revealing group member information is
difficult but desirable. Secure group communication can significantly reduce the computation and communication overhead.
Traditional group key management schemes are based on a
hierarchical tree. Any network entity who wants to set up a
group needs to know the keys of the other group members,
i.e., the group key establishment must be done before starting
the group communication. As a result, the group needs the
group formation beforehand. In this paper, we propose a secure
grouping scheme providing anonymity for group members to
outsiders. Our approach is based on Attribute Based Encryption
(ABE) schemes. In our scheme, each network entity is assigned
with a set of attributes. Each group is identified by a logical
combination of attributes, i.e., the group access policies. The
presented solution has an advantage that there is no need for any
prior knowledge of other group members. Instead, the sender
just needs to focus on the group access policies. Our scheme
further preserves the group formation policies by using a gradual
exposure method on attributes. Compared to existing hiddenpolicy schemes, our solution can greatly reduce the computation
and communication overhead.
Index Terms—group communication, attribute based encryption, anonymity

I. I NTRODUCTION
Secure group communication approaches protect secret information to be shared securely and efficiently among a group
of communicating nodes, in which it has gained attractions in
many application scenarios [1]. Using group communication
solutions, efficient group management and the anonymity of
group remembers are the two most important security features
that have been extensively studied in the literature.
In order to provide a secure group communication environment, a group session key needs to be shared among
group members. Traditional key-distribution schemes rely
on a set of key-encryption-keys (KEKs) and a hierarchical
key management structure to reduce the key management
complexity. Usually, a trusted key server is responsible for
group management by maintaining the minimal set of KEKs
that are shared by legitimate group members. During the
communication, a group session key is encrypted using KEKs
and then it is distributed to group members for decrypting
secret messages. This approach works well in a centralized
group management scenario, i.e., a centralized key server is
responsible for managing the group formation. However, in
real scenarios, it is usually desirable that each group member
can self-manage the group/subgroup formation without relying
on an online centralized group management server.

978-1-4799-1353-4/13/$31.00 ©2013 IEEE

Another critical concern is membership anonymity. Information concerning the group formation, such as group member
identities and group size, are usually the targets of attackers.
In [2], the authors propose an ABE-based anonymous group
management approach. However, using this approach, a message receiver needs to try with all its attributes to decrypt
the ciphertext to determine whether it is a member of the
group, which is not efficient. Moreover, this solution requires
to establish an ABE-based system for each group, which
consequently invokes high group management overhead.
To address the described issues, we propose a new secure
group communication scheme based on ABE. Our approach
achieves better performance than previous solutions by using
a novel solution named Efficient and Anonymous AttributeBased Encryption (EA-ABE). Instead of requiring every message receiver to use each of their attributes to decrypt the
message, a receiver is able to discover his eligibility through
a guided process by discovering the eligibility with the maximum O(h) steps, where h is the height of the attribute
policy tree. In addition, unlike most of previous solutions, the
attribute management of EA-ABE is decentralized, so that any
node can be the group controller or one of the group members
in different group setups. The update processes for both group
session keys and attributes can be distributed among network
entities. In summary, EA-ABE scheme achieves the following
contributions:
•

•

•

•

EA-ABE applies an attribute-based policy tree access
control mechanism that incorporates the policy-based
data access control in the ciphertext. Only eligible group
members can discover the full or partial enforced policies
based on the attributes owned by the group member;
EA-ABE provides privacy protection on group access
policies in that any ineligible group node cannot reveal
the information of the group policy even if they collude
together;
EA-ABE significantly reduces the computation and communication overhead for a group communication participant to determine its group membership;
EA-ABE simplifies both the group setup and role management in a group, and provides a flexible attribute
management.

The remainder of this paper is organized as follows: Section
II provides the related work on secure group communications
and ABE-based solutions; Section III presents the system models and preliminaries of an ABE scheme; detailed description

861

Globecom 2013 - Communication and Information System Security Symposium
2

of EA-ABE scheme is provided in Section IV; the performance
and security analysis is presented in Section V; and finally, we
conclude this paper in Section VI.
II. R ELATED W ORK
Traditional solutions for group communication setup are
based on a key distribution center (KDC) and a hierarchical
tree [3]. When a node needs to set up a group, it needs
the KDC to resolve the minimum set of keys shared among
the group members. Then it sends out the group session key
encrypted with each of the keys. In this way, the KDC who
possesses knowledge of the key hierarchy is involved in the
setup of every communication group.
In 2007, J. Bethencourt et al. proposed a new ABE scheme
called Ciphertext-Policy ABE (CP-ABE) [4]. In this scheme,
each node is assigned with a set of attributes, and each attribute
corresponds to a private key. The policy is defined in the
encryption process. Only eligible entities with satisfactory
attributes can successfully decrypt the ciphertext. The policy
is sent out in plain text together with the ciphertext, so
that a receiver can check if it satisfies the policy before
decryption. CP-ABE makes it possible to apply access control
to individual messages. As such, a sender can specify all
the required attributes without knowing the receivers’ keys
in advance. Moreover, this scheme is secure against collusion
attacks.
Subsequent to the basic CP-ABE scheme, some other
schemes [5, 6] are proposed to enhance certain features of
the original scheme. As those features are not related to our
concern, we will not provide details of them in this paper.
In CP-ABE, the policy is transmitted in clear text. Any
receiver of the ciphertext is able to check the policy even if
he does not satisfy. Thus, the entire policy is exposed to the
attackers, causing a serious privacy issue. To hide the policy
without interrupting the decryption process, several schemes
[2, 7] are proposed to make sure that a message receiver
gets no information about the policy if he fails in decryption.
All these hidden-policy schemes share a common problem
that a node receiving the ciphertext cannot determine if it is
an eligible receiver before it completes the entire decryption
process. This incurs heavy computation overhead in group
setups for a large scale network. When a node sends out a
session key under a policy in broadcast manner, any receiver
of the message will have to decrypt it so as to determine if
it is part of the group. Since the number of group members
is usually smaller than the total number of nodes in network,
the additional computation cost for non-group members is not
negligible. Furthermore, the scheme in [2] is not designed in a
public-key pattern. Only the group controller has the ability to
set up a group, which greatly limits its application scenarios.
To reduce the computation overhead, D. Huang et al.
proposed to gradually expose the policy in multiple steps
[8]. At each step, only one attribute is exposed. In this
way, a receiver can decrypt a message with one attribute at
each step. Once the current decryption step fails, the receiver
immediately knows he is ineligible. This approach greatly

reduces the computational cost because ineligible nodes do
not have to complete the entire decryption process. However,
it only supports AND-gates in the attribute policy which limits
the flexibility of the policy. Moreover, it exposes one more
attribute to the receiver if he fails in the decryption process.
Comparatively, the EA-ABE scheme enables the use of ORgates, and protects the privacy of the attribute policy so that
ineligible nodes cannot get any information on any attribute
in the policy that they do not have.
III. M ODELS AND P RELIMINARIES
In this section, we present the basic system model and
attack model. A general description of CP-ABE scheme is
also provided.
A. System model
In our scheme, each node in network is assigned with a
unique identifier (U ID) and a set of attributes. U ID itself
can be treated as one attribute. A trusted third party (TTP)
is in charge of setting up global parameters for the entire
network. A network node that defines and manages one or
more attributes is defined as the authority of the attribute(s).
Each attribute is defined and managed by the same authority.
Any network node can work as an authority. When a node
needs to set up a group (we denote this node as the Group
Founder of the group), it generates an attribute policy using
logic gates to connect attributes. Therefore, unlike traditional
key management schemes, the Group Founder does not need
to know each of the group members’ keys. All it concerns
is the attribute policy that a group member needs to satisfy.
For example, if a university principal wants to set up a video
conference with deans from every department, he does not
need to know each individual key of the deans. Instead, he can
set up this group using the policy: {P rincipal} OR {Dean}.
Any party in the network that possesses neither {P rincipal}
nor {Dean} will not be able to decrypt any secret information
in the group.
To complete a secure group communication setup, the
Group Founder needs to send out a group session key to
all the other members using the EA-ABE scheme with the
attribute policy it created. Note that unlike [2], any node can
be a Group Founder and set up a group. There is no additional
requirements between a Group Founder and a group member.
In secure group communications, it is necessary for the
Group Founder to authenticate itself to other members. The
goal is to prove that the founder itself satisfies the attribute
policy. Otherwise, an attacker can easily set up a group with
network nodes that he is not supposed to communicate with.
In our design, this requirement is met by sharing information
of each attribute secretly among attribute holders only. A
node without such information cannot use the attribute for
encryption. The details are illustrated in Algorithm 4.
B. Attack model
In this paper, we assume attackers are trying to compromise
the scheme for two goals: (1) joining in a group without eligible attributes; (2) retrieving the group formation information.

862

Globecom 2013 - Communication and Information System Security Symposium
3

Table I
N OTATIONS

To achieve the first goal, an attacker needs to retrieve the
session key of the target group. This can be done by exploiting
vulnerabilities within the secret protection functionality of the
key distributing scheme. If this is difficult, the attacker can
change to target at the group membership information. The
identity information of the authorized key receivers is stored
and protected within the key distribution message. The attacker
needs to analyze this message and the protection technique of
the identity information so as to expose this information or
gain certain amount of knowledge about it. The consequence
of a successful attack is to gain unauthorized information,
identify valuable nodes and launch further attacks on them.

Terms
G0
G1
e(·)
ROOT
Enck (·)
Deck (·)
encryption
sequence
decryption
sequence

C. Preliminaries of CP-ABE
CP-ABE is based on bilinear pairing computation. Suppose
G0 is an additive group and G1 is a multiplicative group. Both
of them are with a large prime order p. Discrete Logarithm
Problem (DLP) is hard in both G0 and G1 . Define a bilinear
map e : G0 × G0 → G1 . This map has three properties:
ab
• Bilinearity: e(aP, bQ) = e(P, Q) , for any P, Q ∈ G0
and a, b ∈ Zp ;
• Nondegeneracy: e(g, g) 6= 1, g is the generator of G0 ;
• Efficiency: Pairing can be efficiently computed.
In CP-ABE, there are three types of keys: master key,
public key and private key. A TTP is required to generate
a set of public parameters and the master key. The TTP is
not involved in network communication. It can be offline.
There are four basic algorithms in CP-ABE: Setup, Encrypt,
KeyGen and Decrypt. In Setup, the TTP chooses two random exponents α, β ∈ Zp . A public key is formatted as
< G0 , g, h, f, e(g, g)α > while the master key is (β, g α ).
1
Here h = g β , f = g β . The public key is published by the
TTP. When a party wants to encrypt a message M , it runs the
Encrypt algorithm, which takes the public key, the message
M and a policy tree T as inputs. The KeyGen algorithm is
used to generate private keys based on the master key and
a set of attributes. For each network node, the TTP runs the
KeyGen once to generate a private key according to the node’s
attributes. When a node receives the ciphertext, it runs the
Decrypt algorithm to get the encrypted data.
IV. ABE FOR C OMMUNICATION G ROUP S ETUP
In this section, we present the EA-ABE scheme for secure
communication group setup. EA-ABE is based on previous
ABE algorithms [4, 8]. We also illustrate the management of
group keys and attribute keys. Before introducing details of
the scheme, we give a summary of notations in Table I.

Ai or An

AP ub

Meaning
a bilinear group with a prime order p
a multiplicative group with the same prime order p
a bilinear map e : G0 × G0 → G1
a global constant value ROOT ∈ G1 as identification
of the secret message protected with the policy
a symmetric encryption algorithm Enck (·) and the
corresponding decryption algorithm Deck (·) in G1
a conjunctive clause representing the sequence of att-ributes in the encryption process
a conjunctive clause representing the sequence of att-ributes in the decryption process
an attribute, Ai is used for denoting an individual att-ribute, An denotes the n-th attribute in a sequence
a public attribute shared among all the network nodes,
the corresponding values stored at each node are
(IP ub , TP ub ), IP ub ∈ Zp , TP ub ∈ G0

the sequence of attributes is enforced by the encryptor. We
name the sequence of attributes when encrypting a clause as
encryption sequence and the opposite sequence as decryption
sequence. We define a public attribute AP ub in EA-ABE.
Unlike other attributes, AP ub is associated with an ordered
pair (TP ub , IP ub ). For each conjunctive clause, the encryptor
adds AP ub at the end of the encryption sequence.
In EA-ABE scheme, a GlobalSetup algorithm is run by
a TTP to generate global parameters for the system. For
each node joining in the network, the TTP runs a NodeJoin
algorithm to generate a unique secret for the node. The
input of NodeJoin is the node’s U ID while the outputs are
{DU ID , XP ub,U ID , YP ub , ZP ub,U ID }. For each attribute,
the attribute authority runs an AuthoritySetup algorithm to
generate secrets associated with the attribute. Additionally,
there are other three basic algorithms in EA-ABE: KeyGen,
Encrypt and Decrypt.
The GlobalSetup algorithm and NodeJoin algorithm are
defined as in Algorithm 1 and Algorithm 2.
Algorithm 1 GlobalSetup
1: Choose a bilinear group G0 with a large prime order p. g is the

generator of G0 ;
2: Choose two random values α, β ∈ Zp ;
3: Publicly define a global constant value ROOT ∈ G1 as identi-

fication of the secret message;
4: Publicly choose a symmetric encryption algorithm Enck (·) and

A. EA-ABE

the corresponding decryption algorithm Deck (·) in G1 ;

Attributes of a node can be any value in strings. In CP-ABE,
these values are converted into mathematical values using hash
functions. In EA-ABE, each attribute string Ai corresponds to
a triplet (Ti , Ii , ki ). Mapping from a string to such a triplet is
not defined by hash functions but determined by the authority
of Ai . An access policy can be represented in Disjunctive
Normal Form (DNF) of attributes. In each conjunctive clause,

5: Define and publish a public attribute shared among the network

nodes, (SP ub , TP ub ), SP ub ∈ Zp , TP ub ∈ G0 ;

6: The global parameters are {G0 , g, g β , e(g, g)α , Enck (·),

Deck (·), (SP ub , TP ub ), ROOT }, global secrets are {β, g α }.

Each authority that manages an attribute Ai will have to
run the AuthoritySetup algorithm (Algorithm 3) to set up
the secrets associated with Ai .

863

Globecom 2013 - Communication and Information System Security Symposium
4

Algorithm 2 NodeJoin

Algorithm 5 Encrypt

1: For each node with U ID joining in the network, generate a

= Sk e(g, g)αs , C 0 = g βs and C 00 =
EncSk (ROOT ), where s ∈ Zp is a random value, Sk is the
message to be encrypted;
Start from the beginning of the clause in the encryption sequence;
For each attribute An , if a triplet (C1,n , C2,n , C3,n ) has already
been calculated, move to the next attribute An+1 and restart step
3 with An+1 ; else, goto step 4;
Choose a random number tn ∈ Zp ;
Calculate:
C1,n = g (In−1 −In )tn ,

1: Calculate C

random number rU ID ∈ Zp and store it securely;
2: Calculate and assign DU ID = g (α+rU ID )/β to the node;
3: Calculate and assign to the node:

2:
3:

r

XP ub,U ID = g rU ID TPPubub ,
YP ub = g rP ub ,

4:
5:

ZP ub,U ID = e(g, g)rU ID IP ub .
where rP ub ∈ Zp is a random number for each node;

(In−1 −In )tn

4: Assign to the node {DU ID , XP ub,U ID , YP ub , ZP ub,U ID }.

C2,n = Tn

C3,n = (kn tn )

Algorithm 3 AuthoritySetup

,

.

1 ≤ n ≤ m;

1: For each attribute Ai , choose two random numbers Ii , ki ∈ Zp ;
2: For each attribute Ai , choose one random value Ti ∈ G0 .

The KeyGen algorithm generates the private keys corresponding to each attribute for each node holding this attribute.
It is a cooperative algorithm between an authority and the TTP,
which is defined in Algorithm 4.
Algorithm 4 KeyGen

−1

(I

m
6: Calculate C1,m+1 = g (Im −IP ub ) , C2,m+1 = TP ub

−SP ub )

.

Algorithm 6 Decrypt
1: Start from the public attribute AP ub ;
2: For each attribute An that the decrypter possesses, compute:

Zn,U IDdec · e(Xn,U IDdec , (C1,n )kn C3,n )
e(Yn , (C2,n )kn C3,n )

1: For each attribute Ai assigned to the node with U ID, the

authority passes U ID, Ii and Ti to the TTP;

= e(g, g)rU IDdec (In−1 ) ;

2: The TTP computes and sends back to the authority:
3: If e(g, g)

rU ID

(In−1 )

is one of the decrypter’s private keys,
then go to step 2 with attribute An−1 ; else go to step 4;
4: Calculate

Xi,U ID = g rU ID Tiri ,
Yi = g ri ,

dec

Sk = C/(e(C 0 , D)/e(g, g)rU IDdec (In−1 ) .

Zi,U ID = e(g, g)rU ID Ii .

If DecSk (C 00 ) == ROOT , Success; else, Failure.

where ri ∈ Zp is a random number;
3: The authority assigns Xi,U ID , Yi and Zi,U ID to the node

together with Ti , Ii and ki generated from Algorithm 3.

The Encrypt algorithm works like this: following the encryption sequence of each conjunctive clause, denote each
attribute from I1 to Im , where m is the number of attributes
in the clause. Choose a random value s ∈ Zp and set I0 = s.
Given such a clause, the encryption process on group session
key Sk is defined in Algorithm 5. A complete encryption
includes such a process for every clause but the overlapping
parts between clauses. For example, given a policy {A AND B
AND C} OR {A AND B AND D}, where A, B, C, and D are
four attributes, the simplified form is {A AND B} AND {C
OR D}. The encryptor calculates the ciphertext for {A AND
B AND C} first and then use the results for {A AND B} to
finish {A AND B AND D} = {A AND B} AND {D}.
The Decrypt algorithm works in the decryption sequence.
Note that the first attribute in decryption sequence is always
AP ub . The decryption process is defined in Algorithm 6.
When the Decrypt algorithm succeeds, Sk is the group
session key embedded in C.
B. Group Setup

distributes a group session key to the group members using
the established policy. In EA-ABE, only the eligible members
can correctly decrypt this key. Any session key updates can
be performed by sending updated session keys to the group
members according to the attribute policies.
The Group Founder authentication is incorporated in the
EA-ABE scheme. This is because in Encrypt algorithm, only
those who possesses the correct value of Tn , In and kn has
the ability to generate the correct ciphertext C1,n , C2,n and
C3,n . Since Tn , In and kn are exclusively shared as a secret
among the nodes who are assigned with attribute An , only
these nodes are able to generate the ciphertexts correctly.
C. Attribute Key Update
In addition to group key management, it is necessary to
incorporate an attribute key update function in case a new
node is assigned with an attribute after the network setup
or a node is deprived of an attribute. The authority runs the
KeyUpdate algorithm, which is defined in Algorithm 7, to
conduct attribute key update.
Algorithm 7 KeyUpdate

With the above scheme, any node that wants to set up a communication group can construct a group attribute policy. This
is straightforward since there is no need for any knowledge
about other group members’ keys. It specifies the attribute
policy that the group members need to satisfy. Then this node

864

1: For attribute Ai , choose two random values Ii0 , ∆ki ∈ Zp ;
2: Encrypt Ii0 and ∆ki for each eligible node U ID that owns

attribute Ai using the node’s U ID as the policy;

0

0
Ii /Ii
3: Each node updates its keys as Zi,U
, k0i =
ID = (Zi,U ID )

ki + ∆ki .

Globecom 2013 - Communication and Information System Security Symposium
5

Table III
C OMPARISON OF COMPUTATION COST IN DECRYPTION

V. A NALYSIS AND E VALUATION
In this section, we analyze EA-ABE from two perspectives:
performance and security (including privacy). For performance
issue, we calculate the computation and communication overhead. We compare the results with the previous schemes. For
security issue, we evaluate the security strength of EA-ABE
based on the attack model in Section III-B.
A. Performance Analysis
For performance, we compare the computation and communication overhead of EA-ABE with CP-ABE [4], CN
scheme [9], NYO scheme (the 2nd construction in [7]), YRL
scheme [2] and GIE scheme [8]. We focus on the cost of
decryption process because encryption is performed once by
the Group Founder while decryption is performed by every
node receiving the group session key message. We compare the
number of time-consuming operations needed in each scheme.
Our experiment is conducted on a Dell D630 machine (Intel
T8100 processor 2.10GHz, 1GB memory) with Ubuntu 10.04.
We choose a prime number with a scale of 154 to set up a
Type A pairing using PBC Library [10]. According to our
experiment, pairing is the most time-consuming operation (In
Table II, the results are the average values of 50 runs.). Thus,
we calculate the number of pairing operations in decryption.

Scheme
CP-ABE
CN
NYO
YRL
GIE
EA-ABE

Anonymity Support
No
No
Yes
Yes
Yes
Yes

Number of Pairings
2Npath + 1 or 0
Npath + 1 or 0
2Nall + 1
2Nattr + 2
3Npath or 3Npart
2Npath + 1 or 2Npart

Table IV
C OMPARISON OF CIPHERTEXT SIZE

Scheme
CP-ABE
CN
NYO
YRL
GIE
EA-ABE

Ciphertext Size
1G1 + (2Nciph + 1)G0
1G1 + (Nall + 1)G0
> 1G1 + (2Nall + 1)G0
1G1 + (3Nall + 2)G0
Nciph G1 + 3Nciph G0
1G1 + (2Nciph + 4)G0 + Nciph Zp

a ciphertext is 1G1 + (2Nciph + 4)G0 + Nciph Zp . This means
the ciphertext consists of 1 element from G1 , 2Nciph + 4
elements from G0 and Nciph elements from Zp . Detailed
results are shown in Table IV. Here, the size of attribute
Table II
policy in CP-ABE and CN is not considered. Among the four
T IME - CONSUMPTION FOR OPERATIONS ( IN MILLISECONDS )
schemes supporting anonymity, the ciphertext size in NYO
Operation Pairing Exponentiation Multiplication Inversion and YRL is much larger than in GIE and EA-ABE. This is
because these two schemes encrypt the ciphertext for all the
Time
4.574
0.088
0.016
0.038
Suppose the number of attributes a decrypter has is Nattr . attributes in the network. GIE and EA-ABE are of the same
In YRL, it represents the number of lower level attributes. order of magnitude, but EA-ABE performs better.
The total number of attributes defined in the network is Nall .
B. Security Analysis
In CP-ABE and CN, the decrypter can choose the attributes
We analyze the security performance of EA-ABE based
used in decryption since the policy is not encrypted in these
on
the attack model in Section III-B. In the following, we
schemes. Therefore, if the decrypter satisfies the policy, the
illustrate
that the security strength of EA-ABE is no weaker
computation cost is related to the number of attributes along
than
CP-ABE.
In addition, we analyze the effectiveness of
the decryption path of the policy tree, which is denoted as
EA-ABE
against
collusion attacks. Furthermore, an attacker
Npath , Npath 6 Nattr . If the decrypter doesn’t satisfy the
cannot
confirm
an
attribute during the decryption process if
policy, the costs for both schemes are 0. This is the case
he
does
not
own
the
attribute. Finally, EA-ABE is able to
when the decrypter realizes his attributes cannot satisfy the
guarantee
forward
and
backward secrecies.
policy and thus discards the ciphertext. In GIE and EATheorem
1:
The
cryptographic
strength of EA-ABE is as
ABE, a decrypter cannot continue with the decryption process
good
as
that
of
the
CP-ABE
scheme.
if he doesn’t have the next attribute to decrypt. When this
Proof Sketch: We need to prove that the differences in
happens, we denote that the decrypter has already decrypted
Npart attributes, Npart 6 Npath . Due to the limitation that ciphertext components between EA-ABE and CP-ABE do not
some schemes only support AND-gates, our comparison is reduce the security of EA-ABE. There are two differences
conducted for the cases when a policy is constructed with between EA-ABE and CP-ABE. The first one is the choice
attributes and AND-gates only. Detailed results are shown in of exponents in C1,n and C2,n for each attribute An . In CPTable III. Among the four schemes supporting anonymity, ABE, the exponent, qy (0), is equal to the y-axis coordinate
GIE and EA-ABE outperforms NYO and YRL. Also, the of a random point on a polynomial. In EA-ABE, this value is
computation cost of EA-ABE is around 2 thirds of GIE’s cost. (In−1 − In )tn which is the difference between the current atTo evaluate communication cost, we compare the size tribute secret In and its parent attribute secret In−1 multiplied
of ciphertexts for every scheme. We denote the number of by a random value tn . Both exponents in EA-ABE and CPattributes used in ciphertexts as Nciph . For each attribute in ABE are randomized so that an attacker cannot gain any useful
the policy, the corresponding ciphertext consists of 2 elements information from the distribution of ciphertexts. If an attacker
from G0 and 1 element from Zp in EA-ABE. The total size of can deduce the values of (In−1 −In )tn , 1 6 n 6 m+1, using

865

Globecom 2013 - Communication and Information System Security Symposium
6

a certain method, he still cannot get the value of (In−1 − In )
nor s since he doesn’t know tn . However, this same method,
if it exists, can be applied to deducing the exponent in CPABE, which leads to the leak of s using Lagrange polynomial
interpolation.
The other difference is that there is an additional ciphertext
C3,n for each attribute in EA-ABE. If an attacker can retrieve
the random value tn , he can get the values g (In−1 −In ) ,
(I
−I )
Tn n−1 n and kn . But he cannot find anything useful if he
doesn’t possess Tn and In associated with the attribute An . 
Theorem 2: EA-ABE is secure against collusion attacks.
Proof Sketch: EA-ABE guarantees the uniqueness of intermediate decryption results for each node. That is in NodeJoin
algorithm, the random value rU ID chosen for each node is
different and unique. If attackers combine their keys together
to decrypt the same policy, the intermediate results they can
get are in the form of e(g, g)rU ID In , which are different
between individual nodes. Furthermore, the difficulty for an
attacker (U ID) to convert his intermediate result to the result
of another node (U ID0 ) equals to the difficulty to get the value
rU ID0 /rU ID which is only known to the TTP. Thus, attackers
cannot correctly recover either the intermediate results or the
secret message Sk from collusion attacks. 
In GIE, when an attacker successfully decrypts the ciphertext corresponding to one attribute, he knows what the next
attribute is. Attackers can use such knowledge to deduce more
information about the targets. In EA-ABE, the attacker cannot
tell what the next attribute is if he does not own it.
Theorem 3: An attacker cannot confirm attributes other than
his own in decryption process.
Proof Sketch: The decryption process in EA-ABE is conducted attribute by attribute. A decrypter can confirm his
ownership of the next attribute in the decryption sequence if he
can decrypt the current one. But he cannot gain any knowledge
about the next attribute if he does not own it. In fact, when
an attacker decrypts along the decryption path to an attribute
An , he is able to get the value e(g, g)rU IDdec (In−1 ) . He can
also get e(g, g)rU IDdec from Zn,U ID and In . However, due to
the difficulty of DLP, he cannot deduce In−1 . 
Theorem 4: EA-ABE guarantees forward and backward
secrecies.
Proof Sketch: To maintain forward and backward secrecies
for each group, the group session key needs to be updated
by encrypting and distributing the new key using EA-ABE.
In addition to group secrecy, it is necessary to guarantee the
forward and backward secrecies for each attribute key. If a
node is assigned with an attribute An after the network setup,
it is assigned with the updated key corresponding to An , i.e.
0
0
In
/In
Zn,U
, k 0n = kn + ∆k n . The node cannot
ID = (Zn,U ID )
decrypt previous communications using An with its current
key. This is because all the elements in its key are updated
to new values except for Tn . Not knowing In , the attacker
cannot conduct any attacks as discussed in Theorem 1. This
security guarantee is also applicable to forward secrecy. But
for forward secrecy, the updated keys are distributed with
EA-ABE to all the nodes except for those whose attribute is

revocated. 
VI. C ONCLUSION
In this paper, we propose the EA-ABE scheme for secure
communication groups. In EA-ABE, there is no need for
any prior knowledge of other group members beforehand.
The group formation policies are preserved in a gradual
exposure way which greatly reduces the computation and
communication overhead compared to existing hidden-policy
solutions. Moreover, EA-ABE is designed in a public-key pattern, making the group establishment more flexible. Forward
and backward secrecies are achieved using a key update mechanism. Experiments and analysis confirm its effectiveness.
ACKNOWLEDGMENT
This research is sponsored by ONR YIP Award N0001410-1-0714 and ARO Research Grant W911NF-11-1-0191.
R EFERENCES
[1] D. Huang and D. Medhi, “A key-chain-based keying
scheme for many-to-many secure group communication,”
ACM Transactions on Information and System Security
(TISSEC), vol. 7, no. 4, pp. 523–552, 2004.
[2] S. Yu, K. Ren, and W. Lou, “Attribute-based on-demand
multicast group setup with membership anonymity,” in
Proceedings of the 4th international conference on Security and privacy in communication netowrks, 2008, pp.
18:1–18:6.
[3] S. Rafaeli and D. Hutchison, “A survey of key management for secure group communication,” ACM Comput.
Surv., vol. 35, pp. 309–329, 2003.
[4] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertextpolicy attribute-based encryption,” in Proceedings of the
2007 IEEE Symposium on Security and Privacy, 2007,
pp. 321–334.
[5] M. Chuah, S. Roy, and I. Stoev, “Secure descriptive
message dissemination in dtns,” in Proceedings of the
Second International Workshop on Mobile Opportunistic
Networking, 2010, pp. 79–85.
[6] S. Müller, S. Katzenbeisser, and C. Eckert, “Distributed
attribute-based encryption,” in International Conference
on Information Security and Cryptology, 2008, pp. 20–
36.
[7] T. Nishide, K. Yoneyama, and K. Ohta, “Attribute-based
encryption with partially hidden encryptor-specified access structures,” in Proceedings of the 6th international
conference on Applied cryptography and network security, 2008, pp. 111–129.
[8] D. Huang, Z. Zhou, and Z. Yan, “Gradual identity exposure using attribute-based encryption,” in International
Conference on Social Computing, 2010, pp. 881 –888.
[9] L. Cheung and C. Newport, “Provably secure ciphertext
policy abe,” in Proceedings of the 14th ACM conference
on Computer and communications security, 2007, pp.
456–465.
[10] B. Lynn, “Pbc library,” in http://crypto.stanford.edu/pbc/,
Accessed March 2013.

866

2

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 13,

NO. 1,

JANUARY/FEBRUARY 2016

Guest Editors’ Introduction: Special Issue
on Reliable and Secure VANETs
Alexey Vinel, Xiaomin Ma, and Dijiang Huang

Ç

V

ad-hoc networks (VANETs) has gained a significant attention during the last decades both from
industrial and academia communities. Novel VANETenabled active safety automotive applications are heavily
dependent on reliability and security of underlying intervehicle communication protocols. The error-prone nature of
the wireless channel and its openness to external invasions
as well as dynamic VANET environment, impose the need
for intensive studies before applications like platooning or
collision avoidance can become a part of our daily life. The
aim of this Special Issue is to encompass research advances
in all areas of reliability and security in VANETs. The 11
papers comprising this Special Issue provide contributions
related to the novel protocols for reliable and secure vehicle-to-vehicle and vehicle-to-infrastructure communication
as well as methods for their performance evaluation.
Cooperative driving applications are based on an underlying vehicular-WiFi extension (i.e., ITS-G5/DSRC) known
for its unreliability and unbounded delay. Few contributions discuss the protocol design in VANETs to meet the
Quality-of-Service (QoS) requirements:




EHICULAR

The paper “V2V QoS Guaranteed Channel Access in
IEEE 802.11p VANETs” by Chang et al. proposes a
distributed and priority enforced channel access
scheme, called EDF-CSMA, to provide guaranteed
QoS for real-time streaming in multi-channel
VANET environments. It is shown that EDF-CSMA
has higher channel utilization than other well-known
mechanisms.
Starting from the observation - confirmed during
experiments - that ITS-G5/DSRC packet losses are
correlated in time and space, the paper “Random
Transmit Power Control for DSRC and its Application to
Cooperative Safety” by Kloiber et al. proposes an innovative solution for congestion/awareness control by
using a randomized transmit power strategy opposed
to current fixed power strategies. Already successfully used in different domains, this unconventional

approach shows several benefits, such as packet loss
decorrelations, channel load reduction, and even support for ultra-high transmit updates (> 10 Hz) at a 60
percent operational channel load.
 In “Secure and Robust Multi-Constrained QoS aware
Routing Algorithm for VANETs” by Eiza et al. the ant
colony optimization technique to compute the best
feasible routes in VANETs subject to multiple QoS
constraints determined by the data traffic type is
suggested. The authors apply the VANET-oriented
evolving graph model to perform plausibility checks
on the exchanged routing control messages among
vehicles.
 The paper “Securing Vehicular IPv6 Communications”
by Fernandez et al. investigates the security design
in VANETs and the proposal of integrating state-ofthe-art IPv6 technologies to create a secure vehicular
mobile network. The implementation and experimental evaluation of the proposal in a vertical handover scenario between 3G and IEEE 802.11p are
carried out.
 Huang et al. focuses on channel spectrum availability sensing for cognitive radio enabled VANETs in
the paper entitled “Historical Spectrum Sensing Data
Mining for Cognitive Radio Enabled Vehicular Ad-hoc
Networks”. A new scheme is proposed for channel
availability prediction using historical spectrum
sensing data mining, Bayesian inference, and a nonparametric hidden Markov chain model. The cognitive radio enabled VANET with the new proposed
spectrum sensing can improve the application-level
QoS for safety services.
The use of traditional symmetric cryptography in
VANETs is discussed in the following papers:




A. Vinel is with the School of Information Technology, Halmstad University, Spetsvinkelgatan 29, SE-302 50, Halmstad, Sweden.
E-mail: alexey.vinel@hh.se.
 X. Ma is with the Department of Engineering, Oral Roberts University,
7777 South Lewis Avenue Tulsa, OK 74171, USA. E-mail: xma@oru.edu.
 D. Huang is with the School of Computing Informatics, Decision Systems
Engineering, Ira Fulton School of Engineering, Arizona State University,
699 S. Mill Ave., Tempe, AZ 85287-8809, USA.
E-mail: dijiang.huang@asu.edu.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identifier below.
Digital Object Identifier no. 10.1109/TDSC.2015.2505361



“PBA: Prediction-based Authentication for Vehicle-toVehicle Communications” by Lyu et al. discusses
broadcast authentication issue for secure one-hop
vehicle-to-vehicle communications. A new broadcast
authentication scheme – Prediction-based Authentication – built on symmetric cryptography, is
designed to defend against computation-based
denial-of-service attacks and resist packet losses
caused by high mobility of vehicles. The authors analyze the security of the proposed scheme under varying vehicular network scenarios.
Li et al. devote their paper “Impossible Differential
Fault Analysis on the LED Lightweight Cryptosystem in
the Vehicular Ad-hoc Networks” to the security analysis
of LED lightweight cryptosystem in VANETs against

1545-5971 ß 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

VOL. 13,

the impossible differential fault analysis (IDFA)
attack with a half byte-oriented fault model. The
analysis allows breaking the 64-bit and 128-bit secret
key of LED by only 48 and 96 faults in average,
respectively. The result proves that LED is vulnerable to a half byte IDFA.
In VANETs all the vehicles broadcast messages about
their current location, speed and direction. Even though
this enables safety applications, it also raises privacy concerns. Pseudonyms management is considered in two
papers:


Zhang et al. present “MixGroup: Accumulative Pseudonym Exchanging for Location Privacy Preservation in
Vehicular Social Networks”, where a novel privacypreserving scheme, called MixGroup, which is able
to efficiently exploit the sparse meeting opportunities for pseudonym changing based on real-traces
observations, is proposed. By integrating the
group signature mechanism, MixGroup constructs
extended pseudonym-changing regions. Then,
vehicles are allowed to successively exchange their
pseudonyms. Results indicate that MixGroup significantly outperforms the existing schemes in both high
traffic and low traffic conditions.
 “A pseudonym management system to achieve anonymity
in vehicular Ad hoc networks” by Artail and Abbani
introduces a system for pseudonym generation, distribution, and replenishing to provide anonymity to
communicating cars in the VANET. The roadside
units play a key role not only by distributing pseudonym sets to cars, but also by shuffling the sets
amongst themselves to maximize anonymity. The
distribution of pseudonym to the roadside units and
to the vehicles is highly adaptive to accommodate
the needs of the vehicles. A distributed optimization
algorithm is developed to manage the shuffling process, and a novel mechanism was devised for cars to
change their pseudonyms.
Finally, some specific VANET applications are studied
from the security perspective:


The paper “Trustworthy Parking Communities: Helping
Your Neighbor to Find a Space” by Timpner et al.
tackles the challenge of securely exchanging parking
spot availability information with neighbors. The
high-performance state-of-the-art encryption and
signature algorithms as well as a mathematical trust
rating model are used to set up Parking Communities for providing a novel trust management for
vehicular parking applications without reliance on a
central Trusted Third Party for retrieving trust ratings. This approach allows end-to-end encrypted
request-response communications in combination
with geocast and can be used as an overlay to existing vehicular networking technologies. Attack scenarios on Parking Communities and their
mitigations are analyzed. A comprehensive comparison with existing key and trust management
schemes for vehicular networks are provided to verify feasibility of the proposed concept.

NO. 1,



JANUARY/FEBRUARY 2016

3

Vehicles-to-grid (V2G) is recognized to be one of the
most emerging technologies, which can be used for
making an energy balance between producers and
consumers. To provide secure negotiation between
these two parties, Lee et al. in the article entitled
“Bayesian Coalition Negotiation Game as a Utility for
Secure Energy Management in a Vehicles-to-Grid Environment” propose a novel Bayesian coalition game based
technique in V2G environment. Keeping in mind the
modern demands for an optimal energy consumption,
the authors assume vehicles as the player of the game,
which perform finite number of actions with respect to
the energy flow between consumers and producers.
The efficacy of the proposed scheme is evaluated by
selecting various performance evaluation parameters
where its performance was found satisfactory with
respect to the selected parameters.
A. Vinel
X. Ma
D. Huang
Guest Editors

Alexey Vinel received the bachelor’s (hons.) and
master’s (hons.) degrees in information systems
from the Saint-Petersburg State University of
Aerospace Instrumentation, Saint Petersburg,
Russia, in 2003 and 2005, respectively, and the
PhD degrees in technology from the Institute
for Information Transmission Problems, Moscow, Russia, in 2007, and the Tampere University of Technology, Tampere, Finland, in 2013.
He is a full professor of data communications
in the School of Information Technology (ITE),
Halmstad University, Halmstad, Sweden. He has been involved in
research projects on vehicular networking standards, advanced driver
assistance systems, and autonomous driving. He has been an associate editor of the IEEE Communications Letters since 2012 and the
IEEE Wireless Communications Magazine since 2015. He is a senior
member of the IEEE.

4

IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING,

Xiaomin Ma received the MS degree in communication and electronic system, the Beijing University of Aerospace and Aeronautics, Beijing,
China, and the PhD degree in information
engineering at the Beijing University of Posts &
Telecommunications. He was a postdoctoral
fellow in the Department of Electrical and Computer Engineering at Duke University, North Carolina. He is a full professor in the Department of
Engineering at Oral Roberts University. His
research interests include stochastic modeling
and analysis of computer and communication systems, physical layer
and MAC layer of vehicular ad hoc wireless networks, computational
intelligence and its applications to coding, signal processing, and control,
and Quality of service (QoS) and call admission control protocols in wireless networks. He has published more than 100 papers in peer-reviewed
journals and conferences. He also holds a US patent. He received
the Best Paper Award in IEEE International Conference on Network
Infrastructure and Digital Content. He gave several invited lectures and
tutorials in US and foreign universities as well as on international conferences. He is in the editorial board of International Journal of Vehicular
Technology, Hindawi Publish House. Also, he has been serving as a
guest editor of Special Issues in several international journals such as
ACM/Springer Mobile Networks & Applications (MONET), and IEEE
Transactions on Dependable and Secure Computing, etc. He is (or was)
PI, Co-PI or a project leader in several projects sponsored by US
National Science Foundation (NSF), NSF EPSCoR, Motorola, Chinese
NSF, AFOSR, and ARO, etc. He is a senior member of the IEEE.

VOL. 13,

NO. 1,

JANUARY/FEBRUARY 2016

Dijiang Huang received the bachelor of science
degree in telecommunications from the Beijing
University of Posts & Telecommunications in
1995, and the master of science and PhD
degrees from the University of Missouri-Kansas
City in 2001 and 2004, respectively, both majored
in computer science and telecommunications. He
joined ASU in 2005 in the Department of Computer Science and Engineering as an assistant
professor. From 2011, he has been an associate
professor in the School of Computing Informatics
and Decision Systems Engineering. His current research interests are in
computer and network security, mobile ad hoc networks, network virtualization, and mobile cloud computing. He is an associate editor of the
Journal of Network and System Management (JNSM) and an editor of
the IEEE Communications Surveys & Tutorials. He has served as an
organizer for many International conferences and workshops. His
research is supported by federal agencies US National Science Foundation (NSF), ONR, NRL, ARO, and NATO, and organizations such as
Consortium of Embedded System (CES), Hewlett-Packard, and China
Mobile. He received the ONR Young Investigator Program (YIP) Award
2010, HP Innovation Research Program (IRP) award 2011 and 2012,
and JSPS Fellowship 2013. He is a cofounder of Athena Network Solutions LLC (ATHENETS). He is currently leading the Secure Networking
and Computing (SNAC) research group at ASU. He is a senior member
of the IEEE.
" For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

IEEE International Conference on Social Computing / IEEE International Conference on Privacy, Security, Risk and Trust

Gradual Identity Exposure Using Attribute-Based Encryption
Dijiang Huang∗ , Zhibin Zhou

Zhu Yan

School of Computing Informatics and Decision Systems Engineering
Arizona State University
Tempe, USA
Email: {dijiang,Zhibin}@asu.edu

Computer Science
Peking University
Beijing, P.R. China
Email: yan.zhu@pku.edu.cn

Abstract—Many Attribute-Based Encryption (ABE) schemes
do not protect receivers’ privacy, such that all the attributes
to describe the eligible receivers are transmitted in plaintexts.
Hidden policy-based ABE schemes have been proposed to protect
receivers’ privacy by using a construction that requires every
user in the system to decrypt the ciphertext using all the
attributes they possess, which incurs great computation and
communication overhead. To address this issue, in this paper,
we propose a new concept – Gradual Identity Exposure (GIE) –
to protect data receivers’ identity. Our approach is to reveal the
receivers’ information gradually by allowing ciphertext recipients
for decrypting the message using their possessed attributes oneby-one (but not all). If the receiver does not possess one attribute
in this procedure, the rest of attributes are still hidden. Compared to hidden-policy based solutions, GIE provides significant
performance improvement in terms of reducing both computation
and communication overhead. We also present a theoretical
framework to model the GIE with several new proposed concepts.
Index Terms—Identity, Privacy.

I. I NTRODUCTION
The introduction of Identity Based Encryption (IBE)
schemes [3] significantly enriched the identity management
research by combining identity management with key management and encryption/decryption procedures. In IBE, the
identity is not only the identifiable information, e.g. email
address, ID number, etc., but also the public key of the identity
carrier. IBE allows a sender to encrypt a message with the
receiver’s identity as the public key. Recently, Attribute Based
Encryption (ABE) [1] scheme extended the basic construction
of IBE. In ABE, the identity is extended to a set of descriptive
attributes that define, classify or annotate the user to which
they are assigned. The encryptor can enforce an access policy,
defined as a set of attributes, with encryption. Only those
receivers whose attributes satisfy the access policy can decrypt
the ciphertext.
The original ABE schemes does not consider the anonymity
of data recipients. The data access policy is attached to the
ciphertext in plaintext form. Thus, passive attackers can locate
and track a user or infer the sensitivity of ciphertext by
eavesdropping the user’s identity in the networks. For example,
the access policy {”ComputerScience”, ”DepartmentChair”}
AND { ”ComputerScience”, ”Student”} implies the recipient’s roles or positions.

Hidden policy [11], [10], [16] schemes have been proposed
to protect the ciphertext recipients’ privacy. In the hidden
policy solutions, the data access policy is not attached with
the ciphertext. Here, we consider the set of attributes as
policies enforced for data access control using ABE schemes.
Since policies also describe who are eligible data receivers
(i.e., who can decrypt the ciphertexts), they can be used
as an identity to represent a group or one user. Although
hidden policy schemes ensure the perfect anonymity, they
incur significant computation overhead for each user in the
system. For example, in [11], the access policies must be predefined to avoid ambiguity. An access policy must contain
all attributes predefined in the entire system. As a result, the
number of attributes may proliferate into thousands in a large
system even though many of the attributes were not actually
used to encrypt the data, and thus the encryption/decryption
process can be very expensive. Another critical drawback of
hidden policy approaches is that each receiver is required to
“try” to decrypting all the ciphertexts they received. Only after
the receivers finished the decryption process, can they know
whether they satisfy the associated policies.
To address the above identified drawbacks, we develop
a new identity management scheme to protect recipients’
anonymity and reduce incurred computation complexity. We
present a new concept – Gradual Identity Exposure (GIE) –
for identity management. GIE has the following capabilities:
•

•

∗ The presented work is supported by US NSF grant CNS-1029546 and
ONR-YIP award.

978-0-7695-4211-9/10 $26.00 © 2010 IEEE
DOI 10.1109/SocialCom.2010.131

881

The user’s identity is exposed gradually based on receivers’ authorized capabilities. At each step, the decrypter needs to satisfy certain attributes to expose next
step attributes. Otherwise, decryption fails immediately
and the decrypter learns nothing more than the attributes
he/she is entitled. This is fundamentally different to the
rigid concept of using hidden policy: “Try to decrypt
the entire ciphertext, if it is decrypted, the policy will
be revealed; if it cannot be decrypted, no policy will be
revealed”.
GIE is flexible in that it does not require a pre-established
policy agreement. Each user can specify a GIE scheduler,
i.e., a procedure to expose an identity gradually, based on
his/her security requirements without negotiating with the
message receivers. This property makes the identity management adaptable in various un-predictable application
scenarios.

Although GIE does need to expose some attributes information to the receivers at beginning. We find that this property
is quite useful in some environments, such as Enterprize
networks, since receivers can learn some information they
are authorized to know. For example, in a large company’s
intra-networks, messages are encrypted and broadcasted to all
departments. Each department has a server to backup messages
targeted to its department, and this backup server only has the
attributes assigned to department, e.g. ”R&D”. One sensitive
message may be encrypted by policy {”R&D”, ”StaffEngineer”, ”Female”} in sequence, where attribute ”R&D” is
revealed first. Although the server cannot learn all attributes
in the policy, it can identify attribute ”R&D” and backup the
message.
Based on the GIE model, we further propose a new concept:
Optimal Identity Exposure (OIE), which requires the identity
exposure procedure to reveal the minimal amount of information when a receiver fails the decryption process. Based on our
investigations, we found that the OIE cannot be guaranteed
for an arbitrarily selected composition attributes. However,
we prove that if OIE exists in a given set of attributes,
we can always find the optimality by using a deterministic
polynomial searching algorithm. To handle the scenarios that
OIE does not exist, we propose two algorithms: Pre-k-optimal
Identity Exposure and Post-k-Optimal Identity Exposure to
reveal an identity at the k far-end and close-end optimal steps,
respectively, in the identity exposure procedure. Intuitively, the
Pre-k-optimal ensures the maximal anonymity in beginning
steps, while Post-k-optimal ensures in ending steps.
The construction of GIE is based on Ciphertext-Policy
Attribute-Based Encryption (CP-ABE) [1] by disclosing attributes and corresponding tree structure gradually in the process of decryption. In this way, attackers can only learn partial
information of receivers’ identities, since they will stop at a
certain step during the decryption procedure. Our presented
techniques do not increase the complexity of encrypting and
decrypting messages with the original CP-ABE scheme. GIE
also inherits the security features, such as collusion resistance,
provided by the CP-ABE scheme presented in [1].
In summary, the contributions of GIE are in three-fold:
(i) We present a new identity management concept by gradually exposing users’ information to protect users’ privacy. This
approach is flexible, and it does not need pre-establishment of
secrets or agreements between communication peers.
(ii) We present a new construction for ABE scheme to
achieve the gradual identity exposure. Our solution inherits
all security properties of original CP-ABE. Moreover, the new
solutions hide the attribute tree through gradual identity exposure procedures, which is robust to counter colluding attackers
sharing information to derive the hidden identity. Furthermore,
with the added new privacy-preservation features, our solution
is efficient in that: it does not increase the computation
overhead compared to the original CP-ABE solution; and it
does not introduce heavy communication overhead compared
to existing attributes anonymizing solutions.
(iii) We present a new anonymity measurement model based

on set theory to capture the gradual uncertainty reduction
of the proposed solution. Based on the proposed anonymity
measurement model, we can evaluate several newly introduced
concepts such as Optimal Identity Exposure, Pre-k-optimal
Identity Exposure, and Post-k-Optimal Identity Exposure.
Rest of this paper is arranged as follows: related work is
presented in Section II; in Section III, the system and models
required to build gradual identity exposure are presented;
the detailed system construction is presented in Section IV;
anonymity measurement model of our solutions is presented
in Section V; In Section VI the security analysis of GIE
encryption scheme and performance evaluations are presented;
finally, we conclude our research and present several on-going
research challenges in Section VII.
II. R ELATED W ORKS AND BACKGROUND
The first fully functional IBE was proposed in [3] . In
Identity based encryption (IBE), an identity or ID is a string
one-to-one mapped to each user. A user can acquire a private
key corresponding to his ID in an off-line manner from trusted
authority and the ID is used as his public key. The ciphertext
encrypted by a particular ID can only be decrypted by the
user with corresponding private key, i.e. the encryption is
one-to-one. Attribute based encryption is a novel extension
from Identity based encryption by enabling expressive access
policy to control the decryption process as presented in [1],
[14], [13], [5], [8], [6], [12], [10]. Particularly, BSW CP-ABE
scheme [1] uses an access policy to encrypt the message. The
ciphertext can be successfully decrypted only if the decrypter’s
set of attributes matches the access policy. The computation
and communication overhead of BSW scheme is linearly depending on the number of attributes in the ciphertext. Authors
in [6] proposed a provable secure CP-ABE scheme, namely
CN CP-ABE. In CN CP-ABE, all the attributes need to be predefined and the computation and communication overheads
linearly depend on the number of attributes pre-defined by the
system. However, both BSW and CN schemes do not consider
hiding the access policy, and thus the access policy is public
known to all receivers.
Privacy Enhancing Identity Management System (PE-IMS)
was discussed by Hansen et al. in [9]. To support PE-IMS,
the anonymous IBE schemes [2], [4], [7] preserve recipient
anonymity by hiding the identity in the ciphertext. To protect
the privacy of access policy, KSW scheme [10] and NYO
scheme [11] was proposed, where the encryptor specified access policy is hidden. Also, YRL scheme was proposed in [16]
based on BSW scheme as a group key management scheme
providing group membership anonymity. This main difference
between our scheme and existing hidden policy policy attribute
based encryption scheme is those schemes require all receivers
to ”try” decrypting all ciphertexts they received. Only after the
receiver finished the decryption process can he know whether
he is allowed to decrypt. Thus, these schemes pose a huge
computational burden on all receivers. On the other hand, with
the property of gradual exposing of attributes, receivers can
882

detect ciphertexts that are not intended for them earlier to save
computational power.
A. Cryptographic Background
We describe the basis of the bilinear group system and secret
sharing scheme in this subsection. The basic construction of
CP-ABE scheme is presented in Appendix.
Bilinear Pairing: Let G0 and G1 are an additive group and
a multiplicative group, respectively, with large prime order p.
It is well-known that Discrete Logarithm (DL) problem is hard
on both G0 and G1 . Let pairing e be an efficiently computable
bilinear map e : G0 × G0 → G1 has the following properties:
Bilinearity: e(aP, bQ) = e(P, Q)ab , ∀P, Q ∈ G0 , ∀a, b ∈
Zp .
Nondegeneracy: e(g, g) ̸= 1 where g is the generator of G0 .
Computability: There exist an efficient algorithm to compute
the pairing.
Secret Sharing: (t, n)-secret sharing is used to divide a
secret into n shares and any t shares can reconstruct the
secret, while combining less than t shares will not disclose
any information about the secret. As introduced by Shamir
et al. in [15], in a t − 1 degree polynomial, any t points
on the polynomial can be used to reconstruct the secret, i.e.
the polynomial. We define the Lagrange coefficients ∆i,S for
i ∈ Zp and a set S, of elements in Zp :
∏ x−j
∆i,S (x) =
(mod p).
i−j

Usually, one attribute yi can create a certain level of
anonymity, which is determined by the cardinality of its set
S yi .
Definition 3 (Gradual Identity Exposure): The attributes
describing an identity are gradually exposed in a one-by-one
fashion and the anonymity is monotonically decreasing. In
other words, at any particular step, exposing attribute yj
will not increase the anonymity. We can have the following
formula:
∇{...yj−1 } ≥ ∇{...,yj−1 ,yj } ,

(1)


For example, if we have the following four attributes
y1 ={ASU employee}, y2 ={faculty at ASU}, y3 ={female
faculty at computer science at ASU}, and y4 ={faculty teaching database at ASU}. In this example, we have |∇{y1 } | ≥
|∇{y1 ,y2 } | ≥ |∇{y1 ,y2 ,y3 } | ≥ |∇{y1 ,y2 ,y3 ,y4 } |.
Definition 4 (Optimal Identity Exposure): For a given set
of l attributes {y1 , . . . , yl }, there are l! possible exposure
procedures. For a given procedure number j, we denote the
anonymity at step i as ∇ji , i.e. the anonymity after exposing
i’th attributes in the procedure. If the optimal identity exposure
procedure exists, it must satisfy the following properties:
1) The sequence of exposed attributes set must satisfy (1).
2) For any step i, The anonymity ∇∗i is always maximized:
∇∗i = max{∇1i , . . . , ∇l!i }

(j∈S,j̸=i)

III. S YSTEM AND M ODELS
In this section, we present the system and models which are
required to construct the proposed solution. We first present the
definitions and new concepts of GIE. Then, the communication
model and attack model are presented in sequence at the end
of this section.

∀

0 ≤ i ≤ n.

(2)

3) The optimality may not exist. However, if the optimality
exists, there is a polynomial algorithm to find the optimal
identity exposure sequence.

Set Size
Starting Identity S1
Up
pe
rbo
un
d

S1-S2

A. Concepts
The GIE construction is based on set theory. We first
describe several notations shown in below:
• y is an attribute.
∗
l
• H is a one-way hash function H : {0, 1} → {0, 1} .
• Sy represents the set of users with attribute y. The
cardinality of this set is represented as |Sy |. The intersection
∩ of two attributes yi and yj is represented
as Syi Syj and∪the union of these two attributes is
presented
as Syi Syj . ϕ represents an empty set and
∪n
| i=1 Syi | = N .
Now, we are ready to present several definitions. Despite the
English definition of identity, i.e., a term uniquely pinpoints
to a person, we extend the definition of identity as follows:
Definition 1 (Identity): An identity I = {y1 , . . . , yn } is a
set of attributes (i.e., terms) that can be used to identify a user
or a group (or a set) of users. An attribute may not be unique
to distinguish a user or a group of users.

Definition 2 (Anonymity): We define ∇{y1 ,...,ym } as the
anonymity of a set of attributes
{y1 , . . . , ym }, which is mea∩
sured by the cardinality | ∀yi ∈{y1 ,...,ym } Syi |.

j ≥ 1.

where

Uncertainty
reduction

S1∩S2
Lo
we
rbo
un
d

y1

y2

...

yn
Exposed attributes

(a)
Sy1

Sy2
50

Ending
Identity
S1∩S2∩…∩Sn

15
65

|Sy1|=110
|Sy2|=100
|Sy3|=90

10
25

20

35 Sy3

(b)
Fig. 1.

Uncertainty reduction with gradual identity exposure.

Definition 4 describes a scenario that the overall system
uncertainty (or remaining system uncertainty) is always the

883

maximal after each uncertainty reduction step.
For example, in Fig. 1(a), after y1∩and y2 are exposed,
the ∩
overall system uncertainty is |S1 S2 |. The higher the
|S1 S2 | value, the larger the value of the overall system
anonymity. Thus, to achieve the best anonymity, we need to
keep the system uncertainty at its maximum when selecting
an attribute to expose.
Satisfying Definition 4 (property 2) guarantees that we can
always achieve the maximal overall system anonymity after
each step (except the last step, which can have maximal
anonymity reduction). Based on the property 2, we can draw
an upper-bound of the optimal identity exposure shown in Fig.
1(a). Additionally, we can also draw lower-bound in the figure
by restricting each step expose maximal information, which
makes overall system anonymity at its minimal level. We must
note that the upper bound and lower bound may not exist for
all cases.
Property 3 states that the optimal solution of identity exposure may not always exist. However, if the optimal solution
exists, we can always find a polynomial algorithm to derive
the optimality. To prove the optimal solution may not exist,
we can simply present an example. In Fig. 1(b), three sets Sy1 ,
Sy2 , Sy2 , and their intersections are presented. The number in
each area represents the size of corresponding set. There are
6 possible exposure sequences, which are listed in below:
No.
1
2
3
4
5
6

Exposure
Sequence
y1 → y2
y1 → y3
y2 → y1
y2 → y3
y3 → y1
y3 → y2

Anonymity
→
→
→
→
→
→

y3
y2
y3
y1
y2
y1

110 → 25 → 10
110 → 30 → 10
100 → 25 → 10
100 → 35 → 10
90 → 30 → 10
90 → 35 → 10

Optimal
at step 1
X
X

Optimal
at step 2

X
X

Optimal
at step 3
X
X
X
X
X
X

In this example, the best first step exposure is sequence 1
or 2, and the best second step exposure is sequence 4 and 6.
Thus, there is no optimal sequence exposure.
To prove that there exists a polynomial algorithm to derive
the optimal solution, we can simply design a greedy algorithm
by searching the minimal uncertainty reduction set at each step
from the starting identity or searching the maximal uncertainty
reduction set in the reversed order from the ending identity. In
step j, there are n − j set combinations to be evaluated, thus
the complexity is bounded by:
n + (n − 1) + (n − 2) + · · · + 1 = O(n2 ).
Since the optimal solution may not always exist, we proposed Pre-k-optimal Identity Exposure and Post-k-Optimal
Identity Exposure, where k is a variable depends on the set
compositions. For example, as shown in Fig. 1(b) and the
above table, there are pre-1-optimal arrangements, namely
y1 → y2 → y3 and y1 → y3 → y2 . There are post-2-optimal
arrangements, namely y2 → y3 → y1 and y3 → y2 → y1 .
B. Communication Model
In our presented system, we need to confine an administrative domain, in which all users must trust the domain manager
(i.e., trusted third party - TTP). Each user derives a set of

attributes and corresponding private keys from the TTP based
on the proposed solutions. TTP can be either online or offline
depending on the types of applications using GIE. When the
TTP is online, since it knows the exact number of users
registered for each attributes, TTP can provide an online query
service by accepting the requests from end users. The TTP
can generate a correct sequence to satisfy the optimal identity
exposure requirements. When users cannot reach the TTP, they
need to construct the attribute tree by themselves and arrange
the exposure sequence based on his/her own knowledge of
the size of each attribute. Users’ decisions may not accurately
reflect the size of involved attribute size, but it is very flexible,
and it can be applied in the scenario that the TTP is offline.
C. Attack Model
Attackers’ goal is to compromise the anonymity features
provided by GIE. Attackers can be either internal or external
users of a given administrative domain. In order to compromise
the proposed GIE scheme, attackers can collude to derive the
extra information that each of them alone cannot derive.
IV. C ONSTRUCTIONS OF G RADUAL I DENTITY E XPOSURE
In this section, we present the detailed cryptographic construction to enable gradual exposure of an identity. In Section
IV-A, we first consider how to convert a AND-gate access
policy to a AND-gate chain that allows the system to expose
attributes in a one-by-one fashion. Next, in Section IV-D, we
present how to encrypt a message using the AND gate chain
to allow a decrypter to discover the identity gradually in the
decryption process.

y1
y1

y2

y3

y2

y3

Fig. 2.

Converting an AND access policy tree to an AND gate chain.

A. Construction of AND Gate Chain
An identity is created by an attribute tree through an AND
gate, which requires the decrypter possesses private keys
for each attribute in the tree to reveal the whole identity.
Different attributes may have different anonymity levels, which
is determined by the set cardinality. In Fig. 2, we present a
conversion from a one-level AND-gate chain to a multiplelevel AND-gate chain. Attributes with low anonymity should
be hidden, unless a decrypter possesses all attributes having
a lower anonymity level. In other words, attributes in an
AND-logic-gate tree are exposed to decrypter gradually in the
process of decryption. Only if the decrypter has the attribute
and the corresponding private keys for current step, he/she can
learn the attributes required for next step. On the other hand,

884

if the decrypter does not have the attribute for current step,
the attribute for next step cannot be revealed.
Since an optimal solution may not always exist, we need
to produce an approximate solution to create an good enough
exposure sequence. To this end, we propose Post-k-optimal
and Pre-k-optimal searching algorithms. To construct the prek-optimal and post-k-optimal, where k is maximized, we
propose two greedy algorithms. The forward greedy algorithm
can find a pre-k-optimal sequence with some maximized k
steps where the anonymity is maximized, and a backward
greedy algorithm can find a post-k-optimal sequence with
some maximized k steps where the anonymity is maximized.
Note that, for the same set of attributes in the AND-gate
chain, the value of k found by pre-k-optimal algorithm may be
different from the k found by post-k-optimal algorithm. For
example, as shown in Fig. 1(b) and the above table, there
are pre-k-optimal arrangements, where kmax = 1, namely
y1 → y2 → y3 and y1 → y3 → y2 . There are post-k-optimal
arrangements, where kmax = 2, namely y2 → y3 → y1 and
y3 → y2 → y1 .
Algorithm 1 Pre-k-Optimal(T ).
Require: T is a structure of an AND gate connecting multiple
attributes, and T ′ is the computed exposure sequence, where
initially T ′ = Ø;
while |T ′ | ̸= |T | do
Find the largest |Sy ∩ ST ′ | where y ∈ T and y ̸∈ T ′ ;
Append y to the end of T ′ ;
end while
return T ′
Algorithm 2 Post-k-Optimal(T ).
Require: T is a structure of an AND gate connecting multiple
attributes, and T ′ is the computed exposure sequence, where
T′ = Ø
while |T | ̸= 0 do
Find the largest |ST \{y} | where y ∈ T ;
Remove y from T ;
Append y to beginning of T ′ ;
end while
return T ′

for encryption and decryption. The master key is the system
secret well guarded by the TTP.
• Bilinear map: G0 × G0 → G1 of prime order p with
generator g;
• Two random α, β ∈ Zp ;
β 1/β
, e(g, g)α >;
• Public key P K =< G0 , g, g , g
α
• Master key is < β, g >.
C. Key Generation
After the setup of system, each user need to be generate a
set of private key components corresponding to his identity,
i.e. the set of attributes. The key generation algorithm is same
to the BSW’s scheme in [1]. The key generation algorithm
will take as input a set of attributes S and output a key that
identifies with that set.
• The TTP first chooses a random r ∈ Zp ,
• Then TTP chooses random rj ∈ Zp for each attribute
yj ∈ S.
• Then TTP computes the key as:
SK = (D = g (α+r)/β ; ∀j ∈ S : Dj = g r ×H(yj )rj ; Dj′ = g rj ).
D. Encryption and Decryption of the AND Chain
We now describe how to encrypt a AND-gate chain such
that the attributes are exposed gradually. We modify the CPABE encrypt and decrypt primitive functions to achieve this
goal (the original CP-ABE scheme is presented in Appendix).
We assume that there is at least one attribute at each level of
the AND-gate chain except the root.
Intuitively, the encryption and decryption algorithms works
by using BSW scheme as subfunction. Each AND-gate act
as an subtree access policy to protect the attributes in the
same level. The exception is at the lowest level, while each
other level’s attribute is encrypted by the AND-gate subtree
in the same level. For example, in Figure 3, the attribute y2
is protected by the AND-gate subtree, so that only if the
decrypter possess attribute y1 , can he reveal y2 and proceed
decryption. Moreover, instead of using attribute strings, we
use hash values of attributes. A user can check whether the
hash value match one of his attributes. On the other hand, this
mechanism adds another level of protection since it is hard to
guess attributes from hash values.

It is easy to prove, that both forward greedy algorithm
and backward greedy algorithm can find the best sequence to
satisfy the overall system anonymity for maximized k steps.
y1

B. System Setup
In this section, we describe how the TTP sets up the system.
TTP first defines the following functions:
• parent(x): return the parent node of x;
• The access tree T also defines an ordering between the
children of every node, that is, the children of a node
are numbered from 1 to num. The function index(x)
returns such a number associated with the node x.
Then, the TTP generates the following parameters. Note
that the public key is a system-wise public parameter used

y1

y2

y3

Current
Decrypter

(a)

y2

y3

y1

Current
Decrypter

y2

Current
Decrypter

y3
(b)

(c)

Fig. 3. The process of decryption and attribute exposing. (a) Initially, all the
attributes are hidden; (b) y3 is exposed in the decryption process; (c) y2 is
exposed in the decryption process.

885

1) Encryption: The encryption algorithm encrypts a message M under the exposure schedule T = y1 → . . . →
yn . The encryption algorithm is performed in the top-down
manner. Starting with level-0 AND gate x0 , the encryption
algorithm chooses a random s ∈ Zp and randomly chooses a
1-degree polynomial qx0 with qx0 (0) = s. Then it calculates:
Cx0 = M e(g, g)αqx0 (0) ;

e(g, g)rqxn−1 (0) = e(g, g)rqyn (0) .
Once the decryption algorithm
e(g, g)rqxn−1 (0) , it calculates:

Cx′ 0 = g βqx0 (0) .

For the level-1 AND gate x1 , it randomly selects a degree1 polynomial qx1 with qx1 (0) = qparent(x1 ) (index(x1 )) =
qx0 (1). Then it calculates the hash value of level-1 attribute
y1 as h1 = H(y1 ) and randomly chooses a k1 to encrypt h1
as {h1 }k1 . Then, it computes:
Cx1 = k1 e(g, g)αqx1 (0) ;

Since the level-(n − 1) AND gate has only one attribute, it
can derive:

e(Di , Cyn−1 )
e(g r · H(i)ri , g qyn−1 (0) )
=
′
e(Di , Cy′ n−1 )
e(g ri , H(i)qyn−1 (0) )
e(g r , g qyn−1 (0) ) · e(H(i)ri , g qyn−1 (0) )

=

qy1 (0) = qparent(y1 ) (index(y1 )) = qx0 (2).

e(g ri , H(i)qyn−1 (0) )
rqyn−1 (0)

= e(g, g)

Then, it computes:

By repeating the process until the level n, for the
level-m AND gate xm , the encryption algorithm randomly selects a degree-1 polynomial qxm with qxm (0) =
qparent(xm ) (index(xm )). Then it calculates the hash value of
level-m attribute ym as hm = H(ym ) and randomly chooses
a random key km to encrypt hm , i.e., {hm }km . Then, it
computes:
Cxm = km e(g, g)αqxm (0) ;

z∈Sxn−1

=

Cym = g qym (0) ;

Cy′ m = H(ym )qym (0) .

Finally, we have the ciphertext CT as follows:
CT ={Cx0 = M e(g, g)αqx0 (0) ; Cx′ 0 = hqx0 (0) ;
hn ; Cyn = g qyn (0) ; Cy′ n = H(yn )qyn (0)

=

Cyi = g qyi (0) ; Cy′ i = H(yi )qyi (0) }.
2) Decryption: Decryption algorithm is operated in a
bottom-up fashion, as shown in Fig. 3, starting from the leveln attribute, where the level-n attribute is initially exposed. The
decryption algorithm calculates:
e(Di , Cyn )
e(g r · H(i)ri , g qyn (0) )
=
′
′
e(Di , Cyn )
e(g ri , H(i)qyn (0) )
e(g r , g qyn (0) ) · e(H(i)ri , g qyn (0) )
e(g ri , H(i)qyn (0) )
rqyn (0)
= e(g, g)
.
=

(e(g, g)r·qparent(z)(index(z)) )

∆i,S ′

xn−1

(0)

∏

r·qx(i)·∆i,S ′

(e(g, g)

xn−1

(0)

.

z∈Sx

Where i = index(z), Sxn−1 = {xn−2 , yn−2 } and Sx′ n−1 =
{index(z) : z ∈ Sxn−1 }.
If the decrypter cannot find corresponding attribute, he/she
cannot decrypt one more level to discover the next attribute.
The same process for level-(n − 2) is repeated for each upper
level to eventually recover message M . Brute force guessing
the next level attribute won’t help since the attacker can not
check whether their guess is correct or not.
V. A NONYMITY E VALUATION M ODELS AND S ECURITY
A NALYSIS OF GIE

∀i ∈ [1, n − 1] : Cxi = ki e(g, g)αqxi (0) ;
Cx′ i = hqxi (0) ; {hi }ki ;

∏

z∈Sx

For each level-m attribute ym , it sets:

Then, it computes:

.

The level-(n − 2) AND gate is decrypted using the same
method in level-(n − 1) AND gate operations except the level
n−2 AND gate requires a degree-1 polynomial, whereas level(n − 1) AND gate requires a degree-0 polynomial.
∏
∆i,S ′
(0)
xn−1
e(g, g)rqxn−2 (0) =
(e(g, g)rqz (0) )

Cx′ m = g βqxm (0) .

qym (0) = qparent(ym ) (index(ym )).

value

Then the decrypter decrypt the hn−1 checks whether one
of his/her attributes has the hash value hn−1 . If found, he/she
can find the attribute yn−1 and then continues the decryption
process through the following computations:

Cx′ 1 = g βqx1 (0) .

Cy′ 1 = H(y1 )qy1 (0) .

the

Cxn−1 /(e(Cx′ n−1 , D)/e(g, g)rqxn−1 (0) ) = kn−1 .

For the level-1 attribute y1 , it sets:

Cy1 = g qy1 (0) ;

derives

In this section, we present several anonymity evaluation
models for the new construction of GIE solutions. Security
analysis of GIE is also provided.
A. Security Analysis
In this subsection, we analyze the security performance
of our scheme under attacks to compromise the anonymity
provided by GIE. Additionally, we will also present the
security strength of GIE encryption scheme.
To evaluate the anonymity strength of GIE encryption
scheme, we present the following lemma:
Lemma 1: At any given step from level n to level 1: (i)
if attackers do not have the attributes for the current level,
886

attackers cannot reduce uncertainty to the next level, and (ii)
attackers cannot gain additional information by sharing their
secret information.
Proof Sketch: To prove the first property, given the strength
of a hash function and meaningful terms used by attributes,
attackers need to deploy dictionary attacks to map a given
attribute to exposed hash value at the current level. Since
attackers do not have the private key, it can only discover
the attributes used by the next level. Thus, the compromised
privacy is restricted by one level of the AND-gate chain.
To address this vulnerability, the TTP can apply a keyed
hash function H on a given attribute and give the hash value
to the user. The secret key is only maintained by the TTP. In
this way, the inputs of the hash function can be considered as
a random number to prevent dictionary attacks. We must note
that using the keyed hash function will reduce the flexibility
of GIE. This is because every user needs to predict attributes
that will be used and gets its corresponding secret key and
hash values from the TTP in advance.
To prove the second property, we need to note that malicious
attackers can combine their attributes and hash values to
identify the hidden attributes. However, then GIE encryption
algorithm restricts them at the currently level if they share their
own secrets. For example, if attacker A has secrets for level-n
attributes, and attacker B has secret for level-(n−1) attributes.
By share their secrets, they may reveal the attributes used at
the level-(n − 1), however they cannot combine their secrets
to correctly decrypt the level-(n − 1) gate. This is because the
construction of the ABE decryption scheme requires to use the
same r value. However, the r values are not same for different
user when TTP distributing secrets to users. Thus, attackers
cannot gain additional information through colluding attacks.

In the following context, we prove the presented GIE
encryption scheme provides the same security strength of the
original CP-ABE scheme. To prove the security of GIE, we
reduce our scheme to CP-ABE using the following lemma.
Lemma 2: The security strength of GIE encryption scheme
is equivalent to CP-ABE scheme.
Proof Sketch: To prove that the proposed scheme is as secure
as CP-ABE, we need to prove that the added components in
the ciphertext, namely Cxi , Cx′ i , and hiki where i ∈ [1, n − 1]
do not reduce the security of the scheme. Other components
of the ciphertext are identical to CP-ABE scheme.
To prove that the additional components do not reduce the
security of the proposed scheme, we need to prove that, given
the Cxi and Cx′ i , the possibility that an attacker can derive
ki or e(g, g)αqxi (0) is negligible. Since ki is randomly chosen
and e(g, g)αqxi (0) is randomized in G2 , deriving each of them
based on known ki e(g, g)αqxi (0) is hard.
Thus, assume that an attacker has ϵ advantage in deriving
ki or e(g, g)αqxi (0) , the attacker will have ϵ advantage in CPABE. This is because CP-ABE uses the same technique to
protect the message. Thus, if CP-ABE scheme is secure, then
our scheme is secure. Moreover, since the security of our
scheme can be reduced to CP-ABE, it is collusion-resistant

as CP-ABE.



VI. P ERFORMANCE E VALUATION OF GIE
In this section, we present the performance evaluation of
GIE in the following aspects: (i) communication overhead, and
(ii) computation overhead. In our performance comparison, we
compare our scheme with BSW CP-ABE scheme [1], CN CPABE scheme [6], NYO scheme [11] and YRL scheme [16],
which are described in Related Work Section.
A. Communication Overhead
The communication overhead is incurred by the transmission of ciphertext. In our proposed solution, for each ANDgate chain with n attributes, 3n members in G0 and n members
in G1 are required 1 . We compare our scheme with several
CP-ABE schemes in the following table:
Scheme
Support
Attributes
Ciphertext Size
Name
Anonymity
Supported
BSW
No
∞
(2n+1) G0 + 1 G1
CN
No
N
(N + 1) G0 + 1 G1
NYO
YES
N
(2N + 1) G0 + 1 G1
YRL
YES
N
(2N + 2) G0 + 1 G1
GIE
YES
∞
3n G0 +n G1
N : the number of predefined attributes and each attribute has 3 values,
namely True, False, and Don’t Care; n: the number of user chosen
attributes.

B. Computation Overhead
We analyze the computation overhead of our proposed
solution in terms of the number of heavy cryptographic operations in the encryption and decryption process. For encrypting
an AND-gate chain with n attributes, we need 3(n − 1)
exponentiations on G0 and n − 1 exponentiations on G1 .
For the decryption scheme, each attribute requires 2 bilinear
pairings and each AND gate requires 1 bilinear pairing. Thus,
in an AND-gate chain with n attributes, the total number of
pairing operations is 3n. Comparing to BSW scheme, the
total pairing operations of GIE are increased by n times
with added anonymity features. The computation overhead of
CN and YRL schemes depends on the predetermined value
N , which is the total number of attributes in the system.
Since the value of N can be very big, thus CN and YRL
schemes are not efficient. In the following table, we summarize
the computation overhead evaluated based on the number of
pairing operations.
Scheme Name
Number of Pairing Operations
BSW
2n
CN
N
YRL
2N
GIE
3n
N : the number of predefined attributes; n: the number of user chosen
attributes.
1 Usually, the pairing takes the form e : E(F m ) × E(F
∗
p
pkm ) → Fpkm ,
where p is a prime, m a positive integer, and k is the embedding degree (or
security multiplier). Here, we use the classical algorithm of Weil pairing with
k = m = 1.

887

VII. C ONCLUSION AND F UTURE W ORK
In this paper, we propose a new approach, called Gradual
Identity Exposure, to anonymize users’ identities. We present
a theoretical framework to model the GIE with several new
proposed concepts. Compared to existing anonymizing techniques through hidden policy or pseudonyms, GIE is effective
in that it provides a layered protection framework to protect
users’ identities through a step-by-step fashion. Moreover, GIE
is more efficient and flexible since receivers do not need to
try decrypting all ciphertexts as in hidden policy schemes.
Based on the proposed GIE construction, we would like
to explore the following directions to enhance the anonymity
and performance features. We will investigate the anonymity
measurement and optimality condition in the gradual exposure
process. Other than current simple Optimal Identity Exposure definition, we plan to investigate information theoretical
optimality condition and efficient planning algorithms. Also,
currently, we only expose one attribute per step, we will extend
the solution to expose multiple attributes in one exposure step
to make the solution more flexible, and increase the computation/communication efficiency. Furthermore, the structure of
multiple AND-gate chains combined by an OR gate needs to
be investigated.

[11] T. Nishide, K. Yoneyama, and K. Ohta. Attribute-based encryption
with partially hidden encryptor-specified access structures. In ACNS’08:
Proceedings of the 6th international conference on Applied cryptography and network security, pages 111–129, Berlin, Heidelberg, 2008.
Springer-Verlag.
[12] R. Ostrovsky and B. Waters. Attribute-based encryption with nonmonotonic access structures. In Proceedings of the 14th ACM conference
on Computer and communications security, pages 195–203. ACM New
York, NY, USA, 2007.
[13] M. Pirretti, P. Traynor, P. McDaniel, and B. Waters. Secure attributebased systems. In CCS ’06: Proceedings of the 13th ACM conference
on Computer and communications security, pages 99–112, New York,
NY, USA, 2006. ACM.
[14] A. Sahai and B. Waters. Fuzzy Identity-Based Encryption. In Advances
in Cryptology–Eurocrypt, volume 3494, pages 457–473. Springer.
[15] A. Shamir. How to share a secret. In Communications of the ACM,
volume 22, pages 612–613. ACM New York, NY, USA, 1979.
[16] S. Yu, K. Ren, and W. Lou. Attribute-based on-demand multicast group
setup with membership anonymity. In SecureComm ’08: Proceedings
of the 4th international conference on Security and privacy in communication netowrks, pages 1–6, New York, NY, USA, 2008. ACM.

A PPENDIX
CP-ABE scheme utilizes Identity-Based Encryption (IBE)
[3] and threshold secret sharing scheme [15]. A brief description of CP-ABE protocols and their working is illustrated in
Table I. For more details, interested readers refer to [1].
TABLE I
CP-ABE P ROTOCOLS

ACKNOWLEDGEMENT
Authors would like to thank anonymous reviewers for their
constructive comments to improve the quality of this work.
R EFERENCES
[1] John Bethencourt, Amit Sahai, and Brent Waters. Ciphertext-policy
attribute-based encryption. In SP ’07: Proceedings of the 2007 IEEE
Symposium on Security and Privacy, pages 321–334, Washington, DC,
USA, 2007. IEEE Computer Society.
[2] D. Boneh, G. Di Crescenzo, R. Ostrovsky, and G. Persiano. Public key
encryption with keyword search. In Eurocrypt, pages 506–522. Springer,
2004.
[3] D. Boneh and M. Franklin. Identity-based encryption from the weil
pairing. In CRYPTO ’01: Proceedings of the 21st Annual International
Cryptology Conference on Advances in Cryptology, pages 213–229,
London, UK, 2001. Springer-Verlag.
[4] X. Boyen and B. Waters. Anonymous hierarchical identity-based
encryption (without random oracles). In Advances in Cryptology CRYPTO, volume 4117, pages 290–307. Springer, 2006.
[5] M. Chase. Multi-authority attribute based encryption. In TCC’07:
Proceedings of the 4th conference on Theory of cryptography, pages
515–534, Berlin, Heidelberg, 2007. Springer-Verlag.
[6] L. Cheung and C. Newport. Provably secure ciphertext policy abe. In
CCS ’07: Proceedings of the 14th ACM conference on Computer and
communications security, pages 456–465, New York, NY, USA, 2007.
ACM.
[7] C. Gentry. Practical identity-based encryption without random oracles.
In Eurocrypt, volume 4004, pages 445–464. Springer, 2006.
[8] V. Goyal, O. Pandey, A. Sahai, and B. Waters. Attribute-based encryption for fine-grained access control of encrypted data. Proceedings of
the 13th ACM conference on Computer and communications security,
pages 89–98, 2006.
[9] M. Hansen, P. Berlich, J. Camenisch, S. Claufl, A. Pfitzmann, and
M. Waidner. Privacy-enhancing identity management. In Information
Security Technical Report, volume 9, pages 35–44. Elsevier, 2004.
[10] J. Katz, A. Sahai, and B. Waters. Predicate encryption supporting
disjunctions, polynomial equations, and inner products. In EUROCRYPT’08: Proceedings of the theory and applications of cryptographic
techniques 27th annual international conference on Advances in cryptology, pages 146–162, Berlin, Heidelberg, 2008. Springer-Verlag.

Protocol 1: Setup
1. Construct bilinear map e : G0 × G0 → G1 of prime order p with a
generator g;
2. Choose random numbers α, β ∈ Zp;
3. Calculate the system public key PK = ⟨e, G0 , G1 , H, g, h = g β , ζ =
e(g, g)α ⟩ and private master key MK = ⟨β, g α ⟩, where H : {0, 1}∗ →
G0 .
Protocol 2: KeyGen(MK, S)
For user i = 1, . . . , n:
1. Choose random numbers ri and rj ∈ Zp , ∀j ∈ attribute set S;
2. Calculate SKi = ⟨Di = g (α+ri )/β ; ∀j ∈ S : Di,j =
′ = g rj ⟩.
g ri H(j)rj ; Di,j
Protocol 3: Encrypt(PK, k, PT )
1. Create access tree PT ;
2. Choose polynomial qx (0) ∀x ∈ PT ;
3. Starting from root R of PT , choose DEK k ∈ Zp and set qR (0) = s
where R is the root of PT ;
4. S is the set of leave nodes of PT , calculates cipher text CT
e = kζ s ; C = hs ; ∀j ∈ S : Cj = g qj (0) ; ∀j ∈ S :
CT = ⟨PT ; C
Cj′ = H(j)qj (0) ⟩;
Protocol 4: Decrypt(CT , SK)
1. DecryptN ode(CT , SK, x)=

e(Di,x , Cx )
= e(g, g)ri qx (0) , ∀x ∈
′ , C′ )
e(Di,x
x

PT ;
2. Using a recursive procedure and DecryptCiphter method, compute the
e
Ce(g,
g)ri s
DEK DecryptCipher(CT , SK, R) =
= k.
e(C, Di )
For detailed descriptions on generations of private keys SK, ciphertext CT , and
function DecryptN ode, please refer to [1].

888

How to Use Attribute-Based Encryption to Implement
Role-based Access Control in the Cloud
Yan Zhu

Di Ma

Computer and Communication Engineering
University of Science and Technology Beijing
30 Xueyuan Rd, Haidian, Beijing 100083, China

Computer and Information Science
University of Michigan-Dearborn
4901 Evergreen Rd, Dearborn, MI 48128

zhuyan@ustb.edu.cn
Chang-Jun Hu

dmadma@umich.edu
Dijiang Huang

Computer and Communication Engineering
University of Science and Technology Beijing
30 Xueyuan Rd, Haidian, Beijing 100083, China

Computing Inf. & Decision Systems Engineering
Arizona State University
699 S. Mill Avenue, Tempe, AZ 85281

huchangjun@ies.ustb.edu.cn

dijiang@asu.edu

ABSTRACT

1. INTRODUCTION

This paper addresses how to construct a RBAC-compatible
attribute-based encryption (ABE) for secure cloud storage,
which provides a user-friendly and easy-to-manage security
mechanism without user intervention. Similar to role hierarchy in RBAC, attribute lattice introduced into ABE is
used to deﬁne a seniority relation among all values of an attribute, whereby a user holding the senior attribute values
acquires permissions of their juniors. Based on these notations, we present a new ABE scheme called Attribute-Based
Encryption with Attribute Lattice (ABE-AL) that provides
an eﬃcient approach to implement comparison operations
between attribute values on a poset derived from attribute
lattice. By using bilinear groups of composite order, we propose a practical construction of ABE-AL based on forward
and backward derivation functions. Compared with prior
solutions, our scheme oﬀers a compact policy representation
solution, which can signiﬁcantly reduce the size of privatekeys and ciphertexts. Furthermore, our solution provides a
richer expressive power of access policies to facilitate ﬂexible
access control for ABE scheme.

Increasingly, more and more enterprises and individuals
have moved their data, such as personal data and large
archive system, into the cloud. Cloud-based storage cloud
be particularly attractive for consumers by providing ondemand capacity, low-cost service, and long-term archive.
Furthermore, consumers can access applications and data
from the cloud anywhere in the world on demand.
However, several recent surveys [1] show that 88% potential cloud consumers worry about the privacy of their data,
and security is often cited as the top obstacle for cloud adoption. Unfortunately, traditional security mechanisms, such
as access control technology, are not suitable for the cloud
environment due to the outsourcing-service characteristics
of cloud storage and the untrusted or honest-but-curious assumption of cloud providers. In order to solve this issue,
attribute-based encryption (ABE) [2, 3, 4] has been proposed in the recent years. ABE is a new cryptographic
technology, which encrypts a message in terms of access constraints based on ﬁne-grain access control (FGAC) model [5,
6]. By using access policy on attributes describing the outsourced data, only authorized users can access and decrypt
the data. For example, we can use ABE to encrypt a ﬁle by
a policy

Categories and Subject Descriptors
D.4.6 [Security and Protection]: Access controls

((𝐹 𝑎𝑐𝑢𝑙𝑡𝑦 = 𝑃 𝑟𝑜𝑓.) and ((𝐷𝑒𝑝. = 𝐶𝑆) or (𝐷𝑒𝑝. = 𝐸𝐸)))

General Terms

If a user obtains a private key with an assignment of attributes {𝐹 𝑎𝑐𝑢𝑙𝑡𝑦 := 𝑃 𝑟𝑜𝑓., 𝐷𝑒𝑝. := 𝐶𝑆}, she/he can decrypt this ﬁle based on the match between access policies
embedded into the ﬁle and identity attributes described in
the user’s private key.
Although ABE is a powerful tool which meets a variety of
application requirements, ABE still has some disadvantages
in its practical uses. For example, ABE is a more individualoriented access control system. The reason is that ABE, as
a ﬁne-grained access control method, requires a user’s direct intervention to deﬁne the access policy for each protected resource. Hence, it is not like traditional access control systems, such as RBAC, which are transparent to all
users (e.g., the system does not require user’s direct intervention). When an application needs to deal with a large
amount of data, the requirement for the user to specify a

Security

Keywords
Cloud Security, Attribute-Based Encryption, RBAC model,
Attribute Lattice, Partial Order

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
CloudComputing’13, May 8, 2013, Hangzhou, China.
Copyright 2013 ACM 978-1-4503-2067-2/13/05 ...$15.00.

33

perfect and sound access policy, will consume large amounts
of user’s energy. Sometimes, it may be unrealistic when
the user’s policies are required to keep consistent with constantly changes of the system. These restrictions hinder the
applicability and popularity of ABE to secure cloud storage.
Therefore, it is necessary to develop a more user-friendly security mechanism for data security in the cloud.
To solve the above issues, we put our attention to rolebased access control (RBAC) that has been widely adopted
by various information systems over the past few years.
Compared with FGAC used in ABE, advantages of RBAC
include simplicity, easy-to-use, and automatic running without user’s intervention. For example, in a Windows-based
network system, a role’s responsibilities and relationships
are speciﬁed by the administrator and various access controls are completely transparent to ordinary users. Typically, users do not need to develop access policies for their
own resources, but if necessary, they can customize their own
policies. The above property makes RBAC model easier to
be accepted by ordinary customers.
Based on the above discussion, our goal in this paper is to
introduce the RBAC model into the ABE scheme, so that
advantages of RBAC could be transplanted into secure cloud
storage. The beneﬁt from the combination is that a more
user-friendly and easy-to-manage security mechanism can be
achieved to protect user’s data in the cloud.
Our objective faces many technical challenges. One of the
most challenging issues is to realize role hierarchy (or called
Lattice) used in RBAC into ABE, as well as partial order
relation. There have been some cryptographic work [7, 8]
to realize the hierarchical key in terms of RBAC, but they
cannot be directly used for ABE. In addition, some work in
ABE have supported the tree-hierarchy (called hierarchical
ABE) [9, 10, 11], but they can not support full RBAC-type
hierarchy which is a lattice with tree, inverted tree, general
hierarchies on them. Therefore, it is necessary to develop a
new construction for ABE with full RBAC-type hierarchy.

Data Access

RBAC-Compatible
ABE
Existing System
with RBAC

Cloud Data Storage

Data Access

Figure 1: The architecture for user-friendly security
cloud storage in existing system with RBAC.
new ABE scheme called Attribute-Based Encryption with
Attribute Lattice (ABE-AL). ABE-AL provides an eﬃcient
approach to support attribute lattices with arbitrary partial
order relations, including the comparison operation (𝐴 ⪯ 𝑣
or 𝐴 ર 𝑣) for a poset of attribute values 𝐻 = (𝑉, ⪯) on
𝑉 = {𝑣1 , ⋅ ⋅ ⋅ , 𝑣𝑛 }, a attribute variable 𝐴 and an attribute
value 𝑣 ∈ 𝑉 . We also prove that our ABE-AL scheme is semantic secure and unforgeable under the eDDH and 𝑚-SDH
assumptions. Compared with prior schemes, our scheme
provides more succinct and richer policy representation for
ﬂexible access control.
Organization. The rest of the paper is organized as follows. Section 2 overviews some basic notations and frameworks. Section 3 articulates the deﬁnition of ABE-AL and
security models. We present the construction of ABE-AL in
Section 4, . We evaluate the security of our scheme in Sections 5. Finally, related works and conclusions are presented
in Section 6 and 7.

2. NOTATIONS AND FRAMEWORK
2.1

RBAC Model

In an information system, a hierarchy or lattice is used
to denote the relationships and arrangements of the objects,
users, elements, values, and so on. Especially, in many access control systems the users are organized in a hierarchy
constructed with a number of classes, called security classes
or roles, according to their competencies and responsibilities. This hierarchy arises from the fact that some users
have more access rights than others. In order to manage
large-scale systems, the hierarchy in RBAC becomes more
complex than other systems. Especially, role hierarchy (RH)
is a natural means for structuring roles to reﬂect an organization’s lines of authority and responsibility. We adopt
the deﬁnitions from RBAC models proposed by Sandu et
al. [13]:

Contributions. In this paper, we address the problem of
how to construct an eﬀective RBAC-compatible ABE for
cloud data encryption. This kind of ABE takes full advantage of RBAC, which provides a well-designed and easyto-manage security mechanism without user intervention.
More importantly, it can fully preserve investment in existing RBAC systems, because it establishes a bridge between RBAC and secure cloud storage. The high level architecture of such a cloud storage system is illustrated in
Figure 1. In this architecture, users who wish to share or
access the data only interact with the existing system with
RBAC (such as Windows NT), and the public cloud is used
to store the actual data in the ABE-encrypted form. The
proposed RBAC-compatible ABE is used in this architecture to transform the RBAC-based access policy into the
FGAC-based access policy, which is also used to implement
attribute-based encryption for user’s data. This architecture fully utilizes the highly automated feature of existing
RBAC system, so it provide a better user-friendly interface
than the original ABE.
The challenge of constructing a RBAC-compatible ABE is
to ﬁnd an eﬀective cryptographic method to realize partial
order relation (derived from role hierarchy in RBAC) in existing ABE scheme. To solve this problem, based on BSW’s
CP-ABE with composite order groups [12], we present a

Definition 1. [Hierarchical RBAC model]: The 𝑅𝐵𝐴𝐶
model has the following components:
∙ 𝑈 , 𝑅, 𝑃 , and 𝑆 denote users, roles, permissions and
sessions respectively;
∙ 𝑃 𝐴 ⊆ 𝑃 × 𝑅 is a many-to-many permission to role
assignment relation;
∙ 𝑈 𝐴 ⊆ 𝑈 × 𝑅 is a many-to-many user to role assignment relation;
∙ 𝑅𝐻 ⊆ 𝑅 × 𝑅 is a partial order on 𝑅 called the role
hierarchy or role dominance relation, written as ⪯;

34

Table 1: Grammar
Attribute
Attribute value
Delivery Policy
Condition
Literal
Relation

for FGAC addresses and policies
𝐴𝑖
∈
a set of attributes 𝔸
∈
Numerals ∣ Strings
𝑣𝑖,𝑗
𝜋
::==
𝜚
𝜚
::== 𝜒 ∣ (𝜚 or 𝜚) ∣ (𝜚 and 𝜚)
𝜒
::==
(𝐴𝑖 ⊙ 𝑣𝑖,𝑗 )
⊙
::==
≺∣≻∣=∣⪯∣ર
Next, we show a simple example to describe the above
deﬁnition with three attribute lattices: 𝐷𝑒𝑝𝑎𝑟𝑡., 𝑓 𝑎𝑢𝑙𝑡𝑦,
and 𝐶𝑙𝑒𝑎𝑟.. We deﬁne the organization of the university:
𝑈 𝑛𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦 ⪯ 𝑆𝑐ℎ𝑜𝑜𝑙 𝑜𝑓 𝐵𝑢𝑠𝑖𝑛𝑒𝑠𝑠 ⪯ 𝐸𝑐𝑜𝑛𝑜𝑚𝑖𝑐𝑠 𝐷𝑒𝑝𝑎𝑟𝑡.,
𝑈 𝑛𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦 ⪯ 𝑆𝑐ℎ𝑜𝑜𝑙 𝑜𝑓 𝐵𝑢𝑠𝑖𝑛𝑒𝑠𝑠 ⪯ 𝐴𝑐𝑐𝑜𝑢𝑛𝑡𝑎𝑛𝑐𝑦 𝐷𝑒𝑝𝑎𝑟𝑡.,
and 𝑈 𝑛𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦 ⪯ 𝑆𝑐ℎ𝑜𝑜𝑙 𝑜𝑓 𝐸𝑛𝑔𝑖𝑛𝑒𝑒𝑟𝑖𝑛𝑔 ⪯ 𝐸𝑙𝑒𝑐𝑡𝑟𝑖𝑐𝑎𝑙 𝐷𝑒𝑝𝑎𝑟𝑡..
It is well-known that there exists the seniority relation among
three basic levels of clearance: (𝑢𝑛𝑐𝑙𝑎𝑠𝑠𝑖𝑓 𝑖𝑒𝑑 ⪯ 𝑐𝑜𝑛𝑓 𝑖𝑑𝑒𝑛𝑡𝑖𝑎𝑙 ⪯
𝑠𝑒𝑐𝑟𝑒𝑡 ⪯ 𝑡𝑜𝑝𝑠𝑒𝑐𝑟𝑒𝑡). Similarly, there also exists the relation among three levels of faculty: (𝑙𝑒𝑐𝑡𝑢𝑟𝑒 ⪯ 𝑎𝑠𝑠.𝑝𝑟𝑜𝑓. ⪯
𝑝𝑟𝑜𝑓.). If the above deﬁnition is implemented in ABE, we
can rewrite the above policy as
(faulty ⪯ 𝑎𝑠𝑠.𝑝𝑟𝑜𝑓. or clear. ર 𝑠𝑒𝑐𝑟𝑒𝑡) and Depart. ર
𝑆𝑐ℎ𝑜𝑜𝑙 𝑜𝑓 𝐸𝑛𝑔𝑖𝑛𝑒𝑒𝑟𝑖𝑛𝑔

∙ 𝑢𝑠𝑒𝑟 : 𝑆 → 𝑈 is a function mapping each session 𝑠𝑖 to
the single user 𝑢𝑠𝑒𝑟(𝑠𝑖 ); and
∙ 𝑟𝑜𝑙𝑒𝑠 : 𝑆 → 2𝑅 is a function mapping each session
𝑠𝑖 to a set of roles: 𝑟𝑜𝑙𝑒𝑠(𝑠𝑖 ) ⊆ {𝑟 ∈ 𝑅∣∃𝑟′ ∈ 𝑅, 𝑟 ⪯
𝑟′ : (𝑢𝑠𝑒𝑟(𝑠𝑖 ), 𝑟′ ) ∈ 𝑈 𝐴} and 𝑠𝑖 has the permissions:
∪
′′
′′
′′
𝑟∈𝑟𝑜𝑙𝑒𝑠(𝑠𝑖 ) {𝑝 ∈ 𝑃 ∣∃𝑟 ∈ 𝑅, 𝑟 ⪯ 𝑟 : (𝑝, 𝑟 ) ∈ 𝑃 𝐴}.
The last component states that the system can automatically run the RBAC without user’s intervention. When a
user performs an operation, ﬁrst of all, the system uses the
function 𝑢𝑠𝑒𝑟(𝑠𝑖 ), taking as input the session 𝑠𝑖 , to get the
single user. Next, the set of the user’s roles 𝑟𝑜𝑙𝑒𝑠(𝑠𝑖 ) is
known by using the user to role assignment relation 𝑈 𝐴.
Then, the user’s permissions are found by using the role hierarchy 𝑅𝐻 and permission to role assignment relation 𝑃 𝐴.
Finally, the system determines whether the user’s operation
is legitimate according to the permissions.

and the assignment of attributes {faculty := 𝑎𝑠𝑠.𝑝𝑟𝑜𝑓., clear. :=
𝑡𝑜𝑝𝑠𝑒𝑐𝑟𝑒𝑡, Depart. := 𝐸𝑙𝑒𝑐𝑡𝑟𝑖𝑐𝑎𝑙 𝐷𝑒𝑝𝑎𝑟𝑡.}. Hence, the attribute lattice can simplify the access policy, reduce the computational overheads, and decrease the size of ciphertexts
and private-keys in ABE. Note that, the ABE with AL must
have the ability to support full RBAC model with tree, inverted tree, and general hierarchies on them, as shown Figure 2.

2.2 ABE with Attribute Lattice
Similar to role hierarchy in RBAC, the hierarchy (or lattice) is also extremely useful for ABE to introduce attribute
lattice (AL) which deﬁnes a seniority relation among all values of an attribute, whereby a user holding the senior attribute values acquires the permissions of their juniors.
In fact, this kind of attribute lattice has been introduced
in FGAC model [5, 6]. Table 1 describes the language according to [14]. We call an access control system as an FGAC
system if this system satisﬁes the above speciﬁcations. Here,
access policy can be expressed as a logical function on some
attribute values. For the sake of clarity, we propose a definition of policy matching (or relation matching) of
attribute-based access control as follows:

D

D

E

E


D

F

F





D

1. Let 𝔸 = {𝐴1 , ⋅ ⋅ ⋅ , 𝐴𝑛 } be a (ﬁnite) set of attributes.
Let 𝑉𝑖 = {𝑣𝑖,1 , ⋅ ⋅ ⋅ , 𝑣𝑖,𝑚 } be a set of values correspond
to an attribute 𝐴𝑖 ∈ 𝔸, where 𝑚 is the number of
values. 𝑉𝑖 is called as a hierarchy, if all elements in
𝑉𝑖 have a partial ordering relation ⪯. That is, 𝐻𝑖 =
(𝑉𝑖 , ⪯).

D
F

E
H

I


E

E
J

I

F

嘾

H

J

K



Figure 2: Some examples for attribute lattice.

2.3

2. Let 𝜒 := 𝐴𝑖 ⪯ 𝑣𝑖,𝑗 denote a literal in terms of the
relation between 𝐴𝑖 and 𝑣𝑖,𝑗 in a poset 𝐻𝑖 . For an
assignment of attribute value 𝐴𝑖 ← 𝑣𝑖,𝑙 , the relation
𝐴𝑖 ⪯ 𝑣𝑖,𝑗 returns “true” if 𝑣𝑖,𝑙 ⪯ 𝑣𝑖,𝑗 ; otherwise, it
returns “false”.

RBAC-Compatible ABE System

Our goal is to improve ABE for implementing cloud data
encryption in the existing RBAC systems. In order to achieve
this goal, we expect to provide an eﬀective method that
transforms the RBAC mechanism into an ABE-based instance. Based on this instance, data can be encrypted by
using ABE and then stored into cloud. In Figure 3, we
provide such a framework of RBAC-compliant ABE system,
where a user can use the existing system with RBAC (such
as Windows, Linux) to access cloud resources. The accessing process is completely transparent to the user. At the
same time, all data in the system can be stored and shared
by using ABE encryption. To compensate the diﬀerence between RBAC and ABE, the administrator need to establish

3. Let 𝜋 := ⊎ 𝜒𝑘 denote an access policy function based
on the Boolean function, where ⊎ denotes either AND
or OR logical operation. For the assignment of attribute values 𝜌 := (𝐴1 , ⋅ ⋅ ⋅ , 𝐴𝑛 ) ← (𝑣1,𝑗1 , ⋅ ⋅ ⋅ , 𝑣𝑛,𝑗𝑛 ),
the policy matching between ⟨𝜋, 𝜌⟩ (which is denoted
as 𝑀 𝑎𝑡𝑐ℎ(𝜋, 𝜌)) returns “true” if the Boolean function
is satisﬁed according to the results of literals, otherwise, it returns “false”.

35

a transformation from RBAC to ABE. Each user’s terminal needs to deploy a RBAC-to-ABE module to achieve the
above transformation. In this section, we will describe how
to implement such a transformation from the RBAC model
in Section 2.1 to the ABE model with attribute lattice in
Section 2.2.

3. RBAC-COMPATIBLE ABE
In the previous section, the attribute lattice (partial order
relation (𝐴𝐿, ⪯)) have been introduced to RBAC-Compatible
ABE. This means that comparison operation ⪯ on attribute
lattice would be executed in the ABE. However, existing
ABE schemes do not support comparison operation on attribute lattices at present1 . In light of the fact that the comparison operation can enhance the capacity of constraint expressions, decrease the computational overheads of encryption and decryption, and reduce the size of ciphertexts and
private-keys, in this section we design an eﬃcient cryptographic comparison operations for arbitrary partial orders
to support the expressions of attribute lattices in ABE.

Cloud

Information
Exchange

Data Exchange

3.1 ABE with Attribute Lattice

Policy Management

An Attribute-based Encryption with Attribute Lattice (ABEAL) consists of the following ﬁve algorithms:

Application
Administrator

Setup(𝜅, 𝔸): Takes in the security parameter 𝜅 and the attribute universe description 𝔸. It outputs a master key
𝑔𝑚𝑘 and a public-key 𝑔𝑝𝑘;

RBAC-to-ABE Module

GenKey(𝑔𝑚𝑘, 𝜌(𝑖) ): Takes in the manager key 𝑔𝑚𝑘 and
a user’s attribute assignments 𝜌(𝑖) for the user 𝑖. It
outputs a user’s private-key 𝑔𝑠𝑘𝑖 .

Cloud Users

Figure 3: The framework of RBAC-Compatible
ABE for secure cloud storage.

Encrypt(𝑔𝑝𝑘, 𝜋, 𝑀 ): Takes in the public key 𝑔𝑝𝑘, the access policy 𝜋 over 𝔸, and the plaintext 𝑀 ∈ {0, 1}∗ . It
outputs a ciphertext 𝐶 such that only users whose private keys satisfy the access policy 𝜋 are able to exact
𝑀.

We deﬁne the following notations that transform the RBAC
model into the ABE model. Given a RBAC system (𝑈, 𝑅, 𝑃,
𝑆, 𝑈 𝐴, 𝑃 𝐴, 𝑅𝐻, 𝑢𝑠𝑒𝑟, 𝑟𝑜𝑙𝑒𝑠), these notations are constructed
on standard RBAC model in Deﬁnition 1.

Decrypt(𝑔𝑝𝑘, 𝑔𝑠𝑘𝑖 , 𝐶): Takes in the public parameters 𝑔𝑝𝑘,
a ciphertext 𝐶 and a private key 𝑔𝑠𝑘𝑖 . If the set of attributes of 𝑔𝑠𝑘𝑖 satisﬁes the access policy of ciphertext,
it outputs the plaintext 𝑀 .

∙ First, each role hierarchy 𝑅𝐻 = (𝑅, ⪯) in RBAC is
assigned a attribute name 𝐴𝑖 , and the corresponding
roles 𝑟𝑗 ∈ 𝑅 becomes the attribute values 𝑣𝑖,𝑗 ∈ 𝑉𝑖 .
The role hierarchies (RHs) in RBAC would be mapped
into the attribute lattices (ALs) in ABE, that is, (𝑅, ⪯
) = (𝑉𝑖 , ⪯). This mapping is direct and obvious.

In this framework, the scheme must obey this rule as follows: Given the above-mentioned (𝜌(𝑖) , 𝜋), we can compute
(𝑔𝑚𝑘, 𝑔𝑝𝑘) ← 𝑆𝑒𝑡𝑢𝑝(1𝜅 , 𝔸) and 𝑔𝑠𝑘𝑖 ← 𝐺𝑒𝑛𝐾𝑒𝑦(𝑔𝑚𝑘, 𝜌(𝑖) ).
Such that, we hold
⎡
⎤
𝐷𝑒𝑐𝑟𝑦𝑝𝑡(𝑔𝑝𝑘, 𝑔𝑠𝑘𝑖 , 𝐶) = 𝑀 ∣
Pr ⎣ 𝐶 ← 𝐸𝑛𝑐𝑟𝑦𝑝𝑡(𝑔𝑝𝑘, 𝜋, 𝑀 ), ⎦ = 1,
𝑀 𝑎𝑡𝑐ℎ(𝜋, 𝜌(𝑖) ) = 𝑡𝑟𝑢𝑒

∙ Next, we deﬁne a function mapping each session 𝑠
to a set of attributes: 𝐴𝑡𝑡𝑟𝑖𝑏𝑢𝑡𝑒(𝑠) ⊆ {𝑣 ∈ 𝑉𝑖 ∣𝑟 ∈
𝑅 : (𝑢𝑠𝑒𝑟(𝑠), 𝑟) ∈ 𝑈 𝐴, 𝑟 = 𝑣}. This function can be
used to obtain the user’s attributes in data encryption. That is, the result of 𝐴𝑡𝑡𝑟𝑖𝑏𝑢𝑡𝑒(𝑠) can be used to
establish access policy through simple logical relationship. This kind of policy is used to deﬁne the policy
in resource encryption.

if and only if the access is granted over ⟨𝜋, 𝜌(𝑖) ⟩ according to
the policy matching criterion.

3.2

∙ Finally, we describe the process of accessing cloud resources. When the user logins the RBAC system, the
user can escrow ABE’s private key to the system. If
the user wishes to access the data in the cloud, the system ﬁrst obtains the access policy of the resource, then
calculates 𝑟𝑜𝑙𝑒𝑠(𝑠) to get the set of authorized roles.
Using the set of authorized roles, the system can check
whether there is an eﬀective subset of roles in 𝑟𝑜𝑙𝑒𝑠(𝑠)
which meets the above access policy. If the subset exists, the system downloads the data and decrypts it
locally.

Security Definition of ABE-AL

To analyze the security of ABE-AL scheme, we ﬁrst consider a new kind of semantic security, called indistinguishability against chosen plaintext attacks with adaptive attribute
lattice (IND-AL-CPA), which can be transformed into the
security against chosen ciphertext attacks (IND-CCA) by
applying a random oracle technique based on Fujisaki-Okamoto
transformation. In this kind of security, we consider that
the adversary can query arbitrary partial ordering relations
(attribute lattices) to construct a key hierarchy. Given an
ABE-AL scheme ℰ𝒮, the IND-AL-CPA security is evaluated
by the following game:

In this framework, we pay more attention to the improvement of ABE’s automated process. If necessary, it is also
easy to implement for modifying artiﬁcially access policies.

1

Note that this kind of hierarchy on posets is diﬀerent from
that on the hierarchy IBE (HIBE) schemes because the latter
only supports a tree structure.

36

Setup. The challenger ℬ runs Setup algorithm, gives the
adversary 𝒜 the public parameters 𝑔𝑝𝑘, and keeps the
master key 𝑔𝑚𝑘;

Given a bilinear map group system 𝕊𝑁 = (Ψ, 𝑁 = 𝑙𝑝𝑞, 𝔾,
𝔾𝑇 , 𝑒(⋅, ⋅)) with public composite order 𝑁 , where 𝑙, 𝑝, 𝑞 are
secret large prime numbers. According to the diﬃculty of
factoring large composite integers, 𝑙, 𝑝, 𝑞 are secure. The
security of our schemes proposed in this paper is constructed
on two basic assumptions:

Query. The adversary 𝒜 gives the challenger ℬ an attribute
identity-poset pair (𝐴𝑖 , ℋ𝑖 ), where ℋ𝑖 = ⟨𝑉𝑖 , ⪯⟩ is an
arbitrary partial ordering relation. The challenger ℬ
assist 𝒜 to construct the cooperatively attribute lattice. After all queries are realized, the adversary can
use public parameters 𝑔𝑝𝑘 to generate a valid ciphertext for an arbitrary policy 𝜋.

Definition 3 (RSA assumption). Given an RSA public key (𝑁, 𝑒) and a ciphertext 𝐶 = 𝑀 𝑒 ∈ 𝔾, it is intractable
to compute the plaintext 𝑀 .
Definition 4 (eDDH assumption). Given ((𝐺, 𝐺′ ),
(𝐻, 𝐻 ′ ), (𝑉, 𝑉 ′ )) = ((𝐺, 𝐺𝜏 ), (𝐻, 𝐻 𝜏 ), (𝑒(𝐺, 𝐻)𝜍 , 𝑉 ′ )), it is
intractable to decide whether or not 𝑉 ′ = 𝑒(𝐺, 𝐻)𝜏 𝜍 , where
𝐺, 𝐻 be two generators in 𝕊𝑁 .

Challenge. The adversary 𝒜 submits two equal length messages 𝑀0 and 𝑀1 . In addition, the adversary gives a
challenge policy 𝜋 in terms of 𝔸. The challenger ℬ
ﬂips a random coin 𝑏 ∈ {0, 1}, and encrypts 𝑀𝑏 under
policy 𝜋. The correspondent ciphertext 𝐶𝑏 is given to
the adversary 𝒜.

Definition 5 (𝑚-SDH assumption). Given ⟨𝐺, 𝐺𝑥 ,
1
2
𝑚
𝐺𝑥 , ⋅ ⋅ ⋅ , 𝐺𝑥 ⟩, it is intractable to compute ⟨𝑐, 𝐺 𝑥+𝑐 ⟩ where
∗
𝑐 ∈ ℤ𝑛 ∖ {−𝑥} and 𝐺 be a generator chosen from 𝔾.

Guess. The adversary outputs a guess 𝑏′ ∈ {0, 1} of 𝑏.
In this game, the advantage of the adversary 𝒜 in attackIND-AL-CPA
ing the ABE-AL scheme is deﬁned
as 𝐴𝑑𝑣ℰ𝒮
(𝒜) =

′
′
′
1
1

∣Pr[𝑏 = 𝑏] − Pr[𝑏 ∕= 𝑏]∣ = Pr[𝑏 = 𝑏] − 2 , where the prob2
ability is taken over the random coins of 𝒜 and all probabilistic algorithms in the scheme.

4.2

Definition 2. A ciphertext-policy attribute-based encryption with attribute lattice (ABE-AL) scheme is (𝑡, 𝜀)-adaptive
attribute lattice against chosen plaintext attacks (IND-ALCPA), if for any polynomial time adversary with time-complexity 𝑡, there is at most a negligible advantage 𝜀 in the above
game.

Setup(𝜅, 𝔸)→ (𝑔𝑝𝑘, 𝑔𝑚𝑘). Given a security parameter 𝜅
and an attribute set 𝔸, the algorithm ﬁrst chooses two
generators 𝐺, 𝐻 ∈ 𝔾 and a generator 𝑊 ∈ 𝔾𝑙 . Then
it chooses a random integer 𝜆 for 𝑙∣𝜆 and sets 𝑇 = 𝐻 𝜆
such that 𝑇 ∈ 𝔾𝑁 ′ . Note that, 𝑒(𝑊, 𝑇 ) = 1.
Next, it chooses a random 𝜁 ∈𝑅 ℤ and sets 𝐷 = 𝑊 𝜁 ∈
𝑔𝑝𝑘
(𝔾𝑙 and 𝑉 = 𝑒(𝐺, 𝐻)
) ∈ 𝔾𝑇 . Then, it publishes
(
) =
𝕊, 𝐻, 𝑇, 𝐷, 𝑉, ℎ(⋅) and keeps 𝑔𝑚𝑘 = 𝜆, 𝜁, 𝐺, 𝑊 secret.

4. CONSTRUCTION OF ABE-AL
4.1

Construction of ABE-AL

Let 𝕊 = (Φ, 𝑁, 𝔾, 𝔾𝑇 , 𝑒(⋅, ⋅)) be a above-mentioned bilinear map group system with public order 𝑁 , where 𝑁 = 𝑙⋅𝑝⋅𝑞.
Let 𝑁 ′ = 𝑝𝑞 and 𝑛 = 𝜓(𝑁 ′ ) are RSA-type parameters.
There is a hash function ℎ : {0, 1}∗ → ℤ𝑁 . The ABE-AL
scheme is constructed as follows:

Bilinear Map and RSA Assumption

We set up our systems using bilinear pairings introduced
by Boneh and Franklin [15, 16]. Give an elliptic curve over a
ﬁnite ﬁeld 𝔽Ψ for a public prime number Ψ. Let 𝔾 and 𝔾𝑇 be
two addition groups with public composite order 𝑁 , where
𝑁 = 𝑙𝑝𝑞 and 𝑙, 𝑝, 𝑞 are three secret large prime numbers. Let
the function 𝑒 be a computable bilinear map 𝑒 : 𝔾×𝔾 → 𝔾𝑇 ,
we deﬁne a bilinear map group system which is a tuple 𝕊 =
(Ψ, 𝑁, 𝔾, 𝔾𝑇 , 𝑒) composed of objects as described above.
We construct our system using composite order bilinear
groups, which were ﬁrst introduced in [16]. Here, we discuss
how to seek this kind of bilinear group. Generating three
random 𝜅-bit primes 𝑙, 𝑝, 𝑞 and set 𝑁 = 𝑙𝑝𝑞 ∈ ℤ, the group
of points on the curve 𝑦 2 = 𝑥3 + 𝑥 over 𝔽Ψ has a subgroup
of order 𝑁 (denoted by 𝔾𝑁 or 𝔾), where Ψ = 𝑘 ⋅ 𝑁 − 1 =
𝑘 ⋅ 𝑙𝑝𝑞 − 1 is prime and Ψ = 3 (mod 4), 𝑙 is a large prime2
and 𝑘 is the smallest position integer such that Ψ is prime.
Let 𝔾𝑇 be the subgroup of 𝔽∗Ψ2 of order 𝑁 . The modiﬁed
Weil paring on some curves in [17, 15] gives a bilinear map
with the above required properties.

Given a hierarchy ℋ𝑖 = (𝑉𝑖 , ⪯) on the attribute 𝐴𝑖 , the
algorithm chooses a random 𝑚𝑖 in ℤ∗𝑁 ′ and 𝜃𝑖 ∈𝑅 ℤ∗𝑁
as the secrets of 𝐴𝑖 . For each attribute value 𝑣𝑖,𝑘 ∈ 𝑉𝑖 ,
computes
𝑤

where 𝑤𝑖,𝑘

𝜓𝑖,𝑘 = 𝑚𝑖 𝑖,𝑘 (mod 𝑁 ′ ),
∏
= 𝑣𝑖,𝑙 ⪰̸𝑣𝑖,𝑘 ℎ(𝑣𝑖,𝑙 ) (mod 𝑛). Then, it com-

putes 𝑊𝑖,𝑘 = 𝐻 𝜃𝑖 ⋅ 𝑇 𝜓𝑖,𝑘 ∈ 𝔾 for all 𝑣𝑖,𝑘 ∈ 𝑉𝑖 . Finally, it makes
{
} 𝑔𝑝𝑘 = 𝑔𝑝𝑘 ∪ 𝑔𝑝𝑘𝑖 public, where 𝑔𝑝𝑘𝑖 =
(𝑣𝑖,𝑘 , 𝑊𝑖,𝑘 ) 𝑣 ∈𝑉 , and makes 𝑔𝑚𝑘 = 𝑔𝑚𝑘∪{𝑚𝑖 , 𝜃𝑖 }
𝑖
𝑖,𝑘
secret.

GenKey(𝑔𝑚𝑘, 𝜌(𝑖) )→ 𝑔𝑠𝑘𝑖 . Let 𝔸(𝑖) denote the set of attributes of user 𝑖 in 𝜌(𝑖) . Given the master key 𝑔𝑚𝑘,
and a set of attribute assignment 𝜌(𝑖) = {𝐴𝑗 := 𝑣𝑗,𝑘 }𝐴𝑗 ∈𝔸(𝑖) ,
the algorithm chooses a fresh 𝛾𝑖 = ℎ(𝐼𝐷𝑖 ) ∈𝑅 ℤ∗𝑁 and
1

computes 𝐴(𝑖) = 𝐻 𝜁+𝛾𝑖 ∈ 𝔾, where 𝐼𝐷𝑖 is a unique
user’s identity. Then, for each 𝐴𝑗∏← 𝑣𝑗,𝑘 in 𝜌(𝑖) , it
computes 𝜃𝑗 = ℎ(𝐴𝑗 ) and 𝑤𝑗,𝑘 = 𝑣𝑗,𝑙 ⪰̸𝑣𝑗,𝑘 ℎ(𝑣𝑗,𝑙 ) in

Theorem 1. Given a group 𝔾 with order 𝑁 = 𝑙𝑁 ′ = 𝑙𝑝𝑞,
where 𝑁 ′ = 𝑝𝑞. Let 𝔾𝑙 and 𝔾𝑁 ′ denote the subgroups of
order 𝑙 and 𝑁 ′ in 𝔾, respectively. We note that when 𝑔 ∈ 𝔾𝑙
and ℎ ∈ 𝔾𝑁 ′ , 𝑒(𝑔, ℎ) is the identity element in 𝔾𝑇 .

𝑤

ℤ𝑛 , such that 𝜓𝑗,𝑘 = 𝑚𝑖 𝑗,𝑘 (mod 𝑁 ′ )
(𝑖)

𝜁

1

𝐴𝑗,𝑘 = 𝑊 (𝜁+𝛾𝑖 )𝜃𝑗 ⋅ 𝐺 𝜃𝑗 +𝜆𝜓𝑗,𝑘 ∈ 𝔾.
)
(
(𝑖)
Finally, it deﬁnes 𝑔𝑠𝑘𝑖 = 𝐴(𝑖) , {𝜓𝑗,𝑘 , 𝐴𝑗,𝑘 }𝐴𝑗 ∈𝜌(𝑖) and
makes 𝑔𝑚𝑘 = 𝑔𝑚𝑘 ∪ {𝑖, 𝛾𝑖 } secret.

2

We make use of the prime 𝑙 to build a subgroup of 𝔾 (denoted by 𝔾𝑙 ), in which elliptic curve Discrete Logarithm
problem is hard.

37

Encrypt(𝑔𝑝𝑘, 𝜋, 𝑀 )→ 𝐶. Given the public-key 𝑔𝑝𝑘 and an
access policy 𝜋, the encryption algorithm encrypts a
plaintext 𝑀 as follows:

4.3

In this subsection, we need to prove that if the decryptor’s
attribute values satisfy the policy 𝜋, and the decryptor can
obtain the correct message 𝑀 from a ciphertext 𝐶 using our
ABE-AL scheme.

1. chooses a fresh 𝑠 ∈𝑅 ℤ∗𝑁 to computes 𝐶1 = 𝑀 ⋅
𝑉 𝑠 ∈ 𝔾𝑇 and 𝐶2 = 𝐷𝑠 ∈ 𝔾;
2. creates an access tree 𝒯 in terms of 𝜋, invokes
the disperse algorithm (see BSW’s scheme [12]) to
compute Δ𝑠 (A𝑗 ) starting from root 𝑠, and then
for each literal in 𝒯 presented as 𝑣𝑗,𝑘′ ⪯ A𝑗 , the
access constraint is computed by Δ𝑠 (A𝑗 ) and
Δ (A𝑗 )

(𝐸𝑗 , 𝐸𝑗,𝑘′ ) = (𝑇 Δ𝑠 (A𝑗 ) , 𝑊𝑗,𝑘𝑠′

Theorem 2. The ABE-AL scheme is correct.

)

3. outputs 𝐶 = (𝒯 , 𝐶1 , 𝐶2 , {𝐸𝑗 , 𝐸𝑗,𝑘′ }A𝑗 ∈𝒯 ).
Decrypt(𝑔𝑠𝑘𝑖 , 𝐶)→ 𝑀 . We deﬁne Γ(𝑗; 𝑘′ , 𝑘) = {𝑣𝑗,𝑙 : 𝑣𝑗,𝑙 ⪰̸
𝑣𝑗,𝑘 , 𝑣𝑗,𝑙 ર 𝑣𝑗,𝑘′ }. Given a ciphertext 𝐶 = (𝒯 , 𝐶1 , 𝐶2 , 𝐶3 ),
the decryption algorithm decrypts 𝐶 by using the private key 𝑔𝑠𝑘𝑖 as follows:
1. For each attribute 𝐴𝑗 ∈ 𝒯 and the ciphertext
𝐸𝑗,𝑘′ for 𝑣𝑗,𝑘′ ⪯ A𝑗 , computes the following functions for the user’s attribute assignment 𝐴𝑗 ←
𝑣𝑗,𝑘 if {𝑣∣𝑣𝑗,𝑘′ ⪯ 𝑣 ⪯ 𝑣𝑗,𝑘 } ∕= ∅:
𝑓Γ(𝑗;𝑘′ ,𝑘) (𝜓𝑗,𝑘 )

=

(𝜓𝑗,𝑘 )

=

𝑚𝑗

𝑣𝑗,𝑙 ∈Γ(𝑗;𝑘′ ,𝑘)

∏

𝑤

where 𝑤Γ(𝑗;𝑘′ ,𝑘)

∏

𝑣𝑗,𝑙 ⪰̸𝑣

𝑗,𝑘′

Correctness of Construction

ℎ(𝑣𝑗,𝑙 )

ℎ(𝑣𝑗,𝑙 )

′

= 𝑚𝑗 𝑗,𝑘 = 𝜓𝑗,𝑘′ (mod 𝑁 ).
∏
= 𝑣𝑗,𝑙 ∈Γ(𝑗;𝑘′ ,𝑘) ℎ(𝑣𝑗,𝑙 ) ∈ ℤ.

Proof. Firstly, if a decryptor’s attribute value 𝑣𝑗,𝑘 satisﬁes the literal 𝑣𝑗,𝑘′ ⪯ 𝐴𝑗 in the ciphertext, the decryptor
can compute 𝑓Γ(𝑗;𝑘′ ,𝑘) (𝜓𝑗,𝑘 ) for 𝑣𝑗,𝑘′ ⪯ 𝑣𝑗,𝑘 since the value
∏
′
𝑣𝑗,𝑙 ∈Γ(𝑗;𝑘′ ,𝑘) ℎ(𝑣𝑗,𝑙 ) ∈ ℤ𝜓(𝑁 ) can be eﬃciently computed
in ℤ. Otherwise, the decrytor cannot obtain 𝑓Γ(𝑗;𝑘,𝑘′ ) (𝜓𝑗,𝑘 )
due to the RSA assumption, that is, the inverse of ℎ(𝑣𝑗,𝑙 ) is
hard to obtain if 𝑛 = 𝜓(𝑁 ′ ) is unknown.
Next, given the correct value 𝑓Γ(𝑗;𝑘′ ,𝑘) (𝜓𝑗,𝑘 ), we can computes the value 𝑆𝑗 as follows:
)
(
(𝑖)
𝑆𝑗 = 𝑒 𝐴𝑗,𝑘 , (𝑇 Δ𝑠 (A𝑗 ) )𝜓𝑗,𝑘 −𝜓𝑗,𝑘′ ⋅ (𝐻 𝜃𝑗 ⋅ 𝑇 𝜓𝑗,𝑘′ )Δ𝑠 (A𝑗 )
)
(
𝜁
1
Δ𝑠 (A𝑗 )𝜃𝑗
Δ𝑠 (A𝑗 )𝑤𝑗,𝑘
𝜃𝑗 +𝜆𝑤𝑗,𝑘
𝜃𝑗 (𝜁+𝛾𝑖 )
⋅𝐺
,𝐻
⋅𝑇
= 𝑒 𝑊
)
(
𝜁
= 𝑒 𝑊 𝜃𝑗 (𝜁+𝛾𝑖 ) , 𝐻 Δ𝑠 (A𝑗 )𝜃𝑗 ⋅ 𝑇 Δ𝑠 (A𝑗 )𝑤𝑗,𝑘 ⋅
)
(
1
𝑒 𝐺 𝜃𝑗 +𝜆𝑤𝑗,𝑘𝑏 , (𝐻 𝜃𝑗 +𝜆𝑤𝑗,𝑘 )Δ𝑠 (A𝑗 )
)
(
𝜁
= 𝑒 𝑊 𝜃𝑗 (𝜁+𝛾𝑖 ) , 𝐻 Δ𝑠 (A𝑗 )𝜃𝑗 ⋅ 𝑒 (𝐺, 𝐻)Δ𝑠 (A𝑗 )
) (
(
)
𝜁
= 𝑒 𝑊 𝜁+𝛾𝑖 , 𝐻 Δ𝑠 (A𝑗 ) ⋅ 𝑒 𝐺, 𝐻 Δ𝑠 (A𝑗 )
)Δ𝑠 (A𝑗 )
(
𝜁
= 𝑒 𝑊 𝜁+𝛾𝑖 ⋅ 𝐺, 𝐻

2. for each attribute 𝐴𝑗 , computes 𝑆𝑗 as
)
(
𝜓𝑗,𝑘 −𝑓Γ(𝑗;𝑘′ ,𝑘) (𝜓𝑗,𝑘 )
(𝑖)
𝑆𝑗 = 𝑒 𝐴𝑗,𝑘 , 𝐸𝑗
⋅ 𝐸𝑗,𝑘′
)Δ𝑠 (A𝑗 )
(
𝜁
= 𝑒 𝑊 𝜁+𝛾𝑖 ⋅ 𝐺, 𝐻

where 𝑒(𝑊, 𝑇 ) = 1 for 𝑊 ∈ 𝔾𝑙 and 𝑇 ∈ 𝔾𝑁 ′ according to
Theorem 1.
Finally, according to the aggregate algorithm in [12], the
𝜁

decryptor can obtain 𝑆 = 𝑒(𝑊 𝜁+𝛾𝑖 ⋅ 𝐺, 𝐻)𝑠 only if the decryptor’s attribute set is matching the policy tree 𝒯 ; otherwise, the decryptor cannot get 𝑆. When the decrytor gets
𝑆, she/he can also compute the correct message 𝑀 since

3. Given the set of {𝑆𝑖1 , ⋅ ⋅ ⋅ , 𝑆𝑖𝑙 }, invokes the aggregate algorithm (BSW’s scheme [12]) from the
leaf-nodes up to the root-node level-by-level to re𝜁

cover 𝑆 = 𝑒(𝑊 𝜁+𝛾𝑖 ⋅ 𝐺, 𝐻)𝑠 , and then computes

𝑀′

𝐶1 ⋅ 𝑒(𝐶2 , 𝐴(𝑖) )
𝑀 =
.
𝑆
′

=
=

If the user’s attributes satisfy the policy tree, then
she/he can obtain the message 𝑀 ; otherwise, she/he
cannot get any information about 𝑀 .

𝐶1 ⋅ 𝑒(𝐶2 , 𝐴(𝑖) )
𝑆

1
)
(
𝑀 ⋅ 𝑒(𝐺, 𝐻)𝑠 ⋅ 𝑒 𝑊 𝑠𝜁 , 𝐻 𝜁+𝛾𝑖
)
(
= 𝑀.
𝜁
𝑒 𝑊 𝜁+𝛾𝑖 , 𝐻 𝑠 ⋅ 𝑒 (𝐺, 𝐻 𝑠 )

Combining these two conditions, we know that if the decryptor can get the message 𝑀 if and only if the decryptor’s
attribute set is matching the policy tree 𝒯 and the decryptor’s attribute values follow the comparison constraints in
the access policy 𝜋. Hence, if the decryptor can get the
message 𝑀 if and only if the decryptor’s attribute sets satisfy the access policy of the attribute lattices.

Remark. This ABE-AL scheme has an optimum performance of storage and computation. For example, the length
of the user’s private key 𝑔𝑠𝑘𝑖 is directly proportional to the
number of attributes in 𝒜(𝑖) , that is, 𝑂(#𝒜(𝑖) ), where # denotes the number of elements in a set. Similarly, the length
of ciphertexts is directly proportional to the number of literals in an access tree 𝒯 corresponding to 𝜋, that is, 𝑂(#𝒯 ).
More importantly, the length of ciphertexts is unrelated to
the size of candidate attribute values for a certain policy, by
which we usually measure the length of ciphertexts in the
trivial equal matching way. Therefore, the shorter ciphertext commonly means the lower overheads of computation,
so that the ABE-AL scheme also has a lower computational
overheads in the process of encryption and decryption.

5.

SECURITY ANALYSIS

In this section, we analyze the security of comparison
mechanism and the semantic security of ABE-AL scheme.
We lay special stress on exploring the new cryptographic
tools contained in the ABE-AL scheme: forward and backward derivation functions. Therefore, we prove that the

38

Definition 7 (Extended-DDH Assumption). Suppose
𝕊 = (Ψ, 𝑁, 𝔾, 𝔾𝑇 , 𝑒(⋅, ⋅)) be a cryptosystem on bilinear pairing. Given (𝐺, 𝐺𝜏 ), (𝐻, 𝐻 𝜏 ), (𝑒(𝐺, 𝐻)𝜍 , 𝑇 ) for two random
𝜏, 𝜍 ∈ ℤ𝑛 , it is hard to decide whether or not 𝑇 = 𝑒(𝐺, 𝐻)𝜍𝜏 ,
where 𝑔, ℎ are two generators in 𝔾 and 𝔾, 𝔾𝑇 with order 𝑁 .

ABE-AL scheme is semantic security and collusion security.
(Note: due to space limitation, proofs of theorems are provided in an extended report which is available online [18].)

5.1

Forward/Backward Derivation Functions

Let ⟨𝑉, ⪯⟩ denote a poset on 𝑉 = {𝑣1 , 𝑣2 , ⋅ ⋅ ⋅ , 𝑣𝑡 }. In order to construct a cryptographic algorithm for partial order
relation, we need to make use of a cryptographic injective
map 𝜓 : 𝑉 → Ψ, where Ψ = {𝜓1 , 𝜓2 , ⋅ ⋅ ⋅ , 𝜓𝑡 } is a set of
cryptographic values and 𝜓𝑖 = 𝜓(𝑣𝑖 ) for all 𝑖 ∈ [1, 𝑡]. It is
obvious that 𝜓 must be an order-preserving map (also called
monotone functions in order theory), such that there exists
a partial-order relation ⪯ to ensure that ∀𝑣𝑖 , 𝑣𝑗 ∈ 𝑉 , 𝑣𝑖 ⪯ 𝑣𝑗
implies 𝜓(𝑣𝑖 ) ⪯ 𝜓(𝑣𝑗 ). In order to setup such an induced
partial-order relation ⪯ with cryptographic character, it is
easy to consider the “one-way” property in cryptography to
deﬁne this partial-order relation in Ψ, as follows:

It is easy to see that an eDDH problem can be transferred
into a DDH problem in 𝔾𝑇 , that is, given (𝑒(𝐺, 𝐻), 𝑒(𝐺, 𝐻)𝜏 ,
(𝑒(𝐺, 𝐻)𝜍 , 𝑇 ) in 𝔾𝑇 to decide whether 𝑇 = 𝑒(𝐺, 𝐻)𝜍𝜏 . This
means that if DDH problem is hard in 𝔾𝑇 then eDDH problem is also hard in 𝔾, 𝔾𝑇 even if the bilinear pairing exists here. More precisely, we have the following theorem
according to the intractability of distinguishing the two distributions involved in the General Decision Diﬃe-Hellman
Exponent (GDDHE) problem [19]:
Theorem 3 (Lower Bound of eDDH, [19]). Given an
eDDH problem on 𝕊 = (Ψ, 𝑁, 𝔾, 𝔾𝑇 , 𝑒(⋅, ⋅)), for any PPT algorithm 𝒜 that makes a total of at most 𝑞 queries to the oracle computing the group operations in 𝔾, 𝔾𝑇 and the bilinear
2
pairing 𝑒 : 𝔾 × 𝔾 → 𝔾𝑇 , we have 𝐴𝑑𝑣 eDDH (𝒜) ≤ 2(𝑞+10)
.
𝑁

Definition 6. Given a poset ⟨𝑉, ⪯⟩ and an injective function 𝜓 : 𝑉 → Ψ on 𝑉 = {𝑣1 , ⋅ ⋅ ⋅ , 𝑣𝑡 }, a function 𝑓 : Ψ → Ψ
(or 𝑓ˆ : Ψ → Ψ) is called Forward (or Backward) Derivation
Function (FDF/BDF) over a public key 𝑝𝑘 according to the
partial order relation in ⟨𝑉, ⪯⟩. If given the value 𝜓(𝑣𝑖 ), the
function 𝑓 (or 𝑓ˆ) satisﬁes the following conditions:

We prove the semantic security of our scheme under the
assumption of extended-DDH problem. Since this kind of security is concerned with the plaintext which be conﬁdentialityprotected rather than the validity of constraints as described
above, we need only to consider the adaptive attribute lattice against chosen plaintext attacks. Hence, we prove the
Theorem 4, in which the advantage of adversary is at most
4(𝑞+10)2
according to Theorem 3 and 𝜀′ > 2𝜀 .
𝑁

∙ Easy to compute: There exists an eﬃcient algorithm
𝑓 (or 𝑓ˆ) to compute 𝜓(𝑣𝑗 ) from 𝜓(𝑣𝑖 ) in a polynomialtime only if 𝑣𝑖 ⪯ 𝑣𝑗 (or 𝑣𝑖 ર 𝑣𝑗 ). That is,
𝜓(𝑣𝑗 ) ← 𝑓𝑣𝑖 ⪯𝑣𝑗 (𝜓(𝑣𝑖 )) (or 𝜓(𝑣𝑗 ) ← 𝑓ˆ𝑣𝑖 ર𝑣𝑗 (𝜓(𝑣𝑖 )));
∙ Hard to invert: it is infeasible for any probabilistic
polynomial time (PPT) algorithm to compute 𝜓(𝑣𝑗 )
from 𝜓(𝑣𝑖 ) if 𝑣𝑖 ∕⪯ 𝑣𝑗 (or 𝑣𝑖 ∕ર 𝑣𝑗 ), i.e., for any PPT
algorithm 𝒜 and negligible 𝜀,

Theorem 4 (Semantic Security). Assuming that extended Decision Diﬃe-Hellman (eDDH) problem on 𝕊 =
(Ψ, 𝑁, 𝔾, 𝔾𝑇 , 𝑒(⋅, ⋅)) with order 𝑁 = 𝑙𝑁 ′ is (𝑡′ , 𝜀′ )-hard, the
ABE-AL construction is (𝑡, 𝜀)-adaptive attribute lattice against
chosen plaintext attacks (IND-AL-CPA), such that for any
PPT algorithm 𝒜 = (𝒜1 , 𝒜2 ), the success probability of 𝒜
satisﬁes
⎡
⎤
∀(𝑔𝑝𝑘, 𝑔𝑚𝑘) ← 𝑆𝑒𝑡𝑢𝑝(𝜅);
𝒪(ℋ
)
⎢
(𝑀0 , 𝑀1 ) ← 𝒜1 𝑖 (𝑔𝑝𝑘); ⎥
′
⎥ ≤ 𝜀,
Pr ⎢
⎣𝑏 = 𝑏 :
⎦
𝑏 ←𝑅 {0, 1},
′
𝑏 ← 𝒜2 (𝐸𝑛𝑐𝑟𝑦𝑝𝑡(𝑔𝑝𝑘, 𝜋, 𝑀𝑏 ))

Pr[𝒜(𝑝𝑘, 𝜓(𝑣𝑖 )) = 𝜓(𝑣𝑗 ) : 𝑣𝑖 ∕⪯ 𝑣𝑗 ] ≤ 𝜀
(or Pr[𝒜(𝑝𝑘, 𝜓(𝑣𝑖 )) = 𝜓(𝑣𝑗 ) : 𝑣𝑖 ∕ર 𝑣𝑗 ] ≤ 𝜀).
Let 𝕊𝑁 = (Ψ, 𝑁, 𝔾, 𝔾𝑇 , 𝑒(⋅, ⋅)) be an above-mentioned bilinear map system of composite order 𝑁 = 𝑙𝑝𝑞. In this system, we make 𝑁 public and keep 𝑁 ′ = 𝑝𝑞 and 𝑛 = 𝜓(𝑁 ′ )
secret. Let ℎ(⋅) be a public cryptographic hash function.
Given a public poset ℋ = ⟨𝑉, ⪯⟩, we choose a random 𝑀
and deﬁne the map function 𝜓 : 𝑉 → Ψ as
∏

𝜓𝑖 ← 𝜓(𝑣𝑖 ) = 𝑚

𝑣𝑖 ∕⪯𝑣𝑙

ℎ(𝑣𝑙 )

where 𝜀′ > 2𝜀 , 𝑡′ ≥ 𝑡 + 𝑞𝐴 𝑡𝐴 + 𝑞ℎ 𝑡ℎ , and 𝑡𝐴 , 𝑡ℎ denotes the
time of attribute query and hash query, even if the secret
𝑛 = 𝜓(𝑁 ′ ) is known.

∈ ℤ𝑁 ′ ,

∈𝑅 ℤ∗𝑁 ′

for all 𝑣𝑖 ∈ 𝑉 , where 𝑚
is the secret and the public
key is 𝑝𝑘 = (𝑁, 𝔾, ℎ(⋅), ⟨𝑉, ⪯⟩) extracted from 𝕊. In order to
improve the randomness of 𝑣𝑖 , the objective of hash function
ℎ : {0, 1}𝑙 → ℤ∗𝑛 is used to convert the binary string 𝑣𝑖 into
an integer. Note that, we do not require that gcd(ℎ(𝑣𝑖 ), 𝑛) =
1 because there is no need to compute ℎ(𝑣𝑖 )−1 (mod 𝑛).

5.2

6.

RELATED WORK

While the concept of FGAC has been around (introduced
as early as 1996 in ISO 10181-3 and X.509 ACs), it has
gained prominence in research literature with its use in trust
negotiation and credential-based access control in a distributed
system with multiple administrative domains [5, 14, 6]. Goyal
et al. [2] ﬁrst deﬁned the two complimentary forms of ABE,
namely, Key-Policy ABE (KP-ABE) and Ciphertext-Policy
ABE (CP-ABE), and provided a construction for KP-ABE.
Then, Bethencourt et al. [12] gave the ﬁrst construction for
a CP-ABE scheme (short for BSW) in the generic group
model. These schemes supported monotonic boolean encryption policies. Many ABE schemes with varying properties have been proposed since then, for example, schemes
that supported non-monotonic boolean encryption policies

Security Analysis of ABE-AL Scheme

The analysis of FDF/BDF and DCF have showed the security of comparison constraints in our ABE scheme. Now,
we focus on the security of ciphertexts in this scheme. Since
semantic security is a widely used deﬁnition for security in
an asymmetric key encryption algorithm, we will also prove
the semantic security of our scheme under extended Decision Diﬃe-Hellman problem (eDDH) assumption, which is
deﬁned as follows:

39

(e.g., [3]), schemes that supported multiple attribute authorities (e.g., [20]), and so on. Recently, Lewko and Waters [21]
proposed a Multi-Authority ABE system, in which any party
can become an authority and there is no requirement for any
global manager. Also, Waters [22] presented a new methodology for realizing CP-ABE under concrete and noninteractive cryptographic assumptions in the standard model.
Lewko et al. [23] presented a fully secure ABE scheme and
attribute-hiding predicate encryption (PE) scheme for innerproduct predicates by using dual system encryption methodology.

[9]

[10]

7. CONCLUSION
In this paper, we addressed the eﬀective method to simplify the policy-speciﬁed burden of cloud users in the process
of using ABE. Our method is to improve ABE to support
RBAC model, the existing RBAC users, without alterations,
can access their ABE-encrypted data in the cloud. To do it,
we built an eﬃcient ABE with attribute lattice by supporting comparison operations on arbitrary partial ordered sets.
Compared with trivial equal and bit matching in prior solutions, our scheme enhances the expressive capacity of access
policies, decreases the computational overheads, and reduce
the size of ciphertexts and private-keys for attribute-based
encryption.

[11]

8. ACKNOWLEDGMENTS

[15]

[12]

[13]
[14]

The work of Y. Zhu and C.-J. Hu was supported by the
National Natural Science Foundation of China (Project No.
61170264 and No. 10990011) and the National 973 Program
(Project No. 2013CB329606).

9.

[16]

REFERENCES

[17]

[1] F. R. Institute. Personal data in the cloud: A global
survey of consumer attitudes.
http://www.fujitsu.com/downloads/SOL/fai/reports/
fujitsu/personal-data-in-the-cloud.pdf, 2010.
[2] Vipul Goyal, Omkant Pandey, Amit Sahai, and Brent
Waters. Attribute-based encryption for ﬁne-grained
access control of encrypted data. In ACM Conference
on CCS, pages 89–98, 2006.
[3] Rafail Ostrovsky, Amit Sahai, and Brent Waters.
Attribute-based encryption with non-monotonic access
structures. In ACM Conference on Computer and
Communications Security, pages 195–203, 2007.
[4] Shucheng Yu, Cong Wang, Kui Ren, and Wenjing
Lou. Achieving secure, scalable, and ﬁne-grained data
access control in cloud computing. In INFOCOM,
pages 534–542. IEEE, 2010.
[5] Lingyu Wang, Duminda Wijesekera, and Sushil
Jajodia. A logic-based framework for attribute based
access control. In FMSE, pages 45–55, 2004.
[6] Rakeshbabu Bobba, Omid Fatemieh, Fariba Khan,
Arindam Khan, Carl A. Gunter, Himanshu Khurana,
and Manoj Prabhakaran. Attribute-based messaging:
Access control and conﬁdentiality. ACM Trans. Inf.
Syst. Secur., 13(4):31, 2010.
[7] Mikhail J. Atallah, Marina Blanton, Nelly Fazio, and
Keith B. Frikken. Dynamic and eﬃcient key
management for access hierarchies. ACM Trans. Inf.
Syst. Secur., 12(3), 2009.
[8] Sabrina De Capitani di Vimercati, Sara Foresti, Sushil
Jajodia, Stefano Paraboschi, and Pierangela Samarati.
Over-encryption: Management of access control
evolution on outsourced data. In Christoph Koch,
Johannes Gehrke, Minos N. Garofalakis, Divesh

[18]

[19]

[20]

[21]

[22]

[23]

40

Srivastava, Karl Aberer, Anand Deshpande, Daniela
Florescu, Chee Yong Chan, Venkatesh Ganti,
Carl-Christian Kanne, Wolfgang Klas, and Erich J.
Neuhold, editors, VLDB, pages 123–134. ACM, 2007.
Rakeshbabu Bobba, Himanshu Khurana, and Manoj
Prabhakaran. Attribute-sets: A practically motivated
enhancement to attribute-based encryption. In
Michael Backes and Peng Ning, editors, ESORICS,
volume 5789 of Lecture Notes in Computer Science,
pages 587–604. Springer, 2009.
Guojun Wang, Qin Liu, and Jie Wu. Hierarchical
attribute-based encryption for ﬁne-grained access
control in cloud storage services. In Ehab Al-Shaer,
Angelos D. Keromytis, and Vitaly Shmatikov, editors,
ACM Conference on Computer and Communications
Security, pages 735–737. ACM, 2010.
Jin Li, Qian Wang, Cong Wang, and Kui Ren.
Enhancing attribute-based encryption with attribute
hierarchy. MONET, 16(5):553–561, 2011.
John Bethencourt, Amit Sahai, and Brent Waters.
Ciphertext-policy attribute-based encryption. In IEEE
Symposium on Security and Privacy, pages 321–334,
2007.
R.S. Sandhu, E.J. Coyne, H.L. Fenstein, and C.E.
Youman. Role-based access control models. IEEE
Computer, 29(2):38–47, 1996.
Rakeshbabu Bobba, Omid Fatemieh, Fariba Khan,
Carl A. Gunter, and Himanshu Khurana. Using
attribute-based access control to enable
attribute-based messaging. In ACSAC, pages 403–413.
IEEE Computer Society, 2006.
D. Boneh and M. Franklin. Identity-based encryption
from the weil pairing. In Advances in Cryptology
(CRYPTO’01), volume 2139 of LNCS, pages 213–229.
springer-verlag, 2001.
Dan Boneh, Eu-Jin Goh, and Kobbi Nissim.
Evaluating 2-dnf formulas on ciphertexts. In Joe
Kilian, editor, TCC, volume 3378 of Lecture Notes in
Computer Science, pages 325–341. Springer, 2005.
Victor S. Miller. The weil pairing, and its eﬃcient
calculation. J. Cryptology, 17(4):235–261, 2004.
Yan Zhu, Di Ma, Chang-Jun Hu, Shan-Biao Wang,
and Dijiang Huang. How to use attribute-based
encryption to implement role-based access control in
the cloud. http://www-personal.engin.umd.umich.
edu/˜safe/8888/asiaccs-scc-full.pdf, 2013.
Dan Boneh, Xavier Boyen, and Eu-Jin Goh.
Hierarchical identity based encryption with constant
size ciphertext. In Advances in Cryptology
(EUROCRYPT’2005), volume 3494 of LNCS, pages
440–456, 2005.
Melissa Chase and Sherman S. M. Chow. Improving
privacy and security in multi-authority attribute-based
encryption. In ACM Conference on Computer and
Communications Security, pages 121–130, 2009.
Allison B. Lewko and Brent Waters. Decentralizing
attribute-based encryption. In Kenneth G. Paterson,
editor, EUROCRYPT, volume 6632 of Lecture Notes
in Computer Science, pages 568–588. Springer, 2011.
Brent Waters. Ciphertext-policy attribute-based
encryption: An expressive, eﬃcient, and provably
secure realization. In Public Key Cryptography, pages
53–70, 2011.
Allison B. Lewko, Tatsuaki Okamoto, Amit Sahai,
Katsuyuki Takashima, and Brent Waters. Fully secure
functional encryption: Attribute-based encryption and
(hierarchical) inner product encryption. In
EUROCRYPT, pages 62–91, 2010.

3430

IEEE TRANSACTIONS ON COMPUTERS,

VOL. 64,

NO. 12,

DECEMBER 2015

Efficient Attribute-Based Comparable
Data Access Control
Zhijie Wang, Student Member, IEEE, Dijiang Huang, Senior Member, IEEE, Yan Zhu, Member, IEEE,
Bing Li, Student Member, IEEE, and Chun-Jen Chung, Student Member, IEEE
Abstract—With the proliferation of mobile devices in recent years, there is a growing concern regarding secure data storage, secure
computation, and fine-grained access control in data sharing for these resource-constrained devices in a cloud computing
environment. In this work, we propose a new efficient framework named Constant-size Ciphertext Policy Comparative Attribute-Based
Encryption (CCP-CABE) with the support of negative attributes and wildcards. It embeds the comparable attribute ranges of all the
attributes into the user’s key, and incorporates the attribute constraints of all the attributes into one piece of ciphertext during the
encryption process to enforce flexible access control policies with various range relationships. Accordingly, CCP-CABE achieves the
efficiency because it generates constant-size keys and ciphertext regardless of the number of involved attributes, and it also keeps the
computation cost constant on lightweight mobile devices. We further discuss how to extend CCP-CABE to fit a scenario with multiple
attribute domains, such that the decryption proceeds from the least privileged attribute domain to the most privileged one to help protect
the privacy of the access policy. We provide security analysis and performance evaluation to demonstrate their efficiency at the end.
Index Terms—Comparative attribute based encryption, constant, dual encryption, dual decryption, privacy-preservation

Ç
1

INTRODUCTION

D

access control has been an increasing concern in
the cloud environment where cloud users can compute, store and share their data. Cloud computing provides
a scalable, location-independent and high-performance
solution by delegating computation tasks and storage into
the resource-rich clouds. This overcomes the resource limitation of users with respect to data storage, data sharing
and computation, especially when it comes to mobile devices considering their limitations of processing hardware,
storage space, and battery life. However, in reality, the
cloud is usually not fully trusted by data owners; moreover,
the cloud service providers may be tempted to peek at
users’ sensitive data and produce trapdoors in computation
for commercial interests. To enforce secure data access
control on untrusted cloud servers, traditional methods
(e.g., AES [1] ) encrypt data before storing it in the cloud,
but they incur high key-management overhead to provide
dynamic group-based access control and significantly
increases the system complexity.
Ciphertext-policy attribute-based encryption (CP-ABE)
[2] has been proposed to provide fine-grained access control
for dynamic group formation in cloud-based data storage
solutions. It enables the data owners to create access policies
by designating attribute constraints and embedding the
ATA



Z. Wang, D. Huang, B. Li, and C.-J. Chung are with the Department of
Computer Science, Arizona State University, Tempe, AZ.
E-mail: {zwang134, dijiang, bingli5, cchung20}@asu.edu.
 Y. Zhu is with the Department of Computer Science, University of Science
and Technology Beijing, Beijing, China. E-mail: bingli5@asu.edu.
Manuscript received 13 Feb. 2014; revised 1 Jan. 2015; accepted 6 Jan. 2015.
Date of publication 5 Feb. 2015; date of current version 11 Nov. 2015.
Recommended for acceptance by K. Li.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identifier below.
Digital Object Identifier no. 10.1109/TC.2015.2401033

data access policies into the ciphertext, such that any data
user has to satisfy the corresponding attributes to access the
data. In some cases, the access control policy takes the form
of range constraints for the corresponding attributes. Nonetheless, CP-ABE is designed to handle descriptive attributes, and it needs to convert comparative attributes into
a bit-wise monotone access tree structure to enforce expressive access control of encrypted data. Green et al. [3]
devised new methods for outsourcing decryption of ABE
ciphertexts with significantly reduced decryption cost, but
their encryption cost grows with the number of involved
attributes, and bitwise comparison has to be adopted for
comparison. Generally speaking, most existing CP-ABE
schemes suffer several drawbacks:


They perform cryptographic comparison operations
(such as  and ) by following a series of bit-wise
equal matching (e.g., 10*11*01) in a hierarchical tree
structure, which involves a substantial amount of
computational cost.
 They do not support effective range comparisons
(e.g., 2  hours  4; 3  level  5). In fact, an attribute could have a collection of possible values in
a sequential partial order. In other words, certain
attributes may take the form of range values.
To address the issues stated above, we propose a
new comparative attribute-based encryption scheme CCPCABE. A telemedicine example in Fig. 1 is used to illustrate
how it works in a real-world scenario. A patient periodically
uploads his/her health records to the medical information
service delivered by a cloud provider, and healthcare
professionals in the designated clinic can monitor his/her
health status based on his/her health records. This patient
has a policy that only healthcare professionals with
positions higher than Nurse can access his/her health info

0018-9340 ß 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

Fig. 1. Two-dimensional attribute ranges in the telemedicine Example.

between time tj and tk . Thus,
V the data access can be specified by a policy P ¼ ½A1 A2 , where A1 ¼ rank and
A2 ¼ time are two attributes, and each attribute has a
certain range, where Rank ¼ {Nurse, Attending Doctor,
Senior Doctor, Clinic Director} and Time ¼ ftx jx 2 Zg.
Correspondingly, a Senior Doctor who has a higher rank can
access the data if he/she has been authorized to the time
interval that is contained in ½tj ; tk . Using CP-ABE scheme,
the temporal comparison relies on bit-matching and incurs
large sizes of data users’ keys and overhead, resulting in
high computational costs in encryption and decryption.
Moreover, strict equal matching is not compliant with
the ubiquitous partial order relations. Zhu et al. [4] first
proposed a flexible comparison-based encryption (CBE)
scheme to address this problem. It utilizes integer comparison to derive designated attribute range bound, and relies
on a hierarchical attribute access tree without the support of
negative attributes and wildcards. This results in linearly
increasing computation and communication overhead with
respect to the number of attributes on the side of data owners and data users, which is not suitable for resourceconstrained mobile devices.
The proposed CCP-CABE integrates all attribute ranges
as a single encryption parameter and compares data users’
attribute ranges against attribute constraints of the access
policy designated by the data owner through a multi-dimensional range derivation function (MRDF). Consequently,
the communication overhead is substantially reduced, as
the packet size is constant regardless of the number of attributes. Furthermore, intensive encryption and decryption
operations can be delegated to a dedicated cloud encryption/decryption service. As a result, the computation cost of
resource-limited data owners and data users remains minimal. These features make the CCP-CABE approach suitable
for data sensing and retrieval services running on lightweight mobile devices or sensors. In addition, we devise an
extended CCP-CABE (ECCPCABE) to enforce the access
control policy written over attributes across various attribute
domains. The presented schemes are secure against key collusion attacks (KCAs) from multiple data users and chosen
delegation key and ciphertext attacks (CDKCAs) from honest-but-curious cloud providers. In summary, our contributions are presented as follows:


CCP-CABE is a new comparative attribute-based
encryption scheme to provide efficient and secure

3431

access control in a cloud-based security service
model. It leverages MRDF to compare data users’
attribute ranges against attribute constraints designated by the data owner.
 CCP-CABE can predefine different range intersection relationships on different attributes. It also
incorporates wildcards and negative attributes so it
can handle more expressive types of data access
control policies.
 CCP-CABE minimizes the communication overhead
to constant size regardless of the number of attributes and comparison ranges. It also minimizes the
computation overhead on resource-constrained data
owners and data users irrespective of the number of
attributes due to secure computation delegation. The
evaluation shows that the computation overhead of
mobile devices remains small and constant, which is
independent of the comparison ranges and the number of user attributes.
 We extend CCP-CABE to enforce the access control
over multiple attribute domains. The encrypted
access policy prioritizes the level of confidentiality
of different attribute domains, and the data users
can only start decryption from the least privileged
domain to the most privileged one to help protect
the privacy of the access policies. We demonstrate
that its communication and computation overhead
only grows with the number of trust authorities
rather than the number of attributes.
The remainder of this paper is organized as follows.
Section 2 describes the system overview of CCP-CABE, its
mathematical preliminaries and related security model.
Section 3 presents CCP-CABE construction, its file structure
and the application scenarios. We further extend CCP-CABE
to fit the scenario with multiple attribute domains in Section
4. Section 5 analyzes the security strength and Section 6
assesses their performance. Section 7 discusses the related
work, and Section 8 concludes the presented solutions.

2

CCP-CABE SYSTEM OVERVIEW,
PRELIMINARIES AND SECURITY MODEL

2.1 CCP-CABE Application Framework
The CCP-CABE framework, as shown in Fig. 2, consists of a
central trust authority (TA), e.g., the government health
agency, a trusted encryption service provider (ESP), a cloud
provider, data owners (e.g., patients) and data users (e.g.,
healthcare professionals). The Trust Authority issues public
and private keys to data users through secure channels
and publishes global parameters. The trusted ESP has enormous computational power. If a data owner is constrained
by computational resource, the ESP can perform part of
data encryption for the data owner by generating the partially encrypted header HeP based on the data owner’s access
control policy regarding attribute constraints, such that the
data owner can perform further encryption requiring minimum computational power. In the telemedicine example,
the patients have resource-limited biometric devices, and
they need to distribute electronic health records (EHRs) to
different storage servers hosted by cloud providers for
healthcare professionals in remote places to review. The

3432

IEEE TRANSACTIONS ON COMPUTERS,

VOL. 64,

NO. 12,

DECEMBER 2015

Fig. 2. The CCP-CABE framework with central trust authority.

Fig. 3. The range relations.

patients can specify different access policies with respect to
healthcare professionals’ attribute ranges (e.g., positions,
service duration). To protect the patients’ privacy, the government health agency issues keys to both patients and
healthcare professionals. In this setup, the data owners can
embed their access policies into the encrypted EHRs, and
only the eligible healthcare professionals can decrypt the
data based on their keys corresponding to the comparative
attribute ranges.

assume that all elements in Ti are in ascending order
such that 0  ti;1  ti;2      ti;ni  Z, where Z is
the maximum integer. Note that each attribute has a
limited number of optional integer values in realworld scenarios, and so it is easy to find an integer Z
such that Z  ti;ni for any Ai 2 A.
 Let t	Ai ðti;j ; ti;k Þ represent the range constraint of
attribute Ai on ½ti;j ; ti;k  where 1  j  k  ni , i.e.,
ti;j  t	Ai  ti;k .
V
 Let P ¼ f t	Ai j8Ai 2 A; ti;j  t	Ai  ti;k g, where 1 
j  k  ni be the policy defined by the data owner
over the set of attributes A and it is expressed as a
series of AND
V operations.
 Let Lu ¼ f t	Ai j8Ai 2 A; ti;a  t	Ai  ti;b g, where 1 
a  b  ni as the attribute ranges possessed by a
data user u over the set of attributes A.
As illustrated in Fig. 3, the data owner can apply any one
of the following attribute range relations fR; R0 ; R
 ; R	 g
over each attribute Ai , such that the data user u’s attribute
ranges Lu has to satisfy the designated attribute range relations over all the attributes to access the resources. R implies
that the attribute ranges Lu should completely satisfy P
V
on Ai , and it holds if ð½ti;j ; ti;k  n ½ti;a ; ti;b  ¼ ;Þ ð½ti;j ; ti;k  \
½ti;a ; ti;b  6¼ ;Þ. On the contrary, R0 implies that the attribute
ranges Lu only needs to partially satisfy P on Ai , and it
V
holds if ð½ti;j ; ti;k  n ½ti;a ; ti;b  6¼ ;Þ ð½ti;j ; ti;k  \ ½ti;a ; ti;b  6¼ ;Þ.
In addition, R
 implies that the access control policy P
designates the eligible data user must not own attribute Ai ,
which is classified as a negative attribute. Note that if the
data user u does not own attribute Ai , he/she will be
assigned a dummy integer value ti;0 , which is distinct from
the other attribute integer values, such that ti;a ¼ ti;b ¼ ti;0 ,
and the system places ti;0 ahead of ti;1 to derive fti;0 ; ti;1 ; . . . ;
ti;ni g in order to follow the ascending order. Accordingly,
there exists ti;j ¼ ti;k ¼ ti;0 in access control policy P. Consequently, R
 is satisfied if and only if ½ti;j ; ti;k  ¼ ½ti;a ; ti;b  ¼
fti;0 g holds.

2.2

Definition of Attribute Range and Problem
Formulation
In Table 1, we list the symbols used in CCP-CABE. The comparison operations are shown as below:


Let A ¼ fA1 ; . . . ; Am g be a finite set of attributes,
and each attribute Ai 2 A contains a set of attribute
values Ti ¼ fti;1 ; ti;2 ; . . . ; ti;ni g consisting of discrete
integer values, where ni is the number of integer
values for attribute Ai . Without loss of generality, we
TABLE 1
Notations for CCP-CABE

Notation

Description

A; Ai
the whole attribute set and its ith attribute
m
the number of attributes in A
ni
the number of attribute values in Ai
P
the data owner’s access control policy
the data user u’s attribute ranges
Lu
R; R0 ; R
 ; R	 four different attribute range relationships
ti;0
the dummy attribute value assigned to a user
if he/she does not possess attribute Ai
ti;ni
the maximum attribute value in Ai
½ti;a ; ti;b 
the attribute range on attribute Ai possessed
by a data user
½ti;j ; ti;k 
the range constraint on attribute Ai defined by P
i
the bound values associated with ½ti;j ; ti;k ;
ri ; r
it depends on the range relation over Ai
F :V !V
Multi-dimensional Range Derivation Function

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

Furthermore, R	 implicates that the data owner does not
care about attribute Ai , then there exist ti;j ¼ ti;0 and
ti;k ¼ tt;ni , and we classify this attribute as a wildcard. If the
data owner specifies Ai as a wildcard, then ½ti;j ; ti;k  becomes
½ti;0 ; ti;ni  and it always holds whatever the data user u’s
attribute range on Ai is. It implies ½ti;j ; ti;k  \ ½ti;a ; ti;b  6¼ ;
always holds if ½ti;a ; ti;b  6¼ ;. In this manner, CCP-CABE is
extended to be a comprehensive scheme to handle different
range relations, and we will explain it further in detail
in Section 3.

2.3 Composite Order Bilinear Map
Our system is based on the same bilinear map group system
SN ¼ ðN ¼ pq; G; GT ; eÞ used in [4] where N ¼ pq is the
RSA modulus, p and q are two large primes. We have G and
GT as two cyclic groups with composite order n, where
n ¼ sn0 ¼ s1 s2 p0 q0 and p; q; p0 ; q0 ; s1 ; s2 are all secret large
primes. e denotes a computable bilinear map e : G  G !
GT with the following properties:
Bilinearity: 8g; h 2 G; 8a; b 2 Z; eðga ; hb Þ ¼ eðg; hÞab ;
Non-degeneracy: g and h are the generators of G,
eðg; hÞ 6¼ 1;
 Computability: eðg; hÞ is efficiently computable.
We have Gs and Gn0 as the subgroups of order s and n0 in
G respectively, and eðg; hÞ becomes the identity element
in GT if g 2 Gs , h 2 Gn0 . As an example, suppose w is the
0
generator of G, then wn is the generator of Gs and ws is the
0
generator of Gn0 . Assume g ¼ ðwn Þ%1 and h ¼ ðws Þ%2 for



set U into V as shown below:
cðfti;j ; ti;k gAi 2A Þ;
Q
Z
ti;k
t
 i;j m
where cðfti;j ; ti;k gAi 2A Þ ¼ ’ Ai 2A i i
2 Gn0 :
ingly, we can define MRDF as shown below:
vfti;j ;ti;k gA 2A
i

1)

i;k

i

t0i;k gAi 2A Þ if ti;j  t0i;j and ti;k  t0i;k hold for each Ai 2 A,
where  denotes the partial-order relations.
To construct a cryptographic MRDF for integer comparisons over multiple attributes, we leverage the multiplicative
group Gn0 of RSA-type composite order n0 ¼ p0 q0 , where p0
and q0 are two large primes. A random generator ’ is
0
selected in the group Gn0 where ’n ¼ 1. Then we generate
two sets fi ; mi gAi 2A where i ; mi 2 Z	n0 , and each i ; mi is
relatively prime to all the other elements in fi ; mi gAi 2A
with sufficiently large order for all Ai 2 A. Consequently,
we can define the mapping function cðÞ to map the integer

The function F can be computed in polynomial time, i.e.,
if ti;j  t0i;j ; ti;k  t0i;k ; 8Ai 2 A, then vft0 ;t0 gA 2A
Ffti;j t0

;t t0 g
i;j i;k i;k Ai 2A

2)

ðvfti;j ;ti;k gA 2A Þ.

i;j i;k

i

i

It is infeasible for any probabilistic polynomial time
(PPT) algorithm to derive vft0i;j ;t0 gA 2A from vfti;j ;ti;k gAi 2A
i;k i
if there exists ti;j > t0i;j or ti;k < t0i;k for some Ai 2 A.

Specifically, F ðÞ takes the form as follows:
vft0

;t0 g
i;j i;k Ai 2A

ðvfti;j ;ti;k gA 2A Þ;

Ffti;j t0

;t t0 g
i;j i;k i;k Ai 2A

i

where
Ffti;j t0

;t t0 g
i;j i;k i;k Ai 2A

¼ ðvfti;j ;ti;k gA 2A Þ

ðvfti;j ;ti;k gA 2A Þ
Q

i



t0i;j 
ti;j ti;k 
t0i;k

Ai 2A i

mi

i

t 
ti;j ti;k 
ti;k
 Q
Q
 i;j
mi
Z
t
t
Ai 2A i
ii;j mi i;k
¼ ’ Ai 2A
0

0
%2 sn

2.4 Multi-Dimensional Range Derivation Function
We propose multi-dimensional range derivation functions
to select the lower-bound and upper-bound integer values
ti;j ; ti;k out of the possible attribute range over each attribute
Ai 2 A, and derive the integer set U ¼ fti;j ; ti;k gAi 2A . To
construct a cryptographic algorithm for range comparison
over multiple dimensions (or attributes), we define the
order-preserving cryptographic map c : U ! V for MRDF
where V takes the form of vfti;j ;ti;k gA 2A . Note that vfti;j ;ti;k gA 2A
i
i
is a cryptographic value reflecting the integer values of
range bounds over each attribute Ai 2 A. The orderpreserving cryptographic map c implies that there exists
vfti;j ;ti;k gA 2A ¼ cðfti;j ; ti;k gAi 2A Þ  vft0 ;ti;k gA 2A ¼ cðft0i;j ; ti;k gAi 2A Þ
i;j
i
i
and vfti;j ;ti;k gA 2A ¼ cðfti;j ; ti;k gAi 2A Þ  vfti;j ;t0 gA 2A ¼ cðfti;j ;
i

Accord-

Definition 1 (Multi-dimensional range derivation function). A function F : V ! V based on U is defined as a multidimensional range derivation function if it satisfies the following two conditions:

some %1 , %2 , it holds that eðg; hÞ ¼ eðw ; w Þ ¼ 1. Our systems leverage the orthogonality between Gn0 and Gs and
keep N; n; s; p; q; p0 ; q0 secret.
%1

3433

0

Q
Z
t0i;k
t0
 i;j m
¼ ’ Ai 2A i i
2 Gn0 :
Note that the ordering relationships among the integer
values ti;j ; ti;k ; t0i;j ; t0i;k can be varied depending on the designated range relation Ri over each attribute Ai , which we
will explain in detail in Section 3. Furthermore, it is infeasi
1
ble to compute 
1
i and mi in polynomial time due to the
0
secrecy of n under the RSA assumption. In addition, each
i is relatively prime to all the other elements in fi gAi 2A ,
and each mi is also relatively prime to all the other elements
in fmi gAi 2A . Consequently, it is infeasible to compute
vfti;j gA 2A from vfti;k gA 2A , or derive vfti;k gA 2A from vfti;j gA 2A if
i
i
i
i
there exists ti;j  ti;k for some Ai 2 A.

2.5 CCP-CABE Overview
The CCP-CABE scheme is comprised of six algorithms as
shown below:




Setupðk; AÞ. The Setup algorithm takes input of the
security parameter k and the attribute set A. It outputs the global parameters GP for encryption and
the master key MK;
KeyGenðGP; MK; u; Lu Þ. The KeyGen algorithm
takes input of global parameters GP , master key
MK, data user u’s ID and corresponding attribute
ranges Lu as the input. It outputs the delegation key
DKu and the private key SKu for each data user;

3434









IEEE TRANSACTIONS ON COMPUTERS,

EncDelegateðGP; MK; PÞ. The EncDelegate algorithm takes GP , MK, and the the data owner’s access
control policy P as the input. It outputs the partially
encrypted header HeP for the data owner to perform
further encryption;
EncryptðGP; HeP Þ. The Encrypt algorithm takes GP
and HeP as the input. It creates a secret ", outputs the
session key K" and the ciphertext header HP such
that only the data users with attribute ranges satisfying the access control policy can decrypt the message;
DecDelegateðHP ; DKu ; Lu ; PÞ. The DecDelegate algorithm takes input of the ciphertext header HP , data
user u’s delegation key DKu and the access control
policy P, and outputs the partially decrypted header
H^P to the data user for further decryption;
DecryptðSKu ; H^P Þ. The Decrypt algorithm takes
input of the partially decrypted ciphertext header
H^P and the data user’s private key SKu . It performs
further decryption over H^P with SKu , and outputs
the session key ek to decrypt the encrypted message.

2.6 Security Model
In our framework, the TA and the ESP are assumed to be fully
trustworthy. However, data users attempt to obtain unauthorized access to data beyond their privileges, and the cloud
provider is considered honest-but-curious. Hence, our framework needs to be resistant against the following attacks:
Key collusion attack. In a normal case, each data user possesses one pre-assigned delegation key and one private key
from TA based on his/her attribute ranges. However, malicious data users attempt to derive new private keys
to reveal data protected by a multi-dimensional attribute
range policy by collusion. The security under KCA is evaluated by the game below:
Setup. The challenger runs Setup algorithm, gives the
adversary the global parameters and keeps private keys.
Learning. The adversary queries the challenger on behalf
of a selected number of users ful g1lU with attribute ranges
fLul g1lU by invoking KeyGen algorithm. The challenger
responds fSKLul ; DKLul g1lU to the adversary in return.
Challenge. The challenger sends a challenge on behalf of
user u0 to the adversary.
Response. the adversary outputs SKLu0 with respect to
user u0 . If SKLu0 is valid and can bring more privileges for
user u0 , then the adversary wins the game.
Chosen delegation key and ciphertext attack. The honest-butcurious cloud providers comply with protocols and output
the correct results, but they are tempted to derive the information from the ciphertext header with the delegation keys
from the data users. The security under CDKCA is evaluated by the following game:
Setup. The challenger runs Setup algorithm, gives the
adversary the global parameters and keeps private keys.
Learning. The adversary queries the challenger on behalf
of a polynomial number of eligible users ful g1lU with attribute ranges fLul g1lU and P by invoking the DecDelegate
algorithm. Note all the users are able to derive session key
from the ciphertext header. The challenger responds with
delegation keys fDKLul g1lU to the adversary in return.

VOL. 64,

NO. 12,

DECEMBER 2015

Challenge. The challenger sends a challenge ciphertext
header to the adversary. The ciphertext header can be
decrypted by the users mentioned above with their private keys.
Response. The adversary outputs the session key from the
challenge ciphertext header. If the session key is valid, the
adversary wins the game.

3

CONSTRUCTION OF CCP-CABE

In this section, we present the six algorithms of CCP-CABE
scheme in detail as follows:

3.1 System Setup (Setup)
The central TA first chooses a bilinear map system
SN ¼ ðN ¼ pq; G; GT ; eð; Þ of composite order n ¼ sn0 and
two subgroups Gs and Gn0 of G. Next, it selects random gen 2 Gn0 such that there exist
erators w 2 G, g 2 Gs and ’; ’
 Þ ¼ 1 but eðg; wÞ 6¼ 1. The TA needs to choose
eðg; ’Þ ¼ eðg; ’
i ; mi 2 Z	n0 over each attribute Ai 2 A, and ensure that each
i ; mi is relatively prime to all the other elements in
fi ; mi gAi 2A . It also employs a cryptographic hash function
H : f0; 1g	 ! G to convert a binary attribute string into
a group element 2 G. In addition, the TA picks random
1

exponents a; b 2 Z	n and generates h ¼ wb ; h ¼ gb and
eðg; wÞa . Consequently, the TA keeps its master key
MK ¼ ðp; q; n0 ; a; bÞ and publishes the global parameters
GP ¼ ðS; g; h; w; h; eðg; wÞa ; ’; fi ; mi gAi 2A ; HðÞÞ:

3.2 Key Generation (KeyGen)
Each user u is labelled with a set of attribute ranges
Lu ¼ f½ti;a ; ti;b gAi 2A with ti;a  ti;b over all attributes. Specially, if the user u does not possess the attribute Ai , then
the TA sets ti;a ¼ ti;b ¼ ti;0 . The TA selects unique integers
t u ; ru 2 Z to distinguish u from other users, and it concatenates the binary string forms of all the attributes and derive
A ¼ ðA1 jjA2 jj    jjAm Þ. Consequently, for each user u with
attribute ranges Lu , his/her private key SKu can be computed as
  aþtu


ðuÞ
ðuÞ
ðuÞ
¼ g b ; gtu ðHðAÞÞru ; wru ;
SKu ¼ D0 ; D1 ; D2
and his/her delegation key is computed as
Q
Z
ti;b
t
r
 i;a m
DKu ¼ ðvLu Þru ¼ ’ u Ai 2A i i
;
Q
ti;a Z
ti;b
 m
where vLu ¼ vfti;a ;ti;b gA 2A ¼ ’ Ai 2A i i
2 Gn0 . Afteri
wards, the keys are transmitted to the user u through secure
channels.

3.3 Encryption Delegation (EncDelegate)
The data owner first defines the access control policy of
i gAi 2A over all attributes,
attribute constraints as P ¼ fri ; r
and sends P to the trusted ESP to delegate the major part of
i g correencryption overhead if necessary. Note that fri ; r
sponds to the attribute constraint ½ti;j ; ti;k  if the policy does
not designate negative attributes or wildcards over Ai .
i based on the
Upon receiving P, the ESP first sets ri and r

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

3435

Fig. 4. File Structure in CCP-CABE.

range relationship Ri designated for the attribute Ai , respectively, as shown below:
i ¼ ti;k if the range relationship
sets ri ¼ ti;j and r
R is designated for the attribute Ai ;
i ¼ ti;j if the range relationship
 sets ri ¼ ti;k and r
R0 is designated for the attribute Ai ;
i ¼ ti;0 if the range relationship
 sets ri ¼ ti;0 and r
R
 (i.e., negative attribute) is designated for the
attribute Ai ;
i ¼ ti;0 if the range relationship R
 sets ri ¼ ti;ni and r
(i.e., wildcard) is designated for the attribute Ai .
Afterwards, the ESP computes vP ¼ vfri ;ri gA 2A ¼
i
Q
r Z

r
i i mi i
A
2A
i
’
. Accordingly, it generates the partially
encrypted header HeP as shown below:


HeP ¼ ðvP w; HðAÞÞ;
and sends it to the data owner for further encryption.

3.4 Encryption (Encrypt)
Upon receiving the partially encrypted header HeP , the data
owner generates a random secret " 2 Zn . Next, it computes
C ¼ h" and the session key ek ¼ eðga ; wÞ" . To improve
efficiency, it first generates a random key ak to encrypt the
target message and uses ek to encrypt the random key ak
with symmetric key encryption Eek ðÞ. Finally, it outputs the
ciphertext header
HP ¼ ðEek ðakÞ; C; E" ; E"0 Þ
¼ ðEek ðakÞ; h" ; ðvP wÞ" ; ðHðAÞÞ" Þ;
and transmits HP and the encrypted message along with P
to the cloud for storage.

3.5 Decryption Delegation (DecDelegate)
The data user u delegates his/her delegation key DKu and
claimed attribute ranges Lu to the cloud. Upon receiving
DKu and Lu , the cloud checks if Lu satisfies P over all attributes. If so, it computes ðvP Þru from ðvLu Þru as shown below:
ðvP Þru ¼ ðvfri ;ri gA 2A Þru
i

¼ Ffti;a ri ;ti;b ri gA 2A ððvLu Þru Þ
i

¼ Ffti;a ri ;ti;b ri gA 2A ððvfti;a ;ti;b gA 2A Þru Þ
i
i
Q
t 

r
r 
t
i i i;a mii;b i
ru
¼ ððvfti;a ;ti;b gA 2A Þ Þ Ai 2A
i
Q
Z
ti;b Q
t 

r
t
r 
t
r
 i;a m
 i i;a mii;b i
¼ ð’ u Ai 2A i i
Þ Ai 2A i
Q
r Z

ri
 im
¼ ð’ Ai 2A i i Þru 2 Gn0 ;

Fig. 5. Different application scenarios.

where vP ¼ vfri ;ri gA 2A and vLu ¼ vfti;a ;ti;b gA 2A . Afterwards,
i
i
the cloud sends H^P ¼ ððvP Þru ; HP Þ along with the ciphertext
to the data user for further decryption.

3.6 Decryption (Decrypt)
Upon receiving H^P from the cloud, the data user first comðuÞ
putes ðvP Þru D2 ¼ ðvP wÞru . Next, it computes

 ðuÞ
e D1 ; E"
Gð"Þ
eððvP wÞru ; E"0 Þ
eðgtu ðHðAÞÞru ; ðvP wÞ" Þ
¼
eððvP wÞru ; ðHðAÞÞ" Þ
eðgtu ; ðvP wÞ" Þ  eððHðAÞÞru ; ðvP wÞ" Þ
¼
eððvP wÞru ; ðHðAÞÞ" Þ
tu
¼ eðg ; ðvP Þ" Þ  eðgtu ; w" Þ
¼ eðgtu ; w" Þ;
where eðgtu ; ðvP Þ" Þ ¼ 1. Accordingly, the data user can
derive the session key ek as shown below:
aþt u 


ðuÞ 
e C; D0
e ðwb Þ" ; g b
¼
¼ eðga ; wÞ" :
ek ¼
Gð"Þ
eðg; wÞtu "
With the session key ek, the data user can first retrieve
the random key ak by decrypting Eek ðakÞ and then derive
the encrypted data with ak.

3.7 File Structure
In CCP-CABE, each file stored in the cloud must be secured
by the access policy specified by the data owner, and the file
structure consists of the access policy, cipher header and the
encrypted data as illustrated in Fig. 4. Specifically, the data
of the file should be encrypted by a session key ek generated
by the data owner using symmetric encryption, and only the
eligible data user whose attribute constraints Lu satisfies
the access control policy P can derive the session key by
his/her delegation/private key pair. Note that the access
policy can be compressed into data with a negligible size.

3436

IEEE TRANSACTIONS ON COMPUTERS,

3.8 Application Scenarios
In this section, we use simple examples to illustrate how
CCP-CABE can adapt for multiple different range relationships as shown in Fig. 5.

VOL. 64,

NO. 12,

vLu ¼ vfti;a ;ti;b gA 2A
i
Q
Z
t
t
ii;a mi i;b
¼ ’ Ai 2A
t1;0 t2;1 t3;3 Z
t1;0 Z
t2;4 Z
t3;3
2 3 m 1
m2
m3

¼ ’1

3.8.1 Scenario I
In the telemedicine example, the data owner applies the
range relationship R; R0 over attributes A1 ; A2 respectively
in the access control policy P. The “Time” attribute takes
value out of the integer set ft1;0 ; t1;1 ; t1;2 ; t1;3 ; t1;4 ; t1;5 g representing different timestamps, and the “Rank” attribute takes
value from the integer set ft2;0 ; t2;1 ; t2;2 ; t2;3 ; t2;4 g representing
different positions in a clinic. It can be learnt that the attribute ranges of the data user are Lu ¼ f½t1;1 ; t1;5 ; ½t2;3 ; t2;3 g,
and the attribute range constraints designated by the data
owner are f½t1;2 ; t1;4 ; ½t2;1 ; t2;4 g. The CCP-CABE operations
associated with MRDF are listed below. The algorithm
KeyGen computes:

vLu ¼ vfti;a ;ti;b gA 2A ¼ ’

Q

Z
t
t
 i;a mi i;b
Ai 2A i

t1;1 t2;3 Z
t1;5 Z
t2;3
2 m 1
m2

:

The algorithm EncDelegate computes:

vP ¼ vfri ;ri gA 2A ¼ ’

Q

r Z

ri
 im
Ai 2A i i

i

t1;2 t2;4 Z
t1;4 Z
t2;1
2 m1
m2

¼ ’1

:

The algorithm DecDelegate computes:
ðvP Þru

t

where D ¼ 11;2

Ffti;a ri ;ti;b ri gA 2A ððvLu Þru Þ
i

t

t

Z
t1;5 Z
t2;3
D
m2

¼ ð’

ru 11;1 22;3 m1

¼ ð’

t
Z
t
t
Z
t
11;2 22;4 m1 1;4 m2 2;1 ru

vP ¼ vfri ;ri gA 2A
i
Q
r Z

ri
 im
¼ ’ Ai 2A i i
t1;0 t2;2 t3;4 Z
t1;0 Z
t2;3 Z
t3;0
2 3 m1
m2
m3

¼ ’1

Þ

Þ ;


t1;1 t2;4 
t2;3 t1;5 
t1;4 t2;3 
t2;1
2
m1
m2
.

3.8.2 Scenario II
In this scenario, an organization plans to select suppliers
from electronic device manufacturers who produce electronic devices with the same intended use, and the products of the qualified manufacturers should meet three
requirements: i) the operating temperature range of the
electronic devices must cover the temperature range
½
50; 80  C; ii) the electronic devices should have never
received any incident reports in the past (i.e., negative attribute); iii) the fortune ranking of the manufacturer is not
concerned (i.e., wildcard). As illustrated in Fig. 5, the attribute ranges of the manufacturer are f½t1;0 ; t1;0 ; ½t2;1 ; t2;4 ;
½t3;3 ; t3;3 g, and the attribute range constraints designated by
the organization are f½t1;0 ; t1;0 ; ½t2;2 ; t2;3 ; ½t3;0 ; t3;4 g where
t1;0 ; t2;0 ; t3;0 > 0, and t1;0 is defined as ”no incident records”.
The CCP-CABE operations associated with MRDF are
listed below. The algorithm KeyGen computes:

:

The algorithm DecDelegate computes:
ðvP Þru

t

¼ ’1

:

The algorithm EncDelegate computes:

where D ¼ 22;2

i

DECEMBER 2015

4

Ffti;a ri ;ti;b ri gA 2A ððvLu Þru Þ
i

¼ ð’

Z
t
t
t
t
Z
t
Z
t
ru 11;0 22;1 33;3 m1 1;0 m2 2;4 m3 3;3 D

¼ ð’

11;0 22;2 33;4 m1

Þ

t

t

t

Z
t1;0 Z
t2;3 Z
t3;0
ru
m2
m3

Þ ;


t2;1 t3;4 
t3;3 t2;4 
t2;3 t3;3 
t3;0
3
m2
m3
.

EXTENDED CCP-CABE

In this section, we discuss how to extend the use of CCPCABE over multiple attribute domains. In some cases,
multiple attribute domains are required by independent
organizations such that each organization can run an
attribute authority (AA) to host its own attribute domain.
Correspondingly, each AA hands out secret keys for a distinct set of attributes to reflect the users’ attribute values
within an attribute domain, and the failure of some attribute
authorities does not impact the operation of other AAs.
Accordingly, only the users with attribute ranges that satisfy
the attribute constraints across multiple attribute domains
can access that data. In addition, different attribute domains
are at different privilege levels from the perspectives of
different data owners, and the data owners should be able to
embed the privilege levels associated with attribute domains
into the access control policy dynamically. As an example, a
military student’s attributes associated with the army are
more privileged than his/her attributes associated with
the enrolled university. Therefore, we use CCP-CABE as the
building block and propose extended CCP-CABE to prioritize different attribute domains to reflect different privilege
levels across domains. In ECCP-CABE, if the attribute ranges
of the data user cannot satisfy the access policy in the corresponding attribute domain, then the decryption process stops
and the access policy over the remaining attribute domains is
still hidden. Table 2 lists the symbols used in ECCP-CABE.
In ECCP-CABE, each AA generates the master key and
global parameters along with users’ keys associate with its
own attribute domain using the same Setup and KeyGen
in CCP-CABE. Next, the data owners can delegate the encryption overhead to the ESP as with EncDelegate in CCP-CABE.
The differences between CCP-CABE and ECCP-CABE lie in
the algorithms of Encryption and Decryption as follows:

4.1 ECCP-CABE Encryption
Each data owner define his/her own access policy across
multiple attribute domains denoted as <A1 ;    ; AX > from

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

TABLE 2
Notations for ECCP-CABE
Notation

Description

Ax ; Ax;i
mx
nx;i
Px
Lx;u
X
½tx;i;a ; tx;i;b 

the xth attribute domain and the ith attribute in Ax
the number of attributes in Ax
the number of attribute values in Ax;i
the data owner’s access control policy in Ax
the data user u’s attribute ranges in Ax
the total number of attribute domains
the attribute range on attribute Ax;i possessed by
a data user
the range constraint on attribute Ax;i defined by P x
the bound values associated with ½tx;i;j ; tx;i;k ;
it depends on the range relationship over Ax;i
the cipher derived from encrypting the
concatenation of P x and HP x
1

½tx;i;j ; tx;i;k 
x;i
rx;i ; r
HP x

the most privileged domain to the least privileged domain.
Upon receiving the partially encrypted header HeP , the data
owner generates a random secret "x 2 Zn for each Ax . Next,
it computes Cx ¼ h"xx and ekx ¼ H1 ðeðgaxx ; wx Þ"x Þ for each Ax
with H1 : GT ! f0; 1g	 , and generates a random key ak to
encrypt the target message.
To embed the privilege levels into the policy, the data
owner first starts from the most privileged A1 and uses ek1 to
encrypt ak to get HP 1 ¼ P 1 jjEek1 ðakÞ where P 1 denotes the
policy over A1 and Eek1 ðÞ denotes the symmetric encryption
using ek1 . Next, the data owner moves on to the second most
privileged A2 and computes HP 2 ¼ P 2 jjEek2 ðHP 1 Þ. The
process goes on until the data owner moves on to the least
privileged AX and computes HP X ¼ P X jjEekX ðHP X
1 Þ.
Finally, it outputs the ciphertext header
HP ¼ ðHP X ; fCx ; E"x ; E"0 x g1xX Þ;
where ðE"x ; E"0 x Þ ¼ ððvP x wx Þ"x ; ðHðAx ÞÞ"x Þ, and transmits HP
and the encrypted message to the cloud for storage.

4.2 ECCP-CABE Decryption
The cloud first transmits HP X to the data user u such that
the data user u knows the corresponding policy P X over the
least privileged attribute domain AX . Upon receiving HP X ,
the data user u checks if LX;u satisfies P X . If so, the data
user u delegates his/her delegation key DKX;u and the
claimed attribute ranges LX;u to the cloud.




DecDelegate. Upon receiving DKX;u and LX;u , the
cloud derives ðvP X ÞrX;u from ðvLX;u ÞrX;u in the same
manner as CCP-CABE, and then sends ðvP X ÞrX;u to
the data user for further decryption.
Decrypt. As with CCP-CABE, the data user u computes

 ðuÞ
e DX ; E"X
;
Gð"X Þ ¼ 
e ðvP X wX ÞrX;u ; E"0 X
Next, the data user u computes

ðuÞ 
 aX
"X e CX ; DX;0
e gX ; wX
¼
;
Gð"X Þ
ðuÞ

aX þt X;u
bX

. Then, the data user u comwhere DX;0 ¼ gX
a
putes akX ¼ H1 ðeðgXX ; wX Þ"X Þ and derives HP X
1 .

3437

Afterwards, the data owner u and the cloud move on to
AX
1 and invoke the algorithms DecDelegate and Decrypt
again. This process proceeds recursively until they reach A1
and retrieve the session key ek. After retrieving the session
key, the data user can derive the encrypted data. It can be
seen that this onion-like decryption enables a gradual exposure of the access control policy from the least privileged
attribute domain to the most privileged attribute domain.
It significantly preserves the privacy of access control policy, as the data user is unable to decrypt one more level to
discover the policy over the next more privileged attribute
domain if his/her attribute ranges cannot satisfy the policy
over the current attribute domain.

5

SECURITY ANALYSIS

In this section, we analyze the security of CCP-CABE
and ECCP-CABE. We hereby list hardness assumptions
presented below for the theorem proofs in the following
sections.
Definition 2 (RSA Assumption). For the RSA delegation key
ðN; eÞ and the ciphertext C ¼ M e 2 Gn0 , it is intractable to
compute the plaintext M.
Definition 3 (Co-CDH Assumption). Given a quadruple
ðg1 ; gy1 ; g2 ; gz2 Þ 2 G4 where y; z 2 Z	n , it is intractable to compute gyz
2 .
Definition 4 (Bilinear Co-CDH Assumption). Given a quintuple ðg1 ; gy1 ; gz1 ; g2 ; gz2 Þ 2 G5 where y; z 2 Z	n , it is intractable
to compute eðgz1 ; gyz
2 Þ.
Definition 5 (Discrete Logarithm Problem (DLP) Assumption). Given ðg1 ; gy1 Þ 2 G where y 2 Z	n , it is intractable to
compute y.
In ECCP-CABE, each attribute authority generates parameters and operate independently in its own attribute
domain as with CCP-CABE. Accordingly, the security of
ECCP-CABE fully depends on CCP-CABE, and the security
proof of CCP-CABE also applies to ECCP-CABE.

5.1 Security for MRDF
We introduce MRDF F ðÞ based on the correctness of for defined in
ward and backward derivation function ðf; fÞ
[4], and it can be expressed as shown below:
Ffti;j t0 ;ti;k t0 gA 2A ðvfti;j ;ti;k gA 2A Þ
i
i;j
i;k i
Q
t0 
ti;j ti;k 
t0i;k
 Q

ii;j
mi
ti;j Z
ti;k
A
2A
i
 m
¼ ’ Ai 2A i i
Q
Z
t0
t0
ii;j mi i;k
A
2A
i
¼’
¼ vft0

;t0 g
i;j i;k Ai 2A

:
ti;j

t0i;j 
ti;j

Z
ti;k

ti;k 
t0i;k

and ð’mi
Þmi
if
It is easy to compute ð’i Þi
0
0

1
ti;j  ti;j and ti;k  ti;k hold. On the contrary, i and m
1
cani
not be efficiently derived by any PPT algorithms under the
RSA assumption due to the secrecy of n0 , Hence, if ti;j  t0i;j , it
ti;j

t0i;j

is intractable to derive ’i from ’i for any Ai 2 A. It is also
Z
ti;k

intractable to derive ’i

Z
t0i;k

from ’i

if t0i;k > t0i;k holds for

3438

IEEE TRANSACTIONS ON COMPUTERS,

any Ai 2 A. In addition, the value of the product
Q

Z
t

t

Q

Q

t

Ai 2A

t0i;j

ii;k is
Z
t0i;k

unique, which implies that Ai 2A ii;j mi i;k ¼
6
Ai 2A i mi
0
0
if there exists ti;j ¼
6 ti;j or ti;k ¼
6 ti;k over some Ai 2 A due to
the relative primality between any two numbers in
fi ; mi gAi 2A . Accordingly, given jn0 j ¼ 512, the collision probability of fvfti;j ;ti;k gA 2A ¼ vft0
i

;t0 g
i;j i;k Ai 2A

0

g is less than 2
2n ¼

2
1;024 , which is negligible. As a result, it is infeasible to
deduce vfti;j ;ti;k gA 2A from vft0 ;t0 gA 2A if ti;j > t0i;j or ti;k < t0i;k
i

i;j i;k

i

holds. Therefore, MRDF is hard to invert and its one-way
property can be guaranteed.

5.2 Security for Key Collusion Attacks
The security of CCP-CABE and ECCP-CABE schemes
against Key Collusion Attacks relies on the confidentiality
of ru associated with user u’s identity. A user could leverage
key collusion attacks to extend his/her attribute range and
increase privileges. For the sake of brevity, we do not take
into account negative attributes and wildcards, as they are
actually special cases of the range relations R and R0 . In
addition, we only consider KCA committed by two adversaries in CCP-CABE, which can be extended to all cases. For
example, a user u0 with attribute ranges Lu0 ¼ f½t0i;a ; t0i;b gAi 2A
attempts to transfer another user u’s attribute ranges Lu ¼
f½ti;a ; ti;b gAi 2A into his/her own key, such that he/she can
obtain more privilege over some attribute Ai as there exists
ti;a < t0i;a < t0i;b < ti;b . In other words, user u0 depends on the
prior knowledge of

VOL. 64,

B invokes the algorithm A with the input ðw ¼ g1 ;
wru ¼ gy1 ; wd ¼ gz2 ; wþdru ¼ gt2 Þ, where t is a random integer;
2) The output of A takes the form of ðR1 ; R2 Þ, and B
checks if R1  R2 ¼ gt2 and eðg1 ; R2 Þ ¼ eðgy1 ; gz2 Þ are
valid; if not, B repeats step ð1Þ.
3) B returns R2 as the output.
The equations above hold as there exist ru ¼ y; R2 ¼
u
u
wdru ; R1  R2 ¼ gþdr
¼ gt2 and eðg1 ; R2 Þ ¼ eðg1 ; gdr
2
2 Þ¼
y z
eðg1 ; g2 Þ. It implicates B can solve Co-CDH problem if
A is a PPT algorithm, which contradicts the hardness
assumption of Co-CDH. This implies it is intractable to
derive ðw ; wdru Þ.
u
t
In addition, the colludersaþtcould
also commit KCA-II
u0
attacks to forge new keys fg b ; gtu0 ðHðAÞÞru0 ; wru0 ; ðvLu Þru0 g
by replacing vLu0 with some new vLu to get some advantage
in their privileges, where there exists ti;a < t0i;a < t0i;b < ti;b
for certain attribute Ai in Lu . We can prove our schemes are
secure against KCA-II attacks with the theorem below:
Theorem 2. Given a multi-tuple ðN; ’; fi ; mi ; ti;j gAi 2A ;
Q
Z
ti;k
t
r
 i;j m
’ u Ai 2A i i
Þ over the elliptic curve system SN , it is
r

Proof of Theorem 1. As w is the generator of G, we can let
aþt u0

gtu ¼ w ; HðAÞ ¼ wd ; vLu ¼ wd1 ; g b ¼ wg , such that the
problem is equivalent to addressing if we can derive
ðw ; wdru Þ from ðDKu ; SKu Þ ¼ ðwg ; wþdru ; wd1 ru ; wru Þ. It is
clear that the unknown d1 is uncorrelated with this problem. Consequently, the problem can be reduced to
ðw; wru ; wd ; wþdru Þ 
! ðw ; wdru Þ, and we assume that a
PPT algorithm A can break this problem.
Given a Co-CDH problem ðg1 ; gy1 ; g2 ; gz2 Þ 
! gyz
2 , an
efficient algorithm B can solve the Co-CDH problem as
shown below:

t0i;j Z
t0i;k



m

Proof of Theorem 2. We first assume there exists ti0 ;j > t0i0 ;j
over one attribute Ai0 2 A. We assume a PPT algorithm
A takes ðN; ’; fi ; mi ; ti;j gAi 2A ; ’ u
ru

Q

Q

Z
t
t
 i;j mi i;k
Ai 2A i
t0

Þ as the input

Z
t0i;k

ii;j mi

Ai 2A
Þ. Without loss
and outputs ðft0i;j ; t0i;k gAi 2A ; ’
of generality, we further assume a PPT algorithm B can

1
derive the plaintext M ¼ C e
with the public key
ðG; N; eÞ and the ciphertext C over certain attribute Ai
based on A, and breaks the RSA problem as follows:

1)

aþt u0

Theorem 1. Given a CCP-CABE cryptosystem over the elliptic
curve system SN , it is intractable to derive gtu or ðHðAÞÞru
from the user u’s keys for any PPT algorithms under Co-CDH
assumption.

Q

intractable to compute ðft0i;j ; t0i;k gAi 2A ; ’ u Ai 2A i i Þ if there
exists ti;j > t0i;j or ti;k < t0i;k for some Ai 2 A under the RSA
assumption.

and he/she launches KCA-I attacks to derive new keys
ðg b ; gtu0 ðHðAÞÞru ; wru ; ðvLu Þru by exchanging gtu0 or
ðHðAÞÞru0 with some known keys. We can prove our
schemes are resistant against KCA-I attacks with the theorem below:

DECEMBER 2015

1)

r


 ðuÞ ðuÞ ðuÞ
ðSKu ; DKu Þ ¼ D0 ; D1 ; D2 ; DKu
 aþtu

¼ g b ; gtu ðHðAÞÞru ; wru ; ðvLu Þru ðSKu0 ; DKu0 Þ

 ðu0 Þ ðu0 Þ ðu0 Þ
¼ D0 ; D1 ; D2 ; DKu0
 aþtu0

¼ g b ; gtu0 ðHðAÞÞru0 ; wru0 ; ðvLu0 Þru0 ;

NO. 12,

2)

B invokes the algorithm A with the input
Q
Z
ti;k
t Q
r
 i;j
m
Ai 2A i
ðN; ’; e ¼ i0 ; ti0 ;j ; C ¼ ’ u i6¼i0 ;Ai 2A i
,
0
where ’ ¼ C ru is a random element in G and ti0 ;j is
a random integer;
B checks A’s outputs ðt0i0 ;j ; RÞ if t0i0 ;j 
 ti0 ;j 
 1  0
t0 0 
ti0 ;j
i ;j

and Ri0

¼ C hold;0 if not, B repeats step ð1Þ;
t 0 
ti0 ;j 
1
i ;j

B computes M ¼ Re
and outputs the
plaintext M.
t0 0 
ti0 ;j 
1
i ;j
holds.
The output of B is valid as M e ¼ C ¼ Re

3)

t0

It is intractable to compute ru ¼ ðr0u i0i ;j Þ
1 mod n0 due to
the hardness of factoring large number N. This implicates B can solve RSA problem in polynomial time if A
is a PPT algorithm, which contradicts the hardness
of RSA. By the same token, it is intractable to deduce
Q
Z
t0i;k
t0
r
 i;j m
Þ if there exists ti0 ;k < t0i0 ;k
ðft0i;j ; t0i;k gAi 2A ; ’ u Ai 2A i i
over one attribute Ai0 2 A, which can be further applied
to multiple attributes in the same manner. Hence, it is
Q
Z
t0
t0
ru
ii;j mi i;k
0
0
A
2A
i
Þ if
intractable to derive ðfti;j ; ti;k gAi 2A ; ’
u
t
there exists ti;j > t0i;j or ti;k < t0i;k for some Ai 2 A.

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

TABLE 3
Comparison of Key Size and Ciphertext Size
Scheme
CP-ABE
CBE
ABE-AL
CCP-CABE

Key Size

Ciphertext Size

ð1 þ 2jSjjBjÞlG
ð1 þ 4jSjÞlG
ð1 þ jSjÞlG þ jSjlZ	n
4lG

lGT þ ð2jT jjBj þ 1ÞlG
ð4jT j þ 1ÞlG
lGT þ ð2jT j þ 1ÞlG
L þ 3lG

Consequently, it is infeasible for the users to forge new
keys with more privileges by key collusion attacks.

Security for Chosen Delegation Key
and Ciphertext Attacks
The DLP assumption makes it is hard for the cloud provider to derive " from the ciphertext header ðC ¼ h" ; E" ¼
ðvP wÞ" ; E"0 ¼ ðHðAÞÞ" Þ. We can also prove that the cloud
provider cannot obtain any advantage in CDKCA with a
polynomial number of delegation keys and ciphertext
headers. The delegation keys DKLu contains only part of
the information, and ru prevents applying one user’s delegation key to another user’s decryption process. Additionally, the secret keys are not disclosed to the cloud
providers, so it is infeasible to cancel out ru ; t u and derive
ek ¼ eðga ; wÞ" without the secret keys. It can be formally
proved under Bilinear Co-CDH assumption with the following theorem:

3439

TABLE 4
Comparison of Communication Overhead
Scheme
CP-ABE
CBE
ABE-AL
CCP-CABE

6

Communication Cost
2lGT þ ð2jSjjBj þ 4jT jjBj þ 3ÞlG
3lGT þ ð3 þ 10jSj þ 8jT jÞlG
2lGT þ ð2 þ jSj þ 4jT jÞlG þ jSjlZ	n
2L þ lGT þ 15lG

PERFORMANCE EVALUATION

In this section, we analyze the complexity of our CCP-CABE
and ECCP-CABE in detail with evaluation results.

5.3

Theorem 3. Given the RSA-type elliptic curve system SN , CCPCABE is semantically secure against CDKCA under the Bilinear Co-CDH assumption.
Proof of Theorem 3. Assume a PPT algorithm A can break
this algorithm. Given a Bilinear Co-CDH problem ðg1 ;
gy1 ; gz1 ; g2 ; gz2 Þ 
! eðgz1 ; gyz
2 Þ, an efficient algorithm B can be
constructed to solve the Bilinear Co-CDH problem based
on A as follows:
Setup: B randomly chooses an integer u and defines
a ¼ yz, b ¼ ui, g ¼ g1 , w ¼ g2 , h ¼ wz ¼ gu1 , z ¼ eðgy1 ; gz2 Þ,
’ ¼ g%2 where i ¼ logg1 g2 and sj%. Accordingly, B sends
GP ¼ ðS; g; h; h; eðg; wÞa ; ’; fi ; mi gAi 2A ; HðÞÞ to A.
Learning: A sends a polynomial number of DecDelegate
queries with fLul g1lU and P. For each query, B computes
Q

r Z

ri
 im
ru
Ai 2A i i

Þ , and sends it to A.
Challenge: B sets " ¼ z and computes h" ¼ ðgz1 Þu ,
Q
r Z

ri
%
 im
þ1
&
, E"0 ¼ g"&
E" ¼ ðg"21 Þ 1 Ai 2A i i
2 , where HðAÞ ¼ g2 ,
and sends them as the challenge ciphertext to A.
Response:A outputs a session key ek0 to B, and B outputs it as the result.
The output of B is valid if A outputs correct result, as
a
"
there exists ek0 ¼ eðgy1 ; gyz
2 Þ ¼ eðg ; w Þ. This implies B can
solve Bilinear Co-CDH problem if A is a PPT algorithm,
which contradict the hardness assumption of Bilinear
Co-CDH.
u
t
ðvP Þru ¼ ð’

Consequently, it is infeasible for the honest-but-curious cloud provider to reveal the encrypted content by
taking advantage of the ciphertext and the delegation
keys.

6.1 Complexity Analysis
We compare the presented CCP-CABE scheme with CBE
[4], ABE-AL [5] and CP-ABE [2] for complexity analysis.
CBE and ABE-AL utilize different forward/backward
derivation functions for comparison-based encryption and
decryption, while CP-ABE and its variants use bit-wise
matching method to implement integer comparison for
comparison-based access control. Similarly to CBE, we
only focus on the pairing and exponentiation operations
while neglecting the hash and multiplication cost in both
G and GT as well as symmetric encryption/decryption
cost, since they are faster compared to the paring and
exponentiation operations. We use similar notations as
with CBE for these operations in both G and GT . B indicates the bit form of the upper and lower bound values of
the attribute range for comparison in CP-ABE. P denotes
bilinear pairing cost. EðGÞ and EðGT Þ refer to the exponential computation overhead in G and GT respectively.
EðZ	n Þ refers to the exponential computation overhead in
Z	n . T represents the number of leaves in the access tree
and S represents the attributes involved in encryption
and decryption. L is the ciphertext size resulting from
symmetric encryption with the session key ek.
We demonstrate the differences of key size and ciphertext size between these schemes in Table 3. It is clear that
the key size in CP-ABE, CBE and ABE-AL grows linearly
with the number of associate attributes S, and the ciphertext
size in these three schemes also increases proportionally
with the number of attributes T in the access tree. In contrast, CCP-CABE keeps both the key size and ciphertext size
constant irrespective of the number of involved attributes.
Table 4 gives the comparison between these schemes
regarding the total communication cost on resource-constrained devices including key generation, delegation,
encryption and decryption, and we can learn that the communication cost of the first three schemes also grows with
the number of related attributes, while the communication
cost of CCP-CABE remains constant regardless of the number of attributes. Note that we do not consider the communication overhead caused by the transmission of P and Lu ,
as they are cleartext, which could be pre-distributed and
compressed into a very small size.
We only list the comparison of the computation overhead
of encryption and decryption on mobile devices in Tables 5
and 6, respectively, as we assume that both the cloud
providers and the ESP are resource-rich in computation

3440

IEEE TRANSACTIONS ON COMPUTERS,

TABLE 5
Comparison of Encryption Overhead
Scheme
CP-ABE
CBE
ABE-AL
CCP-CABE

VOL. 64,

NO. 12,

DECEMBER 2015

TABLE 8
Comparison of Computation Cost between GIE
and ECCP-CABE

Encryption
P þ ð1 þ 2jT jjBjÞEðGÞ
ð1 þ 4jT jÞEðGÞ þ EðGT Þ
ð2jT j þ 1ÞEðGÞ þ EðGT Þ
3EðGÞ þ EðGT Þ

Operation
Encryption
Decryption

GIE
P þ ð1 þ 2jT jjBjÞEðGÞ
ð2 þ 3jSjjBjÞEðGT Þ
þ 2jSjjBjP

ECCP-CABE
3XEðGÞ þ XEðGT Þ
3XlG

TABLE 6
Comparison of Decryption Overhead
Scheme
CP-ABE
CBE
ABE-AL
CCP-CABE

Decryption
ð2 þ 3jSjjBjÞEðGT Þ þ 2jSjjBjP
P þ ð5jSj þ 1ÞEðGÞ
2jSjP þ ðjSj þ 2ÞEðGT Þ þ 2jSjEðGÞ
3P

TABLE 7
Comparison of Key Size, Ciphertext Size and Communication
Cost between GIE and ECCP-CABE
Metric
Key Size
Ciphertext Size
Comm. Cost

GIE
ð1 þ 2jSjjBjÞlG
lGT þ ð2jT jjBj þ 1ÞlG
2lGT þ ð2jSjjBj
þ 4jT jjBj þ 3ÞlG

ECCP-CABE
4XlG
L þ 3XlG
lGT þ ð1 þ XÞ
L þ 17XlG

capability. As a result, the computation overhead on
mobile devices is our only concern. It can be learned that the
encryption and decryption overhead in CCP-CABE remains
the same irrespective of the number of attributes involved in
that all the computation-intensive operations are offloaded
to the resource-rich ESP and cloud providers, while the computation cost of the other three schemes grows with the
increase of the number of associated attributes.
ECCP-CABE uses CCP-CABE as the building block, and
it reveals the policy domain by domain unless it reaches the
most sensitive attribute domain. Correspondingly, GIE [6]
enables the exposure of the access policy, attribute by
attribute. Similar to the previous assumption, we assume B
indicates the bit form of the upper and lower bound values
of the attribute range for comparison, T represents the number of leaves in the tree and S represents the attributes
involved in encryption and decryption in GIE. In addition,
we assume there exist X attribute domains in ECCP-CABE
and the size of HP X is L. Therefore, we compare ECCPCABE with GIE in terms of key size, ciphertext size, and
communication cost associated with encryption, delegation
and decryption as shown in Table 7. The comparison
regarding the computation cost between GIE and ECCPCABE is shown in Table 8.
It can be seen that the key size, ciphertext size and communication cost of GIE grows linearly with the increase of
the number of associated attributes, while those of ECCPCABE increase with the number of attribute domains. This
also applies to GIE and ECCP-CABE in terms of encryption
and decryption cost. In a real-world scenario, the number of
attribute domains is usually smaller than the number of

Fig. 6. Computational cost of CCP-CABE algorithms with different comparison range.

attributes, thus ECCP-CABE is generally more efficient
than GIE in terms of communication and computation cost.
On the other hand, GIE can provide more fine-grained
privacy preservation of access control policy as it reveals
the policy attribute by attribute.

6.2 Computational Evaluation
We have implemented our CCP-CABE scheme in the Mobicloud platform [7] and android smartphone. The TA, ESP
and cloud provider are simulated by virtual machines with
Intel Core i3-2100 CPU at 3.10 GHz and 4 GB memory running 64-bit Ubuntu Precise Pangolin (Ubuntu 12.04) hosted
by the Mobicloud platform. The mobile device is a Samsung
Galaxy Note with Quad core ARM Cortex-A9 at 1.6 GHz
and 2 GB memory running Android 4.2 (Jelly Bean).
The computational cost is emulated by utilizing the Java
Pairing-Based Cryptography (jPBC) library [8] without
considering the communication cost. As with [4], we use the
same bilinear map system S of composite order n where
n ¼ s1 s2 p0 q0 and jp0 j ¼ jq0 j ¼ 256 bits. Our tests demonstrate
that the Ubuntu virtual machines run more than 20 times
faster than the smartphone on average regarding the algorithms in CCP-CABE and ECCP-CABE.
Fig. 6 illustrates the impact of the range of integer comparison on the computational cost of the algorithms in CCPCABE where the total number of attributes is set as 10. We
assume the value range of each attribute is ½1; Z and Z takes
the form of 2x . The data owner adopts the range relationship
R and designates ½38 Z; 58 Z as the attribute constraint over
each attribute, and the attribute range of the data user is
½18 Z; 78 Z. Therefore, the comparison range is Z4 and it grows
from 2 to 212 as x increases from 3 to 14. It demonstrates
that the comparison range has negligible impact over the

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

Fig. 7. Computational cost of CCP-CABE algorithms with different number of attributes.

computational cost of the algorithms in CCP-CABE. This
implies that each attribute can have many integer values for
comparison without increasing the computational overhead
in real-world settings. In Fig. 7, the comparison range is
fixed as 24 . It shows that the computational cost of KeyGen,
EncDelegate and DecDelegate running on server grows
almost linearly as the number of attributes increases from
1 to 12. Meanwhile, the computational cost of Encrypt and
Decrypt remains the same irrespective of the number of
attributes, which is suitable for resource-constrained mobile
devices.
In Fig. 8, we assume each attribute domain has six
attributes and the comparison range of each attribute is
24 . In addition, we use AES-128 for the recursive encryption and decryption over the attribute domains. As each
attribute authority is only responsible for Setup, KeyGen
and EncDelegate in its own domain, its performance is
approximately the same as that in CCP-CABE, and we do
not plot them for the sake of brevity. Fig. 8 shows that
the computational cost of Encrypt, DecDelegate and
Decrypt grows with the number of attribute domains. As
the number of attribute domains is usually smaller than
the number of attributes in real world, the computational
overhead is still acceptable. It can be learned that the data
owner should associate the policy only with the concerned attribute domains to reduce overhead.

7

RELATED WORK

There have been plenty of prior work on secure access data
in mobile and cloud computing scenarios. The biometric
approaches provide various ways of biometric authentication [9], [10] (e.g., iris, voice, fingerprint) to identify human
subject. The biometric approaches generate unique passwords from the distinct biometric characteristics of the
human subject and provide the convenience that there is no
need to carry IDs. However, they are frequently accompanied by reliability issues due to possible false positives or
false negatives, and the resulting permanent passwords
cause inconvenience in case of password changes or revocation. In addition, the biometric passwords store personal
information of human subjects (e.g., DNA) and the

3441

Fig. 8. Computational cost of ECCP-CABE algorithms with different
number of attribute domains.

password theft can result in irredeemable loss. Comparatively, ABE authorizes a subject (e.g., an individual, a process, or a device) without authentication, that is, to
determine if this subject is allowed to access certain resources regardless of its identity. Specifically, ABE decides to
grant a subject the permission to access objects by evaluating its attributes (e.g., ranks, affiliations, credits) associated
with this subject or requested operations rather than the
identity of this subject. In this manner, the anonymity of
this subject can be preserved, and the password theft or revocation in ABE brings less cost compared to that in biometric approaches. Data fragmentation has also been exploited
to secure the data in cloud systems. AONT-RS [11] is implemented by combining the All-Or-Nothing Transform
(AONT) with systematic Reed-Solomon erasure codes, and
AONT-LT [12] is realized by replacing the Reed-Solomon
code with rateless Luby transform codes. They are secure
only if the attacker cannot acquire k slices, and they do not
provide fine-grained access control policy like ABE.
In the meantime, a large body of literature has been done
on data access control and security in cloud-based health
information system. Ateniese et al. [13] investigated techniques to protect the privacy of patients and doctors using
pseudonyms. L€
ohr et al. [14] proposed to construct trusted
privacy domains (TVD) to address the security issues of
end-user platforms and external storage associated with
medical data. Ermakova et al. [15] gave a survey of new scenarios in healthcare and derived different sets of security
and privacy system requirements. Tong et al. [16] proposed
to embed privacy into mobile healthcare systems with the
aid of the private cloud and searchable symmetric encryption. Frontoni et al. [17] constructed a software architecture
to achieve the desired levels of security and privacy of the
patients’ data. The survey paper [18] provides a comparative study on various cryptography, cryptanalysis and steganology techniques including SCAN and chaos methods,
which can be applied to the encryption of images, voice and
video in health information system.
Bethencourt et al. [2] gave the first construction for a CPABE scheme in the generic group model. The first ABE system with adaptive security was proposed by Lewko et al.
[19] using Dual System Encryption techniques. Pirretti et al.

3442

IEEE TRANSACTIONS ON COMPUTERS,

[20] introduced a secure information management architecture based on ABE primitives. Multiple ABE schemes [21],
[22], [23], [24] are proposed to achieve constant ciphertext
length. In [25] the client can outsource pairing operations
to a server, but it still has to compute expensive exponentiations, which is proportional to the size of the policy.
However, most existing ABE schemes rely on bitwise-comparison operators with AND/OR gates and they cannot
effectively support dual comparative expressions. Besides,
the computational cost they bring overwhelms resourcelimited mobile devices. Zhu et al. [4] first introduced
an integer comparison mechanism to fine-grained access
control based on attribute range. But the encryption cost
involved is still too heavy for resource-constrained data
owners, and the size of users’ private keys and ciphertext
overhead grows linearly with the number of attributes.
Moreover, it has not considered negative attributes and
wildcards. Our CCP-CABE scheme supports both negative
attributes and wildcards along with various range relationships over different attributes. It ensures the sizes of key
and ciphertext overhead remain constant regardless of the
number of attributes. Its encryption and decryption overhead over the data owners and data users also stay constant
irrespective of the number of attributes.
Multi-authority ABE starts to attract attention as multiple
attributes authorities are required to operate independently
in many application scenarios. Melissa Chase demonstrated
multi-authority ABE in [26] and it requires a central trusted
party to issue the key to every user. An improved version
[27] removes the central authority, and it requires all the
attribute authorities to cooperate in the access control. The
multi-authority ABE schemes proposed in [28], [29] also
require a centralized authority to create the master key and
accordingly generate keys to each user. In 2011, Lewko and
Waters presented a multi-authority attribute-based encryption system DABE [30] in which no preset access structure
exists and the key generation authorities can work independently from each other. In the meantime, the privacy of
access policy is a concern in attribute-based encryption, and
the schemes [31], [32], [33], [34] are proposed to ensure the
recipient gets no information of the policy if the decryption
fails after a complete computation-intensive process with a
central authority. Our ECCP-CABE enables the data owners
to label attribute domains with different privilege levels in
the access policy and it provides policy exposure at the attribute domain level and perform encryption and decryption
over each attribute domain in a batch-processing manner,
while GIE [6] and offers policy exposure at the attribute
level and it reveals the access policy attribute by attribute in
a central-authority scenario.

8

CONCLUSION

In this paper, we presented a novel range derivation function for comparative attribute-based encryption. Correspondingly, we constructed CCP-CABE framework with a
central trust authority and further extend it to ECCP-CABE
to fit the scenario with multiple attribute domains. Both of
them could enforce highly expressive access control policies
based on different attribute range relationships with the
support of negative attributes and wildcards. CCP-CABE

VOL. 64,

NO. 12,

DECEMBER 2015

kept the computational overhead constant for the data owners and data users regardless of the number of involved
attributes by encrypting and decrypting over all attributes in
a batch-processing manner. Moreover, it kept the communication overhead small and constant regardless of the number of attributes. ECCP-CABE enables the access policy to
prioritize the privilege levels of different attribute domains,
and guarantees the policy exposure domain by domain to
protect the privacy of the access policy. Finally, we proved
their security and demonstrated their efficiency at the end.

ACKNOWLEDGMENTS
This work was supported by ONR YIP, the National 973
Program (Grant No. 2013CB329605) and the National
Natural Science Foundation of China (Grant Nos. 61170264
and 61472032). Zhijie Wang is the corresponding author.

REFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]

[11]
[12]
[13]

[14]
[15]

[16]
[17]

J. Daemen and V. Rijmen, The Design of Rijndael: AES—The
Advanced Encryption Standard. New York, NY, USA: Springer, 2002.
J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-policy attribute-based encryption,” in Proc. IEEE Symp. Security Privacy, 2007,
pp. 321–334.
M. Green, S. Hohenberger, and B. Waters, “Outsourcing the
decryption of abe ciphertexts,” in Proc. 20th Usenix Conf. Security,
2011, p. 3.
Y. Zhu, H. Hu, G. Ahn, M. Yu, and H. Zhao, “Comparison-based
encryption for fine-grained access control in clouds,” in Proc. 2nd
ACM Conf. Data Appl. Security Privacy, 2012, pp. 105–116.
Y. Zhu, D. Ma, C.-J. Hu, and D. Huang, “How to use attribute-based
encryption to implement role-based access control in the cloud,” in
Proc. Int. Workshop Security Cloud Comput., 2013, pp. 33–40.
Z. Zhou and D. Huang, “Gradual identity exposure using attribute-based encryption,” Int. J. Inform. Privacy, Security Integrity,
vol. 1, no. 2, pp. 278–297, 2012.
D. Huang, “Mobile cloud computing,” IEEE COMSOC Multimedia
Commun. Techn. Committee E-Lett., vol. 6, no. 10, pp. 27–31, 2011.
A. De Caro and V. Iovino, “JPBC: Java pairing based cryptography,”
in Proc. IEEE Symp. Comput. Commun., 2011, pp. 850–855.
R. Kannavara, S. Mertoguno, and N. Bourbakis, “Scan secure processor and its biometric capabilities,” J. Electron. Imaging, vol. 20,
no. 2, p. 023 014, 2011.
N. Bourbakis, A. Pantelopoulos, and R. Kannavara, “Security and
privacy in biomedical telemetry: Mobile health platform for
secure information exchange,” in Handbook of Biomedical Telemetry.
New York, NY, USA: Wiley, 2014, pp. 382–418.
J. K. Resch and J. S. Plank, “AONT-RS: Blending security and performance in dispersed storage systems,” in Proc. 9th USENIX
Conf. File Stroage Technol., 2011, p. 14.
M. Baldi, N. Maturo, E. Montali, and F. Chiaraluce, “AONT-LT: A
data protection scheme for cloud and cooperative storage systems,”
in Proc. High Perform. Comput. Simul. Conf., 2014, pp. 566–571.
G. Ateniese, R. Curtmola, B. De Medeiros, and D. Davis, “Medical
information privacy assurance: Cryptographic and system
aspects,” in Security in Communication Networks. New York, NY,
USA: Springer, 2003, pp. 199–218.
H. L€
ohr, A.-R. Sadeghi, and M. Winandy, “Securing the e-health
cloud,” in Proc. 1st ACM Int. Health Inform. Symp., 2010, pp. 220–229.
T. Ermakova, B. Fabian, and R. Zarnekow, “Security and privacy
system requirements for adopting cloud computing in healthcare
data sharing scenarios,” presented at the 19th Americas Conf.
Information Systems, Chicago, IL, USA, 2013.
Y. Tong, J. Sun, S. S. Chow, and P. Li, “Cloud-assisted mobileaccess of health data with privacy and auditability,” IEEE
J. Biomed. Health Inform., vol. 18, no. 2, pp. 419–429, Mar. 2014.
E. Frontoni, M. Baldi, P. Zingaretti, V. Landro, and P. Misericordia, “Security issues for data sharing and service interoperability
in ehealth systems: The Nu. Sa. test bed,” in Proc. Int. Carnahan
Conf. Security Technol., 2014, pp. 1–6.

WANG ET AL.: EFFICIENT ATTRIBUTE-BASED COMPARABLE DATA ACCESS CONTROL

[18] A. Rwabutaza, M. Yang, and N. Bourbakis, “A comparative
survey on cryptology-based methodologies,” Int. J. Inform.
Security Privacy, vol. 6, no. 3, pp. 1–37, 2012.
[19] A. Lewko, T. Okamoto, A. Sahai, K. Takashima, and B. Waters,
“Fully secure functional encryption: Attribute-based encryption
and (hierarchical) inner product encryption,” in Proc. 29th Annu.
Int. Conf. Theory Appl. Cryptographic Tech., 2010, pp. 62–91.
[20] M. Pirretti, P. Traynor, P. McDaniel, and B. Waters, “Secure attribute-based systems,” J. Comput. Security, vol. 18, no. 5, pp. 799–
837, 2010.
[21] K. Emura, A. Miyaji, A. Nomura, K. Omote, and M. Soshi, “A
ciphertext-policy attribute-based encryption scheme with constant ciphertext length,” in Information Security Practice and Experience. New York, NY, USA: Springer, 2009, pp. 13–23.
[22] J. Herranz, F. Laguillaumie, and C. Rafols, “Constant size ciphertexts in threshold attribute-based encryption,” in Proc. Public Key
Cryptography, 2010, pp. 19–34.
[23] N. Attrapadung, B. Libert, and E. De Panafieu, “Expressive keypolicy attribute-based encryption with constant-size ciphertexts,”
in Proc. Public Key Cryptography, 2011, pp. 90–108.
[24] C. Chen, Z. Zhang, and D. Feng, “Efficient ciphertext policy attribute-based encryption with constant-size ciphertext and constant
computation-cost,” in Proc. 5th Int. Conf. Provable Security, 2011,
pp. 84–101.
[25] B. Chevallier-Mames, J. Coron, N. McCullagh, D. Naccache, and
M. Scott, “Secure delegation of elliptic-curve pairing,” in Proc. 9th
IFIP WG 8.8/11.2 Int. Conf. Smart Card Res. Adv. Appl., 2010,
pp. 24–35.
[26] M. Chase, “Multi-authority attribute based encryption,” in Proc.
4th Conf. Theory Cryptography, 2007, pp. 515–534.
[27] M. Chase and S. S. Chow, “Improving privacy and security in
multi-authority attribute-based encryption,” in Proc. 16th ACM
Conf. Comput. Commun. Security, 2009, pp. 121–130.
[28] S. M€
uller, S. Katzenbeisser, and C. Eckert, “Distributed attributebased encryption,” in Proc. Int. Conf. Inf. Security Cryptol., 2009,
pp. 20–36.
[29] K. Yang and X. Jia, “DAC-MACS: Effective data access control for
multi-authority cloud storage systems,” in Security for Cloud Storage Systems. New York, NY, USA: Springer, 2014, pp. 59–83.
[30] A. Lewko and B. Waters, “Decentralizing attribute-based
encryption,” in Proc. 30th Annu. Int. Conf. Theory Appli. Cryptographic Tech.: Adv. Cryptol., 2011, pp. 568–588.
[31] S. Yu, K. Ren, and W. Lou, “Attribute-based content distribution
with hidden policy,” in Proc. 4th Workshop Secure Netw. Protocols,
2008, pp. 39–44.
[32] T. Nishide, K. Yoneyama, and K. Ohta, “Attribute-based encryption with partially hidden encryptor-specified access structures,”
in Proc. 6th Int. Conf. Appl. Cryptography Netw. Security, 2008,
pp. 111–129.
[33] J. Li, K. Ren, B. Zhu, and Z. Wan, “Privacy-aware attribute-based
encryption with user accountability,” in Proc. 12th Int. Conf. Inf.
Security, 2009, pp. 347–362.
[34] S. Yu, K. Ren, andW. Lou,“Attribute-based on-demand multicast
group setup with membership anonymity,” Comput. Netw.,
vol. 54, no. 3, pp. 377–386, 2010.
Zhijie Wang received the BS and MS degrees
from Beijing University of Posts & Telecommunications, in 2007 and 2010, respectively. He is
currently working toward the PhD degree at Arizona State University. His research interests
include wireless networking, applied cryptography, and cloud computing. He is a student member of the IEEE.

3443

Dijiang Huang (M’00-SM’11) received the BS
degree from Beijing University of Posts & Telecommunications, China, 1995. He received the
MS and PhD degrees from the University of Missouri-Kansas City, in 2001 and 2004, respectively. He is currently an associate professor
in the School of Computing Informatics and
Decision System Engineering, Arizona State
University. His current research interests include
computer networking, security, and privacy. He is
an associate editor of the Journal of Network and
System Management (JNSM) and an editor of IEEE Communications
Surveys & Tutorials. He has served as an organizer for many International conferences and workshops. His research is supported by the US
National Science Foundation (NSF), ONR, ARO, NATO, and Consortium of Embedded System (CES). He received ONR Young Investigator
Program (YIP) Award. He is a senior member of the IEEE.
Yan Zhu is currently a professor in the School of
Computer and Communication Engineering, University of Science and Technology Beijing, China.
He was an associate professor at Peking University in China from 2007 to 2012. He was a visiting
associate professor in the Arizona State University From 2008 to 2009, and a visiting research
investigator of the University of MichiganDearborn in 2012. His research interests include
cryptography, secure computation, and network
security. He is a member of the IEEE.
Bing Li received the BS degree from Shandong
University in 2008 and the MS degree from Beijing University of Posts & Telecommunications in
2011. He is currently working toward the PhD
degree at Arizona State University. His research
interests include ad hoc network security, cloud
computing, and robot systems. He is a student
member of the IEEE.

Chun-Jen Chung received the MS degree in
computer science from New York University.
He is currently working toward the PhD degree at
Arizona State University. His current research
interests include computer and network security,
security in software-defined networking, and
trusted computing in mobile devices and cloud
computing. He is a student member of the IEEE.

" For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

8th International Conference on Advanced Computational Intelligence
Chiang Mai, Thailand; February 14-16, 2016

Short Term Traffic Flow Prediction Based on
On-line Sequential Extreme Learning Machine
Zhiyuan Ma and Guangchun Luo

Dijiang Huang

Department of Computer Science and Engineering
University of Electronic Science and Technology of China
Chengdu, Sichuan
Emails: yuliar3514@gmail.com, gcluo@uestc.edu.cn

School of Computing, Informatics, and
Decision Systems Engineering
Arizona State University
Tempe, Arizona
Email: dijiang.huang@asu.edu

Abstract—Traffic flow cannot be predicted solely based on
historical data due to its high dynamics and sensitivity to
emergency situations. In this paper, a real traffic data collected
from 2011 to 2014 is used, and an adaptive prediction model
based on a variant of Extreme Learning Machine (ELM), namely
On-line Sequential ELM with forgetting mechanism, is built. The
model has the capability of updating itself using incoming data,
and adapts to the changes in real time. However, limitations,
such as the requirements of large number of neurons and dataset
size for initialization, are discovered in practice. To improve the
applicability, another scheme involving sequential updating and
network reconstruction is proposed. The experimental results
show that, compared with the previous method, the proposed
one has better performance in time while achieving the similar
accuracy.
Keywords—Traffic flow prediction; adaptive model; ELM; online sequential ELM

I. I NTRODUCTION
Traffic flow prediction has been an important aspect of
intelligent transportation system, but the solutions nowadays
can barely meet the increasing real-time requirements [1].
Moreover, the solutions solely based on historical data are
hardly responsive to changes, which, according to [2], has
become a major challenge in the domain. Although numerous
methods have been proposed [3] [4] [5] [6], a large portion
of them require off-line updating when there are significant
changes in the data. It would not only damage the continuity
of the service built upon them, but also cause tons of data
failing to be analyzed while the updating is in progress.
To effectively tackle the problem, we focus on building an
adaptive model with real time processing ability. One type of
artificial neural network with fast training speed, namely Extreme Learning Machine (ELM) [7] [8], is used, and based on
a variant of ELM, called On-line Sequential Extreme Learning
Machine (OSELM) with forgetting mechanism [9], a scheme
that can update the prediction model in an on-line manner is
built. To validate the feasibility of the scheme, a real traffic
dataset collected from 2011 to 2014 is used in the experiments.
The results show that, with proper adjustments of the initial
dataset size and the number of the hidden layer neurons, the
prediction is reliable. However, the results also show that in
order to make the model feasible, the two parameters, namely
initial dataset size and the number of hidden layer neurons,

978-1-4673-7782-9/16/$31.00 ©2016 IEEE

need to be large enough. It means the model cannot work if
there is limited data, and the large number of hidden layer
neurons also brings high computation complexity. To improve
the applicability, another scheme is proposed. Compared with
previous method, it constructs an ELM network with smaller
dataset size. Then the model updates itself for specific times
before reconstructing a new ELM network. These procedures
repeatedly take place and the experimental results show that to
generate prediction model with similar accuracy, the proposed
scheme requires both small initial dataset size and small
number of hidden layer neurons.
The rest of the paper is organized as follows. Section 2 introduces the background of ELM and OSELM with forgetting
mechanism. The problem description and the traffic dataset
are also introduced in the section. Section 3 details two of
the schemes for building the prediction model, followed by
Section 4 that compares the two schemes through experiments
using real traffic data. In Section 5, some conclusions are
drawn.
II. P RELIMINARIES AND P ROBLEM D ESCRIPTION
A. Extreme Learning Machine and On-line Sequential Extreme Learning Machine
Extreme Learning Machine (ELM) is a single hidden layer
feed forward neural network proposed by Huang et al. [8].
The general form of ELM with L hidden layer neurons can
be described as Equ. (1),
fL (X) =

L
∑

βi gi (X) =

i=1

L
∑

βi g(ai , bi , X)

(1)

i=1

where β1 , β2 , . . . , βL are the output weights between the
hidden layer with L neurons and the output layer, and gi is
a nonlinear piecewise continuous function, namely activation
function, whose parameters ai and bi are randomly assigned
[10].
Unlike traditional machine learning algorithms, ELM directly computes the output weight by minimizing the approximation error described as Equ. (2),

143

min ∥Hβ − T ∥2

β∈RL×n

(2)

where H is the output of hidden layer with L neurons, n is
the number of neurons in the output layer, and T is the target
matrix of training data. The solution is then given as Equ. (3),
β ∗ = H −1 T

T
T
Mk+1 = Mk − Mk Hk+1
(I + Hk+1 M Hk+1
)−1 Hk+1 Pk (4)

where M0 = (H0T H0 )−1 and H( k + 1) is the corresponding
output of the hidden layer for data Xk+1 . The output weight
matrix is then updated using Equ. (5):
T
(Tk+1 − Hk+1 βk )
βk+1 = βk + Mk+1 Hk+1

(5)

where β0 = M0 H0T T0 is the output weight matrix of initialized ELM network.
Still, there is an inevitable step of calculating the hidden
layer output H, whose dimension grows whenever a new
data is added. Eventually, the complexity of calculating the
matrix would reach an upper bound where the machine cannot
handle. In 2012, Zhao et al. proposed a variant of OSELM
in a way of discarding the oldest data so that the matrix H
maintains a relatively small scale [9]. Instead of using Equ.
(4), the algorithm computes an intermediate result Mk+1 with
the oldest data (Xo , To ) using Equ. (6):
Mk+1 = Mk − Mk

[

]T
[
]
−ho
ho
(I +
Mk
hk+1
hk+1
[
]T
[
]
−ho
ho
−1
)
Mk
hk+1
hk+1

(6)

where ho and hk+1 represent the hidden layer output of the
oldest data and incoming data. The new weight matrix βk+1
can be calculated using Equ. (7):
βk+1 = βk + Mk+1

[

−hk
hk+1

60

]T [
]
Tk
(
−
Tk+1
[
]
hk
βk )
hk+1

(7)

where Tk and Tk+1 are the target of the oldest and incoming
data. The algorithm is then extended for time series [13] and
nonstationary problems [14]. And in 2014, Chen et al. further
improved the approach for processing large scale multivariate
data [15].

Traffic Flow Volume

(3)

where H −1 is the Moore-Penrose generalized inverse of matrix H [8] [11]. And because the output weight β is obtained
with one-time calculation, the training speed is extremely fast.
However, in order to use ELM, a complete training dataset
is required, which makes it impossible for on-line updating. To
tackle the problem, Huang et al. provide an idea of incrementally constructing ELM network, namely On-line Sequential
Extreme Learning Machine (OSELM) [12]. For an incoming
data (Xk+1 , Tk+1 ), the algorithm computes a new intermediate
result Mk+1 using Equ.(4):

500 Examples of Traffic Flow Data

70

50
40
30
20
10
0
500

600

700
800
Time Series

900

1000

Fig. 1. 500 examples of traffic flow data. The value of X indicates 5X minutes
after 00:00 on Jan. 1st 2011, and the axis of Y shows the value of traffic flow.
The circles on the curve represent traffic counts recorded every 5 minutes.

B. Problem Description
As mentioned in the introduction, current solutions for
traffic flow prediction are either based on historical data,
or hardly adaptive to changes. Progresses made in modeling
time series data have shown the possibility of constructing
traffic flow prediction which can response to the changes [13].
However, the real traffic data is highly dynamic and fluctuating
as Fig. 1 shows, while the data used in their research changes
in a smooth manner.
In the meantime, not all the data can be taken into consideration. In public transportation system, the widely used models,
such as autoregressive integrated moving average (ARIMA)
and its variants [16] [17], suggest that the effectiveness of the
predictions relies on a subset of the historical data.
To quickly response to the changes in real time while model
the dynamic features of the traffic data, we focus on building
a model that relies on limited historical data, and utilizes the
incoming data for updating. The dataset used in this paper
was collected from 2011 to 2014 on freeways in Phoenix,
AZ, United States, and the field values have been transformed
into numeric for the ease of processing.
III. S HORT T ERM T RAFFIC F LOW P REDICTION S CHEME
A. Traffic Flow Prediction using OSELM with Forgetting
Mechanism
In general, building an adaptive prediction model for traffic
flow involves two steps. The first is to construct a base
predictor using a limited dataset. Once it is done, prediction
result can be generated. In order to make the predictor adaptive
to changes, it requires updating when new data is received. So
the next step is to take advantage of the streaming data, and use
on-line sequential updating mechanism described in OSELM.
However, not all the data can be taken into calculation for
performance considerations. As described in previous section,
the OSELM with forgetting mechanism drops the oldest data

144

Algorithm 1 Traffic Flow Prediction using OSELM with
Forgetting Mechanism
Input:
ActT ype := the type of activation function,
L := the number of hidden layer neurons,
m := the size of initial dataset
Output:
P := predictions of traffic flow
1: initialize the parameters for activation functions:
randomly assign (ai , bi ) as described in Equ. (1) for L
hidden layer neurons;
2: construct the ELM network:
calculate output weight matrix H0 ;
calculate M0 using M0 = (H0T H0 )−1 ;
calculate β0 using Equ. (3);
3: generate the first prediction:
calculate H1 ;
calculate prediction result using P1 = H1 β0 ;
store P1 in P ;
4: while incoming data (Xk+1 , Tk+1 ) is received, do
5:
update the ELM network:
calculate Mk+1 using Equ. (6);
calculate βk+1 using Equ. (7);
6:
generate the (k + 2)th prediction:
calculate hidden layer output Hk+2 ;
calculate prediction result using Pk+2 = Hk+2 βk+1 ;
store Pk+2 in P ;
7: end while
8: return P ;

so that the complexity of the algorithm remains at a certain
level.
The overall procedure of predicting traffic flow using OSELM with forgetting mechanism is shown as Alg. 1. The initialization of the base ELM network is based on original ELM
algorithm. Three parameters, namely the activation function,
the number of hidden layer neurons, and the initial dataset,
should be preset. The activation function can be chosen from a
group of commonly used set, and in this paper, they are chosen
from Gaussian kernal, sigmoidal, sine and hardlim functions,
among which hardlim possesses the best performance. For
the on-line updating capability, we use one-by-one updating
strategy. The essence is like a sliding window, and the first data
record in the window is the one that needs to be discarded
while new data is included. For this reason, the scheme
maintains the same size of data as the initialization step does.
So the initial dataset size not only determine the complexity
of initializing an ELM network, but also the one of updating
it. Together with the number of hidden layer neurons, these
two parameters are essential to the performance of the model,
and require experiments to find the appropriate values.
During the experiments presented in the next section, the
model based on OSELM with forgetting mechanism has two
limitations as follows.
1) The dataset used in the initial step should be large

enough, otherwise the model will be highly inaccurate.
2) The size of the ELM network should be large enough
to model the changes in a small time window.
The large number of dataset size for initialization implies
that the method has to collect enough data before generating
predictions. And large amount of data also brings another
problem of high computation complexity of calculating output
weight β. Because the updating step uses the same amount of
data as the initial step does, the complexity exists not only
in the beginning of the scheme, but in all the procedures.
Meanwhile, the size of the ELM network is determined by
the data feature and the hidden layer neurons. The increase of
the hidden layer neurons also contribute to the complexity of
the calculation.
B. Proposed Method for Traffic Flow Prediction
To diminish the limitations presented in the previous subsection while maintaining the same approximation ability, another
prediction scheme is proposed.
An inevitable part of the previous scheme is to calculate
the multiplication of matrices with large dimensions. The
complexity of calculating a n∗k matrix multiple a k∗m matrix
is O(n∗k∗m), so the calculation of Equ. (6) have a complexity
of O(L4 ) where L is the number of hidden layer neurons. In
the same manner, the complexity of calculating Equ. (7) is
O(L2 ). Therefore, to effectively reduce the complexity, a small
value of L is used in the proposed method. And accordingly, a
small number of initial dataset size is enough for initialization.
Meanwhile, instead of updating the model with OSELM all
the time, the proposed method periodically reconstructs the
ELM network using most recent data. In the first scheme,
the new output weight matrix βk+1 is calculated using the
previous output weight matrix βk , the oldest data (Xo , To )
and the incoming data (Xk+1 , Tk+1 ) as described in Equ. (6)
and (7). To get rid of any possible influences that the discarded
data might do to the current prediction, the reconstruction step
use only the newest m number of data as described in Alg. 2.
Because the scale of the ELM network is small, the time for
reconstructing the ELM network will not severely damage the
performance. The details of the method is as follows.
In the beginning, the first m number of data is used to
construct a base ELM network as Fig. 2 shows. The procedure
is the same as OSELM with forgetting mechanism, and the
only difference is the small value of m. In the experiments
presented in the next section, the results show that the value
of m can be 10 times smaller than the first scheme requires.
In the updating steps, for each incoming data (Xt+1 , Tt+1 ),
the scheme updates itself using the procedure of OSELM for
k times, and then reconstructs a new ELM network using the
most recent m number of data. The alternation of updating
and reconstruction covers the entire life circle of the scheme.
Unlike OSELM with forgetting mechanism whose model
keeps updating after initialization, the predictor used in the
proposed scheme ensures that the current prediction is affected
by no more than the newest m + k number of data. However,
the decrease of the value k indicates the increase of the

145

100

Prediction Results with 2500 Initial Data
300 Hidden Layer Neurons
600 Hidden Layer Neurons
900 Hidden Layer Neurons
1200 Hidden Layer Neurons
1500 Hidden Layer Neurons
Real Traffic Count

80
Prediction Traffic Count

Algorithm 2 Traffic Flow Prediction using Proposed Scheme
Input:
ActT ype := the same definition as Alg. 1,
L := the same definition as Alg. 1,
m := the same definition as Alg. 1,
s := the number of continuous updating steps
Output:
P := predictions of traffic flow
1: initialize the parameters for activation functions:
randomly assign (ai , bi ) as described in Equ. (1) for L
hidden layer neurons;
2: construct the ELM network:
calculate output weight matrix H0 ;
calculate M0 using M0 = (H0T H0 )−1 ;
calculate β0 using Equ. (3);
3: generate the first prediction:
calculate H1 ;
calculate prediction result using P1 = H1 β0 ;
store P1 in P ;
4: count = 0;
5: while incoming data (Xk+1 , Tk+1 ) is received, do
6:
if count < s then
7:
updating ELM network using original OSELM:
calculate Mk+1 using Equ. (4);
calculate βk+1 using Equ. (5);
8:
else
9:
reconstruct ELM network:
count = 0
select most recent m data;
calculate M0 using M0 = (H0T H0 )−1 ;
calculate β using Equ. (3);
10:
end if
11:
generate the (k + 2)th prediction:
calculate Hk+2 ;
calculate prediction result using Pk+2 = Hk+2 βk+1 ;
store Pk+2 in P ;
12:
count+ = 1;
13: end while
14: return P ;

60

40

20

0

-20
2500

3000

3500
4000
Time Series

4500

5000

Fig. 2. Prediction results of OSELM with forgetting mechanism using 2500
initial dataset size. Five different number of hidden layer neurons, namely
300, 600, 900, 1200 and 1500, are evaluated. The value of X indicates 5X
minutes after 00:00 on Jan. 1st 2011, and the axis of Y shows the value of
traffic flow.

and in order to make the results clear, only 2500 predictions
are shown on the graphs.
To imitate the streaming data, the traffic flow counts are
retrieved from the dataset and transfered to the algorithms
one by one. The processing time is recorded when the same
amount of data is received and the corresponding predictions
are made, and the accuracy is compared by Root Mean Square
Error (RMSE) using Equ. (8),
√∑
RM SE =
(P − T )2 /N
(8)

where P is the traffic flow prediction result, T is the actual
traffic flow, and N is the number of data. Unlike other
experiments where the data can be normalized first, the traffic
counts cannot be performed with the operation for they are
continuously generated from the source. In this case, the
RMSE values for different configurations are computed each
time when a new prediction is generated.
A. Prediction Evaluation For OSELM with Forgetting Mechanism

reconstruction steps which in the proposed scheme is time
consuming. To made a trade-off, an appropriate k is required.
In this paper, the value of k is set to be m/2.
Although there is one more parameter in the proposed
scheme, the small value of both m and k enable the model
to predict the traffic trend in a small time window while
maintaining a small size of ELM network. The experimental
results in the next section also confirm it by a detailed
comparison of the two scheme.
IV. E XPERIMENT E VALUATION
In order to evaluate the performance, experiments are conducted on both of the schemes discussed in the previous section. The traffic counts used in the experiments are collected
on a specific road with no missing data throughout the years,

For OSELM with forgetting mechanism, two separate experiments are conducted to evaluate the performance on different
configurations. There are two parameters, namely the number
of hidden layer neurons and the initial dataset size, that require
analyses.
The first experiment examines the effects of different hidden
layer neurons. The parameter of initial dataset size is fixed to
be 2500, and the comparison is given by calculating the RMSEs with the number of hidden layer neurons set respectively
to 300, 600, 900, 1200 and 1500. Fig. 2 and 3 are the graphs
of 2500 prediction results and the corresponding RMSE values
for the five different configurations. It is shown in Fig. 2 that
all the predictions basically coincide with the real traffic count,
and increasing the number of hidden layer neurons does not
guarantee the improvement of the accuracy. For example, the

146

RMSE with 2500 Initial Data

11.5

RMSE with 900 Hidden Layer Neurons
50 Initial Data
500 Initial Data
1000 Initial Data
2000 Initial Data
2500 Initial Data

25
Root Mean Square Error

11
Root Mean Square Error

28

300 Hidden Layer Neurons
600 Hidden Layer Neurons
900 Hidden Layer Neurons
1200 Hidden Layer Neurons
1500 Hidden Layer Neurons

10.5

10

9.5

20

15

9

8.5
2500

3000

3500
4000
Time series

4500

10
9
2500

5000

Fig. 3. RMSE of OSELM with forgetting mechanism using 2500 initial
dataset size. Five different number of hidden layer neurons, namely 300, 600,
900, 1200 and 1500, are evaluated. The value of X indicates 5X minutes after
00:00 on Jan. 1st 2011, and the axis of Y shows the value of RMSE. The
RMSE value shows how much the prediction deviates from the real traffic
flow.

100

Prediction Results with 900 Hidden Layer Neurons
50 Initial Data
500 Initial Data
1000 Initial Data
2000 Initial Data
2500 Initial Data
Real Traffic Count

Prediction Traffic Count

80
60
40
20
0
-20
-30
2500

3000

3500
4000
Time series

4500

5000

Fig. 4. Prediction results of OSELM with forgetting mechanism using 900
hidden layer neurons. Five different numbers of initial dataset size, namely
50, 500, 1000, 2000 and 2500, are evaluated. The value of X indicates 5X
minutes after 00:00 on Jan. 1st 2011, and the axis of Y shows the value of
traffic flow.

configuration of 1200 nodes predicts negative values instead
of zero at the bottom of curve. Meanwhile, Fig. 3 shows that
the increase of the hidden layer neurons generally results in a
small RMSE value, and all the configurations evaluated in the
experiment maintain RMSE values above 9.
Combined with Fig. 2 and 3, the scheme using OSELM with
forgetting mechanism achieves less RMSE values when there
are more nodes in the hidden layer. However, the computing
time increases as well. To generate applicable result in real
time, the value is around 900 under the condition of this
experiment.
The other experiment is conducted by calculating the performance using 900 hidden layer neurons, and the initial dataset

3000

3500
4000
Time series

4500

5000

Fig. 5. RMSE of OSELM with forgetting mechanism using 900 hidden layer
neurons. Five different numbers of initial dataset size, namely 50, 500, 1000,
2000 and 2500, are evaluated. The value of X indicates 5X minutes after
00:00 on Jan. 1st 2011, and the axis of Y shows the corresponding RMSE.
The RMSE value shows how much the prediction deviates from the real traffic
flow.

size is set to be 50, 500, 1000, 2000, and 2500. Fig. 4 and 5
shows the prediction results and corresponding RMSE values
for different initial dataset sizes. In Fig. 4, it is shown that
with small number of initial dataset size, the performance is
not satisfying. For example, with 50 initial dataset size, the
prediction model can hardly predict anything. Even with 1000
initial dataset size, the predictor is still less than satisfactory.
Meanwhile, the RMSEs in Fig. 5 indicate that the increase of
initial dataset size can decrease the values.
The second experiments shows that when using OSELM
with forgetting mechanism for traffic flow prediction, it is
possible to increase the accuracy by increasing the value of
initial dataset size. However, the increase of the initial dataset
size also contributes to the computation complexity. In the
conditions of this experiments, the value is 2500.
The processing time is recorded on using the same number
of initial dataset size to predict the next 2500 traffic counts.
Table I shows that, to maintain a sufficient accuracy for
OSELM with forgetting mechanism, the number of neurons
should be no less than 900, and in this case, the overall
processing time is over 69 seconds.
B. Prediction Evaluation for the Proposed Method
For the proposed scheme, two separate experiments are used
to evaluate the effects of initial dataset size and the number
of hidden neurons. Unlike the configurations in the previous
subsection, only three initial dataset sizes are evaluated in
the first experiment. Because the processing time significantly
grows with the increase of the value, and to evaluate the configuration, on which the model cannot provide near real time
processing, is pointless. For the same reason, the evaluation on
different hidden layer neurons does not use the same values as
the previous subsection does. Meanwhile, the updating step k
is not evaluated because no comparison can be made between

147

P ROCESSING

TABLE I
C OMPARISON FOR T WO S CHEMES

50

N/A

6.544

N/A

13.583

150

N/A

26.500

300

4.068

113.538

600

26.067

1460.791

900

69.160

N/A

1200

145.108

N/A

1500

263.076

N/A

9

8.5

8

7.5
2500

3000

4500

5000

Fig. 7. RMSE of the proposed scheme using 150 hidden layer neurons. Three
different initial dataset sizes, namely 50, 100 and 150, are evaluated. The value
of X indicates 5X minutes after 00:00 on Jan. 1st 2011, and the axis of Y
shows the corresponding values of RMSE. The RMSE value shows how much
the prediction deviates from the real traffic flow.

50 Initial Data
100 Initial Data
150 Initial Data
Real Traffic Count

50
40

100

Prediction Results with 50 Initial Data
50 Hidden Layer Neurons
100 Hidden Layer Neurons
150 Hidden Layer Neurons
300 Hidden Layer Neurons
600 Hidden Layer Neurons
Real Traffic Count

30
80
Prediction Traffic Count

20
10
0
2500

3500
4000
Time series

Prediction Results with 150 Hidden Layer Neurons

60
Prediction Traffic Count

RMSE with 150 Hidden Layer Neurons
50 Initial Data
100 Initial Data
150 Initial Data

Processing Time (Second)
Scheme using OSELM
Proposed Scheme
with Forgetting Mechanism

100

70

9.5

Root Mean Square Error

Number of
Hidden Layer
Neurons

TIME

3000

3500
4000
Time series

4500

5000

Fig. 6. Prediction results of the proposed scheme using 150 hidden layer
neurons. Three different initial dataset sizes, namely 50, 100 and 150, are
evaluated. The value of X indicates 5X minutes after 00:00 on Jan. 1st 2011,
and the axis of Y shows the values of traffic flow.

60

40

20

0
2500

the two schemes. As described in the previous section, the
value of k is fixed to be half of the initial dataset size for
performance considerations.
The first experiment in this subsection evaluates the effects
of different initial dataset size. The number of hidden layer
neurons is set to be 150 for it has the mean performance in the
other experiment. Three different initial dataset sizes, namely
50, 100 and 150, are chosen in the experiments. Fig. 6 and
7 are the prediction results and corresponding RMSE values.
As shown in Fig. 6, the increase of the initial dataset size
causes a few large deviation, and the value of 50 has the best
performance in general. Combined with Fig. 7, it is shown
that the scheme tends to favor small values of initial dataset
size, and simply increasing the number will not decrease the
RMSE. For example, the curve with 150 initial dataset size
has some large deviations around the zero traffic count values
in Fig. 6, although it has the similar RMSE as the curve of
50 initial dataset size does. Both Fig. 6 and 7 indicate that
a small number of initial dataset size can provide effective
predictions, and under the conditions of the experiment, the
value can be set to 50.

3000

3500
4000
Time Series

4500

5000

Fig. 8. Prediction results of the proposed scheme using 50 initial data. Five
different number of hidden layer neurons, namely 50, 100, 150, 300 and 600,
are evaluated. The value of X indicates 5X minutes after 00:00 on Jan. 1st
2011, and the axis of Y shows the value of traffic flow.

The other experiment is to evaluate the effects of different
number of hidden layer neurons. Based on the results of the
first experiment, the initial dataset size is set to be 50, and
a group of five different numbers of hidden layer neurons,
namely 50, 100, 150, 300 and 600, is tested. The data used in
the experiment is the same with the one used in the previous
subsection.
The Fig. 8 and 9 present the prediction results and the
corresponding RMSE values. In Fig. 8, it is shown that all
predictors generate effective predictions with small deviations
from the real traffic counts. Meanwhile, Fig. 9 indicates that
the increase of the hidden layer neurons results in the decrease
of RMSE values. However, the increase of hidden layer
neurons brings another problem of extremely high processing
time. For example, the processing time in Table I shows that

148

50 Hidden Layer Neurons
100 Hidden Layer Neurons
150 Hidden Layer Neurons
300 Hidden Layer Neurons
600 Hidden Layer Neurons

11
Root Mean Square Error

hidden layer neurons for the proposed method can be half the
size of the first scheme. As a result, the proposed scheme has
a better applicability to provide an adaptive model for short
term traffic flow prediction.

RMSE with 50 Initial Data

12

ACKNOWLEDGMENT

10

The authors would like to thank Arizona State University
for providing the traffic dataset and other supports in this
research. The work presented in this paper is funded by China
Scholorship Council (CSC) under No. 201406070043 and
the Science and Technology Department of Sichuan Province
under No. 2015SZ0045.

9

8

7

6
2500

R EFERENCES
3000

3500
4000
Time series

4500

5000

Fig. 9. RMSE of proposed scheme using 50 initial data. Five different number
of hidden layer neurons, namely 50, 100, 150, 300 and 600, are evaluated. The
value of X indicates 5X minutes after 00:00 on Jan. 1st 2011. The axis of Y
shows the value of RMSE. The RMSE value shows how much the prediction
deviates from the real traffic flow.

it takes over 20 minutes when 600 hidden layer neurons are
used in the scheme. Under the condition of the experiment,
the best option for the number of hidden layer neurons is 150.
As described in the beginning of the section, the traffic
counts cannot be normalized beforehand, which results in a
relatively high RMSE values. In this case, both of the schemes
achieve effective predictions with RMSE values around 9.
However, the requirements of the initial dataset size and the
number of hidden layer neurons for the proposed scheme are
10 times smaller than the other one does. Increasing of the
hidden neurons can result in a smaller RMSE values and a
significantly high processing time. However, considering the
real time requirements, the proposed method can choose a
smaller hidden neurons while obtaining the similar RMSE
values as the previous scheme has. The experimental results
with the best configurations for both the schemes also confirm
it.
V. C ONCLUSION
In this paper, we focus on building an adaptive model with
real time requirements for short term traffic flow prediction.
The data used in the paper is collected in urban area, and is
highly dynamic. To effectively model the trend, a novel neuron
network approach, called OSELM with forgetting mechanism, is adopted, and the experimental results show effective
predictions are generated. However, in order to generate an
effective approximation, the method requires a large amount
of initial dataset size as well as a large number of hidden
layer neurons. To improve the applicability, another scheme
based on OSELM is proposed. Unlike the former method,
it periodically updates and constructs the ELM network.
Experimental comparisons are conducted using the same traffic
data, and the results show that, with ten times smaller size of
initial dataset, the proposed one is able to achieve the similar
accuracy as the first scheme does. Meanwhile, the number of

[1] J. Wu, G. Qi, and Y. Du, “A high performance traffic flow forecasting and
management method: Traffic simulation platform,” in 7th International
Conference on Computing and Convergence Technology (ICCCT), Seoul,
Korea, Dec.3-5, 2012, pp. 443–449.
[2] E. I. Vlahogianni, M. G. Karlaftis, and J. C. Golias, “Short-term traffic
forecasting: Where we are and where were going,” Transportation
Research Part C: Emerging Technologies, vol. 43, no. 1, pp. 3–19, Jun.
2014.
[3] W. Zheng, D.-H. Lee, and Q. Shi, “Short-term freeway traffic flow
prediction: Bayesian combined neural network approach,” Journal of
Transportation Engineering, vol. 132, no. 2, pp. 114–121, Feb. 2006.
[4] B. Ghosh, B. Basu, and M. OMahony, “Bayesian time-series model for
short-term traffic flow forecasting,” Journal of Transportation Engineering, vol. 133, no. 3, pp. 180–189, Mar. 2007.
[5] T. Mai, B. Ghosh, and S. Wilson, “Multivariate short-term traffic flow
forecasting using bayesian vector autoregressive moving average model,”
in Transportation Research Board 91st Annual Meeting, no. 12-3728,
Jan.22-26, 2012.
[6] X. Jiang and H. Adeli, “Dynamic wavelet neural network model for
traffic flow forecasting,” Journal of Transportation Engineering, vol.
131, no. 10, pp. 771–779, Oct. 2005.
[7] S. Ding, X. Xu, and R. Nie, “Extreme learning machine and its
applications,” Neural Computing and Applications, vol. 25, no. 3, pp.
549–556, Sep. 2014.
[8] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, “Extreme learning machine:
theory and applications,” Neurocomputing, vol. 70, no. 1, pp. 489–501,
Dec. 2006.
[9] J. Zhao, Z. Wang, and D. S. Park, “Online sequential extreme learning
machine with forgetting mechanism,” Neurocomputing, vol. 87, pp. 79–
89, Jun. 2012.
[10] G. Huang, G.-B. Huang, S. Song, and K. You, “Trends in extreme
learning machines: A review,” Neural Networks, vol. 61, pp. 32–48,
Jan. 2015.
[11] G.-B. Huang, “An insight into extreme learning machines: random
neurons, random features and kernels,” Cognitive Computation, vol. 6,
no. 3, pp. 376–390, Sep. 2014.
[12] G.-B. Huang, N.-Y. Liang, H.-J. Rong, P. Saratchandran, and N. Sundararajan, “On-line sequential extreme learning machine,” in the IASTED
International Conference on Computational Intelligence (CI 2005),
Calgary, Canada, Jul. 4–6, 2005.
[13] X. Wang and M. Han, “Online sequential extreme learning machine with
kernels for nonstationary time series prediction,” Neurocomputing, vol.
145, pp. 90–97, Dec. 2014.
[14] Y. Ye, S. Squartini, and F. Piazza, “Online sequential extreme learning
machine in nonstationary environments,” Neurocomputing, vol. 116, pp.
94–101, Sep. 2013.
[15] J. Chen, G. Zheng, C. Fang, N. Zhang, H. Chen, and Z. Wu, “Time-series
processing of large scale remote sensing data with extreme learning
machine,” Neurocomputing, vol. 128, pp. 199–206, Mar. 2014.
[16] S. Clark, “Traffic prediction using multivariate nonparametric regression,” Journal of Transportation Engineering, vol. 129, no. 2, pp. 161–
168, Mar. 2003.
[17] M. Lippi, M. Bertini, and P. Frasconi, “Short-term traffic flow forecasting: An experimental comparison of time-series analysis and supervised
learning,” IEEE Transactions on Intelligent Transportation Systems,
vol. 14, no. 2, pp. 871–882, Jun. 2013.

149

COMMAG_GUEST_EDITORIAL-Fu.qxp_Guest Editorial 3/3/15 3:26 PM Page 61

GUEST EDITORIAL

MOBILE CLOUD COMPUTING

Xiaoming Fu

M

Stefano Secci

obile Cloud Computing refers to an infrastructure
where both the data storage and the data processing occur outside of the mobile device. Mobile cloud
applications move the computing power and data storage
away from mobile devices and into the cloud, bringing
applications and mobile computing not only to smartphone
users but also to a much broader range of mobile subscribers.
Cloud computing is an emerging paradigm for cost efficient and reliable service provisioning. Today, the rich
availability of energy-harvesting and resource-constrained
mobile computing devices is beginning to converge with
the great opportunity offered by the powerful cloud computing services hosted by virtualized data center resources.
Although mobile applications, cloud computing, and data
center networking techniques have been intensively investigated in the past couple of years, mobile cloud computing
and mobile cloud networking have not raised the attention
of the research community until recently.
In this feature topic we are pleased to introduce a series
of state-of-the-art papers on this specific area. These articles cover the subject from a variety of perspectives, offering the readers an understanding of mobile cloud
computing. A total of five papers were finally selected for
this feature topic out of 33 submissions after a strict peer
review process. They cover a broad range of the field of
mobile cloud computing. While some articles focus on
understanding the challenges and potential ways for
improving the mobile cloud computing architectures and
mechanisms like mobile code offloading, cloudlets and
mobility, others suggest complimenting or applying the
state-of-the-art mobile cloud computing technique, e.g.
leveraging mobile devices’ crowdsourcing and computation
capabilities in accessing mobile cloud services.
An important trend occuring in the area of mobile
cloud computing is the geographical distribution of cloud
facilities, with the deployment of small-size data-centers to

IEEE Communications Magazine • March 2015

Dijiang Huang

Rittwik Jana

form local-area clouds. In the first article, “An Open
Ecosystem for Mobile-Cloud Convergence,” Satyanarayanan et al. discuss how the emergence of Cloudlets,
local-area cloud solutions at or close to the premises of
cloud users, can improve the user experience and argue
how their deployment practices shall follow openness and
neutrality principles.
The citizens’ locations and movement patterns in daily
life are of high relevance to many applications such as city
planning, traffic control and personalized recommendations. In the second article of this feature topic, “Estimating Users’ Home and Work Locations Leveraging
Large-scale Crowd-sourced Smartphone Data,” Liu et al.
utilize crowd-sourcing techniques to collect mobile users’
location data, and leverage the cloud to estimate large
scale users’ home and work location data with a good estimation accuracy.
In the third article, “Mobile Code Offloading: From
Concept to Practice and Beyond,” Flores et al. present
issues and challenges in mobile code offloading, that is,
when mobile devices can execute part of or the entire
application using external cloud computing facilities, and
propose improvements in the state of the art code offloading approaches.
As mobility is one of the main sources of energy harvesting and limited connectivity for mobile devices, mobility-augmented cloud service provisioning becomes an
emerging issue in mobile cloud computing. In the fourth
article, “Mechanisms and Challenges on Mobility-Augmented Service Provisioning for Mobile Cloud Computing,” Li et al. provide an architecture and taxonomy of
research challenges related to mobility augmentation, heterogeneous network convergence, and mobile service provisioning.
Besides data collection, mobile crowdsourcing can offer
various other pervasive services, such as data processing
(Continued on next page)

61

COMMAG_GUEST_EDITORIAL-Fu.qxp_Guest Editorial 3/3/15 3:26 PM Page 62

GUEST EDITORIAL
and computing. In the last article of this feature topic,
“Exploiting Mobile Crowdsourcing for Pervasive Cloud
Services: Challenges and Solutions” Ren et al. adopt the
mobile cloud computing paradigm for mobile crowdsourcing, leveraging the sensing and computational capabilities
of mobile devices as well as user intelligence.
We hope that these articles will help readers understand the state-of-the-art advances in mobile cloud computing, providing current visions of how the mobile cloud
computing architectures and applications may be developed, improved and evolving. In preparing this feature
topic, we wish to thank all the peer reviewers for their
efforts in carefully reviewing the manuscripts to meet the
tight deadlines. We are grateful to the editor-in-chief Sean
Moore for his timely and constructive suggestions.

tions, including content distribution, mobile and cloud computing and
social networks. He is an IEEE Distinguished Lecturer, and was IEEE ComSoc
TCCC vice chair and Internet TC chair.

BIOGRAPHIES

RITTWIK JANA is a lead inventive scientist at AT&T Labs Research. He received
his B.E. degree from the University of Adelaide, Australia, in 1994, and a
Ph.D. from the Australian National University in 1999. He worked as an
engineer at the Defense Science and Technology Organization (DSTO), Australia from 1996 to 1999, and as a member of technical staff at AT&T, New
Jersey since 1999. His research expertise falls in the areas of IPTV, P2P,
mobile middleware, and wireless channel modeling.

XIAOMING FU (fu@cs.uni-goettingen.de) received his Ph.D. from Tsinghua
University, China in 2000. After nearly two years of postdoc work at TU
Berlin, he joined the University of Göttingen, where he is a professor of
computer science and head of the Computer Networks Group since 2007.
His research interests lie in network architectures, protocols and applica-

62

STEFANO SECCI received his Ph.D. from Politecnico di Milano, Italy, and Telecom ParisTech, France, in 2009. After postdoctoral experiences at NTNU,
Norway, and George Mason University, USA, he joined the University Pierre
and Marie Curie, France, where he is an associate professor of telecommunication networks. His research interests lie in network architectures, protocols and applications, including network routing and mobile and cloud
networking. He is vice chair of the IEEE ComSoc/ISOC Internet Technical
Committee.
D IJIANG H UANG is currently an associate professor at the School of Computing Informatics and Decision Systems Engineering at Arizona State
University. His current research interests are in computer and network
security, mobile ad hoc networks, network virtualization, and mobile
cloud computing. His research is supported by federal agencies (NSF,
ONR, ARO, and NATO) and industrial organizations. He is a recipient of
the ONR Young Investigator Award and HP Innovation Research Program
(IRP) Award.

IEEE Communications Magazine • March 2015

ISIT 2009, Seoul, Korea, June 28 - July 3, 2009

On An Information Theoretic Approach to Model
Anonymous MANET Communications
Dijiang Huang
Computer Science and Engineering Department
Arizona State University University
Tempe, AZ 85287, USA
Email: dijiang @asu.edu

Abstract-Measuring communication anonymity (e.g., unlinkability) of anonymous communication systems is a critical,
however, unsolved problem. To address this issue, we present
an information theoretic model for unlinkability measure for
MANETs. Our approach is based on evidence theory, where
the basic measuring component is a "set". We present a traffic
slicing method to model mobility followed by theoretical models
to evaluate sender and receiver unlinkability, path unlinkability,
and system unlinkability.

I. INTROD UCTION

Concealing users' identities and their end-to-end communication relations are two major anonymity requirements
for anonymous communication systems. Address and routing anonymizing techniques have been proposed to fulfill
these requirements. The address anonymizing technique either removes address information from the protocol or uses
pseudonym -based approaches to hide addresses and identities. The routing anonymizing technique segments end-to-end
packet forwarding information in a hop-by-hop manner, and
re-encrypts packets with different cryptographic keys in both
route discovery and packet forwarding processes. Using these
anonymizing techniques, anonymou s communication systems
can preserve communication privacy for users and protect
communication relations from attackers.
To evaluate anonymity performance of a communic ation
system, Shannon information theoretic models [I], [2], [3]
were proposed to define the notion of "more evenly distributed" by assigning probability distributions to anonymity
sets. These models were applied to evaluate the anonymous
performance for Internet based protocols , and they compare
the optimal situation, i.e., every subject in the anonymity
set has the same probability with respect to actions, with
the situation where the subjects might be assigned different
probabilities due to additional information. This information
theoretic approach uses probability theory as the mathematic al
tool and use uncertainty as the measuring metric to quantify
(i.e., in number of bits) the unlinkability.
In this paper, we present an anonymity modeling technique
based on evidence theory [4] for evidence collection, processing, and measurement. We present an information theory
based unlinkability model. Our solution is the first attempt
to address the anonymity measurement for Mobile Ad hoc
Networks (MANETs) using information theory. Particularly,
978-1-4244-4313-0/09/$2 5.00 ©2009 IEEE

we take into considerations the wireless channel properties .
Our solution is suitable for various anonymous communication
scenarios of MANETs .
Our paper is arranged as follows: in Section II, we
present the evidence collection and processing models for
constructing point-to-point and multi-hop evidence matrices. In section III, we present an information theory based
anonymity/unlinkability measuring models. Finally, we conclude our work in section IV.

II. EVID E NCE COLL ECTIO N AND PROC ESSI NG
Our research is inspired by evidence theory-based modeling
techniques [4], which includes three phases: evidence collection, processing, and evaluation . Before using information
theoretical model, we need to collect raw data and generate
evidence for later analysis. To this end, we demonstrate how
to process raw data captured in MANETs. Our goal here is
to derive point-to-point evidence matrices and an end-to-end
evidence matrix within a given period for MANET activities.

A. Evidence Collection
We assume that anonymous MANET routing techniques
(such as [5], [6], [7], [8], [9], [10], [II], [12]) are applied
so that the adversaries cannot discover any information about
the communication patterns from the captured packets. For
demonstration purpose , the PHY/MAC layer is controll ed by
the commonly used 802.11(alb/g) protocol. However, all MAC
frames are encrypted so that the adversaries cannot decrypt
them and reveal the contents. The "virtual carrier sensing" is
disabled to prevent adversaries from identifying point-to-point
communication peers. Furthermore, the source/destination addresses in MAC and IP headers arc set to broadcasting
addresses (i.e., all " 1") or using identifier changing techniques,
such as [13], to anonymize the nodes' identities.

1629

611

b t2

t~t2
I

WI

I

,

b tk ,

~tk
TrafficicaPlured in 6. /k

w,

W2

'-----------~--------------K slices: W llxK= {W k Ik= I, ...,K }
Fig. I.

Slicing the time doma in.

ISIT 2009, Seoul, Korea, June 28 - July 3,2009

We present a "slicing" technique to partition MANET communications in time domain as shown in Fig. I to effectively
handle the mobility by constructing a sequence of relatively
fixed networks. To this end, we slice a period T into a
sequence of time intervals l:>.h , l:>.t2, ..., l:>.tK , and record
the captured packets into their corresponding traffic matrices
W IIXK=(W 1 , W 2 , ... , W K ) . In each traffic matrix Wk =
(W e(i ,j )) NX N (N is the size of the network, k=l, 2, ..., K),
the entry w e(i ,j) is the point-to-point traffic volume (number of
packets) captured from node i to node j (we define W e( i ,i ) to be
0). We use e(i , j ) to denote a link from mobile node i to node
j as long as they are in each other's communication range.
The criterion to create a W k is that W e(i ,j ) must represent
a point-to-point evidence, e.g., a captured packet from i to j .
Suppose within time intervals l:>.h = t2 - t 1 and l:>.t2 = t 3- t 2,
we capture a packet from node i to node j and a packet from
node j to node l, respective. We cannot construct a matrix
W k with W e(i ,j) = 1 and W e (j ,l ) = 1, since we will omit the
potential transmissions from node i to node l through node
j. Instead, we should create two separate matrices W k and
W k+l including w e( i ,j ) = 1 and w e (j ,/) = 1, respectively.
Later, we will present an algorithm to derive multi-hop traffic
matrix from W !lXK .
The construction of matrices W ltxK will automatically
involve mobility in the traffic matrices constructions. This
means that the location of each mobile node is known. This
assumption is built based on many realtime location tracking
solutions with location tracking accuracy from l m-vl Om [14].
For example, traffic matrix W e is created for direct transmissions between nodes during a time interval. Since each
snapshot of the network is triggered by capturing a packet,
as long as a potential receiver j is located within the sender
i 's communication range (i.e., d i j :::; r ), a small change of
distance di j due to mobility will not affect their transmission
relations . If j moves out of the communication range of i due
to the mobility, the value w e( i ,j) = o.
To determine if a captured message is successfully received
by a receiver, we use the channel model presented in [15],
where the authors derived the successful reception probability
(P) as a function of distance (d) between a transmitter and
a receiver under the log-normal shadow fading model. In
particular, P( d) can be approximated as:
1 - ((sJy i3) /2 d :::; R,
P(d) = { (etzIJ)2i3) /2 d > R,
(1)

Fig. 2.

. (c) .... . . .. .

.

(b) Wireless connec tions with (c ) Wifeless connccuo ns

shared med ia
I. receive r SCI R is c risp
2. limited sende r ano nymity

w ith broa dcast ing medi a
I. receive r SCI R is ru Zl:~
2. lim ited se nde r a no nymity

One-hop wired vs wireless communications.

ANODR [17], anonymous wireless communication protocols
hide the senders and receivers' addresses (i.e., both MAC
and IP addresses) . It utilizes the broadcasting property of
wireless communication channels, which can provide a certain
level of anonymity to prevent the attackers from identifying
the packet receiver. As shown in Fig. 2(b - e), the potential
receivers of packet sender s form a receiver set Vr . When the
communication range of s and the location of each node are
known, we can derive the crisp set Vr shown in Fig. 2(b) ; when
the communication range of s is unclear (or unknown), we can
estimate the potential receivers by observing their locations
and thus the receiver set is fuzzy as shown in Fig. 2(e).
In the scenario (b), all potential receivers r i (i = 1, . . . , k )
are neighbors of node s. Thus, the probability of a packet
destined to a receiver is determined by the value of k, in
which the evidence is computed as w e( i ,j) = 11k in previous
section . Here, we argue that, in mobile environments, w e (i ,j )
is changed according to the sender's transmission range and
the number of nodes within the sender's transmission radius .
We define the membership of each node in set Vr with respect
to the sender s as A [s ,vr ](ri) ' which is a value in [0,1] . Thus,
intuitively, we can improve the original definition of We (i ,j ) as
1
follows:

IVr l A [s ,vr ](ri) .

W e( i ,j) =

(2)

In general , wireless signal strength is decreased unevenly with
respect to the distance from the signal source in various directions. This wireless transmission property can be represented
in Fig. 2(e), where the set membership is fuzzy.

where R is the distance P(R) = 1/2 , and (3 is the power
attenuation factor ranging between 2 and 6. In this way, we
can take into the considerations the channel errors due to the
increases of communication distances for each receiving node.

S,

:

,

i

S

,

:

!

!

,

'

,

'

I

•

'~
~:
~. '~

B. Improvement of One-hop Communication Model

o

Typical Internet anonymous communication solutions, such
as Tor [16], run at the application layer. Thus, its point-to-point
communications are not hidden . As illustrated in Fig. 2(a),
the packet sender and immediate packet receiver are known.
Thus, there is no sender and receiver anonymity for onehop communications. In wireless networks, as suggested in

(b)

(a)
(0) Wired connections with
dedicat ed links
I. 110 sende r anony mity
2. no receiver anonymity

d

~

IF

(a)

Fig. 3.

o

'
I

I

,

"

,

( /

IF

(b)

Membership in fuzzy set.

Fig. 3(a) shows the ideal scenario of three communication
ranges of the transmitter s . Station s 's communication neighbors can be affected by s 's transmissions in a different way

1630

ISIT 2009, Seoul, Korea, June 28 - July 3, 2009

depending on the distance from s and the selected transmission
rate. Based on the 802.11 channel model proposed in [18], we
classify three ranges as follows:
• Stations at a distance d < T X are able to correctly
receive data from s, if s transmits at a rate lower or equal
to x.
• Stations at a distance d, where d < IF, they share
the same physical channel; however, multi-station transmissions will cause low signal to noise ratio (SNR).
As a result, within the IF of multiple transmitters, the
receiver can only correctly demodulate frames from a
single source at a time.
• Stations at a distance d, where d < PC S, they are able
to sense the physical carrier and detect the transmissions
from other wireless nodes.
Since wireless signal transmission strength is unevenly distributed, we specify three round belt areas for T X, IF,
and PC S, respectively as shown in Fig. 3(b). We present
three belt areas with width ll, l2, and l3. They are centered
symmetrically at the distance T X, IF, and PCS, respectively.
As we are interested in the direct transmission relation, we
only focus on the transmission range T X. In this case, we
have the membership function 0 ~ A[s,vr ] (ri) ~ 1. If the
membership is decreased linearly within ll, we can derive the
following formulas for the membership function:
O<d<TX_h.
1,
2'
A[s,Vr ] (ri) ==

{

~ - d-l~X'

TX - ~ ~ d < TX +~;

0,

TX

+ ~ < d.

Apply (3) in (2), we can improve the evidence collection
each receiver.

c.

3:
4:

1:

R==W 1

for k= 1 to K - 1 do
R == a(R, Wk+l) + Wk+l
return j3(R)

Note that, in each iteration, the addition (a (R, W k+1) +
W k+l) including the multi-hop traffic derivation function a
shown as in Algorithm 2 and the addition of the point-topoint traffic matrix. The function j3 removes packets that travel
exceeding the multi-hop threshold in the end-to-end traffic
matrix R.
In Algorithm 2, the number of captured packets rather
than the actual size of payloads is considered as the "traffic

R' ==R

for i=1 to N do
3:
for k=1 to Nand k i- i do
4:
for j= 1 to N do
5:
for each x E Wk+l(j, k).pkt do
6:
if =:3 y E r(i,j).pkt s.t. x.time - y.time < T
and y.hop < H then
7:
create z with z.time == x.time
z.hop == y.hop + 1
z.vsize == mini x.vsize, y.vsize}
8:
r'(i, k).pkt=r'(i, k).pkt U {z}
9:
r'(i, k)= r'(i, k)+z.vsize
10: return R'
2:

End-to-End Traffic Matrix

Algorithm 1 -f(W/IxK)
1:

Algorithm 2 -a(R, W k + 1 )

~~f

Given a sequence of point-to-point traffic matrices WIIXK,
our goal is to derive the end-to-end traffic matrix R ==
(r(i, j) )N x N, where r (i, j) is the accumulative traffic volume
from node i to node j, including both the point-to-point traffic
captured directly and multi-hop traffic deduced from the pointto-point traffic. In this paper, we use the term accumulative
traffic matrix and end-to-end traffic matrix interchangeably.
The following Algorithm 1 (function f) takes WIIXK as the
inputs to derive their accumulative traffic matrix R.

2:

volume". Consider the following two situations sl and s2:
sl - node A sends a one-byte packet to node B; and s2
- node A sends a lK-byte packet to node B. Both sl and
s2 actually indicate the same traffic pattern. Additionally, all
the nodes within the communication range of the transmitter
have the same probability to be the real packet receivers
(after considering the error probability in (1)). For example,
if a node i broadcasts a packet in the time interval ~tk.
Within its proximity, we can use (1) to identify nodes jl,
j2, ... i; as potential receivers, the entries We(i,jl)' We(i,j2)
... We(i,jn) are all equally increased by lin. This is equivalent
to dividing a packet into n sub-packets and each targeting
to one neighboring node. For simplicity, in the rest of the
paper, we denote the original packet as "virtual size" 1 and
each of the sub-packets as "virtual size" 1In. Each packet,
e.g., p, represented as We(i,j).pkt on link e( i, j), has three
associated features: p.vsize, p.time and p.hop, denoting the
"virtual size", transmitting time, and hop counts of this packet,
respectively. Thus, every packet recorded in a point-to-point
traffic matrix has the hop-count set to 1.

The a function is a heuristic reasoning procedure that takes
two inputs at each iteration: (a) R is an end-to-end traffic
matrix derived from point-to-point matrices WI to W k, and
(b) W k+l that is the next point-to-point traffic matrix. The
output is the end-to-end traffic matrix derived from WI to
W k+1. For each packet x recorded in W k+1, the function
tries to find a packet y in R that is potentially the same
packet transmitted in x's previous hop, and two constraints
are considered: first, the time between the appearance of the
two packets must be less than the maximum round-trip transmission time; second, the hop-count of packet y must be less
than a certain threshold according to the geographic distance
between a source and its destination. In the algorithm, the
virtual size of each transmitting node restricts the maximum
traffic. It equals to the minimal number of transmissions of
each node en route. We use T and H to represent the time
and hop-count thresholds, respectively. If the network diameter
is d, the average transmission distance of a mobile node is r,
we can derive the approximated hop-count threshold as:

1631

H ==

fdlrl.

(4)

ISIT 2009, Seoul, Korea, June 28 - July 3,2009

The timing threshold T must be at least the value of the
maximum retransmission time. It depends on the specification
of the MAC protocol. For instance, if the 802.11 protocol is
being used, T is determined by the maximum number of retransmissions, the contention window size, and the exponential
back-off algorithm.

Algorithm 3 -f3(R)
1: for i, j=l to N do
2:
for each p E r(i,j).pkt do
3:
if p.hop <h then
4:
r( i, j) .pkt=r( i, j) .pkt-{p}
5:
r( i, j)=r( i, j)-p. vsize
6: return R
The f3 function erases packets from R that does not support
the end-to-end transmissions restricted by the minimal transmission hop counts h. Similar to the maximal hop counts H,
the value of h depends on the networking topology and nodes'
mobility model. Statistically, we find when applying randomwayPoint mobility model to the wireless nodes, the end-toend communication paths usually have no less than rH/2l
hops. To derive an accurate value h, simulation or emulation
based studies should be conduct to derive the best valuate h
according to different mobility models used by MANETs.
After executing f (W 11 x K ), we derive the accumulative
traffic matrix R for the time period Lf=1 ~tk, where the
ith row is the vector of outgoing traffic from node i and the
jth column is the vector of traffic destining to node j.
D. Derive Basic Probability Assignments

Given an end-to-end traffic matrix R, p(Vi,j*) is the probability that node i sends a packet to node j when the packet
is transmitted from node i. p(Vi,j*) is given as:

p(Vi,j* )

==

r(i, j) /Ri ,* == r(i, j) /

L r(i, j),

(5)

vi

j#i

where r ( i, j) represents the accumulative deduced traffic from
node i to node j via each path. R i ,* == L~. r(i,j) is the acJ
cumulative traffic to all potential receivers fr'l-om node i. Thus,
p(Vi,j*) represents the proportion of the traffic transmitted
from node i to node j to all the traffic sent by node i.
p(Vi*,j) is the probability that node j receives a packet sent
by node i. p(Vi*,j) is given as:

p(Vi*,j)

r(i, j) /R*,j == r(i, j) /

L r(i, j),

(6)

\Ii

i#j

where r( i, j) represents the accumulative deduced traffic from
node i to node j via all possible paths. R*,j == L .-:i. r(i, j)
'l-rJ
is the accumulative traffic from all possible senders to node
j. Thus, p(Vi*,j) represents the proportion of the traffic
transmitted from node i to node j to all the traffic received by
node j.
p(Vi,j) is the probability that node i sends a packet to node
j when a packet is detected. p(Vi,j) is given as:

p(Vi,j)

r(i,j)/R*,*

==

r(i,j)/

L L r(i,j),
Vi

\lj

j#i

(7)

where R*,* == Li L .~. r( i, j) is the deduced accumulative
traffic among all possibl~ communication pairs. Thus, p(Vi,j)
represents the proportion of traffic transmitted from node
i to node j to the traffic transmitted among all possible
communication pairs.
Formula (5) and (6) evaluate the receiver's probability
of one packet from one sender and from all senders to a
particular receiver j, respectively; while, (7) evaluates the
communication relations from the perspective of the whole
system.
III. ANONYMITY AND UNLINKABILITY MEASURE
Anonymity is defined as the state of being not identifiable
within an anonymity set V [19]; the anonymity set is the
set of all possible entities Vk E V, where k == 1, ... , N.
Here, we define a set of mobile nodes is represented as V.
A communication relation, X is the power set including all
possible communication relations. We use X s -+ r to represent
a directional mapping from s to r, where X s -+ r E ~ x Vr ,
s E ~, r E Vr , s is the message source and r is the
corresponding destination. In MANETs, we usually use unlinkability to describe the communication relations among
mobile nodes.
Definition 1 (Unlinkability):
1) The unlinkability set is a set V C X containing all
potential acting mobile nodes.
2) The sender/receiver unlinkability is measured by the
probability p of successfully identifying s E ~ or
r E Vr w.r.t. the transmission relation X s -+ r .
3) The communication path unlinkability is measured
by the probabilities VPi of successfully identifying
an end-to-end communication path Ve where q ==
{Xl, ... Xi, ... ,X n } , Xi E Vqi , Vqi ~ X, and n is the
path length.
4) The communication system unlinkability is measured by
the probabilities VPi of successfully identifying Vs; E
X, Vri E X, V~i ~ X w.r.t. the transmission relations
VX s -+ r , where IXI == Nand L;:1 Pi == 1.
5) Perfect unlinkability: For a given pair of mobile nodes
(s, r) EX, we can derive the perfect unlinkability measure for each communication relation X s -+ r E ~ x Vr
as:
H(V) == -log2 p(V) == log2lVI,
(8)
where H(V) is the Hartley uncertainty measure [20},
and p(V) == l/IVI is the probability to identify the
communication relation from the unlinkability set V,
such as the message sender s or the receiver r defined
by X s-+r. (8) implies that we only refer to sender
unlinkability or receiver unlinkability, i.e., we want to
identify the sender or receiver from the unlinkability set
V.
•
The perfect unlinkability implies that the maximum unlinkability can be achieved when the communication system is in
an indistinguishable state. In other words, we cannot derive
the preference of one event over another. In (8), identifying a

1632

ISIT 2009, Seoul, Korea, June 28 - July 3, 2009

sender or a receiver is equivalent to identifying an entity from
the unliability set V. Thus, achieving perfect unlinkability of
a communication system is equivalent to random guessing.
In the terminology of evidence theory [21], the previous
three steps are to build the body of evidence B == {F, p},
where F is afocal element representing the evaluated communication relation, r (i, j), and p is its probability assignment (or
mass). In [22], we used the proportion of evidence supporting
a particular F to the overall evidence supporting focal set
{F} as the probability that is assigned for that focal element.
We propose to use Kullback-Leibler divergence [23] (denoted
by KL, a.k.a., information divergence, or information gain, or
relative entropy) for evaluating the unlinkability performance
of a given MANET for all focal elements, where P == {p}
is the set of probability assignments and Q == {q} is the
maximum achievable unlinkability (using Hartley function as
presented in (8)). The KL measure is represented as follows:

KL(PIIQ) = LP(x) log2
:F

~~:~.

(9)

Using (9), the higher the KL measure, the higher the probability that an end-to-end transmission from the source node
can be identified. We then can plug in various probability
assignments given in (5), (6), and (7) to measure the receiver,
sender and system anonymity, respectively.
IV.

CONCLUSION

In this paper, we present an information theory-based unlinkability evaluation model. The proposed model is more
general and can be used for many communication scenarios
where traditional Shannon information theoretic models may
face difficulty. In addition, we present uses of the proposed
unlinkability model for one-hop and multi-hop communication
scenarios.
To our best knowledge, we first introduce and use the
information theory to model the anonymous communications
in networked communication system. We also firstly extend
the information model from one-hop to multi-hop network
scenarios. Our preliminary simulation studies have proven our
idea (due to page limits, the results are not presented here).
In our next step, we investigate the theoretic foundation to
support the proposed model. For example, the normalization of
the probability distribution in different networking scenarios
need to be further studied; generalized information theory contains a rich set of models, and thus what model are suitable for
evaluating the unlinkability of anonymous communications.
Furthermore, we will run a rich set of network experiments
and test the applicability of our approach in different network
settings.
REFERENCES
[1] C. Diaz, S. Seys, J. Claessens, and B. Preneel, "Towards Measuring Anonymity," in Proceedings of Privacy Enhancing Technologies
Workshop (PET 2002), Lecture Notes in Computer Science, vol. 2482.
Springer, 2002, pp. 54-68.
[2] A. Serjantov and G. Danezis, "Towards an Information Theoretic Metric
for Anonymity," in Proceedings of Privacy Enhancing Technologies.
Springer, 2002, pp. 41-53.

[3] G. Toth, Z. Hornak, and F. Vajda, "Measuring Anonymity Revisited,"
in Proceedings of the Ninth Nordic Workshop on Secure IT Systems,
S. Liimatainen and T. Virtanen, Eds., Espoo, Finland, November 2004,
pp.85-90.
[4] G. Shafer, A Mathematical Theory of Evidence. Princeton University
Press, 1976.
[5] J. Kong, X. Hong, and M. Gerla, "An Identity-free and On Demand
Routing Scheme Against Anonymity Threats in Mobile Ad-hoc Networks," to appear IEEE Transaction on Mobile Computing, 2007.
[6] M. Blaze, J. Ioannidis, A. Keromytis, T. Malkin, and A. Rubin, "WAR:
Wireless Anonymous Routing," Lecture Notes in Computer Science, vol.
3364, p. 218, 2005.
[7] A. Boukerche, K. EI-Khatib, L. Xu, and L. Korba, "SDAR: A Secure
Distributed Anonymous Routing Protocol for Wireless and Mobile Ad
Hoc Networks," in Proceedings of the 29th Annual IEEE International
Conference on Local Computer Networks (LCN'04). IEEE Computer
Society Washington, DC, USA, 2004, pp. 618-624.
[8] S. Seys and B. Preneel, "ARM: Anonymous Routing Protocol for Mobile
Ad hoc Networks," in Proceedings of of the 20th IEEE International
Conference on Advanced Information Networking and Applications Workshops (AINA 2006 Workshops), 2006, pp. 133-137.
[9] R. Shokri, M. Yabandeh, and N. Yazdani, "Anonymous Routing in
MANET Using Random Identifiers ," in Proceedings of the Sixth
International Conference on Networking (ICN'07), 2007, p. 2.
[10] R. Song, L. Korba, and G. Vee, "AnonDSR: Efficient Anonymous
Dynamic Source Routing for Mobile Ad-Hoc Networks," in ACM
Workshop on Security of Ad Hoc and Sensor Networks (SASN) , 2005.
[11] Y. Zhang, W. Liu, W. Lou, and Y. Fang, "MASK: Anonymous Ondemand Routing in Mobile Ad Hoc Networks," IEEE Transactions on
Wireless Communications, vol. 5, no. 9, pp. 2376-2385, 2006.
[12] Y. Qin and D. Huang, "OLAR: On-demand Lightweight Anonymous
Routing in MANETs," in The Fourth International Conference on
Mobile Computing and Ubiquitous Networking (ICMU) (Best paper
award), 2008.
[13] M. Gruteser and D. Grunwald, "Enhancing location privacy in wireless
Ian through disposable interface identifiers: a quantitative analysis," in
Proceedings of the 1st ACM international workshop on Wireless mobile
applications and services on WLAN hotspots, 2003.
[14] J. Hightower and G. Borriello, "A survey and taxonomy of location
systems for ubiquitous computing," IEEE Computer, vol. 34, no. 8, pp.
57-66, 2001.
[15] I. Stojmenovic, A. Nayak, J. Kuruvila, F. Ovalle-Martinez, and
E. Villanueva-Pena, "Physical layer impact on the design and performance of routing and broadcasting protocols in ad hoc and sensor
networks," Computer Communications, vol. 28, no. 10, pp. 1138-1151,
2005.
[16] R. Dingledine, N. Mathewson, and P. Syverson, "Tor: The SecondGeneration Onion Router," in Proceedings of the 13th USENIX Security
Symposium, August 2004.
[17] J. Kong and X. Hong, "ANODR:ANonymous On Demand Routing with
Untraceable Routes for Mobile Ad-hoc Networks," in Proceedings of
ACM MobiHoc, 2003, pp. 291-302.
[18] G. Anastasi, E. Borgia, M. Conti, and E. Gregori, "Wi-Fi in Ad
Hoc Mode: A Measurement Study," in Proceedings of IEEE Annual
Copnference on Pervasive Computing and Communications (PER COM) ,
2004, pp. 145-154.
[19] A. Pfitzmann and M. Hansen, "Anonymity, unlinkability, unobservability, pseudonymity, and identity management - a consolidated proposal
for terminology," Working draft, avaliable at http://dud.inf.tu-dresden.
delliteraturlAnon_Terminology_vO.28.doc, September 2006.
[20] R. V. L. Hartley, "Transmission of Information," The Bell System, vol. 7,
no. 3, pp. 535-563, 1928.
[21] G. J. Klir and M. J. Wierman, Uncertainty-Based Information. PhysicaVerlag, A Springer-Verlag Company, 1998.
[22] D. Huang, "Unlinkability Measure for IEEE 802.11 based MANETs,"
IEEE Transactions on Wireless Communications, no. 2, pp. 1025-1034,
Feburary 2008.
[23] T. M. Cover and J. A. Thomas, Elements of Information Theory. New
York: Wiley, 1991.

1633

A Key-Chain-Based Keying Scheme For
Many-to-Many Secure Group Communication
DIJIANG HUANG and DEEP MEDHI
University of Missouri-Kansas City

We propose a novel secure group keying scheme using hash chain for many-to-many secure group
communication. This scheme requires a key predistribution center to generate multiple hash chains
and allocates exactly one hash value from each chain to a group member. A group member can use
its allocated hash values (secrets) to generate group and subgroup keys. Key distribution can be
offline or online via the key distribution protocol. Once keys are distributed, this scheme enables a
group member to communicate with any possible subgroups without the help of the key distribution
center, and without having to leave the overall group, thus avoiding any setup delay. Our scheme
is suitable for applications where the population of a system is stable, group size is moderate,
subgroup formation is frequent, and the application is delay sensitive. Through analysis, we present
effectiveness of our approach.
Categories and Subject Descriptors: C.2.0 [Computer-Communication Networks]: General—
Security and protection; C.2.4 [Computer-Communication Networks]: Distributed Systems—
Distributed applications; G.2.1 [Discrete Mathematics]: Combinatorics—Permutations and combinations; G.2.2 [Discrete Mathematics]: Graph Theory—Path and circuit problems
General Terms: Security, Theory
Additional Key Words and Phrases: Hash chain, key chain, many-to-many secure group communication, secure group communication

1. INTRODUCTION
Group communication applications can be broadly classified into two types:
one-to-many and many-to-many. For one-to-many communication, shown in
Figure 1, a sender generates/communicates traffic to n − 1 receivers. Examples of applications are pay-TV, software distribution, secure distribution of
copyright-protected material (e.g., music), audio streaming, and so on. On the
other hand in many-to-many communications, each member can potentially be
both a sender and a receiver. Generally speaking, many-to-many communications require formation of both sender-group and receiver-group that are ad hoc
Authors’ address: Dijiang Huang and Deep Medhi, Computer Science and Electrical Engineering
Department, University of Missouri-Kansas City, 550F Flarsheim Hall, 5100 Rockhill Road, Kansas
City, MO. 64110; email: dhuang@umkc.edu, dmedhi@umkc.edu.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is
granted without fee provided that copies are not made or distributed for profit or direct commercial
advantage and that copies show this notice on the first page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior specific
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 1515
Broadway, New York, NY 10036 USA, fax: +1 (212) 869-0481, or permissions@acm.org.

C 2004 ACM 1094-9224/04/1100-0523 $5.00
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004, Pages 523–552.

524

•

D. Huang and D. Medhi

Fig. 1. One-to-many and many-to-many communications.

and the applications usually are delay sensitive. For example, potential applications are dynamic private conferencing, peer-to-peer interactive applications,
online interactive games, and so on.
In this paper, our focus is on secure group communication, and more importantly, many-to-many secure communications. It may be noted that the majority
of current work on secure group communication is for one-to-many. In this case,
centralized group management schemes are usually suitable; for example, the
sender is the group management controller. In Figure 1 (one-to-many), if we consider the population for group communication to be n, sender 1 may want to distribute private information to any possible subset of the set: {2, 3, . . . , n}. Thus,
the research on one-to-many secure group communication has been focused on
group members’ revocation—to construct the desired subgroup with minimal
user storage and group management overhead. Thus, the intuitive approach for
many-to-many communication is to use a centralized key distribution server
that is responsible for subgroup formation. However, this approach has several
deficiencies. First, the introduction of the trusted third party for group management will cause additional group setup delay; this is not suitable for interactive
real-time applications. Second, the centralized framework is vulnerable to single point failure. Third, the centralized key server must be always available
online; this deficiency restricts the usage for certain applications. For example,
in a wireless ad hoc network, the key server must maintain connections with
all group members, which severely constrains the mobility of mobile users.
Another approach for many-to-many secure group communication utilizes
the distributed group management schemes, in which the group members collaborate to build the group key, such as the Group Diffie-Hellman (GDH) method
[Ateniese et al. 1998; Burmester and Desmedt 1996; Steiner et al. 1996, 1998;
Kim et al. 2000]. This approach requires a linear number of expensive publickey operations. In addition to the computation overhead imposed by public-key
operations, each user needs to negotiate with its communication peers to maintain the communication group. This may not be desirable for delay-sensitive
and real-time interactive applications.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

525

In this paper, we develop a hybrid scheme that capture the merits of both centralized and distributed approaches for many-to-many secure group/subgroup
communication that is suitable for delay-sensitive applications which cannot
tolerant communication setup delay. Our approach has two phases: a key predistribution phase and a group communication phase. Similar to the centralized
key server approach, in the key predistribution phase, a Key Distribute Center
(KDC) distributes the keys and index key ID, user ID to each group member
via offline methods or online secure channels. During the group communication
phase, which is different from the centralized key server approach, a group
member can derive subgroup communication keys from its predistributed keys
without relying on KDC. In other words, the subgroup management is decentralized. Compared to the GDH approach, there are no negotiation procedures
and no expensive public key operations involved for setting up such subgroup
communication. We refer to our proposed group management scheme during
the group communication phase as “self-management.” To reduce the storage
overhead, we build a key-forest structure (described later in Section 5) via multiple key chains. Each “tree” (a key chain) in the key-forest structure represents
a particular key derivative relations among all group members. We propose a
key distribution scheme that builds the relations among multiple key chains,
which enable a group member to derive desired subgroup keys without needing
any help from the KDC.
Since the group member itself can validate the subgroup communications
through its predistributed keys and index key ID, user ID, our proposed
scheme is useful for applications that cannot tolerate delay (due to overhead of
subgroup setup) and have frequent occurrence of subgroups. To summarize, our
proposed secure group keying scheme is applicable with the following assumptions: (a) the overall group population is stable, (b) the group size is moderate
and is restricted by the storage requirement of a group member, (c) the subgroup
change is frequent, and (d) the application is delay sensitive.
The rest of this paper is organized as follows. In Section 2, we present a brief
literature survey related to our work. In Section 3, we list the notations that
are used throughout this paper. The requirements to design many-to-many secure group communication is presented in Section 4. In Section 5, we present
some fundamental theorem, lemmas, corollaries, and algorithms for the linear key-chain structure and the multiple key-chain structure. Based on this
foundation, we discuss corresponding keying protocols in Section 6. We then
follow up with performance assessments of the secure group keying scheme in
Section 7. Finally, we present our summary in Section 8.
2. RELATED WORK
Secure group communication keying schemes can be broadly classified into decentralized schemes and centralized schemes. The most well-known decentralized scheme is the GDH method Ateniese et al. 1998; Burmester and Desmedt
1996; Steiner et al. 1996, 1998; Kim et al. 2000. This approach requires a
linear number of expensive public-key operations. The works in Alves-Foss
[2000], Burmester and Desmedt [1995], and Kim et al. [2000, 2001] reduce the
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

526

•

D. Huang and D. Medhi

number of public-key operations. Besides the computational overhead imposed
by public-key operations, each user needs to negotiate with its communication
peers to maintain the communication group. In general, this is not suitable for
delay-sensitive and real-time interactive applications.
For centralized secure group communication keying schemes (which are all
nonpublic key solutions), we categorize them into two groups: one from the
information theory community, and the other from the Internet community.
2.1 Secure Group Communication Schemes from the Information
Theory Community
Secure group communication schemes proposed by the information theory community are broadly classified into (i) key predistribution scheme (KPS) and (ii)
broadcast encryption scheme (BES).
KPS is inspired by Blom [1985] and extensively studied by Blundo et al.
[1993, 1995, 1996, 1998], Gong and Wheeler [1990], Korjik et al. [1995],
Kurosawa et al. [1995], Leighton and Micali [1994], and Stinson and van Trung
[1998]. KPS requires a trust authority to distribute secret information in such a
way that only privileged subsets (prespecified) of participants are able to compute certain keys. For zero-broadcasting (t, ≤ w)-KPS, providing t members
subgroup communication
and

 preventing collusion among at most w members,
a user need to carry t+w−1
keys. In the worst case with t + w= n and t = w,
t−1
n−1
the maximum number of keys a user would need to possess is n/2
.
BES consists of a key predistribution phase, followed later by a broadcast message which is to be decrypted only by a privileged subset (prespecified) of participants [Berkovits 1992; Fiat and Naor 1994; Blundo et al. 1993,
1994, 1996; Just et al. 1994]. Stinson’s
  [1997] summarizes that this
 survey
approach requires a user to possess wj=0 n−1
keys for BES to prevent the colj
lusion among w users. Naor et al. [2001] developed a subset-difference method,
which requires 12 log2 n keys being stored at members with 2w communication
overhead.
2.2 Secure Group Communication Schemes from the Internet Community
Within the Internet community, we can classify secure group communication
keying schemes as key-oriented schemes (KOS) and framework-oriented schemes
(FOS). Three excellent surveys are Dondeti et al. [1999], Moyer et al. [1999],
and Rafaeli and Hutchison [2003]. Generally speaking, KOS uses key derivative
relations to build up the keying scheme. Group members use their secrets to
generate the desired group key [see Briscoe 1999; Waldvogel et al. 1999; Wallner
et al. 1999; Wong et al. 2000]. Snoeyink et al. [2001] studied the multicast key
distribution based on KOS. They gave the lower bound for adding or deleting a
user as (log n). For a sequence of m additions or evictions, the total distribution
cost is (m log n). Sherman and McGrew [2003] proposed the One-way Function
Tree (OFT) scheme in which the key distribution cost for bulk additions (m
members) remains in the order of (m log n) and the key distribution cost for
bulk eviction is improved to the order of (m log(n/m)).
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

527

FOS uses hierarchical group relations to set up group keys. FOS can be
either flat that has one group management center, or multilevel groups that
the group management overhead is distributed to multiple group management
centers [see Gong and Shacham 1994; Harney and Muckenhirn 1997; Ballardie
1996; Mittra 1997].
2.3 Summary
Most of the work mentioned above are designed for one-to-many group communication. While some of these approaches can be used in many-to-many
group communications by considering the fact that a many-to-many communication is made up of “many” one-to-many communications. When one considers issues such as communication overhead, storage constraints, and delaysensitive requirements, very few are well suited for many-to-many secure group
communication.
3. NOTATIONS
The following notations will be used throughout the rest of the paper:
N
U
uc
Kn
K(E, V)

All positive integer
Group of users {uc |c = 1, . . , n}, |U| = n
Group member uc ∈ U
Graph K composed of n vertices
Graph K composed of set of edges E = {ei j |i, j = 1, 2, . . . , n} and
set of vertices V = {vi |i = 1, 2, . . . , n}
s
Number of Hamiltonian cycles that used to create a fully
connected graph Kn , where n = 2s + 1.
t
Identify a Hamiltonian cycle, where t = 1, . . . , s
d (ui , u j ) The distance between two members ui and u j in a Hamiltonian
−
→
←
−
cycle, where d (ui , u j ) = min{ d (ui , u j ), d (ui , u j )}
−
→
d (ui , u j ) The distance between ui and u j in the increased order,
−
→
where d (ui , u j ) = ( j − i) and j > i
←
−
d (ui , u j ) The distance between ui and u j in the decreased order,
←
−
where d (ui , u j ) = (n + i − j ) and j > i
K î
A key chain {ki0 , . . . , kir }, indices î = {i0 , . . . , ir }, r ≤ n − 1 and
|K î | = r + 1 is the length of the key chain
K î(t)
A key chain allocated following Hamiltonian (permutation) cycle t
ki j
A key in key chain K î , j = {0, . . . , r}. The number of derived
subgroups of ki j is given by |ki j | = |K î | − j = r − j + 1
ki(t)j
A key in key chain K î(t)
k

A temporary session key
S
Subgroup of users, S ⊆ U
S̄
Complementary subgroup of S, S ∩ S̄ = φ and S ∪ S̄ = U
Si j
Subgroup of users that use key ki j
L
The subgroup size L = |S|
p(t)
tth permutation cycle, where t = {1, 2, . . . , s} and s = (n − 1)/2
(t)
pk
kth permutation generated by permutation cycle p(t)
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

•

528

p(t)
I
Sk(t)
h j (·)
f (·)
E(·)
D(·)
I(·)
⇒
||

D. Huang and D. Medhi
(t)
Index of a permutation cycle p(t) , p(t)
I = p0
(t)
The sequence of a permutation pk
Hash function, which hash input j times
Key generating function
Encrypting function
Decrypting function
Index function
Derivative relation
Concatenate operation

4. MANY-TO-MANY SECURE GROUP COMMUNICATION REQUIREMENTS
In this section, we discuss design requirements for secure group communication
that support many-to-many communication considering the following aspects:
communication phases, storage constraint, self-management, and key agreement protocol. All our analysis is based on a group of n users and each of them
is identified by uc , where c = 1, . . . , n.
4.1 Secure Group Communication Phases
Our proposed secure group communication scheme includes two phases: the
key predistribution phase and the group communication phase. In the key predistribution phase, a KDC distributes the keys and index key ID, user ID to
each group member via offline methods or online secure channels. Then, the
group members enter the group communication phase. During the group communication phase, a group member can derive subgroup communication keys
from its predistributed keys without relying on KDC. We refer to our proposed
group management procedure during the group communication phase as “selfmanagement.”
4.2 Storage Constraint
We assume that the key server is responsible for keys predistribution. A group
member needs sufficient space to store the secrets preinstalled by the key server
in the key predistribution phase and uses the predistributed secrets to setup
group keys during the group communication phase. Two factors restrict the
group member’s storage space: the applications and the hardware restriction.
A typical many-to-many application is private conferencing which involves intensive interactive private communications among group members. It can be
used in either a wired network environment or an ad hoc network environment.
If the size of a group is n, then the possible number of subgroups is 2n−1 − 1.
Current low-end mobile devices such as personal digital assistants (PDAs) have
memory size ranged from 8 to 128 MB or more. Thus, we assume that the end
user has the key space limitation of 1 MB to support 2n−1 −1 number of subgroup
communications.1
1 For

high-end devices, such as laptops, such storage limitation is not necessarily an issue.

ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

529

4.3 Self-Management
Our proposed scheme is suitable for real-time interactive applications and the
subgroup memberships may change frequently. This type of applications demands the minimal delay for subgroup setup for communication. We require
that a group member can self-generate the desired subgroup keys without the
help of key server after the key predistribution phase. This requirement is also
helpful for ad hoc network where the key server may not be online all the time.
4.4 Key Agreement Protocol
The sender can use a session key k 
 to encrypt data and use subgroup keys
as key-encrypting key (KEK) to encrypt the session key that is attached to the
encrypted data. Multiple subgroup keys can be used as KEKs to fulfill desired
subgroup composition. Using the encrypting function E(·) and decrypting function D(·), the sender can encrypt the data as follows:



i1 j1 , . . . , ir jr , Ek (t1 ) (k 
 ), . . . , Ek (tr ) (k 
 ) , Ek 
 (Data)
i1 j
1

ir jr

(i1 . . . ir ∈ {1, 2, . . . , n − 1}; j 1 . . . jr ∈ {1, 2, . . . , n − 1}; t1 . . . tr ∈ {1, 2, . . . , s})
The superscript tr of k stands for the key chain being derived from the appropriate Hamiltonian cycle. Algorithm 5.1 gives the complete description on how to
generate the Hamiltonian cycles and Section 6 presents how to use the generated Hamiltonian cycles to build our keying scheme. {i1 , . . . , ir } is the key chain
list. The subscription jr tells which key element is used in the corresponding
key chain. If a receiver possesses a key element j k in the key chain ir , if and
only if jr ≥ j k , then she can hash the key kitrr j by jr − j k times to derive key
k
kitrr jr . The description of the key message is presented in Section 6.1.2. Once the
encrypted message is received, the group members can determine the following information: (1) source of the senders, (2) subgroup formation. In order to
facilitate the key agreement protocol to achieve these two goals, the proposed
secure group keying scheme considers that (a) the key id is served as the group
id , and (b) the key id tells the group formation.
Once a receiver receives this message, she can search the key chain list
{i1 , . . . , ir } to find out if she belongs to the receiver group. If so, she can use the
decryption function D(·) to decrypt the session key k 
 , and then use the session
key to decrypt the data.
5. USING HASH CHAIN TO BUILD KEY CHAIN
In this section, we present the preliminaries that are building blocks for our
secure group keying protocols. We first show how we can use a hash function [Rivest 1992] to construct a hash chain, and subsequently, to form a key
chain. We present three lemmas in regarding to forming noncolluding (defined
in Definition 5.1) subgroups, which are based on the linear structure of a key
chain. Then, we discuss two lemmas: Lemma 5.6 is used for building the unbalanced keying protocol that is suitable for centralized multicast applications;
Lemma 5.7 is used for building the balanced keying protocol that is suitable
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

530

•

D. Huang and D. Medhi

Fig. 2. An example of keys allocation (n = 6, r = 5).

for decentralized multicast applications. More discussion about balanced and
unbalanced keying protocols will be given later in Section 6.
We start with function h(·) which is a hash function that maps an arbitrary
length message M to a fixed length message digest MD. It satisfies the following
properties:
(1) h(·) is publicly known.
(2) Given M , it is relatively easy to compute h(M ).
(3) Given MD, it is computationally infeasible to find a message M such that
h(M ) = MD.
(4) Given M and h(M ), it is computationally infeasible to find a message
M 
 (= M ) such that h(M 
 ) = h(M ).
A hash chain is a sequenced hash values with the linear derivative relations
among them. For example, we use h j (·) to denote using hash function h(·) on a
message j times. The outputs of the multiple hash operations construct a hash
chain. A hash chain maintains a linear derivative relations among multiple
hash values, that is, h j (·) can derive hr (·) when j < r.
Consider message M i to be the ith initial key element that is used by a user
to generate the cryptographic key denoted by ki0 , where ki0 = f (M i ), and where
f (·) is a key generating function; this key generating function is publicly known
and generates the exact length of cryptographic key. Thus we have the following
relation:
ki j = f (h j (M i )) ( j > 0).
Since h(·) is publicly known, we know that the derivative relations of a hash
chain are:
M i ⇒ h1 (M i ) ⇒ · · · ⇒ h j (M i ) ⇒ · · · ⇒ hr (M i )

(1 < j < r)

Then, through function f (·), corresponding key chain derivative relations are:
ki0 ⇒ ki1 · · · ⇒ ki j ⇒ · · · ⇒ kir

(1 < j < r)

The derivative relations among multiple keys form a linear hierarchical
structure from top (ki0 ) to the bottom level (kir ). One straight forward key allocation example is shown in Figure 2, which is composed of 6 keys (r = 5). If we
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

531

allocate a key to each group members from uc to uc+5 , each group member can
derive its lower-level keys. Then 6 subgroups can be formed via the key chain
K î , denoted by Si0 to Si5 . Note that these subgroups are noncolluding subgroups,
in which s set of members cannot collude to derive the keys used by a given
subgroup unless at least one of members belongs to that subgroup.
Definition 5.1. The noncolluding feature of the group key management is
described as follows: ∀S ∈ U, we have ∀ui ∈ S, ui ⇒ K S and ∀u j ∈ U \ S, u j ⇒
KS.
Based on the above discussion we has the following lemmas.
LEMMA 5.2. For a key chain with length |K î | = r + 1, it is possible to form
r + 1 noncolluding subgroups.
PROOF. A key chain K î contains r + 1 keys, which can be assigned to r + 1
group members. These group members can form r + 1 subgroups from size 1 to
r + 1.
LEMMA 5.3. For a key chain with length |K î | = r + 1 and a user group |U| =
n, n = r +1 is the minimum length of key chain to form n noncolluding subgroups
when one key is uniquely assigned to each group member.
PROOF. If we assign two keys kim and kil to a user uc , and there exist a key
kix where l < x < m, we cannot assign kix to any other users except uc . This is
because key kim has been assigned to uc , uc should not derive any keys which
is higher than its level. But key kil will allow uc to derive kix . Then, this would
not be a noncolluding subgroup. Also, if more than one key are assigned to a
user, it will increase the length of a key chain. Thus, from Lemma 5.2 we know
that a key chain is at least of length n and exactly one key from the key chain is
assigned to a user, which can guarantee every user is a member of a subgroup
and there is no collusion problem.
LEMMA 5.4.

Key ki j can serve as a subgroup key with the group size of j + 1.

PROOF. Key ki j is hashed j times, which can be derived by j keys (or group
members).
5.1 Multiple Key Chains for Unbalanced Keys Allocation
We extend the linear structure of a key chain to a non-linear structure by
combining multiple key chains. All these properties provide critical ingredients
to our keying science due to efficiency and flexibility. In this section, we present
the methods for unbalanced keys allocation. It is used for building a unbalanced
keying protocol that is suitable for centralized multicast applications, in which
a multicast center initiates the majority of multicast sessions.
Assigning more than one key from multiple key chains to a user is very
similar to arranging the group member’s positions in different key chains. We
assume U is fixed with size n; then, assigning keys to a group member is the
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

532

•

D. Huang and D. Medhi

same as to follow permutations in different key chains. Our goals are two folds:
(1) Maximizing the number of subgroups that can be covered.
(2) Minimizing the number of keys possessed by a group member.
Note that these two goals contradict each other. We show how we can achieve
the minimized number of keys possessed by a group member under certain subgroup coverage requirements. In order to evaluate the efficiency of the keying
scheme we define the term of k/g ratio.
Definition 5.5. k/g ratio is ratio of the incremental number of keys to
the incremental number of covered subgroups:
k/g =

I(K î ) − I(K l̂ )
i
j =l +1 |S j |

(i > l ≥ 1)

(1)

Equation (1) specifies the increased number of subgroup keys needed when one
subgroup is added in. I(·) is the index function where I(K î ) = i and I(K l̂ ) = l .
Further, I(K î )−I(K l̂ ) = |i−l | stands for the increased number of keys of a group
member when adding key chains from K (l +1)
ˆ to K î . Here, we using Lemma 5.3,
and each key of a key chain is uniquely assigned to a group member. l
≥ 1 means
that there already exists at least one key chain. The summation ij =l +1 |S j |
stands for the summation of distinct subgroups supported by key chains from
K (l +1)
ˆ to K î . An efficient keying scheme always come with the least value of the
k/g ratio. For example, assigning a unique key to each subgroup without
derivative relation, k/g ratio is 1. If we have n members, the number of
keys a group member possessed is 2n−1 . When n is very big, this keying scheme
is impractical. Thus, our task is to find the minimal k/g ratio while the
maximum number of subgroups are supported.
In order to study how we can allocate keys from multiple key chains, we use
some preliminary definitions from the permutation theory (see the Appendix).
First, we consider the maximum number of subgroup keys possessed by a
group member using n − 1 key chains.
LEMMA 5.6. Consider user uc ∈ U, where |U| = n, n ≥ 3 and c = {1, . . . , n}.
If we allocate n − 1 keys ki j (0 ≤ j ≤ n − 1, i = {1, . . . , n − 1}) to user uc , each of
these keys from a unique key chain, then the minimum k/g ratio is 1/(n − 2)
and the maximum number of subgroups the user uc can communicate with is
n2 − 3n + 4.
PROOF. We number the users in the group U from 1 to n. From Lemmas 5.2
and 5.4, we know that each key chain can maximally form n subgroups. When a
user possesses all ki0 (i = {1, . . . , n−1}), he can communicate with the maximum
number of subgroups. When we have n−1 key chains, we can assign all the head
of the n−1 key chains (ki0 ) to a user, which can maximize the number of subgroup
keys the user can derive. We need to assign keys in n − 1 key chains to n users
systematically, which can form the maximum number of distinct subgroups.
This is the same as arranging the permutation of n users. If we assign number
1 to the user u1 and 2, . . . , n to the rest n − 1 users uc (c ∈ {2, . . . , n}), we
use permutation cycles (see Definition A.3 in the Appendix) to assign keys
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

533

Fig. 3. n − 1 key chains.

to avoid subgroups overlapping. The permutation can be represented by two
cycles p = {{1}, {n, 2, 3, . . . , n − 1}}. If we multiply p to identity permutation
I = {1, 2, . . . , n} by n − 1 times, the result of multiplication is the same as
identity permutation I :
I = I · pn−1
For each multiplication, the permutation cycle {n, 2, 3, . . . , n − 1} causes the
element from position 2 transposing to position n and other elements (excluding
at the positions 1 and 2) transposing to the immediate left position. Thus, we
can have n − 1 distinct permutations I, I · p, . . . , I · pn−2 . Note that, in each
permutation, the first element is 1 and the second elements will be distinct
elements from 2 to n. As shown in Figure 3, the permutation sequences are
shown from right to left. Each column represents a key chain which is indexed
by i and each row element represents a key ki j which is indexed by j . Beginning
the second row, the key elements above the dash line is indexed by n − i + j
and the key elements on and below the dash line is indexed by j − i + 1.
Because of the top-bottom hierarchical key-chain structure, we need to do
a top-down search to find if there exists overlapped subgroups. We randomly
pickup column i; the second element in this column is n − i + 2 which is above
the dash line. In order to find the same subgroup members composition, other
key chains should contain the element n − i + 2. In the immediate right key
chain, the element n − i + 2 is one level below (row 3) and n − i + 1 is on the
same level (row 2). But on column i, the element n − i + 1 is on the bottom
level (row n). This means that we need to search the group members all the
way down to the bottom, then we can find two totally matched subgroups. We
also observe that, due to the cycle, the right/left key chains always maintain
the structure that element n − i + 1 is above element n − i + 2, which means
there is no subgroups which can match except that the subgroup contains all
group members. Thus, in permutations of I, I · p, . . . , I · pn−2 , there is no same
formation of subgroup except the subgroup that contains all group members.
The total number of subgroups is n(n − 1) − 2(n − 1) + 2 = n2 − 3n + 4. Thus,
k/g ratio is equal to the increment of 1 key to the incremental of supported
subgroups, which is 1/(n − 2).
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

534

•

D. Huang and D. Medhi

Fig. 4. n key chains.

If we add one more key chain and still put 1 in the first place, there will be
overlapping of subgroups with previous subgroups. Thus, increasing one key,
the incremented number of subgroups will be less than n − 2, and then the new
ratio is k/g < 1/(n − 2).
The proof of Lemma 5.6 uses one particular permutation cycle {n, 2, 3, . . . ,
n−1} from the second position to the last position. The number of permutations
of a given number n having exactly 1 permutation cycles is defined by the
Stirling numbers of the first kind S1 (n, 1) = (n − 1)! [Comtet 1974]. In fact, for
any one of (n − 1)! permutation cycles, Lemma 5.6 is valid and provable.
5.2 Multiple Key Chains for Balanced Keys Allocation
Lemma 5.6 addresses key allocation issues for a particular user (u1 in our proof
of Lemma 5.6). For more general case, we assume every group member is treated
equally. In this section, we present methods for balanced keys allocation. They
are used for building a balanced keying protocol that is suitable for decentralized multicast applications, in which every member has the same opportunity
to initiate a multicast session.
LEMMA 5.7. Consider user uc ∈ U, where |U| = n, n ≥ 1 and c = {1, . . . , n}.
There exists n distinct key chains K î and |K î | = n. If we allocate n keys ki j
(1 ≤ i ≤ n, 0 ≤ j ≤ n − 1) to user uc , each from a unique key chain, the number
of subgroups supported by n key chains is n2 − n + 1. On average, the number of
subgroups that a user can communicate with is n(n − 1)/2 + 1.
PROOF. Using permutation cycle p = {n, 1, 2, . . . , n − 1}, we can build the
permutation matrix, which is shown in Figure 4. Then, we have n distinct
permutations I, I · p, . . . , I · pn−1 . Each column represents a key chain. Following the permutation sequence, we can build nonoverlapping subgroups to
assign keys to each group member. The proof is the same as in the proof for
Lemma 5.6. The only difference is that for Lemma 5.6, the length of permutation cycle is n − 1, and for Lemma 5.7, the length of permutation cycle is n.
Thus the total number of subgroups is the total number of subgroups in the
permutation matrix minus n − 1 overlapped groups (all members group), that
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

535

is n · n − (n − 1) = n2 − n + 1. The number of subgroup keys that user uc can
generate directly is given as follows:
n


|ki j | − (n − 1) =

n−1


(|K î | − j ) − (n − 1)

j =0

i=1

=

n−1


(n − j ) − (n − 1)

j =0

=

n(n − 1)
+ 1.
2

To give a more visualized view of our scheme, we consider the scenario where
every group member is a vertex (each group member in U is mapped to a vertex
in V: vc ∈ V, uc = vc , and c = {1, 2, . . . , n}) of a graph K(E, V). To find a full
permutation cycle (covers every number in a permutation cycle) is the same
as to find a spanning cycle2 of the graph. The directed edge ei j (ei j ∈ E and
i, j = {1, 2, . . . , n}) between two nodes i and j means a transposition of position
i to position j in the permutation. Assuming that a group has n members, in
which we associate them to n vertices in a graph, where n is odd (n = 2s + 1
and s ∈ N ). These n vertices can form a fully connected graph which we refer to
as K2s+1 . We now state the following important theorem [Harary 1969] which
is applicable here.
THEOREM 5.8. The fully connected graph K2s+1 is the sum of s spanning cycles, where s ∈ N . (For proof, refer to Harary [1969], p. 89)
This theorem states that any fully connected graph K2s+1 can be constructed
by s independent spanning cycles. These s spanning cycles have no overlapped
edges, and each cycle has exactly n edges. Since our keying scheme is based on
a sequence of hash values, we use the term “Hamiltonian cycles”3 instead of
“spanning cycles.”
There are many ways to create s independent Hamiltonian cycles. We present
an algorithm that creates s Hamiltonian cycles for graph K2s+1 , where 2s + 1 is
a prime.
Algorithm 5.1 (Hamiltonian cycles creation algorithm)
Initial
Procedures

Given n entities: v1 , v2 , . . . , vn , where n = 2s + 1, s ∈ N
construct a set of s paths denoted by Pt , on the points
v1 , v2 , . . . , v2s+1 as follows:
(1) create s paths: Pt = v1 vt+1 v2t+1 v3t+1 . . . v2st+1 , where
t = {1, . . . , s}. All the subscripts are taken as integers
(mod 2s + 1)
(2) the Hamiltonian cycle Zt is then constructed by joining
v1 to the endpoints of Pt

End
2A
3A

spanning cycle is the one that covers every nodes in a graph exactly once.
Hamiltonian cycle visits each vertex exactly once in sequence.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

536

•

D. Huang and D. Medhi

For any group of users U (|U| = n and n = 2s + 1, s ∈ N ), we can always find
s Hamiltonian cycles (or spanning cycles or permutation cycles) which have no
overlapped edges. Using Algorithm 5.1, we have the index of permutation4 that
is constructed by Hamiltonian cycle Zt :
p(t)
I = {{1, t + 1, 2t + 1, . . . , 2st + 1}

mod

(2s + 1)}

(2)

(t)
(t)
p(t)
I is the first permutation ( pI = p0 ). The permutation cycle is given as

p(t) = I · ({2, 3, . . . , 2s + 1, 1})t

(3)

Thus, there exists 2s permutations, which are given by
pk(t) = I · ( p(t) )k

(k = {1, 2, . . . , n − 1})

(4)

(t)
The sequence of a permutation indexed by p(t)
I is represented by Sk , where
(t)
(t)
(t)
k = {1, 2, . . . , n − 1}. We also have S0 = p0 = pI .

6. SECURE GROUP KEYING PROTOCOL
Based on discussion so far, if we associate each subgroup member to a unique
vertex in a fully meshed graph by following the tour of a continuous path,
finding a subgroup key is equivalent to find a continuous path among these
subgroup members in the graph. Based on this important observation, we now
discuss our secure group keying protocol in detail.
6.1 Balanced Keying Protocol
In the balanced keying protocol, we treat each group member equally. The balanced keying protocol is based on Lemma 5.7, Theorem 5.8, and Algorithm 5.1.
Given U = {uc |c = 1, 2, . . . , n} and n key chains, where n = 2s + 1 and
t ∈ {1, 2, . . . , s}. We have the following algorithm.
Algorithm 6.1 (Key assignment algorithm)
Initial
Step 1

Step 2

Select a unique t ∈ {1, 2, . . . , s}; initialize variable k = 0
(1) for key chain K î , using Algorithm 5.1, a Hamiltonian cycle Zt
is a permutation cycle p(t) given by equation (3).
(2) permutations pk(t) are given by equation (4) and the
corresponding sequence is Sk(t) .
(3) denote I j (Sk(t) ) for the ( j + 1)th element in sequence Sk(t) .
(4) assign ki j to user uI j (S (t) ) , where j = {0, 1, . . . , n − 1}
k
k = k + 1, if k ≥ n, Stop. Otherwise goto step 1

Algorithm 6.1 presents how to distribute keys to group members from a
given key chain. The following algorithm shows how to distribute keys to group
members by following the tour of s Hamiltonian cycles.
4 Note

here that the superscript (t) does not stand for the power of permutation or sequence. It
means the permutation or sequence derived from the tth Hamiltonian cycle.

ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

537

Fig. 5. An example of Hamiltonian cycles for seven nodes (n = 7, s = 3).

Fig. 6. An example of permutations for 7 group members (n = 7, s = 3).

Algorithm 6.2 (Key-chain assignment algorithm)
Step 1
Step 2

Given a graph Kn , where n = 2s + 1, s ∈ N , build s Hamiltonian
cycles using Algorithm 5.1
By taking the tour of s Hamiltonian cycles using Algorithm 6.1,
build s sets of keys allocation

6.1.1 An Example of Balanced Keying Protocol. We illustrate the keying
scheme via an example with the group size 7.
Example 6.1. We consider 7 group members as 7 vertices in a graph, shown
in Figure 5. Following Algorithm 5.1, we build three separate Hamiltonian
cycles. Node 1 is the starting point of each of these three Hamiltonian cycles.
These three cycles form a fully meshed graph K7 . Following Algorithms 6.1 and
6.2, we form the permutation table in Figure 6. The keys allocation is shown in
Table I.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

538

•

D. Huang and D. Medhi
Table I. n = 7 Group (Only Subscript i j of ki j is Shown in this Table)

K7 nodes
Member
Cycle 1
Cycle 2
Cycle 3
K7 nodes
Member
Cycle 1
Cycle 2
Cycle 3

1
u1
10 26 35 44 53 62 71
10 26 35 44 53 62 71
10 26 35 44 53 62 71
5
u5
14 23 32 41 50 66 75
12 21 30 46 55 64 73
16 25 34 43 52 61 70

2
u2
11 20 36 45 54 63 72
14 23 32 41 50 66 75
14 24 33 42 51 60 76
6
u6
15 24 33 42 51 60 76
16 25 34 43 52 61 70
14 23 32 41 50 66 75

3
u3
12 21 30 46 55 64 73
11 20 36 45 54 63 72
13 22 31 40 56 65 74
7
u7
16 25 34 43 52 61 70
13 22 31 40 56 65 74
12 21 30 46 55 64 73

4
u4
13 22 31 40 56 65 74
15 24 33 42 51 60 76
11 20 36 45 54 63 72

In Table I, each group member has 21 keys (in a column) which belong to
three different cycles (due to space limitation, we only present the subscripts
(i j ) of the ki j in each row). K î(t) is a key chain that is constructed by following
the tth Hamiltonian cycle (t = {1, 2, . . . , s}) to allocate keys to group members.
And similarly, we can add notation (t) to key ki(t)j . Figure 5 shows that any
two-group members are connected by a direct-link and they both can derive
a two-member subgroup key to form a secure communication. For example,
if we randomly select u1 and u4 then, in the Hamiltonian cycle 3, u1 and u4
are adjacent, and in the third key chain, u4 has the key k1(3)
and u1 can derive
1
.
These
relations
can
be
applied
to
any
combination
of two group
it from its k1(3)
0
members. Note that these Hamiltonian cycles cannot cover every combination
of selected group members. In a Hamiltonian cycle with n entities, the number
of l different group members in a continuous path is n, where l < n. Thus,
in a group with n members, using Algorithm 5.1 there will be s cycles formed.
The number of l adjacent members in s cycles is
 s ∗ n. In Example 6.1, when
s = 3, the number of 3-member subgroups is 73 = 35 and s ∗ n = 21. Hence,
we can infer that three Hamiltonian cycles cannot totally cover every possible
combination of subgroup members. However, we can build relations among the
cycles to solve this problem.
6.1.2 Key Messages. We can use a session key k 
 to encrypt data and use
subgroup keys as KEK to encrypt the session key that is attached to the encrypted data. Multiple subgroup keys can be used as KEKs to fulfil desired
subgroup composition. Using the encrypting function E(·) and decrypting function D(·), we can encrypt the data as follows:







i1 j1 , . . . , ir jr , Ek (t1 ) (k ), . . . , Ek (tr ) (k ) , Ek 
 (Data)
i1 j
1

ir jr

(5)

(i1 . . . ir ∈ {1, 2, . . . , n − 1}; j 1 . . . jr ∈ {1, 2, . . . , n − 1}; t1 . . . tr ∈ {1, 2, . . . , s})
the receivers check the key chain list {i1 , . . . , ir } to see if they belong to the group.
The checking method is straight forward: a receiver compares each element in
the list with the j k in the key chains she possesses; if and only if jr ≥ j k , she
belongs to the group; then she can hash the key kitrr j by jr − j k times to derive
k

ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

539

Fig. 7. Subgraph K3 .

key kitrr jr . To decrypt the data, she first decrypts the session key:
	






k = Dk (tr ) Ek (tr ) (k )
ir jr

ir jr

(6)

and then uses k 
 to decrypt the received cypher data:
Data = Dk 
 (Ek 
 (Data))

(7)

COROLLARY 6.1. Using Algorithm 6.2, we can build s (Group size is n, s =
(n−1)/2 and s ∈ N ) sets of key chains, and for those arbitrarily selected subgroup
members, we can find b(0 ≤ b ≤ s) encryption relations that provide secure
subgroup communication.
PROOF. Theorem 5.8 specifies that in a fully meshed graph Kn , where n =
2s + 1, s ∈ N , there will be s Hamiltonian cycles. Following Algorithm 6.2, we
can form s sets of key chains. For any subgroup S ⊆ U, we can find at most b
continuous path segments in s Hamiltonian cycles, where b ≤ s. The encryption
and decryption formats are given from equations (5) to (7).
In Example 6.1, if we consider subgroup members u2 , u6 , and u7 , we cannot
find any continuous path in three Hamiltonian cycles for these three group
members. We prune graph K7 to K3 , shown in Figure 7. When u2 wants to send
messages to subgroup {u2 , u6 , u7 }, u2 sends out the cypher text as follows:



51 , 41 , Ek (3) (k 
 ), Ek (2) (k 
 ) , Ek 
 (Data)
51

41

The encrypted session key is attached to the cypher text. Only u6 and u7 can decrypt the encrypted session key and thus can decrypt the message. In the worst
case, the number of encryption/decryption operations is equal to the number of
Hamiltonian cycles. It is important to note that this subgroup keying scheme
can completely avoid KDC being involved in the subgroup’s communication,
and the secure subgroup’s communication can be freely formed.
6.1.3 Lower Bound and Upper Bound Analysis of the Number of Encrypted
Key Messages. In this section, we will do an analysis on the lower and upper
bound on the number of encrypted key messages.
COROLLARY 6.2. Consider when each group member has the same probability
to be selected to form a desired subgroup with size L = |S|. The lower bound of
the number of transmitted encrypted keys is 1; the upper bound is L when L ≤ s
and s when L ≥ s (where s = (n − 1)/2).
PROOF. The proof of lower bound is straight forward. When all subgroup
members are located consecutively within any of Hamiltonian cycles, the sender
can use one key as the subgroup key.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

540

•

D. Huang and D. Medhi

We consider that the overall group can be described as a sorted list from
member 1 to member n. We assume the sender to be ui . In a Hamiltonian
cycle, we define d (ui , u j ) to be the distance between two members ui and u j .
That is, d (ui , u j ) is the minimum of the distances that counted in the increased
←
−
−
→
order and decreased order, represented by d (ui , u j ) = ( j − i) and d (ui , u j ) =
−
→
←
−
(n + i − j ), where i < j . Thus d (ui , u j ) = min{ d (ui , u j ), d (ui , u j )}, where
1 ≤ d (ui , u j ) ≤ s.
To build a subgroup with r subgroup members by using one subgroup key,
sender ui needs to find a key chain segment that can be one segment of any of
the Hamiltonian cycles which contains exactly r subgroup members. Thus, the
distance between two consecutive subgroup members in the key chain segment
must be the same. Finding the upper bound on the number of subgroup keys for
our scheme is equivalent to finding the maximum number of chain segments
to set up the subgroup key. Obviously, when the subgroup size L > s, at least
L − s pair of subgroup members share the same chain segment with the sender.
Hence, the upper bound must be less than or equal to s. To prove that the
upper bound is s, we only need to create a scenario that needs s key chains.
We assume that the sender is u1 ; then, the group of receivers is S \ {u1 } =
{u2 , . . . , us−2 , us , us+2 , . . . , un−1 }, where |S \ {u1 }| = s. Now, distances between u1
and each receiver are: d (u1 , u2 ) = 1, d (u1 , un−1 ) = 2, d (u1 , u4 ) = 3, d (u1 , un−3 ) =
4, . . . , d (u1 , us ) = s. Since each pair of the even index of users and the odd index
of users are not contiguous (one from the increased order, another from the
decreased order), they cannot use the subgroup key that is derived from the
same Hamiltonian cycle and none of the key chain segments contains more
than two members. Thus, in the worst case, the upper bound of the number of
encrypted key messages is s.
6.1.4 Average-Case Study. In this section, we propose two group key
searching algorithms and use the proposed algorithms to study the average
case.
In our proposed algorithms, S represents the desired subgroup that user
ui ∈ S wants to set up, where S ⊂ U and |S| = L. User ui (the sender) is required
to find r (1 ≤ r ≤ L) keys to encrypt session key k 
 ; then, use the session key to
encrypt the message. We propose two searching algorithms to find the subgroup
keys for two scenarios. They are: (1) Addition algorithm: when |S| ≤ (|U| + 1)/2,
we have L = |S|; (2) Eviction algorithm: when |S| > (|U| + 1)/2, we have L =
|U| − |S|. This is equivalent to evict L group members from the system.
We assume that the group members are indexed from 1 to n, where n is the
overall group size. We use the following notations that are used in the proposed
algorithms:
S:
d (i, j ):
chain(t):
chain(t̂):

subgroup, where group member i, . . . , j ∈ S. Particularly, we use
i to represent the sender, others represent the receivers.
the distance between any two group members i and j .
tth key chain can be used to derive KEKs, where 1 ≤ t ≤ s
the sorted key chains in the decreased order by the
sizeof(chain(t))

ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

increase(t):
decrease(t):
KEK(t) :
indicator[ j ]:

•

541

the key chain t is created by increased searching.
the key chain t is created by decreased searching.
KEK derived from key chain t.
a boolean array that identify the group members, where j ∈ S
if and only if indicator[ j ] == TRUE.

We now present the addition algorithm.
Algorithm 6.3 (Addition Algorithm)
main function
functions:
create(chain(t))

Addition Algorithm
create(chain(t))
chain(t̂) = sort(chain(t))
derive KEKs()
∀ j ∈ S, t = [( j − i) mod s] and chain(t) = TRUE
begin 1: k := 1 to s
if ((chain(k) == TRUE))
begin 2: m := 1 to L − 1
flag := 0
if (indicator[(i + nk) mod n] == TRUE)
increase(t)[m] = (i + nk) mod n; flag = 1
if (indicator[(i + L − nk) mod n] == TRUE)
decrease(t)[m] = (i + L − nk) mod n; flag = 1
if (flag == 0) break
end begin 2
end begin 1

chain(t̂)

sort key chains in a decreased order by the sizeof(chain(t))

derive KEKs()

begin: for each chain(t) in chain(t̂)
if (∀ j ∈ S \ {i} user j is marked)
break
if (∃ j ∈ (increase(t) || decrease(t)) j is unmarked)
mark j ;
ir := [chainID(i) − sizeof(decrease(t))] mod n;
jr := sizeof(increase(t)) + sizeof(decrease(t));
KEK(t) := ki(t)
r jr
end begin

chainID(i)

begin: k := 1
if [(kn + d (1, i)) mod t == 0]
chainID(i) = (kn + d (1, i))/t + 1; break
else k := k + 1; continue
end begin

After a group member executes the addition algorithm, s/he derives a set of
}. Using the message format formula presented in equasubgroup keys {keyi(t)
r jr
tion (5), s/he can communicate with the desired group members. The addition
algorithm involves three functions: create(chain(t)), chain(t̂), and derive KEK().
The operational complexities for these three functions are O(sL), O(s log s),
and O(sL), respectively. Our simulation shows that the average number of
operations for create(chain(t)) is approximately 2–4 times of subgroup size L,
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

542

•

D. Huang and D. Medhi

and the average number of operations for derive KEK() is approximately 1–2
times of subgroup size L. Our simulation is based on the group size n = 503
and the subgroup group size L = 2, . . . , 251.
When subgroup S > (n + 1)/2, we construct the subgroup by evicting
L = n − |S| members from the system. We modify the addition algorithm (only
derive KEK() function is modified) and present the eviction algorithm as follows.
Algorithm 6.4 (Eviction Algorithm)
main function

Eviction Algorithm
create(chain(t))
chain(t̂) = sort(chain(t))
derive KEKs()

functions:
create(chain(t))

same as Algorithm 6.3

chain(t̂)

same as Algorithm 6.3

derive KEKs()

begin: for each chain(t) in chain(t̂)
if (∀ j ∈ S \ {i} user j is marked)
break
if (∃ j ∈ (increase(t) || decrease(t)) j is unmarked)
mark j ;
ir := [chainID(i) + sizeof(increase(t)) + 1] mod
jr := n − L − 1;
KEK (t) := ki(t)
r jr
end begin

chainID(i)

n;

same as Algorithm 6.3

The complexity of the eviction algorithm is the same as addition algorithm.
Using either the addition or the eviction algorithm, each group member can
derive the desired subgroup keys. We have simulated the addition and eviction
subgroup key searching algorithms. Through regression fitting, we have found
that the function f (L) = a + bL + cL ln(L) matches our simulation data. The
simulation results and curve fitting function are shown in Figure 8. Figure 8(a)
shows the simulation results for the group sizes 251 and 503. Figure 8(b) shows
the parameters of curve fitting functions for the group sizes ranged from 31 to
503; note that in this range of group size, parameter a varies from −2.027 to
−10.2344, parameter b from 1.8627 to 2.56477, and parameter c from −0.4723
to −0.37534. In particular, for a group size of 251, we have found that the
parameters take the following values: a = −5.76, b = 2.33, c = −0.38. The
complexity comparison studies are given in Section 7.5.
6.2 Unbalanced Keying Protocol
Unbalanced keying protocol is based on Lemma 5.6, in which the system is prone
to give higher preference to one group member. This type of keying protocol is
suitable for “one-to-many” communication, in which the selected member is the
multicast center. Figure 3 shows a n × (n − 1) permutation matrix. If we remove
the first row, it is actually (n−1)×(n−1) balanced permutation matrix. Thus, we
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

543

Fig. 8. Curve fitting.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

544

•

D. Huang and D. Medhi

still can use the keying protocol proposed in Section 6.1 to analyze unbalanced
keying protocol. Based on Lemmas 5.6 and 5.7, we have the following corollary.
COROLLARY 6.3. If there are n multicast listeners (n is prime and n ≥ 5)
and 1 multicast center, using Algorithms 6.1 and 6.2, the number of distinct
subgroups supported by n(n − 1)/2 key chains is (n3 − 4n2 + 7n + 2)/2, which is
the number of subgroups a multicast center can set up.
 
PROOF. The number of subgroups formed by k of n group members is kn ,
(1 ≤ k ≤ n). The number of subgroups formed by k of n group members by
usingAlgorithms
6.1 and 6.2 is s ∗ n = n(n − 1)/2. When k = {1, n − 1, n}, we

have kn < n(n − 1)/2. Thus, there are subgroup overlapping. The number of
subgroups supported by n(n − 1)/2 key chains is given as follows:
	 
 	

 	 

n
n
n
s ∗ n ∗ (n − 3) +
+
+
= (n3 − 4n2 + 7n + 2)/2
1
n−1
n
7. PERFORMANCE ASSESSMENT OF SECURE GROUP KEYING SCHEME
In this section, we analyze the performance issues related to the group keying
scheme in regard to security, storage, and communication.
7.1 Security Consideration
Our scheme requires a trusted third party during the key predistribution phase,
in our case—KDC. The strength of keying scheme depends on the used hash
algorithms (such as MD5 [Rivest 1992], SHA-1 [NIST 1995], and so on).
In our case, KDC maintains the group member’s ID and the corresponding group member’s key sets. The key label ki(t)
can uniquely identify a group
0
member, which can be used as group member’s ID.
One-to-one communication within a group can be authenticated by using
subgroup key. The receiver can identify the sender immediately, because only
two communication participants can generate the subgroup key ki(t)
. For the
1
subgroup with more than two members, the authentication can only verify the
message generated from the legitimate subgroup members.
7.2 Storage Complexity and Subgroup Formation Issues
We discuss four keying schemes based on Lemma 5.6, Corollary 6.3, and
Lemma 5.7 (or Algorithm 6.1) and Algorithm 6.2. They are:
— Unbalanced scheme 1 (UBS1): n − 1 keys are allocated to each group member
and one group member can set up subgroups more easily (directly) than other
group members;
— Unbalanced scheme 2 (UBS2): n(n − 1)/2 keys are allocated to each group
member and one group member can set up subgroups more easily (directly)
than other group members;
— Balanced scheme 1 (BS1): n keys are allocated to each group member and
each group member can set up the same number of subgroups directly;
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

•

Key-Chain-Based Keying Scheme

545

Table II. Storage Requirement and k/ g Ratio of Different Keying Schemes
UBS1 (n ≥ 3)

UBS2 (n ≥ 5)

BS1 (n ≥ 1)

BS2 (n ≥ 1)

†
n2 −3n+2

n

n2 −n
2

n

n2 −n
2

n2 −n+2
2

n3 −2n2 +3n−2
4

2n
n2 −n+2

2n
n2 −n+2

Storage

KDC

n−1

requirement

Group member

n−1

n2 −3n+2
2

Number of subgroups

n2 − 3n + 4

n3 −7n2 +18n−10
2

k/ g ratio

n−1
n2 −3n+4

2

†

‡

n2 −3n+2
n3 −7n2 +18n−10

†
These equations are adjusted to n − 1 multicast listeners based on Lemma 5.6.
‡ This equation is adjusted to n − 1 multicast listeners from Corollary 6.3.

— Balanced scheme 2 (BS2): n(n−1)/2 keys are allocated to each group member
and each group member can set up the same number of subgroups directly.
7.2.1 Storage Complexity. Table II shows the storage requirements of the
group with n members. Due to the derivative relations of a key chain, both the
KDC and group members keep the same number of keys. This property is beneficial in reducing the storage overhead of the KDC. The storage complexity of
UBS1 and BS1 is O(n). The number of subgroups a user can directly derive is
O(n2 ). Note that these two keying schemes cannot set up secure subgroup communication by using Corollary 6.1, since a group member does not have enough
keys to derive all possible subgroup keys. The storage complexity of UBS2 and
BS2 is O(n2 ). The number of subgroups a user can directly derive is O(n3 ). Note
that these two keying schemes can set up secure subgroup communication that
supports all possible subgroups by using Algorithm 6.3 or Algorithm 6.4.
7.2.2 Zero-Delay Group Management. In our presented secure group keying schemes, no subgroup key distribution during the communication setup
is required as long as the KDC distributes the keys to each group member
at the system initialization time. Using USB2 and BS2, a group member can
derive O(n3 ) number of subgroup keys directly. For those subgroup keys that
cannot be derived directly from predistributed keys, a group member can use
self-managed subgroup-formation scheme as given from Equations (5) to (7). In
the broadcast environment, we assume each group member can receive every
transmitted message in the broadcast channel. If the system has a synchronized mechanism, k 
 that is used the first time can be used as KEK for the rest
of the subgroup communication session.5 Thus, it is required to send multiple
encrypted k 
 only within the first synchronized intervals of the subgroup communication session. If the system does not have a synchronized mechanism, it
requires the sender to indicate which k 
 he had used before. Every group member needs to store previously received k 
 for future transmission, in which each
k 
 has a time-to-live parameter associated with it.
5 An election scheme is required when there are multiple first time subgroup session keys received
within the same synchronized period. Discussion of the election scheme is outside the scope of this
paper.

ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

546

•

D. Huang and D. Medhi

7.3 Complexity Analysis of Group and Subgroup Key Derivation
Recall that group and subgroup keys are derived from group member’s key sets.
Before the communication begins, a group member needs to know every other
group member. This can be done at the time of a group’s initial setup procedure
when the KDC tells every group member the role of each group member. When a
group member sends an encrypted message, it needs to attach group member’s
ID and key ID − ki(t)j along with the encrypted message. A receiver can quickly
derive the proper subgroup key to decrypt the message.
Note that the longest key chain is of length n. From Lemma 5.2, when the
subgroup size is k, the maximum required hash operations for a subgroup member is k − 1 and the derivation complexity is O(k). Coppersmith and Jakobsson
[Coppersmith and Jakobsson 2002; Jakobsson 2002] have shown that the generation of hash chain has a complexity of O(log2 n). They proposed a “pebble” method that can be used on the most frequently used key chains. We as1
sume that every subgroup is formed with equal probability
; this implies
2n −1
n
(
k)
that the probability of forming an subgroup with size k is 2n −1 . The average sub
) . It is easy to show that the average length
group size is given by nk=1 k 2(nk−1
of derivative operations is n/2. By using the scheme proposed by Coppersmith
and Jakobsson, it can also be shown that on the average, the number of hash
operations is log2 n − 1.
7.4 Ratio of Number of Keys to Number of Subgroups
In order to evaluate the efficiency of our keying scheme, we define the ratio
of number of keys at a member to number of subgroups that can be directly
generated by a member. We call it k/ g ratio, which specifies the number of
keys (or secrets) that are required to build a subgroup communication. Note
that the ratio k/ g is different from k/g which was defined in Equation (1),
which evaluates the incremental change of a key to the incremental change of
number of subgroups. The ratio k/ g evaluates the overall efficiency of a keying
scheme.
Table II shows the k/ g ratio of four difference keying schemes. Note that
k/ g ratios of four different keying schemes have the same complexity O(n−1 ).
7.5 Comparative Studies of Secure Group Communication Schemes
To our knowledge, there is no shared-key-based scheme designed specifically for
many-to-many group communication; however, some of the one-to-many group
communications schemes can be used for many-to-many group communication.
We consider two such relevant one-to-many group communication schemes for
comparison with our scheme: one comes from the information theory community (subset difference scheme [Naor et al. 2001]), and the other scheme from
Internet community ((KOS)—OFT scheme [Sherman and McGrew 2003]). We
have also considered a naı̈ve scheme in this comparison.
7.5.1 Naı̈ve Scheme. The naı̈ve scheme works as follows. During the key
predistribution phase, a pairwise key is predistributed for each pair of group
members; during the group communication phase, a group member ui broadcast
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

547

a encrypted message and only desired group members can decrypt the message.
The message format is given as:
[u1 , u2 , . . . , u L , Eki1 (k 
 ), Eki2 (k 
 ), . . . , EkiL (k 
 )], Ek 
 (M )
Upon receiving the message, a receiver u j looks up the receiver list, locates the
proper position to decrypt the session key k 
 by using the shared pairwise key
ki j , and then decrypts the message M.
7.5.2 Subset-Difference Scheme. The subset-difference scheme is an improved version of BES [Fiat and Naor 1994]. During the keys predistribution
phase, each group member is predistributed a set of secrets. In the group communication phase, the KDC broadcasts a message; only the legitimate group
members can decrypt the message and then derive the group key. Naor et al.
[2001] proposed the subset-difference scheme. In this scheme, a complete binary key tree is constructed and receivers are viewed as leaves. The collection
of subsets S1 , . . . , Sw defined by this algorithm corresponds to subsets of the
form “a group of receivers G 1 minus another group G 2 ,” where G 2 ⊂ G 1 . The
two groups G 1 , G 2 correspond to leaves in two full binary subtrees. Therefore,
a valid subset S is represented by two nodes in the tree (vi , v j ) such that vi
is an ancestor of v j that denoted as Si, j . A leaf u is in Si, j if and only if it is
in the subtree rooted at vi but not in the subtree rooted at v j ; in other words,
u ∈ Si, j if and only if vi is an ancestor of u but v j is not. Using the key assignment scheme proposed by Noar et al., each group member is required to store
1
log2 n + 12 log n + 1 keys, and the length of the broadcast message is at most
2
2L − 1.
7.5.3 One-Way Function Tree (OFT) Scheme. The OFT scheme proposed a
binary key tree structure. Group members are all located at the leaves in the
key tree. Two keys are associated with each node of the key tree. Each internal
node i has two children, namely left(i) and right(i). The node key for node i is
represented by the following formula:
 

 
ki = f g kleft(i) , g kright(i)
where function g is one way, and f is a mixing function. Ancestors of a node are
those nodes in the path from its parent node to the root. The set of ancestors of a
node is called ancestor set and the set of siblings of the nodes in ancestor set are
called sibling set. Each member receives the key (associated to its leaf node),
its sibling’s blinded key (processed by one-way function g ) and the blinded
keys corresponding to each node in its sibling set. For a balanced tree, each
member stores log2 n + 1 keys. When a node’s key changes, the new key must
be encrypted with its two children’s key and the blinded key changed in a
node has to be encrypted only with the key of its sibling node. Sherman and
McGrew [2003] proposed an improved method to reduce the broadcast size
and the computational effort of multiple additions and evictions. They call the
corresponding operations as bulk addition and bulk eviction. Before the group
operations, the key server constructs a combined ancestor tree (CAT) who is
on the tree of ancestors of the affected leaves. After a batch operation, the key
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

548

•

D. Huang and D. Medhi

Table III. Comparison Table of Many-to-Many Secure Group Keying Schemes
Scheme/
Feature
OFT

Group
Management
Centralized

Message Size (Bulk)
Addition
Eviction
sL K + L(d K + I )
sL K + LI

Subset-diff

Centralized

Scheme/
Feature

Group
Management

Group Formation
Message (Bulk)

Naı̈ve

Self-managed

L(K + I )

BS2/UBS2

Self-managed

[a + bL + cL ln(L)]K

n/a

KDC
(2n − 1)K

(2L − 1)(K + I ) (2n − 1)K
KDC

Storage
Member
(d + 1)K
( 12 d 2 + 12 d + 1)K
Storage
Member

n(n−1)
K
2
n(n−1)
K
2

(n − 1)K
n(n−1)
K
2

n, number of members in the group; I , number of bits in member id ; d , depth of a key tree (for a balanced tree
d = log2 n); K , size of a key in bits; L, size of a subgroup; sL , size of the CAT; a, b, c, constants specified in
Figure 8(b).

server must broadcast the blinded secrets of all nodes on the CAT and the size
of this broadcast is the size of the CAT. The lower bound and upper bound of
the size of CAT sL is given as:
2L − 1 + log2 (n/L) < sL < 2L − 1 + Llog2 (n/L)

(8)

where L is number of leaves in the CAT (number of added or deleted members).
7.5.4 Comparisons of Many-to-Many Communication Schemes. We note
that most of the proposed secure group keying schemes are tailored for one-tomany communications [Dondeti et al. 2000]. In case of many-to-many communication, the key management overhead is proportional to the number subgroups.
Moreover, setting up subgroup communication via trusted third party (KOS
and BES) will introduce additional communication delays between the subgroup members and centralized servers, making it difficult for real-time/delaysensitive applications.
In Table III, we compare our proposed balanced scheme with two centralized group keying schemes (one from KOS—OFT scheme, another from BES—
subset difference scheme). In addition, we have constructed a naı̈ve scheme, in
which a unique key is distributed for each pair of group members. According
to the OFT scheme proposed by Sherman and McGrew [2003], on average, the
sL is close to the lower bound for bulk addition and sL is about 15% of the upper bound for bulk eviction (the lower/upper bound is shown in equation (8)).
According to the authors [Naor et al. 2001], in the subset-difference scheme,
the average case is 1.25L for randomly selecting the group members. In our
scheme, that is, the (un)balanced scheme, the values of coefficients a, b, c for
the curve fitting function are shown in Figure 8, where |U| ≤ 503.
Figure 9 shows that the communication overhead invoked by our scheme
is the minimum among the compared schemes. The most expensive operation
is the bulk addition operation of the OFT scheme. Although, the bulk eviction
operation is less expensive, the frequent group formations may involve both
bulk addition and eviction. The communication overhead invoked by the subsetdifference scheme is even higher than the naı̈ve scheme. From this comparison
study, we can infer that minimizing the storage overhead for group members
comes at the expense of increased communication overhead.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

549

Fig. 9. Comparison of number of key messages for many-to-many communication schemes.

8. CONCLUSION
In this paper, we have proposed a new secure group communication keying scheme for many-to-many group/subgroup communication. Our proposed
scheme is suitable for applications that have the following three requirements:
— frequent subgroup setup for communications within a moderate size group
without leaving the overall group
— the entire population change of the system is not prominent
— delay-sensitive setup for secure subgroup communication
We propose two schemes for secure group communication. Our proposed unbalanced keying scheme can be used in the multicast environment, in which
a multicast center initiates most of the communication. We also present a
balanced keying scheme that treats each group member equally where every
group member can initiate the group/subgroup communication. Furthermore,
our proposed balanced keying scheme requires O(n2 ) storage space, and more
importantly, supports many-to-many secure subgroup communication. Our performance comparison studies show that the proposed schemes has minimal
communication overhead of key set-up message.
There are two limitations of our proposed schemes. When the entire group
formation is uncertain. This means the population of the system is unstable, and
group members in the system keep changing continually. Then, this scenario
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

550

•

D. Huang and D. Medhi

can be considered as a situation where the population of a system is infinite
and our proposed schemes are not designed to handle infinite population. The
second limitation is that the group size is limited by storage capacity of group
member’s personal device. In order to solve this problem, we need to build
multiple levels key-tree structure, in which multiple groups compose a global
group. The multiple levels key-tree structure will be considered in a subsequent
paper.
APPENDIX
We present some preliminary definitions of permutation theory are given
in Skiena [1990].
Definition A.1 (Permutation). The rearrangement of elements in an ordered list S into a one-to-one correspondence with S itself, is also called an
“arrangement number” or “order.” The number of permutations on a set of n
elements is given by n!.
For example, there are 2! = 2 · 1 = 2 permutations of {1, 2}, namely {1, 2} and
{2, 1}, and 3! = 3 · 2 · 1 = 6 permutations of {1, 2, 3}, namely {1, 2, 3}, {1, 3, 2},
{2, 1, 3}, {2, 3, 1}, {3, 1, 2}, and {3, 2, 1}.
Definition A.2 (Permutation group). A permutation group is a finite group
G whose elements are permutations of a given set and whose group operation is
composition of permutations in G. Permutation groups have orders dividing n!.
Definition A.3 (Permutation cycle). A permutation cycle a subset of a permutation whose elements trade places with one another. Permutations cycles
are called “orbits” by Comtet [1974, p. 256].
For example, in the permutation group {4, 2, 1, 3}, (143) is a 3-cycle and (2)
is a 1-cycle. Here, the notation (143) means that starting from the original
ordering {1, 2, 3, 4}, the first element is replaced by the fourth, the fourth by
the third, and the third by the first, that is, 1 → 4 → 3 → 1. In this paper,
we use curly braces “{}” to represent the permutation cycle, for example, the
permutation cycle {1, 4, 3}.
ACKNOWLEDGMENTS

This work was partially supported by DARPA under agreement No. F30602-971-0257 and by the University of Missouri Research Board. The authors thank
Lein Harn for his help and guidance when the authors first touched the research
area of secure group communication. The authors also thank Amit Sinha for
his feedback on the construction of the keying schemes. The authors also thank
Jane Vogl and Balaji Krithikaivasan for proof reading of an earlier version of
this paper. Finally, the authors would like to thank anonymous reviewers for
their valuable, detailed comments that improve both the content and representation of this paper.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Key-Chain-Based Keying Scheme

•

551

REFERENCES
ALVES-FOSS, J. 2000. An efficient secure authenticated group key exchange algorithm for large
and dynamic groups. In Proceedings 23rd National Information Systems Security Conference
(NISSC). National Institute of Standards and Technology, National Computer Security Center,
Baltimore, MD, USA, 254–266.
ATENIESE, G., STEINER, M., AND TSUDIK, G. 1998. Authenticated group key agreement and friends.
In Proceedings of the 5th ACM Conference on Computer and Communications Security. ACM
Press New York, NY, USA, San Francisco, California, 17–26.
BALLARDIE, T. 1996. Scalable multicast key distribution. RFC 1949.
BERKOVITS, S. 1992. How to broadcast a secret. In Advances in Cryptology: EUROCRPT ’91.
Lecture Notes in Computer Science, vol. 547. Springer-Verlag, Berlin, 536–541.
BLOM, R. 1985. An optimal class of symmetric key generation systems. In EUROCRYPT’84.
Lecture Notes in Computer Science, vol. 209. Springer-Verlag, Paris, France, 335–338.
BLUNDO, C. AND CRESTI, A. 1995. Space requirements for broadcast encryption. In Advances in
Cryptology: EUROCRYPT ’94. Lecture Notes in Computer Science. Springer-Verlag, New York,
287–298.
BLUNDO, C., MATTOS, L. A. F., AND STINSON, D. R. 1994. Multiple key distribution maintaining user
anonymity via broadcast channels. J. Comput. Secur. 3, 4, 309–323.
BLUNDO, C., MATTOS, L. A. F., AND STINSON, D. R. 1996. Trade-offs between communication and
storage in unconditionally secure schemes for broadcast encryption and interactive key distribution. In Proceedings of the 16th Annual International Cryptology Conference on Advances in
Cryptology. Springer-Verlag, Santa Barbara, California, USA, 387–400.
BLUNDO, C., SANTIS, A. D., HERZBERG, A., KUTTEN, S., VACCARO, U., AND YUNG, M. 1993. Perfectlysecure key distribution for dynamic conferences. Lecture Notes in Computer Science, vol. 740.
Springer-Verlag, Berlin, 471–486.
BLUNDO, C., SANTIS, A. D., HERZBERG, A., KUTTEN, S., VACCARO, U., AND YUNG, M. 1998. Perfectlysecure key distribution for dynamic conferences. Inform. Comput. 146, 1, 1–23.
BLUNDO, C., SANTIS, A. D., AND VACCARO, U. 1996. Randomness in distribution protocols. Informat.
Comput. 131, 2, 111–139.
BRISCOE, B. 1999. Marks: Zero side effect multicast key management using arbitrarily revealed
key. In Networked Group Communication (NGC’99). Springer-Verlag, Pisa, Italy.
BURMESTER, M. AND DESMEDT, Y. 1995. A secure and efficient conference key distribution system.
In Proceedings of Eurocrypt’ 94. Lecture Notes in Computer Science, vol. 950. Springer-Verlag,
Berlin, 275–286.
BURMESTER, M. AND DESMEDT, Y. 1996. Efficient and secure conference-key distribution. In Security
Protocols Workshop. Springer-Verlag, Cambridge, UK, 119–129.
COMTET, L. 1974. Advanced Combinatorics: The Art of Finite and Infinite Expansions. Dordrecht,
Boston, D. Reidel Publishing, Co., Netherlands.
COPPERSMITH, D. AND JAKOBSSON, M. 2002. Almost optimal hash sequence traversal. In Finacial
Cryptography. InterVarsity Press, Southampton, Bermuda.
DONDETI, L. R., MUKHERJEE, S., AND SAMAL, A. 1999. Survey and Comparison of Secure Group
Communication Protocols. Tech. rep., University of Nebraska, Lincoln.
DONDETI, L. R., MUKHERJEE, S., AND SAMAL, A. 2000. A distributed framework for scalable secure
many-to-many communication. In Fifth IEEE Symposium on Computers and Communications.
Antibes-Juan les Pins, France.
FIAT, A. AND NAOR, M. 1994. Broadcast encryption. In CRYPTO’93. Lecture Notes in Computer
Science, vol. 773. Springer-Verlag, Santa Barbara, California, 480–491.
GONG, L. AND SHACHAM, N. 1994. Elements of trusted multicasting. In Proceedings of the
2nd ACM Conference on Computer and Communications Security, Fairfax, Virginia. 176–
183.
GONG, L. AND WHEELER, D. I. 1990. A matrix key-distribution scheme. J. Cryptol. 2, 1, 51–
59.
HARARY, F. 1969. Graph Theory. Addison-Wesley Publishing Company, Inc.
HARNEY, H. AND MUCKENHIRN, C. 1997. Group key management protocol (GKMP) architecture.
RFC 2094.
ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

552

•

D. Huang and D. Medhi

JAKOBSSON, M. 2002. Fractal hash sequence representation and traversal. In IEEE International
Symposium on Information Theory.
JUST, M., KRANAKIS, E., KRIZANC, D., AND VAN OORSCHOT, P. 1994. On key distribution via true
broadcasting. In Proceedings of the 2nd ACM Conference on Computer and Communications
Security. 81–88.
KIM, Y., PERRIG, A., AND TSUDIK, G. 2000. Simple and fault-tolerant key agreement for dynamic
collaborative groups. In ACM Conference on Computer and Communications Security. 235–244.
KIM, Y., PERRIG, A., AND TSUDIK, G. 2001. Communication-efficient group key agreement. Tech.
rep., Department of Information and Computer Science, University of California, Irvine.
KORJIK, V., IVKOV, M., MERINOVICH, Y., BARG, A., AND VAN TILBORG, H. C. A. 1995. A broadcast key
distribution scheme based on block designs. In IMA Conference. 2–12.
KUROSAWA, K., OKADA, K., AND SAKANO, K. 1995. Security of the center in key distribution schemes.
In Advances in Cryptology: ASIACRYPT ’94. Lecture Notes in Computer Science.
LEIGHTON, T. AND MICALI, S. 1994. Secret-key agreement without public-key cryptography. Advances in Cryptology: CRYPTO ’93. Lecture Notes in Computer Science, vol. 773. 456–479.
MITTRA, S. 1997. A framework for scalable secure multicasting. In ACM SIGCOMM. 277–288.
MOYER, M. J., RAO, J. R., AND ROHATGGI, P. 1999. A survey of security issues in multicast communications. IEEE Netw. 13, 6, 12–23.
NAOR, D., NAOR, M., AND LOTSPIECH, J. 2001. Revocation and tracing schemes for stateless receivers. In Lecture Notes in Computer Science, vol. 2139. 41–62.
NIST. 1995. Secure Hash Standard. FIPS PUB 180-1.
RAFAELI, S. AND HUTCHISON, D. 2003. A survey of key management for secure group comunication.
ACM Comput. Surv. 35, 3, 309–329.
RIVEST, R. L. 1992. The MD5 message-digest algorithm. RFC 1321.
SHERMAN, A. T. AND MCGREW, D. A. 2003. Key establishment in large dynamic groups using oneway function trees. IEEE Trans. Softw. Engng 29, 5, 444–458.
SKIENA, S. 1990. Implementing Discrete Mathematics. Addison-Wesley Publishing Company.
SNOEYINK, J., SURI, S., AND VARGHESE, G. 2001. A lower bound for multicast key distribution. In
IEEE INFOCOM 1, 22–26.
STEINER, M., TSUDIK, G., AND WAIDNER, M. 1996. Diffie-Hellman key distribution extended to group
communication. In ACM Conference on Computer and Communications Security. 31–37.
STEINER, M., TSUDIK, G., AND WAIDNER, M. 1998. CLIQUES: A new approach to group key agreement. In Proceedings of the 18th International Conference on Distributed Computing Systems
(ICDCS’98). IEEE Computer Society Press, Amsterdam, 380–387.
STINSON, D. R. 1997. On some methods for unconditionally secure key distribution and broadcast
encryption. Des. Codes Cryptogr. 12, 3, 215–243.
STINSON, D. R. AND VAN TRUNG, T. 1998. Some new results on key distribution patterns and broadcast encryption. Des. Codes Cryptogr. 14, 3, 261–279.
WALDVOGEL, M., CARONNI, G., SUN, D., WEILER, N., AND PLATTNER, B. 1999. The versakey framework:
Versatile group key management. IEEE J. Sel. Areas Commun. 17, 9, 1614–1631.
WALLNER, D. M., HARDER, E. J., AND AGEE, R. C. 1999. Key management for multicast: Issues and
architectures. RFC 2627.
WONG, C. K., GOUDA, M., AND LAM, S. S. 2000. Secure group communications using key graphs.
IEEE/ACM Trans. Netw. 8, 1, 16–30.
Received May 2003; revised April 2004; accepted July 2004

ACM Transactions on Information and System Security, Vol. 7, No. 4, November 2004.

Globecom 2014 - Communication and Information System Security Symposium

Towards Distributed Privacy-Preserving Mobile
Access Control
Zhijie Wang, Dijiang Huang, Huijun Wu, Bing Li, Yuli Deng
Arizona State University, Tempe, USA
{wangzj, dijiang, huijun.wu, bingli5, yuli.deng}@asu.edu

Abstract—The mobile marketing is growing exponentially
worldwide due to the emerging high speed wireless Internet
and the proliferation of smartphones with powerful processors.
Consequently, the management of the massive volume of mobile
identities has sparked a lot of interest in both industry and
academia, as they turn out to be a heavy burden for many
mobile application startups. The conventional federated identity
management technologies have been developed to delegate the
users’ identity tasks across different security domains to reduce
the burden over the identity service consumers (i.e., Relying
Party). However, they also raises serious security and privacy
issues, such as the vulnerability to Single Point of Failure
(SPOF) and the privacy leakage with respect to users’ historical
access information. To address these issues, we architect a novel
Distributed Privacy-preserving Mobile Access Control (DP-MAC)
framework. This framework also leverages a dual-root trust
model to prevent identity theft in case of mobile device loss. In the
end, we give performance evaluation and prove its applicability
by implementing our system in the Cloud Computing platform
and android smartphones based on jPBC in real-world settings.

I. I NTRODUCTION
The fast-growing online applications and services for smartphones boost the online setup of mobile identities, and large
quantities of identity setups have proven to be a financial
and management burden for many start-up entrepreneurs.
On one hand, since smartphones store tremendous personal
information about the individual users, the management of
mobile identities must be handled with extreme caution as it
is often related to personal proprietary resources. On the other
hand, there is a rising demand on an open and federated mobile
identity management system to facilitate the access control of
resource sharing between collaborating parties across heterogeneous security domains. Therefore, these factors necessitate
an open, comprehensive and secure mobile access control system whereby different mobile service providers can outsource
the access control tasks and reduce the management cost.
A natural approach to address this problem is to leverage
the existing federated identity management framework based
on the concept of Identity-as-a-Service (IDaaS). The federated
identity management frameworks built on IDaaS, such as
OpenID [1], emerges as widely-accepted solutions to integrate
multiple identity service providers and consumers together.
The OpenID is an open standard for authentication delegation.
It architects a framework in which the Identity Provider (IdP)
acts as a centralized authority by holding the identities and
credentials of the End Users (EU). When the EU interacts with

978-1-4799-3512-3/14/$31.00 ©2014 IEEE

the Relying Party (RP)(e.g., a website or application), the RP
delegates the authentication process to the IdP. However, it is
prone to several security attacks. First of all, the IdP could
be Honest-But-Curious (HBC) and it can easily invade EU’s
privacy, because the IdP will know all the RPs that the EU
has been trying to log into, since the RPs have to delegate
the authentication requests to the IdP, and the RPs need to
directly communicate and verify with the IdP. Second, OpenID
is vulnerable to SPOF. A single IdP can become the central
axis by undertaking the authentication tasks for numerous RPs
and EUs, and the crash of this IdP will imperil all the related
authentication and access control processes. Worse still, once
the IdP is compromised, all the EUs’ credentials stored on
this IdP are exposed to the attacker. Last but not the least, the
malicious RP can launch a phishing attack by directing the
EU to a bogus authentication webpage of a fake IdP.
To address the issues stated above, we propose a novel
Distributed Privacy-preserving Mobile Access Control (DPMAC) framework based on the integration of decentralized
Attribute-Based Encryption (DABE) [2] and Identity-Based
Encryption (IBE) [3]. In DP-MAC, the Service Provider (SP)
can create different access policies and dynamically select
multiple IdPs to undertake the tasks for mobile access control
whereby the SPOF issue can be solved. In addition, the IdPs
are prevented from tracking the mobile users’ historic access to
SPs, because the IdPs are not allowed to directly communicate
with the SPs and they cannot infer which SP the user is
trying to log in. A side benefit is that the phishing attack
is eliminated as there is no webpage redirection. Moreover,
the system utilizes the Dual-Root Trust (DRT) model wherein
the Mobile User (MU) splits her secret credential into two
parts, and stores them on the mobile device and the usercentric Mobile Cloud (MC) respectively. Note that different
users can freely select different cloud providers (e.g., Amazon
EC2, Microsoft Azure) to be the MC and store their credential
part, such that compromising any cloud platform has no impact
on the users on other cloud platforms and SPOF is mitigated
accordingly. Hence, the loss of mobile device does not cause
identity theft, since both parts are indispensable to validate
the user in the process of mobile access control. Additionally,
the major computation cost is shifted from the resourceconstrained mobile device to MC as a result. To sum up, our
contributions are four-fold as follows:

582

•

We architect a new distributed framework with dual-

Globecom 2014 - Communication and Information System Security Symposium

•

•

•

ŝƐƚƌŝďƵƚĞĚW<'Ɛ

root trust for mobile access control whereby the SPOF
problem is mitigated due to multiple IdPs and distributed
MCs, and the threat of mobile identity theft is alleviated.
We devise a new access control model to counter against
HBC attack from IdP, thereby protecting mobile users’
privacy with respect to the historic access information.
In DP-MAC, the SPs do not need to establish shared
secrets with any IdPs, and they do not maintain the credentials of any mobile users, thereby achieving the maximum scalability in the distributed environment where the
number of IdPs and mobile users can grow exponentially.
We implement DP-MAC in mobile cloud platform and
android smartphones with jPBC [4] to prove its applicability in real-world settings.

W<'ϭ

ϭͲ^ĞƚƵƉ

͙͘͘͘
ϯͲDh>ŽŐŝŶZĞƋƵĞƐƚ

DŽďŝůĞ

In DP-MAC, the mobile users can use credentials from
multiple identity providers without disclosing their historical
access information of application services to the identity
providers. It utilizes a decentralized architecture as illustrated
in Figure 1, and consists of five components as follows:

•

/ĚWŵ

ŽŶƚƌŽů

͙͘͘͘

ϲͲ'ĞŶZĞƐƉŽŶƐĞǆ

ϲ

ϳͲ'ĞŶZĞƐƉŽŶƐĞ
ϴͲsĞƌŝĨŝĐĂƚŝŽŶ
ϳ
ŝƐƚƌŝďƵƚĞĚ
D
Ϯ

ϰ

ϯ

ϴ
ϱ
^W

Fig. 1: The Architecture of DP-MAC

A. System Model

•

/ĚWϭ

ϱͲ'ĞŶŚĂůůĞŶŐĞ ĐĐĞƐƐ

Dh

In this section, we presents the system model of DP-MAC
and adversary model as well as cryptographic preliminaries.

•

ϭ

ϰͲ'ĞŶdŽŬĞŶ

II. T HE DP-MAC F RAMEWORK D ESIGN AND
P RELIMINARIES

•

^ǇƐƚĞŵ
^ĞƚƵƉ

ϮͲDhZĞŐŝƐƚĞƌ

The remainder of this paper is organized as follows. Section
II describes the system model and security requirements.
Section III provides the detailed construction of DP-MAC
based on cryptographic operations. Section IV gives the performance evaluation and security analysis. Section V discusses
the related work, and conclusions are given in section VI.

•

W<'Ŭ

Distributed P ublic Key Generators (D-P KGs): The
D-PKGs are trusted parties to generate private keys for
the Identity Providers based on their identity strings in
the system setup. After that, the D-PKGs go offline until
a new Identity Provider joins or leaves the system.
Identity P rovider (IdP ): An IdP is an entity that issues
unique identifiers to the registered mobile device users.
It is responsible for authenticating the mobile users for
the Service Providers.
Service P rovider (SP ): The SP is usually a website
or an application that provides services and resources for
the mobile users. It delegates the authentication tasks to
the trusted IdPs to reduce its own overhead.
M obile Cloud (M C): The MC provide a dedicated
virtual machine to the mobile user for computation services and credential storage. It functions as a middle-man
between multiple IdPs and the mobile user to help reduce
the communication and computation cost of the mobile
device.
M obile U ser (M U ): The MU is the owner of a mobile
device and she needs to log into the SP for services and
resources.

B. Adversary Model
We have the following assumptions: 1) Both the IdPs and
MCs comply with the protocol and output the correct results;
2) The mobile devices perform secure execution of trusted
codes in trusted execution environment 3)Different classes of
participating parties do not collude together; 4) the communication between different classes of participating parties are
protected by secure channels. Accordingly, we consider the
following attacks in DP-MAC:
• Single P oint of F ailure (SP OF ): The DP-MAC
system cannot proceed due to the crash of any single
party, which could be an IdP, a MC or a PKG.
• Honest But Curious (HBC): Both the IdPs and MCs
honestly follow the procedures, but they are interested
in tracking the MU’s historical access information to
different SPs.
• Impersonation: The malicious SP might leverage the received token to impersonate the MU in the future mobile
authentication and access control procedure. Meanwhile,
the MU could be subject to identity theft due to the loss
of her mobile device.
In section V, we will prove that our system is resilient against
the attacks mentioned above.
C. Cryptographic Preliminaries
Bilinear pairings are the basic operations in our framework. Assume G and GT are two cyclic groups with order
q generated by a Bilinear Diffie-Hellman (BDH) parameter
generator G. Correspondingly we set up a bilinear map system
S = (q, G, GT , e) where e denotes a computable bilinear map
e : G × G → GT with the following properties:

583

Globecom 2014 - Communication and Information System Security Symposium

TABLE I: Notations

Bilinearity: ∀G, W ∈ G, ∀a, b ∈ Z, e(G a , W b ) =
e(G, W )ab ;
• Non-degeneracy: G and W are the generators of G,
e(G a , W b ) 6= 1;
• Computability: e(G, W ) is efficiently computable.
In our system,we set G = W and make G, G, GT public.
The cryptographic techniques of our system are constructed
on top of IBE with D-PKGs and DABE. IBE enables
the encryptor to use the receipient’s identity string (e.g.,
“bob@gmail.com||current-year”) as the public key to encrypt
messages, thus it eliminates the need for a public key distribution infrastructure. DABE enables the encryptor to encrypt
data using a policy written over credentials across different
authorities between which there is no coordination. Therefore,
the SP can use the IdP’s identity as the public key to encrypt
some secrets, and send them to the IdP through the mobile
device and MU for authentication without worrying about
being tampered. Also, the SP can dynamically select multiple
trusted IdPs for mobile authentication and access control by
creating an access policy with LSSS access structure [5], [6].
Consequently, even if some IdPs are compromised, the SP
can easily adjust the authentication criterion by removing the
impacted IdPs and adding other IdPs.
•

Notation
GIDu
(k0 , k)
I, Ii
IM U
ISP
Imin
εj
di,j
di
A
Ax
ρ(x)
s
SKi = {αi , yi }
SKi,1 = g yi
SKi,2 = g αi
Ki,u

Description
The unique ID of the mobile device (e.g., IMEI).
the threshold of D-PKGs; k is the total number of
PKGs and at least k0 of these PKGs can derive the
secret key.
the IdP set and the i-th IdP in I.
the set of the IdPs registered by the MU.
the set of the IdPs trusted by the SP in a mobile
authentication and access control process.
the minimum subset contained in both IEU and ISP
that can satisfy the access policy.
the master key share generated by the j-th PKG from
the k0 PKGs selected by the IdP.
the private key share generated by the j-th PKG from
the k0 PKGs selected by the IdP Ii .
the private key of the IdP Ii .
a LSSS-based access matrix used by the SP to select
the trusted IdPs.
the x-th row of A.
the mapping from Ax to IdP x.
a random secret generated by the SP in a mobile
authentication and access control process; s ∈ Zq .
the secret of the MU generated in the registration
process on IdP i where αi , yi ∈ Zq .
the secret key share stored on the MC with respect
to IdP Ii where g ∈ G.
the secret key share stored on the MU’s mobile
device with respect to IdP Ii .
the credential of MU u stored on IdP Ii .

III. S YSTEM C ONSTRUCTION AND W ORKFLOW
In this section, we describe how to construct our system
and exhibit the workflow in Figure 2. The most commonly
notations are listed in Table I. In System Setup phase, the
distributed PKGs cooperatively broadcast global parameters
params and issue private key di to each IdP Ii . Next, the
MU registers on IdPs with credentials and store the secret
key shares on the smartphone and MC separately. In Mobile
Authentication and Access Control phase, the SP selects the
minimum subset of IdPs Imin for the MU based on the access
policy, and the MU provides Imin -related tokens. Accordingly,
the SP challenges the MU, and the MU forwards challenge0
to the selected IdPs after further processing. Consequently, the
IdPs generate response for the SP to validate via the MU and
the corresponding MC.

MU

SP

In the system setup, the D-PKGs generates public parameters and computes private keys for IdPs. The MU also registers
at selected IdPs and MC with secret keys and credentials.
1. Setup(κ, G, I) → (params, {di }Ii ∈I ): Given a security
parameter κ, a BDH parameter generator G and a collection I
of IdPs, the k distributed PKGs do the following steps:
1) Given a security parameter κ, it runs G to generate a
prime q, G, GT of order q so that there exists a bilinear
map e : G × G → GT .
2) Pick random generators P, g ∈ G and ε ∈ Z∗q . As with
the distributed PKGs in IBE, each of the k PKGs keeps
one share εj of a Shamir secret sharing of ε mod q in
a k 0 -out-of-k fashion.
3) Choose three cryptographic hash functions H1 , H2 , H3
such that there exist H1 : {0, 1}∗ → G∗ , H2 :
GT → {0, 1}n for some n, and H3 : {0, 1}∗ →
Z∗q . The public system parameters are params =
{q, G, GT , e, n, P, g, Ppub = P ε , H1 , H2 , H3 }
4) Given the i-th IdP’s identity string Ii ∈ {0, 1}n ,
each IdP Ii selects k 0 out of the k PKGs to compute
ε
Qi = H1 (Ii ) ∈ G∗ and {di,j | di,j = Qi j }1≤j≤k0 .
Subsequently, the IdP Ii derives
P its private key by
Q aj
a j εj
computing di = j di,j = Qi j
where the aj ’s
are the appropriate Lagrange coefficients.
5) The D-PKGs goes offline until any of the IdPs need to
be revoked or a new IdP joins the system.

D-PKGs

IdPs

Distributed MCs

A. System Setup

1. params, d

i

System
Setup

2. Sk , Sk , K
i,1

3. II

i,u

min

4. token
Mobile
Access
Control

i,2

token

2

5. challenge

1

challenge’
6. response

x

7. response
8. verification

Fig. 2: The DP-MAC Workflow

2. MURegister(params, I) → {SKi,1 , SKi,2 , Ki,u }Ii ∈IM U :
In this process, the MU registers at a subset of IdPs IM U ⊆

584

Globecom 2014 - Communication and Information System Security Symposium

1) On receiving token2 , the SP picks a random number
s ∈ Zq to compute C0 = e(g, g)s for validation in the
end. It also selects a random vector v ∈ Zlq with s as its
first entry, and a random vector w ∈ Zlq with 0 as its first
entry. We use Ax to denote the row x of A. For each
row Ax , it picks a random secret Rx ∈ {0, 1}m , and
calculates λx = Ax ·v, wx = Ax ·w and rx,3 = H3 (Rx ),
thereby deriving the challenge message as below:
challenge = (A, {C1,x , C3,x , C4,x }Ix ∈Imin ),
where
rx,2 rx,3
C1,x = e(g, g)λx e(g rx,1 , SKx,2
)
αρ(x) rx
λx
,
= e(g, g) e(g, g)
rx,1 rx,2 rx,3 wx
C3,x = SKx,1
g = g yρ(x) rx g wx ,
∗
r∗
C4,x = {P rx , Rx ⊕ H2 (gxx )},

I. She also selects a MC at will and registers a dedicated
virtual machine. All the keys and credentials are computed in
an oblivious manner. The steps proceed as follows:
1) The MU selects multiple IdPs IM U ⊆ I, and registers
a unique account on each IdP with GIDu . For IdP Ii ,
the MU randomly selects αi , yi ∈ Zq as the secrete
key SKi = {αi , yi }, and stores the credential Ki,u =
g αi H1yi (GIDu ) on IdP Ii .
2) The MU computes SKi,1 = g yi for every selected
IdP Ii and stores {SKi,1 }Ii ∈IM U on a dedicated virtual
machine of the selected MC.
3) The MU computes SKi,2 = g αi for every selected
IdP Ii , stores {SKi,2 }Ii ∈IM U on the mobile device and
discards the secret {SKi }Ii ∈IM U .
B. Mobile Authentication and Access Control
In this procedure, the MU and the SP interactively negotiate
to derive a minimum subset of IdPs Imin to satisfy the SP’s
access policy. Afterwards, the MU provides proofs to the SP
with the help of the MC, and the SP sends the encrypted
proofs to the IdPs through the mobile device and the MC for
validation. This process proceeds as follows:
3. MULoginRequest(IM U , ISP ) → Imin : In this phase, the
MU and the SP cooperates to derive a minimum subset of
IdPs from the intersection of the SP-trusted IdPs and the MUregistered IdPs to satisfy the access policy. The steps go as
follows:
1) The MU sends a login request to the SP, and the SP
shows the EU its access policy in the form of a boolean
formula in terms of the trusted IdPs ISP . For example,
the policy IdP 1∧IdP 2∧(IdP 3∨IdP 4∨IdP 5)) implies
the MU must have registered at IdP1, IdP2, and one out
of IdP3, IdP4 and IdP5.
2) The MU selects the IdPs she has registered, and they
can derive
T the minimum subset Imin such that Imin ⊆
(IM U ISP ) to satisfy the authentication criterion. We
do not discuss the details about how to derive Imin in
this paper due to page limits. If |Imin | = 0, then the
login request is declined. Otherwise, the authentication
and access control process proceeds.
4. GenToken(params, {SKx,1 , SKx,2 }Ix ∈Imin ) → token2 :
In this phase, the SP requests the validation that the MU has
registered at the IdPs in Imin , and the MU produces the proof
with the help of the MC as follows:
1) The MU invokes the RESTful service running on the
MC through SSL/TLS. The MC computes and transfers
rx,1
token1 = {g rx,1 , SKx,1
}Ix ∈Imin to the MU by randomly selecting rx,1 ∈ Zq .
2) Upon receiving token1 , the MU randomly selects rx,2 ∈ Zq , and then computes token2 =
rx,1 rx,2
rx,2
0
{g rx,1 , SKx,1
, SKx,2
, }Ix ∈Imin and {C2,x
=
rx,1 rx,2
g
}Ix ∈Imin . Subsequently, it transfers token2 to
0
the SP but keeps {C2,x
}Ix ∈Imin .
5. GenChallenge(params, token2 ) → challenge0 . In this
phase, the SP generates and transfers a challenge to the IdPs
through the MU and the MC as follows:

and rx = rx,1 rx,2 rx,3 , gx = e(H1 (Ix ), Ppub ).
2) The SP sends challenge to the MC through
the MU, and the MU derives challenge0 =
0
(A, {C1,x , C2,x
, C3,x , C4,x }Ix ∈Imin ) by appending
0
{C2,x }Ix ∈Imin and transfers it to the MC. The MC
splits and forwards the corresponding part of challenge0
to each selected IdP respectively.
6. GenResponsex(params, challenge0 ) → responsex : In
this phase, each IdP Ix performs an initial decryption over
the challenge and outputs responsex as follows:
1) The IdP Ix derives rx,3 by applying IBE decryption to
C4,x with its private key dx :
r∗

∗

Rx ⊕ H2 (gxx ) ⊕ H2 (e(dx , P rx ))
∗
∗
= Rx ⊕ H2 (e(H1 (Ix ), Ppub )rx ) ⊕ H2 (e(dx , P rx ))
∗
∗
= Rx ⊕ H2 (e(H1 (Ix ), P ε )rx ) ⊕ H2 (e(H1ε (Ix ), P rx ))
= Rx
and retrieves rx,3 = H3 (Rx ) thereafter. Then it derives
0
C2,x = (C2,x
)rx,3 = g rx .
2) Subsequently, the IdP Ix looks up GIDu in the registered
user table, and computes responsex :
C1,x · e(H1 (GIDu ), C3,x )
=e(g, g)λx e(H1 (GIDu ), g)wx
e(Kρ(x),u , C2,x )
which is then sent back to the MC.
7. GenResponse(params, {responsex }Ix ∈Imin )
→
response: In this phase, the MC completes the final
decryption as below:
1) Upon receiving responsex from each IdP
Px, the MC
selects constants cx ∈ Zq such that
x cx Ax =
(1, 0, · · · , 0). Thereafter it computes response as below:
Y
0
?
(e(g, g)λx e(H1 (GIDx ), g)wx )cx = e(g, g)s .
x

2) the MC sends response to the SP through the MU.
8. Verification the SP verifies response against C0 . If they are
equal, then the MU is granted the access to log in; otherwise
the MU’s access request is rejected.
IV. S ECURITY A NALYSIS AND E VALUATION
In this section, we provide the security assessment and the
evaluate results regarding the participating parties.

585

A. Security Analysis

Computation overhead (millisecond)

10000

As the security of DP-MAC mainly relies on IBE and
DABE, its security strength can be also proved using the same
proofs in [3] and [2]. In addition, we use the two assumptions
below to ensure the security in the following part.
DEFINITION 1 (Discrete Logarithm Problem(DLP) Assumption). Given g, g x ∈ G where x ∈ Z∗n , then for any probabilistic polynomial-time (PPT) algorithm A and negligible ε,
we have P r[A(g, g x ) = x] ≤ ε.
DEFINITION 2 (Decisional Diffie-Hellman Problem(DDH)).
Given a randomly chosen 4-tuple (g, g a , g b , g c ) ∈ G4 with
a, b ∈ Z∗n to determine whether c = ab or not. The DDH
assumption holds in G if no PPT algorithm A has nonnegligible advantage ε in solving the DDH problem in G.
Theorem 1: DP-MAC is secure against the authentication
spoofing attack committed by the MU.
Proof: DP-MAC ensures that the MU cannot prove her
authenticity alone without delegating the authentication tasks
to all the IdPs required by the access policy. In practice,
the MU is motivated to spoof the SP that she has been
authenticated by all the target IdPs, which is not the truth.
Nonetheless, the SP generates a blinding factor Rx for each
IdP Ix , and forwards it to the IdP Ix through the MU and the
MC after encrypting it with Ix ’s public key. The cryptographic
strength of IBE prevents the MU and her dedicated virtual
machine from deriving Rx without the help of Ix . As such,
the MU cannot derive C2,x , and the cryptographic strength
of DABE ensures that the MU cannot compute the correct
response for validation without the knowledge of C2,x . In
addition, given C1,x , C3,x and token2 , the blinding factor Rx
prevents the MU from deducing e(g, g)λx and g wx due to the
hardness of DLP. As a result, the MU cannot derive the correct
response and authenticate herself to the SP.
Theorem 2: DP-MAC is secure against the impersonation
attack launched by the SP.
Proof: DP-MAC ensures that the malicious SP cannot
impersonate an authenticated MU with all the information in
prior authentication and access control process. In actuality,
the malicious SP might impersonate the MU in previous
authentication process to get validation from the RP in a
new authentication process by reusing the received token2 .
0
Nevertheless, the MU didn’t disclose C2,x
= g rx,1 rx,2 to
0
in order
the malicious SP, and the SP has to derive C2,x
to be successfully authenticated due to the cryptographic
strength of DABE. Note that token2 takes the form of
{g rx,1 , g yx rx,1 rx,2 , g αi rx,2 }, and the unknown yx renders it
impossible for the SP to derive g rx,1 rx,2 from g yx rx,1 rx,2 .
Assume the malicious SP has made a successful guess of
g rx,2 from g αi rx,2 , the hardness of DDH ensures that the SP
can derive g rx,1 rx,2 from g rx,1 and g rx,2 with a negligible
probability in polynomial time. Hence DP-MAC prevents the
SP from launching any impersonation attacks against the MU.
Furthermore, the decentralized architecture enables DPMAC to be robust against the fault of any system component,

Computational overhead (millisecond)

Globecom 2014 - Communication and Information System Security Symposium

D−PKGs (Server)
MU (Smartphone)

1000

100
1

2

3
4
5
The number of IdPs

6

10000

MC (Server)
SP (Server)
MU (Smartphone)
aveIdP (Servers)

1000

100
1

2

3
4
5
The number of IdPs

6

(a) The computational cost in system (b) The computational cost in authensetup phase
tication and access control phase

Fig. 3: The computational costs in DP-MAC.
and thus it mitigates the SPOF problem. Also, k 0 out of k
PKGs are employed to generate secret key for IdP, and the
adversary cannot get any advantage if less than k 0 PKGs
are compromised. Note that the MU can register a dedicated
virtual machine in any cloud, and the corruption of one cloud
platform wouldn’t impact other MUs in other cloud platforms.
In addition, DP-MAC protects the privacy of the MU
against HBC attacks from the IdPs, because the SP delegates
the authentication and access control to the IdPs through
MU without direct interactions with IdPs, and the challenge
messages do not contain any information about the SP. Both
the IdPs and the MC cannot gain any knowledge about the SP,
as the MU is placed between the MC and the SP, and it cannot
infer the SP from the tokens and the challenge messages.
Last but not the least, DP-MAC can prevent identity theft
in case of mobile device loss, because the adversary cannot
establish SSL/TLS channel with the dedicated virtual machine
in the MC, such that it is unable to complete the authentication
and access control process using SKx,2 only.
B. Performance Evaluation
In this subsection, we implement DP-MAC in Mobicloud
[7] and android smartphone. The MU uses a Samsung Galaxy
Note with Quad core ARM Cortex-A9 at 1.6GHz and 2GB
memory running Android 4.2 (Jelly Bean), and the other
participating parties are simulated by Dell desktop with dualcore Intel(R) Pentium(R) 4 CPU at 2.80GHz and 2GB memory
running 32-bit Ubuntu Lucid Lynx (Ubuntu 10.04). The experiment utilizes Java Pairing-Based Cryptography (jPBC) library
[4] based on Type-A ECC curve which features the fastest
group operation. It is on the supersingular curve y 2 = x3 + x
over the 512-bit finite field.
From Figure 3(a) it can be seen that the computation time
of D-PKGs and the MU in M U Register increases almost
linearly as the number of associated IdPs grow from 1 to 6.
As the algorithms in the system setup phase run only one
time, the computational overhead of the MU are acceptable
in real life, as the users are unlikely to register at too many
IdPs. Figure 3(b) illustrates the computational overhead in the
authentication and access control phase. We do not consider

586

Globecom 2014 - Communication and Information System Security Symposium

the time cost of M U LoginRequest and V erif ication, as
they do not involve any computation-intensive cryptographic
operations. It can be seen that the computation time of MC,
the SP and the MU grow almost linearly. The computation
time of IdPs on average keeps around 270 milliseconds as the
number of selected IdPs grow from 1 to 6. We believe the
computational cost is acceptable for the MU, as this is only
one-time authentication and access control phase, and the MU
can be assigned a session key by the SP to perform symmetric
encryption after validation. Moreover, our experiments show
that the CPU usage on the Samsung smartphone falls within
[0.61, 0.62] while the CPU usage of the Dell server falls
within [0.65, 0.79] as the number of IdPs increases from 1
to 6. Besides, the total battery consumption on the Samsung
smartphone is negligible as it remains below 1%.

VI. C ONCLUSION
In this paper, we proposed a novel digital identity management system DP-MAC to address a few security concerns. The
distributed architecture of DP-MAC mitigates SPOF attack
and it is robustness against attacks over different participating
parties. The MU’s privacy of historical access information to
different services is also ensured by separating the IdPs from
the SP, such that the IdPs have no knowledge about the SP
that the MU tries to log into. The SP can dynamically adjust
its access policy without incurring additional cost, and it does
not store any shared secrets ot certificates of the IdPs, thereby
bringing a high scalability to the system. Our DP-MAC breeds
more convenient and safe identification services for mobile
users, and it can spawn a new ecosystem in the real-world
wireless industry where cloud providers can reap profit from
secure identification services on the internet by working as
middle agents between the IdPs and mobile users.

V. R ELATED W ORK

ACKNOWLEDGMENT
This research is sponsored by ONR YIP Award N0001410-1-0714 and ARO Research Grant W911NF-11-1-0191.

OpenID 2.0 [1] was developed as an open communitydriven platform as a scalable user-centric identity infrastructure on the Internet. Seong et al. [8] architected a decentralized social networking infrastructure using the OpenID
management system so users can retrieve data with their
established personas. Bertino et al. [9] designed a privacypreserving digital identity management system to authenticate
users based on user identity properties, and the registrar signs
on the commitment of users’ attributes to generate certificate
for the users. Chow et al. [10] presented SPICE whereby the
users can authenticate themselves to the service providers with
certificates when the registrar is offline, but the revoked users
can use certificates to access services, which is still unknown
to the service providers.
Shamir first proposed the concept of Identity-Based Cryptosystems [11] whereby the need for public-key certificates are
eliminated. A practical and efficient Identity-Based Encryption
(BF-IBE) [3] scheme was presented based on bilinear pairing
in 1999. Sahai and Waters proposed the first ABE scheme
[12] in 2005 where an identity is viewed as a set of descriptive
attributes. A derived version [13] was proposed to dynamically
set up multicast groups with group membership anonymity.
Melissa Chase demonstrated multi-authority ABE in [14] and
it requires a central trusted party to issue the key to every
user. An improved version [15] removes the central authority,
but it requires all the attribute authorities to participate in
the access control, which does not fit our scenario. In 2011,
Allison Lewko and Brent Waters presented a multi-authority
attribute-based encryption system DABE [2] in which no
preset access structure exists and the key generation authorities
work independently from each other. Our DP-MAC is built
on top of IBE and DABE and they bring robustness and
scalability. With the usage of Linear Secret-Sharing Scheme,
the SP can easily adapt the access control policy. The MC
assists the MU in the computation and communication with
different IdPs, and it helps alleviate the threat of identity theft.

R EFERENCES
[1] D. Recordon and D. Reed, “Openid 2.0: a platform for user-centric
identity management,” in Proceedings of the second ACM workshop on
Digital identity management. ACM, 2006, pp. 11–16.
[2] A. Lewko and B. Waters, “Decentralizing attribute-based encryption,”
Advances in Cryptology–EUROCRYPT 2011, pp. 568–588, 2011.
[3] D. Boneh and M. Franklin, “Identity-based encryption from the weil
pairing,” in Advances in CryptologyCRYPTO 2001. Springer, 2001,
pp. 213–229.
[4] A. De Caro and V. Iovino, “jpbc: Java pairing based cryptography,” in
the 2011 IEEE Symposium on Computers and Communications (ISCC).
IEEE, 2011, pp. 850–855.
[5] A. Beimel, “Secure schemes for secret sharing and key distribution,”
Ph.D. dissertation, PhD thesis, Israel Institute of Technology, Technion,
Haifa, Israel, 1996.
[6] S. Müller, S. Katzenbeisser, and C. Eckert, “On multi-authority
ciphertext-policy attribute-based encryption,” Bulletin of the Korean
Mathematical Society, vol. 46, no. 4, pp. 803–819, 2009.
[7] D. Huang et al., “Mobile cloud computing,” IEEE COMSOC Multimedia
Communications Technical Committee (MMTC) E-Letter, vol. 6, no. 10,
pp. 27–31, 2011.
[8] S.-W. Seong, J. Seo, M. Nasielski, D. Sengupta, S. Hangal, S. K.
Teh, R. Chu, B. Dodson, and M. S. Lam, “Prpl: a decentralized social
networking infrastructure,” in Proceedings of the 1st ACM Workshop
on Mobile Cloud Computing & Services: Social Networks and Beyond.
ACM, 2010, p. 8.
[9] E. Bertino, F. Paci, R. Ferrini, and N. Shang, “Privacy-preserving digital
identity management for cloud computing,” Data Engineering, vol. 32,
no. 1, 2009.
[10] S. Chow, Y.-J. He, L. Hui, and S. Yiu, “Spice–simple privacy-preserving
identity-management for cloud environment,” in Applied Cryptography
and Network Security. Springer, 2012, pp. 526–543.
[11] A. Shamir, “Identity-based cryptosystems and signature schemes,” in
Advances in cryptology. Springer, 1985, pp. 47–53.
[12] A. Sahai and B. Waters, “Fuzzy identity-based encryption,” Advances
in Cryptology–EUROCRYPT 2005, pp. 557–557, 2005.
[13] S. Yu, K. Ren, and W. Lou, “Attribute-based on-demand multicast group
setup with membership anonymity,” Computer Networks, vol. 54, no. 3,
pp. 377–386, 2010.
[14] M. Chase, “Multi-authority attribute based encryption,” in Theory of
Cryptography. Springer, 2007, pp. 515–534.
[15] M. Chase and S. S. Chow, “Improving privacy and security in multiauthority attribute-based encryption,” in Proceedings of the 16th ACM
conference on Computer and communications security. ACM, 2009,
pp. 121–130.

587

Available online at www.sciencedirect.com

Ad Hoc Networks 6 (2008) 560–577
www.elsevier.com/locate/adhoc

A secure group key management scheme for hierarchical
mobile ad hoc networks
Dijiang Huang

a,*

, Deep Medhi

b

a

b

Department of Computer Science and Engineering, Arizona State University, AZ, United States
Department of Computer Science and Electrical Engineering, University of Missouri–Kansas City, MO, United States
Received 6 April 2006; received in revised form 17 April 2007; accepted 30 April 2007
Available online 16 May 2007

Abstract
In this paper, we present a secure group key management scheme for hierarchical mobile ad-hoc networks. Our
approach aims to improve both scalability and survivability of group key management for large-scale wireless ad-hoc
networks. To achieve our goal, we propose the following approaches: (1) a multi-level security model, which follows a
modiﬁed Bell-La Padula security model that is suitable in a hierarchical mobile ad-hoc networking environment, and
(2) a decentralized group key management infrastructure to achieve such a multi-level security model. Our approaches
reduce the key management overhead and improve resilience to any single point failure problem. In addition, we have
developed a roaming protocol that is able to provide secure group communication involving group members from diﬀerent
groups without requiring new keys; an advantage of this protocol is that it is able to provide continuous group communication even when the group manager fails.
 2007 Elsevier B.V. All rights reserved.
Keywords: Security; Group key management; Hierarchy; Ad-hoc network; Many-to-many group communication

1. Introduction
A hierarchical mobile ad-hoc network (HMANET) architecture is formed by multiple groups in
a hierarchical network structure in which each
group consists of multiple mobile nodes. The HMANET architecture has been extensively studied [1–3].
In this paper, we focus on the security aspect of the
HMANET architecture, especially on developing an

*
Corresponding author. Tel.: +1 480 965 2776; fax: +1 480 965
2751.
E-mail address: dijiang@asu.edu (D. Huang).

eﬃcient secure group key management scheme. It
may be noted that wireless mobile devices usually
have limited energy capacity, which restricts their
communication abilities [4]. Thus, compared to the
ﬁxed network infrastructure, an eﬃcient group keying scheme in an HMANET that can address reduction of both communication and computation
overhead is desirable. A critical issue in key management in the HMANET framework is whether a
scheme allows movement of mobile nodes from
one group to another without unduely increasing
overhead, which impacts power consumption cost.
Furthermore, in a real-time application environment, a device that is visiting another group should

1570-8705/$ - see front matter  2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.adhoc.2007.04.006

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

be able to communicate without unduely incurring
heavy key establishment cost.
In this paper, we focus on a HMANET environment in which devices (i.e., users with devices) may
frequently move from one group to another. We
have developed a keying scheme that allows such
movement without requiring a new key generation
and establishment for each communication session.
To reduce both communication and computation
overhead of group key management schemes for
HMANET, we present a shared-key-based groupkey management scheme in which the group key
management includes two phases: (1) a key predistribution phase and (2) a group communication
phase. In order to discuss these phases, we ﬁrst
introduce a few terminology: an add means a new
user becomes a member of an existing group; this
is distinguished from a join when a group member
joins an existing group/subgroup communication
session. When a member leaves a group permanently, we refer to it as a delete or hard eviction;
if a member leaves an existing group communication session, it is referred to as a leave or soft
eviction.
It is assumed that each group forms initially
with a stable group population for which a key
pre-distribution phase is initially invoked. In each
such group, a group manager is assumed to be in
charge of the key distribution for its group. If a
new user is added to an existing group, then a
new key distribution is invoked; this is not to be
confused with a user from another group visiting
an existing group. To avoid frequent key pre-distribution, a group can be formed that allows some
empty slots. For instance, suppose a group is of
size 50, but is anticipated to grow to 60 soon; in
this case, the group can be started with 60 slots
in our group keying scheme, so that the empty slots
can be ﬁlled with if a new user is added to the
group, yet not requiring another key distribution
unless the group size actually goes over 60. It
should be noted that key pre-distribution is not
required for the following three cases: (1) a subset
of existing group members need to communicate
impromptu for a secure subgroup communication
session, (2) a member is to be excluded from an
existing communication session, and (3) a member
is involved in multiple subgroup communications
simultaneously (subgroups can be overlapped).
This three scenarios fall under the communication
phase and operations involved fall under join or
leave, as deﬁned earlier. Furthermore, our keying

561

scheme has the property that a user can be in multiple subgroup communications sessions without
requires news keys.
It may be noted that a hierarchical group structure improves the scalability of key management
for large-scale heterogenous MANETs. The drawbacks of a hierarchical structure are: (1) it reduces
the ﬂexibility of the group formations, and (2) it
requires an additional mechanism to handle roaming of group members. For example, a mobile user
may travel to other groups and might not be able
to set up communication back to its original group
members, or if the group manager fails, then a new
group manager needs to be assigned either by the
higher-level nodes or elected by other group members. To solve such issues, we present a source-routing-based roaming protocol which utilizes a
computational eﬃcient multicast-tree encoding
scheme using Prüfer sequence [5].
We next comment on security policy. The Bell-La
Padula (BLP) conﬁdentiality security model provides a basis for us to build a security model for
HMANET [6]. Brieﬂy, the BLP model describes a
secure computer system abstractly, without regard
to the system’s applications. Our hierarchical structure follows a modiﬁed Bell-La Padula conﬁdentiality security policy model to accommodate a
distributed hierarchical environment; in this model,
the key derivation relation is downward in which
the higher-level group members can decrypt the
lower-levels’ ciphertext. We address applicability
of the BLP model from its abstract form to the
secure group key management framework in an
HMANET environment.
1.1. Related work
Several secure group communication key management schemes have been presented in the past
decade. The previous work can be broadly classiﬁed
into distributed schemes and centralized schemes
[7]. The most well-known distributed scheme is the
Group Diﬃe–Hellman (GDH) method [8–10]. This
approach requires a linear number of expensive
public-key operations, while there have been eﬀorts
to reduce the number of public-key operations
[8,11]. However, due to the computational overhead
imposed by public-key operations, each user needs
to negotiate with its communication peers to maintain the communication group. In general, this class
of schemes is not suitable for delay sensitive and
real-time interactive applications.

562

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

Centralized secure group communication keying
schemes (which are all non-public key solutions)
have been approached by two diﬀerent research
communities: one from the information theory community, and the other from the Internet community.
In the approach that stems from the information
theory community, the Key Pre-distribution Scheme
(KPS) plays a critical role [12,13]. KPS requires a
trust authority to distribute secret information
before group communication; then during group
communication, only privileged subsets (pre-speciﬁed) of participants are able to compute certain
keys. For instance, the Broadcast Encryption
Scheme (BES) [14] consists of a key pre-distribution
phase, followed by a broadcast message which is to
be decrypted only by a privileged subset (pre-speciﬁed) of participants. In the approach that stems
from the Internet community, the Framework Oriented Schemes (FOS) [15–18] is a popular scheme,
which uses hierarchical group relations to set up
group keys. FOS can be either a single ﬂat group
under one management center or multi-level groups
with multiple group management centers. For
instance, the Key Oriented Schemes (KOS) use
key derivation relations to build up the keying
scheme. Group members use their secrets to generate the desired group key (see [19–22]). Centralized
scheme requires the key server to be always online
to maintain the group changes. In our previous
work, we have shown that the group management
overhead is prohibitively high if the group member
join or leave during the communication phase is frequent [23].
Approaches such as key pre-distribution and
pairwise key establishment schemes (e.g., [24,25])
have been proposed in recent years for sensor
networks. A set of secrets are pre-installed in each
sensor before deployment. After they are deployed,
each sensor can set up pairwise keys with its neighboring nodes. Although the key distribution mechanism is somewhat similar to our approach, the goal
is diﬀerent. We target to set up all possible subgroup
keys instead of pairwise keys such that during the
communication phase there is no key veriﬁcation
cost – a desirable property for real-time interactive
applications.
Basagni et al [26] proposed a shared key based
solution for key management in large scale ad hoc
networks. Their approach assumes that each mobile
node is a good node and behaves properly. By combining mobility-adaptive clustering and an eﬀective
probabilistic selection of the key-generating node,

a shared key is periodically updated among all
mobile nodes.
Rhee et al. [27] have presented a secure group key
management architecture in HMANET environment. They create two levels of groups: a cell group
located at the bottom of the hierarchy uses centralized group key management, and a control group
located on top of cell groups uses distributed group
key management. In each cell group, the group key
management is managed by the group manager,
which is not suitable for frequent subgroup formation/deletion and delay sensitive applications. In
addition, the group member migration will invoke
heave public-key operations.
In current research literature, there are no security models for the HMANET. In a hierarchical
structure, the Bell-La Padula (BLP) security model
[28,29] is a possible choice. However, the BLP
security model was originally designed for computer
systems, not distributed hierarchical networks.
Although, the BLP model has been extended to traditional multi-level secure message systems [30], its
suitability to the HMANET has not be addressed
so far.
1.2. Contributions
Our work focuses on the following directions in a
HMANET framework: (1) we present a multi-level
security model, (2) we have developed a hierarchical
secure group keying scheme to decentralize the
group key management overhead to multiple group
managers, and (3) we present an inter-group roaming protocol for inter-group key management to
improve the survivability when group managers fail
or members from one group roam in another group.
Speciﬁcally, we present a unique solution by integrating the group keying and group management
within a hierarchical networking framework that
allows scalability of group key management.
We also discuss how our approach is applicable
to the BLP conﬁdentiality security model. In each
group, the group keying scheme follows the same
group formation structure. As a result, the group
keying scheme can be applied to every group in
the multi-level hierarchical group structure. A
second advantage is that due to the decentralized
group management structure in HMANET, our
approach is resilient to any single point failure problem. In addition, our roaming protocol is able to
provide secure group communication for group
members in diﬀerent groups and it is able to provide

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

continuous group communication when a group
manager fails. We present performance assessment
of our scheme to support our claims.
1.3. Organization
The rest of the paper is organized as follows: in
Section 2.1, the HMANET architecture is presented
along with the security model and the attack model.
In Section 3, the hierarchical group key management keying scheme and the roaming protocol are
described in details. The performance issues are
given in Section 4. Finally, we summarize our work
in Section 5.
2. HMANET: architecture, security model, and
attack model
2.1. Overall architecture
We ﬁrst describe the hierarchical mobile ad-hoc
network architecture. It consists of three levels: root
level, mobile backbone network level, and mobile
user network level; in each level, there can be multiple nodes. Thus, we can envision a root network
followed by multiple mobile backbone networks
(MBNs), which is associated with a node in the root
network; in turn, a mobile user network (MUN) is
associated with each MBN node. For example,
MBNs can be based on unmanned ariel vehicles
(UAVs). The general architecture is depicted in
Fig. 1. In order to identify the entities and group
structure of the HMANET, we use a dot notation.
A dot separates two neighboring levels, the higherlevel on the left and the lower-level on the right. A
notation always starts from the root level. For
example, as shown in Fig. 1, we use n(i) = n1 Æ n2 Æ i
to represent an MUN node in a three-level hierarchy, where n = n1 Æ n2 can be used to identify the
group where the node i locates.
Root level. At the top of the hierarchy, a root
node is associated with an MBN. The root node
can provide the shared beam to its MBN nodes to
maintain connectivity for one area of operations
in lower levels. In Fig. 1, the root node group is represented as G(*); a root node has the highest computation and communication power among all mobile
nodes in the system; we assume that the root node
cannot be easily compromised. Due to the highest
security level of root level nodes, encrypted messages sent from lower-level nodes can be decrypted
by the root level nodes, and messages encrypted

563

and sent by a root level node cannot be decrypted
by lower-level nodes. In our multi-level security
model, which is discussed later, designated nodes
at each level are assumed to be trusted entities at
their levels.
MBN level. Multiple MBN nodes form a control
group. We assume that MBN nodes have more
communication and computation power than
MUN nodes. Each MBN node can set up a direct
wireless link with the root level nodes. Multiple
MUN nodes and at least one MBN node form a cell
group in the hierarchical group structure where the
MBN node acts as the group manager for a set of
MUN nodes. In Fig. 1, the control group is represented as G(n), where n is the group number.
MUN level. MUN nodes are mobile devices that
have limited computation and communication capabilities. The communication among MUN nodes
can be set up directly if they are located within each
other’s communication range. If an MUN node
cannot set up the wireless links directly to its group
members, it can set up multihop wireless connections via its group manager.
It may be noted that a member of an MUN
might move or travel to another MUN or MBN.
This member must be able to still communicate with
its subgroup in its native network on a real-time
basis without authenticating every time. Thus, an
inter-group secure group management scheme is
necessary that allows the roaming capability.
2.2. HMANET security model
An important issue for the HMANET is the
security model. This, in turn, is related the secure
group communication. In this section, we present
the security model that extends Bell-La Padula security model for HMANET. We further describe how
security is enforced. We then present the attack
model that can be addressed by our secure group
scheme, followed by how roaming is architected.
2.2.1. Multi-level security policies
In the hierarchical structure presented in Fig. 2.1 ,
the key derivation relation is downward and thus the
higher-level group members can decrypt the lowerlevels’ ciphertext. We deﬁne subjects as mobile users
and objects as data (or messages). Compared to
multi-level security model [28], we map the rights
decrypt to read, encrypt to write, and key generate
(for group members) to execute. We can deﬁne the
dom (dominates) as follows:

564

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

Root node
Mobile Backbone Network
1
(MBN) node
Mobile User Network
(MUN) Node

G(*)

G(1)
1.3

1.1

2

Root
Level

G(2)
2.2
2.3

MBN
Level

1.2
2.1

G(1.3)
G(1.1)
1.3.1 1.3
1.1
1.1.3 G(1.2)
1.1.1
1.3.2 1.3.3
1.2.1
1.1.2
1.2
1.2.2
Area 1

G(2.2)
2.2.2
G(2.1)
2.1.1 2.1

G(2.3)
2.3.1 2.3

2.2 2.2.3

MUN
Level

2.3.2 2.3.3

2.1.3
2.1.2

Area 2

Fig. 1. Group architecture of hierarchical ad-hoc networks.

Deﬁnition 1
1. The security level (L(ui), P(i)) dominates the security level (L(uj), P(j)) if and only if L(uj) 6 L(ui)
and P(i) ) P(j).
2. The security level (L(ui),P(i)) dominates the security level (L(C),K) if and only if L(C) 6 L(ui) and
P(i) ) K.
In the Deﬁnition 1-(1), security levels of ui and uj
can be represented by dot notations n(i) and n(j),
respectively; we deﬁne n(i) dom n(j) if and only if
n(i)  n(j) (e.g., n(i) = n1 Æ n2 and n(j) = n1 Æ n2 Æ n3).
P(i) ) P(j) represents that the user ui can generate
P(j) from his/her pre-installed secrets set P(i). The
dot notation is deﬁned similar to the compartment
or categorization of a subject or an object in BLP
model. In the Deﬁnition 1-(2), L(ui) is the ciphertext
receiver’s group level (is represented as the dot notation n(i)); L(C) is the encryption level of the ciphertext by using the set of keys K; P(i) ) K represents
that the user ui can derive at least one key in K from
his/her preinstalled secrets set P(i), where the C is
encrypted by the keys 2 K.
The least upper bound (LUB) of the HMANET
is the root node (denoted by u0) of the hierarchical
structure, i.e., (L(u0),P(0)) dominates (L(ui), P(i))

and (L(C), K) for any user ui, ciphertext C, and
key set K. Due to the decentralized hierarchical
structure of HMANET, the greatest lower bound
(GLB) does not have meaning when two users are
located in diﬀerent groups. This is because they cannot derive a shared key without the help by each
other’s group manager to decrypt a ciphertext.
Within a group, the GLB is the ciphertext encrypted
by the group key (L(C),K(G)), where G is the group
and "ui 2 G, (L(ui),P(i)) dominates the security level
(L(C),K(G)).
The Deﬁnition 1-(1) of dom tells us if a user dom
another group member, he/she must be able to
derive all the secrets possessed by that group member; the Deﬁnition 1-(2) of dom tells us if a user dom
a ciphertext, he/she must be able to derive at least
one encryption key used to encrypt the ciphertext.
Then, we can have the following simple security
conditions:
• Simple security conditions:
1. ui can decrypt ciphertext C if and only if ui dom C
and ui has discretionary decrypt access to C.
2. ui can distribute secrets set P(j) to uj if and only if
ui dom uj and ui has discretionary key distribute
access to P(j).

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

Based on the above described hierarchical
encryption policy, it is easy to see that the trust relations of the security model are from the bottom level
to the top level. As shown in Fig. 2.1, the root level
nodes are the group managers of control groups.
They are responsible for distributing keys to MBN
nodes in the MBN level and they can also derive
the group/subgroup keys used in the MUN level.
An MBN node is the group manager of a cell group,
it is responsible for distributing keys to MUN nodes
in its cell group. A group manager hosts a cluster
rooted by itself, however it cannot derive secrets
used in other clusters. This means that any group
member dominates the lower-level group members
within the same cluster. For example, as shown in
Fig. 1, node 1 creates a cluster rooted from itself.
Node 1 can derive keys used in groups G(1),
G(1.1), G(1.2), and G(1.3), but it cannot derive keys
used in groups G(2), G(2.1), G(2.2), and
G(2.3).Compared to the write policy of BLP security
model [29], we deﬁne the following property to prevent a higher-level from encrypting and sending
data to a lower-level.
• *-Property (Star Property): ui can encrypt plaintext T by using P(i) ) K if and only if
L(ui) 6 L(T) and P(j) ; K when L(P(j)) <
L(P(i)), and ui has discretionary encrypt access
to T.

565

message to node 1.2.1, the encrypted message (using
the same level group key) must be checked by the
group manager 1.2 for sanitization, and then 1.2
re-encrypts the message using the same level group
key and sends it to 1.2.1. Due to the cluster structure,
1.1 cannot derive the shared key used by node 1.2.1.
There are two situations in which the right to
encrypt is possible following the star property:
(a) If L(ui) = L(T), ui can use any subgroup key to
encrypt the message T within the same security
level.
(b) If L(ui) < L(T), ui must use key k i0 to encrypt
the message T.
Here, key k i0 is the ith initial key element to derive a
sequence secrets (see Section 3.1 for the construction of group keys); it can be derived only by the
group manager (i.e., the trust entity), the group
manager can use a higher-level key to re-encrypt
the message. In this way, we can allow a lower-level
group member to encrypt the message at a higherlevel. Note that in an HMANET environment, the
message originator must specify the security level
of the message. This can be achieved by specifying
the destination node id n(i), where the group number n is the security level (i.e., the group id) of the
destination node ui.
2.3. Attack model

2.2.2. Security enforcements
Our multi-level security model is composed of
multiple clusters rooted by each root level nodes.
The clustering structure regulates the key derivative
relations following the hierarchical framework of an
HMANET. To enforce the simple security conditions, due to the hierarchical key derivative relations, our secure keying scheme allows a higherlevel node ui to decrypt the ciphertext C sent from
a lower-level node uj when (L(ui), P(i))dom(L(C),K)
and (L(ui),P(i))dom (L(uj), P(j)). The dominating
scope of the node ui is the cluster structure rooted
from ui (see Fig. 2.1).
The star property mentioned earlier prevents the
higher-level group members to encrypt data using
lower-level group keys. We solve this problem by
introducing trusted entities (i.e., the group managers
or leaders). Thus, to enable a higher-level group
member to encrypt down, we rely on the group manager who distributes keys to his/her immediate
lower-level group members. For example, as shown
in Fig. 2.1, if node 1.1 wants to send an encrypted

We next consider the attack model for which we
assume the following: (1) lower-level group members are more prone to be captured than higher
group members; (2) the higher-level communication
equipment are tamper-proof devices. The adversaries cannot easily derive the set of secrets preinstalled in the devices. Thus, the adversaries can
be either compromised devices at the lower-levels
or malicious higher-level members. The goal of the
adversaries is to breach the security model presented
in Section 2.2.
For intra-group key management, the adversaries can share their pre-distributed keys and try to
compromise the group keys used by other subgroups that do not include the adversaries. We refer
to this attack as a colluding attack. To counter a
colluding attack, the deployed intra-group keying
scheme should provide the security feature such that
a collection of compromised nodes will gain zero
information on uncompromised keys used by
other subgroups. Such a non-colluding property is

566

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577
G(1)

G(1)
1.1

1.1

1.3

1.3
1.2

1.2

G(1.3)

G(1.3)
G(1.1)

1.3.1

G(1.1)

1.3

1.1.3
1.1.1

1.1

1.1.1

1.1

G(1.2)

1.3

1.3.2

G(1.2)

1.3.3
1.3.2

1.1.2

1.3.1

1.1.3

1.3.3
1.1.2

1.2.1

1.2.1

1.2.2

1.2.2
1.2

1.2

Area 1

Area 1
Scenario 1: node 1.2.1 is moving
out the the communication range
of cell group G(1.2). New path:
1.2.1--1.1--1.2--1.2.2

Scenario 2: MBN node 1.2 stops
working. New path:
1.2.1--1.1--1.3--1.3.2--1.2.2

Fig. 2. Roaming among groups.

achieved through our previous solutions proposed
in [23].
For inter-group key management, the attacks are
HMANET routing attacks [31]. For example, the
adversaries can: (i) spoof, alter, or replay messages,
(ii) selectively forward messages, (iii) deploy Sinkhole and Wormhole attacks, (iv) deploy Sybil
attacks, etc. In our attack model, these attacks
aim to compromise our security model and they
can be classiﬁed into three types: DoS attacks, message disclosure attacks, and session-hijacking
attacks. Our group key management scheme and
roaming protocol are vulnerable to DoS attacks.
Additional security framework to counter the DoS
attacks should be deployed, which is not our
research focus in this paper. To prevent the message
from being disclosed and prevent session-hijacking
attacks, end-to-end encryption and authentication
must be provided.
2.4. Roaming among groups
In HMANET, a ﬂat group is originally assigned
to a group member as the group member’s home
group; then, others are host groups (or roaming
groups). A mobile node may move out of the communication ranges from its home group members;
the group manager of a group may fail due to software or hardware failure. In these scenarios, roaming protocols are used to maintain the connections

among group members. For example, as shown in
Fig. 2 scenario 1, node 1.2.1 moves out of the communication range of cell group G(1.2) and it is
within the communication range of cell group
G(1.1). Mobile node 1.2.1 needs to set up secure tunnels to its home group G(1.2) via MBN node 1.1.
One possible secure tunnel is 1.2.1–1.1–1.2–1.2.2.
In scenario 2, if MBN node 1.2 fails and group
members cannot set up direct wireless links, a secure
tunnel 1.2.1–1.1–1.3-1.3.2-1.2.2 can be set up.
In order to support secure and seamless roaming
that involves minimal connection setup delay, a
roaming node is required to set up a secure key with
roaming group members before the roaming begins.
This requires the MBN nodes to maintain the network topology formed by control group nodes in
realtime. To this end, we can use topology-aware
ad-hoc routing protocols, such as TBRPF [32] or
protocols based on positioning system enabled
devices (e.g., GPS devices), such as [33]. Based on
the topology information of MBN nodes in the system, each MBN node maintains a topology graph
formed by all MBN nodes and a neighbor list of
the topology graph; e.g., Fig. 3 shows that the
neighbor list of node 1.5 is {1.3, 1.4, 1.7, 1.8}. To
support roaming among groups, each cell group
G(m Æ n) maintains a roaming key denoted by
kvjG(m Æ n). Due to the multi-level security model,
we require the end-to-end encryption during roaming; the intermediate nodes can only help the roam-

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

1.6
1.1
1.10

1.4
1.7
1.5

1.9
1.2

1.8
1.3

Fig. 3. Network topology of control group and neighbor list.

ing nodes to set up security tunnels to their home
group. Hence, a roaming key is only used to prevent
outsiders from disclosing the transferred ciphertexts. A group manager (MBN node) exchanges its
cell group roaming keys with other group managers
in its neighbor list. When a group manager receives
a neighbor group’s roaming key, it distributes the
neighbor group roaming key to its cell group members. Thus, when a host group’s member moves to a
neighboring group, it can use the roaming key to set
up secure connections with its host group members.
In this way, we can use this proactive key agreement
method to reduce the key establishment time due to
roaming by group members.
3. Secure group key management for HMANET
In this section, we present our secure group key
management scheme for HMANET. This approach
is built on our previous keying scheme for a ﬂat
architecture [23]. Brieﬂy, our extended scheme is a
multi-level, multi-group keying structure. In this
scheme, each group member maintains the same
number of pre-installed keys and each group member can serve as the group manager for a lower-level
group. We present two roaming protocols to solve
the roaming issues in a hierarchical secure multigroup communication environment. We ﬁrst brieﬂy
summarize a few details of the keying scheme for a
ﬂat architecture [23] that is relevant for the describing the proposed new scheme for HMANET.

567

to set up secure group/subgroup communication
services, without having the group key establishment for each instantiation of a communication –
thus, the scheme is suitable for real-time services,
saving on setup delay. The scheme is based on two
phases: a centralized key pre-distribution phase
and a distributed group communication phase. In
the key predistribution phase, a key distribute center (KDC) distributes the keys (or secrets) and index
hkey ID, user IDi to each group member, for example, via oﬄine methods. During the group communication phase, a group member can derive subgroup
communication keys from its predistributed keys
without relying on KDC without incurring setup
delay.
In order to reduce the storage overhead of a
member, we build a key-forest structure via multiple
key chains. Each ‘‘tree’’ (a linear key chain) in the
key-forest structure represents a particular key
derivative relations among all group members. A
one-way function is used to construct a one-way
function chain, and subsequently, to form a key
chain. A one-way function chain (OFC) is a sequence
of values with linear derivation relations among
them, see Fig. 4. For example, we use gj(Æ) to denote
using g(Æ) on a message j times, i.e., gj(Æ) can derive
gr(Æ) when j < r.
Now set k i0 ¼ M i to represent the ith initial key
element to derive a sequence of secrets. For brevity,
we do not diﬀerentiate a secret and the corresponding key. A key is represented as k ij ¼ f ðgj ðM i ÞÞ and
f is a publicly known key generating function. Thus
based on the derivative relations of an OFC, we
have the following key derivate relations (i.e., a
key chain):
k i0 ! k i1    ! k ij !    ! k ir ;

where 1 < j < r:
ð1Þ

3.1. Secure group keying scheme for a ﬂat
architecture: An overview
This scheme is for a single group with a stable
population where a subset of group members want

Fig. 4. An example of one-way function chain.

568

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

The derivative relation of a key chain is from the
head (k i0 ) to the tail (k ir ) where ij can uniquely identify a subgroup composition. A keying example is
shown in Fig. 4, which is composed of 6 keys
(r = 5). If we allocate a key to each group member
from uc to uc+5, each group member can derive its
lower-level keys. Then 6 subgroups can be formed
via the key chain, denoted by Si0 to Si5 . Note that
these subgroups are non-colluding subgroups, in
which a subset of members cannot collude to derive
the keys used by a given subgroup unless at least
one of colluding members belongs to that subgroup.
It can be shown that if there are n group members,
we can systematically distribute a unique subset of
key elements from nðn1Þ
key chains. Using the pre2
distributed key elements, each group member can
derive a subset of keys (denoted as set K) to cover
all possible subgroup compositions. On average,
the size of K is in the order of a sub-linear function
of the subgroup size [23].
We utilize the following abstract presentations
for group keying relations. We deﬁne a user’s identiﬁer as ui = n(i), where n(i) is the dot notation of the
group member identiﬁer, 1 6 i 6 G and G = jG(n)j
is the ﬂat group size (we use ﬂat group and group
interchangeably). The group member ui holds a set
of predistributed secrets represented as P(i). For a
subgroup key, we present the following deﬁnition:
Deﬁnition 2. The set of subgroup keys shared
between user ui and the subgroup members in S =
{u1, . . . ,us}, where jSj P 2 and ui 2 S, is represented
as K(n(i), S) = {kj"j, {P(i) ! k} \ {P(j) ! k} 5 ;,
j 5 i, and n(j) 2 S}.

where ij is a key identiﬁer, see (1), and ks is a session
key. After receiving the message, a receiver ﬁrst
checks the list {ijj"j 2 Snj} to see if he/she belongs
to the subgroup. If he/she is involved in the subgroup, the receiver can derive a proper subgroup
key to decrypt the session key and then decrypt
the message.
We next discuss suitability of this scheme for
group key management. Subgroup formation and
deletion are the main group management operations. For example, as shown in Fig. 5, the directed
arrow at the lower portion of the ﬁgure represents
the subgroup key derivative relations using the
one-way function. This approach has two primary
beneﬁts. First, a group member can generate the
group/subgroup keys without the help from its
group manager. Thus, once the key sets are distributed, the group/subgroup key negotiation is unnecessary. This feature is crucial for delay sensitive
applications that require minimal group key setup
delay. Second, the group key revocation is simple
and no additional group management overhead is
required. This is because revoking a group member is equivalent to generating a diﬀerent subgroup
key.
3.2. Multi-level multi-group secure group keying
scheme
We are now ready to describe our extended
scheme. First, note that a hierarchical group keying

Note that the set of shared keys can be derived
from both P(i) and each secret set in
{P(1), . . . , P(s)}nP(i). In particular, K(n(i), S) represents the minimum number of keys that can be
derived by ui to cover all subgroup members in S.
During the secure group communication phase, a
session key ks is used to encrypt data and
KðnðiÞ; SÞ ¼ fk ij g are used as key-encrypting key
(KEK) to fulﬁl desired subgroup composition where
ij is used to identify the key element location in a key
chain, see (1). In this way, n, i, and set {ijj"j 2 Snj}
can uniquely identify a subgroup composition and
the corresponding subgroup keys. Using the
encrypting function E(Æ), we can encrypt data as
follows:
h½fij j8j 2 S n jg; Ekij ðk s Þ; Eks ðDataÞi;

ð2Þ

Fig. 5. An example of key distribution for three group members
within a ﬂat group.

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

structure can be built using a one-way function. The
relation among diﬀerent levels in the structure is in a
top-down fashion. We utilize the derivative relations of one-way function chains to build the hierarchical structure. In this way, the size of the preinstalled key set for each node in the HMANET
remains the same.
In order to explain our new scheme, we ﬁrst present a simple example to illustrate the group key
distribution scheme for a 3-member ﬂat group composed of u1, u2, and u3 (see Fig. 5). In this example,
three keys are distributed to each group member
from three diﬀerent key chains. Any two of the
group members can derive corresponding 2-member
subgroup keys without the colluding problem, as
described in [23].
In an HMANET, each mobile node can create its
own cluster and serves as a group manager for a
lower-level group. The mobile node uses its predistributed secrets (or keys) to generate lower-level
group members’ secrets (or keys). Before generating
a key set for a lower group member, the group manager needs to regenerate its key set. We accomplish
this step using a shuﬄe algorithm, which is presented as Algorithm 1. Using the shuﬄe algorithm,
the key distribution as shown in Fig. 5 for ﬂat architecture is essentially shuﬄed.
Algorithm 1 (Shuffle algorithm).
Input: for group manager ui,
fkgui ¼ fk1 ; . . . ; k i0 ; . . . ; kn g, where 1 6 i 6 n.
Output: fk 0 gui ¼ fk 010 ; . . . ; k 0i0 ; . . . ; k 0n0 g
1 : Begin
2: j = 1;
3 Loop k 0j0 ¼ gðk i0 ; kj Þ;
4 if (j = = n) goto End;
5 j = j + 1;
6 goto Loop;
7 End
*Note: the subscript in k represents the position
j
in key set fkgui possessed by user ui; it is not used to
identify the key chain position described in (1). h
After shuﬄing the original key set fkgui , the
group manager ui derives a new key set fk 0 gui . For
example, before shuﬄing, u1’s original key set is
fkgu1 ¼ fk 10 ; k 21 ; k 32 g. After shuﬄing, u1 has the
key set fk 0 gu1 ¼ fgðk 10 ; k 10 Þ; gðk 10 ; k 21 Þ; gðk 10 ; k 32 Þg,
as shown in Fig. 6, where g is a publicly known
one-way function. Within the home group, k 10 is
unique for u1 and we call k 10 as the key seed of u1.
In this way, the group manager u1 still uses the

569

Fig. 6. An example of multi-level group key distribution for three
group members. The lower-level groups managed by u2 and u3 are
omitted.

key set fkgu1 to communicate the mobile nodes (u2
and u3) within its home group, while it uses the
key set fk 0 gu1 to generate the key sets for its controlled group members fu01 ; u02 ; u03 g in the lower-level.
Thus, lower-level group members can only collude
to derive the key set fk 0 gui but not the key set
fkgui . It may be noted that the changes of keys in
a group manager’s key set fkgui aﬀects only a limited number of keys. For example, if the key set possessed by u3 is compromised by attackers, they
cannot derive the key k 030 . This is because only u1
knows k 10 and the function gðk 10 ; k 32 Þ prevents
attackers from deriving the key k 030 .
There are three important properties of the shufﬂing algorithm: (1) the shuﬄe algorithm prevents
group members from deriving group manager’s
keys, (2) shuﬄing the group manager’s key set can
present ‘‘1 aﬀects n’’ problem, i.e., it avoids requiring all group members key sets to be changed if
one member’s key set needs to be changed, (3) it
allows to create the clustering hierarchical structure
shown in Fig. 1, which follows the multi-level security model presented later.
Since we want the ability of members of a group
to roam to other groups, and still be able to do
secure group/subgroup communication, it is important that the keying scheme allows that. This
primarily depends on (1) how roaming keys are distributed and (2) how group communication sessions
are set up among host groups and from a host
group to a node’s home group. These are addressed
next.
3.2.1. Distributing roaming keys
The roaming key for group i is represented as k iv .
It has two restrictions: (i) all group members in
group i can derive the key k iv easily; (ii) a roaming
node cannot derive extra key information of group

570

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

i from the roaming key. As shown in the example
presented in Fig. 5, each group member can derive
the group key k i ¼ gðk 12 ; k 22 ; k 32 Þ in group i. We
use one-way function g to generate the roaming
key for the group i: k iv ¼ gðk i Þ. Thus, all group members in group i can derive the roaming key k iv and a
host node cannot derive any group key information
of group i from the roaming key k iv .
3.2.2. Roaming to home group
In Section 2.4, we discussed the scenario where a
mobile node roams among groups. One of the
important research goals is to be able to set up a
shared key between the roaming node and host
group manager with minimal key setup delay (note
that the shared key is only shared between the node,
roaming group manager, and home group manager). The established shared key can be used to
set up secure tunnels from the roaming node to
the home group manager. In order to provide roaming ability for group members, we present a roaming
protocol as summarized in Table 1.
Brieﬂy, in our roaming protocol, time stamps
(N1, N2, and N3) are used to guarantee that the message is new; here function I is an incremental function, e.g., ‘‘add 1’’. In step r, roaming node i
sends a request to host group manager j. Then the
request is forwarded to home group manager l
in step s. After verifying the request, the home
group manager picks session key ks and encrypts
the session key by two pairwise keys: klj is shared
between two group managers and kli is shared
between the roaming node and the home group
manager. The response from the home group manager is sent back to the host group manager in step

t. In step u, the host group manger forwards the
encrypted session key ks to the roaming node. Note
that if a roaming node does not have a direct connection with the host group manager, in step u,
the host group manager needs to distribute session
key ks to its group members that are intermediate
nodes in the setup tunnel. If the host group manager
does not have a direct connection with the home
group manager, the messages in step s and t
should also be encrypted/decrypted by the pairwise
keys on each hop from the source group to the destination group.
3.2.3. Roaming among host groups
In an HMANET, the MBN node may fail. In
order to maintain the group communication, each
MUN node needs to be registered at the host group
manager and depends on the host group to connect
to the rest of its home group members.
As described in Section 2.4, we assume that an
MBN node is running either a topology-aware adhoc routing protocol or a positioning system
enabled device. Each MBN node knows the network topology at the MBN level. When an MBN
node fails, the rest of the MBN nodes will notice
it immediately and they are ready to accept the
requests from MUN nodes in the failure group.
When an MUN node approaches a host group, it
sends a request to the host group manager. The
request is protected via the host group’s roaming
key previously distributed via the MUN node’s
home group manager. After a roaming node sets
up a secure channel to the host group manager,
the host group manager propagates the MUN
node’s information to other MBN nodes. After all

Table 1
Roaming protocol between roaming node and its home group manager

N1,N2,N3: time stamps; node#: node id; i,j,l: group id; ks: session key.
f(): incremental function; E(): encryption algorithm; kil = kli, kjl = klj.
k jv : roaming key of group j.

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

MUN nodes have established secure channels in
their host groups, each host group manager creates
a reachable member list based on the information
received from other MBN nodes and then forwards
the list to the MUN nodes in its group.
When a roaming node wants to communicate to
a subgroup of its home group members, it creates
the message based on the encryption message presented in (2) and sends the message to the host
group manager by encrypting the whole message
via the group roaming key.
Home group members may be located within
multiple host groups. In order to forward the
message to proper host group managers, a communication eﬃcient multicast roaming protocol is
required. We present a multicast roaming protocol
based on Prüfer sequence [5]. Using Prüfer
sequence, we can signiﬁcantly reduce the multicast
roaming protocol’s complexities in terms of both
communication overhead and operational overhead
[33].
A high-level description of the multicast roaming
protocol is as follows:
i. A roaming node uses derived subgroup/group
key to encrypt the message.
ii. The roaming node encrypts the message
again by using the group’s roaming key.
Together with the desired group member list,
the messages are sent to the host group
manager.
iii. The host group manager decrypts the message
by using the group’s roaming key. Based on
the desired group member list, the host group
manager creates a multicast packet by using
Prüfer encoding algorithm to generate a Prüfer sequence; the derived Prüfer sequence is
set in the multicast packet header; and then
the multicast packet is sent out.
iv. Based on the received Prüfer sequence and
Prüfer decoding algorithm, an MBN node
makes decisions to drop or forward the multicasting message. If the MBN node is one of
destination nodes, it forwards the packet to
the corresponding receivers.
v. The receiver uses the corresponding subgroup/group key to decrypt the encrypted
message.
Prüfer encoding/decoding algorithms
The Prüfer encoding/decoding algorithms are as
follows:

571

Algorithm 2 (Prüfer encoding algorithm). Let (i,j)
represents the edge between node i and j. The
corresponding Prüfer sequence P of a tree T can be
obtained by the following steps:
i. Let node i be the lowest labeled leaf node of T
and j be the node incident to i; append j to the
end of P from left to right.
ii. Remove node i and edge (i,j) from T;
iii. Go back to step 1 until one edge is left.
Algorithm 3 (Prüfer decoding algorithm). For a
Prüfer sequence P and a set P 0 of eligible node labels
not included in P, a unique tree T can be obtained
by the following steps:
i. Let i be the lowest integer of P 0 and j be the
left-most integer of P. Add edge (i,j) into T.
Remove i from P 0 and j from P. If j does not
occur elsewhere in P, put it into P 0 .
ii. Repeat step 1 until no element is left in P.
iii. Now that there are exactly two nodes r and s
left in P 0 , add edge (r,s) into T.
The Prüfer encoding/decoding schemes are used
when a node wants to communicate to multiple
receivers in diﬀerent groups, which is equivalent to
multicasting a message to multiple receivers over a
multihop network. Since an HMANET has no ﬁxed
routers, all nodes are moveable and can be connected dynamically in an arbitrary manner. We
assume that the cost of each link in the HMANET
is assumed to be 1. We adopt Prim’s algorithm to
compute a minimum cost multicast tree, known
commonly as the Steiner tree.
Earlier in the example shown in Fig. 3, we
assumed that MBN node 1.1 receives a packet
for multicasting securely to multicast group
MG = {1.1, 1.2, 1.5, 1.7, 1.8}. Fig. 7 shows the network topology graph computed by node 1.1 when
it receives the packet for multicasting. Source node
1.1 derives a Steiner tree with 6 nodes. Note that
the node 1.4 is not a message receiver but it is in
the Steiner tree. Thus, we use gray color to represent
node 1.4.
To illustrate the Prüfer encoding algorithm,, we
note that node 1.2 is the lowest labeled leaf node
and node 1.1 connects to node 1.2. Using the Prüfer
encoding algorithm, node 1.1 becomes the ﬁrst element of P and edge (1.2, 1.1) is removed from the
graph. Next node 1.1 is the lowest leaf node with

572

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

1.1

1.2

1.4

1.5
1.7

1.8

Fig. 7. A Steiner tree for multicast group, rooted at MBN node
1.1.

node 1.4 connecting to it. Append node 1.4 to P and
remove node 1.1 and edge (1.1,1.4). Repeat this
process until only edge (1.5, 1.8) is left and Prüfer sequence P = (1.1, 1.4, 1.5, 1.5) is obtained
(P 0 = (1.2, 1.7, 1.8) and P 0 is the set of nodes in
MG but not in P). Thus, node 1.1 encodes the multicast tree with 6 nodes as the Prüfer sequence
(1.1, 1.4, 1.5, 1.5) of length 4. Prüfer sequence P
and its complement P 0 are put in the multicast
packet header. When an MBN node receives the
multicast packet, it ﬁrst decrypts the Prüfer
sequence by using Prüfer decoding algorithm. 1.2
is the smallest number in P 0 and 1.1 is the leftmost
number in P. We do the following: adding edge
(1.1, 1.2) to the tree, removing 1.2 from P 0 , and
moving the leftmost integer 1.1 from P to P 0 since
1.1 is no long exists in P. Thus, we can derive
P = (1.4, 1.5, 1.5) and P 0 = (1.1, 1.7, 1.8). Next, 1.1
becomes the smallest node in P 0 and 1.4 is the leftmost node in P. We do the following: adding edge
(1.1, 1.4) in tree, removing node 1.1 from P 0 , and
moving 1.4 from P to P 0 . In the third step, edge
(1.4, 1.5) is added to the tree and node 1.4 is
removed from P 0 . Finally, edge (1.5, 1.7) is added
to the tree and only 1.5 and 1.8 are left in the P 0 .
We then add the edge (1.5, 1.8) in the tree. In this
way, we can reconstruct the Steiner tree shown in
Fig. 7.
After reconstructing the Steiner tree, the MBN
does the following:

ii. If it neither belongs to the multicast group nor
is in the Prüfer sequence, it simply discards the
packet (e.g., node 1.3).
iii. If it is not in the multicast group but in the
Prüfer sequence, it realizes it is an interior
node of the multicast tree, and it just forwards
the packet (e.g., node 1.4).
iv. If it is in the multicast group and Prüfer
sequence, it realizes it is an interior node of
the multicast tree, and it receives the packet
and forwards the packet (e.g., node 1.5).
Using Algorithm 4, only the MBN nodes in the
Steiner tree will forward the received packets to
the next hop. Thus, by using Prüfer sequence, the
communication overhead for group communications is reduced.
4. Performance assessments
We present performance assessments from two
perspectives: group key management (i.e., storage
requirements, the communication overhead of
group key management, and the complexity of
group and subgroup key derivation) and the roaming protocol.
4.1. Performance assessments of group key
management
We assume that the height of a hierarchical
group structure is h and each group has the same
size n. In an HMANET network structure, there
are two extreme cases (see Fig. 8):
i. each group only has one immediate lowerlevel group; and
ii. each group member has one immediate lowerlevel group.
In general, these two cases address the lower
bound and upper bound of the corresponding performance metrics. Our following discussion is based
on these two cases.

Algorithm 4 (Prüfer sequence routing).
i. If it is not in the sequence and belongs to the
multicast group and it is a leaf node of the
Steiner tree, it receives the packet, but does
not forward it any further (e.g., node 1.2,
1.7, and 1.8).

4.1.1. Storage requirements
The biggest gain of our hierarchical group keying
scheme is the reduction of the storage overhead
since the storage requirements of our hierarchical
group keying structure is independent of the size
of the overall HMANET. For example, if the

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

n

group members increases exponentially, while the
number of predistributed keys for each group member remains the same. Using two cases stated earlier,
we derive the following Lemma:

n
n

n

n

h

n

n

Lemma 1. When each group has only one immediate
lower-level group, the number of supported group
members is N = n Æ h; when each group member has
one immediate lower-level group, h the number of
1Þ
supported group members is N ¼ nðnn1
.

n
Extreme 2

Extreme 1

573

Fig. 8. Group hierarchical structures: two extreme cases.

number of keys possessed by each group member is
determined by the size of its home group, i.e., a ﬂat
group, the storage requirements of the home group
with n members is n(n  1)/2 keys for both group
manager and group members, see [23]. Fig. 9 shows
the comparison of the group key size using 56 bits,
128 bits, and 160 bits. It provides a guideline to
determine the group size under certain memory
and key size restrictions. For example, if the storage
is limited to 600 KB, then a group size of n = 419
can be easily fulﬁlled with a 56 bits key size, but
can only support a group size of n = 248 if the key
size is increased to 160 bits.
If we increase the number of levels of a hierarchical group structure, the total number of supported

Proof 1. In the ﬁrst case, the total number of supported group members in each group is n. If the
height of an HMANET is h, the total number of
supported group members is N = n Æ h. In the second case, at the level h = 1, we have n1 = n group
members; at level h, we have nh group members.
Accumulating the number of supported group
members in all levels, the number P
of membersh in
h
1Þ
an HMANET framework is N ¼ i¼1 ni ¼ nðnn1
.
Thus,
the
overall
group
size
is
between
n
Æ
h
and
nðnh 1Þ
, where n(n  1)/2 number of keys are preinn1
stalled for each member. h
4.1.2. Communication overhead
To assess communication overhead, we
assume that each group member has the same

1000

(KB)

Key size 160bits
Key size 128bits
Key size 56bits

900

Storage requirements at a member

800

700

600

500

400

300

200

100

0

50

100

150

200

250

300

Number of nodes
Fig. 9. Storage requirements for group members.

350

400

574

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

probability to be selected as a receiver in the
HMANET. For a subgroup size L, we use T(L) to
represent the average number of key messages
involved in each group and Ttot to represent the
average number of total key messages. In [23], we
showed that T(L) can be modeled by the function
a + bL + cLlnL for a ﬂat group, where a,b,c are
constants.
Lemma 2. Assume that a subgroup member is equally
likely with probability p to be a member of any of the
groups and the subgroup size is k. Then,
(1) For the first case: the average communication
overhead Ttot(k) is given by:
!
k
k
X
ki
pi ð1  pÞ T ðiÞ;
T tot ðkÞ ¼ h 
i
i¼0
where p ¼ 1=h:

ð3Þ

(2) For the second case: on the average, the total
number of key messages is
!
h
k
k
X
X
i1
T tot ðkÞ ¼
pi ð1  pÞki T ðiÞ;
n 
i
i¼1
i¼0
where p ¼ 1=

h
X

ni1 :

ð4Þ

i¼1

Proof 2. We assume that each user has the same
probability to be located in each group. The subgroup size is denoted as k. The probability that a user
is located in a group is denoted by p. Then, the probability thatthere
 are i members in a group is
k i
Prðx ¼ iÞ ¼
p ð1  pÞki . Thus, the average
i
number of messages is Pr(i)T(i) when there are i subgroup members. The
Pk expected number of messages
sent to a group is i¼0 PrðiÞT ðiÞ. If the communication system contains m groups, the overallPaverage
k
communication overhead is T tot ðkÞ ¼ m i¼0 PrðiÞ
T ðiÞ for a subgroup communication with size k.
Thus, we can derive
Pthe formulas (3) where m = h
and (4) where m ¼ hi¼1 ni1 in Lemma 2. The worst
scenario is 2T(k) when k subgroup members are
evenly distributed in the HMANET and each group
manager duplicates and disseminates the messages to
its group members. From [23], we know T(k) is a sublinear function of k. Thus, in the worst case, the communication overhead is doubled in the HMANET
compared to the ﬂat group structure. However, the

number of supported group members increases as
O(2h1n) of a full key-tree HMANET where h is
the height of the key-tree and n is the size of a ﬂat
group. Thus the gain is substantial. h
4.1.3. Complexity analysis of the group and
subgroup key derivation
Recall that group and subgroup keys are derived
from group member’s key sets. Before the communication begins, a group member needs to know
every other group member. When a group member
sends an encrypted message, it needs to attach the
key ids along with the encrypted message. Then a
receiver can derive the proper subgroup key to
decrypt the message.
Note that the longest key chain is equal to the
size of the group. If function g is a one-way function
and the subgroup size is k, the maximum required
hash operations for a subgroup member is k  1
and the derivation complexity is O(k). It has been
shown that the generation of a hash chain has the
complexity of O(log2n) (see [34,35]). We assume that
every subgroup is formed with an equal probability
1
; this implies that the probability of forming a
2n 1
ð nÞ
subgroup with size k is 2nk1. The average subgroup
Pn
ðnÞ
size is given by k¼1 k 2nk1. It is easy to show that
the average number of key-derivation operations is
n/2. By using the scheme presented in [34,35], it
can be shown that the average number of hash operations is dlog2 n  1e.
We have conducted benchmark studies of various one-way function algorithms. The benchmark
is computed on an HP iPAQ 4700 pocket PC with
624 MHz Intel processor, and 64MB memory.
Fig. 10 represents the plots for the CPU processing
time utilized by various hashing algorithms along
with the increased size of a subgroup (bottom-up:
MD5-512, SHA-160,256,384,512; the numbers after
MD5 and SHA are the input size – bits). Note that
the benchmark is computed based on the average
number of hash operations dlog2n  1e (a step function). In an HMANET, deriving the corresponding
keys also depends on its height h. We can derive the
following Lemma.
Lemma 3. When each group has one immediate
lower-level group, the average number of key-derivation operations is linearly proportional to the height
of the HMANET, i.e., h = N/n, where h is the height,
N is the total number of mobile users, and n is the size
of a flat group. When each group member has an

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

575

0.0016

0.0014

CPU usage time (seconds)

0.0012

0.001

SHA-512
SHA-384

0.0008

SHA-256
SHA-160
MD5-512

0.0006

0.0004

0.0002

0
0

20

40

60

80

100

Subgroup Size
Fig. 10. CPU usage by hashing algorithms for generating the encryption/decryption keys.

immediate lower-level group, the average number of
key derivative operations is proportional to the height
of the HMANET, i.e., h = log nN.
From this lemma, we can determine that the
number of derivative operations is between
(lognN) Æ D and (N Æ D)/n, where D is the average
number of derivative operations within each group.
4.1.4. Remark
The HMANET structure is targeted to reduce
the storage overhead for each group member. However, with the increases in the number of groups and
the height of the hierarchical structure, the communication overhead and the key derivative complexity
do increase, i.e., a sub-linear function of a subgroup
size. Compared to the storage and communication
overhead, the key derivative complexity is not a
major issue, since the height of an HMANET
increases slowly (in the order of lognN). Thus, there
is a tradeoﬀ in balancing the storage overhead and
the communication overhead.

protocols based on positioning system [33] (i.e.,
using GPS devices) can build network topology.
Each MBN node will compute a multicast tree
(i.e., a minimum cost multicast tree – a Steiner tree)
by using heuristic algorithms such as [36,37].
Once the multicast tree is determined, an MBN
node encodes the tree in a Prüfer sequence. The
derived Prüfer sequence is put in the header of the
multicast packet. Using Prüfer sequence is communication eﬃcient since mobile nodes do not need to
send the whole description of the multicast tree
(e.g., node adjacency matrix). The size of Prüfer
sequence is O(n), where n is the size of multicast
group. It can be proved that the complexities of
Prüfer encoding and decoding algorithms are both
in the order of O(n2). Based on the Prüfer sequence
multicast routing algorithm, the receiver makes a
decision to forward or drop the packets. Since an
MBN node knows all its neighbors, it can select
the next-hop forwarding nodes.
5. Summary

4.2. Performance analysis of roaming protocols
Roaming requires MBN nodes to maintain the
network topology in realtime. Topology-aware
ad-hoc routing protocols, such as TBRPF [32] or

In this paper, we present a secure group key management framework for hierarchical mobile ad-hoc
networks. Our approach considers (1) a security
model, 2) a hierarchical group keying scheme using

576

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577

a key-chain approach, and 3) a roaming protocol
between host groups and home groups. Our framework is suitable for ad-hoc network applications
where the overall group population is stable, the
subgroup communication is frequent and highly
dynamic, and the mobility of a mobile node is not
restricted within its communication range. We propose the ﬁrst solution for hierarchical mobile ad-hoc
networks using a modiﬁed Bell-La Padula model.

[12]

[13]

[14]

Acknowledgement
The authors would also like to thank anonymous
reviewers for their valuable, detailed comments that
improve both the content and representation of this
paper.
References

[15]
[16]

[17]
[18]

[1] A. Iwata, C.-C. Chiang, G. Pei, M. Gerla, T.-W. Chen,
Scalable Routing Strategies for Ad Hoc Wireless Networks,
IEEE Journal on Selected Areas in Communications 17 (8)
(1999) 1369–1379.
[2] G. Pei, M. Gerla, X. Hong, C.-C. Chi, A Wireless Hierarchical Routing Protocol with Group Mobility, in: Proceedings of the IEEE Wireless Communications and Networking
Conference (WCNC), 1999, pp. 1538–1542.
[3] R. Ramanathan, M. Steenstrup, Hierarchically-Organized,
Multihop Mobile Wireless Networks for Quality-of-Service
Support, Mobile Networks and Applications 3 (1) (1998)
101–119.
[4] C.E. Jones, K.M. Sivalingam, P. Agrawal, J.C. Chen, A
Survey of Energy Eﬃcient Network Protocols for Wireless
Networks, Wirel. Netw. 7 (4) (2001) 343–358.
[5] H. Prüfer, Neuer Beweis eines Satzes ueber Permutationen,
Archiv für Mathematik und Physik 27 (1918) 742–744.
[6] M. Bishop, Computer Security: Art and Science, AddisonWesley Professional, 2002.
[7] S. Rafaeli, D. Hutchison, A Survey of Key Management for
Secure Group Communication, ACM Computing Surveys
35 (3) (2003) 309–329.
[8] Y. Kim, A. Perrig, G. Tsudik, Simple and fault-tolerant key
agreement for dynamic collaborative groups, in: Proceedings
of the ACM Conference on Computer and Communications
Security, 2000, pp. 235–244.
[9] G. Ateniese, M. Steiner, G. Tsudik, Authenticated group key
agreement and friends, in: Proceedings of the 5th ACM
conference on Computer and communications security,
ACM Press New York, NY, USA, San Francisco, California, United States, 1998, pp. 17–26.
[10] M. Burmester, Y. Desmedt, Eﬃcient and Secure Conferencekey Distribution, in: Proceedings of the Security Protocols
Workshop, Springer-Verlag, Cambridge, UK, 1996, pp. 119–
129.
[11] J. Alves-Foss, An Eﬃcient Secure Authenticated Group Key
Exchange Algorithm for Large and Dynamic Groups, in:
Proceedings of 23rd National Information Systerms Security
Conference (NISSC), National Institute of Standards and

[19]

[20]

[21]

[22]
[23]

[24]

[25]

[26]

[27]

[28]

Technology, National Computer Security Center, Baltimore,
MD, USA, 2000, pp. 254–266.
R. Blom, An Optimal Class of Symmetric Key Generation
Systems, in: EUROCRYPT’84, Lecture Notes in Computer
Science, Vol. 209, Springer-Verlag, Paris, France, 1985, pp.
335–338.
C. Blundo, A.D. Santis, A. Herzberg, S. Kutten, U. Vaccaro,
M. Yung, Perfectly-Secure Key Distribution for Dynamic
Conferences, Information and Computation 146 (1) (1998)
1–23.
A. Fiat, M. Naor, Broadcast Encryption, in: CRYPTO’93,
Lecture Notes in Computer Science, Vol. 773, SpringerVerlag New York, Inc., Santa Barbara, California, United
States, 1994, pp. 480–491.
T. Ballardie, Scalable Multicast Key Distribution, RFC
1949, 1996. <http://www.ietf.org/rfc/rfc1949.txt>.
L. Gong, N. Shacham, Elements of Trusted Multicasting, in:
Proceedings of the 2nd ACM Conference on Computer and
Communications Security, Fairfax, Virginia, 1994, pp. 176–
183.
H. Harney, C. Muckenhirn, Group Key Management
Protocol (GKMP) Architecture, RFC 2094.
S. Mittra, A Framework for Scalable Secure Multicasting,
in: Proceedings of ACM SIGCOMM, 1997, pp. 277–288.
C.K. Wong, M. Gouda, S.S. Lam, Secure group communications using key graphs, IEEE/ACM Transactions on
Networking 8 (1) (2000) 16–30.
A.T. Sherman, D.A. McGrew, Key Establishment in Large
Dynamic Groups Using One-Way Function Trees, IEEE
Transactions on Software Engineering 29 (5) (2003) 444–
458.
M. Waldvogel, G. Caronni, D. Sun, N. Weiler, B. Plattner,
The VersaKey Framework: Versatile Group Key Management, IEEE Journal on Selected Areas in Communications
17 (9) (1999) 1614–1631.
D.M. Wallner, E.J. Harder, R.C. Agee, Key Management
for Multicast: Issues and Architectures, RFC 2627.
D. Huang, D. Medhi, A Key-chain Based Keying Scheme
For Many-to-Many Secure Group Communication, ACM
Transactions on Information and System Security 7 (4)
(2004) 523–552.
L. Eschenauer, V.D. Gligor, A Key-management Scheme for
Distributed Sensor Networks, in: Proceedings of the 9th
ACM Conference on Computer and Communication Security (CCS-02), 2002, pp. 41–47.
H. Chan, A. Perrig, D. Song, Random Key Predistribution
Schemes for Sensor Networks, in: Proceedings of 2003
Symposium on Security and Privacy, IEEE Computer
Society, Los Alamitos, CA, 2003, pp. 197–215.
S. Basagni, K. Herrin, D. Bruschi, E. Rosti, Secure Pebblenets, in: Proceedings of the 2nd ACM international symposium on Mobile ad hoc networking & computing, ACM
Press New York, NY, USA, 2001, pp. 156–163.
K. Rhee, Y. Park, G. Tsudik, An Architecture for Key
Management in Hierarchical Mobile Ad-Hoc Networks,
Journal of Communications and Networks 6 (2) (2004) 156–
162.
D.E. Bell, Looking Back at the Bell-La Padula Model, in:
Looking Back at the Bell-La Padula Model, in: ACSAC ’05:
Proceedings of the 21st Annual Computer Security Applications Conference, IEEE Computer Society, Washington,
DC, USA, 2005, pp. 337–351.

D. Huang, D. Medhi / Ad Hoc Networks 6 (2008) 560–577
[29] D.E. Bell, L.J. LaPadula, Secure Computer Systems: Uniﬁed
Exposition and Multics Interpretation, Tech. rep., MITRE
Corporation (1976).
[30] C. Landwehr, C. Heitmeyer, J. McLean, A Security Model
for Military Message Systems: Retrospective, ACM Transaction on Computer System 2 (3) (1984) 198–222.
[31] C. Karlof, D. Wagner, Secure Routing in Wireless Sensor
Networks: Attacks and Countermeasures, Elsevier’s AdHoc
Networks Journal, Special Issue on Sensor Network Applications and Protocols 1 (2–3) (2003) 293–315.
[32] R.G. Ogier, F.L. Templin, M.G. Lewis, Topology Dissemination Based on Reverse-Path Forwarding (TBRPF), IETF
Internet RFC 3684.
[33] S. Basagni, I. Chlamtac, V.R. Syrotiuk, Location Aware,
Dependable Multicast for Mobile Ad-Hoc Networks, Computer Networks 36 (2001) 659–670.
[34] D. Coppersmith, M. Jakobsson, Almost Optimal Hash
Sequence Traversal, in: Proceedings of the Finacial Cryptography, InterVarsity Press, Southampton, Bermuda, 2002,
pp. 102–119.
[35] M. Jakobsson, Fractal Hash Sequence Representation and
Traversal, in: Proceedings of the IEEE International Symposium on Information Theory (ISIT’02), 2002, pp. 437–444.
[36] F.K. Hwang, D.S. Richards, Steiner Tree Problems, Networks 22 (1992) 55–89.
[37] K. Makki, N. Pissinou, O. Frieder, Eﬃcient Solutions to
Multicast Routing in Communication Networks, Mobile
Networks and Applications 1 (2) (1996) 221–232.

Dijiang Huang received his B.S. degree
from Beijing University of Posts &
Telecommunications, China 1995. He
received his M.S., and Ph.D. degrees
from the University of Missouri–Kansas
City, in 2001 and 2004, respectively. He
is an Assistant Professor in the Computer Science & Engineering Department
at the Arizona State University. His
current research interests are computer
networking, security, and privacy.

577

Deep Medhi is Professor of Computer
Networking, Computer Science and
Electrical Engineering Department at the
University of Missouri-Kansas City,
USA. He received B.Sc. (Hons) in
Mathematics from Cotton College/
Gauhati University, India, M.Sc. in
Mathematics from the University of
Delhi, India, and Ph.D. in Computer
Sciences from the University of Wisconsin-Madison, USA. Prior to joining
UMKC in 1989, he was a member of technical staﬀ at AT& T
Bell Laboratories. He was an invited visiting professor at the
Technical University of Denmark and a visiting research fellow at
Lund Institute of Technology, Sweden. He is a Fulbright senior
specialist. His research interests are resilient multi-layer network
design, network routing and design, sensor networks. He has
published over seventy papers, and is co-author of the books
Routing, Flow, and Capacity Design in Communication and
Computer Networks (2004), and Network Routing: Algorithms,
Protocols, and Architectures (2007), both published by Morgan
Kaufmann Publishers.

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010

An Optimal Key Distribution Scheme for Secure
Multicast Group Communication
Zhibin Zhou and Dijiang Huang
Arizona State University

Abstract— Many IP multicast-based applications, such as multimedia conferencing, multiplayer games, require controlling the
group memberships of senders and receivers. One common
solution is to encrypt the data with a session key shared with all
authorized senders/receivers. To efficiently update the session key
in the event of member removal, many rooted-tree based group
key distribution schemes have been proposed. However, most of
the existing rooted-tree based schemes are not optimal. In other
words, given the O(log N ) storage overhead, the communication
overhead is not minimized. On the other hand, although Flat
Table scheme [1] achieves optimality [2], it is rather dismissed
due to the vulnerability to collusion attacks.
In this paper, we propose a key distribution scheme – EGK
that attains the same optimality as Flat Table without collusion
vulnerability. Additionally, EGK provides constant message size
and requires O(log N ) storage overhead at the group controller,
which makes EGK suitable for applications containing a large
number of multicasting group members. Moreover, adding members in EGK requires just one multicasting message. EGK is
the first work with such features and out-performs all existing
schemes.
Index Terms— Security, Group Key Management, Multicast.

I. I NTRODUCTION
IP multicast is used to distribute data to a group of receivers.
Datagram addressed to the multicast group will be delivered
to all group members efficiently. Many IP multicast-based
applications require providing security services such as privacy
and authenticity for transmitted data. One way to restrict the
data access in secure multicast communication is to encrypt the
data using a group key that can be only accessible by desired
group members. To this end, a session encryption key (SEK)
for the communication group should be established during the
communication. Moreover, to support dynamic group changes,
the SEK needs to be updated when group members join or
leave the multicast group to comply backward secrecy and
forward secrecy, which are defined as follows:
•
•

Backward Secrecy: new joined group members must have
no access to past group communication;
Forward Secrecy: revoked group members must have no
access to future group communication;

As the members may join or leave the group dynamically,
it is very critical to ensure only legitimated group members
have the update-to-date SEKs. Particularly, removing members
poses the scalability problem for multicast group key management. To illustrate this problem, we can consider l clients
are removed from a group of size N . To remove l group
member(s), a new SEK should be generated and distributed
to each of (N − l) remaining clients. Thus, the problem of
removing any arbitrary l members can be transformed to the

problem of communicating with a subgroup of any arbitrary
(N − l) members in a scalable and secure way.
To facilitate the key distribution for multicast groups with
membership changes, many rooted-tree based key distribution
schemes have been proposed, such as [3], [4], [5]. In these
schemes, each member is distributed log N secrets, where N is
the group size. In [2], when group size is N , the authors proved
that assigning log N secrets to each member is the information
theoretical optimal strategy. We extend the optimality concept
and define a new optimality concept with consideration on
both storage overhead and communication overhead for all
possible group formations:
•

Storage-communication-optimality condition: given the
log N pre-distributed secrets for a group size of N , each
group member can combine any of the log N secrets to
decrypt 2log N − 1 = N − 1 different encrypted streams.

The storage-communication-optimality condition describes the
balanced optimality condition between the number of secret
keys and the number of multicasted messages.
Previous solutions [3], [4], [5] are not storagecommunication-optimality. Flat Table (FT) scheme [1]
achieved storage-communication-optimality with minimized
the communication overhead [2]. However, despite its superior
efficiency over other schemes, FT scheme is vulnerable to
collusion attacks, in which multiple removed members
combine their pre-distributed secrets to decrypt updated SEK
and thus forward secrecy can be compromised.
Our Contribution In this paper, we propose an Efficient Group keying (EGK) scheme to achieve non-colluding,
storage-communication-optimal group key management. In
EGK, a group controller (GC) is responsible for key generation
and distribution and the group data are encrypted by a SEK.
Each group member (GM) is assigned a unique n-bit ID,
where n = log N . GC also generates and distributes a set of
n secrets, which are one-to-one mapped to the bits in GM’s
ID. Note that, although different GMs may share common bits
in their IDs, the pre-distributed secrets are generated by using
different random numbers. As a result, GMs cannot combine
their secrets that are masked by different random numbers. We
denote the set of pre-distributed secrets as a GM’s private key.
Whenever members are removed from the group, GC will
multicast an encrypted key-update message. Only the remaining GMs are able to recover the message and update SEK as
well as their private keys. To achieve storage-communicationoptimality, we use the similar method of Flat Table scheme.
A minimized boolean function in the form of sum-of-productexpression (SOPE) is calculated based on the IDs of remaining

978-1-4244-5837-0/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010

GMs, in order to minimize the number of encrypted keyupdate messages. Any remaining GM can combine n predistributed secret shares in his/her private key to decrypt a
key-update message.
EGK is the first work that achieves storage-communicationoptimality with constant message size and immune to collusion
attack. It outperforms existing group key management schemes
in terms of communication and storage efficiency. We must
note that in [6], the authors utilized the ciphertext policy attributed based encryption (CP-ABE [7]) scheme to implement
FT so that it is secure against collusion attack. Although their
solution is similar to EGK, we adopt a different approach
to improve the communication efficiency in comparison with
using CP-ABE directly. As mentioned in [6], the size of each
message is very large and grows linearly on the number of
attributes in the access policy [6], [7]. In EGK, the message
is substantially reduced to a constant size. Overall, the main
contributions of EGK are presented as follows:
• With any number of removing GMs, the number of encrypted key-update messages is information theoretically
minimized to O(log N ).
• The size of each message in encrypted key-update message is constant.
• The communication overhead of adding GMs is O(1),
i.e., only one multicast message is required.
• The storage overhead of GC and GM is O(log N ) even
if GC does not store IDs of GMs.
• EGK is collusion resistant and provides forward and
backward group key secrecy.
Paper Organization The rest of this paper is organized as
follows. We describe related works in Section II. Section III
presents system models used in this paper. We present detailed
EGK construction in Section IV. In Section V, we discuss the
performance of EGK scheme and the comparison of several
existing group key management schemes. Finally, we conclude
our work in Section VI.
II. R ELATED W ORKS
Multicast key distribution schemes have been investigated
intensively in past two decades. Some of the works include
but not limited to [3], [8], [9]. Due to the richness of related
research, we cannot list all the related work in this area. We
refer to [10], [11] as two excellent surveys.
In the follows, we present a simple example to illustrate the
performance of existing rooted-tree based solutions under the
considerations of storage-communication-optimality condition.
Typically, the rooted-tree based solutions require O(log N )
storage overhead [12]. The authors in [2] showed that the
assignment of O(log N ) keys for each group member is the
best strategy for group communication schemes.
Most of the existing tree-based multicast key distribution
with O(log N ) storage overhead (such as OFT [4], LKH [3],
and ELK [5]) only improves the efficiency marginally. This is
because, in these solutions, based on the log N pre-distributed
auxiliary keys, each group member can merely participate in
log N subgroups. As shown in Figure 1(a), three auxiliary nonroot keys are assigned to group member u2 : K11 , K21 , and
K32 . Using these auxiliary keys, u2 can directly participate

Fig. 1. Illustration of two kinds of tree structures. Tree (a) is used in non-flat
table schemes and tree (b) is used in flat table scheme.

in three subgroup communication: (1) {u1 , u2 , u3 , u4 } using
K11 ; (2) {u1 , u2 } using K21 ; and (3) singleton group {u2 }
using K32 .
To achieve the storage-communication-optimality condition,
centralized FT scheme [1] adopts a slightly different construction of balanced key trees. As shown in Figure 1(b), 3
non-root keys are distributed to the group member u2 : K11 ,
K21 , and K32 . Using these auxiliary keys, u2 can participate
in seven subgroup communication: (1) {u1 , u2 , u3 , u4 } uses
K11 ; (2) {u1 , u2 } uses K21 ; (3) {u2 , u4 , u6 , u8 } uses K32 ;
(4) {u1 , u2 } uses K11 and K21 ; (5) {u2 , u4 } uses K11 and
K32 ; (6) {u2 , u6 } uses K21 and K32 ; finally (7) the singleton
subgroup {u2 } uses three keys K11 , K21 and K32 . Note that
u2 can combine (such as using XOR) the pre-distributed keys
to secure subgroup communication. In FT scheme, based on
the O(log N ) pre-distributed secrets, each group member can
participate in 2log N − 1 = N − 1 subgroups by combining
their predistributed secrets.
In [2], the authors showed that using FT schemes presented
in Figure 1(b) provides the optimal solution in terms of
reducing communication overhead for group key management.
However, FT suffers the collusion problem, which prevents it
from being used for secure group key management. To prevent
the collusion attacks, Cheung et al. [6] proposed CP-ABE-FT
to implement the FT using CP-ABE. However, message size
of CP-ABE-FT is linearly growing [6], while EGK features a
constant message size.
III. S YSTEM M ODELS A ND BACKGROUND
Communication Model The communication model of EGK
is based on the IP multicast framework. All GMs belong to a
multicast group G. Each GM u can send or receive diagrams
encrypted by SEK. When more GMs are removed from the
group, the GC just multicasts one key-update message. Only
eligible GMs can decrypt the message and update their private
key.
ID and Bit-Assignment Each GM is associated with a unique
binary ID: b0 b1 . . . bn−2 bn−1 , where n = log N . The ID is
issued by the GC when the GM joins the multicasting group.
Once the GM left the group, his/her ID can be re-assigned
to other joining GMs. We can use a logic literal, called bitassignment, Bi and Bi to indicate the binary value at position
i in an ID. Bi indicates the i’th bit of an ID is 1; B i indicates
the i’th bit of an ID is 0. For a group with N GMs, the
length of an ID is n = log N and the total number of bitassignments is 2n; that is, two binary values are mapped to
one bit position (one for value 0 and one for value 1). We call

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010

α+r

Fig. 2.

An illustration of bit-assignments for a 3-bit ID space.

the set of all possible bit-assignments to be Universe U , which
contains 2n bit-assignments. A GM u is uniquely identified
by the set of bit-assignments Su associated with u’s ID. Also,
multiple GMs may have a common subset of bit-assignments.
For example, in Figure 2, a GM u1 ’s ID is 000 and a GM u2 ’s
ID is001, Su1 = {B 0 , B 1 , B 2 } and Su2 = {B 0 , B 1 , B2 } and
Su1 Su2 = {B 0 , B 1 }.
Collusion Attack refers to multiple GMs combining their predistributed private keys to decrypt the ciphertext not intended
to them. However, there is no such a compromised insider GM
that works as a decryption proxy for attackers. One example of
this attack is when multiple GMs are revoked from the group,
they try to collude to recover the secrets of some valid GMs
to reveal group messages.
Bilinear Pairing is a bilinear map function e : G0 ×G0 → G1 ,
where G0 and G1 are two multiplicative cyclic groups with
large prime order p. The Discrete Logarithm Problem (DLP)
on both G0 and G1 is hard. One of the pairing properties is
Bilinearity: e(aP, bQ) = e(P, Q)ab , ∀P, Q ∈ G0 , ∀a, b ∈ Z∗p .
IV. C ONSTRUCTIONS OF EGK
A. Group Setup
We describe how the GC sets up the multicast group.
First, GC chooses a bilinear group G0 of prime order p
with generator g. Also, GC chooses a publicly known oneway function H. Then, it chooses two non-trivial random
numbers α, β ∈ Z∗p . For simplicity, we can map the universe
of bit-assignments U to the first |U | members of Z∗p , i.e.,
the integers 1, 2, . . . , |U |. Finally, for each bit-assignment
B ∈ U , GC chooses a non-trivial random number yB ∈
Zp . We denote this set of 2n random numbers by YB =
{yB0 , yB 0 , . . . , yBn−1 , yB n−1 }.
GC publishes the group public parameter GP = {G0 , e, g,
H}. The group master key: M K = {β, g α , g β , e(g, g)α , YB }
is well protected by the GC.
B. GM Joining and Key Generation
When a new GM u joins the group, u needs to set up a
secure channel with the GC using either a pre-shared key
or public key certificates. GC then checks whether the GM
is authorized to join in the group. Once the checking is
passed, GC assigns a unique ID bun−1 bun−2 ...bu0 and a set of
bit assignments Su to u.
Once u is admitted to the group, GC runs key generation
algorithm KeyGen(M K, Su ) to generate private key SKu
for u, where M K is the group master key and Su is the
set of bit-assignments in u’ ID. The algorithm first chooses
a non-trivial random number r ∈ Z∗p . Then, it computes

g β . Finally, for each bit-assignment B ∈ Su , the KeyGen()
algorithm calculates a blinded secret share g ryB . The outputted
α+r
private key SKu : {D = g β , ∀B ∈ Su : DB = g ryB }.
If u is the first GM in the group, GC will generate an initial
SEK and sends the private key {SKu , SEK} to the new GM
u through a secure channel. If u is not the first joining GM,
to preserve backward secrecy, GC generates another random
key SEK  and multicast {SEK  }SEK . Each GM other than
u can decrypt the message and replace SEK with SEK  .
Finally, GC sends {SKu , SEK  } to the new GM u through a
secure unicast channel. In the join process, besides the unicast
communication, GC only needs to multicast one message, i.e.,
{SEK  }SEK . Thus, the communication overhead for GMs
join is O(1).
C. Encryption and Decryption
We present how GC can encrypt a message with a set of
bit-assignment S, so that only GMs whose IDs satisfy S can
decrypt the message. For example, in a three-bit-ID group, if a
ciphertext is encrypted by using bit-assignment S = {B 0 , B1 },
GMs with IDs 010 and 011 can decrypt the ciphertext.
1) Encryption: ENC(GP, M K, S, M ) encryption algorithm takes inputs of the system master key M K, the group
parameter GP , a set of bit-assignment S, the message M , and
returns the ciphertext CT . In EGK, only the GC can perform
ENC since M K is the system master key. Given
 the set of
bit-assignment S, it is easy to find a YS =
B∈S yB . For
example, if S = {B 0 , B1 , B2 }, YS = yB 0 + yB1 + yB2 .
After calculating YS , the ENC() algorithm generates a
non-trivial random number t ∈ Z∗p . Then, the algorithm
computes C0 = M e(g, g)αtYS , C1 = g βtYS , C2 = g t . Thus,
the ciphertext is as: CT : {S, C0 = M e(g, g)αtYS , C1 =
g βtYS , C2 = g t }.
2) Decryption: On receiving the CT, GMs whose ID satisfied the bit-assignment S associated with the ciphertext,
can decrypt the CT by performing decryption algorithm
DEC(GP, SK, CT ).
The DEC() algorithm first checks whether the GM u is eligible to decrypt the message by testing whether Su ⊆ CT.S,
where CT.S represents the bit assignments associated with
the ciphertext CT . Then, for each bit assignment B ∈ CT.S,
the algorithm use
u’s pre-distributed secret
shares DB = g ryB

to compute F = B∈CT.S g ryB = g r B∈CT .S yB = g rYCT .S .
Next, the algorithm computes A1 = e(C1 , D) =
e(g, g)(α+r)tYCT .S and A2 = e(C2 , F ) = e(g, g)rtYCT .S .
Then the algorithm divides A1 by A2 and get A3 =
A1 /A2 = e(g, g)αtYCT .S , which blinds the plaintext in ciphertext. Finally, the algorithm unblinds the ciphertext by
calculating C0 /A3 = M .
D. Encryption for Subgroups of GMs
In this subsection, we present how EGK can just multicast
one encrypted message to enable any arbitrary subgroup of
members to decrypt the message. We first define some of the
terms used in the following presentations:
• Literal: A variable or its complement, e.g., B1 , B1 , etc.
• Product Term: Literals connected by AND, e.g., B2 B1 B0 .
• Sum-of-Product Expression (SOPE): Product terms connected by OR, e.g., B2 B1 B0 + B2 .

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010

Given the subgroup of GMs L, the boolean membership
functions M (B0 , B1 , . . . , Bn−2 , Bn−1 ), which is in the form
of SOPE, can determine the membership of the subgroup. That
is, only if GM u belongs to the subgroup, M (IDu ) = 1.
Formally, the following properties of membership functions
hold:

0 iff u ∈ G \ L,
M (bu0 , bu1 , . . . , bun−2 , bun−1 ) =
1 iff u ∈ L.
For example, if the subgroup L = {000, 001, 011, 111}, then
M = B 0 B 1 B 2 + B 0 B 1 B2 + B 0 B1 B2 + B0 B1 B2 .
The GC runs the Quine-McCluskey algorithm [13] to reduce
M to minimal SOPE Mmin . GC can permit do not care
values on those IDs that are not currently assigned to any
GM to further reduce the size of Mmin . Since Mmin is in
the form of SOPE, GC can encrypt the message for each
product term. That is, for each product term E in Mmin ,
GC runs ENC algorithm with the set of bit-assignment S
that contains all literals in E. The total number of ciphertexts
equals to the number of product terms in Mmin . For example,
if L = {000, 001, 011, 111}, then Mmin = B 0 B 1 + B1 B2 .
We can find that Mmin contains two product terms. Thus, GC
can encrypt a message M for subgroup L with two messages
M{B 0 ,B 1 } and M{B1 ,B2 } .
E. GM Leaving
1) Key Update: When several GMs (denoted by set L) are
removed from the multicasting group, GC needs to update the
{M K, SEK} as well as the private key for each remaining
GM u ∈ G \ L. We present how this process can be done
efficiently.


GC first changes M K  = {β, g α , e(g, g)α }, where α is
randomly selected in Zp . Then, GC multicasts an encrypted
α −α

key-update factor kuf = g β . Note that kuf is encrypted,
and it cannot be decrypted by any u ∈ L.
Each GM u ∈ G \ L updates its private key SKu based
α −α
on the key updating factor g β . This process only updates
be updated by
the
the component D in SKu. The new D can
α −α
α+r
α −α
α+r+α −α
β
β
β
β
=g
·g
=g
=
following
method: D · g
α +r
g β . Also, each u ∈ G \ L updates their SEK simply by
α −α
computing SEK  = H(g β ).
2) Single or Multiple Leave: We first consider that only
one GM leaves the group. For example, if the leaving GM
u’s ID is 101 with bit-assignment Su = {B0 , B 1 , B2 }. The
key updating message is encrypted as {kuf }{B 0 } , {kuf }{B1 } ,
{kuf }{B 2 } and is multicasted to the entire group. If ID 100 is
not assigned, {kuf }{B 2 } is not needed. Although the leaving
member may intercept the transmitted messages, it cannot
decrypt them since every message is encrypted with a bit
assignment that the leaving member does not possess. Each
of remaining GMs can decrypt at least one of the multicasted
messages.
We now focus on the case when multiple GMs leave the
multicast group. Given the set of leaving GMs L, GC can
easily derive the set of remaining GMs G \ L as well as
the set of unassigned IDs if GC stores all assigned IDs. If
GC does not store assigned ID, GC can assume all IDs are

TABLE I
C OMPARISON OF COMMUNICATION OVERHEAD .
Scheme
EGK
FT
FT-CP-ABE

Communication Overhead
join
single leave
multiple leaves
Θ(1)
O(log N )
≈ O(log N )
Θ(log N )
O(log N )
≈ O(log N )
Θ(1)
O(log N )
≈ O(log2 N )
1

1

BGW
N/A
O(N 2 )
O(N 2 )
ACP
Θ(N )
Θ(N )
Θ(N )
Tree
Θ(1)
Θ(log N )
O(l · log N )
N : the number of group members; l: the number of leaving
members; t: maximum number of colluding users to compromise the ciphertext.

assigned. Then, the GC runs the Quine-McCluskey algorithm
[13] to reduce the membership function M () to minimal
SOPE. Then, GC can encrypt the key updating factor for each
product term. The total number of encrypted key updating
factors equals to the number of product terms in Mmin . For
example, we assume that two GMs {000, 010} leave, five GMS
{001, 011, 100, 101, 110} remain, and {111} is not assigned
to any GM (i.e., the ID bit assignments are do not care).
With the considerations do not care values, M can be reduced
to Mmin = B0 + B2 . GC need to multicast two messages
{kuf }{B0 } and {kuf }{B2 } .
V. P ERFORMANCE A SSESSMENTS
In this section, we present the performance assessment of
EGK scheme. We compare EGK with several previous solutions: Flat Table scheme (FT) [1], FT implemented using CPABE (FT-CP-ABE) [6], subset-difference broadcast encryption scheme (Subset-Diff) [14], BGW broadcasting encryption
[15], access control polynomial (ACP) scheme [16], and treebased schemes represent a set of solutions such as OFT [4],
LKH [3], ELK [5], etc. The comparative results are presented
in the Table I:
We first discuss the communication overhead of several
broadcasting encryption schemes. For BGW scheme, the mes1
sage size is O(N 2 ) as reported in [15]. In ACP scheme, the
size of a message depends on the degree of access control
polynomial, which equals to the number of current GMs plus
the number of joining GMs or the number of current GMs
minus the number leaving GMs. Thus, the message size is
Θ(N ).
For tree-based multicast key distribution schemes such as
OFT, LKH, and ELK, the communication overhead for a GM
leaving depends on the number of keys to be updated in
the tree [5]. Some tree-based schemes try to optimize the
number of messages to update all the affected keys in the
case of multiple leaves. In ELK [5], which is known to be one
of the most efficient tree-based schemes, the communication
overhead for multiple leaves is Θ(a−l), where a is the number
of affected keys and l is the number of leaving GMs. Since
there are log N nodes on the path from the root to leaves in
the tree structure, the total number of affected keys when l
GMs leave the group is O(l · log N ).
When removing multiple GMs from an EGK group, the
number of messages depends on the number of product terms
in the Mmin . In the worst cases, EGK out-performs all the
tree-based schemes except FT. Since EGK requires the same
number of messages as FT when removing a set of GMs, we
use the results from [1]. In the worst case, the number of keys

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings
This paper was presented as part of the Mini-Conference at IEEE INFOCOM 2010

based on our evaluation results in Figure 3(c) and 3(d), the
total message size of EGK will be smaller than symmetric
key based schemes when the size of a group is large due to
fewer numbers of transmitted messages. It can be expected
in large scale systems, where the size of a multicast group is
larger than 4096, EGK will be much more efficient than other
schemes.
VI. C ONCLUSION
(a)

(c)

(b)

(d)

Fig. 3. (a) Number of messages required for multiple removal when group
size is 1024; (b) Number of messages for group size 4096; (c) Size of total
messages for group size 1024; (d) Size of total messages for group size 4096.

to be updated is N − N/2 = N/2 for ELK and FT, since
there are N non-leaf keys to be updated and the number of
leaving GMs is N/2. We can see that, in the worst case, EGK’s
performance is same as ELK approach.
We compared EGK with LKH in the group size as 1024
GMs and 4096 GMs, and the number of messages required
are shown in Figure 3(a) and Figure 3(b), respectively. In the
comparison, we consider the cases of 5%, 25%, 50% IDs are
not assigned (i.e., do not care value). As a comparison, the
message number curve of LKH is also plotted. We can see
that EGK performs better than LKH and it achieves roughly
O(log N ) complexity, where the constant factor is about 20 for
the 1024-member group and 50 for the 4096-member group.
Finally, we look into the message size of EGK, FT-CPABE[6], and symmetric key tree-based schemes. As mentioned
in [6], in FT-CP-ABE, the size of ciphertext grows linearly
based on the increase of the number of attributes in the
access policy [6], [7]. Experimentally, the message size in
FT-CP-ABE starts at about 650 bytes, and each additional
attribute adds about 300 bytes. In a system with 10-bit ID
or 1024 GMs, the number of attributes using FT-CP-ABE
ciphertext is at most 10 and the message size may be as
large as 650+9*300=3350 bytes. Since the number of attributes
in the access policy is bounded by log N , we can conclude
that the communication overhead of FT-CP-ABE is in the
order of O(log2 N ). In EGK, every ciphertext contains exactly
one group member on G0 and two group members on G1 .
Empirically, the value on G0 or G1 can be about 128 bytes.
Thus, the ciphertext in EGK is bounded by 400 bytes, which
is significantly smaller than the ciphertext size reported in
FT-CP-ABE [6]. Moreover, since the component C2 in the
ciphertext can be shared by multiple messages, we can further
reduce the message size of EGK. Existing tree-based schemes
using symmetric encryption algorithms, such as AES, enjoys
the advantage of small ciphertext. To encrypt a 32-byte SEK,
those schemes require as low as 32-byte ciphertext. However,

EGK achieves the Storage-communication-optimality without colluding problem. EGK greatly improves the communication efficiency (O(log N ) for multiple-leave operations),
storage efficiency (O(log N ) for both GM and GC). Moreover,
EGK scheme provides group forward/backward secrecy, and
it is resistant to colluding attacks.
R EFERENCES
[1] I. Chang, R. Engel, D. Kandlur, D. Pendarakis, D. Saha, I. Center,
and Y. Heights, “Key management for secure lnternet multicast using
Boolean functionminimization techniques,” INFOCOM’99. Eighteenth
Annual Joint Conference of the IEEE Computer and Communications
Societies. Proceedings. IEEE, vol. 2, 1999.
[2] R. Poovendran and J. Baras, “An information-theoretic approach for
design and analysis ofrooted-tree-based multicast key management
schemes,” IEEE Transactions on Information Theory, vol. 47, no. 7,
pp. 2824–2834, 2001.
[3] C. Wong, M. Gouda, and S. Lam, “Secure group communications using
key graphs,” Networking, IEEE/ACM Transactions on, vol. 8, no. 1, pp.
16–30, 2000.
[4] A. Sherman and D. McGrew, “Key Establishment in Large Dynamic
Groups Using One-Way Function Trees,” IEEE TRANSACTIONS ON
SOFTWARE ENGINEERING, pp. 444–458, 2003.
[5] A. Perrig, D. Song, and J. Tygar, “ELK, A New Protocol for Efficient
Large-Group Key Distribution,” IEEE SYMPOSIUM ON SECURITY
AND PRIVACY, pp. 247–262, 2001.
[6] L. Cheung, J. Cooley, R. Khazan, and C. Newport, “Collusion-Resistant
Group Key Management Using Attribute-Based Encryption,” Cryptology
ePrint Archive Report 2007/161, 2007. http://eprint. iacr. org, Tech. Rep.
[7] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-Policy AttributeBased Encryption,” Proceedings of the 28th IEEE Symposium on Security and Privacy (Oakland), 2007.
[8] G. Caronni, M. Waldvogel, D. Sun, and B. Plattner, “Efficient security
for large and dynamic multicast groups,” Proceedings of the IEEE 7th
International Workshop on Enabling Technologies: Infrastructure for
Collaborative Enterprises (WET ICE98), 1998.
[9] X. Li, Y. Yang, M. Gouda, and S. Lam, “Batch rekeying for secure group
communications,” Proceedings of the 10th international conference on
World Wide Web, pp. 525–534, 2001.
[10] M. Moyer, J. Rao, and P. Rohatgi, “A survey of security issues in
multicast communications,” Network, IEEE, vol. 13, no. 6, pp. 12–23,
1999.
[11] S. Rafaeli and D. Hutchison, “A survey of key management for secure
group communication,” ACM Computing Surveys (CSUR), vol. 35, no. 3,
pp. 309–329, 2003.
[12] R. Canetti, T. Malkin, and K. Nissim, “Efficient CommunicationStorage Tradeoffs for Multicast Encryption, Advances in CryptologyEurocrypt99,” Lecture Notes in Computer Science, vol. 1592, pp. 459–
474, 1999.
[13] E. McCluskey, “Minimization of Boolean functions,” Bell System Technical Journal, vol. 35, no. 5, pp. 1417–1444, 1956.
[14] A. Fiat and M. Naor, “Broadcast Encryption, Advances in CryptologyCrypto93,” Lecture Notes in Computer Science, vol. 773, pp. 480–491,
1994.
[15] D. Boneh, A. Sahai, and B. Waters, “Fully collusion resistant traitor
tracing with short ciphertexts and private keys,” pp. 573–592, 2006.
[16] X. Zou, Y. Dai, and E. Bertino, “A Practical and Flexible Key Management Mechanism For Trusted Collaborative Computing,” INFOCOM
2008. The 27th Conference on Computer Communications. IEEE, pp.
538–546, 2008.

Future Generation Computer Systems 66 (2017) 30–35

Contents lists available at ScienceDirect

Future Generation Computer Systems
journal homepage: www.elsevier.com/locate/fgcs

iDoctor: Personalized and professionalized medical
recommendations based on hybrid matrix factorization
Yin Zhang a , Min Chen b,∗ , Dijiang Huang c , Di Wu d , Yong Li e
a

School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China

b

School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China

c

Department of Computer Science and Engineering, Arizona State University, USA

d

School of Information Science & Technology, Sun Yat-Sen University, China

e

Department of Electronic Engineering, Tsinghua University, China

highlights
•
•
•
•

We propose a topic model based approach to discover user preference distribution and doctor feature distribution.
We propose an emotion-aware approach to identify emotional offset in user reviews via sentiment analysis.
We incorporate topic model and emotional offset into the matrix factorization model.
The experimental results show that the proposed model provides a high-performance healthcare recommendation.

article

info

Article history:
Received 17 June 2015
Received in revised form
26 November 2015
Accepted 3 December 2015
Available online 12 January 2016
Keywords:
Healthcare
Recommendation
Matrix factorization
Sentiment analysis
Topic model

abstract
Nowadays, crowd-sourced review websites provide decision support for various aspects of daily life,
including shopping, local services, healthcare, etc. However, one of the most important challenges for
existing healthcare review websites is the lack of personalized and professionalized guidelines for users
to choose medical services. In this paper, we develop a novel healthcare recommendation system called
iDoctor, which is based on hybrid matrix factorization methods. iDoctor differs from previous work in
the following aspects: (1) emotional offset of user reviews can be unveiled by sentiment analysis and
be utilized to revise original user ratings; (2) user preference and doctor feature are extracted by Latent
Dirichlet Allocation and incorporated into conventional matrix factorization. We compare iDoctor with
previous healthcare recommendation methods using real datasets. The experimental results show that
iDoctor provides a higher predication rating and increases the accuracy of healthcare recommendation
significantly.
© 2015 Elsevier B.V. All rights reserved.

1. Introduction
With the rapid development of mobile networks such as
the fifth generation (5G) system [1,2], a significant amount
of professional knowledge from various sectors is available to
Internet users at anywhere and can be accessed anytime to provide
assistance decision [3,4]. For example, we can choose different
movies according to the ratings on IMDB,1 while the selection

∗

Corresponding author.
E-mail addresses: yin.zhang.cn@ieee.org (Y. Zhang), minchen2012@hust.edu.cn
(M. Chen), Dijiang.Huang@asu.edu (D. Huang), wudi27@sysu.edu.cn (D. Wu),
liyong07@tsinghua.edu.cn (Y. Li).
1 http://www.imdb.com/.
http://dx.doi.org/10.1016/j.future.2015.12.001
0167-739X/© 2015 Elsevier B.V. All rights reserved.

of restaurants, hotels and stores can be referred to other users’
reviews on Yelp.2 Similarly, the way that people choose medical
service is changing with health related reviews websites, such as
Vitals,3 Healthgrades4 and RateMDs,5 etc. Through these websites,
detailed information about doctors can be obtained for choosing
doctor with an online appointment. This innovative process
of medical consultation exhibits high efficiency compared to
traditional onsite doctor selection [5]. However, several challenges
exist to enable personalized and accurate medical services:

2 http://www.yelp.com/.
3 http://www.vitals.com/.
4 http://www.healthgrades.com/.
5 http://www.ratemds.com.

Y. Zhang et al. / Future Generation Computer Systems 66 (2017) 30–35
Table 1
Emotional offset in user reviews.
Text
easy-going person. It is not always typical nowadays to get a PCPa who one
feels comfortable speaking with. As for the staff, only two of the doctor’s
assistants were kind to my mother. The rest such as the lady who sits at the
window to collect payments gives an attitude that the patient is a bother as
they are never friendly nor show appreciation. The way we are treated is that
we are bothering them which is not right. It is truly regretful.
a

Primary care physician.

• Personalized and professionalized demand: It is very common nowadays for patients to search medical service by disease,
but the search results may contain too many doctors to meet
diverse needs [6]. Furthermore, user experience is always the
most important for the system design [7]. For example, some
users would much rather find a doctor nearby, while others
prefer prescription to injection as treatment. Unfortunately, at
present such personalization and professionalization demand
cannot be satisfied intelligently according to user and doctor
feature [8].
• Emotional offset: Like other sectors, it is a great issue for the
medical crowd-sourced reviews that rating accuracy is often
interfered by users emotion [9]. For example, a doctor’s rating
is 4 and a review about him is presented in Table 1. It can be
concluded that this doctor is not so welcomed and such rating
is possibly an encouragement, which has directly influenced the
objectivity and accuracy of doctors estimation.
To address these challenges, this article proposes a personalized
and professionalized doctor recommendation system named
iDoctor, which can conduct comprehensive analysis on healthcare
crowd-sourced reviews and perform text sentiment analysis, topic
model, matrix factorization and other methods. Specifically, this
article makes the following contributions: (1) We propose a topic
model based approach to discover user preference distribution and
doctor feature distribution, which are incorporated into the matrix
factorization model to provide more accurate and personalized
medical recommendation. (2) We propose an emotion-aware
approach to identify emotional offset in user reviews via sentiment
analysis, which is incorporated into the matrix factorization model
to provide more objective recommendation.
The remainder of this article is organized as follows. Section 2
presents related works of matrix factorization, text sentiment
analysis, and topic model. In Section 3, we introduce iDoctor
architecture, theories foundation, and technical details. Section 4
analyzes the performance of recommendation provided by iDoctor,
and compares it with other recommendations. Finally, we conclude
this article in Section 5.
2. Related works
2.1. Matrix factorization
Nowadays, the recommendation based on matrix factorization
proposed by Koren et al. in [10], has achieved acceptable result for
rating prediction. Through this model, users and items are mapped
to a low dimensional latent factor space which is the explanation
to users ratings, and a user-item rating matrix is regarded as the
product of user and item as presented in Eq. (1).
Rm×n = Pm×k ∗ Qk×n

(1)

in which k represents the number of selected latent factors, P and Q
represent the weights of each user and item for each characteristic
in latent factor space, which are the result of rating matrix R
factorization and used for rating prediction. Usually, Stochastic
Gradient Descent (SGD) [11] is used for calculating P and Q .

31

Remarkably, some latent factors can be ignored, so k < m, n.
For example, category, director and actor attract more attention
than duration and language, which can be ignored in matrix
factorization.
Because of the good performance of matrix factorization, many
researchers try to extend this work. In [12], Jamali et al. proposed a
matrix factorization with trust propagation for recommendation
in social networks. In [13], Baltrunas et al. proposed matrix
factorization based approach for context aware recommendation.
2.2. Text sentiment analysis
User emotion plays an important role in market analysis,
opinion mining and human–computer interaction, so more and
more attention has been attracted to emotion recognition [14]. In
general, it is complex for emotion recognition through language
and facial expression, whereas the development of psychology and
linguistics simplifies the process of text sentiment analysis. The
text document contains not only topics but also user’s emotional
features that users expressions always correlate well with the
emotion at that time.
At present, quite a few works try to integrate emotional actors
into personalized recommendation [15]. In [16], Poirier et al.
proposed a collaborative filtering recommendation according to
sentiment analysis of user reviews instead of rating. In [17], Ko
et al. proposed a hybrid recommendation algorithm based on
content and collaborative filtering, in which the vector of item
features and user emotion is calculated from item descriptions and
user reviews.
2.3. Topic model
In the topic model, a document is regarded as the mixture and
combination of multiple topics, and each word in the document is
generated by such a procedure that a topic is selected with certain
probability from document-topic distribution and then this word
is selected with certain probability from topic-word distribution.
Currently, the Latent Dirichlet Allocation (LDA) topic model is
widely adopted for document topic extraction. Through LDA, topics
and their probability distribution can be calculated for analyzing
document similarity, which is essential for document classification
and personalized recommendation.
Currently, there are many proposals that try to incorporate
topic model into matrix factorization. In [18], Agarwal et al.
represented item with some words, which are mapped to a
multi-topic distribution, and provide recommendation through
regression forecasting. In [19], McAuley et al. used topic model
to extract item features from user reviews, integrate them with
matrix factorization, and verify that the accuracy of this proposal
is higher than rating matrix.
3. iDoctor: medical recommendation based on hybrid matrix
factorization
In this article, we propose iDoctor to provide user with professionalized and personalized doctor recommendation through
mining user emotion and preference from user rating and reviews
about doctors. Specifically, it includes the following modules, and
the architecture is illustrated in Fig. 1:

• Sentiment analysis module, which can calculate user emotional offset from user reviews text.

• Topic modeling module, which is used to extract the
distribution of user preferences and doctor features.

• Hybrid matrix factorization module, which is integrated with
two feature distributions extracted by LDA for rating prediction.

32

Y. Zhang et al. / Future Generation Computer Systems 66 (2017) 30–35

Fig. 1. Architecture of the iDoctor system.

3.1. Sentiment analysis for emotional offset
Considering the emotional offset in user reviews about doctor,
sentiment analysis is necessary to calculate the offset for revising
the original rating. Specifically, we calculate the emotional offset
through non-supervisory learning method based on sentiment
lexicon in the following steps:
1. Each user review text is preprocessed, including word segmentation and morphological normalization.
2. After removing stopword and punctuation, we have a collection
of words which may involve emotional offset.
3. With sentiment lexicon SentiWordNet 3.0 [20], the emotional
offset of each review can be calculated.
4. Furthermore, considering the influence of negative words, it is
necessary to split each review in punctuation. In the separated
subsentence, if the number of negatives is odd, the polarity
(positive ‘‘+’’ or negative ‘‘−’’) of this subsentence should be
reversed. Obviously, the overall emotional offset is the sum of
all the subsentence.
Assume that there are i words in subsentences sub, we can
calculate the sentiment value with Eqs. (2) and (3).
Pol(sub) =


−1
1

if the number of negative words in sub is odd
if the number of negative words in sub is even
(2)


Sen(sub) =




SentiWordNet (wi ) × Pol(sub) .

(3)

wi ∈sub

Wherein, Pol(sub) represents the polarity of sub; SentiWordNet
(wi ) represents the sentiment value of word i calculated according
to SentiWordNet 3.0.
However, there is significant difference among user review
lengths, and the emotional offset of longer review is most likely
higher than shorter one. In order to balance the influences
that the different length of review exert over overall variance,

normalization is essential to calculate the overall emotional offset
of user review.
Assume that there are j subsentences in review re including
n sentiment words, we can calculate the emotional offset with
Eq. (4).



Sen(subj )

subj ∈re

.
(4)
n
Obviously, the emotional offset of each user review falls in the
range of [−1, 1], which is used to revise the original rating.
Offset (re) =

3.2. Topic modeling for user preference
Generally, user reviews contain detailed personalized evaluation about doctors, such as their feelings towards medical environment, doctor’s ability and attitude. On the one hand, every user
preference can be discovered from these details, which is the basis for personalized recommendation. On the other hand, Table 2
describes that doctor features can be summarized from different
user’s reviews, such as specialty, fee range and prescribing habits,
which also may be the basis of doctor selection.
Therefore, LDA model is adopted by iDoctor to extract the topics
of user latent preference and doctor features can be extracted
from user review comments on doctors, which are involved in
matrix factorization for providing more accurate and personalized
recommendation.
3.3. Hybrid matrix factorization for personalized and professionalized
doctor recommendation
Based on the emotional offset calculated in Section 3.1, the
original rating is expected to be revised with Eq. (5).
RSij = ρ Rij + (1 − ρ)Sij

(5)

in which RSij represents the revised rating on doctor j by user i, Rij
represent the original rating, Sui represents the emotional offset,

Y. Zhang et al. / Future Generation Computer Systems 66 (2017) 30–35
Table 2
The features included in user reviews.

33

Table 3
Parameters to be determined.

Text

Feature

Parameter

Representation

Optimum

Dr. Davis is a gem! Extremely reassuring,
knowledgeable & smart. I had been fretting about an
ongoing problem, wondering if it could be something
else. My PCP just did his prescribing a pill call me in a
week thing. I wanted to talk to someone & have an
exam! Well Dr. Davis did just that & took his time to
explain—what a novel idea! He had some
recommendations which are helping me. The main
thing was this man responded to me with kindness &
concern & did his best to give me peace of mind.

Reassuring,
knowledgeable,
smart, took time to
explain, kindness,
concern

η
λ

Learning rate
Regularization parameter
Iterations
Weight of original rating
Number of latent topic
Weight of user preference
Weight of doctor feature

0.001
0.1
100
0.7
30
0.1
0.1

and rho is used for adjusting the weight between original rating
and emotional offset. With Eq. (5), user emotional factor is involved
in the matric factorization through the revised user–doctor rating
matrix.
In Section 3.2, the preference topic distribution of user i,
namely, Ui = (x1 , x2 , . . . , xk ), and the features topic distribution of
doctor j, namely, Ij = (y1 , y2 , . . . , yk ), are calculated through LDA.
In the above expressions, k represents the number of latent topics.
In the conventional matrix factorization, which is named
Basic Matrix Factorization (BMF) in this article, the factorized
matrixes cannot represent personalization. Hence, we propose
Hybrid Matrix Factorization (HMF) involving user preference and
doctor feature for more personalized recommendation, and loss
function is defined as presented in Eq. (6),
J = ∥RS − P × Q T ∥2F + α∥U − P × A∥2F

+ β∥I − Q × A∥2F + λ(∥P ∥2F + ∥Q ∥2F + ∥A∥2F ),

(6)

in which RS represents the rating matrix revised with emotional
offset, P represents user latent factor matrix, Q represents doctor
latent factor matrix, α is used for adjusting the weight of user
preference distribution, while β is a parameter used for adjusting
the weight of doctor feature distribution, and λ is used for
regulating the weight of regularizing filter.
In order to achieve the best performance for HMF, Eq. (6) is
expected to be minimized. After factorization, lower dimension
matrixes of P, Q and A represent user, doctor, and the latent-topicmapping matrix of latent-factor-rating matrix respectively. Finally,
rating is available to be predicted through matrix multiply P × Q ,
and latent factor matrixes P and Q are calculated by SGD, which
includes the partial derivatives presented in Eqs. (7), (8), and (9).

∂J
= −2(R − P × Q T )Q − 2α(U − P × A)AT + 2λP
∂P
∂J
= −2P T (R − P × Q T ) − 2β(I − Q × A)AT + 2λQ
∂Q
∂J
= −2α P T (U − P × A) − 2β Q T (I − Q × A) + 2λA.
∂A

(7)
(8)
(9)

4. Experiments and analysis
4.1. Experimental data and evaluation standards
Experimental data in this article is obtained from a crowdsourced review website called Yelp.6 We select rating and
reviews about three types doctor (i.e. Internal Medicine Family
Practice and Urgent Care) in Pittsburgh, Charlotte, Phoenixand
Las Vegas for experiment. All the data are preprocessed by
Natural Language Toolkit (NLTK),7 which is a leading platform for

6 http://www.yelp.com/dataset_challenge/.
7 http://www.nltk.org/.

N

ρ

K

α
β

building Python programs to work with human language data,
for word segmentation, removal of punctuation and stop word,
and lemmatization. In the experiment, around 80% of this data
are randomly selected for training, while the others are used
for verifying the performance of our proposal. In particular, the
experimental data includes 97 618 reviews about 8519 doctors
submitted by 12 036 users.
Furthermore, Root Mean Square Error (RMSE) [21] is used
for evaluating the accuracy of the proposed recommendation
algorithm. With Eq. (10), the RMSE between predicted rating and
actual rating can be calculated that the smaller the RMSE is, the
better the performance of recommendation is.


 n
1 
(pi − ri )2 .
RMSE = 
n i =1

(10)

In the above equation, n is the number of records in test data
set, pi represents the predicted rating, and ri represents the actual
rating.
4.2. Experiment design and result analysis
In this article, the experiment is designed for comparing our
proposed HMF with BMF proposed in [11], and the hardware environment of our experiments is a computer with Intel Pentium Dual
core CPU, 2.7 GHz dominant frequency, 8G primary memory. However, the parameters should be determined before the comparison.
Table 3 shows the details of the parameters to be determined.
In Table 3, η, λ and N are the three basic parameters in SGD
for matrix factorization. Through simple substitution, the results
are satisfactory while η = 0.001, λ = 0.1, and N = 100. And
the others are determined with the following determination of
optimum parameters. ρ , K , α and β are only used in HMF, and we
determined one parameter through fixing other three ones.
1. M: Both in BMF and HMF, M is expected to be determined. Based
on the definition of loss function of BMF in [11], we evaluate
RMSE with M = [5, 10, . . . , 30, 35]. As shown in Fig. 2(a), it
is obvious that when M = 15, RMSE is minimum. Hence, the
number of latent factors in HMF is determined to be 15 either.
2. ρ : We set K = 20, α = 0.1, β = 0.1, and try to minimize
RMSE with ρ = [0, 0.1, . . . , 0.9, 1]. In particular, ρ = 0
means to directly use emotional offset to predict rating, while
ρ = 1 means to directly original rating. As shown in Fig. 2(b),
which indicates that the weight of emotional offset should
be relatively smaller than original rating, because the original
rating is usually submitted after serious consideration and it can
represent adequately user review.
3. K : We substitute ρ = 0.7 and set α = 0.1, β = 0.1. Fig. 2(c)
illustrates the experimental results for RMSE calculation with
K = [10, 20, . . . , 60, 70] that RMSE is minimized when K =
30. That is because if K is too small, the topic distributions
of user preference and doctor feature cannot be represented
sufficiently in HMF. Conversely, the convergence rates of HMF
is too low to minimize RMSE.

34

Y. Zhang et al. / Future Generation Computer Systems 66 (2017) 30–35

(b) Determination of ρ .

(a) Determination of M.

(d) Determination of α and β .

(c) Determination of K .

Fig. 2. Determination of optimum parameters.

Table 4
Comparison between HMF, BMF, User-based and Item-based CF.
RMSE

Item-based CF
User-based CF
BMF
HMF

5. Conclusions

M
5

10

15

20

25

30

35

1.561
1.562
1.254
1.248

1.561
1.561
1.253
1.246

1.561
1.561
1.252
1.244

1.561
1.561
1.252
1.245

1.561
1.561
1.253
1.246

1.561
1.561
1.254
1.248

1.561
1.561
1.254
1.249

4. α and β : According to the representation, we try to find the
optimum of α, β ∈ [0, 1] by grid search [22], and Fig. 2(d)
shows that RMSE is minimized when α = 0.1, β = 0.1. It
indicates that the weights of user preference and doctor feature,
which are expected to revise BMF for more accurate prediction,
should be relative small.
With determined optimum parameters, RMSE of HMF is
lower than that of BMF which means HMF-based iDoctor
based can provide more accurate recommendation. Furthermore,
considering the similarity between the number of latent factors in
matrix factorization (i.e. M) and the number of neighborhood in
collaborative filtering (CF) which is one of the most representative
techniques used by recommendation systems, item-based CF and
user-based CF are available to be involved into the comparison. As
shown in Table 4, RMSE of HMF is significantly lower than that of
other models, and it proves that iDoctor can provide more accurate
doctor recommendation.

It is challenging to address the problem that user choose
doctor online without sufficient personalized and personalized
instruction. To solve the problem, proposed iDoctor to (1) discover
emotional rating from user reviews to revise user original rating;
(2) discover topic distributions of user preference and doctor feature to improve conventional matrix factorization. Our experiment
results proved that the prediction of proposed HMF is better than
BMF, item-based CF, and user-based CF, and iDoctor can provide
considerable accurate recommendation. In our future work, we
plan to take the time-varying possibility of user preferences into
account and import data from social networks to further increase
the recommendation accuracy, and try to develop a general system
like iDoctor to provide more personalized, professionalized and objective recommendation.

Acknowledgments
The research reported here was supported by China National
Natural Science Foundation under Grants 61572220. Prof. Di Wu’s
work was supported in part by the National Natural Science
Foundation of China under Grant Nos. 61272397 and 61572538,
and the Guangdong Natural Science Funds for Distinguished Young
Scholar under Grant No. S20120011187.

Y. Zhang et al. / Future Generation Computer Systems 66 (2017) 30–35

References
[1] K. Zheng, L. Zhao, J. Mei, M. Dohler, W. Xiang, Y. Peng, 10 gb/s hetsnets
with millimeter-wave communications: access and networking-challenges
and protocols, IEEE Commun. Mag. 53 (1) (2015) 222–231.
[2] X. Ge, H. Cheng, M. Guizani, T. Han, 5g wireless backhaul networks: challenges
and research advances, IEEE Netw. 28 (6) (2014) 6–11.
[3] M.S. Hossain, G. Muhammad, Cloud-assisted speech and face recognition
framework for health monitoring, Mob. Netw. Appl. (2015) 1–9.
[4] D. Zhang, C.-H. Hsu, M. Chen, Q. Chen, N. Xiong, J. Lloret, Cold-start recommendation using bi-clustering and fusion for large-scale social recommender
systems, IEEE Trans. Emerging Top. Comput. 2 (2) (2014) 239–250.
[5] T.R. Hoens, M. Blanton, A. Steele, N.V. Chawla, Reliable medical recommendation systems with patient privacy, ACM Trans. Intell. Syst. Technol. (TIST) 4 (4)
(2013) 67.
[6] M. Hossain, Cloud-supported cyber-physical localization framework for
patients monitoring, IEEE Syst. J. PP (99) (2015) 1–10. http://dx.doi.org/10.
1109/JSYST.2015.2470644.
[7] K. Zheng, X. Zhang, Q. Zheng, W. Xiang, L. Hanzo, Quality-of-experience
assessment and its application to video services in lte networks, IEEE Wirel.
Commun. 22 (1) (2015) 70–78.
[8] G. Luo, S.B. Thomas, C. Tang, Automatic home medical product recommendation, J. Med. Syst. 36 (2) (2012) 383–398.
[9] Y. Tan, Y. Zhang, M. Zhang, Y. Liu, S. Ma, A unified framework for emotional
elements extraction based on finite state matching machine, in: Natural
Language Processing and Chinese Computing, Springer, 2013, pp. 60–71.
[10] Y. Koren, R. Bell, C. Volinsky, Matrix factorization techniques for recommender
systems, Computer (8) (2009) 30–37.
[11] R. Gemulla, E. Nijkamp, P.J. Haas, Y. Sismanis, Large-scale matrix factorization
with distributed stochastic gradient descent, in: Proceedings of the 17th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining,
ACM, 2011, pp. 69–77.
[12] M. Jamali, M. Ester, A matrix factorization technique with trust propagation
for recommendation in social networks, in: Proceedings of the Fourth ACM
Conference on Recommender Systems, ACM, 2010, pp. 135–142.
[13] L. Baltrunas, B. Ludwig, F. Ricci, Matrix factorization techniques for context
aware recommendation, in: Proceedings of the Fifth ACM Conference on
Recommender Systems, ACM, 2011, pp. 301–304.
[14] M.S. Hossain, G. Muhammad, B. Song, M.M. Hassan, A. Alelaiwi, A. Alamri,
Audio-visual emotion-aware cloud gaming framework 25 (12).
[15] Y. Moshfeghi, J.M. Jose, Role of emotional features in collaborative recommendation, in: Advances in Information Retrieval, Springer, 2011, pp. 738–742.
[16] D. Poirier, F. Fessant, I. Tellier, Reducing the cold-start problem in content
recommendation through opinion classification, in: 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology
(WI-IAT), Vol. 1, IEEE, 2010, pp. 204–207.
[17] M. Ko, H.W. Kim, M. Yi, J. Song, Y. Liu, Moviecommenter: Aspect-based
collaborative filtering by utilizing user comments, in: 2011 7th International
Conference on Collaborative Computing: Networking, Applications and
Worksharing (CollaborateCom), IEEE, 2011, pp. 362–371.
[18] D. Agarwal, B.-C. Chen, flda: matrix factorization through latent dirichlet
allocation, in: Proceedings of the Third ACM International Conference on Web
Search and Data Mining, ACM, 2010, pp. 91–100.
[19] J. McAuley, J. Leskovec, Hidden factors and hidden topics: understanding rating
dimensions with review text, in: Proceedings of the 7th ACM Conference on
Recommender Systems, ACM, 2013, pp. 165–172.
[20] S. Baccianella, A. Esuli, F. Sebastiani, Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining, in: LREC, Vol. 10, 2010,
pp. 2200–2204.
[21] A. Zollanvari, E.R. Dougherty, Moments and root-mean-square error of the
Bayesian mmse estimator of classification error in the Gaussian model, Pattern
Recognit. 47 (6) (2014) 2178–2192.
[22] T. Nakagawa, Y. Iwahori, M. Bhuyan, Defect classification of electronic board
using multiple classifiers and grid search of svm parameters, in: Computer and
Information Science, Springer, 2013, pp. 115–127.

Yin Zhang is a faculty member of the School of Information and Safety Engineering, Zhongnan University of
Economics and Law. He worked as a Poster-Doctoral Fellow in the School of Computer Science and Technology at
Huazhong University of Science and Technology (HUST)
for two years. He is a handling Guest Editor for New Review
of Hypermedia and Multimedia. He serves as reviewer for
IEEE Network, Information Sciences. He is TPC Co-Chair for
5th International Conference on Cloud Computing (CloudComp 2014). He is Local Chair for the 9th International
Conference on Testbeds and Research Infrastructures for
the Development of Networks & Communities (TRIDENTCOM 2014), and CloudComp 2013.

35

Min Chen is a Professor in School of Computer Science
and Technology at Huazhong University of Science and
Technology (HUST). He is the Director of Embedded and
Pervasive Computing (EPIC) lab. He was an Assistant
Professor in School of Computer Science and Engineering
at Seoul National University (SNU) from Sep. 2009 to Feb.
2012. He worked as a Post-Doctoral Fellow in Department
of Electrical and Computer Engineering at University of
British Columbia (UBC) for three years. Before joining
UBC, he was a Post-Doctoral Fellow at SNU for one and
half years. He received Best Paper Award from IEEE ICC
2012, and Best Paper Runner-up Award from QShine 2008. He is a Guest Editor
for IEEE Network, IEEE Wireless Communications Magazine, etc. He is Co-Chair
of IEEE ICC 2012-Communications Theory Symposium, and Co-Chair of IEEE ICC
2013-Wireless Networks Symposium. He is General Co-Chair for the 12th IEEE
International Conference on Computer and Information Technology (IEEE CIT-2012)
and Mobimedia 2015. He is General Vice Chair foTridentcom 2014. He is Keynote
Speaker for CyberC 2012, Mobiquitous 2012 and Cloudcomp 2015. He has more than
260 paper publications, including 120+ SCI papers, 50+ IEEE Trans./Journal papers,
6 ISI highly cited papers and 1 hot paper. He has published a book on IoT: OPNET
IoT Simulation (2015) with HUST Press, and a book on big data: Big Data Related
Technologies (2014) with Springer Series in Computer Science. His Google Scholars
Citations reached 5400+ with an h-index of 35. His top paper was cited 656 times,
while his top book was cited 420 times as of Aug. 2015. He is an IEEE Senior Member
since 2009. His research focuses on Internet of Things, Mobile Cloud, Body Area
Networks, Emotion-aware Computing, Healthcare Big Data, Cyber Physical Systems,
and Robotics, etc.
Dijiang Huang received his Bachelor of Science degree
in Telecommunications from Beijing University of Posts
& Telecommunications in 1995. He received his Master
of Science and Ph.D. degrees from University of MissouriKansas City in 2001 and 2004, respectively, both majored
in Computer Science and Telecommunications. He joined
Computer Science and Engineering Department at ASU
in 2005. Dr. Huang’s research is supported by NSF, ONR,
ARO, HP, and Consortium of Embedded System (CES). He
is a recipient of ONR Young Investigator Award and HP
Innovative Research Award.
Di Wu is an Associate Professor and Associate Department
Head in the Department of Computer Science, Sun Yat-sen
University, Guangzhou, China. He received the B.S. degree
from the University of Science and Technology of China,
Hefei, China, in 2000; the M.S. degree from the Institute
of Computing Technology, Chinese Academy of Sciences,
Beijing, China, in 2003; and the Ph.D. degree in Computer
Science and Engineering from the Chinese University
of Hong Kong, Shatin, Hong Kong, in 2007. During
2007–2009, he worked as a postdoctoral researcher in
the Department of Computer Science and Engineering,
NYU Polytechnic School of Engineering (previously Polytechnic Institute of NYU),
advised by Prof. Keith W. Ross. He was also working closely with Prof. Yong Liu
and Prof. Joel Wein. He was a co-recipient of IEEE INFOCOM 2009 Best Paper
Award. He has served as the Media Streaming IG Chair (2014–2016) of IEEE
Communications Society Multimedia Communications Technical Committee, the
TPC Co-chair of IEEE GLOBECOM-CCSNA Workshop 2014, Chair of CCF YOCSEFGuangzhou (2014–2015), Member of the Council of China Computer Federation
(2012–2015). He has also served as the Guest Editor of IEEE Transactions on
Circuits and Systems for Video Technology, Special Issue on ‘‘Visual Computing
in the Cloud: Mobile Computing’’, and the Editor of SCI-indexed journals, such
as Springer Telecommunication Systems, Springer Peer-to-Peer Networking and
Applications, Wiley Security and Communication Networks. His research interests
include Multimedia Networking, Cloud Computing, Big Data Analytics, Internet
Measurement, and Network Security.
Yong Li received the B.S. degree in Electronics and
Information Engineering from Huazhong University of
Science and Technology, Wuhan, China, in 2007 and the
Ph.D. degree in electronic engineering from Tsinghua
University, Beijing, China, in 2012. During July–August
2012 and 2013, he was a Visiting Research Associate
with Telekom Innovation Laboratories and The Hong Kong
University of Science and Technology, respectively. During
December 2013–March 2014, he was a Visiting Scientist
with the University of Miami. He is currently a Faculty
Member of the Department of Electronic Engineering,
Tsinghua University. His research interests are in the areas of networking and
communications.

Traffic Analysis-based Unlinkability Measure for IEEE
802.11b-based Communication Systems
Dijiang Huang
Computer Science and Engineering
Arizona State University
Tempe, AZ 85287-8809 USA
dijiang@asu.edu
ABSTRACT
Measuring communication anonymity (e.g., unlinkability)
of wireless ad hoc networks is a critical but still unsolved
problem. In order to solve this problem, we propose a twostep unlinkability measuring approach: (a) statistical traffic analysis-based evidence collection, (b) evidence theorybased unlinkability measure. To demonstrate our approach,
we use IEEE 802.11b-based ad hoc networks as our analyzing communication systems. Based on our proposed IEEE
802.11b transmission and channel models, we can collect a
set of evidence which can be used to set up a probability assignment for each possible communication relation (i.e., the
data sender and corresponding receiver); and then we can
apply the evidence theory-based unlinkability measuring approach to the collected evidence to derive the unlinkability
measure of the given 802.11b-based ad hoc network.

point-to-point and end-to-end relations). The above mentioned approaches provide solutions for end-to-end unlinkability by applying hop-by-hop packet re-encryption. However, outside adversaries can detect and capture data traffic
in the media, and then statistically analyze point-to-point
(or local) data traffic to discover end-to-end communication
relations. We call this type of attacking procedures as statistical traffic analysis (STA) attack.
It is important to measure the anonymity performance (in
terms of unlinkability) on countering STA attacks. This will
guide us to improve the resilience of a wireless ad-hoc communication system to STA attacks. For this goal, we introduce evidence theory [17] as the mathematical tools to evaluate the unlinkability of a wireless communication system.
Since the IEEE 802.11b-based1 wireless ad hoc networks are
widely deployed, we use IEEE 802.11b-based wireless system
as our analyzing communication system.

Categories and Subject Descriptors

1.2 Attacker’s Capabilities

C.2.0 [Computer-communication networks]: General—
Security and protection

We assume that adversaries are outside traffic observers.
They can capture and monitor network traffic at any spot
within a communication system. The goal of the adversaries
is to derive both point-to-point and end-to-end communication relations, i.e, the linkability, by inspecting the frame
transmissions at physical and MAC layers. In summary, the
adversaries have the following capabilities:

General Terms
Algorithms, Security, Theory.

Keywords

1. Adversaries can detect, capture, and monitor the traffic transmitted within a wireless communication system; however they cannot decrypt the content of captured frames when cryptographic algorithms are applied.

Unlinkability, Traffic Analysis, Evidence Theory.

1.

INTRODUCTION

1.1 Motivations

2. Adversaries are silent observers, i.e., without injecting
frames or interrupting frame transmissions.

Several wireless ad hoc network-based anonymous routing
protocols have been recently proposed for wireless mobile
ad-hoc networks, e.g., [3, 11, 16, 20], etc. These anonymity
communication approaches mainly focus on unlinkable data
transmissions. By “unlinkablility”, we mean that, it is not
possible to trace who communicates with whom (i.e., both

3. Adversaries can locate wireless stations and trace their
movements.
4. Based on the assumptions 1 - 3, using sophisticated
wireless signal detection devices (multiple detection
devices might be deployed), adversaries can detect the
wireless signal transmission power and transmission directions at any given location within a communication
system. In other words, the adversaries can locate the
signal source.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
WiSe’06, September 29, 2006, Los Angeles, California, USA.
Copyright 2006 ACM 1-59593-557-6/06/0009 ...$5.00.

1

In particular, our research analysis mainly focuses on IEEE
802.11b specifications which can be extend to other 802.11x
protocols without losing generality.
65

1.3 Review of Anonymous Ad Hoc Network
Routing and Packet Delivery

riod when the locations of the mobile stations are relatively
static. In addition, the statistical traffic analysis involves
set and subset inclusive inferences to derive the probabilities of possible packet forwarding paths. For example, the
supporting evidence (i.e., direct evidence) of traffic between
pairs hA, Bi and hB, Ci can be used to deduce the probability of transmissions for the path hA, B, Ci (i.e., indirect
evidence). Shannon information theory does not provide
such an inclusive probability inference capabilities.
Evidence theory [17] is a branch of generalized information
theory. It is a suitable candidate to measure the anonymity
for statistical traffic analysis in wireless communication environments. An evidence is a concrete measure of the real
wireless system such as a captured data packet and the measure can be quantified to derive the probability assignments
for the transmission patterns of each wireless node. Thus,
the probability is more dynamic which is suitable for node
mobility. In addition, the belief measure Bel is an intuitive
and natural measure for set and subset involvements (i.e.,
from several direct evidence to derive an indirect evidence)
and it can be reduced to Shannon measure when no subset
involvements are taken place.

Although our research focuses on physical and MAC layers of a wireless system, we must understand the ability
of existing anonymous ad hoc network routing and packet
delivery approaches at the upper layers which can help us
to design more effective anonymous wireless communication
system using cross-layer designing approaches.
Most of existing anonymous multi-hop wireless communication systems utilize two techniques: 1) on-demand path
discovery, and 2) packet re-encryption. When on-demand
path discovery is applied, a route request is broadcasted
hop-by-hop from the source to the destination; once receiving an request, the destination node generates a reply (a
confirmation) and unicasts it along the reverse direction of
the corresponding request path. In this way, the packet
delivering path between the source station and the destination station is set up. When packet re-encryption is applied, on each hop, both the routing and data packets are
encrypted by a unique cryptographic key. Using these approaches, the same packet appears different on each packet
forwarding hop. Thus, an eavesdropper cannot identify the
same packet transmitted on every packet forwarding hop.
Although the anonymous routing and packet delivery approaches can provide a degree of unlinkability, the adversaries can still collect evidence at substrate layers to deduce
the potential end-to-end communication relations. Thus, it
is very important to design the anonymous communication
systems using across layers approach. For example, some
lower layers’ functions such as addressing can be moved to
the upper layers in order to hide the direct communication
relations between the frame sender and the corresponding
receiver.

1.5 Our Contributions and the Potentials of
Our Proposed Research
Our main contributions of this paper are in two-fold:
• We categorize and analyze physical and MAC layers
of IEEE 802.11b protocols in terms of frame transmission and reception. The categorization and analysis of
physical and MAC layers properties help us to understand how adversaries collet evidence to conduct STA
attacks.
• We introduce evidence theory to build up the unlinkability measuring mechanism for wireless communication systems, which can handle inferences of indirect
evidence effectively (i.e., infer multi-hop end-to-end
communication relations form captured point-to-point
direct evidence).

1.4 State of the Art Anonymity Measure for
Communication Systems
The anonymity research was initiated by David Chaum’s
paper on untraceable electronic mail [4] in 1980s. In late
1990’s, the field of anonymity research received extensive
attentions. In order to evaluate and quantify the anonymity
provided by a communication system, several approaches
were proposed to measure the anonymity (i.e., unlinkability) for Internet-based protocols, such as [6, 15, 18]. These
approaches use Shannon information theory as the mathematical tools which use uncertainty as the measuring metric
to quantify (i.e., in number of bits) the anonymity. These
approaches work well in wired environments where the communication relations among potential communication peers
are relatively static; and the behavior of each communication node is predefined based on a known probability assignment. For example, in Crowds [14], each node is preassigned
a probability p to forward the packet to the destination or
1 − p to the other random chosen forwarder.
An intuitive approach is to utilize previously proposed
anonymity measuring solutions for wireless networking environments. However, in wireless ad-hoc environments, it is
difficult to predefine the probability assignment of the transmission pattern for each mobile station. This is because that
the number of immediate potential receivers of a transmitted packet is non-predictable due to the wide area coverage
of the wireless communication channels and the mobility
of wireless stations. Thus, a packet sending or receiving
probability assignment is only validate during the time pe-

In this paper, the evidence is defined as the number of
captured data frames (or packets) within a given time period. Since the evidence theory does not restrict the types of
measurements, it leaves the space for us to inspect broader
evidence such as timing, mobility, etc., where the art is to
quantify evidence and convert the evidence to probability
assignments for all possible communication relations. We
are currently in the processes of creating evidence measures
based on different types of evidence. Furthermore, the traffic analysis-based anonymity research is not just restricted
within IEEE 802.11b networks. Our proposed approaches
point a research direction that can cover a variety types of
wireless networks.

1.6 Paper Arrangement
The rest of this paper is organized as follows: in section
2, we present a communication model of IEEE 802.11b and
corresponding threat model and possible solutions; based
on the point-to-point attack model presented in section 2,
we present a STA attack-based unlinkability measure in section 3; in section 4, we use simulation to demonstrate the
use of our proposed unlinkability measuring approach; finally, we conclude our research in section 5.
66

Preamble

PLCP Header

MAC Data

Data

Frame
Control

Duration
ID

Receiver
Address

Transmitter

Frame
Control

Duration
ID

Receiver
Address

Transmitter

RTS

CTS

Frame
Control

Duration
ID

Receiver
Address

ACK

Frame
Control

Duration
ID

Receiver
Address

Address

BSSID

data (≈ 10%) is sent at two adjacent rates to the current one. Then, at the end of a specified decision time
window, an evaluation of the performance of all the
three transmission rates takes place. The actual data
throughput per rate setting is calculated by dividing
the number of frames by their total transmission time.
Finally, a switchover is made to the rate that provided
the best throughput during the decision window.
• Frame error rate (FER) -based Rate Control. This approach counts the number of transmitted frames that
do not get acknowledgements during a specific time
window along with a count of all transmitted frames.
Based on these counts and the threshold values for
upgrading and downgrading transmission rates, a new
transmission rate is selected.
• Retry-based rate control. The transmission rate is selected based on the number of unsuccessful retransmissions (usually 5 to 10 retries).

CRC

Sequence
Control

N/A

Frame
Body

Address

Figure 1: 802.11b Frame Format.

2.

COMMUNICATION MODELS OF IEEE
802.11b PROTOCOL

In this section, we analyze the physical layer model, MAC
layer protocols, and communication channel model of IEEE
802.11b standards. Based on our analysis, we categorize and
evaluate the potential threats to disclose the point-to-point
communication relations. All these potential threats will
help adversaries to create an evidence base to discover endto-end communication relations which we will discuss in details in the next section. Our discussion and analysis in this
section are based on IEEE 802.11b 11Mbps standard. Our
analytical approach can be easily applied to other 802.11
standards (e.g., 802.11a/g), which are out of the scope of
this paper.

We notice that all the above mentioned rate control algorithms are directly related to signal to noise ratio (SNR),
where the noise include both ambient noise and accumulative interference from other wireless devices. Consequently,
the SNR is linked to the communication link settings, such
as transmission rate and distance.

2.1.2 Relations among Transmission rate, transmission distance, and FER

2.1 Physical Layer Model

In order to correctly demodulate the received signal, the
SNR must be greater or equal to a threshold β at the receiver
side. In [8], Gupta and Kumar presented a general physical
model of a wireless communication channel between i and j
(j is the receiver):

802.11b protocol covers the MAC and Physical layers.
The 802.11b frame2 format is shown in Figure 1. 802.11b
Physical layer includes Physical Layer Convergence Procedure (PLCP) and Physical Medium Dependent (PMD) sublayers. The PLCP prepares 802.11b frames for transmission
and directs the PMD to actually transmit signals, change radio channels, receive signals, and so on. In a 802.11b frame,
the Preamble is used for synchronization and frame timing,
and the PLCP Header is always transmitted at 1 Mbit/s
and contains logical information that will be used by the
physical layer to decode the frame. The signal subfield in
the PLCP header (not shown in Figure 1) identifies the data
transmission rate to indicate the data rate used by the data
portion. In the following subsections, we present the rate
control mechanism of 802.11b at the physical layer and its
relations to node location and FER. Finally, based on our
analysis, we present a rate control and location management
approach to improve the unlinkability of 802.11b-based networks.

Pi
(dij )α
≥ β,
SN R =
P
Pk
N + k∈T
α
k6=i (dkj )

(1)

where Pi and Pk are the transmission power chosen by i, k,
and T is the universe of all wireless stations; dij and dkj
are the communication distance between node pairs (i, j)
and (k, j), respectively; α is the signal power decay and
2 ≤ α < 4 as addressed in [1]; the noise includes the ambient
noise N and the accumulative interference from all other
nodes. Clearly, (1) is a function of the distance from each
node to the receiver when each node’s transmission power
is fixed. In general, the relation between dij and dkj should
follow the inequation:

2.1.1 802.11b Transmission Rate Control

dkj ≥ γ · dij .

802.11b standards [10] do not specify the algorithm for
performing dynamic rate switching in WaveLAN implementations. Thus, it is up to the vendors to design and implement such algorithms. In general, there are three practical rate selection algorithms [9] by obtaining the statistical information on the wireless links, i.e., the achieved
throughput, the frame error rate (FER), and the acknowledged transmissions.

(2)

γ determines the factor of the distance to a interferer k who
has the similar transmission device as the sender i and the
receiver j. Theoretically, shown in [13], for an asynchronous
direct-sequence BPSK (DBPSK) system γ = 0.38 for one
interferer. However, in most of 802.11b wireless implementations, the value of γ is usually greater than 1. The experiments conducted in [2] show that the value of γ is in the
range of 2 ∼ 3 which depends on the hardware implementations.
In Figure 2 (derived from [2] and [5]), we draw the relations among distance, transmission rate, and SNR values
based on the experiments and analysis from [2] and [5]. SNR
is firmly related to the bit-error rate in the link, and hence

• Throughput-based Rate Control. A small fraction of
2

In this paper, all our discussions focus on physical and
MAC layers, we use “frame” most of the time to indicate
a transmission unit. Without specific notation, we do not
differentiate the terms of frame and packet.
67

802.11b

Rate

SNR
( ≈ dB )

(Mbps)

13
5.5Mbps zone

11

DQPSKCCK

DQPSKCCK
5.5

8.88
DQPSKBaker DBPSK
Baker 4.5
1.2

2
1
30

70

90

120

(m)

11Mbps zone

S

2Mbps zone

Distance

1Mpbs zone

Figure 2: 802.11b communication Rate–Distance–
SNR–Modeling/Codeing. The physical layer head
is always transmitted by 1Mbps and the rate is set
in the PLCP signal sub field. Different rates use different signal modulating and coding schemes, e.g.,
DBPSK (Differential Binary Phase Shift Keying),
DQPSK (Differential Quadrature Phase Shift Keying), Baker sequence, and CCK (Complementary
Code Keying).

Figure 3: IEEE 802.11b rate zones with omnidirectional antenna.
scheme (Baker or CCK) to correctly recover the received data (see the modulations and rates mapping
of 802.11b in Figure 2).
• Almost all implementations use the best-effort data
transmission approach, i.e., the wireless devices transmit data at the maximum rate that the transmission
media can afford. If we reduce the transmission rate
to confuse the adversaries, the capacity of the wireless
communication system has to be reduced.

to the FER. Based on the above discussions, we can derive
the following relations:
1
1
∝d∝ ,
(3)
SN R
r
where d is the transmission distance and r is the communication rate.
F ER ∝

2.1.3 Rate-location-based Unlinkability Analysis
The proportional relations shown in (3) are nonlinear relations which depend on both hardware and software implementations (the proportions may vary due to different
wireless devices); nevertheless, the relation shown in (3) can
guide us to derive the point-to-point communication relations. For example, if there are several potential receivers
are located within a transmitter’s communication range, we
can derive the communication relations based on the following inferences (referred as rate-location attack ):

Against Rate-location Attack
Since the transmission rate information cannot be hidden
and the transmission rate depends on the transmission distance to the receiver and the noise level, we propose two research directions to improve the communication unlinkability based on location control and rate selection algorithms.
• Location Control. The probability to identify a communication relation pair is N1 , where N is the number of wireless stations that locate within the same
rate zone. Thus, it is desirable that the intended receiver located within the same rate zone which covers
as many stations as possible (i.e., with big value of N ).
Based on the location information of wireless stations,
the sender/receiver should move to a desired location
to increase the value of N . Mobile user equipped with
a GPS device can utilize geography-based ad hoc network routing protocol [12] to achieve this goal.
• Rate selection. If the sender can frequently change
its transmission rates, the various rates will make adversaries more difficult to discover the right receiver.
In order to enable the sender to have more selectable
rates to transmit, it is desirable that the sender and
the receiver can move closer. We analyze the complexity of the adversaries to identify a data frame receiver
as follows. If there are Nk wireless stations located in
the rate zone k with the rate rk , the sender has frequency qk to transmit a frame at rate rk , and there are
s available rates where rk1 < rk2 < rs if k1 < k2 < s;
then we can derive the probability pk to determine the
receiver at zone k:
!
k
k
X
X
1/
where k ≤ s.
(4)
Nj qi ,
pk =

• Lower rate means either there is a remote receiver or
the noise level is high. If the noise level can be monitored, we can estimate the communication distance
based on the transmission rate.
• Higher rate means either there is a close receiver or the
noise level is low. The same as the lower rate scenario,
if the noise level can be monitored, we can estimate
the communication distance based on the transmission
rate.
When wireless devices’ hardware properties are known, it
is easier to derive the transmission rate zones for each node,
i.e., the coverage area centered by the wireless device with
various radii which map to different transmission rates (see
rate zones of 802.11b in Figure 3). Based on the transmission
rate zones of a particular type of wireless device and their
physical locations, the adversaries can derive the communication relations based on the detected information, such as
rate information in the PLCP header.
Why anti-rate-location attack is difficult?
It is difficult to deploy anti-rate-location attack techniques.
The reasons are given as follows:
• The rate information in PLCP header cannot be omitted, since the frame receiver needs it to select correct demodulating (QBPSK or QDPSK) and decoding

i=1

68

j=i

As we know, when a wireless station located in the
rate zone rk , it can correctly demodulate the signals
transmitted in the rate rj when rj ≤ rk . Within a rate
zone j, the probability to correctly identify a receiver is
1/Nj . Thus, pk is the expected evaluation of probability assignments in each rate zone j when rj ≤ rk . In
particular, we can achieve the maximal unlinkability
between communication pairs when all nodes transmit
at the rate r1 , and the minimal unlinkability when all
nodes transmit at the rate rs .

G 1 =SIFS
G 3 =DIFS
CW =Contention Window

G3

Src

RTS

Data

Dest

G1

G1

G1

CTS

ACK
G3

Other

CW

NAV (RTS)

MPDU

NAV (CTS)
Slot tim e

Defer Access
(specified in Duration ID field)

Backoff after
Defer

Figure 4: 802.11b MAC layer: 4-way frame transmissions. SIFS (Short Inter Frame Space) is used to
separate transmissions belonging to a single dialog
(e.g. Fragment - ACK), and is the minimum inter
frame space, and there is always at most one single
station to transmit at this given time, hence having
priority over all other stations. DIFS (Distributed
IFS), is the inter frame space used for a station willing to start a new transmission.

2.1.4 Summary of Rate Control and Its Relations to
Unlinkability
802.11b rate control is indispensable for mobile ad hoc
networks. Many dynamic rate control algorithms have been
proposed to improve the capacity of a wireless communication system. However, both mobility and capacity of the
wireless system have to be compromised to improve the unlinkability of the wireless communication system. Thus, a
promising solution must involve cross-layer designs that take
into the considerations of routing, mobility, and system capacity.

follows: the sending station first transmits a short control
frame called RTS (Request To Send), which includes the
destination and the duration of the following transaction
(i.e., the frame and the respective ACK); the receiving station responds (if the medium is free) with a response control
frame called CTS (Clear To Send), which includes the same
duration information; all other stations receiving either the
RTS and/or the CTS set their virtual carrier sensing indicators (a.k.a, NAV) for the given duration and use these
information together with the physical carrier sensing.

2.2 Virtual Carrier Sense and Data Transmission of 802.11b MAC Layer Protocol
2.2.1 Data Transmission
802.11b frame format is presented in Figure 1. In general,
there are three main types of frames:
• Data Frames: which are used for data transmission.
• Control Frames: which are used to control access to
the medium (e.g. RTS, CTS, and ACK).
• Management Frames: which are used to exchange management information and are transmitted the same
way as data frames, but are not forwarded to upper
layers.

2.2.3 Against Linkability Disclosure Using 802.11b
MAC Protocol
802.11b data transmission with ACK confirmation and
virtual carrier sensing clearly demonstrate the corresponding point-to-point communication relations. We summarize
the identifiable information as follows:
• The frame transmission sequence must follow a distributed synchronization mechanism where the frames’
transmissions are delimited by SIFS, DIFS, and various time windows (such as NAV, slot time, contention
windows, etc). This frame transmission mechanism requires that a frame must be transmitted in sequence.
Thus, for a given time fragment, the type of the next
transmitted frame is predictable.
• The source and destination addresses in data, ACK,
RTS, and CTS frames disclose the point-to-point communication relations.

Each of these types is as well subdivided into different subtypes, according to its individual specific function.
802.11b uses a collision avoidance mechanism together
with a positive acknowledge scheme. In Figure 4, the diagrams show a transaction between sending station (Src)
and and receiving station (Dest), and the network allocation vector (NAV) setting of their neighbors. The NAV
state specified in the duration ID subfield in a MAC frame,
is combined with the physical carrier sensing to indicate the
busy state of the medium. The sending station senses the
medium; if the medium is busy then it defers; if the medium
is free for a specified time (called DIFS, Distributed Inter
Frame Space), then the station is allowed to transmit. The
receiving station will check the CRC of the received frame
and send the acknowledgment frame (ACK). The receipt of
the ACK indicates the sender that no collision occurs; otherwise the sender will retransmit the frame until the number
of retransmissions reaches a given threshold.

An intuitive solution is to change the header field to prevent
the adversaries from identifying the frame type and the corresponding frame senders/receivers. The possible modifications of the header fields include: (a) source/destination addresses are set to broadcasting address, i.e., all “1”, or using
identifier changing techniques, such as [7]; (b) for data/ACK
frames, the frame control field subtype “signal” is set to
the same value, the Duration ID field is set to the same
value, and the length of each data frame is the same; (c) for
RTS/CTS frames, the modifications are the same as in (b).
The modification (a) is viable with the added overhead
that all stations within the communication range must process the received frame and the upper layers, i.e., the application layer must be involved in order to identify the
sender/receiver. The analysis of (b) is similar as (a). In

2.2.2 Virtual Carrier Sensing
802.11b defines a virtual carrier sensing mechanism as
shown in Figure 4. The virtual carrier sensing mechanism
is designed to reduce the phenomena which is called hidden terminal problem, i.e., two stations transmit simultaneously and interference to each other at the receiving station.
The procedure of the virtual carrier sensing is described as
69

R3

Tx_Range

IF _

Ra

PCS_Range

S

PCS
_Ra
ng

IF
_R
an
g

changeable

e

ge
an
_R
IF

R1
ng

e

S2

S1

PCS_Range

R2
R4

e

Figure 5: 802.11b channel model with omnidirectional antenna.

Figure 6: 802.11b interference model with omnidirectional antenna.

order to make reliable transmission, we must relay on upper
layer to identify the type and address of a received frame3 .
In Section 2.1, we analyzed the rate zone partitions where
the adversaries had the probability 1/N to identify a possible receiver when the rate zone covered N wireless stations.
This conclusion is based on the assumptions that the modifications (a) and (b) must be applied. Thus, the modifications (a) and (b) are useful to prevent the adversaries from
identifying the corresponding communication pairs. As we
have pointed out, these modifications have the overhead of
introducing cross-layer management and reducing the system capacity due to frame stuffing (i.e., ACK frame must
be packed with the same length as of the data frame).
The modifications in (c) are not viable since (c) will change
802.11b’s communication mechanism and the frame transmission and synchronization mechanisms will be broken. In
addition, if we cannot hide the frame type of RTS/CTS
frames in the frame control field, sustaining the same frame
size is useless.
Another possible solution is to stop sending the RTS/CTS
frames. This approach is applicable since the RTS/CTS
frames are optional in 802.11b specification. In this way,
the frame transmission control totally relies on the physical
carrier sensing. As pointed out in [2], the authors who opposed to use virtual carrier sensing argued that the virtual
carrier sensing could not reduce interference but introduce
the communication overhead. In next subsection, we will
analyze the solutions with/without RTS/CTS options.

a single source at a time. Note that the IF Range
scope is changeable depending on the hardware properties and the noise level. It may be less or greater
than the scope of T X Range(x).
• Stations at a distance d, where d < P CS Range, they
are able to sense the physical carrier and detect the
transmissions from other wireless nodes.
An example of the classified ranges is shown in Figure 6,
where the source stations S1 and S2 are located outside of
each other’s IF Range but within each other’s P CS Range.
If stations are allowed to transmit data frams simultaneously, the pairwise communication relation (S1 , R1 ) can interference with (S2 , R2 ) and the pairwise communication
relation (S1 , R3 ) can also prevent R2 from receiving data
frames from S2 correctly. However, two pairwise relations
(S1 , R3 ) and (S2 , R4 ) do not interference with each other
although their IF Ranges are overlapped. To prevent the
above mentioned interference problems, in many implementations, the station will defer the transmission if it locates
within another transmitting station’s P CS Range.
As shown in (2), γ is a value that can be less than 1.
Thus, a receiver can correctly decode the signal even if a
closer interferer concurrently transmits in the same channel,
which means T X range(x) > IF Range. However in most
of the wireless systems, γ > 1. Multiple factors affect the
value of γ, such as the used modulating and coding schemes,
the sensitivity of hardware device, the number of interferers,
and the ambient noise levels, etc.

2.3 802.11b Channel Model

2.3.2 Preserving Unlinkability by Reducing the Conflict Evidence

2.3.1 Communication Range Classifications

The analysis of 802.11b’s channel model tells us that the
802.11b-based communications are confined by both timing
and spacial restrictions. In order to prevent revealing the
communication relations, the underlying MAC protocol and
channel model must provide minimal evidence to the adversaries. In many communication scenarios, the contradict
evidence can help the adversaries to narrow down the scope
of the target group. In the example shown in Figure 6, if
S1 and S2 transmit in sequence, for each transmission, the
number of potential receivers is 3. Thus, the probability to
identify a frame receiver is 1/3. If S1 and S2 transmit concurrently, we can eliminate the potential receivers R1 and
R2 since they are located within the overlapped IF Ranges.
Moreover, depending on the deployed ad-hoc routing protocol, we can infer the directions of the transmitted frames
(not via R1 and R2 in this example). Thus, we should avoid
the transmission when two stations IF Ranges are overlapped. The above discussed communication phenomena is

We assume that wireless station S transmits with rate
x ∈ {1, 2, 5.5, 11}. Station S’s communication neighbors can
be affected by S’s transmissions in a different way depending
on the distance from S and the selected transmission rate.
Based on the 802.11b channel model proposed in [2], we
classify three ranges (see Figure 6) as follows:
• Stations at a distance d < T X Range(x) are able to
correctly receive data from S, if S transmits at a rate
lower or equal to x.
• Stations at a distance d, where d < IF Range, they
share the same physical channel; however multi-station
transmissions will cause low SNR due to (1). As a
result, within the IF Range of multiple transmitters,
the receiver can only correctly demodulate frames from
3
Note that in order to keep the communication privacy, all
upper layers’ data should be encrypted.

70

similar to the systems when directional antennas are used
instead of using omnidirectional antennas. In implementations, it is a tradeoff to use directional or omnidirectional
antennas in terms of preserving unlinkability. On one hand,
directional antennas will decrease the possibilities for the adversaries to detect the source of transmitted signals; on the
other hand, once a signal source is detected, the intended
receivers are easier to be identified due to the small scope of
potential receivers.
Based on the above discussions, we conclude that if the
signal source is difficult to be identified (such as tiny objects
or concealed objects), the directional antennas are preferred;
otherwise the omnidirectional antennas are preferred. When
omnidirectional antennas are used, a safer technique is to
defer the transmission when the station is located within
the transmitting station’s P CS Range. In this way, we can
reduce the opportunities of the adversaries to detect conflicting evidence.

A

(b)

A

i
1

2
i

j

B

C

2
B

C

j

Figure 7: An example of 3 nodes Ad-hoc network.
existence of communications between two or more wireless
stations. In our following presentations, we use a toy example (shown in Figure 7) to illustrate the use of our evidence
collection approach and unlinkability measuring method.

3.1 Evidence Collection
In Figure 7(a), three wireless stations form an ad-hoc network. We assume that the wireless stations are equipped
with omnidirectional antennas. Since omnidirectional antennas are used, at location i and j, an adversary can detect
the transmissions from stations A, B, and C. At the location i and j, the adversary may detect the same data frame
sent from station A. To determine the right frame receiver,
the adversary can decide the location scope of potential receivers based on the strength of the signal, rate information,
and the distance to the sender as we have discussed in Section 2.1.3. For example, the rate zone and the detected rate
information in the PLCP field can be used to determine if
a station is a potential receiver. In our toy example, we assume that the station C is located outside of the rate zone of
the station A. We must note that the collected evidence only
represents the communication status in a given time period.
Thus, the unlinkability measure is valid only for that given
time period and it is useful to evaluate instant unlinkability
for a given communication system. In the rest of this paper, without special notation, the unlinkability measure is
confined by the time period of corresponding evidence collection.
As shown in Figure 7(b), the detected number of pointto-point frames are given as follows:

2.4 Summary of the Analysis of Point-to-point
Communication Privacy Preservation
The ultimate goal of the adversaries is to derive the endto-end transmission relations between wireless stations even
if all possible unlinkability preserving techniques are applied. In order to achieve this goal, the adversaries must understand the communication basics of the wireless systems.
Based on the analysis of physical and MAC layer protocols
in this section, we summarize the following point-to-point
unlinkability preservation methods for 802.11b protocol.
i. Location and rate control must be used to minimize
the probability presented in (4).
ii. ACK frames should be omitted. Otherwise all data
frames and ACK frames must have the same size. The
signal subtype in frame control field must be set to the
same value. Thus, adversaries cannot easily identify
the corresponding traffic direction.
iii. The fields of the source and destination addresses must
be hidden to reduce the opportunity of the adversaries
to identify the communication pairs.
iv. The virtual carrier sensing should not be applied. Thus,
the physical carrier sensing is the only way for wireless
stations to sense the channel.
v. A channel must avoid concurrently receiving frames
from multiple senders. Thus, a wireless station should
differ its transmissions when it locates with another
transmitting station’s P CS Range.
vi. Omnidirectional antennas are preferred when the wireless stations are easier to be located and identified.

Location
Appearance time sequence
# of packets
Source
Destination

i
∆t1
1
A
B

i
∆t2
2
B
A

j
∆t2
2
B
C

we then can infer the following communication relations
based on the number of detected frames and their corresponding appearance time sequence:
(i)
(ii)
(iii)
(iv)

Based on the above listed physical/MAC model, the capabilities of an outside adversary are restricted to statistical
traffic analysis when upper layers’ hop-by-hop encryption
and decryption techniques are applied. In the next section,
we present such an STA attack.

3.

(a)

A→B
B→A
B→C
A→B→C

The frame detected from source A at location i is the evidence supporting the claim (i) (since C is located outside
of A’s rate zone, we cannot derive the relation A → C); the
packets detected from source B at location i are the evidence supporting the claim (ii); the packets detected from
source B at location j are the evidence supporting the claim
(iii); from claims (i) and (iii) and their corresponding timing
information, we can deduce the evidence for claim (iv). In
order to derive the amount of the evidence for a deduced
claim, we define the following formula:

STATISTICAL TRAFFIC ANALYSIS

In this section, we present the procedure of evidence collection and an unlinkability measuring approach based on
evidence theory [17]. Our evidence collection is based on
IEEE 802.11b physical and MAC layers channel model presented in previous section. In our following analysis, a captured data frame is defined as an evidence which proves the

w(V ) = min {w(U )},
U ⊆∆t V

71

|V | ≥ 2.

(5)

Set
hA, Bi
hB, Ai
hB, Ci
hA,
P B, Ci

w(V )
1
2
2
1
6

m(V )
1/6
1/3
1/3
1/6
1

Bel(V )
1/6
1/3
1/3
2/3

C(m)
1.585 bits

Simulation area
Number of stations
Number of Communication
Pairs
Wireless card
Propagation model
Transmission Speed
T X Range
P CS Range

Table 1: Body of evidence of the example shown in
Figure 7(b).

measure when each ordered set V represents a point-to-point
one-hop communication relation. In our presented toy example, C(m) = 1.585bits, where the value of C(m) represents the average number of bits required to describe one
system anonymity state in the binary format by a given set
of probability assignments. In general, large C(m) value
means more unlinkability of a communication system.

3.3 Summary of Anonymity Measure
In this paper, we present a systematical approach to evaluate the unlinkability of IEEE 802.11b-based anonymous
communications under STA attacks. Our approach includes
three steps: (a) a evidence collection approach based on the
proposed physical/MAC communication model presented in
Section 2, (b) a statistical evidence quantifying and basic
probability generating approach, and (c) an evidence theorybased unlinkability measure. Among our proposed unlinkability measure, m(V ) represents the occurrence probability
of the claim V among all the claims; Bel(V ) represents the
evidential occurrence probability of the claim V among all
the claims; and C(m) represents the statistical evaluation
of the evidential occurrences for a communication system.
We observe that the difference between m(V ) and B(V ) is
subtle: m(V ) focuses on the occurrence of a claim while the
Bel(V ) focuses on the occurrences of the supporting evidence for the claim V . In general, a longer path requires
more evidence to support the claim. Thus, it is not necessary that the small value of m(V ) will deduce the small
value of Bel(V ). C(m) is the overall unlinkability performance evaluation that takes into the considerations of both
m(V ) and Bel(V ).

U ∈P(X)

where
X

m(V ) = 1.

V ∈P(X)

In Table 1, the values of m(V ) are computed based on (6).
It is clearly shown that (6) represents the proportion of
the evidence for a claim to all available and relevant evidence. Compared to the definitions used by the evidence
theory [17], m(V ) is indeed the basic probability assignment
for the claim defined by the ordered set V .

3.2 Measuring Unlinkability
Evidence theory (a.k.a., Dempster-Shafer theory) is an
important tool to deal with uncertainty which is best covered in a book by Shafer [17]. In this subsection, we describe
the basic representations of evidence theory and our interpretations in terms of unlinkability measure.
Given the basic probability assignment m, the corresponding belief measure is determined for all ordered sets U ⊆∆t V
by the formulas:
X
m(U ),
(7)
Bel(V ) =

4. SIMULATION ANALYSIS
4.1 Simulation Setup
We use network simulation-2 (ns2) as our simulation tools.
In our simulation, we only analyze the data frame transmission patterns. We summarize the simulation settings in
Table 2. The simulation is based on the physical channel
set up in [19] and the unlinkability adjustments (i-vi) proposed in our physical channel models (see Section 2.4). In
our simulation, we assume that no ACK messages are transmitted and we evaluate the unlinkability measure at two extreme scenarios: the transmission rate is at (a) the maximal
transmission rate (11Mpbs), or (b) the minimal transmission rate (1Mpbs). We randomly choose 10 wireless stations
and deploy them in a 500×500m2 simulation area. 5 end-toend pairs (h0, 1ih2, 3ih3, 4ih8, 7ih9, 6i) are randomly chosen
to transmit CBR traffic with the rate of 11Mbps.

U |U ⊆∆t V

where,

Orinoco 11b card (omnidirectional)
TwoRayGround
(CBR)11Mbps
160m (Rev. sensitivity -82dBm)
550m (Rev. sensitivity -94dBm)

Table 2: Simulation Setup.

In (5), w(V ) represents the evidence for the set V ∈ P(X);
X is a universal set containing all wireless stations within a
system and P(X) denotes the power set of X, i.e., all subsets
of X. We note that the set V is an ordered set (denoted by
sign h·i), where the elements of set V are formed by the operator ⊆∆t on all potential subsets U and it operates on all
subset evidence following a given time sequence. In Table 1,
the values of w(V ) are computed based on (5). In particular, w(hA, B, Ci) = min∆t1 ,∆t2 {w(hA, Bi), w(hB, Ci)}. The
use of (5) is intuitive, since we use the assumption that the
capacity of a multi-hop path is confined by its minimal capacity hop.
We define the normalized value m(V ) as follows:
X
w(U ),
(6)
m(V ) = w(V )/
m : P(X) → [0, 1], m(∅) = 0, and

500 × 500m2
10
5: (h0, 1ih2, 3ih3, 4ih8, 7ih9, 6i)

Bel : P(X) → [0, 1].

The Bel(V ) denotes the the possibility that a wireless station in X involves in an acting relation (i.e., a frame delivering path) defined in an ordered set V . In Table 1, we
present the values of belief measure for the example given
in Figure 7(b). In particular, Bel(hA, B, Ci) = m(hA, Bi) +
m(hB, Ci) + m(hA, B, Ci), which represents the probability
that an evidence supports the claim of path A → B → C
during the time period ∆t = ∆t1 + ∆t2 .
The expected unlinkability measure on all available evidence can be evaluated in the following formula:
X
m(V ) log2 Bel(V )
(8)
C(m) = −

4.2 Simulation Results

V

During the simulation, 8 stations are detected transmitting data frames (they are 0,1,2,3,6,7,8,9) during a 40-second

We notice that (8) will be reduced to Shannon information
72

Potential immediate receivers

9
7

8

8

7

7

9
8

6

6

All possible direct communication pairs

TX_Range<160m

6

5

5
4

3

3

3

3

3

1

1

1

0

0

2
1
0
0

1

2

3

4

5

6

7

8

9

10

28
27
26
25
24
23
22
21
20
19
18
17
16
15
14
13
12
11
10
9
8
7
6
5
4
3
2
1
0
0

0.5

Source nodes

]

V

w(V )

#

V

h0, 1i
394
10
h3, 0i
h0, 3i
394
11
h3, 1i
h0, 5i
394
12
h3, 6i
h0, 7i
394
13
h3, 7i
h1, 0i
400
14
h3, 8i
h1, 3i
400
15
h6, 2i
h1, 7i
400
16
h6, 3i
h1, 8i
400
17
h6, 9i
h2, 6i
401
18
h7, 0i
Highlights are real communication

w(V )

#

V

w(V )

405
405
405
405
405
401
401
401
405
pairs.

19
20
21
22
23
24
25
26
27

h7, 1i
h7, 3i
h7, 4i
h7, 5i
h8, 1i
h8, 3i
h8, 9i
h9, 6i
h9, 8i

405
405
405
405
400
400
400
394
394

Table 3, presents the collected evidence that we can utilize
to analyze the communication unlinkability. We can use (7)
and (8) to evaluate the unlinkability for each communication pairs or the entire system. For demonstration purpose,
we only present a detailed unlinkability evaluation for a particular wireless station 0. Note that the body of evidence
created here is different from the toy example presented in
previous section. Here, we are interested in the evidence for
a particular communication relation, i.e., the end-to-end relations from station 0 to station 1. If each node transmits at
the maximal rate, based on Table 3 and using (5) and (6), we
can derive the probability assignments for 7 available paths
as follows:
m(V )
1/19
2/19
3/19
2/19
3/19
3/19
5/19

Bel(V )
1/19
3/19
8/19
3/19
6/19
6/19
11/19

2.5

In our unlinkability evaluation, m(V ) stands for the probability that an evidence supports the end-to-end communication from 0 to 1 which is using path V ; the belief unlinkability measure Bel(V ) is the accumulative evidence that
supports the claim of path V ; the complexity to describe
an anonymity state from all possible paths from station 0
to station 1 is 1.714bits. If a node transmits at the minimal rate, all other nodes are potential receivers and forwarders. In general, the number of possible `paths
´ from 0
6
to 1 with k-hop (we define k = |V | − 1) is k−1
(k − 1)!
(note that we have only 6 nodes transmit data except 0
and 1). Thus, the total number of paths increases from 7
to 1597 compared to the scenario when the maximal transmission rate is used. Since the number of the evidence collected from each source is almost identical (see Table 3),
we can use the length of a path toPestimate
` 6 ´its probability assignment: m(V ) ≈ (|V | − 1)/( 7k=1 k−1
(k − 1)! · k),
where |V | ≥ 2. Based on the inclusive relations among different paths, we can derive the belief measure for a path
P|V |−1 ` |−2´
Bel(V ) = k=1 |Vk−1
· mk+1 , where mk+1 stands for the
probability assignment for a path with the length of k + 1
and |V | ≥ 2. Due to page limits, we omit the proofs of
the above presented equations. Finally, using (8), we can
derive C(m) = 6.5243 (the measure of unlinkability is increased 28 times comparing to the maximum rate case where
C(m) =1.714 bits). Based on the above analysis, we conclude that in the scenario when the minimal transmission
rate is used by each wireless station, the wireless system exhibits the best unlinkable performance; on the contrary, the
worst unlinkable performance is shown when the maximal
transmission rate is used by each wireless station.

Table 3: Direct evidence collection from the simulation for ∆t = 40s (with maximal transmission rate).

Path V
h0, 1i
h0, 3, 1i
h0, 3, 7, 1i
h0, 7, 1i
h0, 7, 3, 1i
h0, 3, 8, 1i
h0, 3, 6, 9, 8, 1i

2

Figure 9: Frame transmission pattern of all potential
direct communication pairs (with maximal transmission rate).

time period (dots represent the transmitted frames and lines
demonstrate the frames transmission sequence). According
to the distance between each pair of nodes and the transmission rate zone, when every node transmits at the maximal
rate, we derive the potential sender-receiver relations in Figure 8. Thus, the original 8 sender-receiver relations (highlighted in Table 3) are expanded to 27 sender-receiver relations shown in Figure 9 (the numbers on y-axis are mapped
to the communication pairs given in Table 3) due to the locations of wireless stations and the physical channel model
of the wireless system. When each node transmits at the
minimal rate, all nodes in the system are potential next-hop
receivers since the distance between any pair is less than
1Mbps rate zone scope (i.e., 550m).

1
2
3
4
5
6
7
8
9

1.5

Time

Figure 8: Source nodes and their potential immediate frame receivers (with maximal transmission
rate).

#

1

5. CONCLUSION
In this paper, we analyzed the communication properties of wireless systems using IEEE 802.11b standards. We
presented an unlinkability measuring approach based on evidence theory. In our approach, an evidence is a concrete
measure of a number of detected frames within a given time
period and it serves as the basic element to set up our unlinkability measuring mechanism. Our approach is more general
comparing to the traditional Shannon information theorybased solutions, where the unlinkability measure is based
on the use of predefined probability assignments. Moreover,
our evidence-based solutions are able to deal with set involvement inferences by using belief measure.
We initiated the research of unlinkability measurements

C(m)

1.714bits

73

by applying evidence theory. In our study, we have the following observations which can guide us in the unlinkability
research area:

[5] J. del Prado Pavon and S. Choi. Link adaptation
strategy for ieee 802.11 wlan via received signal
strength measurement. In Proceedings of ICC, 2003.
[6] C. Dı́az, S. Seys, J. Claessens, and B. Preneel.
Towards measuring anonymity. In R. Dingledine and
P. Syverson, editors, Proceedings of Privacy
Enhancing Technologies Workshop (PET 2002).
Springer-Verlag, LNCS 2482, April 2002.
[7] M. Gruteser and D. Grunwald. Enhancing location
privacy in wireless lan through disposable interface
identifiers: a quantitative analysis. In Proceedings of
the 1st ACM international workshop on Wireless
mobile applications and services on WLAN hotspots,
2003.
[8] P. Gupta and P. R. Kumar. The capacity of wireless
networks. IEEE Transactions on Information Theory,
46(2), March 2000.
[9] I. Haratcherev, J. Taal, K. Langendoen, R. Lagendijk,
and H. Sips. Automatic IEEE 802.11 rate control for
streaming applications. In WIRELESS
COMMUNICATIONS AND MOBILE COMPUTING,
2005.
[10] IEEE Standard 802.11. Wireless lan medium access
control (MAC) and physical layer (PHY)
specifications, 1999.
[11] J. Kong and X. Hong. ANODR:ANonymous On
Demand Routing with Untraceable Routes for Mobile
Ad-hoc Networks. In ACM MobiHoc, 2003.
[12] J. Li, J. Jannotti, D. S. J. D. Couto, D. R. Karger,
and R. Morris. A scalable location service for
geographic ad hoc routing. In ACM Mobicom, 2000.
[13] A. Muqattash, M. Krunz, and W. E. Ryan. Solving
the near-far problem in CDMA-based ad hoc
networks. Ad Hoc Networks, 1(4):435–453, 2003.
[14] Reiter and A. D. Rubin. Crowds: Anonymity for web
transactions. Communications of the ACM,
42(2):32–48, 1999.
[15] A. Serjantov and G. Danezis. Towards an information
theoretic metric for anonymity. In R. Dingledine and
P. Syverson, editors, Proceedings of Privacy
Enhancing Technologies Workshop (PET 2002).
Springer-Verlag, LNCS 2482, April 2002.
[16] S. Seys and B. Preneel. ARM: Anonymous routing
protocol for mobile ad hoc networks. In Proceedings of
of the 20th IEEE International Conference on
Advanced Information Networking and Applications Workshops (AINA 2006 Workshops), 2006.
[17] G. Shafer. A Mathematical Theory of Evidence.
Princeton University Press, 1976.
[18] G. Tóth, Z. Hornák, and F. Vajda. Measuring
anonymity revisited. In S. Liimatainen and
T. Virtanen, editors, Proceedings of the Ninth Nordic
Workshop on Secure IT Systems, pages 85–90, Espoo,
Finland, November 2004.
[19] W. Xiuchao. Simulate 802.11b channel within ns2.
http://www.comp.nus.edu.sg/∼ wuxiucha/research/
reactive/report/80211ChannelinNS2 new.pdf.
[20] Y. Zhang, W. Liu, and W. Lou. Anonymous
communications in mobile ad hoc networks. In
Proceedings of IEEE Information Communications
Conference (INFOCOM), March 2005.

• Evidence theory is a generalized information theory
that can be reduced to Shannon information theory
under a certain circumstance. Comparing to Shannon
information theory, evidence theory must rely on a well
founded evidence collection mechanism in order to correctly conduct unlinkability evaluation. In communication systems, this requirement means that the evaluator must understand the mechanism/infrastructure
of the evaluating system and clearly define what is the
evidence and how accurate the evidence can be collected. Due to different communication circumstances
(such as protocols, hardware devices, etc.), the evidence collection must use different measuring and collecting standards and methods .
• In addition to the number of captured data frames,
evidence has broader meanings, such as timing, mobility, etc. We need to exploit more on different types of
evidence.
• The states of an anonymous communication system
can be explosive when the number of stations increases
and the corresponding point-to-point relations are complicated. We must device an efficient approximative
approach to analyze the evidence collected from the
large-scale communication systems.
• Finally, existing MANET anonymous communication
system designs target at defending both active and
passive traffic analysis attacks; however, the effectiveness of such security designs under various MANET
QoS requirements is usually overlooked. To address
this problem, we need to investigate security solutions
using a cross-layer design approach that evaluates crosslayer MANET functions to fulfill desired security as
well as service performance requirements.

ACKNOWLEDGEMENT
Thanks to Sean Williams for helping me to set up the initial simulation environment. In particular, the author appreciates the valuable suggestions from reviews in order to
improve the quality of this paper.

6.

REFERENCES

[1] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and
E. Cayirci. A survey on sensor networks. IEEE
Communications Magazine, 40:102 – 114, August
2002.
[2] G. Anastasi, E. Borgia, M. Conti, and E. Gregori.
Wi-Fi in ad hoc mode: A measurement study. In
Proceedings of IEEE Annual Copnference on Pervasive
Computing and Communications (PERCOM), 2004.
[3] A. Boukerche, K. El-Khatib, L. Xu, and L. Korba. A
novel solution for achieving anonymity in wireless ad
hoc networks. In Proceedings of the 1st ACM
international workshop on Performance evaluation of
wireless ad hoc, sensor, and ubiquitous networks, 2004.
[4] D. Chaum. Untraceable electronic mail, return
addresses, and digital pseudonyms. Communications
of the ACM, 24:84–88, 1981.
74

SeRViTR: A Framework for Trust and Policy
Management for a Secure Internet and Its
Proof-of-Concept Implementation
Xuan Liu1 , Akira Wada2 , Tianyi Xing3 , Parikshit Juluri1 , Yasuhiro Sato4 ,
Shingo Ata2 , Dijiang Huang3 , Deep Medhi1
1 University of Missouri–Kansas City, USA, 2 Osaka City University, Japan, 3 Arizona State University, USA,
4 Japan Coast Guard Academy, Japan

Abstract—A secure network is considered to be an important
goal of the Future Internet; one way this can be embodied is by
having ﬂexible and robust routing functionalities with intrinsic
security mechanisms. It is also desirable to provide user-centric
or service-centric routing capabilities to achieve service-oriented
trafﬁc controls as well as trust and policy management for
security. Based on these potential needs, a ﬂexible, scalable,
and robust routing framework that enables ﬁne-grained ﬂow
control under ﬁxed or dynamic policies called the Virtual
Trusted Routing and Provisioning Domain (VTRouPD) [11] has
been recently proposed. In this paper, we present a framework
called the Secure and Resilient Virtual Trust Routing (SeRViTR)
framework, which is a proof-of-concept model of VTRouPD
at the implementation level. SeRViTR has particular entities
that are designed for policy management and trust management
between different VTRouPDs to enable a secure Internet. We
deﬁne the roles of each entity within the SeRViTR framework as
well as the messages exchanged between them. We also discuss
how policy management and trust negotiation can be achieved.
Moreover, we present validation on the functional implementation
of several SeRViTR components to illustrate how to create virtual
domains and change of trust levels between virtual domains.
Index Terms—Secure routing, virtualization, policy and trust
management.

I. I NTRODUCTION
One of the factors that has led to the success of the
current Internet is its flexible and robust routing functionality. However, with the rapid growth of the Internet, many
issues have risen that cannot be solved by a plain routing
capability. One of the major problems is in regard to network
trustworthiness. Currently, the Internet lacks trustworthiness at
the network level as a fundamental function. There are often
ad hoc approaches to thwart attack traffic injected by malicious
users. It is also difficult to protect the leakage of confidential
information to untrusted users. As a result, even though the
Internet has become a critical infrastructure for society, users
remain concerned about the safety of the Internet. End users
are still required to have a deeper knowledge regarding the
security for protecting their own communication.
In general, the current Internet has a limited capability of trustworthiness. For example, a secure tunnel (e.g.,
IPSec [13] [14]) is established to exchange the routing information, or access control lists are used for filtering traffic from unreliable networks by adding network prefixes to

their blacklist. An approach such as IPSec is a point-topoint approach, rather than being a network-wide solution.
From a routing standpoint, the current Internet provides a
simple and network-centric packet forwarding function by
only referring the destination address of the packet where
packets are forwarded in the shortest-path manner. However,
in the Future Internet, it is strongly desirable to have user- or
service-centric routing capabilities to achieve service-oriented
traffic controls. Additionally, in the Future Internet, to handle
various network services’ flexibilities and dynamics, routing
is required to be more flexible, and have fine-grained flow
controls based on a policy, while addressing trustworthiness.
Based on the above-mentioned background, a flexible, scalable, and robust routing framework that enables fine-grained
flow control under fixed or dynamic policies called Virtual
Trusted Routing and Provisioning Domain (VTRouPD) [11]
has been recently proposed. A VTRouPD is constructed by
a collection of networking resources including routers and
switches based on virtualization techniques; e.g., constructing virtual managed domains through tunneling and VLAN
technologies. Within one or spanning mulitple VTRouPDs,
we can further create user-centric virtual routing domains
that are denoted as 𝜇VTRouPDs. To realize VTRouPDs and
𝜇VTRouPDs, there are many technical issues to be solved.
First, to support flexible traffic control according to various
service or user requirements, diversification of routing functionality is mandatory instead of the unified routing strategy
(i.e., shortest path forwarding) used in the current Internet. For
this, the network should be virtualized and sliced according to
control policies in place that change dynamically. Delivery
of critical traffic should be especially secured by using an
isolated slice from other traffic and controlled independently.
Second, the integrated routing framework should support both
user- or service-centric traffic controls, and provide secured
communication with differentiated security requirements.
In this paper, we present a framework called the Secure
and Resilient Virtual Trust Routing (SeRViTR) framework,
which is a proof-of-concept model of VTRouPD at the
implementation level. We first discuss the trustworthiness,
which SeRViTR focuses on, and then we describe our design
and implementation model of SeRViTR, by enumerating key

c 2012 IEEE
978-1-4673-0269-2/12/$31.00 ⃝

1159

components.
The paper is organized as follows: we first describe related
works in Section II, then clarify the routing with trustworthiness in Section III. Our design model of SeRViTR with
descriptions on detailed operations of key components is
presented in Section IV and Section V. We next discuss the
implementation issues in Section VI. Finally, we conclude this
paper with future research topics in Section VII.

9 Content-awareness risk management/Intrusion detection and response.
9 Isolation: resource, information flow, services, software, and applications
9 Mobile routing: provide a reliable and survivable automatic routing platform for future trustworthy
network routing.

Routing Services Provisioning
RSN

RSN

RSN

RSN

NM

NM

NM

NM

­VTRouPD j
­VTRouPD k

II. R ELATED W ORK
Network virtualization research has been active in recent
years. A recent survey [10] states network virtualization may
occur at four different layers: the physical layer, link layer,
network layer, and application layer. In particular, PlanetLab [3] is an application-layer virtualization while VINI [5]
and VNET [6] are network and link-layer virtualizations,
respectively. In [9], network virtualization in GpENI [16] was
presented that uses the VINI framework. With virtualization
techniques, various new services arise such as network management and resource management. In [8], a programmable
hardware platform to construct virtual data planes that focus on
hardware implementation was presented. In [17], the authors
presented VROOM (Virtual ROuters On the Move), which is
a new network-management primitive that avoids unnecessary
changes to the logical topology by allowing (virtual) routers
to freely move from one physical node to another. The work
presented in [12] focuses on the accountability in a virtualized
hosting environment. [15] introduces a policy-based resource
management function into a virtual network environment
based on a two-phase resource distributive model. Being
a virtual laboratory, the Global Environment for Network
Innovations (GENI)[1] is an open and large-scale experimental
environment for researchers to collaborate and explore future
networks. GENI enables the network to be sliceable so that
users can share resources and achieve isolations. Although
there are several projects joining GENI such as OpenFlow[2]
and ProtoGENI[4], there is not much work on policy or
trust management in such network virtualization environments,
especially one that focuses on secure routing.
Our approach is different than the above. Our goal is to build
multiple virtualized routing domains through a comprehensive
approach by using logical virtual routers to partition the physical networking environment into multiple virtual networks,
while having trustworthiness an an intrinsic property. We provide a fine-grained virtualization for user-centric networking
services by allowing to set a secure policy. Furthermore, we
also design a mechanism to dynamically negotiate trust levels
between domains.
III. ROUTING M ODEL WITH I NTEGRATED
T RUSTWORTHINESS
Trustworthiness is a fundamental criterion of routing in
SeRViTR. We start with our perspective on trustworthiness that
is used in the context of SeRViTR. Trustworthiness needed to
be realized for a trustable network in the Future Internet may

1160

Trust
Management
Service (TMS)

­VTRouPD i

Virtualization
Resource/Application
Manager (RAM)

Programmable
Router

Network Router Cloud

Fig. 1.

Virtual Trust
Routing and
Provisioning
Domain
(VTRouPD)
Manager

Notation:
RSN: Routing Service Node
Direct link or control
Indirect link or control

SeRViTR: The Basic Concept

vary based on different viewpoints from end users, to network
operators, or to service providers, as follows.
∙ From the viewpoint of users, trustworthiness of communication is based on the degree to which users can
trust a communication peer. Generally, trustworthiness
is often related to the importance of the information to
be communicated. For example, none of the end users
may like the situation when their private information is
delivered over the untrusted network. To achieve this,
the network should be isolated based on the degree of
trustworthiness, and the communications in the lower
trustworthiness network should be more restricted.
∙ From the viewpoint of the network, trustworthiness of the
network is determined by the condition in which routing
in the network is secured and safe. That is, any routing information (e.g., routing table exchanges, signalling traffic,
MIB, etc.) must be confidential, secured, and protected.
∙ From the viewpoint of service providers, trustworthiness
of services is the situation that the service is protected,
secured, and exclusive of anonymous users. Not only
users, but also paths to users, might need to be managed
by a service provider.
To realize the above stated diverse needs in regard to trustworthiness, adding a special routing layer is not sufficient. A
network should have the capability to be sliced, isolated from
each other, managed by an integrated security policy, and a
secure routing protocol along with flexible traffic engineering.
Our aim with SeRViTR is to show a viable proof-of-concept
model to achieve these goals.
IV. S E RV I TR: OVERVIEW, M ODELS AND S PECIFICATION
A. Using SeRViTR to Realize VTRouPD
In [11], VTRouPD was proposed as a new conceptual model
supporting the following features: (a) multiple routing domains
can be constructed based on services under different trust
levels, (b) trust levels are pre-calculated at the network level
in order to handle security between routing domains, (c) the

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

TABLE I
VTROU PD C OMPONENTS WITH ROLE D ESCRIPTIONS
VTRouPD Component
VTRouPD

Role
Managed Domain

𝜇VTRouPD

Virtual Domain (intra)
Virtual Domain (spanning)

Trust
Management
(TMS)

Service

VTRouPD Manager
Routing Service Node
Resource Application Manager
(RAM)

Authentication Server
Policy Manager
Trust Level Regulator
Domain Controller
Virtual Router

Description
Physical Topology and Virtual Domain used as the scope of Policy which
Administrator inputs
The sub-domain which consists of virtual routers under a particular routing
policy in a single VTRouPD
The sub-domain spanning multiple VTRouPDs consists of virtual routers
under a particular policy, i.e., if 𝜇 is a 𝜇VTrouPD, and 𝑉𝑖 and 𝑉𝑗 and two
VTRouPDs that 𝜇 spans, then 𝜇 ⊆ 𝑉𝑖 ∪ 𝑉𝑗 , 𝜇 ⊈ 𝑉𝑖 , 𝜇 ⊈ 𝑉𝑗
Generating and distributing authentication information to Policy Manager
Invoking 𝜇VTRouPD creation/deletion by providing policy management
Trust level negotiation between multiple VTRouPDs
Creating 𝜇VTRouPDs based on the policy
Physical routers where virtual router instances can be created on physical
machines.

Resource management

TABLE II
T ERMS U SED IN THE M ESSAGE T YPES

entry points have the capability to authorize and/or control
traffic when necessary.

Term
VirtualDomainID

Typically, from a system’s perspective, traffic management
and network resource management components are necessary
for monitoring and managing a network. There are three
components involved to achieve this purpose, as presented in
Fig. 1: Trust Management Service (TMS), VTRouPD Manager, and Resource and Application Manager (RAM). Every
physical router that belongs to a VTRouPD has complete
routing information of its own VTRouPD, and we name it
the Routing Service Node (RSN). In each VTRouPD, one or
multiple router instances, or virtual routers, are loaded at every
RSN. The VTRouPD Manager is in charge of sub-domain
creation/deletion/updating, while TMS is the Trust Authority
(TA) for the system. TMS manages the secure routing from
two aspects. On one hand, it handles the cryptographic key
and parameter distribution and revocation. On the other hand,
it also provides identity search, federation services for multiple administrative domains, policy checking and enforcement
functions. Hence, identity and federation services for physical nodes belonging to multiple administrative domains are
supported.
The conceptual VTRouPD model in [11] was proposed from
the perspective of a high-level design. In order to realize the
concept described in the VTRouPD model, we have designed a
comprehensive architecture called Secure and Resilient Virtual
Trust Routing (SeRViTR) that crystallizes the components
defined in the VTRouPD model. In this work, we design
functional components at the implementation level to realize
the roles of TMS and VTRouPD Manager. We also define the
exchanging messages for the communication between these
functional components. Table I presents the VTRouPD components and their roles in the SeRViTR framework, and Table II
summarizes the terminologies for the key fields defined in the
message types. These notations will be used through the rest
of the paper. In the following subsections, we illustrate the
message types and SeRViTR components successively.

RSNID
FlowID
ActionID
Trust
TrustID
OutboundDomainID

Description
The identifier for identifying the Virtual Domain
The identifier for identifying the Routing
Service Node
The identifier for identifying flow
The identifier for kinds of processes
Trustworthiness of flow
The identifier for identifying Trust
The identifier used for communication between different VTRouPDs

B. SeRViTR Message Types
When proposing VTRouPD, it was identified that the Trust
Management Service (TMS) should be responsible for two
tasks. In this paper, we further elaborate the TMS by assigning
it three different roles: Authentication Server, Policy Manager,
and Trust Level Regulator, which are discussed in Section IV.
In Fig. 2, the Policy Manager communicates with every other
individual SeRViTR component. In order to implement policy
management, we introduce four message types with their
packet formats. They are the main information exchanged
between the Policy Manager and other SeRViTR components
when setting up routing policies or negotiating trust levels
between VTRouPDs.
1) Virtual Domain Management Message: The Virtual Domain Management Message is exchanged between the Policy
Manager and VTRouPD Manager to manage Virtual Domain s.
The packet format for the Virtual Domain Management message is shown in Fig. 3(a). It has a field to indicate action
(Create (C) / Modify (M) / Delete (D) / Reply (R)) to be taken
by the Virtual Domain along with the list of Routing Service
Node ’s identifiers and the VirtualDomainID. Any resource to
be assigned to the Virtual Domain is also indicated.
2) Flow Table Update Message: A Flow Table Update
Message is for communication between the Policy Manager
and Flow Controller to update the flow table at the Flow
Controller. The packet format for the Flow Table Update
message is shown in Fig. 3(b). It carries the TrustID and

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

1161

VTRouPD A

VTRouPD B

ForwardingID (VlanID)
ForwardingID
(VlanID)
Flow
Controller

Host

Virtual Domain

Virtual Domain

1
OutboundDomainID

Flow
Controller

2
Flow
Controller

3

Flow
Controller
Host

Administrator

FlowID

Physical Topology

Physical Topology

RSN

RSN

VTRouPD
Manager
Traffic Monitor

Authentication
Manager

Policy
Manager

Traffic
Monitor

VTRouPD
Manager

Trust Level
Regulator

Trust Level
Regulator

Trust Management Service (TMS) at VTRouPD A

Policy
Manager

Authentication
Manager

Trust Management Service (TMS) at VTRouPD B

Fig. 2.

SeRViTR: Architectural Overview

ActionID, along with the FlowID. In particular, the FlowID
is the identifier of the input flow and the ActionID specifies
the action that can be the Attach/Strap/Modify ForwardingID
or Encrypt/Decrypt flows. Here, in order to identify packets
associated with a flow, marked by FlowID, we use OpenFlow
Switch Specification v1.1[7], in which we define a 256-bit field
for FlowID. The information content of FlowID is shown in
Table III.
3) Routing Table Update Message: A Routing Table Update
Message is communicated between the Policy Manager and
Routing Service Node s for routing table updates. The packet
format for a Routing Table Update message is shown in
Fig. 3(c). It carries the ActionID along with an input/output
port and Forwarding ID for input and output packets.
4) Outbound Domain ID Notiﬁcation: The Outbound Domain ID Notification is exchanged between the Policy Manager and Trust Level Regulator for trust negotiation among
VTRouPDs. The packet format for Outbound Domain ID
Notification is shown in Fig. 3(d). It has a field to indicate any
priority for an OutboundDomainID, along with the OutboundDomainID and Forwarding ID for input and output packets.

(a) Virtual Domain Management message

(b) Flow Table Update message

(c) Routing Table update message

TABLE III
F LOW ID: I NFORMATION C ONTENT
Input Port (8)
VLAN ID (16)
IP ToS (8)
Source IP Address (32)
Source MAC Address (48)
Source Port Number (16)

HostID

HostID

FlowID

4

Ethernet Frame Type (16)
VLAN Priority (8)
Protocol Number (8)
Destination IP Address (32)
Destination MAC Address (48)
Destination Port Number (16)

(d) Outbound Domain ID Notification
Fig. 3.

Message Type and Corresponding Packet Format

C. SeRViTR Components
Table I shows the equivalent relationship between
VTRouPD and SeRViTR components. In this part, we will
illustrate the role of each SeRViTR components, and the
interactive relation between each other.
1) VTRouPD: A VTRouPD is the domain with administrative control. Within a VTRouPD, there can be multiple Virtual
Domains, each being identified by a VirtualDomainID.

1162

2) 𝜇VTRouPD: A 𝜇VTRouPD is a user-centric virtual
routing domain that spans VTRouPDs. A 𝜇VTRouPD can
operate at the flow-level, where the flow is recognized by
assigning security policies. A VTRouPD may contain multiple
𝜇VTRouPDs. If there is only one VTRouPD between the
source and the destination, then a 𝜇VTRouPD is also a Virtual

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

Domain, or sub-domain, inside the VTRouPD. However, If
there are multiple VTRouPDs between the source and the
destination, a 𝜇VTRouPD represents the whole virtual routing
domain that spans different VTRouPDs. In other words, the
𝜇VTRouPD, in this case, spans multiple Virtual Domain s.
3) Policy Manager: A Policy Manager is associated with
each VTRouPD, and the role of the Policy Manager is manyfold:
∙ It invokes policies that are assigned by the Administrator
∙ It is in charge of policy management. We use XACML
(eXtensible Access Control Markup Language) to describe the rules, and each rule is identified by <FlowID,
Trust>. In order to ensure security, we use a unique 16bit integer to identify the Trust based on the policy
∙ It announces the request of creation or deletion of Virtual
Domains to the VTRouPD Manager. When a new TrustID
is obtained, the Policy Manager will generate the request
and send it to the VTRouPD Manager through the Virtual
Domain Management Message (Fig 3(a))
∙ It sends a Flow Table Update Message (Fig 3(b)) to the
Flow Controller that manages the flow table, informing
how incoming packets (flows) should be processed at the
Flow Controller
∙ It plays a role in negotiating the trust level between
managed domains. To do so, it creates an OutboundDomainID, and communicates with the Trust Level Regulator about the Outbound Domain ID Notification.
The Policy Manager maintains three tables, the Rule-set Table,
the Trust-level Table, and the Virtual Domain Table. The
operation of the Policy Manager is depicted in Fig 4
4) Trust Level Regulator: The Trust Level Regulator behaves as a trust gateway in each VTRouPD, through which
the trust level is established, changed, and updated between
two VTRouPDs. It relays the Outbound Domain ID notification
that is sent from the Policy Manager to other VTRouPD ’s
Trust Level Regulator s.
5) Authentication Server: The Authentication Server is responsible for the generation and distribution of authentication
keys, and it manages the HostID and Secret, where the HostID
indicates an IP address or a user name, and Secret is the
password or certificate.
6) VTRouPD Manager: A VTRouPD Manager manages
the information of physical routers within the VTRouPD
and it is responsible for the creation or deletion of the
VirtualDomainID, as well as resource management in terms
of resource information from Routing Service Node s. The
VTRouPD Manager maintains a Virtual Domain Management
Table that stores information of the Virtual Domain s, the
RSNID s and the Resource Information. In order to create
Virtual Domain s, the VTRouPD Manager assigns a VirtualDomainID, and inserts it into the Virtual Domain Management
Table. Similarly, in order to delete a Virtual Domain, the
VTRouPD Manager takes the entry off from the Virtual
Domain Management Table. For the resource management,
the VTRouPD Manager obtains resource information such as
bandwidth from the Routing Service Node. The VTRouPD

Fig. 4.

Operations of Policy Manager

Manager sends the Routing Table Update Message (Fig 3(c))
to the Routing Service Node to update its routing table.
Particularly, the ForwardingID is set as the VlanID in our
implementation. For clarity, we use the VlanID in the rest of
this paper.
7) Routing Service Node: A Routing Service Node is a
physical programmable router within the VTRouPD, and it is
in charge of forwarding packets to a specific Virtual Domain.
A Routing Service Node forwards packets to the next or Flow
Controller by modifying VlanID denoted in the routing table.
8) Flow Controller: The Flow Controller is the new component we added in SeRViTR, and it is placed at the edge of
the VTRouPD. A Flow Controller forwards flows to appropriate Virtual Domains based on a given policy. For any outgoing
packet, the VlanID is removed from a data packet; while for
any incoming packet, a VlanID is attached according to the
Flow Table. Also, a Flow Controller encrypts the incoming
packet and decrypts the outgoing packet according to the flow
table. The Flow Controller updates the flow table based on the
Flow Table Update Message.
9) Trafﬁc Monitor: The Traffic Monitor is used to monitor
anomaly behaviors of the flows at the ingress routers. If
anomaly traffic is detected, it informs the flow information to
the Trust Level Regulator. We assume that there is a separate
engine for identifying anomaly traffic.
V. P OLICY AND T RUST M ANAGEMENT IN S E RV I TR
We now present the enabling techniques to establish
VTRouPDs that use a systematic approach. We start with
a description of research challenges in the policy and trust
management, then we will discuss our method.
A. Challenges for Policy and Trust Management
To establish VTRouPDs, we require network routers to be
programmable, i.e., we should be able to create multiple virtual
routers (VRs) on the same physical router and each VR is
responsible for a particular Virtual Domain. However, there is

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

1163

Policy
Manager

Administrator

a certain roadblock since the router’s hardware configuration
restricts the number of Virtual Domain s on each router. Secondly, using the routing function alone, virtualization cannot
fully meet the requirement of merging traffic from two Virtual
Domain s at the edge of one VTRouPD and send it to another.
To address these issues, a flexible and lightweight virtual
routing policy management and enforcement mechanism is
required. On the other hand, the trust management is independently managed in different VTRouPD s. Hence, different
administrative domains can have different compositions of
VTRouPD s. To federate the trust management among the
VTRouPD s created by different administrative domains, we
need to construct a trust negotiation system to address the
incurred inconsistency and incompatibility issues.
The second critical trust management issue is how to initiate
trust among routers (and virtual routers). To address this, a
reputation based approach can be used. Trust Management
Service, which involves the Trust Level Regulator and the
Policy Manager, can collect feedback from the system to rank
the trust of a router, Virtual Domain, and the VTRouPD,
and in turn they can calculate trust ranking, and provide a
recommended trust level for the corresponding party as the
initial trust level. The trust level can be measured using metrics
such as, percentage of good traffic transited, reliability of the
routing system, trust levels of ingress and egress neighboring
domains, etc.
B. Trust Management Service Sequence Diagram
Considering the challenges above, we propose our methods.
In the following, we present sequence diagrams for a number
of situations of VTRouPD Trust Management Services.
1) Policy Setting: Policy setting involves a series of steps,
including creating Virtual Domain s, and updating routing
tables and flow tables. The sequence diagram for policy
setting is shown in Fig. 5. As we can see from this figure,
the Administrator inputs a policy, and on receiving this, the
Policy Manager assigns a FlowID and unique TrustID. As we
mentioned earlier, once the Policy Manager sets the TrustID
and there is no VirtualDomainID that corresponds to the
TrustID in the Virtual Domain Table at the Policy Manager, it
will generate and send a request to create a Virtual Domain to
the VTRouPD Manager through the Virtual Domain Management Message. In turn, the VTRouPD Manager will assign
the VirtualDomainID that is used for updating the Virtual
Domain Management Table, and sends Routing Table Update
Message s to the Routing Service Node s. The Routing Service
Node replies with an Update Complete Notification and the
VTRouPD Manager sends a response back to the Policy
Manager. Next, the Policy Manager sends the Flow Table
Update Message to the Flow Controller that responds with an
Update Complete Notification to indicate that it has already
updated the routing policies. At last, the Policy Manager will
notify the Administrator that the policy setting is completed.
2) Outbound Trust Level Notiﬁcation: Two VTRouPD s can
negotiate trust levels through their own Trust Level Regulator s.
The sequence diagram for outbound trust level notification

1164

㻵㼚 㼜 㼡 㼠㻌㻼㼛 㼘㼕㼏㼥

Domain
Controller

Flow
Controller

Virtual Router

Generation of FlowID
㼍㼚 㼐 㻌TrustID
FlowID, TrustID
㼂㼕㼞㼠㼡 㼍㼘㻌㻰 㼛 㼙 㼍㼕㼚
㻹 㼍㼚 㼍㼓 㼑㼙 㼑㼚 㼠㻌㻹 㼑㼟㼟㼍㼓 㼑
㻔㻲㼘㼍㼓 㻦㻌㻯㻕

Generation of
VirtualDomainID
VirtualDomainID
㻾 㼛 㼡 㼠㼕㼚 㼓 㻌㻱㼚 㼠㼞㼥㻌㼁 㼜 㼐 㼍㼠㼑㻌㻹 㼑㼟㼟㼍㼓 㼑
䠄 㻵㼚 㻛㻻㼡 㼠㻌VLAN ID, In/Out Port, ActionID䠅

㼂㼕㼞㼠㼡 㼍㼘㻌㻰 㼛 㼙 㼍㼕㼚
㻹 㼍㼚 㼍㼓 㼑㼙 㼑㼚 㼠㻌㻹 㼑㼟㼟㼍㼓 㼑

㼁 㼜 㼐 㼍㼠㼑㻌㻯㼛 㼙 㼜 㼘㼑㼠㼑㻌㻺 㼛 㼠㼕㼒㼕㼏 㼠 㼕 㼛㼚

䠄 Flag: R䠅
㻲㼘㼛 㼣 㻌㼀㼍㼎 㼘㼑㻌㻹 㼍㼚 㼍㼓 㼑㼙 㼑㼚 㼠㻌㻹 㼑㼟㼟㼍㼓 㼑 㼍
䠄 FlowID, TrustID, ActionID䠅
㼁 㼜 㼐 㼍㼠㼑㻌㻯㼛 㼙 㼜 㼘㼑㼠㼑㻌㻺 㼛 㼠㼕㼒㼕㼏 㼠 㼕 㼛㼚

㻯㼛 㼙 㼜 㼘㼑㼠㼕㼛 㼚 㻌㼛 㼒 㻌
㻼㼛 㼘㼕㼏㼥㻌㼟㼑㼠㼠㼕㼚 㼓

Fig. 5.
㻼㼛 㼘㼕㼏 㼥 㻌
㻹 㼍㼚㼍㼓 㼑㼞

Policy Setting

㼀㼞 㼡 㼟 㼠㻌㻸 㼑 㼢 㼑 㼘㻌
㻾 㼑 㼓 㼡 㼘㼍 㼠㼛 㼞
CreateOutbound
DomainIDList()

㻻 㼠㼔 㼑 㼞 㻌
㻰 㼛 㼙 㼍 㼕㼚 㻓㼟
㼀㼞 㼡 㼟 㼠㻌㻸 㼑 㼢 㼑 㼘㻌
㻾 㼑 㼓 㼡 㼘㼍 㼠㼛 㼞

㻻 㼠㼔 㼑 㼞 㻌
㻰 㼛 㼙 㼍 㼕㼚 㻓㼟
㻼㼛 㼘㼕㼏 㼥 㻹 㼍 㼚 㼍 㼓 㼑 㼞

OutboundDomainIDList
NotifyDomainID
(OutboundDomainIDList)

ConnectCompleted

Fig. 6.

NotifyDomainID
(OutboundDomainIDList)

ref

ConnectCompleted

NotiﬁedOutboundDomainID
(OutboundDomainIDList)

Outbound Trust Level Notification

is shown in Fig. 6. In this case, the Policy Manager first
creates the OutboundDomainID list, and then notifies the Trust
Level Regulator with the OutboundDomainID list. In turn, the
Trust Level Regulator is responsible for communication with
another Trust Level Regulator associated with a corresponding
NotifyDomainID. Once this is received by the other Trust
Level Regulator, it first verifies the validation. If the NotifyDomianID is acceptable, the Trust Level Regulator communicates
with its own Policy Manager about the NotifyDomainID,
so that data communication is possible between these two
VTRouPD s based on the established level of trust.
3) Trust Level Change Notiﬁcation: Periodically, there
would be a requirement to communicate a trust level change
within a Managed Domain in regard to communication with
another VTRouPD. The sequence diagram for such a change
is shown in Fig. 7. In this case, when the other VTRouPD ’s
Trust Level Regulator is aware of the trust level change, it
communicates the change to the first VTRouPD ’s Trust Level
Regular. Then, internally, this change is notified to its Policy
Manager, which in turn informs its Traffic Monitor to request
detecting these changes.
VI. S E RV I TR E XPERIMENTAL E NVIRONMENT AND
F UNCTIONAL I MPLEMENTATION
Our implementation environment involves three sites, which
are Osaka City University in Japan, Arizona State University and the University of Missouri - Kansas City in the
United States. The experimental environment consists of three
VTRouPDs, one located at each site, respectively. A Trust

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

㻻 㼠㼔 㼑 㼞 㻌㻰 㼛 㼙 㼍 㼕㼚 㻓㼟 㻌
㼀㼞 㼡 㼟 㼠㻌㻸 㼑 㼢 㼑 㼘㻌
㻾 㼑 㼓 㼡 㼘㼍 㼠㼛 㼞

㼀㼞 㼡 㼟 㼠㻌㻸 㼑 㼢 㼑 㼘㻌
㻾 㼑 㼓 㼡 㼘㼍 㼠㼛 㼞

㻼㼛 㼘㼕㼏 㼥 㻌
㻹 㼍㼚㼍㼓 㼑㼞

㼀㼞 㼍 㼒㼒㼕 㼏 㻌㻹 㼛 㼚 㼕㼠㼛 㼞

TrustLevelChangeNotiﬁcation
(OutboundDomainID)
TrustLevelChangeNotiﬁcation
(OutboundDomainID)

Fig. 7.

RequestDetectAnomaly
(OutboundDomainID)

Trust Level Change Notification

Level Regulator among these domains will communicate to
establish the appropriate trust levels. We started with building
the experimental environment and implementing SeRViTR
components concurrently. On one hand, we are building tunnels among the three sites, and we have built GRE tunnels
through Open vSwitches and passed basic connection testing.
On the other hand, we have implemented the VTRouPD
Manager, the Flow Controller and the Routing Service Node s
in a two-VTRouPD environment within one site.
A. Geo-distributed Multi-Domain Infrastructure
To establish a geo-distributed multi-domain infrastructure,
we have established a layer-2 GRE tunnel so that any two sites
have either a direct or an indirect layer-2 connection. An Open
vSwitch, which is another intelligent mode besides the native
linux bridge mode in Xen[18] virtualization, is deployed to
establish the tunnel. It uses the OpenFlow protocol and also
supports various controllers that speak OpenFlow protocol. In
this case, a layer-2 GRE tunnel has been chosen so that any
layer-2 above technology, i.e., VLAN, is enabled upon this
layer-2 tunnel. The real entity being tunneled is the virtual
bridge that can be attached to any VIF (Virtual Interface) or
PIF (Physical Interface). This means that both the physical
XenServer or the virtual machine are actually in this tunnel.
Using this flexible mechanism to establish the tunnel also
guarantees the easiness of future extensions since the tunnel
is established by using an Open vSwitch under the OpenFlow
protocol. Additional descriptions can be found at [19].
Start

Create Virtual
Domain

Decide Virtual
Domain’s Member

Listen to Routing
Service Nodes

Create Routing Table
Update Message

Send Routing Table
Update Message

Routing Table
Update Message

VTRouPD Manager

Start

Connect to
VTRouPD
Manager

Receive Routing Table
Update Message

Read Routing Table
Update Message

Update
Routing Table

Routing Service Node

Fig. 8. Communication between the VTRouPD Manager and the Routing
Service Node

B. Experimental Environment
Our first experiment is to create virtual domains, where
the flows are correctly differentiated by the trust level. Since
we are yet to implement the Policy Manager and Trust Level
Regulator, the VTRouPD Manager creates Virtual Domain s
and assignes the FlowID and the TrustID.

Our experimental environment is OpenFlow based. The
VTRouPD Manager is based on NOX 0.9.1 on an Ubuntu
10.10 platform where each function is implemented in C++.
The Flow Controller and Routing Service Node s are implemented using NetFPGA 2.1.3 full on CentOS 5.3 where the
OpenFlow Switch was installed. As we mentioned earlier,
the Flow Controller assigns different VlanID s to the flows
according to their trust level. When a Virtual Domain is
created, the Flow Controller will update its flow table and
the Routing Service Node updates its routing table, so that the
end system can communicate with each other.
Next, we illustrate how the VTRouPD Manager communicates with a Routing Service Node based on the policy
setting mechanism to get the routing table updated, shown in
Fig.8. Upon detecting the connection from the Routing Service
Node s, the VTRouPD Manager will determine the members
for the Virtual Domain s it has created, and afterward sends the
Routing Table Update Message to the Routing Service Node s
to get the routing table updated.
C. Experimental Scenario: Multiple Domains
We have setup a connection between two end-hosts belonging to two different VTRouPD s as shown in Fig. 9. In
this scenario, our goal is to validate the functionalities of
the Flow Controller, the VTRouPD Manager and the Routing
Service Node. With each VTRouPD setup, there are two Flow
Controller s, one each at ingress and egress points; a VTRouPD
Manager is connected to three Routing Service Node s. We
considered two different types of applications: SSH and HTTP,
where the HTTP flow is set to the lowest trust level and the
SSH flow is assigned to be at the highest trust level. When
the host, PC1, at VTRouPD A sends out both types of packets
to the ingress Flow Controller (FC1) with the pre-determined
policy rule <FlowID, Trust>, the FC1 updates its flow table,
attaches VlanID s to SSH and HTTP flows respectively, and
sends the VlanID to the Virtual Domain according to the
TrustID. Meanwhile, the Routing Service Node s update their
routing tables. When both flows arrive at the egress Flow
Controller (FC2), FC2 strips the previous VlanID, and attaches
a new VlanID to each flow and sends this new VlanID to the
ingress Flow Controller (FC3) at VTRouPD B. Finally, when
flows arrive at FC4, the egress Flow Controller, FC4, strips
the VlanID s and forwards the flow to the destination PC2.
The second validation is the degradation of the trust level
when anomaly traffic is detected in the flow. In our current
experimental setup, we assume that there is anomaly traffic
mixed in the SSH flow that is detected in VTRouPD A. We
change the TrustID manually, and in turn, the policy rule
is updated at FC3, which then attaches a different VlanID
to the SSH flow and sends it to a different Virtual Domain
that is under a lower trust level. The degraded SSH flow is
represented as a dotted arrow in Fig.9.
VII. S UMMARY AND F UTURE W ORK
In this paper, we propose an overview of the design of
SeRViTR framework for the Future Internet according to

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

1165

VTRouPD A

VTRouPD B
21

111

109

19
11

31

50

32

12

101

18

FC1

60

13
41

42

FC4
107
131

FC2
70

FC3

PC2

OutboundDomainID

TLR

TLR
Physical Connection

ϤVTRouPD - SSH Flow with degraded trust level

ϤVTRouPD - SSH Flow with highest trust level

ϤVTRouPD - HTTP Flow with lowest trust level

Fig. 9.

Multiple-Domain Environment

the idea of the VTRouPD from our earlier work. We introduce the role and responsibility of VTRouPD components
in the SeRViTR architecture. Specifically, we illustrate the
VTRouPD Trust Management Service that is able to setup
trust levels for different virtual domains within a VTRouPD,
and negotiate the trustworthiness levels of the flows between
VTRouPD s. From our basic result of implementation, we have
been able to create flow-level 𝜇VTRouPDs under different
trust levels, and migrate the flow to the 𝜇VTRouPD under
a lower trust level given that the anomaly traffic is detected in
the flow.
In the future, we plan to implement the rest of the components in SeRViTR architecture. In particular, we will have the
Policy Manager, Trust Level Regulator, and Traffic Monitor
to fully provide Trust Management Service. We shall declare
policies and corresponding metrics to evaluate whether a flow
is good or not. Our experiments in this paper were only implemented locally at one site, and we plan to scale it to the other
two institutions through globally layer-2 VLAN techniques,
constructing at least one VTRouPD at each institution.
The policy management system has the flexibility of defining the security policy for each domain and can be used as
an experimental tool. For example, GENI provides collaborative and exploratory environments for academia, industry
and the public, which is a good platform to which the policy
management system can be extended. We plan to make this
system public for experimenters so that users can claim,
configure resources, define their own policy, and evaluate the
policy mechanism in the real system. For this, GENI provides
good lower level infrastructure support for various platforms.
Thus, our next step is to explore how to make this policy
management system an aggregate in the GENI platform.
ACKNOWLEDGEMENT
This work is supported by US NSF grants CNS-1029562
and CNS-1029546, Office of Naval Research’s (ONR) Young
Investigator Program (YIP), an HP IRP grant, and Japan NICT
International Collaborative Research Grant.
R EFERENCES
[1] “GENI: Global Environment for Network Innovations,” http://www.geni.
net/.
[2] “OpenFlow,” http://www.openflow.org/.

1166

108

103

17

PC1

121
102

[3]
[4]
[5]
[6]
[7]
[8]

[9]

[10]
[11]
[12]

[13]
[14]
[15]
[16]

[17]

[18]
[19]

“PlanetLab,” http://www.planet-lab.org/.
“ProtoGENI,” http://www.protogeni.net.
“VINI: Virtual Network Infrastructure,” http://vini-veritas.net/.
“Virtuoso: Resource Management and Prediction for Distributed
Computing using Virtual Machines,” http://virtuoso.cs.northwestern.
edu/. http://virtuoso.cs.northwestern.edu
“Open Flow Switch Specification,” http://www.openflow.org/documents/
openflow-spec-v1.1.0.pdf, Feburary 2011.
M. B. Anwer and N. Feamster, “Building a fast, virtualized data
plane with programmable hardware,” in Proceedings of the 1st ACM
workshop on Virtualized infrastructure systems and architectures,
ser. VISA ’09. New York, NY, USA: ACM, 2009, pp. 1–8.
http://doi.acm.org/10.1145/1592648.1592650
R. Cherukuri, X. Liu, A. Bavier, J. Sterbenz, and D. Medhi, “Network
virtualization in GpENI: Framework, implementation and integration
experience,” in Proc. of 3rd IEEE/IFIP International Workshop on
Management of the Future Internet (ManFI’2011), Dublin, Ireland, May
2011, pp. 1212–1219.
N. M. K. Chowdhury and R. Boutaba, “A survey of network
virtualization,” Comput. Netw., vol. 54, pp. 862–876, April 2010.
http://dx.doi.org/10.1016/j.comnet.2009.10.017
D. Huang, S. Ata, and D. Medhi, “Establishing Secure Virtual Trust
Routing And Provisioning Domains For Future Internet,” in Proceedings
of IEEE Globecom, The Next Generation Networking Symposium,, 2010.
E. Keller, R. B. Lee, and J. Rexford, “Accountability in hosted virtual
networks,” in Proceedings of the 1st ACM workshop on Virtualized
infrastructure systems and architectures, ser. VISA ’09. New York,
NY, USA: ACM, 2009, pp. 29–36. http://doi.acm.org/10.1145/1592648.
1592654
S. Kent and R. Atkinson, “Ip authentication header,” IETF RFC 2402,
Tech. Rep., 1998.
S. Kent and R. Atkinson, “Ip encapsulating security payload (esp),” IETF
RFC 2406, Tech. Rep., 1998.
T. Miyamura, S. Kamamura, and K. Shiomoto, “Policy-based resource
management in virtual network environment,” in Network and Service
Management (CNSM), 2010, pp. 282 – 285.
J. Sterbenz, D. Medhi, B. Ramamurthy, C. Scoglio, D. Hutchison,
B. Plattner, T. Anjali, A. Scott, C. Buffington, G. Monaco, D. Gruenbacher, R. McMullen, J. Rohrer, J. Sherrell, P. Angu, R. Cherukuri,
H. Qian, and N. Tare, “The Great Plains Environment for Network Innovation (GpENI): A programmable testbed for future Internet architecture
research,” in Proc. of 6th International Conference on Testbeds and Research Infrastructures for the Development of Networks & Communities
(TridentCom), Berlin, Germany, May 2010, pp. 428–441.
Y. Wang, E. Keller, B. Biskeborn, J. van der Merwe, and J. Rexford,
“Virtual routers on the move: Live router migration as a networkmanagement primitive,” SIGCOMM Comput. Commun. Rev., vol. 38, pp.
231–242, August 2008. http://doi.acm.org/10.1145/1402946.1402985
xen.org, “Xen Hypervisor,” http://www.xen.org/.
T. Xing, X. Liu, C.-J. Chung, A. Wada, S. Ata, D. Huang, and D. Medhi,
“Constructing virtual networking environment in a Geo-distributed Programmable Layer-2 Networking Environment (G-PLaNE),” in IEEE 5th
International Workshop on the Network of the Future (FutureNet-V),
Ottawa, Canada, June 2012.

2012 IEEE/IFIP 4th Workshop on Management of the Future Internet (ManFI)

The 31st Annual IEEE International Conference on Computer Communications: Mini-Conference

Towards Temporal Access Control in Cloud Computing
Yan Zhu∗, Hongxin Hu† , Gail-Joon Ahn†, Dijiang Huang†, and Shanbiao Wang ∗
∗

Peking University, Beijing, 100080, China
Arizona State University, Tempe, Arizona, 85281, USA
{yan.zhu,wangshanbiao}@pku.edu.cn; {hxhu,gahn,dijiang.huang}@asu.edu
†

Abstract—Access control is one of the most important
security mechanisms in cloud computing. Attribute-based
access control provides a flexible approach that allows data
owners to integrate data access policies within the encrypted
data. However, little work has been done to explore temporal
attributes in specifying and enforcing the data owner’s policy
and the data user’s privileges in cloud-based environments.
In this paper, we present an efficient temporal access control
encryption scheme for cloud services with the help of cryptographic integer comparisons and a proxy-based re-encryption
mechanism on the current time. We also provide a dual
comparative expression of integer ranges to extend the power
of attribute expression for implementing various temporal
constraints. We prove the security strength of the proposed
scheme and our experimental results not only validate the
effectiveness of our scheme, but also show that the proposed
integer comparison scheme performs significantly better than
previous bitwise comparison scheme.
Index Terms—Cryptography, Temporal Access Control, ReEncryption, Integer Comparison, Cloud Computing

decrypt and access the data. Since the access control policy
of every object is embedded within it, the enforcement of
policy becomes an inseparable characteristic of the data
itself. This is in direct contrast to most currently available
access control systems, which rely directly upon a trusted
host to mediate access and maintain policies.
Even though there have been some previous work to
construct fine-grained access control systems in clouds [3],
[4], existing work lacks a systematic mechanism to support
a complete temporal control. Temporal dimension has generated a great amount of interest in security community as
an important property of access control for security system
management in recent years [5], [6]. However, existing
attribute-based solutions are difficult to provide full features
of temporal data access control due to following reasons:
∙

I. I NTRODUCTION
Cloud computing provides an extensible and powerful
environment for growing amounts of services and data by
means of on-demand self-service. It also relieves the client’s
burden from management and maintenance by providing a comparably low-cost, scalable, location-independent
platform. However, cloud computing is also facing many
challenges for data security as the users outsource their
sensitive data to clouds, which are generally beyond the
same trusted domain as data owners.
To address this problem, access control is considered as
one of critical security mechanisms for data protection in
cloud applications. Unfortunately, traditional data access
control schemes usually assume that data is stored on
trusted data servers for all users. This assumption however
no longer holds in cloud computing since the data owner
and cloud servers are very likely to be in two different
domains. Hence, attribute-based access control [1], [2] has
been introduced into cloud computing to encrypt outsourced
sensitive data in terms of access policy on attributes describing the outsourced data, and only authorized users can
Y. Zhu works in Beijing Key Laboratory of Internet Security Technology
and Institute of Computer Science and Technology, Peking University, Beijing, 100080, China. This work of Y. Zhu and S. Wang was supported by
the National Natural Science Foundation of China (Project No. 61170264
and 10990011).
This work of G.-J. Ahn and H. Hu was partially supported by the
grants from US National Science Foundation (NSF-IIS-0900970 and NSFCNS-0831360) and Department of Energy (DE-SC0004308). D. Huang’s
research is sponsored by Office of Naval Research Young Investigator
Program (ONR-YIP) and NSF-CNS-1029546.

978-1-4673-0775-8/12/$31.00 ©2012 IEEE

∙

∙

The system models of existing systems cannot support dual comparative expressions (DTE), in which two
range-based comparative constraints must be embedded
into the outsourced files as well as the user’s private key.
The existing systems don’t support current time, which
is essentially an important factor for enforcing temporal
access control.
Bethencourt et al. [1] has provided a bitwise-comparison
method (called BSW’s scheme) to realize a pretty simple
control, e.g. 𝑎 < 11, but this method does not support
range expressions in user’s private key because both
“*1*” and “*0*” may appear in the same bit position.

In this paper, we address the afore-mentioned problems
by constructing a temporal access control solution along
with a proxy-based re-encryption mechanism [7] for cloud
computing. The proposed scheme is originated from the
needs of practical cloud applications, in which each outsourced resource can be associated with an access policy on
a set of temporal attributes, e.g., period-of-validity, opening
hours, or hours of service. Each user can also be assigned
a license with several privileges based on the comparative
attributes. To enforce the valid matches between access
policies and user’s privileges, we introduce a proxy-based
re-encryption mechanism [7] with respect to the current
time. This design brings about several efficient benefits,
such as flexibility, supervisory, and privacy protection,
compared with prior work.
Our solution also addresses another practical issue
to implement cryptographic integer comparisons and reencryption mechanism on the current time. We provide
a cryptographic expression of integer ranges to extend

2576

the power of attribute expression, and propose a temporal
access control encryption (TACE) scheme to implement
various temporal constraints. This scheme provides a constant size of ciphertext, private-key, and depth of policytree, as well as a nearly linear-time complexity. Other
security features, such as forward and backward derivation
functions, are provided in our scheme as well. In addition,
we prove the security of these two functions under the RSA
and Co-CDH assumption [8]. To demonstrate the feasibility
of our proposed approach, we implement a prototype of
TACE system. Our experimental results not only validate
the effectiveness of our scheme and algorithms, but also
show our scheme has better performance for integer comparison than existing bitwise comparison scheme.
This paper is organized as follows. Section II discusses
our research goals and models. Section III shows our
framework and security requirements. Section IV provides
main techniques pertaining to our construction. In Section V, we analyze our scheme in terms of its security and
performance, respectively. Finally, we discuss the related
work in Section VI and conclude this paper in VII.
II. P ROBLEM S TATEMENT
A. Design Goals
Our main design goal is to help the data owner achieve
temporal data access control on files stored in cloud servers.
Although this kind of access control is based on finegrained access control introduced for outsourced data services [3], we intent to ensure that all kind of temporal
access policy can be securely and efficiently implemented
for outsourced data services. Specially, we also want to
solve the following problem: Given an access constraint
𝑡𝑖 ≤ 𝐴𝑡 ≤ 𝑡𝑗 in policy 𝒫 embedded in the ciphertext 𝒞
and a privilege 𝑡 𝑎 ≤ 𝐴𝑡 ≤ 𝑡𝑏 in the user’s private key 𝑆𝐾,
how to guarantee that the ciphertext can be decrypted only
at a valid current time 𝑡 𝑐 ? Here, the valid current time 𝑡 𝑐
means that two conditions, 𝑡 𝑐 ∈ [𝑡𝑖 , 𝑡𝑗 ] and 𝑡𝑐 ∈ [𝑡𝑎 , 𝑡𝑏 ],
must be satisfied at the same time.
B. System Model
Considering a cloud-based data storage service involving
three different entities, as illustrated in Fig. 1: data owner,
cloud server, and many data users (e.g., computers, mobile
devices, or general equipments). In addition, in order to
implement temporal access control, we require a clock
server designed to always provide exactly the same current
time by communicating with each other.
e

Tim

Data
ted ral
o
ryp
Enc Temp cy
h
it
Poli
w
ess
Acc

Data Owners

Fig. 1.

Re-encryption
Proxy

Clock

Ti
m
e

Encr
Data ypted
Acces
s

Untrsted Clouds

Access Permission & License
(the user's private keys)

Data Users

Temporal constraints on privilege-licence assignment.

To ensure the data access compliant with the assigned
policy, fine-grained access control has been introduced
into the outsourced storage service. We extend this kind
of access control mechanisms to support temporal access
control encryption (TACE) described as follows:
∙ First, the data owner makes use of a temporal access
policy 𝒫 to encrypt data before store it to clouds.
∙ Second, once receiving an access request from a user,
the cloud service checks whether corresponding temporal
constraints can be satisfied in 𝒫 with respect to the
current time 𝑡𝑐 , then employs a re-encryption method
to convert the encrypted data into another ciphertext 𝐶 𝑡𝑐
that embed current time 𝑡 𝑐 and sent it the user.
∙ Finally, the authorized user can use her/his private key
𝑆𝐾 with access privilege ℒ to decrypt 𝐶 𝑡𝑐 . In this model,
we assume the cloud service is a semi-trusted service that
can use the correct time to re-encrypt data.
C. Benefits of TACE
Flexibility: TACE-based cryptosystem can provide more
flexible access control based on temporal constraints as
follows: a) Date control on Year, Month, and Day, e.g.,
((2010 ≤ 𝑌 𝑒𝑎𝑟 ≤ 2011) AND (4 ≤ 𝑀 𝑜𝑛𝑡ℎ ≤ 7));
and b) Periodic control on Week and Hour, e.g., ((3 ≤
𝑊 𝑒𝑒𝑘 ≤ 5) AND (8 : 00𝑃 𝑀 ≤ 𝐻𝑜𝑢𝑟 ≤ 10 : 00𝑃 𝑀 )).
More importantly, this cryptosystem also supports all kind
of level controls and integer comparisons, e.g., ((3 ≤
Security Clearance ≤ 5) OR (2, 000 ≤ Salary ≤ 5, 000)).
Supervisory: Traditional cryptosystems, that only contains
both encryption and decryption processes, has not an efficient method to monitor the usage of encrypted data. TACEbased cryptosystem introduces a proxy-based re-encryption
mechanism that can apply the current time to determine
whether the user’s download request is reasonable, and rely
on the re-encryption technologies to produce a new version
of data under the current time. Such a proxy service can
also integrate with other rich information to determine the
legitimacy of user behaviors.
Privacy Protection: In our system model, the access policies are enforced entirely dependent upon temporal attribute
matches between ciphertexts and private keys in the client
side. In the re-encryption process, cloud servers do not
require any user information which is used to enforce access
policies. Hence, this mechanism ensures that user privacy,
including user identity and access privilege in the user’s
private key, will not be disclosed to cloud servers.
III. F RAMEWORK AND S ECURITY R EQUIREMENTS
A. Notations
For sake of clarity, we introduce following notations:
∙ 𝒜: the set of attributes 𝒜 = {𝐴 1 , ⋅ ⋅ ⋅ , 𝐴𝑚 };
∙ 𝐴𝑘 (𝑡𝑖 , 𝑡𝑗 ): the range constraint of attribute 𝐴 𝑘 on [𝑡𝑖 , 𝑡𝑗 ],
i.e., 𝑡𝑖 ≤ 𝐴𝑘 ≤ 𝑡𝑗 ;
∙ 𝒫: the access control policy expressed as a Boolean
function on AND/OR logical operations, generated by
the grammar: 𝒫 ::= 𝐴 𝑘 (𝑡𝑖 , 𝑡𝑗 )∣𝒫 AND 𝒫∣𝒫 OR 𝒫;

2577

∙

ℒ: the access privilege assigned into the user’s licence,
generated by ℒ ::= {𝐴 𝑘 (𝑡𝑎 , 𝑡𝑏 )}𝐴𝑘 ∈𝒜 .

The definitions of 𝒫 and 𝒞 can meet the basic requirements of dual temporal expressions. Given a time
assignment 𝑡𝑐 for 𝐴𝑘 , the constraint or privilege 𝐴 𝑘 (𝑡𝑖 , 𝑡𝑗 )
outputs 𝑡𝑟𝑢𝑒 if 𝑡𝑖 ≤ 𝑡𝑐 ≤ 𝑡𝑗 , otherwise outputs 𝑓 𝑎𝑙𝑠𝑒.
We call it a valid time assignment if and only if both
𝐴𝑘 (𝑡𝑖 , 𝑡𝑗 ) ∈ 𝒫 and 𝐴𝑘 (𝑡𝑎 , 𝑡𝑏 ) ∈ ℒ output true.
B. TACE Framework
With focusing on temporal access control and reencryption mechanism in cloud computing, the TACE
scheme consists of five algorithms:
1) Setup(1 𝜅, 𝒜): Takes a security parameter 𝜅 and a list of
attributes 𝒜 as input, outputs the master key 𝑀 𝐾 and
the public-key 𝑃 𝐾 𝒜 ;
2) GenKey(𝑀 𝐾, 𝑢 𝑘 , ℒ): Takes the user’s ID number 𝑢 𝑘 as
input, the access privilege ℒ and 𝑀 𝐾, outputs the user’s
private key 𝑆𝐾 ℒ ;
3) Encrypt(𝑃 𝐾 𝒜, 𝒫): Takes a temporal access policy 𝒫 and
𝑃 𝐾𝒜 as input, outputs the ciphertext header ℋ 𝒫 and a
random session key 𝑒𝑘;
4) ReEncrypt(𝑃 𝐾 𝒜, ℋ𝒫 , 𝑡𝑐 ): Takes a current time 𝑡 𝑐 and a
ciphertext header ℋ 𝒫 and 𝑃 𝐾𝒜 as input, outputs a new
ciphertext header 𝐻 𝑡𝑐 ;
5) Decrypt(𝑆𝐾 ℒ, ℋ𝑡𝑐 ): Takes a user’s private key 𝑆𝐾 ℒ , and
a ciphertext header ℋ 𝑡𝑐 on the current time 𝑡 𝑐 as input,
outputs a session key 𝑒𝑘;
With the help of this framework, the workflow of TACEbased cryptosystem is described in Fig.2. For sake of
clarity, the operations on the data are not shown in the
framework since data owner could easily employ traditional
symmetric key cryptography to encrypt and then outsource
data with the help of a random session key.

C. Security Models
First, given a scheme based on our TACE framework, we
must guarantee that this scheme can follow the principle in
secure temporal control: Let 𝐴 𝑘 ∈ 𝒜 be a range-based
temporal attribute and (𝒫, ℒ) be a constraint-privilege pair
with 𝐴𝑘 , where 𝐴𝑘 [𝑡𝑖 , 𝑡𝑗 ] ∈ 𝒫 and 𝐴𝑘 [𝑡𝑎 , 𝑡𝑏 ] ∈ ℒ. Given
a current time 𝑡𝑐 , secure temporal control requires that
the access is granted if and only if 𝑡 𝑐 ∈ [𝑡𝑖 , 𝑡𝑗 ] and
𝑡𝑐 ∈ [𝑡𝑎 , 𝑡𝑏 ]. This means that the TACE scheme can must
also obey this rule as follows: Given the above-mentioned
(𝒫, ℒ), we can compute (𝑀 𝐾, 𝑃 𝐾 𝒜 ) ← 𝑆𝑒𝑡𝑢𝑝(1𝜅, 𝒜),
𝑆𝐾ℒ ← 𝐺𝑒𝑛𝐾𝑒𝑦(𝑀 𝐾, 𝑢𝑘 , ℒ), and (ℋ𝒫 , 𝑒𝑘) ←
𝐸𝑛𝑐𝑟𝑦𝑝𝑡(𝑃 𝐾, 𝒫). Such that, we hold
[
]
ℋ𝑐 ← 𝑅𝑒𝐸𝑛𝑐𝑟𝑦𝑝𝑡(𝑃 𝐾𝒜 , ℋ𝒫 , 𝑡𝑐 );
Pr
= 1,
𝐷𝑒𝑐𝑟𝑦𝑝𝑡(𝑆𝐾ℒ , ℋ𝑡𝑐 ) = 𝑒𝑘
if and only if the access is granted over (𝒫, ℒ) and 𝑡 𝑐
according to fine-grained access control model. Besides
these, we are more concerned with the security risk from
cloud servers or data users, as follows:
∙ Cloud servers: Similarly to [9], [3], we just consider
“Honest but Curious” cloud servers, that is, cloud servers
will follow our proposed protocol in general (especially
for a uniform Clock service), but try to find out as much
secret information as possible based on their inputs. More
specifically, we assume cloud servers are more interested
in file contents, changing time range in policy, and user
access privilege than other secret information.
∙ Data users: Dishonest users would try to access files
outside the scope of their access privileges. To achieve
this, unauthorized users may intent to change the temporal constraints in his privilege independently or cooperatively. In addition, each party is preloaded with a
private key and the public key can be easily obtained
when necessary.
IV. M AIN T ECHNIQUES

Data

A. Main Idea

Data Owner:
Encryption

Header HP

Current
Time

Encrypted Data

Policy

Proxy in Could:
Re-Encryption

Time[8:00AM,12:00AM] AND
Month[March,July] AND
Year[2010,2011]

Header HP

Encrypted Data

Policy at the Current Time
Time[10:00AM,10:00AM] AND
Month[May,May] AND
Year[2011,2011]

Data Users:
Decryption

License

Time[9:00AM,10:00AM],
Month[April,June],
Year[2011,2011]

Data

Fig. 2.

Workflow of TACE-based Cryptosystem.

This framework is based on BSW’s scheme [1], in which
both AND/OR operations and basic fine-grained access
control are not within the scope of this paper.

In order to achieve temporal access control on outsourced data in the cloud, we present and combine the
following three advanced cryptographic techniques: integer
comparison, current-time re-encryption and attribute-based
encryption (ABE). The existing integer comparison scheme,
first introduced in BSW’s Cipher-policy ABE scheme, is a
trivial method based on bitwise comparisons and AND/OR
logical operations. Unfortunately, this method does not
support the time attribute with range 𝐴 𝑘 [𝑡𝑎 , 𝑡𝑏 ] in the
private key 𝑆𝐾, as well as the re-encryption mechanism. To
resolve this challenging issue, we provide a new idea for
designing cryptographic “one-way” property to represent
the total ordering relation in integer. This means that given
the integer relation 𝑡 𝑖 ≤ 𝑡𝑗 and two corresponding value
𝑣𝑡𝑖 , 𝑣𝑡𝑗 , there exists an efficient algorithm to obtain 𝑣 𝑡𝑗 from
𝑣𝑡𝑖 , but it is hard to compute 𝑣 𝑡𝑖 from 𝑣𝑡𝑗 . Based on this
idea, we have constructed a practical one-way function to

2578

realize the integer comparison. Also, we have demonstrated
how to incorporate these functions into the BSW’s scheme
to realize fine-grained access control in clouds [10].
B. Forward/Backward Derivation Functions
Let time be denoted as a countable set 𝑈 =
{𝑡1 , 𝑡2 , ⋅ ⋅ ⋅ , 𝑡𝑇 } constituted from the discrete consecutive
integers with total ordering 0 ≤ 𝑡 1 ≤ 𝑡2 ≤ ⋅ ⋅ ⋅ ≤ 𝑡𝑇 ≤ 𝑍,
where 𝑍 is the maximum integer. In order to construct a
cryptographic algorithm for integer comparison, we make
use of a cryptographic map 𝜓 : 𝑈 → 𝑉 , where 𝑉 =
{𝑣𝑡1 , ⋅ ⋅ ⋅ , 𝑣𝑡𝑇 } is a set of cryptographic values. It is obvious
that 𝜓 must be an order-preserving map, that is a map such
that if 𝑡𝑖 ≤ 𝑡𝑗 in 𝑈 implies there exists a partial-order
relation ⪯ to ensure 𝑣 𝑡𝑖 ⪯ 𝑣𝑡𝑗 in 𝑉 , where 𝑣𝑡𝑖 = 𝜓(𝑡𝑖 )
and 𝑣𝑡𝑗 = 𝜓(𝑡𝑗 ). In order to setup this kind of relation
over 𝑉 , we consider the partial-order relation in 𝑉 as the
“one-way” property in cryptography, as follows:
Definition 1: Given a function 𝑓 : 𝑉 → 𝑉 based on a
set (𝑈, ≤), it is called a forward derivation function if it
satisfies the following conditions:
∙ Easy to compute: the function 𝑓 can be computed in a
polynomial-time, if 𝑡 𝑖 ≤ 𝑡𝑗 , i.e., 𝑣𝑡𝑗 ← 𝑓𝑡𝑖 ≤𝑡𝑗 (𝑣𝑡𝑖 );
∙ Hard to invert: it is infeasible for any PPT algorithm to
compute 𝑣𝑡𝑖 from 𝑣𝑡𝑗 if 𝑡𝑖 < 𝑡𝑗 .
Similarly, we also define a function 𝑓¯ to realize the
derivation in opposite direction, which is called Backward
Derivation. In order to avoid interference between 𝑓 and
𝑓¯, we use a different sign 𝜓¯ : 𝑈 → 𝑉¯ , and then define the
backward derivation function 𝑓¯ : 𝑉¯ → 𝑉¯ based on the ≥
relation in (𝑈, ≤), e.g., 𝑣 𝑡𝑗 ← 𝑓𝑡𝑖 ≥𝑡𝑗 (𝑣𝑡𝑖 ).
C. Cryptographic Constructions
We propose a cryptographic construction for integer
comparisons based on the forward/backward derivation
functions. This construction is built on a special group 𝔾
of RSA-type composite order 𝑛 = 𝑝 ′ 𝑞 ′ . First, we choose
two random secrets 𝜑, 𝜑¯ in a group 𝔾. Next, we choose
two different random 𝜆 and 𝜇 in ℤ ∗𝑛 , where the order of
𝜆, 𝜇 are sufficiently large in ℤ ∗𝑛 . Based on RSA system,
¯
we define two mapping functions (𝜓(⋅), 𝜓(⋅))
from an
integer set 𝑈 = {𝑡1 , ⋅ ⋅ ⋅ , 𝑡𝑇 } into 𝑉 = {𝑣𝑡1 , ⋅ ⋅ ⋅ , 𝑣𝑡𝑇 } and
𝑉¯ = {¯
𝑣𝑡1 , ⋅ ⋅ ⋅ , 𝑣¯𝑡𝑇 } as follows:
𝑣𝑡𝑖
𝑣¯𝑡𝑖
𝑡

𝑡𝑖

← 𝜓(𝑡𝑖 ) = 𝜑𝜆
∈ 𝔾;
𝑍−𝑡𝑖
𝜇
¯ 𝑖 ) = 𝜑¯
← 𝜓(𝑡
∈ 𝔾.
𝑡

where, 𝜑𝜆 denotes 𝜑(𝜆 ) rather than (𝜑𝜆 )𝑡 . Note that, the
¯𝑡𝑗 = 𝑢𝑍−𝑡𝑗 , can only be computed
values, 𝑤𝑡𝑖 = 𝜆𝑡𝑖 and 𝑤
in the integer ℤ because 𝑛 ′ and 𝑛 are unknown based on
the actual difficulty of factoring large numbers 𝑛. Next,
¯
according to the definition of 𝜓(⋅) and 𝜓(⋅),
it is easy to
define the forward derivation function 𝑓 (⋅) and backward
derivation function 𝑓¯(⋅) as
𝑣𝑡𝑗
𝑣¯𝑡𝑗

𝑡𝑗 −𝑡𝑖

← 𝑓𝑡𝑖 ≤𝑡𝑗 (𝑣𝑡𝑖 ) = (𝑣𝑡𝑖 )𝜆
∈ 𝔾,
𝑡𝑖 −𝑡𝑗
𝜇
← 𝑓¯𝑡𝑖 ≥𝑡𝑗 (¯
𝑣𝑡𝑖 ) = (¯
𝑣𝑡𝑖 )
∈ 𝔾.

𝑡𝑖

𝑡𝑗 −𝑡𝑖

𝑡𝑗

= 𝜑𝜆 = 𝑣𝑡𝑗 ∈ 𝔾 and
It is easy to show that (𝜑𝜆 )𝜆
𝑡𝑖 −𝑡𝑗
𝑍−𝑡𝑗
𝑍−𝑡𝑖
)𝜇
= 𝜑¯𝜇
= 𝑣¯𝑡𝑗 ∈ 𝔾. But it is intractable to
(𝜑¯𝜇
obtain 𝑣𝑡𝑖 from 𝑣𝑡𝑗 for 𝑡𝑖 ≤ 𝑡𝑗 under the RSA assumption
that 𝜆−1 and 𝜇−1 cannot be efficiently computed.
V. S ECURITY A NALYSIS AND P ERFORMANCE
E VALUATION
A. Security of Forward/Backward Derivation Functions
The security of TACE scheme is based on the RSA
assumption and Gap Diffie-Hellman (GDH) assumption.
Since this scheme is constructed based on BSW’s CPABE scheme, it remains the security properties of their
scheme, e.g., IND-CPA [1]. Hence, we focus on the security
analysis of the different parts between them: we introduce
the forward and backward derivation functions 𝑓 (⋅), 𝑓¯(⋅)
into our scheme, so we need to assure the “one-way”
property in the forward and backward derivation processes.
This kind of “one-way” property can be guaranteed because
the inverse of 𝜆, 𝑢 cannot be computed in ℤ ∗𝑛 if 𝑛 is
unknown. Thus, 𝜆 𝑡𝑐 −𝑡𝑖 , 𝑢𝑡𝑗 −𝑡𝑐 ∈ ℤ∗𝑛 cannot be computed in
𝑡𝑐 −𝑡𝑖
ℤ for 𝑡𝑐 < 𝑡𝑖 and 𝑡𝑗 < 𝑡𝑐 , so that 𝑓𝑡𝑐 ≤𝑡𝑖 (𝑣𝑡𝑖 ) = (𝑣𝑡𝑖 )𝜆
𝑡𝑗 −𝑡𝑐
and 𝑓¯𝑡𝑐 ≥𝑡𝑗 (𝑣𝑡𝑗 ) = (¯
𝑣𝑡𝑗 )𝜇
is intractable. Strictly, this
kind of “one-way” property can be proved under the
RSA assumption: given an RSA public key (𝑁, 𝑒) and a
ciphertext 𝐶 = 𝑀 𝑒 ∈ 𝔾, it is infeasible to compute 𝑀 .
𝑡𝑖
Theorem 1: Given a quintuple (𝑛, 𝜆, 𝑡 𝑖 , 𝜓 𝜆 ) over the
RSA-type elliptic curve system 𝕊 𝑁 , where 𝜓 is unknown.
𝑡𝑗
It is infeasible to compute (𝑡 𝑗 , 𝜓 𝜆 ) with 𝑡𝑗 < 𝑡𝑖 for all
probabilistic polynomial time (PPT) algorithms under the
RSA assumption.
Proof: Seeking a contradiction, we assume that there
𝑡𝑗
exists a PPT algorithm 𝒜 that can get a (𝑡 𝑗 , 𝜓 𝜆 ) under
above input, where 𝑡 𝑗 < 𝑡𝑖 . This is equivalent to say that
this algorithm can solve the RSA problem over elliptic
curve for the public-key (𝔾, 𝑁, 𝑒) and a ciphertext 𝐶, be𝑡𝑖 −𝑡𝑗 −1
∈
cause the ciphertext can be computed by 𝑀 = 𝑅 𝑒
𝔾 if (𝑡𝑗 , 𝑅) is a solution of 𝒜 on input (𝑛, 𝜆 = 𝑒, 𝑡 𝑖 , 𝐶)
𝑡𝑖 −𝑡𝑗
due to 𝑅 𝜆
= 𝐶 = 𝑀 𝜆 , and 𝑡𝑖 − 𝑡𝑗 − 1 ≥ 0. This
contradicts the hypothesis.
B. Performance Evaluation
We have implemented our scheme in Qt/C++ and experiments were run on an Intel Core 2 processor with
2.16 GHz and 500M of RAM on Windows Server 2003.
All disk operations were performed on a 1.82TB RAID
5 disk array. Using GMP and PBC libraries, we have
implemented a cryptographic library upon which temporal
attribute systems can be constructed.
We compare the performance of BSW’s scheme and our
scheme over integer ranges. We show the computational
overheads for BSW’s scheme and our scheme for different
sizes of 𝑈 in Figure 3. It is obvious that our scheme
is more efficient than BSW’s scheme. The reason is that
the computation costs of algebraic operations and simple
modular arithmetic operations can be neglected, because

2579

they run fast enough [11] in contrast with bilinear map
operations. Without loss of generality, the performance
of our scheme is better than that of BSW’s scheme in
[1; 10, 000, 000].

Fig. 3.
Computational overheads of BSW’s scheme (Red) and our
scheme (Black) for integer comparison operations: (a) Setup algorithm,
(b) KegGen algorithm, (c) Encrypt algorithm, and (d) Decrypt algorithm.

Next, we analyze the storage and communication overheads of our TACE scheme. Thanks to the use of forward
(or backward) derivation function for total ordering, TACE
scheme has 𝑂(1) size of private-key and ciphertext for
a certain integer attribute in Table I, as well as a nearly
linear-time complexity. But, for a comparison range [1, 𝑍],
the storage and computation costs of BSW’s scheme are
nearly 𝑂(log 2 𝑍) times than those of our scheme. Hence,
in comparison with BSW’s scheme, TACE scheme provides
a lower bound on variety of qualities, such as storage,
communication and computation overheads.
TABLE I
C OMPARISON OF BSW’ S SCHEME AND OUR SCHEME .
BSW’s Scheme
𝑡1 ≤ 𝑡
𝑡 ≤ 𝑡2
Ciphertext size
Private-key size
Depth of policy tree
Computation overhead

log2 ∣𝑈∣
log2 ∣𝑈∣
log2 ∣𝑈∣
log2 ∣𝑈∣

log2 ∣𝑈∣
log2 ∣𝑈∣
log2 ∣𝑈∣
log2 ∣𝑈∣

Our Scheme
𝑡1 ≤ 𝑡
𝑡 ≤ 𝑡2
1
1
1
1

1
1
1
1

VI. R ELATED W ORK
In recent years, cryptographic access control [12], [13]
has been introduced as a new access control paradigm to
manage dynamic data sharing systems in cloud computing.
It relies exclusively on cryptography to provide confidentiality of data managed by the systems, and is particularly
designed to run in an untrusted or hostile environment
which lacks of trust knowledge and global control [13].
Attribute-based encryption (ABE) is proposed to realize
a fine-grained attribute-based access control mechanism.
Since Sahai and Waters [14] introduced ABE as a new
means for encrypted access control in 2005, ABE has
received much attention and many schemes have been
proposed in recent years, such as, key-policy ABE (KPABE) [4], [2] and ciphertext-policy ABE (CP-ABE) [1],

[15]. For example, the model proposed by Yu et al. [3]
introduced key-policy attribute-based encryption (KP-ABE)
to achieve secure and scalable FGAC in cloud computing.
Temporal control is of particular significance and has
been concerned in traditional access control [5], [16]. For
example, in [5] the authors gave a temporal access control
model and described applications in database systems and
secure broadcasting. However, in the context of ABE, little
work has been done on studying time control or integer
comparison mechanisms. Even though Bethencourt et al.
[1] gave a bitwise comparison method to realize integer
comparison on CP-ABE scheme, it is unfortunately not
efficient enough for practical applications.
VII. C ONCLUSIONS
In this paper, we addressed the construction of temporal access control in cloud computing. Based on forward/backward derivation functions, we proposed a temporal access control encryption to support time range comparisons and re-encryption mechanism. We also discussed how
to handle current time controls and temporal constraints
with our solution.
R EFERENCES
[1] J. Bethencourt, A. Sahai, and B. Waters, “Ciphertext-policy attributebased encryption,” in IEEE Symposium on Security and Privacy,
2007, pp. 321–334.
[2] R. Ostrovsky, A. Sahai, and B. Waters, “Attribute-based encryption
with non-monotonic access structures,” in ACM Conference on
Computer and Communications Security, 2007, pp. 195–203.
[3] S. Yu, C. Wang, K. Ren, and W. Lou, “Achieving secure, scalable,
and fine-grained data access control in cloud computing,” in INFOCOM, IEEE, 2010, pp. 534–542.
[4] V. Goyal, O. Pandey, A. Sahai, and B. Waters, “Attribute-based
encryption for fine-grained access control of encrypted data,” in CCS,
ACM, 2006, pp. 89–98.
[5] E. Bertino, P. A. Bonatti, and E. Ferrari, “TRBAC: A temporal rolebased access control model,” ACM Trans. Inf. Syst. Secur., vol. 4,
no. 3, pp. 191–233, 2001.
[6] J. B. Joshi, E. Bertino, U. Latif, and A. Ghafoor, “A generalized
temporal role-based access control model,” IEEE Transactions on
Knowledge and Data Engineering, vol. 17, pp. 4–23, 2005.
[7] R. Canetti and S. Hohenberger, “Chosen-ciphertext secure proxy reencryption,” in CCS, ACM, 2007, pp. 185–194.
[8] D. Boneh and X. Boyen, “Short signatures without random oracles,”
in EUROCRYPT, Springer, 2004, pp. 56–73.
[9] S. D. C. di Vimercati, S. Foresti, S. Jajodia, S. Paraboschi, and
P. Samarati, “Over-encryption: Management of access control evolution on outsourced data,” in VLDB, ACM, 2007, pp. 123–134.
[10] Y. Zhu, H. Hu, G.-J. Ahn, M. Yu, and H. Zhao, “Comparison-based
encryption for fine-grained access control in clouds,” in CODASPY,
ACM, 2012, To appear.
[11] P. S. L. M. Barreto, S. D. Galbraith, C. O’Eigeartaigh, and M. Scott,
“Efficient pairing computation on supersingular abelian varieties,”
Des. Codes Cryptography, vol. 42, no. 3, pp. 239–271, 2007.
[12] A. Harrington and C. D. Jensen, “Cryptographic access control in a
distributed file system,” in SACMAT, ACM, 2003, pp. 158–165.
[13] A. V. D. M. Kayem, “Adaptive cryptographic access control for dynamic data sharing environments,” Ph.D Thesis, Queens University
Kingston, Ontario, Canada, October 2008.
[14] A. Sahai and B. Waters, “Fuzzy identity-based encryption,” in
EUROCRYPT, Springer, 2005, pp. 457–473.
[15] V. Goyal, A. Jain, O. Pandey, and A. Sahai, “Bounded ciphertext
policy attribute based encryption,” in ICALP (2), 2008, pp. 579–591.
[16] E. Bertino, B. Carminati, and E. Ferrari, “A temporal key management scheme for secure broadcasting of xml documents,” in CCS,
ACM, 2002, pp. 31–40.

2580

On Economic Mobile Cloud Computing Model
Hongbin Liang1,3 , Dijiang Huang2 , and Daiyuan Peng1
1

3

School of Information Science and Technology, Southwest Jiaotong University
2
School of Computing Informatics and Decision Systems Engineering,
Arizona State University
Department of Electrical and Computer Engineering, University of Waterloo

Abstract. Cloud has become a promising service model for mobile devices. Using cloud services, mobile devices can outsource its computationally intensive operations to the cloud, such as searching, data mining, and
multimedia processing. In this service computing model, how to build an
economic service provisioning scheme is critical for mobile cloud service
providers. Particularly when the mobile cloud resource is restricted. In
this paper, we present an economic mobile cloud computing model using
Semi-Markov Decision Process for mobile cloud resource allocation. Our
model takes the considerations the cloud computing capacity, the overall
cloud system gain, and expenses of mobile users using cloud services.
Based on the best of our knowledge, our presented model is the ﬁrst to
address the economic service provisioning for mobile cloud services. In
the performance evaluation, we showed that the presented economic mobile cloud computing model can produce the optimal system gain with
a given cloud service inter-domain transfer probability.
Keywords: Mobile Cloud Computing, Semi-Markov Decision Process.

1

Introduction

With the development of wireless access technologies such as 3/4G, LTE, and
WiMax, mobile devices can gain access to the network core over longer distances and larger bandwidths. This allows for very eﬀective communication between mobile devices and the cloud infrastructure. A new service architecture is
necessary to address the requirements of users in their unique operational environment and create new mobile applications. Cloud computing is a new business
model focusing on resource-on-demand, pay-as-you-go, and utility-computing [1].
Cloud computing can be broadly classiﬁed as infrastructure-as-a-service (IaaS),
platform-as-a-service (PaaS), and software-as-a-service (SaaS). Critical research
issues for cloud computing such as computation oﬄoading, remote execution,
and dynamic composition have been extensively discussed in previous literature.
Recent research have been focused on cloud computing for mobile devices [4,6,
9]. Cloud computing for mobile devices has a major beneﬁt in that it
enables running applications between resource-constrained devices and Internetbased Clouds. Moreover, resource-constrained devices can outsource computation/communication/resource intensive operations to the cloud. CloneCloud [2]
M. Griss and G. Yang (Eds.): MOBICASE 2010, LNICST 76, pp. 329–341, 2012.
c Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2012


330

H. Liang, D. Huang, and D. Peng

focuses on execution augmentation with less consideration on user preference or
device status. Samsung has proposed the concept of elastic applications, which
can oﬄoad components of applications from mobile devices to cloud [10]. We
generalize mobile cloud services based on the MobiCloud computing model presented in [3], which is shown in Figure 1. Mobile cloud uses weblets (application
components) to link the cloud services and mobile devices. A weblet can be
platform independent such as using Java or .Net bytecode or Python script or
platform dependent, using a native code. However, its execution location can be
run on a mobile device or migrated to the cloud, i.e., run on one or more virtual
nodes oﬀered by an IaaS provider. In this way, an elastic application can dynamically augment the capabilities of a mobile device, including computation power,
storage, and network bandwidth, based on the devices’ status with respect to
CPU load, battery power level, network connection quality, security, etc. One or
more weblets are running in the Weblet Container (WC).

New (transferred
from other domains)

Mobile Cloud Service Provisioning
Domain 2

Inter-domain
Transfer
W

W

SN

Mobile Cloud Service
Provisioning Domain 1

W

W

SN

SN

W

W

W

SN

SN

Intra-domain
Transfer

New

SN

Mobile Cloud Service
Provisioning Domain 3
New

Virtualization
WC

WC

W: Weblet
WC: Weblet Container
SN: Service Node

Mobile device pool

Fig. 1. Reference Model of Mobile Cloud Computing

In the cloud, a service node (SN) is responsible for managing the weblet’s
loading and unloading in the virtual image. An SN can only handle one weblet
from either a new migrated weblet request or a transferred weblet request. Each
virtual image has a capacity to hold one weblet at a time. The SN can handle
three types of service requests: (i) New : a new weblet migration request received
from a mobile device or transferred from other mobile cloud service provisioning
domains, (ii) Intra-domain transfer : an existing weblet transferred from one SN
to another within the same mobile cloud service provisioning domain, and (iii)
Inter-domain transfer : a weblet transferred from current mobile cloud service
provisioning domain to another one.
In our presented mobile cloud service model, the cloud can provide a large
numbers of virtual images (one virtual image is associated with one CPU, and
the CPU can only handle one weblet at a time), however, in reality, the number
of virtual images is restricted by the capacity of the cloud hardware conﬁguration. The inter-domain weblet transfer (the third type of service request)

On Economic Mobile Cloud Computing Model

331

means the lose of revenue for the current mobile service provider. As a result,
an economic mobile computing model is desired to maximally utilize the cloud
resource and achieve the maximum beneﬁt (economic gain) at the same time.
The presented economic mobile computing model consists three types of weblet
migrations. We diﬀerentiate these migrations based on their economic gains, in
which a intra-domain weblet transfer migration from another SN usually generates higher economic gain than a new weblet migration from the mobile device or
another mobile cloud service provisioning domain, and the inter-domain transfer
migration means the lose of revenue. Besides the economic gain, the presented
economic mobile computing model also needs to consider the cost due to CPU
(or virtual image) occupation. Moreover, the model also needs to consider the
trade-oﬀs of the battery consumptions of mobile devices vs. the expenses of using
cloud services. Thus, the total economic gain is determined by a comprehensive
approach taking all the above mentioned considerations.
In this paper, we present an economic mobile computing model based on SemiMarkov Decision Process (SMDP) model. The contributions of our solutions are
in three-fold:
– We ﬁrstly apply the Semi-Markov Decision Process to derive the optimal
resource allocation policy for mobile cloud computing.
– Our model can take into the considerations both maximizing the system gain
of the cloud and reducing the expenses for mobile users.
– Finally, our model can be used to achieve the maximum system gain with a
given inter-domain transfer probability constraint.
The rest of this paper is arranged as follows: In Section 2, we present basic
system models. In Section 3, the Semi-Markov Decision Process model for mobile
cloud computing is presented. We present the inter-domain transfer probability
in Section 4. The performance evaluation is presented in Section 5. Finally, we
conclude our work in Section 6.

2

System Description

We consider that a mobile cloud consists of two types of nodes, virtual SNs and
physical mobile devices (MDs). An MD is a wireless node with limited computing
capability and energy supply. An MD can migrate its mobile codes (i.e., weblet)
to the cloud. When the cloud receives a migration request, it will decide: wether
the SN should accept the request or perform inter-domain transfer based on the
consideration if the overall system gain of acceptance.
In the following, we present the system assumptions and states, and the reward
model for the mobile cloud computing system.
2.1

System Assumptions

We assume that a service running at an MD or an SN in the cloud costs diﬀerently. For simplicity, we also assume the CPU in the cloud is single thread, thus,

332

H. Liang, D. Huang, and D. Peng

each weblet in processing occupies one CPU. There are K CPUs in the cloud
system. We reserve K − L (L < K) CPUs for the intra-domain transfer to ensure
that the weblet transfers mostly occur within a mobile cloud service provisioning domain. The distribution for a new weblet migration and an intra-domain
transfer weblet migration follows the Poisson distribution with mean rate λn
and λt , respectively. The CPU occupation time of a new weblet and that of an
intra-domain transfer weblet in an SN follow exponential distribution with mean
rate μn and μt , respectively.
2.2

System States

The system states can be described based on the service events (including both
arrival and leave events) and the service load. In mobile cloud computing system
model, we can deﬁne three service events: 1) a new weblet request arrives from
an MD or another mobile cloud service provisioning domain, denoted by An ; 2)
an intra-domain transfer weblet request arrives from one SN to another within
the same mobile cloud service provisioning domain, denoted by At ; and 3) a
weblet leaves current mobile cloud domain, denoted by F . The service load can
be represented as the numbers of new weblets and intra-domain transfer weblets
in the mobile cloud, which are denoted as sn and st , respectively. Therefore, the
system state can be expressed as
S = {ŝ|ŝ = (sn , st , e)},
where 0 ≤ sn + st ≤ K, 0 ≤ sn ≤ L, L < K, K is the number of CPUs, K − L
is the number of reserved CPUs for the intra-domain transfer weblet migration.
Here, L is the maximal number of CPUs for the new weblet migration and
e ∈ {An , At , F }.
2.3

Reward Model

For a system state with an incoming weblet migration service request (i.e., An
or At ), two actions can be adopted by the mobile cloud: accept or transfer
(without speciall notice, the “transfer” means inter-domain transfer in the rest
of this paper). We denote the action to accept the request as a<s,e> = 1 and the
action to transfer the request as a<s,e> = 0, where s = (sn , st ) and e ∈ {An , At }.
On the other hand, for a system state with a weblet leave, there is no action to
be performed and we deﬁne the action as a<s,F > = 0. Then, the action space is
deﬁned as Actŝ , where
⎧
⎨ 0 (no action), e = F
Actŝ = 0 (transfer), e ∈ {An , At }
(1)
⎩
1 (accept),
e ∈ {An , At }.
We also simplify the action as a, where a ∈ Actŝ .

On Economic Mobile Cloud Computing Model

333

Based on the system state and its corresponding action, one can evaluate the
reward to the cloud, which is computed based on the income and the cost as
follows:
r<s,e> = w<s,e> + g<s,e> , e ⊆ {An , At , F },
(2)
where w<s,e> is the net lump sum income for the cloud and a mobile device,
and it is computed as:
⎧
a<s,e> = 0, e ∈ {An , At , F }
⎨ 0,
(3)
w<s,e> = (αs − αd ) En + γ d Ud , a<s,An > = 1
⎩
(αs − αd ) Et + γd Ud , a<s,At > = 1.
Here, αs and αd are weight factors for cloud and mobile device, respectively.
They satisfy 0 ≤ αs , αd ≤ 1 and αs + αd = 1. En and Et are the incomes of
the cloud when it accepts a new weblet migration request from an MD, or an
intra-domain transfer weblet migration request from a diﬀerent SN. Here, Ud
represents the income measured by the saved battery energy for the MD when
the cloud accepts the weblet migration. γd is the weight factor that satisﬁes
0 ≤ γd ≤ 1.
In (2), g<s,e> denotes the system cost and it is given by:
g<s,e> =τ<s,e> o<s,e> , a<s,e> ∈ Actŝ .

(4)

In (4), τ<s,e> is the average service time when the system state transfers from
< s, e > to the next potential state; o<s,e> is the cost rate of the service time,
and it is deﬁned as
⎧
a<s,e> = 0, e ∈ {An , At , F }
⎨ −f (sn , st ),
o<s,e> = −f (sn + 1, st ), a<s,An > = 1
(5)
⎩
−f (sn , st + 1), a<s,At > = 1,
where f (·) is a linear function of sn and st .

3

SMDP Based Mobile Computing Model

SMDP known as stochastic dynamic programming can be used to model and
solve dynamic decision making problems. The SMDP model has the following
elements: system states, action sets, the events cause the decision, decision
epochs, transition probabilities, and rewards. We use standard notations and
deﬁnitions as deﬁned in [7] for our SMDP-based problem formulation.
Based on the SMDP model, to obtain the maximum long term reward, we
need to calculate the transition probabilities between each system state. There
are only three events in the cloud (i.e., a new weblet migration request arrival,
an intra-domain transfer weblet migration request arrival, and a weblet leave).
The next decision epoch occurs when any of the events takes place. TAn and
TAt denote the time intervals from current state to the next weblet migration
event, and TF denotes the time interval from current state to the next weblet

334

H. Liang, D. Huang, and D. Peng

leave event. Then, the next decision epoch T satisﬁes T = min(TAn , TAt , TF ).
TAn , TAt , and TF follow exponential distributions with rate λn , λt , and (sn μn +
st μt ), respectively. Thus, T follows exponential distribution with rate λn + λt +
sn μn + st μt . Then, the expected time between current state and a new state can
be expressed as:
⎧
−1
⎨ [sn μn + st μt + λn + λt + a<s,An > μn ] , e = An
−1
(6)
τ (ŝ, a) = [sn μn + st μt + λn + λt + a<s,At > μt ] , e = At
⎩
−1
e
=
F.
[sn μn + st μt + λn + λt ] ,
q(j|ŝ, a) denotes the state transition probability from the current state ŝ to the
next state j when action a is chosen. For a states ŝ =< s, e > (e ∈ {An , At , F })
with action a = 0, q(j|ŝ, a) can be obtained as follow:
⎧
λn τ (ŝ, a), j =< sn , st , An >, sn ≥ 0, st ≥ 0
⎪
⎪
⎨
λt τ (ŝ, a),
j =< sn , st , At >, sn ≥ 0, st ≥ 0
(7)
q(j|ŝ, a) =
μ
τ
(ŝ,
a),
j
=< sn − 1, st , F >, sn ≥ 1, st ≥ 0
s
⎪
n n
⎪
⎩
st μt τ (ŝ, a), j =< sn , st − 1, F >, sn ≥ 0, st ≥ 1.
where 0 ≤ sn + st ≤ K, 0 ≤ sn ≤ L.
For a states ŝ =< sn , st , e > (e ∈ {An , At }) with action a = 1, q(j|ŝ, a) can
be obtained as follow:
⎧
j =< sn + 1, st , An >, sn ≥ 0, st ≥ 0
λn τ (ŝ, a),
⎪
⎪
⎨
λt τ (ŝ, a),
j =< sn , st + 1, At >, sn ≥ 0, st ≥ 0
(8)
q(j|ŝ, a) =
(sn + 1)μn τ (ŝ, a), j =< sn − 1, st , F >, sn ≥ 1, st ≥ 0
⎪
⎪
⎩
(st + 1)μt τ (ŝ, a), j =< sn , st − 1, F >, sn ≥ 0, st ≥ 1.
where 0 ≤ sn + st ≤ K, 0 ≤ sn ≤ L.
Figure 2 shows the state transition probabilities when there exists only one
type of weblet migrations in the mobile cloud.
Since the time between two decision epochs can be regarded as exponentially
distributed and the expected time between two decision epochs is τ (ŝ, a). Then
the distribution of the time between two decision epochs is given as:
F (t̄|ŝ, a) = 1 − e−τ (ŝ,a)

−1

t̄

, t̄ ≥ 0.

(9)

Then we have
Q(t̄, j|ŝ, a) = q(j|ŝ, a)F (t̄|ŝ, a),

(10)

where (10) denotes if at a decision epoch the system occupies state ŝ ∈ S,
after the cloud chooses an action a from the set of Actŝ at state ŝ. The next
decision epoch occurs at or before time t̄, and the system state at that decision
epoch equals j with probability Q(t̄, j|ŝ, a). We use Q(dt̄, j|ŝ, a) and F (dt̄|ŝ, a)to
represent the time-diﬀerential.
Then we can get the reward of the system when an event (arrival or leave)
occurs. To incorporate the action into the notations, we let r(ŝ, a) denote r<s,e> ,
h(ŝ, a) denote h<s,e> , and o(ŝ, a) denote o<s,e> . As the system state does not

On Economic Mobile Cloud Computing Model

O

<2,A>

{a=1, O  2P }
O

{a=1,

O

{a=0, O  P }

{a=0, O  2P }

4P

{a=1, O  4P }

3P

{a=1, O  3P }

O

2P
}
O  2P

{a=1,

O

{a=0, O  P }

P

}

P

{a=1, O  P }



{a=0, O }

O

<1,A>

}
3P 3P

, O

P

{a=0, O }

}
2P 2P

, O

,
=0
O

{a=1, O  P }

=0
{a

=0
{a

{a

<0,A>

{a=0, O  3P }
<2,F>
<3,F>

O

<1,F>

3P

2P
}
O  2P

{a=0, O  2P }

<0,F>

{a=0,

{a=0, O  3P }

P

{a=0, O  P }

335

<3,A>

O
O  3P

}

{a=0,

O
}
O  3P

Fig. 2. An example of state transition probabilities for only one type of weblet migrations. The ﬁrst item in the brackets is the action and the second item in the brackets
is the state transition probability.

change between two decision epochs, the expected discounted reward during
τ (ŝ, a) satisﬁes:

 τ1


[1 − e−ατ1 ]
a
−αt̄
a
r(ŝ, a) = h(ŝ, a) + o(ŝ, a)Eŝ
e dt̄ = h(ŝ, a) + o(ŝ, a)Eŝ
α
0
o(ŝ, a)τ (ŝ, a)
,
(11)
= h(ŝ, a) +
1 + ατ (ŝ, a)
where α is the discounted rate.
Let D denote the class of deterministic Markovian decision rules and d denote
each deterministic Markovian decision rule. There exists a stationary deterministic optimal policy denoted by d∞ . At the current decision epoch, state ŝ is occupied and the cloud makes the decision to choose action d(ŝ) ∈ Actŝ under the
deterministic Markovian decision rule d. Then, when the system occupies state
j at the next decision epoch, for each d, q(j|ŝ, d(ŝ)), r(j|ŝ, d(ŝ)), and τ (ŝ, d(ŝ))
denote the state transition probability, reward, and expected occupation time
between two states, respectively, in which they are deﬁned as follows:
qd (j|ŝ) = q(j|ŝ, d(ŝ)); rd (j|ŝ) = r(j|ŝ, d(ŝ)); τd (ŝ) = τ (ŝ, d(ŝ)).
Thus, under the decision rule d, we deﬁne the distribution of the time between
two decision epochs as Fd (t̄|ŝ) = F (t̄|ŝ, d(ŝ)), and then we can rewrite (10) as:
Qd (t̄, j|ŝ) = Q(t̄, j|ŝ, d(ŝ)).
The expected inﬁnite-horizon discrete-time discounted reward is
	 ∞
∞
d∞
e − αt̄ Qd (dt̄, j|ŝ) ναd (j),
να (ŝ) = rd (ŝ) +
j ∈S

0

(12)

336

H. Liang, D. Huang, and D. Peng

where Qd (dt̄, j|ŝ) = qd (j|ŝ)Fd (dt̄|ŝ) is derived from (10).
According to (9), the long-term reward (12) can be simpliﬁed as:


  ∞
∞
∞
−1 −[α+τ (ŝ)−1 ]t̄
d
ναd (ŝ) = rd (ŝ) +
τ
(ŝ)
e
d
t̄
qd (j|ŝ)ναd (j)
d
0
j∈S


∞
= rd (ŝ) + 1+τd1(ŝ)α
qd (j|ŝ)ναd (j).

(13)

j∈S

To simplify the calculation, we assume that τd (ŝ)−1 is a constant, and τd (ŝ)−1 =
k for all ŝ ∈ S. Then the equation (13) can be rewritten as:
	
∞
∞
ναd (ŝ) = rd (ŝ) + λ
qd (j|ŝ)ναd (j),
(14)
j ∈S
k
where λ = k+α
. Thus the optimal reward has the discrete-time discounted evaluation equation as:
⎫
⎧
⎬
⎨
	
ν(ŝ) = max r(ŝ, a) + λ
q(j|ŝ, a)ν(j) .
(15)
⎭
a∈Actŝ ⎩
j∈S

Since the system cost g<s,e> is a continuous-time Markov decision process with
constant transition rate k, it can be uniformized so that the results and algorithms for discrete-time discounted models can be used directly. We deﬁne an
uniformization of the continuous-time Markov decision process with components
denoted by “˜”. Let S̃ = S, Ãctŝ = Actŝ , Q̃d denote the matrix with components
qd (j|ŝ) for all ŝ ∈ S̃. We use the same assumption given by [7], where
[1 − q(ŝ|ŝ, a)]τ (ŝ, a)−1 ≤ k̃.

(16)

Based on this assumption, we deﬁne a constant k̃ = λn +λt +K∗max(μn , μt ) < ∞
satisfying any ŝ ∈ S. The uniformization maximum v(ŝ) of optimal rule d can
be obtained as:
⎧
⎫
⎨
⎬
	
q̃(j|ŝ, a)ν(j) .
ν(ŝ) = max r̃(ŝ, a) + λ
(17)
⎭
a∈Ãctŝ ⎩
j∈S

where λ =

k̃
,
k̃+α

r̃(ŝ, a) ≡

1+ατ (ŝ,a)
r(ŝ, a) (α+
,
k̃)τ (ŝ,a)



q̃(j|ŝ, a) =

and

[1−q(ŝ|ŝ,a)]
,j =
τ (ŝ,a)k̃
q(j|ŝ,a)
,
j 	= ŝ.
τ (ŝ,a)k̃

1−

ŝ

(18)

Since the state space and action space is limited, then the maximum of equation
(17) exists for all ν ∈ V . In [7], the author proved that if the maximum of (17)
is obtained for each ν ∈ V , then there exists a stationary deterministic optimal
policy d∗ . Thus, we have


d∗ ∈ arg max r̃d +λQ̃d ν(ŝ) ,
(19)
d∈D

∗ ∞

which means that (d ) is optimal. To obtain the maximum ν(ŝ) and optimal
d∗ , we can use Value Iteration Algorithm that is described in [7].

On Economic Mobile Cloud Computing Model

4

337

Inter-domain Transfer Probability

One of an important QoS metrics of the cloud system is the inter-domain transfer
probability for end users. This is because the inter-domain service transfer may
cause service disruptions or incur longer service delay. In this section, we discuss
and attain the inter-domain probability based on the presented SMDP-based
mobile cloud computing model.
From (17), the expected total discounted reward ν(ŝ) at state ŝ ∈ S is only
related with λn , λt , μn , μt and K. For a state of weblet leave, there is no action (i.e., a = 0). Therefore, we only need to consider the state with weblet
migration arrivals. If λn , λt , μn , μt and K are ﬁxed, then ν(ŝ) is also ﬁxed at
state < sn , st , A >, A ∈ {An , At }. Moreover, the action a ∈ {0, 1} at state
< sn , st , A >, A ∈ {An , At } is ﬁxed, i.e., accept or transfer (i.e., inter-domain
service transfer). From the system point of view, the purpose to accept or transfer a weblet migration request is to achieve higher long-term rewards at state
< sn , st , A >, A ∈ {An , At }. Let π<sn ,st ,e> , e ∈ {An , At , F } denote the steadystate probability of state < sn , st , e >, e ∈ {An , At , F }, π<sn ,st ,A> , A ∈ {An , At }
denote arrival steady-state probability of state < sn , st , A >, A ∈ {An , At }. From
n
t
[8], we can simply use Pinter−transf er = Pinter−transf
er + Pinter−transf er as the
n
inter-domain transfer probability for the entire system, where Pinter−transf
er
t
and Pinter−transf er are inter-domain transfer probabilities for new weblet migration requests and intra-domain transfer requests, respectively. The entire system
inter-domain transfer probability Pinter−transf er is a ratio of all inter-domain
transferred weblets migration requests to all arrived weblets migration requests,
which is deﬁned as:
N


Pinter−transf er =

H


sn = 0 st = 0

((1−a<sn ,st ,An > )π<sn ,st ,An > +(1−a<sn ,st ,At > )π<sn ,st ,At > )
N


H


(π<sn ,st ,An > +π<sn ,st ,At > )

sn = 0 st = 0

,

0 ≤ N +H ≤ K, 0 ≤ N ≤ L
(20)

where a<sn ,st ,An > ∈ Ãctŝ is the action adopted at state < sn , st , An > and
a<sn ,st ,At > ∈ Ãctŝ is the action adopted at state < sn , st , At >.
According to the result of [5], we can derive π<sn ,st ,e> , e ∈ {An , At , F } as:
π<sn ,st ,An > =
(1 − a<sn ,st ,An > )π<sn ,st ,An > k̃+λk̃n −β + (1 − a<sn ,st ,At > )π<sn ,st ,At > λk̃n
n
+ a<sn ,st ,An > π<sn ,st ,An > k̃−β−μ
+ π<sn ,st ,F > λk̃n
k̃
λn
λn
+ a<smax
,st ,An > π<smax
,st ,An > k̃ + a<sn ,smax
,At > π<sn ,smax
,At > k̃ ,
t
t
n
n

π<sn ,st ,At > =
(1 − a<sn ,st ,An > )π<sn ,st ,An > λk̃t + (1 − a<sn ,st ,At > )π<sn ,st ,At > k̃+λk̃t −β
t
+ a<sn ,st ,At > π<sn ,st ,At > k̃−β−μ
+ π<sn ,st ,F > λk̃t
k̃
λt
λt
+ a<smax
,st ,An > π<smax
,st ,An > k̃ + a<sn ,smax
,At > π<sn ,smax
,At > k̃ ,
n
n
t
t

338

H. Liang, D. Huang, and D. Peng

π<sn ,st ,F > = π<smin
n ,st ,F >

smin
n μn
k̃

+ π<sn ,smin
,F >
t

+ (1 − a<smin
)π<smin
,st ,An >
n ,st ,An >
n

smin
n μn

μt
smin
t
k̃

+ π<sn ,st ,F > k̃−β
k̃

k̃
μt
smin
t
k̃
min
sn μn
(1 − a<smin
)π<smin
n ,st ,At >
n ,st ,At >
k̃
μt
smin
t
min
(1 − a<sn ,smin
)π
,At > <sn ,st ,At >
t
k̃
min
μ
μt
s
smin
t
a<sn ,st ,An > π<sn ,st ,An > n k̃ n + a<smax
,smin
,An > π<smax
,smin
,An >
n
n
t
t
k̃
min
min
s
μ
sn μn
max ,A > π<smin ,smax ,A >
a<sn ,st ,At > π<sn ,st ,At > t k̃ t + a<smin
,
t
t
t
n ,st
n
k̃

+ (1 − a<sn ,smin
,An > )π<sn ,smin
,An >
t
t
+
+
+
+

(21)
where β = sn μn + st μt + λn + λt , 0 ≤ sn + st ≤ K and 0 ≤ sn ≤ L. To
= min(sn + 1, K − st , L), smin
=
cover the boundary conditions, we deﬁne smin
n
t
max
=
max(s
−
1,
0).
min(st + 1, K − sn ), sn = max(sn − 1, 0) and smax
t
t
The summation of the steady-state probability for all states is equal to 1, and
thus we have:
N



H



sn = 0 st = 0

π<sn ,st ,e> = 1, e ∈ {An , At , F }, 0 ≤ N + H ≤ K, 0 ≤ N ≤ L.

(22)
Based on Equations (21) and (22), the steady-state occurring probability
π<sn ,st ,e> , e ∈ {An , At , F } can be obtained. Thus, the entire system interdomain transfer probability Pinter−transf er can be attained.

5

Performance Evaluation

The inter-domain transfer probabilities of our presented SMDP-based mobile
cloud computing model are compared with that computed by using Guard occupation model [8]. We conduct a simulation-based study, in which the comparative
results are presented in Figure 3. In this simulation, we set the new weblet migration request arrival rate λn as 5, the intra-domain transfer weblet migration
request arrival rate λt as 2, and the leave rates of both new and intra-domain
transfer migration requests (μn and μt ) as 4. We set the maximal number of
CPUs for the new weblet migration requests L = 
0.8K. Thus, the number of
reserved CPUs for the weblet intra-domain transfer migration requests is K − L.
For each value of K, we run the simulation for 5 times.
In Figure 3, we observe that the inter-domain transfer probabilities of both
SMDP-based occupation model and Guard occupation model decrease with the
increase of the number of CPUs. Additionally, we can see that the inter-domain
transfer probability is only related to the total number of CPUs in the cloud
when the arrival rate and leave rate of weblets are ﬁxed. This also conﬁrms our
discussion about the inter-domain tranfer probability presented in Section 4.
We also observe that if the number of CPUs is smaller than 10 or larger than
22, the diﬀerences of the inter-domain transfer probabilities between the SMDPbased occupation model and Guard occupation model is very small. In addition,

On Economic Mobile Cloud Computing Model

339

Inter−domain Transfer Probability
(New + Intra−domain Transfer weblet request)

1.6
SMDP−based Occupation Model
Guard Occupation Model
1.4
1.2
1
0.8
0.6
0.4
0.2
5

10

15
The Number of CPUs

20

25

Fig. 3. An example to compare the inter-domain transfer probabilities of using SMDP
occupation model and Guard occupation model

if the number of CPUs is between 10 and 22, then, the diﬀerences of the interdomain transfer probabilities are increased. This phenomena can be explained
as follows:
– If the number of CPUs is small (i.e., less than 10 in our simulation), then,
both SMDP-based occupation model and Guard occupation model cannot
accommodate the incoming weblet migration requests for the given simulation setting. As a result, both inter-domain transfer probabilities are high.
– If the number of CPUs is large (i.e., larger than 22 in our simulation), then,
SMDP-based occupation model and Guard occupation model have suﬃcient
CPUs to accommodate the coming weblet migration requests for the given
simulation setting. Thus, both inter-domain transfer probabilities are low.
– If the number of CPUs is moderate (i.e., between 10 and 22 in our simulation), the inter-domain transfer probability of the SMDP-based occupation
model is higher than that computed by using the Guard occupation model.
This is because the SMDP-based occupation model focuses more on the
maximal system reward that involves the system income and cost, service
expenses of MDs, and conservation of energy consumption of MDs. However,
the Guard occupation model purely focuses on the reduction of inter-domain
transfer rate, which may not be the optimal in terms of system reward.
In general, the increase of the inter-domain transfer probability not only means
the decrease of the revenue of a mobile cloud service provider, but also means
the disruption of a service. Thus, the system reward should be obtained under
a given inter-domain transfer probability to satisfy the desired QoS, i.e., the

340

H. Liang, D. Huang, and D. Peng

optimal policy d∗ should also consider the restriction enforced by the given interdomain transfer probability.
If the inter-domain transfer probability is given by PB , then the system reward
(17) can be rewritten as:
⎧
⎫
⎨
⎬
	
ν(ŝ) =
max
q̃(j|ŝ, a)ν(j) .
r̃(ŝ, a) + λ
(23)
Pinter−transf er ≤PB ,a∈Actŝ ⎩
⎭
j∈S

The optimal policy (17) can be rewritten as:
d∗ ∈ arg

6

max

Pinter−transf er ≤PB ,d∈D



r̃d +λQ̃d ν(ŝ) .

(24)

Conclusion

In this paper, we present an economic mobile cloud computing model based
on Semi-Markov Decision Process. In our approach, both the maximal system
reward and expenses of mobile devices are considered. We present the interdomain transfer probability of the SMDP-based mobile cloud computing model
using both theoretical approach and simulation comparative studies. Particularly, we derive both the constraint maximal system reward and the optimal
decision policy under a given inter-domain transfer probability. In the future, we
will incorporate more system metrics into the constructions of the reward function such as diﬀerent application tasks or security levels based on multi-threads
CPUs. Moreover, we will investigate the optimal CPUs allocation issues using
the SMDP-based occupation model.
Acknowledgement. Hongbin Liang’s research is supported by the China Scholarship Council and Dijiang Huang’s research is supported by the Oﬃce of Naval
Research’s Young Investigator Program.

References
1. Armbrust, M., Fox, A., Griﬃth, R., Joseph, A., Katz, R., Konwinski, A., Lee, G.,
Patterson, D., Rabkin, A., Stoica, I., et al.: Above the clouds: A berkeley view
of cloud computing. EECS Department, University of California, Berkeley, Tech.
Rep. UCB/EECS-2009-28 (2009)
2. Chun, B., Maniatis, P.: Augmented Smartphone Applications Through Clone
Cloud Execution. In: Proceedings of USENIX HotOS XII (2009)
3. Huang, D., Zhang, X., Kang, M., Luo, J.: Mobicloud: A secure mobile cloud framework for pervasive mobile computing and communication. In: Proceedings of 5th
IEEE International Symposium on Service-Oriented System Engineering (2010)
4. Lyons, K., Pering, T., Rosario, B., Sud, S., Want, R.: Multi-display Composition:
Supporting Display Sharing for Collocated Mobile Devices. In: Gross, T., Gulliksen, J., Kotzé, P., Oestreicher, L., Palanque, P., Prates, R.O., Winckler, M. (eds.)
INTERACT 2009. LNCS, vol. 5726, pp. 758–771. Springer, Heidelberg (2009)

On Economic Mobile Cloud Computing Model

341

5. Ni, W., Li, W., Alam, M.: Determination of optimal call admission control policy
in wireless networks. IEEE Transactions on Wireless Communications 8(2), 1038–
1044 (2009)
6. Pering, T., Want, R., Rosario, B., Sud, S., Lyons, K.: Enabling pervasive collaboration with platform composition. In: Proceedings of Perviasive (2009)
7. Puterman, M.: Markov decision processes: Discrete stochastic dynamic programming. John Wiley & Sons, Inc., New York (2005)
8. Ramjee, R., Towsley, D., Nagarajan, R.: On optimal call admission control in
cellular networks. Wireless Networks 3(1), 29–41 (1997)
9. Li, X., Zhang, H., Zhang, Y.: Deploying Mobile Computation in Cloud Service. In:
Jaatun, M.G., Zhao, G., Rong, C. (eds.) Cloud Computing. LNCS, vol. 5931, pp.
301–311. Springer, Heidelberg (2009)
10. Zhang, X., Schiﬀman, J., Gibbs, S., Kunjithapatham, A., Jeong, S.: Securing elastic
applications on mobile devices for cloud computing. In: Proceedings of the 2009
ACM Workshop on Cloud Computing Security, pp. 127–134 (2009)

Ad Hoc Networks 7 (2009) 1526–1535

Contents lists available at ScienceDirect

Ad Hoc Networks
journal homepage: www.elsevier.com/locate/adhoc

ASPE: attribute-based secure policy enforcement
in vehicular ad hoc networks
Dijiang Huang *, Mayank Verma
Department of Computer Science and Engineering, Arizona State University, 699 S Mill Avenue, Tempe, AZ 85281, United States

a r t i c l e

i n f o

Article history:
Available online 23 April 2009

Keywords:
Security
Vehicular networks
Secure group communications
Key management
Attribute based encryption

a b s t r a c t
Vehicular ad hoc networks (VANETs) are usually operated among vehicles moving at high
speeds, and thus their communication relations can be changed frequently. In such a highly
dynamic environment, establishing trust among vehicles is difﬁcult. To solve this problem,
we propose a ﬂexible, secure and decentralized attribute based secure key management
framework for VANETs. Our solution is based on attribute based encryption (ABE) to construct an attribute based security policy enforcement (ASPE) framework. ASPE considers
various road situations as attributes. These attributes are used as encryption keys to secure
the transmitted data. ASPE is ﬂexible in that it can dynamically change encryption keys
depending on the VANET situations. At the same time, ASPE naturally incorporates data
access control policies on the transmitted data. ASPE provides an integrated solution to
involve data access control, key management, security policy enforcement, and secure
group formation in highly dynamic vehicular communication environments. Our performance evaluations show that ASPE is efﬁcient and it can handle large amount of data
encryption/decryption ﬂows in VANETs.
Ó 2009 Elsevier B.V. All rights reserved.

1. Introduction
In vehicular ad hoc networks (VANETs), which include
both vehicles and roadside units, security and privacy
research is mainly based on the entity level or data level
(a.k.a., entity trust [1–5] vs. data trust [6]). At the entity
level, previous research mainly focused on how to ensure
the genuineness of the data source, i.e., providing origin
integrity. The entity trust requires validation of an entity
(e.g., an identity, a license number, or a pseudonym),
which is usually performed by using authentication techniques. The data trust requires to evaluate the trustworthiness of data contents. The evaluation technologies of data
trust can be generally classiﬁed as data integrity checking,
probability based statistic modeling techniques, and
majority rule-based evaluation. In VANETs, transmitted
* Corresponding author. Tel.: +1 480 965 2776; fax: +1 480 965 2751.
E-mail addresses: dijiang@asu.edu (D. Huang), mayank.verma@asu.
edu (M. Verma).
1570-8705/$ - see front matter Ó 2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.adhoc.2009.04.011

data should be accessed by their intended receivers. However, due to fast movements of vehicles, most existing key
management solutions only consider setting up entity
trust without considering who should access the data.
Moreover, due to the broadcasting nature of VANETs, it is
desirable to enforce a group-based key management solution to improve the communication efﬁciency with strong
security and privacy policies on who are eligible for the
corresponding group communications. This factor has been
largely ignored in existing solutions for both the entity
trust and data trust. Thus, it is highly desired to allow
the data source to specify the security access control policies on the broadcasted data.
To enable the security data access control policy in
VANETs, we use attributes as the basic properties of vehicles
for access control and secure group communications in VANETs. Particularly, attributes are used to describe the roles
of VANET communication participants. Attributes abstract
entity and data trust at a certain level, and they can be used
to identify a group of entities. For example, attributes can

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

be described as follows: (i) ownership of vehicles: taxes are
associated with a company, police cars in a city, (ii) type of
events: accidents, congestions, and (ii) property of events:
location-based services, road trafﬁc updates, etc. Attributes
can be further classiﬁed as dynamic and static attributes,
depending on whether the attributes change frequently or
remain the same during a relatively long period in comparison to ephemeral connections of VANETs. Vehicles that fulﬁll a set of descriptive attributes form a group. Considering
attributes as policies associated with a group, we introduce
a new concept policy group. A policy group is a group of
vehicles conﬁned by their attributes, such as common
interests, security or service requirements, or environmental constraints (e.g., street name, time, driving direction,
etc.). A lpolicy group is deﬁned by the message source
and is organized automatically without relying on an online trust party to manage the group. This means as long
as a vehicle ‘‘satisﬁes” the speciﬁed attributes by the message source, it will be able to decrypt the message encrypted by using the given attributes. To enable such a
capability, we propose a novel attribute-based security policy enforcement (ASPE) framework by using the basic formation of attribute-based encryption (ABE) scheme [7],
which utilizes identity based encryption (IBE) [8] and
threshold secret sharing scheme [9].
Our contributions are in three-fold: (i) ASPE provides an
architectural solution that enforces policy control in highly
dynamic communication environments. The policies
deﬁned are based on vehicles’ surrounding situations and
can be modiﬁed to achieve different security and privacy
goals for VANETs. We describe the ASPE architecture by
deﬁning policies for data access control through vehicular
group communications. (ii) We show how ASPE policies
can be extended to perform subgroup vehicular communications with minimum communication and computation
overhead. (iii) We present an optimization of ABE for
vehicular networks, which helps ASPE run more efﬁciently.
Our performance evaluations demonstrate the soundness
of ASPE for large-scale vehicular networks.
The rest of the paper is organized as follows: Section 2
details previous work in area of vehicular group communication; In Section 3, we present the ASPE model; Section 4
describes ASPE in detail; Performance evaluation of ASPE is
detailed in Section 5; Finally, we conclude our work in
Section 6.

2. Related work
In VANETs, the group formation, key distribution, and
group maintenance are difﬁcult tasks considering the
ephemeral vehicle-to-vehicle communications. In CARAVAN [10], the group formation assumes that vehicles forming a group are moving with the similar speed and
maintaining relatively constant distance from each other.
This assumption is very restricted in that it assumed a very
ideal communication scenario in VANETs. Moreover, the
methodology adopted by CARAVAN faces following issues:
(1) All vehicles moving at a similar velocity within a certain distance forms a group. Thus, the group formation is
very restricted. (2) The selection procedure of group leader

1527

invokes additional communication overhead. (3) The communication overhead within the group (V2V) and outside
the group (V2I/I2V) is very high due to frequent exchanges
of PKI certiﬁcates for every communication session.
In [11,12], the authors propose to utilize group
communication and group signature based schemes to
achieve security and privacy. The solutions in [12] assume
that the underlying group has already been formed. The
group communications thereafter are performed by using
group signature schemes [13] to protect the privacy of
the transmitting vehicle. Similar to CARAVAN, GSIS [12]
has the similar issues of rigid group formation in dynamic
VANET communication environments. The group signature
scheme proposed by Guo et. al. [11] provides a solution for
group formation by grouping vehicles based upon their
location and roles. However, the communications among
vehicles belonging to different categories are not
addressed.
The solutions proposed by Raya and Hubaux [14] presented a location-based group formation in VANETs. The
group formation is performed based on the location of
the vehicles, i.e., based on where the vehicle is rather than
whom the vehicle is. This solution has several restrictions.
For examples, the road is assumed to be dissected into
small cells as groups. The vehicle closest to the center of
a cell is declared as group leader. A group leader encrypts
the group key with every group member’s public key to
establish secure group communications. As a result, the
key issue needs to be address is how to adjust the cell size
according to the density of vehicles on the road to maximally reduce the group management and communication
overhead. This approach requires intensive collaborations
among vehicles, which are very difﬁcult in highly dynamic
VANETs.

3. ASPE system and models
In this section, we present the network model, policy
tree formation, and the attack model. The background of
attribute based encryption is presented in Appendix A.
3.1. Network model
The network model (Fig. 1) of VANETs comprises onroad units, off-road units, and the interfacing layer. Onroad units consist of vehicles, road side units (RSUs) and
communication networks such as the cellular networks.
The on-line trusted parties, e.g., RSUs, are usually managed
by a local transportation department ofﬁce. Vehicles can
use wireless LAN technologies to establish short distance
communications or use Internet-based security services
through RSUs or cellular networks to establish remote
communications. We assume that vehicles are equipped
with following hardware units:
 Event data recorder (EDR): EDR records activities of the
vehicle such as engine overheating, and road events
such as accidents observed by the vehicle in motion.
 Tamper proof devices (TPD): TPD contains information
about the vehicle that cannot be modiﬁed, such as

1528

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

Off-Road Units
Trusted
Authority (TA)

Internet Backbone

Interfacing Layer

On-Road Units

Access Network
Road Side
Units (RSUs)

Cellular
Network
V2I
Event Data
Recorder
(EDR)

V2I
Event Data
Recorder
(EDR)

Global
Positioning
Device (GPS)

Global
Positioning
Device (GPS)

V2V
Tamper Proof
Device (TPD)

Processing
Unit (PU)

Vehicle

Tamper Proof
Device (TPD)

Processing
Unit (PU)

Vehicle
O n l in e C o m m u n ic a tio n

O fflin e C o m m u n ic a tio n

Fig. 1. Network model for ASPE.

Vehicle Identiﬁcation Number (VIN), certiﬁcates, private
keys.
 Processing units (PU): Processing units are responsible
for performing V2I, I2V or V2V communications. For
example, creating event messages, enforcing security
and privacy policies, encrypting/decrypting data, etc.
 Global position system (GPS): Every vehicle is assumed to
be equipped with GPS devices.
Off-road units consist of trusted authorities (TA) that
provides the standard key management services for users
to derive their private keys according to their dedicated
attributes. Communications between off-road and on-road
units are enabled through the interfacing layer, i.e., the
Internet.
3.2. Policy tree formation
Before describing policy tree formation, we deﬁne what
is a policy in this paper.
Deﬁnition 1. A policy is deﬁned as a rule R described over
a set of attributes Y, where Y are linked together by a tree
structure PT. The rule governs the operations over the data
by providing access control, if and only if the access
structure PT is satisﬁed with the requesters attributes.
In ASPE, an access tree structure is refereed as a Policy
Tree (PT). A PT regulates the policies by means of specifying attributes in the PT. These policies are deﬁned over a
set of attributes that describe the access control rules to
the data. These policies can be broadly categorized into
static and dynamic attributes. An example of such a
classiﬁcation is represented in Table 1, where Y s and Y d
represent static and dynamic attribute set, respectively.
The security policies are represented as a combination of
attributes and the associated logical operators (LO), as

shown in Fig. 2. For example, PT 1 ¼ ðY 1 ðx1 Þ ^ Y 1 ðx2 ÞÞ_
Y 1 ðx3 Þ represents logical operations among three attributes
fY 1 ðx1 Þ, Y 1 ðx2 Þ; Y 1 ðx3 Þg, where PT 1 is satisﬁed if either the
combination of attribute Y 1 ðx1 Þ ^ Y 1 ðx2 Þ is true or if
Y 1 ðx3 Þ is true. In this example, a PT is represented as a tree
with attributes as leaf nodes and logic operators as internal
nodes, where logic operators LO ¼ fLOi j^; _; <; 6; >; P; k
out of ng.
Example scenario: The example scenario discussed next
provides a base for understanding how policy trees assist
secure group/subgroup communications. Here, we present
an illustrative example, which will be utilized in the
following contexts. Consider a VANET scenario consisting
of vehicles and RSUs as shown in Fig. 3a. The dynamic
attributes set Y d ¼ hRN ¼ RD101 ; RS ¼ Si ; RD ¼ East=West,
ED ¼ 03=15=09; ET ¼ T s i. RSUs uses DSRC or 802.11 based
protocols to communicate with vehicles when they come
in RSUs communication range. Vehicles can communicate
with neighboring vehicles and RSUs to exchange emergency messages or normal data.
3.2.1. Private key generation and distribution
Once attributes are determined, TAs are responsible to
generating corresponding private key component1 for each
attribute possessed by a VANET user. Thus, a set of private
key components with respect to a set of attributes form a
private key for a user. It must be noted that each private
key component is derived for a public attribute. Although
multiple users can share the same attribute, their corresponding private keys are different. Moreover, they cannot
collude to gain additional attributes without generating corresponding private key components from the trusted

1
A private key component is a private key corresponding to an attribute.
It is equivalent to the private key of an identity in IBE scheme [8].

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535
Table 1
Classiﬁcation of attributes.
Road attributes

Environment
attributes

Vehicle attributes

Y d : Road name (RN)
Y d : Road segment
number (RS)
Y d : Road direction (RD)
Y d : Road intersection (RI)

Y d : Date (ED)
Y s : Vehicle category (VC)
Y d : Time stamp (ET) Y d : Vehicle application
or service (VS)
Y s : City name (EC)
Y s : State name (ES)

Fig. 2. Policy Tree example based on attributes.

authority. In essence, the attributes and logic operators
construct the policies, and users share the same set of attributes in the policy tree to form a policy group for secure
communications.
ASPE uses a hybrid and decentralized trust framework
to distribute private key components for VANET users.
For dynamic attributes, decentralized servers can be
deployed through road side units (RSUs) or through well

1529

deployed cellular networks. The private keys (SK) of static
attributes can be derived in advance using off-line methods via a TA. The private key components of dynamic attributes can be derived from a local on-line trusted server,
such as an RSU or using cellular networks.
As shown in Fig. 2, the encryption process in PT is performed through a top-down approach and the decryption
process is performed in a bottom-up fashion. In this example, the PT also shows a hierarchical structure containing
three sub-policy trees (PT 1 ; PT 2 , and PT 3 ). For example, if
vehicles possess attributes at PT 1 level, they can derive
the secret at level LO1 . However, if LO2 is an AND gate, they
must also possess attributes at the PT 2 level to retrieve the
secret at LO2 . From this example, we can see that the policy
tree approach is very ﬂexible by constructing the policy
tree structure with different logical gates, which provide
us a powerful tool to construct group and subgroup communications. In the following context, we refer to the policy tree created by the off-line trusted authority as static
s  PT and the policy tree created by the on-line trusted
parties as dynamic d  PT.
3.2.2. Policy group formation
The policies for group formation are deﬁned as a set of
rules that grant accesses to the data by restricting who can
satisfy the policy tree. In other words, policy group formation in APSE is based upon the policy trees, which are regulated by the attributes (see Table 1) common to all
vehicles. Although using common attributes can result in
very large group size; in ASPE, this group size can be conﬁned by a speciﬁc location. The group size in Fig. 3a is limited to only vehicles present at the location, as they share
common dynamic attributes RS.
3.2.3. Policy sub-group communications
Utilizing static attributes in conjunction with dynamic
attributes provides the ﬂexibility of performing subgroup

Fig. 3. (a) Example group formation in VANETs. (b) Dynamic attribute based Policy Tree.

1530

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

communications. Here, the policy is deﬁned as a set of
rules that grant data access for the policy group. For example, if the attribute vehicle category (VC) in Y s is used with
dynamic attributes in PT shown in Fig. 3b, the access to the
data is restricted to subgroup members that belong to VC.
Here, VC can be a civilian vehicle, a government vehicle, or
can belong to a speciﬁc organization or company. Consider
the example scenario, we assume that black vehicles are
police cars. As all group members sharing dynamic attributes in that location can communicate securely using
PT, the messages exchanged among the police vehicles
are also available to other group members. We can prevent
the information leakage by extending the policy tree. For
example, we can enforce another attribute: vehicle category (VC ¼ police). As civilian vehicles will not have the
private key component for the attribute VC ¼ police, they
cannot decrypt the messages exchanged among police
vehicles. It is important to note that the CP-ABE scheme
cannot be directly applied by adding another leaf node in
PT shown in Fig. 3b. This is because CP-ABE requires a universal trusted authority to generate attributes for each
vehicle. The message cannot be decrypted by combining
private key components issued from different authorities.
We solve this problem by combining multiple policy trees
(Fig. 2). The detailed procedure is explained in Section 4.
3.3. Attack model
The attack model considers existence of both passive
and active attackers. The attackers goals are to hinder
group formation and gain unauthorized access to the data
exchanged within the group. We assume that attackers can
be VANET participants. Although, RSUs and the TA cannot
be compromised, the attacker can try to impersonate an
RSU or a TA. Attackers can intercept all the trafﬁc transmitted by RSUs and vehicles, and they can inject fake
messages.

4. Descriptions of ASPE
In this section, we discuss ASPE in detail. When vehicles
entering an area controlled by an RSU, the RSU and vehicles perform mutual authentication by exchanging certiﬁcates. The certiﬁcates being issued by the trusted
authority (TA) can be veriﬁed by both vehicles and the
RSU. As the RSU is connected to the Internet, RSU also
checks vehicles’ certiﬁcate against certiﬁcate revocation
list (CRL). The RSU then generates the private key components for the dynamic attributes with respect to road conditions, location, and time. As the example shown in
Fig. 3b, there are ﬁve dynamic attributes that are monitored by RSUi (denoted as RSUðiÞ if road direction (RD)
attribute is ignored (see the dynamic attributes descriptions in Table 1). In the follows, we describe the two phases
that are involved during the ASPE procedure.
4.1. Phase I: group key distribution
In this phase, group keys are established between vehicles and they are used in Phase II to perform group and

subgroup communications. Phase I is performed by
RSUðiÞ by executing Protocol 1 after successful mutual
authentication has been performed.
Protocol 1 (Group key distribution). RSUðiÞ and vehicles
perform the following operations:
(1) RSUðiÞ chooses random numbers a; b 2 Zp and
rv 2 Zp for vehicle v 2 V, where V is the vehicle set.
(2) RSUðiÞ executes SETUP protocol (presented in Protocol 3 in Appendix A) with vehicles, and generates
v
public key PK RSUðiÞ ¼ hG0 ; g; h; f ; fa i and private masa
ter key MK RSUðiÞ ¼ hb; g i.
(3) For all vehicles in range, compute their private key
where
components
SK v ¼ hD; Dy ; 8y 2 Y d ; D0y i,
v ¼ 1; 2; 3; . . . using (A.3).
(4) For all vehicles, perform encryptions: EPK v ðSK v Þ,
where PK v is the public key of the vehicle derived
from its certiﬁcate.
(5) RSUðiÞ transmits encrypted data (EPK v ðSK v Þ) to vehicle v.
The private key components are generated for all
dynamic attributes in Y d . Apart from the road and vehicular attributes, the environmental attributes such as ET
changes more frequently. Hence, if the message is encrypted with ET at t 1 , message decryption at t2 should
not reconstruct the original message M. However, if ET is
excluded, the system will be vulnerable to replay attacks.
Thus, to include ET; RSUðiÞ generates a time stamp T s for
a speciﬁed time interval. This time stamp T s is a constant
value for the time interval t2  t1 . For example, if the time
interval is for ﬁve minutes ranging from 3:00PM–3:05PM,
the RSUðiÞ generates a time stamp T s by choosing a random
number c 2 Zp and hashing it with the RSU’s ID. As a new
random number c is chosen for every interval, the uniqueness of time stamp T s is guaranteed. Successful completion
of Protocol 1 guarantees that every vehicle has obtained
dynamic attributes along with the corresponding private
key components that vehicles will use in Phase II to perform group communications using policy trees.
4.2. Phase II: group and sub-group communication
During phase II, each vehicle can create a PT by deﬁning
its own policies. One such policy example is illustrated in
the example scenario shown in Fig. 3. Since the PT in
Fig. 3b contains only dynamic attributes, all vehicles satisfying the PT will be able to decrypt the message. Hence, a
group is formed with no clear boundaries. This ﬂexibility
signiﬁcantly reduces the overhead involved in adding/
deleting members, rearranging and updating group keys.
However, this ﬂexibility can be further extended to form
subgroups within the group at the cost of minor group
key management overhead. The advantage of subgroup
communications has been detailed in Section 3.2.3. Traditionally, the frequent group and subgroup changes will require setting up separate group keys between the speciﬁed
group members leading to signiﬁcant overhead.
In ASPE, group/subgroup formation is through the policy tree speciﬁed by the message originator, thus there is

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

a

1531

b

Fig. 4. Sub-group communication using (a) Single tree PT containing both static and dynamic attributes, (b) two separate trees, PT 1 containing static and
PT 2 dynamic attributes.

no group member addition/deletion operations and key
updates are not required. Following the PT discussed in
the example scenario (Fig. 3b), the communications performed between any two vehicles can be heard by all
group members. To restrict the communication within a
subgroup, e.g., only police vehicles, the sender can perform
subgroup communication protocol as shown as follows:
Protocol 2 (Sub-group communication protocol). A vehicle:
(1) Creates two policy trees: static policy tree PT 1 and
dynamic policy tree PT 2 .
(2) Calls Protocol 5, ENCRYPTIONhPK; M; PT 2 i and
obtains.

e ; C; 8y 2 Y d ; C y ; C 0 i
CT 2 ¼ hPT 2 ; C
y
(3) Randomly selects C y as a secret from CT 2 .
(4) Calls Protocol 5, ENCRYPTION hPK; C y ; PT 2 i and
obtains.

e 0;
CT 1 ¼ hPT 1 ; C

C 0 ; 8x 2 Y s : C 0x ; C 00x i

(5) The
ciphertext
is
in
hCT 1 ; CT 2 n C y ; PT ¼ fPT 1 ; PT 2 gi.

the

form

of

Note that the selected C y is considered as a secret and it
will not be transmitted with CT 2 . The encryption is
enforced in a top-down fashion, i.e., ﬁrst operates on PT 2 ,
and then is followed by PT 1 . The policy tree PT 1 is constructed over static attributes whereas PT 2 over dynamic
attributes as shown in Fig. 4b. In CP-ABE, the private key
components for all attributes form an access tree that are
generated using key generating parameters for a group.
Key generating parameters used in CP-ABE scheme are
a; b, and r, and they are used for generating PK; MK, and
SK, respectively. Thus, a message encrypted using PT can
be easily reconstructed using decryption protocol (Protocol
6). In ASPE, as both static and dynamic attributes are required for subgroup communications, if single policy tree
PT (Fig. 4a) is used for encrypting the message, the message cannot be reconstructed using Protocol 6. This is because the encrypting parameters are different, e.g., r
value used by the ofﬂine TA and online RSUs.

4.3. ASPE operation optimizations
In VANETs, due to vehicles’ mobility, long communication delay is not acceptable for safety-related applications.
It is desirable to minimize the delay of policy-tree-based
encryption procedures discussed in previous sections. As
ASPE is constructed based on CP-ABE, the optimization
techniques (described in CP-ABE [7]) such as combining
similar attributes can be directly applied to ASPE. Additionally, we propose two techniques to expedite the ASPE
operations. The ﬁrst operation optimization is to use a
key encryption key (KEK), which can signiﬁcantly reduce
the time of performing encryption/decryption protocol.
The data can be encrypted by running any symmetric key
encryption algorithm using the key and then the key is encrypted using a policy tree. As the key size will usually be
less then data size, encrypting KEK through PT is a cost
effective procedure. The second optimization is to standardize some common situations in VANETs. As CP-ABE requires transmitting PT in plaintext along with the CT, the
ciphertext size can be very big. To reduce this overhead,
a standard table with indexes having a generalized set of
tree structures can be embedded into the vehicle’s processing unit.2 If a generic policy tree is used, the vehicle can
send the index of the tree by looking up the table. It is
important to note that, although vehicles can create their
own policy trees, this optimization is especially useful
when communication regarding standard messages like
accident report has to be performed. In next section, we
present a comparison between traditional and optimized
CP-ABE schemes.
5. Performance assessments
In this section, we provide performance assessments
of ASPE. Particularly, our assessments focus on computation overhead, communication overhead, and security
strength.

2
The table can be installed at the time of vehicle manufacturing. We
assume that all manufacturers follow same standard indexing table.

1532

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

5.1. Performance evaluation setup
The evaluation has been performed on a 64-bit Pentium
IV with a 3.2 GHz processor. The protocol implementation
uses 160-bit elliptical curve cryptography. The vehicles are
assumed to be able to transmit data over a distance up to
1000 m. The packet payload size as per SAE J1746 standard
[15], GPS, NTCIP hazard codes [16], and standard protocol
headers [17] are set to 100, 200, or 400 (Bytes). We assume
the V2V communications use 802.11 based technologies
and V2I uses DSRC technology [18]. Following 802.11 standards, the maximum allowable payload size is 2312 bytes
(with WEP header) that we have used in our simulation to
provide the worst case performance results. In addition, as

Table 2
Notation and values.
Time
notation

Operation
time (ms)

Description

T CV
T SV
T GðKÞ
T SigðVÞ
TE
TD

0.07
0.07
0.00025
1.42
0.07
1.52

PKI certiﬁcate veriﬁcation time
Signature veriﬁcation time
256-bit symmetric key generation time
Time for signing value V
Time to encrypt messages using PKC
Time to decrypt messages using PKC

Time to generate private key for 5 attributes
3
2.5

Time (s)

2
1.5
1
Time to generate private
key for 5 attributes

0.5
0

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
Number of Vehicles

the data rate for DSRC varies from 6 to 27 mbps, the round
trip time taken for V2I/I2V communication using DSRC in
exchanging 400 bytes of data is very small and can be
neglected. As per US trafﬁc standards [19], the maximum
allowable speed for vehicles on 4–8 lane highway is
90 mph and the average inter-vehicle safe distance is
assumed to be 10 m in jammed and 30 m in smooth trafﬁc
conditions. The benchmark taken for performing cryptography related operations is listed in Table 2. Particularly,
we use the CP-ABE implementation provided at [20].
5.2. Computation overhead
Fig. 5 shows the time to generate private key components for vehicles in the region controlled by an RSU. For
secure group communications, minimum of four attributes
(RN, RS, ED and ET) are required when the road direction is
ignored. The total time taken by the RSU (T RSU ) to generate
private key components for vehicles is calculated as:

T RSU ¼ ðT CV þ T GðSKÞ þ T Sig½GðSKÞ þ T E Þ  N v ;
where T CV is the PKI certiﬁcate veriﬁcation time, T GðSKÞ is
the time to generate private key components, T Sig½GðSKÞ is
the time to sign the generated private key components,
T E is the time to encrypt messages using public key cryptography (PKC), and N v is the number of vehicles. Let’s consider the maximum capacity on an eight lane (single-side)
US freeway with vehicles traveling at maximum allowable
speed of 90 mph. If 8 vehicles simultaneously enter the
communication range of an RSU, the RSU will use 1.42 s
to generate private key components for all the vehicles
within Dt ¼ 0:034 miles. If RSU is mounted with two such
DSRC each monitoring a single direction, then the distance
traveled in generating private key components is 0.0678
miles, which equals to handle 172 mph road trafﬁc.
Fig. 6a and b show a comparison of the amount of time
taken to perform encryption/decryption in a group. The
time is taken to perform encryption and decryption using
ASPE with optimized operations are calculated as:

T EncOpt ¼ T GðKÞ þ T EðAESKÞ þ T EðCPABEðPTÞKEKÞ þ T SigðEðKEKÞÞ
T DecOpt ¼ T SV þ T DðCPABEðPTÞKEKÞ þ T DðAESKÞ :

Fig. 5. Key generation time.

0.25

0.12
0.1

0.2

Enc (Traditional CP-ABE)
Enc (Optimized CP-ABE)

0.1

Time (s)

0.15

Dec (Traditional CP-ABE)

0.06

Dec (Optimized CP-ABE)

0.04
0.02

0.05

Packet Size (B)

Packet Size (B)

Fig. 6. Computation overhead.

2300

2100

1900

1700

1500

1300

900

1100

700

500

300

2300

2100

1900

1700

1500

1300

900

1100

700

500

300

100

0

0
100

Time (s)

0.08

1533

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

T EðProtocolKeyÞ and T DðProtocolKeyÞ represent the time to perform
encryption and decryption operations, respectively. Fig. 6a
and b show the amount of time is taken to perform encryption/decryption by traditional and optimized CP-ABE
schemes with only one policy tree comprising of 5 attributes. The messages are ﬁrst encrypted by performing
256-bit advanced encryption standard (AES) encryption.
Then the key is encrypted using CP-ABE encryption algorithm. The decryption process is in the reverse order. It
can be observed that the time taken by a vehicle to perform
encryption and decryption using optimized CP-ABE
scheme is signiﬁcantly less than using CP-ABE to encrypt
the entire message. Fig. 6a and b show that the measurement for a maximum allowable packet size for 802.11
standard, i.e., 2312 bytes for inter-vehicle communications. Even for a packet size of 2313 bytes, the time taken
to encrypt the message with optimized scheme is 0.081 s,
which is much less than 0.191 s taken by the traditional
CP-ABE scheme. Similarly, the decryption time for optimized is 0.052 s, whereas for the traditional scheme is
0.097 s.

the security of group and subgroup communication is
based on the private key components generated by the
RSU, a compromised RSU can completely disrupt ASPE
operations. Although we assume that RSU cannot be compromised, however an attacker can deploy an adversarial
RSU. The certiﬁcate based mutual authentication procedure performed when a vehicle enters the RSU’s coverage
range hinders the attackers from deploying this attack.
For an adversary impersonating other vehicles, the adversary cannot generate valid signatures for the ciphertext
transmitted to other vehicles. This is because the attacker
does not have the genuine vehicle’s private key, and thus
the attacker will fail to impersonate another valid users.
We must note that ASPE does not prevent attackers
from encrypting a message using a set of attributes. This
is because both attributes and encrypting parameters are
publicly known. Thus, signatures of transmitted messages
are required when authentication is demanded. To reduce
the number of times on computing signatures, using the
optimized solution, we can just attach a signature for the
ﬁrst transmitted message. The following trafﬁc can be
authenticated using the KEK encrypted in the ﬁrst
message.
ASPE may suffer from denial of service (DoS) attacks,
i.e., a sender can sends messages encrypted with a number
of attributes to overburden the receiver. Although DoS attacks is difﬁcult to prevent as it is difﬁcult to prevent any
vehicle from sending messages using ASPE, the attackers
can be revoked. As vehicles have to sign the ciphertext before transmitting, other vehicles can report this mischievous activity to RSUs. RSUs then can generate new
dynamic attributes to revoke the misbehaved vehicles.
The detailed approaches for revoking misbehaved vehicles
is out of scope of this paper.

5.3. Communication overhead
The measurements for subgroup communication in VANETs are shown in Fig. 7a and b. In our performance evaluations, we considered two policy trees PT 1 ; PT 2 as shown
in Fig. 4. The encryption was ﬁrst performed with PT 2 (5
attributes) followed by PT 1 (3 attributes). We evaluate
the optimized procedures. In addition, a symmetric KEK
is ﬁrst encrypted with PT 2 and then PT 1 . The time taken
to encrypt (0.322 s for non-optimized solution and 0.12 s
for optimized solutions for a data with 2312 bytes) a message using two policy trees in both non-optimized and
optimized CP-ABE scheme is higher than the single tree
structure; however, it is still less than the time required
to generate new keys for all vehicles in a subgroup. We
can observe the same properties for the evaluations of
decryption process in Fig. 7.

6. Conclusion and future work
In this paper, we proposed a novel attribute-based solution for policy enforcement on VANET data access control.
The solution provides a general framework for deﬁning
policies enforced by means of policy trees, which can be
modulated to achieve secure V2V, V2I or I2V communications in VANETs. We also provided the performance results
to show that ASPE is practical for VANET communications.

Packet Size (B)

Packet Size (B)

Fig. 7. Computation overhead.

2300

2100

1900

1700

2300

2100

1900

1700

1500

1300

900

1100

700

500

300

0

1500

0.05

Dec (Optimized CP-ABE)

1300

0.1

Dec (Tradition CP-ABE)

900

Enc (Optimized CP-ABE)

100

Enc (Traditional CP-ABE)

Time (s)

0.2
0.15

100

Time (s)

0.25

0.2
0.18
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
1100

0.3

700

0.35

500

In this section, we discuss the security vulnerabilities
and the countermeasures of ASPE to against attacks. As

300

5.4. Security analysis

1534

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

However, other security and policies related issues like
anonymity in VANETs, efﬁcient authentication based on
ASPE, collusion resistance under strong security requirements, misbehavior detection and revocation, etc., need
to be further explored.

decryptor executes DecryptNode(CT; SK; R) on the root
node R and retrieves the message M.
In the above, we highlighted the main procedures of
using CP-ABE scheme [7], which comprises of four key
algorithms namely: Setup, Encryption, KeyGen and Decryption. We describe each of these protocols in details.

Appendix A. A background of attribute based
encryption

Protocol 3 (Setup). This algorithm takes a security parameter k and returns a public key PK and master secret key
MK. This setup operation is performed by selecting:

Attribute based encryption (ABE) related research is a
very active recently [7,21–27]. Here, we demonstrate
how to use ABE to provide an integrated and ﬂexible solution to incorporate data access control, role based access
control, security policy enforcement, and secure group
communications. ABE is an access control mechanism initially proposed by Sahai and Waters [28]. In ABE scheme,
the encryptor creates an access tree structure PT with a
set of attributes and threshold logic gates. This access tree
structure describes the access control policies that a user
must satisfy to gain access control to the encrypted data.
To decrypt the message, the user must own the private
key components associated with the attributes in the access tree structure. These private key components are generated by a trusted authority.
Ciphertext policy attribute based encryption (CP-ABE)
[7] scheme extends ABE by permitting arbitrary access formulas in the ciphertext policy. CP-ABE scheme utilizes
identity based encryption (IBE) [8] and threshold secret
sharing scheme [9]. During the setup protocol (Protocol
3), the trusted authority generates the bilinear map e from
addition group to multiplicative group of prime order p
with a generator g such that:

 Bilinear map: G0  G0 ! G1 is a map from addition
group G0 to multiplicative group G1 of prime order p
with a group generator g.
 Two random numbers a; b 2 Zp are selected.
 A hash function H : f0; 1g ! G0 that maps the bit string
to a point in group G0 .
The setup algorithm generates:

PK ¼ hG0 ; g; h ¼ g b ; f ¼ g 1=b ; eðg; gÞa i;
MK ¼ hb; g a i:

ðA:1Þ
ðA:2Þ

Protocol 4. Key Generation (MK, Y)). The key generation
protocol takes a set of attributes Y and the master secret
key as input. It outputs a set of private key components,
in which each corresponds to an attribute y 2 Y. The algorithm is operated by the TA and it works in following three
steps:
 For a user v, TA chooses a random r 2 Zp ,
 TA chooses a random ry 2 Zp for each attribute y 2 Y.
 TA ﬁnally computes the key as.

e : G0  G0 ! G1 :
Mapping e posses two properties, bilinearity and nondegeneracy, which are useful for encryption/decryption
protocols. Also, the mapping e is symmetric:
x

y

xy

y

SK ¼ hD ¼ g ðaþrÞ=b ;

8y 2 Y; Dy ¼ g r  HðyÞry ; D0y ¼ g ry i:
ðA:3Þ

x

eðg ; g Þ ¼ eðg; gÞ ¼ eðg ; g Þ:
The output hPK; MKi, where PK is a public key and MK is
a master secret key only known to the TA. Following the
generation of PK; MK, the TA generates the private key
components SK v for user v, where v ¼ 1; 2; . . . ; n (presented in Protocol 4). Once generated, these private key
components SKs are distributed to the corresponding users.
During the communications, an encryptor creates an access tree PT over a set of attributes Y. The encryptor then
generates the ciphertext CT by running encryption protocol (Protocol 5), which breaks the message into multiple
secret shares, and then recursively runs the secret sharing
scheme for each secret share down to the bottom level.
Such a secret share is a one-to-one mapping to a public
known attribute at the bottom of the access tree PT.
The decryption protocol (Protocol 6) takes public key
PK, message M, and policy tree PT as inputs. A decryptor
can only decrypt the ciphertext CT, if and only if he/she
possesses corresponding private key components SK that
corresponds to the attributes satisfying the access tree
PT. The decryptor runs DecryptNode(CT; SK; k) of Protocol
6 for all leaf nodes (indexed by variable k). Then, the

Protocol
5 (Encryption(PK, M, PT)). Message
M
is
encrypted under the tree PT with the public key PK. We
only describe the encryption procedure for one-level tree
for simplicity. The algorithm chooses a polynomial qk for
each node k (including the leaves) in the tree PT starting
from the root node R. For each node k in the tree, the
degree dk of the polynomial qk is set to be one less than
the threshold value T k of that node, that is, dk ¼ T k  1.
Starting from R, the algorithm chooses a random key
s 2 Zp and sets qR ð0Þ ¼ s. Then another point dR is chosen
on polynomial qR to deﬁne it completely. Finally, for all leaf
nodes y 2 Y of tree PT, the ciphertext CT is constructed over
PT by computing:

e ¼ M  eðg; gÞas ; C ¼ hs ¼ g bs ; 8y 2 Y;
CT ¼ hPT; C
C y ¼ g qy ð0Þ ; C 0y ¼ HðyÞqy ð0Þ i:

ðA:4Þ

Protocol 6. (Decryption (CT, SK, k)).
 We ﬁrst deﬁne a recursive algorithm DecryptNodeðCT;
SK; kÞ that takes inputs such as a ciphertext CT, private

D. Huang, M. Verma / Ad Hoc Networks 7 (2009) 1526–1535

key components SK associated with attribute set
Y ¼ fyg, and a attribute y from PT.
 If the node k represents a leaf node, then y ¼ attðkÞ is the
attribute value of node k. If y 2 Y, then,

DecryptNodeðCT; SK; kÞ ¼
¼
¼

eðDy ; C y Þ
eðD0y ; C 0y Þ
eðg r  HðattðkÞÞry ; g qx ð0Þ Þ
eðg ry ; HðattðkÞÞqx ð0Þ Þ
eðg r ; g qx ð0Þ Þ  eðHðattðkÞÞry ; g qx ð0Þ Þ
eðg ry ; HðattðkÞÞqx ð0Þ Þ

¼ eðg; gÞrqx ð0Þ :
If y R Y, deﬁne DecryptNodeðCT; SK; kÞ ¼?.
 The decryption algorithm begins by calling the function
DecryptNode on the root node R of the tree PT. If the tree
is satisﬁed by Y, set

A ¼ DecryptNodeðCT; SK; RÞ ¼ eðg; gÞrqR ð0Þ ¼ eðg; gÞrs :
 M is reconstructed by computing.

M¼

e A
C
:
eðC; DÞ

References
[1] B. Parno, A. Perrig, Challenges in securing vehicular networks, in:
Proceedings of the HotNets-IV, 2005.
[2] P. Papadimitratos, L. Buttyan, J.-P. Hubaux, F. Kargl, A. Kung, M. Raya,
Architecture for secure and private vehicular communications, in:
Proceedings of the Seventh International Conference on ITS
Telecommunications, 2007.
[3] M. Gerlach, A. Festag, T. Leinmuller, G. Goldacker, C. Harsch, Security
architecture for vehicular communication, in: Proceedings of the
Fifth International Workshop on Intelligent Transportation (WIT),
March, 2007.
[4] M. Gerlach, F. FOKUS, Trust for vehicular applications, in:
Proceedings of the Eighth International Symposium on
Autonomous Decentralized Systems (ISADS), 2007, pp. 295–304.
[5] M. Raya, J. Hubaux, Securing vehicular ad hoc networks, Journal of
Computer Security 15 (1) (2007) 39–68.
[6] M. Raya, P. Papadimitratos, V. Gligor, J. Hubaux, S. EPFL, On datacentric trust establishment in ephemeral ad hoc networks, in:
Proceedings of the IEEE Infocom, 2008.
[7] J. Bethencourt, A. Sahai, B. Waters, Ciphertext-policy attribute-based
encryption, in: Proceedings of the 28th IEEE Symposium on Security
and Privacy (Oakland), 2007.
[8] D. Boneh, M. Franklin, Identity-based encryption from the Weil
pairing, in: Proceedings of the CRYPTO 01, Springer-Verlag, 2001.
[9] A. Shamir, How to share a secret, Communications of the ACM 22
(11) (1979) 612–613.
[10] K. Sampigethaya, L. Huang, M. Li, R. Poovendran, K. Matsuura, K.
Sezaki, CARAVAN: providing location privacy for VANET, in:
Proceedings of the Embedded Security in Cars (ESCAR), 2005.
[11] J. Guo, J. Baugh, S. Wang, A group signature based secure and
privacy-preserving vehicular communication framework, in:
Proceedings of the Mobile Networking for Vehicular Environments
(MOVE), 2007, pp. 103–108.
[12] X. Lin, X. Sun, P. Ho, X. Shen, GSIS: a secure and privacy-preserving
protocol for vehicular communications, IEEE Transactions on
Vehicular Technology 56 (6 Part 1) (2007) 3442–3456.
[13] D. Chaum, E. Van Heyst, Group signatures, Lecture Notes in
Computer Science 547 (1991) 257–265.
[14] M. Raya, J. Hubaux, Efﬁcient secure aggregation in VANETs, in:
Proceedings of the Third International Workshop on Vehicular Ad
hoc Networks, 2006, pp. 67–75.

1535

[15] ISP-vehicle location referencing standard. SAE Standard J1746, July
2001. <http://www.consystec.com/newyork/capitaldistrict/capital/
standards/stdﬂowsae-j1764.html>.
[16] Institute of Transportation Engineers. Trafﬁc management data
dictionary (TMDD) and message sets for external trafﬁc
management center communications (MS/ETMCC), 2004. <http://
www.ite.org/tmdd>.
[17] Wireless LAN Medium Access Control (MAC) and Physical Layer
(PHY) speciﬁcations. IEEE Standard 802.11a-1999, 1999. <http://
www.csse.uwa.edu.au/adhocnets/802.11-1999.pdf>.
[18] C. Cseh, Architecture of the dedicated short-range communications
(DSRC) protocol, in: IEEE Vehicular Technology Conference (VTC),
vol. 3 (3), 1998, pp. 2095–2099.
[19] United states trafﬁc rules and regulations, wiki page: <http://
en.wikipedia.org/wiki/Trafﬁc>.
[20] B.W. John Bethencourt, Amit Sahai, Ciphertext-Policy AttributeBased Encryption, 2006. <http://acsc.csl.sri.com/cpabe>.
[21] M. Chase, Multi-authority attribute-based encryption, Lecture Notes
in Computer Science 4392 (2007) 515–534.
[22] L. Cheung, C. Newport, Provably secure ciphertext policy ABE, in:
Proceedings of the 14th ACM Conference on Computer and
Communications Security, ACM New York, NY, USA, 2007, pp.
456–465.
[23] V. Goyal, O. Pandey, A. Sahai, B. Waters, Attribute-based encryption
for ﬁne-grained access control of encrypted data, in: Proceedings of
the 13th ACM Conference on Computer and Communications
Security, ACM Press New York, NY, USA, 2006, pp. 89–98.
[24] J. Katz, A. Sahai, B. Waters, Predicate encryption supporting
disjunctions polynomial equations and inner products, Lecture
Notes in Computer Science 4965 (2008) 146–162.
[25] J. Li, K. Kim, Attribute-Based Ring Signatures, IACR ePrint, 2008.
[26] R. Ostrovsky, B. Waters, Attribute-based encryption with nonmonotonic access structures, in: Proceedings of the 14th ACM
Conference on Computer and Communications Security, ACM New
York, NY, USA, 2007, pp. 195–203.
[27] M. Pirretti, P. Traynor, P. McDaniel, B. Waters, Secure attribute-based
systems, in: Proceedings of the 13th ACM Conference on Computer
and Communications Security, ACM Press New York, NY, USA, 2006,
pp. 99–112.
[28] A. Sahai, B. Waters, Fuzzy identity-based encryption, in: Advances in
Cryptology–Eurocrypt, vol. 3494, Springer, 2005, pp. 457–473.

Dijiang Huang is an Assistant Professor and
the Department of Computer Science and
Engineering in the School of Computing
Informatics, at Arizona State University since
2005. His primary research areas are computer networking: network protocols and
mobility simulation; security and privacy: key
management, authentication protocol, attack
analysis, privacy preserving, and attack resilient network design.

Mayank Verma received his M.S degree at the
Computer Science and Engineering Department, Arizona State University in 2008. Then
he joined Brocade Communications as a
security and networking engineer.

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2011 proceedings

Least Squares Disclosure Attack in Mobile Ad Hoc
Networks
Yang Qin

Dijiang Huang

Microsoft Cooperation
Email: yang.qin@microsoft.com

Arizona State University
Email: dijiang@asu.edu

Abstract—Traffic analysis is considered the most powerful
strategy of disclosing the hidden communication relations in
an anonymous communication system. Statistical traffic analysis
attacks are even more subtle in that the attackers are usually
eavesdroppers who do not modify the network’s behaviors. Moreover, the attackers even do not need to look into the traffic content, which may be encrypted, in order to analyze the statistical
characteristics. Such attacks have been thoroughly investigated
for static wireline networks. However, none of these mechanisms
can be directly applied to mobile ad hoc networks (MANETs) due
to the inability to deal with mobility, the ad hoc infrastructure
and the broadcasting nature of wireless transmissions. Recent
research on statistical traffic analysis attacks targeting MANETs
is restricted to disclosing the end-to-end traffic distribution. In
this paper, we present the least squares disclosure attack (LSDA),
targeting a popular MANET routing strategy, that is, the position
based routing (a.k.a geographic routing). LSDA utilizes the traffic
distribution disclosed by existing solutions, and de-anonymizes
the network communication on a per-flow basis. In LSDA, traffic
disclosure is modeled as a least squares problem subject to linear
constraints. The empirical study demonstrates that, the proposed
solution can de-anonymize the network flows in high accuracy.

I. I NTRODUCTION
In the literature, many traffic analysis models have been
proposed to disclose the end-to-end communication relations
in traditional static wireline networks, such as brute force
[1], node flushing [2], timing [3], and message tagging (e.g.,
watermarking) [1], [4], [5]. Statistical traffic analysis attacks
are receiving more interests due to their passive nature, i.e.
attackers only need to collect information and perform analysis quietly without changing the network behavior (such as
injecting or modifying packets). The predecessor attacks [6],
[7] and statistical disclosure attacks [8], [9] are two representatives. However, it is difficult to adopt these approaches
to analyze MANET traffic because of the following three
natures of MANETs: (i) The broadcasting nature. In wireline
networks, a point-to-point (one-hop) message transmission
usually has only one possible receiver. Wireless transmissions
incur additional uncertainty since messages are broadcasted
to all nodes within the transmitting range. (ii) The ad hoc
nature. MANETs are infrastructureless, where any node can
serve as both a host and a router. Thus, it is difficult to
determine the role of a node to be a source, a destination,
or just a relay. (iii) The mobile nature. Most of existing
traffic analysis models do not take mobility into consideration.
Mobility makes the communication relations between mobile

nodes more complex.
Investigation on statistical traffic analysis against MANETs
is quite restricted. In [10], an evidence theory based model is
proposed for MANETs. In this model, every captured packet is
treated as an evidence supporting a point-to-point transmission
between the sender and receiver. The model is then extended
to a comprehensive statistical traffic pattern discovery system
named STARS [11]. In STARS, a sequence of point-to-point
traffic matrices are created based on the captured packets, and
used to derive the end-to-end (multi-hop) traffic matrix. A
heuristic approach is then used to reveal the communication
relations by computing the probability for each pair of node
to be an actual end-to-end link. The result is equivalent to an
end-to-end traffic distribution, which describes the ratio of the
traffic between a particular pair of nodes to the overall network
traffic during certain time period.
However, STARS cannot de-anonymize MANET communications on a per-flow basis. Moreover, STARS is a general
system which does not take into account the special features
of particular protocols while inferring the traffic patterns. In
fact, different routing protocols have completely different behaviors. Some of the unique behaviors can disclose important
information about the communication relations. For instance,
if the protocol uses a constant strategy for establishing the
end-to-end paths (choosing the relays), then it is possible to
infer the communication relations from the selected relays.
Position based routing (PBR) [12], [13] is such an example.
PBR does not rely on the network topology. Routing decisions
are made at each hop by selecting the next hop that is closest
to the destination in terms of the geographic distance. In this
case, given the source and destination, the routing decision can
easily be reproduced if the location of every node is known.
In other words, the source and destination can be (partially)
inferred if the chosen path (relays) is known.
In this paper, we present the least squares disclosure attack
(LSDA), which utilizes the traffic distribution disclosed by
STARS (or other similar traffic profiling approaches), and
takes the advantage of the deterministic routing behavior of
PBR. For each packet p captured at any node s, a relay matrix
is constructed in which each column represents a path from s
to one of its possible destinations. The possible destinations
are indicated by the traffic distribution, and the paths towards
them are reproduced using PBR based on the nodes’ locations.
The column corresponding to destination d tells which nodes

978-1-61284-233-2/11/$26.00 ©2011 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2011 proceedings

are the relays that will forward the packet p, if p is initiated
by s and destined to d. That is, we can (partially) determine
whether s − d is the source-destination pair of p by checking
if there are packets captured at these nodes that are indicated
as the relays. In addition, the final decision of the sourcedestination pairs for all captured packets should conform to
the traffic distribution. Based on these observations, the traffic
disclosure problem is modeled as a linearly constrained least
squares problem, which is efficiently solvable [14], [15].
The contribution of this paper is four-fold: i) To our best
knowledge, LSDA is the only traffic analysis strategy that
is able to de-anonymize MANET communications on a perflow basis; ii) Our research is creative in that we are the
first to exploit the unique behaviors of particular routing
schemes; iii) In LSDA, traffic disclosure is modeled as a
thoroughly investigated optimization model; iv) The empirical
study demonstrates that, LSDA comprimises MANET communication anonymity in high accuracy.
The rest of the paper is organized as follows. Section II
states the traffic disclosure problem. In Section III, the least
squares disclosure attack is presented in detail. We describe
the experiments are analyze the results in Section IV. The last
section concludes this paper.
II. P ROBLEM S TATEMENT
The research presented in this paper targets a mobile ad hoc
network protected by anonymity enhancing techniques such
that all information flows are encrypted. The adversaries cannot decrypt the flows, and neither can they reveal the end-toend communication relations from the routing layer and above.
However, the adversaries are capable of capturing every packet
transmitted in the network. Using location tracking systems,
they are aware of the locations of the mobile nodes at any
given time. The MANET uses a position bases routing strategy
whose routing decisions are reproducible given the nodes’
locations. In addition, the traffic distribution in the network is
given (by STARS or similar traffic profiling schemes), which
is called the profiled traffic distribution. Our purpose is to deanonymize the network communications on a per-flow basis.
The traffic disclosure problem can be formally stated as
follows.
1) We, the adversaries or traffic analyzers, capture every
packet sent by each node. We do not know the immediate
receiver of the packet. It is not known whether the packet
is initialized by the sender or the sender is just a relay. Let
F = (f (1), f (2), ..., f (N )) denote the vector of the captured
packets, where f (i) is the number of packets sent by node i
and N is the total number of nodes in the MANET.
2) The packet content is invisible to us. The network uses
padding techniques to unify the size of all packets.
3) PBR is used for routing, and at any point of time, the
location of each node in the network is known. Thus, the
routing decisions (paths) can be reproduced given any sourcedestination pair.
4) The profiled traffic distribution is given, denoted by
matrix P = (p(i, j))N ×N , where p(i, j) is the percentage of

traffic from source i to destination j in the overall end-to-end
traffic. The traffic that is actually captured exactly conform to
the profiled traffic distribution.
5) The goal is to identify the actual source and destination
of every network flow.
III. L EAST S QUARES D ISCLOSURE ATTACK
In this section, the least squares disclosure attack (LSDA)
is presented in detail. In LSDA, the traffic disclosure problem
stated in Section II is modeled as a linearly constrained least
squares problem.
A. Relay Matrix
Given the source and destination of a packet, and the time
at which the packet is captured, the routing decisions of PBR
are reproducible. For example, suppose the packet is initiated
by source s at time t1 for destination d, the first relay r1
can be identified by finding the neighboring nodes of s which
is geographically closest to d at time t1 . Similarly, assuming
the packet arrives at r1 and r1 starts to forward the packet
at time t2 (t2 > t1 ), the next relay selected by r1 is the
neighboring node of r1 which is closest to d at time t2 .
Eventually, the entire path from s to d is reproduced. Note
that the time duration between t2 and t1 is usually very
short. Generally, there are two basic strategies to deal with
this time duration: 1) If the packet size is small, and the
packet transmission time is negligible in terms of the network
topology change, the duration can be simply ignored; 2) If the
packet size is large, or the nodes’ moving speed is relatively
high and the network topology has notable changes during
the packet transmission, we can assume that the time duration
(Δt = t2 − t1 ) is constant, given that all packets are of the
same size. In this case, given the starting time t1 , we can
approximately determine the time points t2 , ..., tm at which
the packet is forwarded at each hop. For simplicity, in the rest
of the model, these two strategies will not be differentiated
and we just assume the entire path from the source to the
destination can be reproduced.
However, for any intercepted packet, the actual source or
destination of the packet is not known. Moreover, if the node
which the packet is captured from is indicated by the profiled
traffic distribution matrix (P = (p(i, j))N ×N
N) as a possible
source (i.e. letting the node be s, we have i=1 p(s, i) > 0),
it is even not possible to tell whether this node
the packet
is
N
source or just a relay. (Note that in the case of i=1 p(s, i) =
0, it is certain that s is just a relay.) Hence, all possibilities
need to be enumerated and the relay matrix needs to be built
up for each packet.
Suppose there are totally m captured packets sent by node
s which is indicated as a possible source node, then we have
m relay matrices: Rs,p (p = 1, ..., m). The relay matrix Rs,p
indicates which nodes will be possibly selected as the relays
for the pth packet, by assuming s is the packet source and
enumerating all possible destinations of s, according to the
profiled traffic distribution matrix P . Generally, for each node
d such that p(s, d) > 0, d is a possible destination of s. So

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2011 proceedings

we have the relay matrix Rs,p = (rs,p (i, j))N ×n , where N
denotes the total number of nodes while n is the number of
possible destinations of s. rs,p (i, j) = 0 or 1, which indicates
whether node i is a relay if j is the destination. In other words,
the j th column of the relay matrix is the reproduced routing
path from source s to destination j, with the source and all
relay nodes marked as 1 and others
marked as 0. It is important
N
to re-emphasize that, if we have i=1 p(s, i) = 0 in P , which
means s is not a possible source, then it is not necessary to
create the relay matrices for s.
In order to elaborate the relay matrices, a simple example
is presented as follows. Suppose there is a tiny MANET with
5 mobile nodes and the profiled traffic distribution P is:
⎡
⎤
0
0 0.1 0.1 0
⎢0
0
0
0 0⎥
⎢
⎥
⎢0.3 0
0
0.2
0⎥
⎢
⎥.
⎣0
0
0
0 0⎦
0.1 0.1 0.1 0 0
A packet p is intercepted from node 3. From the profiled traffic
distribution, it is known that only node 1 and 4 are possible to
be node 3’s destination (p(3, 1) = 0.3, p(3, 4) = 0.2). Thus,
the packet p may be associated with such a relay matrix (based
on the reproduced routing decisions):
	

T
0 0 1 1 1
.
R3,p =
1 0 1 0 0
The relay matrix tells that, if the packet is initiated by node 3
and destined to node 1, then for transferring this packet, node
3, 4, 5 will all have a packet transmission (broadcasting); if
the packet is initiated by node 3 but destined to node 4, then
the path will only consist of node 1 and node 3. It is worth
noting that the relay matrix is built upon the assumption that
node 3 is actually the source (initiator), but in fact, node 3
may be just a relay itself. This case is taken into account in
the modeling too, as presented shortly in the next section.
B. Modeling Traffic Disclosure
The purpose of the traffic disclosure is to identify all endto-end flows, in terms of their sources and destinations. That
is, for each packet p captured at node s (sent by s), where
s is indicated by the profiled traffic distribution matrix as a
possible source, we want to determine: 1) whether s is the
source of p, and 2) if s is the source, among the possible
destinations of s, which node is the actually destination.
We use a variable x(s, p, d) to indicate whether node s and
d are the actual source and destination of packet p, where
x(s, p, d) = 1 means “true” and x(s, p, d) = 0 means “false”.
Since a packet can only have one source and destination, we
have:

x(s, p, d) = 0 or 1,
(1)
d∈Ds

where

the sum equals to 1 means s is indeed the source of p, the sum
equals to 0 means s is just a relay of p.
If s is not the source,

there must be a node s , such that
d ∈Ds x(s , p , d ) =

1, where p and p are in fact the same packet appearing at
different hops.
Let
Xs,p = (x(s, p, d1 ), ..., x(s, p, dn )), di ∈ Ds (i = 1, ...n),
(2)
that is, Xs,p is the variable vector for the packet p sent by s. At
most one of the variables in Xs,p is 1 and all others are 0, and
x(s, p, di ) = 1 denotes that s and di are actually the source
and destination of packet p. In addition, since the relay matrix
Rs,p indicates the selected relays for each different possible
destination, we have:
Fs,p = Rs,p · Xs,p ,

(3)

where Fs,p = (fs,p (1), ..., fs,p (N )) is the vector that indicates
which nodes are selected as the relays for the transfer of packet
p (fs,p (i) = 1 denotes that the node i is a relay). For instance,
in the example given in Section III-A, we have the relay matrix
R3,p . Suppose X3,p = (1, 0), which means node 3 and node
1 are the actual source and destination of the packet, we get
F3,p = [0 0 1 1 1]T ,
which means node 3, 4, and 5 are involved in transferring
the packet p initiated by node 3. Reversely, capturing packets
at these 3 nodes also indicates that X3,p = (1, 0), instead of
(0, 1) or (0, 0), assuming there is no other interferences. In
this case, the communication anonymity is compromised by
discovering the two ends of this information flow.
Nonetheless, Fs,p is not known to us for each packet p sent
by each node s. What can be obtain from the intercepted traffic
is a cumulative traffic vector F = (f (1), f (2), ..., f (N )),
where f (i) is the number of packets captured from node i
(i = 1, ..., N ), that is, the total number of packets node i sends
out, including both the packets that are initiated by node i and
those that are forwarded by i. Apparently, we have


Fs,p =
Rs,p · Xs,p .
(4)
F =
∀s,p

∀s,p

Let S = {si |i = 1, ..., k} be the set of all nodes which send
out traffic and are indicated by the profiled traffic distribution
matrix as possible source nodes, the overall variable vector is
defined as
X = (Xs1 ,1 ...Xs1 ,ms1 Xs2 ,1 ...Xs2 ,ms2 
......Xsk ,1 ...Xsk ,msk ),

(5)

where “” represents vector concatenation, and msi denotes
the total number of packets sent by node si . Note that Xs,p
is defined in Equation (2). Similarly, the overall relay matrix
is defined by concatenating all single relay matrices as:

Ds = {d|p(s, d) > 0},

R = (Rs1 ,1 ...Rs1 ,ms1 Rs2 ,1 ...Rs2 ,ms2 

which is the set of all possible destinations of node s. Note that

......Rsk ,1 ...Rsk ,msk ).

(6)

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2011 proceedings

It follows Equation (4), (5) and (6) that,
F = R · X.

IV. E XPERIMENTS AND A NALYSIS
(7)

We can obtain F by intercepting the traffic, and obtain R by
reproducing the position based routing decisions based on the
location tracking ability. X is the variable to be determined.
Once X is determined, all end-to-end flows are identified.
However, simply solving Equation (7) cannot achieve the
goal. The equation may have infinite solutions. Many of them
may not comply with the constraint given in Equation (1).
Moreover, it is known that the captured traffic strictly conform
to the profiled traffic distribution P . In order to precisely
disclose the actual traffic patterns, X must match P . That is,
the traffic distribution given by X should be as close to that
indicated by P as possible. Let M denote the total number
of information flows (i.e, the total number of packets that are
initiated):


x(s, p, d),
(8)
M=
X=
s

p

d

then M × p(s, d) should be the actual number of s − d flows.
In other words, there should be such number of packets that
are initiated by s and destined to d, so if we have
δ(s, d) =

ms


x(s, p, d) − M × p(s, d), ∀s, d

(9)

p=1

then δ(s, d) should be as close to 0 as possible.
To conclude, the traffic disclosure problem to be solved can
be modeled as a linearly constrained least squares problem as
follows:
N
N 

δ 2 (s, d)
(10)
minimize
s=1 d=1

subject to R · X = F,

x(s, p, d) ≤ 1,
0≤

(11)
(12)

d∈Ds

M−
δ(s, d) =

ms




X = 0,

x(s, p, d) − M × p(s, d), ∀s, d

(13)
(14)

p=1

0 ≤ X ≤ 1.

(15)

Note that (12) and (15) are obtained by relaxing the following
integer constraints, respectively:

x(s, p, d) = 0 or 1,
d∈Ds

X = 0 or 1.
The relaxation is correct because it is certain that the optimal
solution to the problem without integer constraint is an integer
solution, which is the actual traffic pattern.

In this section, the empirical study is presented and the
results are analyzed.
The simulated MANET is deployed across a 1000 × 1000m
area. All nodes are mobile and their movements follow the
random way-point mobility model. In order to perform comparative study, the following factors vary in different scenarios.
• Total number of nodes, N .
• Communication range, r. Two nodes with a distance less
than this range are considered to be able to directly talk
to each other.
• Total number of source nodes, k. These source nodes are
randomly selected.
• Maximum number of destinations each source can have,
dm . The destinations are also randomly selected.
Though the number of nodes and the communication rage are
variables, the entire network is guaranteed to be connected. In
addition, the maximum number of flows (packets) each source
can initiates is restricted to 20. These flows go to the selected
destinations in a random order.
Since the purpose is to demonstrate LSDA, STARS is not
involved in the simulations, although LSDA has to rely on
STARS (or other traffic profiling schemes) to obtain the profiled traffic distribution in practice. For simplicity, the actual
traffic distributions are used as the profiled traffic distributions.
The following five different scenarios are simulated:
• Scenario A: N = 50, r = 300, k = 5, dm = 3
• Scenario B: same with A except N = 80
• Scenario C: same with A except k = 10
• Scenario D: same with A except dm = 5
• Scenario E: same with A except r = 800
In each scenario, the simulation runs for 10 rounds using the
corresponding settings. In each round, the results of LSDA are
compared with the actual traffic pattern. We call the incorrect
inferences of flows the “failures”. The “error-ratio” is defined
as
number to f ailures
.
error − ratio =
total number of f lows
Obviously, the error-ratio represents how precisely the proposed strategy can disclose the actual end-to-end communication relations and how badly the communication anonymity
is compromised. The error-ratios in different scenarios are
illustrated in Fig. 1.
First of all, it can be seen that LSDA achieves significantly
good performance in most cases. In Fig. 1(a), the highest
error-ratio is only around 15%. In other words, LSDA can
successfully identity the source and destination of 85% flows
in the MANET. Fig. 1(b) is even better, in 6 out of the 10
rounds, LSDA correctly identifies the source and destination
of all flows, and the highest error-ratio is as low as 12%.
The only difference between scenario A and B is that B
has 30 more nodes than A. The larger number of nodes
result in a higher network density, which makes the relay
matrices more distinguishing. That is, comparing with a sparse
network, the selected routing paths in a dense network are

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE ICC 2011 proceedings

error-ratio

Average error-ratio: 0.047

Average error-ratio: 0.041

error-ratio

0.16
0.14
0.12
0.1
0.08
0.06
0.04

0.14

0.02
0

0.02

error-ratio
0.2

0.1

0.15

0.08
0.06

0.1

0.04

0.05

0
1

2

3

4

5

6

7

8

9

0
1

10

Average error-ratio: 0.122

0.25

0.12

2

3

4

5

6

7

8

9

10

1

2

3

4

5

round

round

(a) Scenario A

(b) Scenario B

error-ratio

Average error-ratio: 0.085

6

7

8

9

10

round

(c) Scenario C
Average error-ratio: 0.332

error-ratio
0.6

0.25

0.5

0.2

0.4

0.15

0.3

0.1

0.2

0.05

0.1

0

0
1

2

3

4

5

6

7

8

9

10

1

2

3

4

5

6

7

8

9

10

round

round

(d) Scenario D

(e) Scenario E
Fig. 1.

more distinguishable from each other. In this case, it is easier
to disclose the two ends of a flow based on the captured
traffic. In a sparse network, the paths from different sources to
different destinations are likely to overlap at certain “bottleneck” relay nodes.
When the number of source nodes (k) increases as in Fig.
1(c), or the maximum number of destinations for each source
(dm ) increases as in Fig. 1(d), the accuracy of LSDA is
degraded. In some cases, the error-ratio reaches 20%. The
reason is quite clear. When k and dm are small, the total
number of flows are small, and more importantly, the network
traffic is confined within a small set of nodes. In other words,
the profiled traffic distribution matrix P has many 0 entries,
which means the uncertainty (anonymity) of the entire system
is low. Once k and dm get increased, the network traffic
increases, and more nodes will be involved in the network
communications. Consequently, the system anonymity also
increases, which means it is harder to perform the traffic
disclosure attacks.
As can be seen in Fig. 1(e), scenario E is an outlier where
LSDA has poor performance. The communication range r is
deliberately set to 800 meters so that most of the network
flows only have one hop (the source talks to the destination
directly). The error-ratios in scenario E are unacceptably high.
For instance, the highest error-ratio is even higher than 50%.
Note that this is only an extreme case. Since almost all flows
are one-hop conversations, no intermediate nodes (relays) will
be involved in the communications. Thus, the only factor that
differentiates two flows is the source-destination pair itself.
The relay matrices are not distinguishing at all.
V. C ONCLUSION
In this paper, a novel traffic analysis attack named LSDA
is designed to compromise the communication anonymity of
mobile ad hoc networks. LSDA takes the advantage of the
reproducible routing decisions of the position based routing
strategy, and models traffic disclosure as a linearly constrained

Error Ratio

least squares problem. LSDA is the only strategy that can deanonymize MANET communications on a per-flow basis. The
empirical study shows that, LSDA is able to identify the source
and destination of each end-to-end flow in high accuracy.
R EFERENCES
[1] J. Raymond, “Traffic analysis: Protocols, attacks, design issues, and open
problems,” Lecture Notes in Computer Science, pp. 10–29, 2001.
[2] D. Chaum, “Untraceable Electronic Mail, Return Addresses, and Digital
Pseudonyms,” Communications of the ACM, vol. 24, pp. 84–88, 1981.
[3] M. Reed, P. Syverson, and D. Goldschlag, “Anonymous connections
and onion routing,” Selected Areas in Communications, IEEE Journal
on, vol. 16, no. 4, pp. 482–494, 1998.
[4] W. Dai, “Two attacks against a PipeNet-like protocol once used by the
Freedom service,” http://weidai.com/freedom-attacks.txt.
[5] X. Wang, S. Chen, and S. Jajodia, “Network Flow Watermarking Attack
on Low-Latency Anonymous Communication Systems,” in Proceedings
of 2007 IEEE Symposium on Security and Privacy, May, 2007, pp. 116–
130.
[6] M. Reiter and A. Rubin, “Crowds: Anonymity for web transactions,”
ACM transactions on information and system security, vol. 1, no. 1, pp.
66–92, 1998.
[7] M. Wright, M. Adler, B. Levine, and C. Shields, “The predecessor
attack: An analysis of a threat to anonymous communications systems,”
ACM Transactions on Information and System Security (TISSEC), vol. 7,
no. 4, pp. 489–522, 2004.
[8] G. Danezis and A. Serjantov, “Statistical disclosure or intersection
attacks on anonymity systems,” in Proceedings of 6th Information
Hiding Workshop (IH 2004). Springer, 2004, pp. 293–308.
[9] C. Troncoso, B. Gierlichs, B. Preneel, and I. Verbauwhede, “Perfect
Matching Disclosure Attacks,” Lecture Notes in Computer Science, vol.
5134, pp. 2–23, 2008.
[10] D. Huang, “Unlinkability Measure for IEEE 802.11 based MANETs,”
IEEE Transactions on Wireless Communications, no. 2, pp. 1025–1034,
Feburary 2008.
[11] Y. Qin and D. Huang, “A statistical traffic pattern discovery system for
manets,” in Proceedings of IEEE Military Communications Conference
(MILCOM), 2009.
[12] B. Karp and H. T. Kung, “GPSR: greedy perimeter stateless routing for
wireless networks,” in Proceedings of Mobile Computing and Networking, 2000, pp. 243–254.
[13] Y. Ko and N. Vaidya, “Location-Aided Routing (LAR) in mobile ad hoc
networks,” Wireless Networks, vol. 6, no. 4, pp. 307–321, 2000.
[14] Å. Björck, Numerical methods for least squares problems. Society for
Industrial Mathematics, 1996.
[15] J. Stoer, “On the numerical solution of constrained least-squares problems,” SIAM Journal on Numerical Analysis, vol. 8, no. 2, pp. 382–411,
1971.

SDN based scalable MTD solution in Cloud Network
Ankur Chowdhary

Sandeep Pisharody

Dijiang Huang

School of Computing, Informatics and Decision Systems Engineering
Arizona State University, Tempe, AZ
<achaud16, spishar1, dhuang8>@asu.edu

ABSTRACT

Traditional networks are composed of heterogeneous elements such as routers, firewall, switches. Each of these
devices has their own proprietary software and protocols.
This kind of network setup leaves very little scope for innovation in network. Software-Defined Networking (SDN) has
emerged as a solution for addressing this challenge. SDN
environment generally consists of OpenFlow switches and
controllers, communicating over a secure channel. SDN provides a service oriented architecture to deploy modular solutions for different requirements.
The SDN controller can work as a centralized security policy enforcer. Ethane [6] provides a model for user authentication and stronger binding between packets and origin.
The programmable interfaces afforded by SDN can be
conformed to achieve a dynamic defensive strategy based
MTD [23]; thereby providing a systematic solution by selecting countermeasures to prevent or mitigate attacks in
an SDN enabled data center networking environment [8,15].
SDN based random host mutation [15] makes use of mapping
between real and virtual IP addresses to make a reconnaissance difficult for attackers with the SDN controller providing centralized management of mutation control across the
network.
In an Infrastructure-as-a-Service (IaaS) cloud, Virtual
Machines (VMs) are managed by tenants and may contain
various vulnerabilities and thus they are easy targets for
attackers. Chung et al. [7] present an MTD approach to automate an iterative three-step procedure to counter network
attacks, a) network intrusion detection; b) threat analysis;
and c) countermeasure selection and deployment. To this
end, we use an Attack Graph (AG) based vulnerability analysis model to enumerate all possible attack scenarios, allowing the cloud system to select countermeasures before identified vulnerabilities are exploited. Selected countermeasures
could be based on link and network layer operations and reconfiguration, such as a) traffic redirection; b) traffic blocking/dropping; c) quarantining; d) MAC/IP addresses reconfiguration; etc. Since changes for the network are applied in
an SDN based IaaS cloud by generating new flow rules that
are added to the controller, it is necessary to check and resolve conflicts with existing rules, enterprise security policies
and business Service Level Agreements (SLA) before such
policies are deployed. The policy conflict problem becomes
even harder in SDN enabled cloud networking setup since
each SDN switch, both physical and software switches, can
be considered a distributed firewall instance. Additionally,
SDN based policy checking demands a cross-layer checking
since flow rules may be defined at different protocol layers [20].

Software-Defined Networking (SDN) has emerged as a
framework for centralized command and control in cloud
data centric environments. SDN separates data and control
plane, which provides network administrator better visibility
and policy enforcement capability compared to traditional
networks. The SDN controller can assess reachability information of all the hosts in a network. There are many critical
assets in a network which can be compromised by a malicious
attacker through a multistage attack. Thus we make use of
centralized controller to assess the security state of the entire
network and pro-actively perform attack analysis and countermeasure selection. This approach is also known as Moving Target Defense (MTD). We use the SDN controller to
assess the attack scenarios through scalable Attack Graphs
(AG) and select necessary countermeasures to perform network reconfiguration to counter network attacks. Moreover,
our framework has a comprehensive conflict detection and
resolution module that ensures that no two flow rules in
a distributed SDN-based cloud environment have conflicts
at any layer; thereby assuring consistent conflict-free policy
implementation and preventing information leakage.

Keywords
Software-Defined Networking (SDN), Moving Target Defense (MTD), Attack Graph (AG)

1.

INTRODUCTION

Moving Target Defense (MTD) [13, 25] is a transformative approach to security of multi-tenant cloud environment
that leverages the dynamism in computer systems to create
an environment that has a changing attack surface. This
dynamism gives rise to the need for a framework to accurately, and in a timely fashion, examine the complex relationships between various hosts and security vulnerabilities
in an ever changing cloud networking environment, and ensure that any changes made to the environment do not conflict with security policies.
ACM acknowledges that this contribution was authored or co-authored by an employee, or contractor of the national government. As such, the Government retains
a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only. Permission to make digital or hard copies
for personal or classroom use is granted. Copies must bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. To copy otherwise, distribute, republish, or post, requires prior
specific permission and/or a fee. Request permissions from permissions@acm.org.

MTD’16, October 24 2016, Vienna, Austria
c 2016 ACM. ISBN 978-1-4503-4570-5/16/10. . . $15.00

DOI: http://dx.doi.org/10.1145/2995272.2995274

27

ers [20].
To address the described issues, in this research, we
present a novel framework that includes a stable converged
AG even in a dynamic environment. We incorporate the
programmable network capabilities of SDN to isolate, quarantine, and inspect traffic and leverage these capabilities to
implement MTD countermeasure strategies. Finally, we run
candidate countermeasures through a policy conflict resolution module that ensures it does not conflict with existing
security policy or business SLAs. The key contribution of
our work is:
• We automate dynamic system reconfiguration safely
by leveraging scalable AG and cross-layer security policy checking. It requires no involvement by network
operators.
• We are able to successfully implement a framework
that does real-time network reconfiguration either proactively, or reactively to any abnormal events in the
environment.
• The reconfigured system is guaranteed to be compliant
with security and SLA requirements of the organization.
This paper is organized as follows. In Section 2, we present
some background and a motivation scenario for the presented research. The system models and architecture are
presented in Section 3. The detailed description of our
framework is presented in Section 4. The performance evaluation is presented in Section 5 and related work is presented
in Section 6. Finally, we conclude our work and future research directions in Section 7.

2.

Tenant A
Internet

Host A1

Host A2

Quarantine
A2’s IP

Offload A2
to A3

vSwitch
Host A3

SDN
Controller
vSwitch

Host Z
Honeypot

Data Center

Figure 1: Motivating scenario for policy conflict.

b) modifies an incoming packet’s destination address from
host A2 to host A3 if the source is considered to be a nonadversarial source; c) stops all outbound traffic from the IP
that originally belonged to host A2, but now belongs to host
Z to the rest of the data center; and d) permits traffic on
port 443 to host A3 (not of great importance to our case).
The original policy allowing only port 443 to the IP of host
A2, and the new policy allowing all traffic to the IP address
of host Z are now in conflict.

BACKGROUND
3.

Attack graphs (AG) are a good tool to represent the security state of entire network. AGs have proved to be a
very useful tool to detect multi-staged and multi-hop attacks which may not be obvious to the network administrator by plain analysis. Some of the earlier works in this
field have used model checking [27, 28] and formal language
based methods [28] to enumerate all possible attack scenarios in the cloud system. We use AG based analysis in our
threat model for our work.
Moving Target Defense (MTD) techniques have been devised as a tactic wherein security of a system is enhanced
by having a rapidly evolving system with a variable attack
surface; thereby giving defenders an inherent information
advantage. An effective countermeasure used in MTD is
network address switching, which can be accomplished in
SDN with great ease.
In the data center network shown in Figure 1, we have
Tenant A hosting a web farm. Being security conscious, only
traffic on TCP port 443 is allowed into the IP addresses that
belong to the web servers. When an attack directed against
host A2 has been detected, the MTD application responds
with countermeasures and takes two actions: a) a new webserver (host A3) is spawned to handle the load of host A2;
and b) the IP for host A2 is migrated to the Honeypot network and assigned to host Z.
In order to run forensics, isolate and incapacitate the attacker, the HoneyPot network permits all inbound traffic,
but no traffic outward to other sections of the data center.
These actions result in new flow rules being injected into the
flow table that a) permits all traffic inbound to the IP that
originally belonged to host A2, but now belongs to host Z;

SYSTEM ARCHITECTURE & MODEL

In this section, we describe system architecture of our
SDN based MTD system, show how to use a distributed
Scenario Attack Graph (SAG) model to describe the possible threats and vulnerabilities in a large network, and propose a policy conflict checking model to address the possible
conflicts from mitigation strategies of the countermeasure
selection.

3.1

Threat Model

Figure 2: Threat Model.

28

In our attack model, we assume that an attacker can be
located either outside or inside of the virtual networking
system. The attackers primary goal is to exploit vulnerable VMs and compromise them as zombies. Our protection
model focuses on virtual network based attack detection and
reconfiguration solutions to improve the resiliency to zombie
explorations. Our work does not involve a host based IDS
and does not address how to handle encrypted traffic for attack detections. Our proposed solution can be deployed in
an Infrastructure-as-a-Service (IaaS) cloud networking system, where the Cloud Service Provider (CSP) is benign. We
also assume that cloud service users are free to install any
operating systems or applications, even if they are known to
be from adversarial sources.
We consider an OpenStack based cloud networking environment Figure 2. The components in the figure are OpenStack modules responsible for various functions. Nova is
responsible for VM provisioning and management. Neutron
provides network control. We install Firewall-as-a-Service
(FaaS) on top of Neutron. Neutron interacts with OpenDaylight (ODL) controller through a REST API. Various
firewall operations at layer-2 or layer-3 in this overlay network can be deployed to VM’s ODL policies via Neutron.
If we assume one VM of tenant 1 has a web server running
and another VM on tenant 2 has database server running. If
the goal of attacking is to compromise database server, the
attacker can first compromise web server on tenant 1 via
remote code execution or FTP based vulnerability. Once
he/she has access to the web server, he/she can use a web
server as a zombie VM and compromise the database server
on tenant 2 using SQL injection or SSH CLRF injection
vulnerabilities.

3.2

Figure 3: System Architecture.
DAC cycle, which ensures the system’s security compliance
and real time visualization.
Figure 4 represents the overlay structure of networks in an
SDN environment, and the layer on which each of the modules operates. Note that the modules function independent
of the physical topology, as is typical in any cloud environment. The SAG generation and countermeasure strategy
is based on the overlay network topology. The candidate
countermeasures are suggested as modifications to the overlay network.

3.3

Attack Analysis Model

Definition 1. A hypergraph is a generalization of a normal
graph H = (V, E). V represents vertices V = {vi |1 ≤ i ≤
n} and E = {ej |1 ≤ j ≤ m} represent the hyperedges. A
hyperedge is a subset of vertices. The degree of vertex is the
number of hyperedges it is part of. Degree of a given vertex
d(vi ) = |ej | ≥ 2.

System Architecture

Definition 2. A node N = {H, V } in an AG is a combination of hosts in the environment and the possible vulnerabilities that exist on that particular host.

Our system provides a framework to implement effective
MTD solutions while ensuring that the implemented solutions stay consistent with the overall security policy, and
do not cause unexpected side-effects as a result of conflicts
with other flow rules present in the system. This framework
utilizes the current system configuration, security policies,
flow rules, and a vulnerability database as input. It follows
a Detect-Analyze-Counter (DAC) cycle to make real time
updates to the network environment and effectively track
any system state or policy changes. This is accomplished
through four functionally distinct modules, as shown in Figure 3: a) attack and information gathering module; b) attack
analytics module; c) countermeasure selection and enforcement module; and d) policy conflict checking and resolution
module.
The attack and information gathering component consists of a vulnerability information gathering module. This information is sent to the attack analytics module
which conducts AG processing and analysis to determine
the current exposure to vulnerabilities. Based on the node
vulnerability and reachability information and flow rules obtained from the SDN environment, this module performs
node based security classification and stores the information in a database with the node acting as a primary key.
This information is then passed to countermeasure selection
and enforcement module. A candidate countermeasure is selected, and evaluated for consistency with the organization’s
security policy and SLAs. Upon acceptance, these new flow
and connectivity information is then fed back to the attack
and information gathering module. This creates a dynamic

Definition 3. An Attack Graph (AG) is a tuple G = {S, τ,
s0 , st } where S = N is number of states possible, τ ⊆ S∗S.
s0 ⊆ S is set of initial states and st ⊆ S is set of success
states.
Definition 4. Hypergraph partitioning is the process of partitioning a hypergraph into k-way (k ≥ 2) disjoint set of
node blocks B1 , B2 , Bk such that Bi ∩ Bj = ∅ ∀i 6= j.
Thus, we are trying to find a k-way mincut in a hypergraph.
Definition 5. A Scenario Attack Graph (SAG) = (V,E)
where
1. V = NC ∪ ND ∪ NR denotes a set of vertices that
includes conjunction nodes (NC ) to represent exploits,
disjunction node (ND ) denoting results of exploit, and
root node NR denoting the initial step of an attack scenario.
2. E = Epre ∪ Epost denotes the set of directed edges. An
edge e ∈ Epre ⊆ ND ∗ NC denotes that NC can be
attained only if ND is satisfied. An edge e ∈ Epost ⊆
NC ∗ ND means that ND can be obtained if NC is satisfied.
As can be seen from Figure 2 the threat model under
consideration has four nodes. We denote the web server
running on VM1 WS, the database server on VM4 as DS and
the attacker as A. The following is a possible chaining of
exploits by the attacker:

29

Figure 4: System modules and operating layers.
• execCode(A,WS,8080) - Remote Code exploit.
• execCode(A,WS,21) - FTP vulnerability exploit.
• execCode(WS,DS,22) - CLRF inject vulnerability exploit.
• execCode(WS,DS,53) - SQL injecttion exploit.
If there are N services each on the two hosts VM1 and
VM2, a fully connected AG will have N 2 nodes. It is easy
to see how the size of the nodes in AG can soon grow out of
bounds, making it hard to comprehend and represent each
possible attack scenario.
Our experimental results on Mininet [1] using an ODL
controller shows that it takes over twenty minutes to
generate an AG for a network of ten thousand nodes.
We plan to use the SDN based ODL controller in cloud
infrastructure to manage the complexity of assessing the
security state of the entire network. A MTD solution for
such a large network will face scalability challenges - state
space explosion, something our MTD solution effectively
addresses.
We partition the large AG into Sub Attack Graph
(SubAG) using the SDN controller as driver program. The
driver program coordinates with the sub attack graph
creation modules known as SubAG Agents to construct
a full AG. This helps in fast real time attack scenario
analysis. The process of the hypergraph partitioning based
AG creation reduces the time to construct full AG. The
AG constructed helps in MTD countermeasure selection in
real-time. For instance, in Figure 5 the hosts are partitioned
into two SubAGs each shown with different color. Services
SSH and FTP on hosts VM1, VM2, VM3; and ISCSI, SSH
and MySQL on VM4, VM5, VM6 represent two partitions
for the AG. The key idea is to distribute the load of SubAG
creation over several processors for each tenant and then
check reachability links across the tenants. The attacker in
Figure 5 has root access on VM1, so he is able to exploit
service MySQL based vulnerability on VM4. We merge
reachability information across SubAG’s to get final the
AG. The number of processors depends upon Cluster on
which Openstack is deployed. For instance, if we are using
HP Blade Server Cluster with 10 CPUs allocated to the

task of partitioning, with 2 processors per CPU, value of
the number of processors is 20.
Attack graphs are also useful in identifying the critical

Figure 5: A network reachability based partitioned
Attack Graph
assets in the network, for instance Asset Rank [24] based
approach can be used to rank critical assets in network,
which are more likely to be affected as a result of network
vulnerabilities. We can prioritize these assets for MTD
countermeasure.
The attack graph based approach is very effective in handling the dynamic attacks such as DDoS. If a botnet server
communicates with clients to target a system resource, this
information can be modeled using Attack Graph.
Most
modern vulnerability scanners report only the known vulnerabilities in the network such as remoteCodeExecution,
localBufferOverflow, etc. An attacker, however on gaining
privileges on a machine can install malicious applications
that can trigger zero day vulnerabilities. For instance, in
the Figure 5 VM1 which is WebServer may be providing
some web service to VM2. Once an attacker has gained root
access on VM1, he can downgrade a patched software, e.gflash player to a vulnerable version and try to compromise

30

VM1. These unknown security risks can also be modeled
using Attack Graphs. Although not discussed in the current
paper, we plan on exploring this active area of research
using attack graphs.

tion can impact the service availability for clients accessing
these VMs. We use formal methods post-countermeasure to
ensure System Liveliness and System Safety [5]. We identify
all preconditions for liveliness as Plive and Psaf e [5]. For
example,
Psaf e = {¬root(W S), ¬localprivEsc(f tpServ), ...}

3.4

and

Policy Conflict Checking Model

Plive = {sshAccess(V M 1, V M 2), f tpAccess(V M 1, f tpServ)}
Definition 6. A countermeasure is a set of operations on
a system that results in updating network configuration or
traffic policy that thwarts attacks while adhering to system
security policies and providing consistently high user experience.

Starting
state
of
system
is
s0
=
{userAccess(V M 1), userAccess(W S), ..} and the terminating state of the system is st .
For the attack graph G, we check preconditions nodes
described in attack analysis model e ∈ Epre ⊆ ND ∗ NC ,
then NC |= Psaf e ∪ Plive . We ensure all preconditions lead
to a state st which belongs to a critical asset to satisfy
safety and liveliness properties.

Implementing any countermeasure in an SDN environment would require a new set of flow rules to be generated.
However, introducing new flow rules as part of the countermeasure selection brings to light complex issues, amongst
which are cross-layer policy conflicts. Since abstracting the
data plane from the control plane in SDN means that multiple users could share the same physical network; if a tenant
were to implement an MTD solution, they could be implementing flow rules without holistic system knowledge. While
these flow rules are implemented perceivably private security policies, their presence on a shared control plane means
it could lead to potential flow rule conflicts in the overall
environment.
In a flow table F containing rule set {r1 , r2 , ..., rn }, with
each flow rule ri ∈ R being a 6-tuple < pi , αi , νi , i , ρi , ai ),
we have a) p as the priority of the rule defined in the range
[1, 65535]; b) α is the ingress port; c) ν is a VLAN ID; d) 
is a 6-tuple having source and destination addresses at OSI
layer-2, layer-3 and layer-4; e) ρ as the layer-4 protocol; and
f) a as the action set for the rule. Match fields α and ν, representing ingress port and VLAN ID merely eliminate and not
add to potential conflicts. Hence, we do not include them
in further discussion. Flow rules also contain packet counters and timeout values, but they are not relevant match or
action fields in rule processing.
Since flow rules in an SDN environment are clearly a
super-set of rules in a traditional firewall environment, work
on flow rule conflicts are an extension of the work on firewall
rule conflicts. While several works have classified firewall
rule conflicts ;the seminal work of Al-Shaer and Hamed [4]
is often used to classify firewall rule conflicts in a single firewall environment. Pisharody et al. [20] introduced a new
classification of conflicts that better describes conflicts between address space overlap over multiple OSI layers.
Knowing that OpenFlow specifications clarify that if a
packet matches two flow rules, only the flow rule with the
highest priority is invoked, conflicts in SDN flow rules can be
classified into categories Redundancy, Generalization, Correlation, Shadowing, Overlap, Imbrication as discussed by
Pisharody et al. [20].

3.5

4.

IMPLEMENTATION

In this section, we discuss the implementation details for
modules that comprise our framework. First, we discuss algorithms for a scalable AG, followed by a countermeasure
selection module and then the policy conflict detection and
resolution module. We note that the present system assumes the intrusion detection already in place and it will
send alerts to the security analysis module when malicious
attacks are detected.
The overall architecture of AG generation involves the creation of a reachability and vulnerability based hypergraph
on each tenant. The decision on creation of hypergraph
is based on size of number of nodes per tenant. A generated hypergraph is partitioned based on number of processors allocated by the administrator. For example, if three
processors are allocated for a given tenant, then each processor will take care of the creation of a SubAG, and we
will have three SubAGs. We use parallelization based on
PySpark [3] framework to merge the SubAG for each tenant. Resilient Distributed Datasets (RDDs) [33] are parallel
data-structures that are used for information exchange in
distributed networks. RDDs exchanges post conditions generated by each SubAG and attack tenant AG till no new
post conditions are left.

4.1

Attack Analysis Algorithm

We improve scalability of the attack analysis algorithm
by using parallelization framework and partitioning of large
hypergraph [17] into the logical framework of SubAG. The
data structures such as RDD are used for an efficient hypergraph partitioning.
Algorithm 1 is responsible for creating a hypergraph and
Algorithm 1 Hypergraph Partitioning Algorithm
1: procedure PartHypergraph(G, k ≥ 2, p, H ← ∅)
2:
V ← v1 , v2 , ...., vn
3:
for i = 1 → (n) do
4:
H ← H ∪ {vi , N (vi )}
5:
edgecuts, parts ← ParMETIS(H, k)
6:
return SHG

System Safety and Stability Post Countermeasures

As discussed during countermeasure selection algorithm 4
the VM is migrated from one physical server to another in
way that the overall vulnerability score for system is decreased. We still need to ensure no new attack scenarios
from reshuffling impact system safety. In addition, migra-

partitioning the hypergraph based on parallel hypergraph
partitioning algorithm ParMETIS [17]. The algorithm takes

31

graph G0 between two SubAG contain edges such that
ei ∈ {SubAG[vi ], SubAG[vj ]} and SubAG[vi ] 6= SubAG[vj ].
This means bipartite Graph G0 = SHGi ∩ SHGj . We make
use of RDD to update edges that belong to such bipartite
matching. Since there will be only a finite number of edges
which will be part of such matching, we will be able to do
the updates in constant time.
Next we will describe Countermeasure selection algo-

graph connectivity information represented by G as input,
along with a number of processors p, number of partitions
required k and empty data structure for hypergraph H. The
vertices in neighborhood of the vertex N (v) are part of hyperedge.
The Hypergraph H is then partitioned into regions based
on number of tenants as shown in use case Figure 5 using
the partitioning algorithm. SHG[ni ] will return partition to
which node ni belongs to after partitioning. For example, in
Figure 5, SHG[vm1:http:8080] will return Tenant Node 1.
Each processor p is responsible for construction of a SubAG
or cluster for a given tenant. This distribution of load for AG
construction is done using a PySpark [3] based framework
which maps SubAG construction phase over the p processors.
Hypergraph partitioning process aims to find k-way mincut in a Hypergraph, with k>1. Consider a variable  such
that 0 <  < 1. The objective of partitioning algorithm is
to construct a partition set π = {B1 , B2 , .., Bk } from the
hypergraph. The cost function for partitioning algorithm is
fo (π, E) where E represents the hyperedges. In our case,
cost is the run-time for the Algorithm. The weight function
for partitioning algorithm is fw (π) which is the cumulative
vulnerability score for each partition in our design.
The weight of each partition can be fetched from a weight
function by relation Wi = fw (Bi ). The average vulnerability score of all partitions is Wavg . The goal of the algorithm
is to optimize fw and fo , such that Wi < (1 + )Wavg [30].
In Algorithm 2 we check all vulnerability and reachability

Algorithm 3 Attack Graph Merge Algorithm
1: AG ← ∅
2: procedure GENERATE-FULL-AG(SubAG[])
3:
AG ← SubAG[]
4:
for each ei ∈ Read F rom RDD do
5:
if ei = {SubAGi , SubAGj } i 6= j then
6:
AG ← AG ∪ ei
rithm which will select best countermeasure possible from
pool of countermeasures based on the current state of network.

4.2

Countermeasure Selection and Deployment

In this algorithm, we consider two tables, one for virtual
machines and another for physical servers. Based on a designed vulnerability score, we trigger the migration of one of
the VMs. The score itself is the exponential average of the
CVSS Base Score from each vulnerability in the VM with a
maximum value of 10.
Let V Si vulnerability score for V Mi is defined as [7]:
X
V Si = M in{10, ln
expBaseScore(v) }
(1)

Algorithm 2 Sub AG Generation Algorithm
1: procedure Generate-SubAG(SHG)
2:
EN = Find Edge Nodes(SHG);
3:
for each e ∈ EN do
4:
Attackers = Find_External_Nodes_with_priv(e)
5:
V ulns = Find_Vulns_Info(SHG)
6:
Reaches = Find_Reach_Info(SHG)
7:
SAG = Create_SubAG(Attackers, V ulns, Reaches)
8:
while true do
9:
P ostConds = Find_New_PostConds(SAG)
10:
for each p ∈ P ostConds do
11:
Write_To_RDD(Agent, p)
12:
P ostConds =Read_NewPostCond(Agent)
13:
if P ostConds.size() == 0 then
14:
break

We use the greedy Algorithm 4 based on threshold CVSS
[2] score to perform migration pro-actively, assuming P S =
(P S1 , P S2 ,...,P SN ); and V M = (V M1 , V M2 ,..., V MK ).
The algorithm, pro-actively reshuffles the network reAlgorithm 4 VM Migration Countermeasure Selection Algorithm

1:
2:
3:
4:
5:
6:
7:

edges. The preconditions of the AG are the requirements for
an exploit to be successful. The postconditions on the other
hand mean privilege gained on successful exploit e.g. root
access. Since postconditions act as trigger or precondition
for another vulnerability, all new post conditions are written to the RDD. The agents or processors can check postconditions specific to their SubAG and update the SubAG
if necessary. The partitions generated from Algorithm 1 are
taken as input SHG for Algorithm 2. Since we check the
RDDs for updated information the AG generation process
makes sure new information such as nodes leaving the system or VMs migrating from one Physical server to another
are reflected in real time.
Next, in Algorithm 3 we merge the individual SubAGs. The input for the Algorithm is an array of individual SubAG’s. The edges that are part of bipartite

8:
9:
10:
11:

N The number of physical servers
K The number of VMs
V S The list of vulnerability score for VMs
for i:1 to N do
SP ← P S size Get physical server Size
while SP > 0 do
max ← k
for j: k+1 to K do
if V S[j] > V S[max] then
max ← j V Mj has a higher vulnerability
score V Sj
V Mj should be migrated to another Physical server
SV ← V M size
if SV < SP then V Mj is in Migration
SP ← SP − SV

sources, thus reduces the attack probability of the attacker.
While there are reactive solutions for protecting network resources, like Signature based IDS, deep packet inspection,
etc., they can be combined with proactive countermeasure
specified by algorithm to further reduce attack scenarios.
Since any change in the network configuration introduces
new flow rules into the SDN environment, as well as

32

4.4

alters the AG by disconnecting certain attack paths, while
opening up another potential attack paths; two sets of
actions follow: a) ensure that the new flow rules being
injected into the environment satisfy system policies and do
not conflict with existing rules; and b) generate new AG for
the modified system/network configuration.

4.3

SDN Controller Attack Prevention

SDN controller is a critical component in our infrastructure. The failure of the controller can affect the whole system. A distributed controller approach has been discussed in
Elasticon [9] where failure of one component will not affect
the whole system. Another example of distributed controller
has been discussed in Hyperflow [26]. The problem with
these approaches can be coordination between various components of the controller. We plan to leverage fault tree [32]
based failure analysis technique to address events/preconditions as defined in Section 3.3 that can lead to controller
failure. After the fault tree for these events has been constructed we can implement countermeasures to prevent preconditions leading to these events. As software related security bugs can also cause failure events we plan to perform
Static Analysis (SA) of controller code for OpenDaylight
controller that we are using in our implementation. This
can help us in identifying critical software warnings [10] to
help controller code developers follow safe coding practices.

Policy Conflict Resolution

The flow rule conflict detection and resolution module as
shown in Figure 6 helps resolve conflicts in flow rules in the
SDN environment. It consists of several sub-modules that
together examine a candidate countermeasure (selected by
the Countermeasure selection module), and achieve a conflict free flow rule table that then be used to implement the
updated security and traffic management countermeasure.
These are:

5.

EVALUATION

To evaluate our system, we considered vulnerability
information in MulVAL format, network reachability
information, and OpenDaylight based flow rules. The
data for MulVAL is generated using vulnerability scans
conducted on a prototypical virtualized cloud computing platform based on Openstack framework. The flow
rules from SDN controller and candidate countermeasures are translated to MulVAL host access control
based rules like allow(Everyone, read, webPages), and
(Src, Dst, Protocol, DstPort).

Figure 6: System overview representing flow rule
conflict detection module.
• Flow rule extractor that receives the candidate countermeasure in flow rule format from the countermeasure selection module, and also obtains the current flow
table from the SDN controller.
• Atomization engine: Since OpenFlow enables chained
flow tables with rules having set-field actions, in order to correctly identify conflicts between flow rules,
we atomize the flow rules by processing the chains and
ensuring that only the atomic actions of permit, deny,
and traffic shaping remain. The atomization process
itself follows along the lines of ipchain processing in
Unix.
• Conflict detection module that identifies conflicts
based on the categories described in Section 3.4.
• Conflict resolution module that attempts to resolve
conflicts automatically. However, in case of interpretative conflicts (generalization, correlation and imbrication), the candidate countermeasure is rejected and
an alternate countermeasure is sought from the countermeasure selection module.

5.1

Complexity Analysis

The complexity of our work is analyzed by individually
considering the complexities of AG creation, countermeasure selection and policy conflict resolution and any new
postconditions.
Serial partitioning approaches such as KL-Partitioning
[16] have a run time of O(N 2 log N ) to partition hypergraph with N nodes. We employ parallel partitioning algorithm [17] which distributes the task of partitioning hypergraph over p processors, which takes O(N/p)+O(N log p)
time to partition a hypergraph with N nodes. In the worst
case scenario we have full connectivity between all nodes in
the network.
RDDs as discussed in our algorithm contain partition information once the partitioning algorithm finishes its computation. These data structures update any new information from changes due to implementation of a countermeasure in network and use it to update attack graph dynamically. The merge time using RDD in such a scenario will
have a new postcondition generated on each node in the
network. This allows each node in network to exploit every
other node. Using p processors the load of creating all these
new post conditions can be distributed over p processors.
The AG merge time in such a case is O((N/p)2 ). This is
similar to a search using Depth First Search (DFS) over the
network, but with the search time distributed over p processors. Thus complexity of AG creation in worst case is sum
of hypergraph partitioning time and merge time giving us a
run time of O((N/p)2 ) + O(N/p) + O(N log p).
We analyze the complexity of the policy conflict detection

The candidate flow rule and the flow table are on the controller are parsed, and atomized. As a result of this process,
every flow rule that had an action which led to the execution of a different flow rule table was modified into one (or
more) rules that had terminal actions of permit, deny and
QoS. The resulting master flow rule table is then sorted by
descending order of the priority before being sent to the conflict detection engine [20]. A Patricia trie [19] based search
structure is used to conduct an efficient search to find overlapping layer-3 address spaces.

33

Parts K
3
4
5
6
7
8
9

separately below since it involves additional factors such as
flow rules and vulnerabilities. If n is the number of flow rules
that exist in the environment, r is the number of rules generated by candidate countermeasures, and |V | is the number
of vulnerabilities in network and |CM | the number of countermeasures, policy conflict detection and countermeasure
selection takes O(|V | × |CM |) + O(n.r).
Thus, the total running time for the algorithm will by
combining running times from the hypergraph partitioning,
AG merge and the policy conflict detection and countermeasure selection giving a total run time of O((N/p)2 ) +
O(N/p)+O(N log p)+O(|V |×|CM |)+O(n.r) ≈ O((N/p)2 ).

Time Taken [s]

Figure 8: Running time evaluation.

which is produced by MulVAL. We start by generating a
Hypergraph, which is dependent on the number of hyperedges. The time taken to generate hypergraph will be fixed
if the number of nodes do not change. The SubAG generation takes the most amount of time, and this time increases
with the increase in number of partitions K, from K = 3
to K = 6 which can be attributed to the time involved in
spawning separate agents for each SubAG. For K = 7 the
time decreases for SubAG generation, which is due to the
performance gain obtained due to parallelization. For K = 8
and K = 9, the SubAG generation time increases again. The
suitable K can thus be selected based on numerous iterations of the algorithm. The merge time for algorithm shows
a constant increase, which is expected except for an outlier
at K = 7. The overall performance gain in this network configuration due to use of spark based distributed structure is
significant. Thus, the solution can serve as the best model
for large, densely or sparsely connected networks.
The scalability and the runtime for the flow rule conflict module was tested with an input file containing about
10, 000 atomic flow rules, the processing time was about 6.45
ms. Rules were further replicated and inserted into the system to observe the growth of computation time. Figure 8
shows results from our experiment runs using different input
flow table sizes. Ten different test runs each were conducted
on flow tables of size varying from 10, 000 to 100, 000 rules,
and the resulting running times were averaged to get the
results in the plot. The results clearly show that our system
effectively identifies flow rule conflicts and takes corrective
action in spite of the large data sets. The results also clearly
show a O(n) running time. The run time of approximately
0.56 ms per 1, 000 flow rules for our system bodes well since
it clearly indicates that this module would not be the performance bottleneck in an SDN based MTD system.

20
16
12
8
4
0.3

0.5

0.7

Number of Nodes

0.9

101

Number of Flow Rules

K=3
4
5
6

0.1

Total Time
6.82
7.914
8.27
10.64
8.25
10.56
10.8

101.5

104

The experiments were run on an Intel i7 based cloud system. The host Operating System was Ubuntu 14.04. First,
we evaluated the dependency of time to generate AG to
the number of hosts and their connectivity. We conducted
the test on a MulVAL file with 1, 700 densely connected
hosts. The implementation of AG clusters/partitions generation involves use of the PySpark based parallelization
framework. Each SubAG is generated by one processor in
a Apache Spark framework. We computed the time to construct a scalable AG for a fixed number of partitions while
increasing number of nodes from 1, 700 to 11, 500. The time
to construct scalable AG increases as expected, going from
around 9 seconds for 5, 600 nodes to about 28 seconds to
generate AG for 11, 500 nodes. This drastic increase in time
is because the graph is densely connected and the number
of interconnections increase rapidly as we scale up the number of nodes. The time to construct an AG is still less than
half a minute, which is acceptable considering the number
of reads/write operations involved and merging phase of the
different AG partitions.

24

SHG Merge
0.24
0.29
0.43
0.48
0.44
0.57
0.68

105

Experimental Validation

30
28

SubAG Gen
6.28
7.76
7.84
10.16
7.8
10.09
10.32

Table 1: Time based complexity analysis of algorithm

Total Running Time (ms)

5.2

HG Part
0.30
0.35
0.36
0.37
0.38
0.36
0.36

1.1
·104

Figure 7: AG generation time vs Number of nodes
Next, we conducted an experiment to measure the time
required by the various parts of the algorithm, such as time
to partition hyper graph (PartHypergraph), time taken for
the SubAG generation (Generate-SubAG) and time for merging the smaller sub hypergraphs into a large connected AG
(GenerateFullAG). The results are shown in the Table 5.2.
The size of AG is N = 10, 000. The network is sparsely
connected. The time taken by various phases of algorithm
doesn’t include the time taken to create the input SAG

34

6.

RELATED WORK

grammable networking approach to improve their detection
accuracy. For example, changing the network filtering and
traffic forwarding rules can help the system to reduce the
unrelated network flows for traffic-pattern based anomaly
detection models. While signature based detection tools
show good performance, identifying known attacks like TCP
SYN-Flood, ICMP-flood. Although anomaly based detection models have high false positive rates sometimes, they
can help identify attack patterns not yet seen such as in
zero-day attacks. We plan to employ regression and other
statistical measures to ensure accuracy of anomaly detection methods. We also plan to deploy our solution in a
full-fledged Openstack based cloud environment.

A Hierarchical Attack Representation Model (HARM)
[11] is used to assess the effectiveness of an MTD technique [12]. While the authors employ several MTD techniques such as OS diversification and address randomization,
their experimental results only consider few hundred nodes.
The authors do not evaluate if the implemented changes conflict with other security policies. While an implicit assumption of countermeasure not conflicting with current system
rules may well be fair in a traditional environment, in a
multi-tenant shared data center environment, any change in
logical system configuration for a tenant may impact other
tenants, and hence evaluating if the implemented countermeasure conflicts with the rules present in the system is
essential.
Greedy shuffling MTD strategy using secret proxies to
fend of DDoS attack is used in [21] focusing mainly on DDoS
attacks. We plan on studying the role of vulnerability in the
target environment and cascading dependency created by
multi-hop attack in the system.
Predictability oriented defense against adaptive adversaries [22] combines game theory and machine learning. Authors model attackers action in ML feature space to provide
defense against current and future attacks. Spam filtering
has been used as a target application for this work.
The paper [31] has discussed switching strategies using
game theoretic approach for web applications.
Enforcing a conflict free security policy in cloud environments based on SDN has been studied in Flowguard [14],
Pyretic [18] and FRESCO [29]. These works deal effectively with direct conflicts by rejecting the policy and implementing role-based and signature-based enforcement to
ensure applications do not circumvent existing security policy. However, a flow can be defined in multiple layers, where
traditional policy checking approaches do not consider; for
examples, indirect security violations, partial violations or
cross-layer conflicts cannot be handled them. Moreover,
they appear not to fully leverage the SDN paradigm that lets
flow rules do traffic shaping in addition to implementing accept/deny security policy. Our previous work [20] overcame
some of these shortcomings by including analyzing traffic
rate limiting policies along with security policies to detect
and resolve direct, indirect and partial conflicts.

7.

Acknowledgments
This research is supported by NSF Secure and Resilient Networking (SRN) Project (1528099) and NATO Science for
Peace & Security Multi-Year Project (MD.SFPP 984425).
S. Pisharody is supported by a scholarship from the NSF
CyberCorps program (NSF-SFS-1129561).

8.

REFERENCES

[1] Mininet virtual network, 2015.
[2] CVSS, 2016.
[3] PySpark, https://spark.apache.org/docs/0.9.0/
python-programming-guide.html, 2016.
[4] E. S. Al-Shaer and H. H. Hamed. Firewall policy
advisor for anomaly discovery and rule editing. In
Integrated Network Management, 2003. IFIP/IEEE
Eighth International Symposium on, pages 17–30.
IEEE, 2003.
[5] C. Baier, J.-P. Katoen, and K. G. Larsen. Principles
of model checking. MIT press, 2008.
[6] M. Casado, M. J. Freedman, J. Pettit, J. Luo,
N. McKeown, and S. Shenker. Ethane: Taking control
of the enterprise. In ACM SIGCOMM Computer
Communication Review, volume 37, pages 1–12. ACM,
2007.
[7] C.-J. Chung, P. Khatkar, T. Xing, J. Lee, and
D. Huang. NICE: Network intrusion detection and
countermeasure selection in virtual network systems.
Dependable and Secure Computing, IEEE
Transactions on, 10(4):198–211, 2013.
[8] C.-J. Chung, T. Xing, D. Huang, D. Medhi, and
K. Trivedi. SeReNe: On establishing secure and
resilient networking services for an sdn-based
multi-tenant datacenter environment. In Dependable
Systems and Networks Workshops (DSN-W), 2015
IEEE International Conference on, pages 4–11. IEEE,
2015.
[9] A. A. Dixit, F. Hao, S. Mukherjee, T. Lakshman, and
R. Kompella. Elasticon: An elastic distributed SDN
controller. In Proceedings of the tenth ACM/IEEE
symposium on Architectures for networking and
communications systems, pages 17–28. ACM, 2014.
[10] S. Heckman and L. Williams. On establishing a
benchmark for evaluating static analysis alert
prioritization and classification techniques. In
Proceedings of the Second ACM-IEEE international
symposium on Empirical software engineering and
measurement, pages 41–50. ACM, 2008.

CONCLUSIONS

We provided a secured cloud framework for MTD solution.
As can be seen from the experimental results our solution
can scale well on a large network. The DAC methodology
ensures that any security threats present in the network are
detected and resolved in real time fashion. Our scalable AG
solution is very useful in analyzing the security state of a
large network, which would otherwise be difficult to interpret for a network administrator. Once we reconfigure the
network using a countermeasure selection module, we ensure
that there is no security policy violation or conflict in the
adjusted network. Our experimental study used OpenDaylight controller and Mininet testbed for evaluation.
The presented work focuses on known network attacks
and vulnerabilities to establish attack analysis model and
guide system to deploy selected countermeasures to provide
MTD solution. Our next step will incorporate anomaly detection models, and the research goal is how to use the pro-

35

[22] K. G. Richard Colbaugh. Predictability oriented
defense against adaptive adversaries. In Proceedings of
IEEE International Conference on Systems, Man, and
Cybernetics (SMC), pages 14–17. IEEE, 2012.
[23] R. Saha and A. Agarwal. Sdn approach to large scale
global data centers. Proceedings of Open Networking
Summit, Santa Clara, California, USA, 2012.
[24] R. E. Sawilla and X. Ou. Identifying critical attack
assets in dependency attack graphs. In European
Symposium on Research in Computer Security, pages
18–34. Springer, 2008.
[25] B. Schmerl, J. Cámara, G. A. Moreno, D. Garlan, and
A. Mellinger. Architecture-based self-adaptation for
moving target defense. Technical report, Technical
Report CMU-ISR-14-109. Carnegie Mellon University,
2014.
[26] S. Sezer, S. Scott-Hayward, P. K. Chouhan, B. Fraser,
D. Lake, J. Finnegan, N. Viljoen, M. Miller, and
N. Rao. Are we ready for SDN? implementation
challenges for software-defined networks. IEEE
Communications Magazine, 51(7):36–43, 2013.
[27] O. Sheyner and J. Wing. Tools for generating and
analyzing attack graphs. In Proceedings of Vol. 3188
Lecture Notes in Computer Science pp 344-371, pages
344–371. Springer, 2003.
[28] O. M. Sheyner. Scenario graphs and attack graphs.
PhD Thesis, CMU, 2004.
[29] S. Shin, P. A. Porras, V. Yegneswaran, M. W. Fong,
G. Gu, and M. Tyson. Fresco: Modular composable
security services for software-defined networks. 2013.
[30] A. Trifunovic. Parallel algorithms for hypergraph
partitioning. University of London, 2006.
[31] S. G. Vadlamudi, S. Sengupta, S. Kambhampati,
M. Taguinod, Z. Zhao, A. Doupé, and G. Ahn. Moving
target defense for web applications using bayesian
stackelberg games. CoRR, abs/1602.07024, 2016.
[32] B. Vesely. Fault tree analysis (FTA): Concepts and
applications. NASA HQ, 2002.
[33] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma,
M. McCauley, M. J. Franklin, S. Shenker, and
I. Stoica. Resilient distributed datasets: A
fault-tolerant abstraction for in-memory cluster
computing. In Proceedings of the 9th USENIX
conference on Networked Systems Design and
Implementation, pages 2–2. USENIX Association,
2012.

[11] J. B. Hong and D. S. Kim. Performance analysis of
scalable attack representation models. In Security and
Privacy Protection in Information Processing Systems,
pages 330–343. Springer, 2013.
[12] J. B. Hong and D. S. Kim. Scalable security models
for assessing effectiveness of moving target defenses. In
Dependable Systems and Networks (DSN), 2014 44th
Annual IEEE/IFIP International Conference on,
pages 515–526. IEEE, 2014.
[13] W. House. Trustworthy cyberspace: Strategic plan for
the federal cyber security research and development
program. Report of the National Science and
Technology Council, Executive Office of the President,
2011.
[14] H. Hu, W. Han, G.-J. Ahn, and Z. Zhao.
FLOWGUARD: building robust firewalls for
software-defined networks. In Proceedings of the third
workshop on Hot topics in software defined
networking, pages 97–102. ACM, 2014.
[15] J. H. Jafarian, E. Al-Shaer, and Q. Duan. Openflow
random host mutation: transparent moving target
defense using software defined networking. In
Proceedings of the first workshop on Hot topics in
software defined networks, pages 127–132. ACM, 2012.
[16] G. Karypis, R. Aggarwal, V. Kumar, and S. Shekhar.
Multilevel hypergraph partitioning: Applications in
vlsi domain. Very Large Scale Integration (VLSI)
Systems, IEEE Transactions on, 7(1):69–79, 1999.
[17] G. Karypis and K. Schloegel. Parallel graph
partitioning and sparse matrix ordering. University of
Minnesota, Department of Computer Science and
Engineering, 2013.
[18] C. Monsanto, J. Reich, N. Foster, J. Rexford,
D. Walker, et al. Composing software defined
networks. In NSDI, pages 1–13, 2013.
[19] D. R. Morrison. Patricia - Practical algorithm to
retrieve information coded in alphanumeric. Journal of
the ACM (JACM), 15(4):514–534, 1968.
[20] S. Pisharody, A. Chowdhary, and D. Huang. Security
policy checking in distributed SDN based clouds. In
2016 IEEE Conference on Communications and
Network Security (CNS) (IEEE CNS 2016), Oct. 2016.
[21] A. S. Quan Jia, Kun Sun. Motag: Moving target
defense against internet denial of service attacks. In
Proceedings of 22nd International Conference on
Computer Communication and Networks (ICCCN),
pages 1–9. IEEE, 2013.

36

A Database Oriented Management for
Asynchronous and Consistent Reconfiguration in
Software-Defined Networks
Yuki Kawai† , Yasuhiro Sato∗ , Shingo Ata† , Dijiang Huang‡ , Deep Medhi§ , and Ikuo Oka†
† Osaka

City University, Japan
Coast Guard Academy, Japan
‡ Arizona State University, USA
§ University of Missouri–Kansas City, USA
∗ Japan

Abstract—Software-Defined Networking (SDN) is a new approach to manage the whole network flexibly by decoupling
the control plane and the forwarding plane. While forwarding
elements can be managed by a unified control, complexity arisen
from the network size and scalability regarding the increase of
the control traffic are notable problems. To deal with events of
network reconfiguration that occur asynchronously and change
frequently with intervals shorter than hours, a controller has to
continue to asynchronously update the configuration of the whole
network. However, it is hard to maintain the consistency of the
configuration of the whole network because it needs to manage
a huge amount of network information and to deal with user
requests that occur asynchronously. In this paper, we propose a
database oriented management for asynchronous reconfiguration
to achieve the consistency of configuration in SDN. We design a
structure of the database to store network information and two
functional components. Finally, we adopt our management system
to an OpenFlow-based network, and validate that our system can
manage and control an OpenFlow network via the database.

I.

I NTRODUCTION

As one of the new approaches to make network configuration easier and to realize a more flexible network environment, Software-Defined Networking (SDN) has emerged [1].
In SDN, network devices such as routers and switches are
specialized for packet forwarding, while the control function
is separated from the forwarding plane. The control function
is implemented in a SDN controller that manages all network
devices placed on the forwarding plane through a software
program. Thus, the controller retrieves the network information from all network devices, and processes the information
appropriately to decide packet-forwarding rules. If the network
size becomes large, the controller has to handle a huge amount
of the information, which is a network condition or control
message [2]. It is hard for the controller to continue to reconfigure the whole network while maintaining the consistency
of the configuration. In such cases, important problems we
should be addressed are (1) to maintain the consistency against
a huge amount of information updates, and (2) to operate the
information update frequently and asynchronously.
In this paper, we propose a database oriented management
for asynchronous and consistent reconfiguration in SDN and
we also design two functional components, configuration engine and conversion driver. For our motivation, we design
c 2014 IEEE
978-1-4799-0913-1/14/$31.00 ⃝

structures of two databases, Logical DB and Physical DB.
Logical DB stores abstracted network configuration that is
described by network administrator. Physical DB manages
the underlying physical network information that is used for
creating packet-forwarding rules for SDN switches. We also
design two functional components, configuration engine and
conversion driver. We address the problems mentioned above
by stating that (1) a controller stores all of the information,
such as the physical topology, the global network status,
and the configurations into a relational database, and (2)
each functional component can operate independently and
asynchronously to prevent conflicts caused by the information
updates. A key idea of the system is to manage up-to-date
information about network configuration or the network status
in databases. The database has the advantage of data processing
and addresses asynchronous updates by the transaction processing. Each functional component fetches the information
stored in databases and creates information about network
configuration. Each component operates independently and
asynchronously through databases, since the path computation
function is separated from the control function. For this purpose, we also consider table structures of the databases that
store the network information, such as the physical topology
and packet forwarding rules. To reveal advantages of our approach, we apply the concept of database oriented management
on an OpenFlow-based experimental network and validate that
our system can configure an OpenFlow-based network through
the databases.
The paper is organized as follows. A survey of related
works is found in Section II. The detailed description of our
proposed system is shown in Section III. We implement the
databases and the functional components on an OpenFlowbased network in Section IV. Finally, we conclude this paper
in Section V.
II.

R ELATED WORK

In SDN architecture, scalability of SDN controllers and
consistency of configurations in the whole network become
notable concerns [2][3]. The authors in [4] modified a NOX
controller, which is one of the SDN controllers, to optimize
multi-thread processors and investigate controller performance
in four public SDN controllers including the modified NOX.
In [5], the authors proposed an extensible SDN control system,
the throughput of which scales with the number of CPU cores

on a single controller. They also claimed that a centralized
control on the control plane may cause a bottleneck on SDN
controllers. As the network size becomes large, a controller has
to manage a huge number of forwarding elements and flows.
As a result, configuration updates occur frequently, and then it
is hard to maintain the consistency of the whole network [6].
In [7], the authors proposed a real-time verification system for
the configuration of the whole network to prevent configuration
failure or misses by checking forwarding rules between SDN
applications and SDN controllers. Another approach to achieve
a more scalable control system is a physically-distributed
control plane [8]. In such a distributed control system, the
control plane consists of multiple controllers that manage
different domains of the whole network. To ensure the global
connectivity between arbitrary two end nodes, each controller
has to communicate with the adjacent controllers to exchange
local configurations while maintaining the consistency. Furthermore, when updating from an old policy to a new policy
across multiple switches, where two policies coexist in the
whole network at the same time, then the consistency of
the configurations among the switches is hard to maintain.
Reitblatt et al. addressed one of the important problems in
configuring multiple SDN switches [9]. To ensure the consistency of a per-packet or per-flow level, they introduced the
configuration version number and timeout value.
III.

A DATABASE ORIENTED MANAGEMENT FOR
ASYNCHRONOUS RECONFIGURATION

In this section, we describe the overview of our database
oriented management system for SDN and show the design of
the databases, configuration engine, and conversion driver.
A. Overview
Figure 1 shows the overview of our database oriented
management system in SDN. Our system has two databases,
Logical DB and Physical DB and two functional components,
Configuration engine and Conversion driver. To manage a
network, a network administrator specifies abstracted network
configurations, and stores the configurations into the Logical
DB. Based on the network configuration stored in the Logical
DB, the configuration engine determines the communication
paths according to a specified routing protocol and allocates
network resources to configure the physical network. After
that, each engine creates low-level network information and
stores them into the Physical DB. Even if two or more engines
are specified in one network by the administrator, these engines
can access the databases independently and asynchronously. A
conversion driver translates the low-level network information
into a configuration file adapting to the notation of a certain
SDN controller. Finally, a SDN controller updates the flow
table of each switch through a software program translated by
the conversion driver.
B. Databases
1) Logical DB: Figure 2 shows the table structure of
the Logical DB, which manages high-level network information described by network administrators. The high-level
network information denotes an abstracted network configuration. Forinstance, the administrator indicates which node
participates in the network, which routing mechanism is

Network Administrator

Abstracted
network
config.

Abstracted
network config.
Physical network info./
Low-level network config.

Logical DB
Physical DB

Low-level network config.

Conversion
Drivers

NOX

Trema

Beacon

Config file
for NOX

Config file
for Trema

Config file
for Beacon

Configuration
Engines
Fetch
Fetch/Update
Push

SDN controllers
Configuration
commands

Fig. 1.

Overview of our proposed management system in SDN

Network Element
Network Element ID
Element type =
{Managed Network, Node}
Deleted
Updated
Node
Network Element ID
Node name
Deleted
Updated

Fig. 2.

SDN-enabled nework

Managed Network
Managed Network ID
Managed Network name
Deleted
Updated
Network Group
Managed Network ID
Network Element ID
Deleted
Updated

Engine List
Managed Network ID
Configure Engine ID
Deleted
Updated
Configuration Engine
Configuration Engine ID
Engine name
Deleted
Updated

Table structure of Logical DB

adopted, and how many network resources are assigned to the
communication paths. Because of this abstracted configuration,
the administrator does not have to know the global information of the physical topology and low-level configuration
commands to manage SDN switches. A managed network
is a network where a network administrator manages it as
an administrative domain. For instance, a virtualized network
operating on the physical network is a managed network. The
managed network table contains the managed network name
to identify managed networks in the control plane. A network
consists of either nodes, networks or both. Thus, a network
can contain another network. A node or a network is defined
as a network element stored in the network element table.
The information of node is managed in the node table. The
information of network is managed in the network group table
as a set of the network elements. The configuration engine
table stores the information of configuration engines that the
network administrator can adopt to a managed network in
high-level network information. The engine list table manages
mapping information of managed network and configuration
engine. The deleted and updated fields in each table are used
for checking whether the entry has been changed or not.
2) Physical DB: Figure 3 shows the table structure of
the Physical DB. The information stored in the tables of this
database can be categorized into either the physical information or the intermediate code. The physical information, such
as the node address, is stored in the physical information tables,
which are enclosed within the dashed line. The low-level
control information generated by the configuration engine,

Link Resource
Link ID
Bandwidth
Utilization
Deleted
Updated
Link
Link ID
Bandwidth
Propagation
Delay
Deleted
Updated
Node Interface
Interface ID
Node ID
MAC address
IP address
Interface #
Deleted
Updated
Node Resource
Node ID
Table size
Deleted
Updated

Fig. 3.

LAN
LAN ID
Network address
Deleted
Updated
Link List
LAN ID
Link ID
Deleted
Updated
Interface List
Link ID
Interface ID
Deleted
Updated
Node
Node ID
Node name
Max table size
datapath
Deleted
Updated
Physical Information Tables

Path
Path ID
Managed Network ID
source network
element ID
destination network
element ID
Deleted
Updated
Rule
Rule ID
Path ID
Node ID
priority
input port
dl type
VLAN Tag
source ip address
destination ip address
protocol
ip tos
source port #
destination port #
Deleted
Updated

VLAN
VLAN ID
Path ID
Link ID
VLAN Tag
Deleted
Updated
Action
Action ID
Rule ID
action
Deleted
Updated
Output
OutPut ID
Rule ID
output
Deleted
Updated
Intermediate Code
Tables

Table structure of Physical DB

such as the switching action, is stored in the intermediate code
tables, which are enclosed within the dash-dot line.
a) Physical information tables: The physical information tables consist of eight tables. The link table stores
the physical link information, such as the propagation delay
and the line speed. The current status of the physical link is
managed in the link resource table. The LAN table stores the
network address of the network segment, and the LAN list
table manages the link IDs connecting to the same network
segment. The node table in the physical database stores a node
identifier (e.g., IP address) and datapath ID that are required
from SDN controllers. The node interface table manages the
information of physical interfaces equipped on the node. A
physical link is connected to two physical interfaces on distinct
nodes. The interface list table manages the physical interfaces
ID and the link ID. The physical information described above
has to be inputted by the network administrators as the initial
setting before our proposed system operates.
b) Intermediate code tables: Intermediate code is a
fundamental network configuration information to be required
for configuring SDN switches. Thus, this code is constitutes
more general information that is easy to apply to the notation
of various SDN controllers. The intermediate code is managed
in six tables in the physical database. The path table manages
communication paths between the source and destination nodes
participating in the managed network that is identified by
the Managed Network ID field. Since a communication path
consists of two or more physical links connecting to the
intermediate codes between the source and destination nodes,
the link set table manages the path ID and several link IDs
that constitute the same path. VLAN is widely adopted to
realize virtualized networks in SDN-enabled networks including OpenFlow. Because a physical link belongs to multiple
communication paths, it is not enough to assign a pair of
VLAN IDs and VLAN tags to each physical link. Thus, the
VLAN ID and VLAN tag are assigned to the link identified
by both the path ID and the link ID. The rule table manages
forwarding rules to be applied to the switch identified by the
node ID and has the same fields of IP packets and L2 frames.
The switching actions to be applied to the flows identified

Physical DB
172.16.20.54

Logical DB
172.16.20.51

Link set
Link ID
Path ID
Deleted
Updated

Control plane

CE: Shortest
Path Routing
172.16.20.53
OF Controller
192.168.20.50

Admin's Terminal
172.16.20.90

OpenFlow commands

1
squeeze1
192.168.1.1

Fig. 4.

exp-net

10
OF Sw A

20

OF Sw B

2

squeeze2
192.168.1.2

Forwarding plane

Our experimental network

at each switch are managed in the Action table. The actions
include rewriting of the MAC address or IP address and
attaching/strapping a VLAN tag. To forward one packet to two
or more physical interfaces at once, the output table manages
the output interfaces where the packet is forwarded.
C. Configuration engine
The configuration engine fetches the abstracted network
information from the Logical DB and processes them to create
the intermediate code. Basically, each configuration engine
operates independently and has just one role. Typical roles
are routing calculation and resource management etc. Network
administrators can decide which engines are applied to a
managed network by specifying them in the high-level network
information. In our management system, various network
designs can be achieved by a combination of configuration
engines. Moreover, it is easy to add new configuration engine
to our system, and asynchronous transactions can be processed
sufficiently because of the independency of the configuration
engines.
D. Conversion driver
The conversion driver converts the information stored in the
intermediate code tables into a suitable configuration program
that the SDN controller can read directly. Although various
SDN controllers are proposed thus far, there is no compatibility
among the SDN controllers. Thus, the network administrator
has to prepare a configuration file that is appropriate for each
controller, even if the network configuration is the same. The
administrator can configure the network without considering
the details of the SDN controllers because the conversion
driver absorbs the difference among the SDN controllers. The
administrator can cope with a change of the SDN controller
by shifting to an appropriate conversion driver.
IV.

I MPLEMENTATION OF DATABASES AND FUNCTIONAL
COMPONENTS

In this section, we implement and validate our database
oriented management system on an OpenFlow network.
A. Implementation environment
Figure 4 shows the detailed settings of our experimental
network. The control plane consists of the databases and
functional components that are operated on Debian Squeeze

TABLE I.

Network
Administrator

TABLES
Logical DB

Physical DB

Configuration Engine

1

2

SQL query for
Network Config
Managed Network name
Configure Engine ID
Network Element ID

SQL query for
Update Detection
SQL query for
Fetch Network Config
Managed Network ID
Network Element ID

3

SQL query for Fetch
Physical Network Information
Node ID
Link ID

4

Interface ID
LAN ID

SQL query for
Insert Intermediate Code
source network element ID
destination network element ID
Path ID
Node ID
datapath
priority
input port
dl type
VLAN Tag
protocol
ip tos
output
source ip address
destination ip address
source port #
destination port #

(a) From the time administrator specifies abstracted configuration to the time
Physical DB is updated.

Conversion Driver

Physical DB
SQL query for
Update Detection

SDN Controller (Trema)

Network devices
(OpenFlow Switches)

5

SQL query for
Fetch Intermediate Code
datapath
priority
input port
dl type
VLAN tag
protocol
ip tos
output
source ip address
destination ip address
source port #
destination port #

6
Configuration File

7

Configuration
Commands

(b) From the time conversion driver detects update in Physical DB to the time
a new network becomes available.
Fig. 5.

RULE TABLE WHICH IS ONE OF THE I NTERMEDIATE CODE

Sequence diagrams of functional components in our system

with Linux 2.6.32. The administrator’s terminal is operated
on Mac OS X 10.6.8. Two OpenFlow Switches are placed on
the forwarding plane and each of these is connected directly
to a client’s PC. The numbers denoted beside the switches
mean port numbers of the physical interface connecting to the
cable. The SDN controller, where Trema [10] is installed, is
connected to a management port of each OpenFlow Switch. We
develop a Logical DB and Physical DB on a MySQL Server
version 5.1.66. The engine and the driver are implemented in
C++.
B. Implementation of our management system
Figure 5(a) shows a sequence diagram from the time when
the network administrator stores abstract network information
into the Logical DB to the time when the engine stores the
intermediate code into the Physical DB. Figure 5(b) shows a
sequence diagram from the time when the conversion driver
detects an update of the Physical DB to the time when the
OpenFlow controller configures the OpenFlow switches. The
procedures of managing a network in our system are described
as follows.
At Step 1, the network administrator describes abstracted
network configurations for creating a network. To confirm that
a new network is successfully created, the administrator obtains the assigned managed network ID from Logical DB. After
that, the administrator has to specify nodes or networks that

Rule ID
1
2
3
4
5
6
7
8

Node ID
3
3
4
4
4
4
3
3

Path ID
1
1
1
1
2
2
2
2

dl type
arp
ip
arp
ip
arp
ip
arp
ip

source ip address
192.168.1.2
192.168.1.2
192.168.1.2
192.168.1.2
192.168.1.1
192.168.1.1
192.168.1.1
192.168.1.1

destination ip address
192.168.1.1
192.168.1.1
192.168.1.1
192.168.1.1
192.168.1.2
192.168.1.2
192.168.1.2
192.168.1.2

participate in the new network and the configuration engines
to be applied to the network. At Step 2, the configuration
engine continuously monitors the network information in the
Logical DB. If the network group table or the engine list table
has been updated, the engine fetches the network information
from tables in the Logical DB related to the engine. At Step
3, the configuration engine requests physical information to
the physical DB for performing path calculation or resource
assignment. At Step 4, each engine creates the intermediate
code as fundamental information of the configuration file for
the SDN controllers, and updates the code to the intermediate
code tables in the Physical DB. Table I shows snapshot of the
intermediate code when we configured a network denoted in
Fig.4. At Step 5, if the tables containing the intermediate code
have updated, the conversion driver sends a SQL query to fetch
information of the tables. The driver converts the intermediate
code like Table I into the flow table. At Step 6, the conversion
driver converts the intermediate code into a configuration file
and transfers it to the SDN controller. Finally, Trema applies
the configuration file and sends configuration commands to
OpenFlow switches according to the configuration file.

C. Experimental Validation
We check whether squeeze1 and squeeze2 can communicate with each other in a new network created by configuring only the Logical DB. The details of the configuration
of our experiment are shown in the previous section. After
updating the Logical DB, we confirmed that two clients can
reach each other by a ping command.

V.

C ONCLUSION

We have proposed a database oriented management for
asynchronous reconfiguration in SDN. For this, we have designed structures of the databases, and two functional components. Based on our design, we have also adopted our system
to an OpenFlow network, and also validated that the OpenFlow
network can be managed via the databases. For future topics,
we need to evaluate scalability of our system and take time to
reflect on the rules.

ACKNOWLEDGMENT
This work is supported by US NSF grants CNS-1029562
and CNS-1029546, the Office of the Naval Research’s (ONR)
Young Investigator Program (YIP), and a Japan NICT International Collaborative Research Grant.

R EFERENCES
[1] Open Networking Foundation, “Software-defined networking: The new
norm for networks.” White Paper, April 2012.
[2] S. H. Yeganeh, A. Tootoonchian, and Y. Ganjali, “On scalability
of software-defined networking,” IEEE Communications Magazine,
vol. 51, pp. 136–141, February 2013.
[3] N. P. Katta, J. Rexford, and D. Walker, “Incremental consistent updates,”
in Proceedings of the 2nd ACM SIGCOMM Workshop on Hot Topics
in Software Defined Network (HotSDN 2013), (Hong Kong, China),
pp. 49–54, August 2013.
[4] A. Tootoonchian, S. Gorbunov, Y. Ganjali, M. Casado, and R. Sherwood, “On controller performance in software-defined networks,” in
Proceedings of the 2nd USENIX Conference on Hot Topics in Management of Internet, Cloud, and Enterprise Networks and Services (HotICE 2012), (San Jose, CA), p. 10, April 2012.
[5] A. Voellmy and J. Wang, “Scalable software defined network controllers,” in Proceedings of the 2012 ACM SIGCOMM Computer
Communication Review, (Helsinki, Finland), pp. 289–290, August 2012.
[6] T. Mizrahi and Y. Moses, “Time-based updates in software defined
networks,” in Proceedings of the 2nd ACM SIGCOMM Workshop on
Hot Topics in Software Defined Network (HotSDN 2013), (Hong Kong,
China), pp. 163–164, August 2013.
[7] A. Khurshid, W. Zhou, matthew Caesar, and P. B. Godfrey, “Veriflow:
Verifying network-wide invariants in real time,” in Proceedings of the
1st ACM SIGCOMM Workshop on Hot Topics in Software Defined
Networks (HotSDN 2012), (Helsinki, Finland), pp. 49–54, August 2012.
[8] A. Dixit, F. Hao, S. Mukherjee, T. Lakshman, and R. Kompella,
“Towards an elastic distributed SDN controller,” in Proceedings of the
2nd ACM SIGCOMM Workshop on Hot Topics in Software Defined
Network (HotSDN 2013), (Hong Kong, China), pp. 7–12, August 2013.
[9] M. Reitblatt, N. Foster, J. Rexford, and D. Walker, “Consistent updates
for software-defined networks: change you can believe in!,” in Proceedings of the 10th ACM Workshop on Hot Topics in Networks (HotNets-X),
(Cambridge, Massachusetts, USA), pp. 1–6, November 2011.
[10] H. Shimonishi, Y. Takamiya, Y. Chiba, K. Sugyo, Y. Hatano, K. Sonoda,
K. Suzuki, D. Kotani, and I. Akiyoshi, “Programmable network using
openflow for network researches and experiments,” in Proceedings of
the 6th International Conference on Mobile Computing and Ubiquitous
Networking (ICMU 2012), (Okinawa, Japan), pp. 164–171, May 2012.

Dynamic Game based Security framework in SDN-enabled
Cloud Networking Environments
Ankur Chowdhary
Adel Alshamrani

Sandeep Pisharody
Dijiang Huang

School of Computing, Informatics and Decision Systems Engineering
Arizona State University, Tempe, AZ
<achaud16, spishar1, aalsham4, dhuang8>@asu.edu

ABSTRACT

in a single device is hard; it becomes very difficult to detect
and counter such attacks. In addition, each different device
may have vendor specific command and control mechanism.
Software Defined Network (SDN) provides separation between data and control plane [13]. A logically centralized
controller such as OpenDaylight (ODL) is used for taking
control decisions such as routing, load balancing, firewall
policies, IDS and Service Level Agreement (SLA) [14]. The
data-plane, which is involved with traffic forwarding remains
a part of devices such as switches and routers. The control
decisions taken by control plane are enforced by devices.
In this work we model the DDoS attack as a dynamic
game between the attacker and administrator. The attacker
has a goal of targeting critical infrastructure by sending a
huge volume of traffic through bots distributed inside or outside the target environment. While we can assume some of
the bots are detected by the IDS based on signature match,
modern DDoS botnets are very stealthy in nature. To this
end, we introduce a game theoretic model which will help
uncover entire botnet, and rate limit traffic from these malicious users/bots. The concept of reward and punishment
which is used in game theoretic models to enforce cooperation between firms has been employed in this research work.
To sustain mutually desirable outcomes, the agents/users
with undesired behavior are punished. Various game theoretic approaches that can be used to model the system have
been shown in the figure below.

SDN provides a way to manage complex networks by introducing programmability and abstraction of the control
plane. All networks suffer from attacks to critical infrastructure and services such as DDoS attacks. We make use of the
programmability provided by the SDN environment to provide a game theoretic attack analysis and countermeasure
selection model in this research work. The model is based
on reward and punishment in a dynamic game with multiple
players. The network bandwidth of attackers is downgraded
for a certain period of time, and restored to normal when
the player resumes cooperation. The presented solution is
based on Nash Folk Theorem, which is used to implement a
punishment mechanism for attackers who are part of DDoS
traffic, and reward for players who cooperate, in effect enforcing desired outcome for the network administrator.

Keywords
Software Defined Networking (SDN), Game Theory, Distributed Denial of Service (DDoS), Moving Target Defense
(MTD), Cloud Systems

1.

INTRODUCTION

Distributed Denial of Service (DDoS) is a major security
problem affecting networks. Some recent cases include a
massive DDoS attack on DNS provider Dyn in October 2016,
and an attack on the website krebsonsecurity.com which was
of magnitude 650 Gbps. The attackers leverage sophisticated botnets such as Leet to send massive traffic to the
victim, thus overwhelming the limited capacity of the victim. Traditional networks usually incorporate mechanisms
such as firewall, Intrusion Detection System (IDS) and Intrusion Prevention System (IPS) to detect and counter such
attacks. Since there are multiple entities (such as routers,
firewall, switches etc.) involved in enforcing the security
mechanism, and cooperative sharing of attack information
between devices that have data and control plane embedded

Game Theory
Cooperative

Competitive

Static Dynamic Static Dynamic

Figure 1: Game theory classification.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

We consider our system to be a dynamic multi-player
game. A single network administrator (SDN Controller in
our case) is playing against multiple players, some of which
are attackers. We deploy administrator’s strategy in form of
Openflow rules. Since some of the countermeasures deployed
as part of defense strategy can conflict with some existing
rules, in our previous work [15] we use a flow rule conflict
detection and resolution algorithm to first detect and then

SDN-NFV Sec’17, March 22-24, 2017, Scottsdale, AZ, USA
c 2017 ACM. ISBN 978-1-4503-4908-6/17/03. . . $15.00

DOI: http://dx.doi.org/10.1145/3040992.3040998

53

eliminate flow rule conflicts. The attackers have some incentive of deviating from normal behavior at a particular
instant but admin has control over network resource optimization, and he can counter attacker’s move by limiting
his available bandwidth in next time instance of play.
In Section 2, we discuss a motivating example and some
key terminology. Section 3 introduces a reward-punishment
model based on Nash Folk theorem. Section 4 consists of
implementation and Section 5 discusses the evaluation of a
game theoretic model on a small test environment. We discuss some related work in dealing with DDoS attacks in SDN
and compare our model to them in Section 6. Finally, conclusion of this work and direction for the future are discussed
in Section 7.

2.

Player 1

a11
a21

Player 2
a12
a22
( B2 , B2 ) ( 3B
, B4 )
4
B 3B
B 4B
(4, 4 ) (5, 5 )

Table 1: Normal form representation of Attacker
and administrator Payoff ’s
a12 , i.e. cooperate. However, in second period t = 2 he/she
checks the history H of P1 defined above, observes the
earlier defect action, and selects a22 irrespective of action
chosen by P1 . To punish the P1 further, he chooses same
action as t = 2 in period t = 3. The deviation from normal
behavior is considered a trigger strategy.

BACKGROUND

In this Section, we introduce some background concepts
used in this research work.

We define the minmax payoff in a Game before introducing definition of Nash Folk theorem which we use as the basis
for our deterrence algorithm for malicious users.

Definition 1. We define a N player extensive form repeated
game G with perfect information between multiple players
as G = {N, Ai , ui } where N = {1, 2, . . . n} denotes number
of players, ai ∈ Ai is the action set available to player i.
ui : ai 7→ Ri is the payoff function that maps actions to
reward value R.

Definition 4. The minmax payoff value of a player is
the lowest payoff value that can be forced upon a given
player by all other players. This is denoted by value vi =
mina−i ∈A−i maxai ∈Ai ui (a−i , ai ).
Since the future payoff is less desirable compared to the
current payoff value, we use discount factor δ ∈ (0, 1]. We
use this variable to motivate the definition of the Nash Folk
theorem.

Definition 2. We consider that the game has been played
to t periods of time, and define game history in an instance t
as ht = {a1 , a2 , .., at−1 } = At−1 . This denotes actions taken
∞
P
by a player until now. H1 = {∅}, and H =
Ht .

Definition 5. The Nash Folk Theorem for a an extensive
form game states that payoff profile which was present for
Nash Equilibrium denoted by wi can be enforced upon a given
player in the long term by punishing him for a given period of time. If the player P1 deviates from good behavior,
his opponents will use minmax strategy against him/her till
the continuous reward value is no better than in the case
T
P
where he never shows malicious behavior. wi ≥ vi +
δt ×

t=1

A player i prefers an action at over bt if ui (at ) ≥∗i ui (bt ).
The payoff profile for a player is considered feasible in this
game, i.e. convex
combination of payoff
P profiles of outcome
P
of A, s =
a∈A αa = 1. Here s
a∈A αa u(a) such that
represents the strategy vector for a player.

t=1

We illustrate the game used in this work with an example
of two players, who take turns to decide on an action. Assume the players P1 and P2 correspond to an attacker and
administrator.

mina−i ∈A−i maxai ∈Ai ui (at−i , ati ). Here vi denotes defection
payoff for attacker at t = 0. The second equation on right
hand side i.e. mina−i ∈A−i maxai ∈Ai ui (at−i , ati ) shows that
P1 has been min-maxed by other players from t = {1, T } if
he defect at t = 0. The value for T , i.e. time periods for
which punishment should be carried out can be derived by
solving this linear inequality.

Definition 3. The strategy vector of a player i, s∗i is
best response to strategy vector of all other players s∗−i if
ui (s∗i , s∗−i ) ≥ ui (si , s∗−i ) for all si . This vector is a Nash
Equilibrium if the relation holds for all si and all i.

Extensive form game tree for such a game is depicted in
Figure 2 below. The P1 represents the attacker and P2 represent the network admin in this figure.
The path in green indicates the administrator’s choice of
action when the user behaves normally. We can see the payoff matrix from Table 1 and check average bandwidth at end
of period t = 2, which will be B2 since the user is cooperating at t = {0, 1}. In case user P1 defects (behaves as an
attacker), he/she will gain bandwidth 3B
at t = 1, but the
4
administrator P2 will punish user at t = 1, resulting in a
bandwidth BW = B5 during the next time period. The re+ B5 } = 0.475B, which
sulting average BW will be 12 × { 3B
4
is lower than 0.75B, the bandwidth had P1 behaved in a
cooperative fashion. The path in red shows attack countermeasure procedure followed by P2 . In the long term the
attacker will be better off by behaving normally (sending no
malicious traffic) if we deploy rate limiting mechanism using
this scheme.

For the two player example, we consider both players
would try to play Nash Equilibrium value against each other.
Let us consider utility in terms of network bandwidth for
this game. P1 has actions a1 = {Cooperate, Defect} and P2
has action set a2 = {Cooperate, Defect}. As long as any
player behaves in a benign manner, the administrator will
allow normal bandwidth to the player. If attack from some
malicious node in a network is detected by administrator,
he/she will play a strategy of Rate-Limiting the attacker’s
bandwidth available. Sample payoff matrix in normal form
has been shown in the Figure 1, where B denotes the total
network bandwidth.
Since we consider a dynamic game with perfect information, we need to consider an extensive form of the game.
For this particular example, consider that the attacker
chooses action a12 , that is defect against P2 who assumes
all users for network behave in a benign way and chooses

54

tack. The example below shows Snort signature used as a
trigger for DDoS prevention mechanism based on the game
theoretic approach.

t=0

P1

P2

P1

t=2
𝐵

P2

P1

P1

𝐵

alert tcp $HOME_NET any -> $HOME_NET 80
(flags: S; msg:"Possible TCP DoS";
flow: stateless; threshold: type both,
track by_src, count 70, seconds 10;
sid:10001;rev:1;)

t=1

t=2

P1
3𝐵

Avg BW = ½ ∗ ( 2 + 2 )

Once Snort triggers the DDoS defense mechanism, the
SDN flow table will be updated to rate limit the traffic from
a particular source to destination in the home network.
𝐵

Avg BW = ½ ∗ ( 4 + 5 )

Figure 2: Extensive form of Dynamic Game

3.

SYSTEM ARCHITECTURE & MODEL

The system architecture as shown in Figure 3 consists of
ODL [9] based SDN platform. The southbound APIs are
used for interacting with data-plane elements. We assume
that the switches for our architecture are Openflow enabled.
These switches interact with the hosts inside or outside the
network. As can be seen, some hosts send normal traffic
to switch while others act as part of a DDoS botnet. The
SDN controller platform consists of several elements such as
topology manager to perform any network topology reconfiguration, network config element to ensure persistence of
the current network configuration.

DDoS
Prevention

Attack Graph
Generator

Attack
Countermeasure
Evaluator

Figure 4: Traffic Rate Limiting in SDN
Figure 4 shows various entries for a given SDN flow table
[1]. The match field is used for matching ingress port and
packet headers. In this example, we have snort alert for IP
Address 192.168.2.1, which has been classified as attacker’s
IP. The Instruction field of flow table is added. The rate
limit decided by the algorithm is set in Rate sub-field of
Band Field in Meter Table. In the Figure 4 Once the period
of punishment decided by the administrator is over for this
particular IP address, the Rate sub-field will be updated to
default traffic burst rate. We use the REST API to push
these values continuously to ODL controller.

Network Services and
Orchestration

Northbound REST API

Snort
IDS

Topology
Manager

4.
Network
Config

SDN Controller Platform

4.1

Southbound REST API
Openflow Enabled
Device

Open vSwitch

IMPLEMENTATION

System setup used and algorithmic details for Nash Folk
theorem based DDoS Prevention are discussed in this section.

Openflow Rate Limiting Algorithm

The Openflow based rate limiting algorithm described
in this section consists of two procedures. One procedure
SET-RATE-LIMIT-METER is used for invoking meter with
specified meterID in the corresponding flow table. By default the meter table is optional for a Flow Table. The
host behaving normally will not face any decreased bandwidth. However, if the host is behaving maliciously and
a trigger event based on Snort IDS alert is used to invoke
meter with ID 1, the Bandwidth would be set to a value decided by the rate limit policy, depending upon cooperation
or defection of malicious host in the current and subsequent
periods. Lines 7-10 depict the preset values of bandwidth
for host i Pi . The procedure NASH-FOLK-RATE-LIMIT
based on the greedy approach loops through all flow tables
in invoking meter with rate limiting threshold if matching
source host is found in the list of malicious hosts from a
Snort IDS (lines 11-17). The procedure of punishment is

Dataplane Elements

Figure 3: System Architecture
The main element from this layer used by us is Snort
IDS [3]. We consider a signature based detection mechanism
to collect and categorize network traffic as malicious or benign. This information is passed on to a network service and
orchestration layers through northbound REST APIs. We
consider three types of DDoS attacks in this work namely,
SYN-Flood Attack, UDP Flood Attack, ICMP Flood At-

55

Algorithm 1 SDN-DDoS-Rate-Limit-Algo
1: procedure Set-Rate-Limit-Meter(meterName, bandID, bandRate)
2:
M eterN ame ← this.meterN ame
3:
mbh ← M eterBuilder.meterBandHeader()
4:
mbh.setBandID(this.bandID)
5:
mbh.setBandRate(this.bandRate)
6: procedure Nash-Folk-Rate-Limit(
)
7:
ui (coop, coop) ← Bc {Host Pi cooperates}
8:
ui (coop, def ) ← {Bcd > Bc } {Host Pi defects}
9:
ui (def, coop)] ← {Bdc < B} {Host Pi defected at
tk−1 }
10:
ui (def, def ) ← {Bdd < Bdc } {Host Pi defected at
tk−1 and tk }
11:
for i ∈ [0,n-1] do
12:
f t ← F lowT ablei
∈
DDoSTrigger(src ip)
13:
if
ft.match.src ip
k
P
t
δ ui (coop, coop)
≤
ui (coop, def ) +
and

Figure 5: Linear Topology in SDN
for DDoS mitigation decreases the traffic rate by a factor δ
consecutively until the long term average for traffic is within
normal traffic burst from a provided host. In this particular
experiment we used the value of damping factor δ = 0.8.
This scheme punishes all the attacking hosts by degrading
traffic throughput gracefully, instead of blocking the traffic
entirely or rate limiting to a fixed value, which can affect
the traffic from legitimate users.

t=0
k
P

t

δ ui (def, {coop, def }) then

t=1

x ← ft.Instruction()
x.SET-RATE-LIMIT-METER(”RLMeter”, 1,
ui (det, coop))
16:
else
17:
x.SET-RATE-LIMIT-METER(”RLMeter”, 1,
ui (det, det))

14:
15:

Number
of Attacking
Hosts
50
100
200
300
400
500

carried out for k instances of time where value of k is dek
P
termined by equation
δ t ui (coop, coop) ≤ ui (coop, def ) +
t=0
k
P

δ ui (def, {coop, def }) in line 13. This linear equation en-

1.33
2.70
5.54
8.122
10.83
15.69

Table 2: Number of Hosts vs ICMP Traffic at T=30s
post attack.

t=1

The table shows that traffic burst at target for 100
hosts is 79.85 Mbps when there is no attack prevention
mechanism to deal with DDoS attack. However, once the
trigger for Rate Limit is set by IDS, the traffic decreases
to 2.70 Mbps, a decrease of factor 30. Similarly, as the
number of attacking hosts increase from 100 to 500, the
throughput of DDoS attack increases from 79.58 Mbps to
467.16 Mbps, which shows a linear scaling in attack traffic.
The Rate Limit (RL) algorithm quickly adapts to increased
traffic and decreased corresponding traffic limit for 500
hosts to a value 15.69 Mbps. On comparing attack traffic
and corresponding rate limited traffic for 500 hosts, we
can observe a decrease by a factor of 29. The experiment
shows a successful countermeasure using a game theoretic
approach of punishing the attacker on a sufficiently large
network.

EVALUATION

We used network simulator [2] and ODL controller on
Ubuntu 16.04 OS. We conducted two experiments in our
evaluation. The first experiment uses the algorithm proposed in Section 4 to deal with ICMP flood attacks. The
second experiment uses the same algorithm for TCP SYN
flood and UDP flood based attacks on a fat tree topology.
The variation in topologies for both experiments is used to
check the generality of our solution.

5.1

39.49
79.85
163.69
241.17
321.96
467.16

ICMP Traffic
post Rate
Limit(Mb/s)

t

sures that defecting host is no better than for case of normal
behavior at end of k periods of punishment.

5.

ICMP Flood
Traffic (Mb/s)

Experiment 1: ICMP Flood DDoS Attack
on Linear Topology

In our first experiment we created a linear topology in
mininet environment with the number of hosts varying from
50 to 500. The topology had a single layer of hosts, all
connected to one switch. An example of linear topology can
be seen in Figure 5.
We created an attack script in python, which uses multiprocessing to spawn shell for each host and send ICMP
traffic of large packet sizes to a single host in the network.
The traffic is port mirrored to a dummy port. The IDS intercepts the attack signature for ICMP flood DDoS attack
and passes information to ODL controller. ODL application

5.2

Experiment 2: TCP/UDP Flood DDoS Attack on Fat Tree Topology

Most of the attacks faced by organizations target some
DNS server to send large burst of TCP or UDP packets to
target host. Also, since data centers follow fat tree topology architecture, we conducted experiment to test our algo-

56

5.3

rithm on a fat tree topology using mininet, with depth=3,
and fanout=3. We used a damping factor δ = 0.9 for this
experiment.

The algorithmic complexity will depend upon the number
of users in the system. In the worst case, all (N number of
users) will behave maliciously. We consider n to be number
of flow tables, and k to be upper bound on time for punishing a particular host. The complexity will be O(N × n × k).
The values n and k will be constant, so we get c = n×k. The
complexity will effectively be O(N ×c) ∼ O(N ). Thus Openflow Rate Limiting Algorithm will have linear time complexity. The algorithm will be very fast with guaranteed termination.

6.

In this experiment the normal allowed limit for TCP and
UDP traffic set by SDN controller was 3.0 Mbps. We ran
TCP SYN Flood DDoS attack on a topology of 64 hosts.
The traffic decay once the rate limiting algorithm based attack countermeasure mechanism is triggered based on IDS
alerts is plotted in red in Figure 7. Initially DDoS traffic
is 157.03 Mbps, which clearly violates the permissible limit.
The SDN controller pushes the flow to deal with this attack,
and the traffic is reduced to 18.11 Mbps at t=10s. The traffic burst reaches a value 3.02 Mbps at t=50s, which is nearly
equal to normal traffic rate allowed on this network.

Attacker’s Bandwidth(Mb/s)

SYN Flood Traffic(Mb/s)
UDP Flood Traffic(Mb/s)

140

100

50
40
30
20
10
0

10

20

30

40

50

RELATED WORK

We analysed several works that either use some intelligent framework to deal with active attacks in SDN or use
some game theoretic model in network security. In [16], authors combine game theory and Machine Learning (ML) to
model attacker’s behavior in ML feature space. This work
uses spam filtering as a target application to provide defense
against current and future attacks. Random host mutation
based on SDN platform has been used by Jafarian et al. [10]
to map real and virtual IP addresses, and make reconnaissance hard for malicious hosts. Chung et al. [8] [7] have
used proactive defense and countermeasure analysis framework in cloud network. The authors have used z Bayesian
framework for attack analysis. Our work is based on Nash
Equilibrium based attack model in dynamic games.
Braga et al. [5] have used pattern recognition based on Self
Organizing Maps (SOM) to filter DoS attack traffic in NOX
based Openflow network. The solution is lightweight compared to earlier works on the DoS attack detection based on
KDD dataset. We have some concerns about the accuracy of
pattern recognition in DDoS attack detection hence we have
relied on signature based detection mechanism. FRESCO
[17] which has been developed on top of NOX based SDN
framework provides modular security to defend against network attacks. Bot Miner service module in FRESCO uses
clustering mechanism to detect bots through network level
flow analysis. Markov game based framework for two player
zero sum game has been discussed by Alpcan et al. [4]. Their
framework used Markov Chain based attack modeling to
send information to IDS, so that the administrator can deal
with active attacks.
Kampanakis et al. [12] have discussed obfuscation as a
possible Moving Target Defense (MTD) strategy to deal
with attacks in SDN environment. Authors have discussed
OS fingerprinting and network reconnaissance as specific
types of attacks in SDN. Random mutations of this nature
may, however disrupt any active services and some costbenefit analysis of MTD strategy is necessary. Another approach based on MTD solution for prevention of DoS attacks on SDN networks has been discussed by [11]. The
authors propose the idea of moving secret proxies to new
network locations using a greedy algorithm. This solution
however is limited to malicious insiders in a network. A scalable attack graph approach to deal with system vulnerability
based multi-hop attack has been discussed by Chowdhary et
al. [6]. The authors use distributed hypergraph partitioning
approach to construct an attack graph for a large system,
however don’t discuss the possible countermeasures to deal
with active attacks such as DDoS, NTP amplification, etc.,
which we discuss as part of this work. In [18] authors use a

Figure 6: Fat Tree topology in SDN

160

Complexity Analysis

60

Time
Figure 7: TCP and UDP Flood Attack Mitigation
on fat tree topology
Similarly, the traffic pattern for a UDP flood attack starts
off around 127.38 Mbps. The rate limit algorithm decreases
this value to 15.12 Mbps at t=10s. Traffic rate is further
reduced to 4.52 Mbps at t=40s. Finally traffic burst reaches
a value 3.01Mbps at t=60s, and algorithm stops further
enforcement of rate limit after t=60s. The IDS waits for
further intrusion alerts at this point to notify the controller
in case, malicious traffic is still sent by attacking hosts. Thus
we can see from this experiment that the algorithm will take
less than one minute to mitigate TCP and UDP based DDoS
attacks on a sufficiently large network.

57

game theoretic framework to deal with attacks against web
applications. This work uses Stackelberg game to model
attack and defense.

7.

[3] Snort IDS, https://www.snort.org/, 2017.
[4] T. Alpcan and T. Basar. An intrusion detection game
with limited observations. In Proceedings of the 12th
Int. Symp. on Dynamic Games and Applications, 2006.
[5] R. Braga, E. Mota, and A. Passito. Lightweight DDoS
flooding attack detection using NOX/OpenFlow. In
Local Computer Networks (LCN), 2010 IEEE 35th
Conference on, pages 408–415. IEEE, 2010.
[6] A. Chowdhary, S. Pisharody, and D. Huang. SDN
based scalable MTD solution in cloud network. In
Proceedings of the 2016 ACM Workshop on Moving
Target Defense, pages 27–36. ACM, 2016.
[7] C.-J. Chung. SDN-based Proactive Defense Mechanism
in a Cloud System. PhD thesis, Arizona State
University, 2015.
[8] C.-J. Chung, P. Khatkar, T. Xing, J. Lee, and
D. Huang. NICE: Network intrusion detection and
countermeasure selection in virtual network systems.
Dependable and Secure Computing, IEEE
Transactions on, 10(4):198–211, 2013.
[9] L. Foundation. Opendaylight SDN controller.
https://www.opendaylight.org/, 2017.
[10] J. H. Jafarian, E. Al-Shaer, and Q. Duan. Openflow
random host mutation: Transparent moving target
defense using software defined networking. In
Proceedings of the first workshop on Hot topics in
software defined networks, pages 127–132. ACM, 2012.
[11] Q. Jia, K. Sun, and A. Stavrou. MOTAG: Moving
target defense against internet denial of service
attacks. In 2013 22nd International Conference on
Computer Communication and Networks (ICCCN),
pages 1–9. IEEE, 2013.
[12] P. Kampanakis, H. Perros, and T. Beyene. SDN-based
solutions for moving target defense network
protection. In World of Wireless, Mobile and
Multimedia Networks (WoWMoM), 2014 IEEE 15th
International Symposium on a, pages 1–6. IEEE, 2014.
[13] D. Kreutz, F. M. Ramos, P. Verissimo, C. E.
Rothenberg, S. Azodolmolky, and S. Uhlig.
Software-defined networking: A comprehensive survey.
proceedings of the IEEE, 103(1):14–76, 2015.
[14] E. Z. Nick Feamster, Jennifer Rexford. The road to
sdn: An intellectual history of programmable
networks. In Proceedings of the ACM SIGCOMM,
pages 87–98. ACM, 2014.
[15] S. Pisharody, A. Chowdhary, and D. Huang. Security
policy checking in distributed SDN based clouds. In
2016 IEEE Conference on Communications and
Network Security (CNS) (IEEE CNS 2016), Oct. 2016.
[16] K. G. Richard Colbaugh. Predictability oriented
defense against adaptive adversaries. In Proceedings of
IEEE International Conference on Systems, Man, and
Cybernetics (SMC), pages 14–17. IEEE, 2012.
[17] S. Shin, P. A. Porras, V. Yegneswaran, M. W. Fong,
G. Gu, and M. Tyson. Fresco: Modular composable
security services for software-defined networks. 2013.
[18] S. G. Vadlamudi, S. Sengupta, S. Kambhampati,
M. Taguinod, Z. Zhao, A. Doupé, and G. Ahn. Moving
target defense for web applications using bayesian
stackelberg games. CoRR, abs/1602.07024, 2016.

CONCLUSIONS

We analyzed a game theoretic framework based on reward and punishment mechanism which is used successfully
in game theoretic modeling. Using a greedy algorithm we
solved an optimization problem for rate limiting network
bandwidth as a punitive mechanism for misbehaving players in a dynamic network game. The optimization algorithm
used in this work, based on Nash Folk theorem, allowed us
to degrade network bandwidth gracefully, without applying a static hard limit on network traffic. Our experimental work targeted DDoS attacks, specifically ICMP Flood,
TCP SYN Flood, UDP Flood. The algorithm is able to
deal with all these attacks based on alerts received from
SDN controller. The framework proposed leveraged benefit of network optimization and programmability offered by
SDN quite well, and the proposed algorithm can adapt well
on varying topologies as demonstrated by Experiments 1
and 2 in Section 5.
We used the damping factor δ to be on higher side
{0.8, 0.9} in this experimental work to put more weight on
future punishment based payoff to the attacker. The normal
bandwidth which we used as a baseline for threshold bandwidth was selected by observing normal TCP, UDP traffic in
a medium sized network for a time duration of about 10-15
minutes. Both these parameters can have an impact on final
results and convergence time of the algorithm. We plan to
study the impact of variation in these two parameters in the
OpenStack based cloud as an extension of this work.
Our motivation in use of a signature based IDS was to deal
with DDoS attacks whose signature can be easily identified.
Most of anomaly detection methods we studied prior to the
experimental setup of this work suffered from the issue false
alarms. We plan to use Artificial Intelligence (AI) based
algorithms to train our system for identified attacks and
use anomaly detection along with signature based detection
mechanism to construct a comprehensive attack mitigation
solution as part of future work.
A limitation of our experimental work is the number of
host subprocess we can spawn using the multiprocessing
thread, which is currently limited to around 500. We plan to
leverage a cloud framework based on OpenStack to deal with
this scalability concern and analyze the impact of algorithm
on dynamic attacks in a real cloud environment.

Acknowledgments
This research is supported by NSF Secure and Resilient Networking (SRN) Project (1528099) and NATO Science for
Peace & Security Multi-Year Project (MD.SFPP 984425).
S. Pisharody is supported by a scholarship from the NSF CyberCorps program (NSF-SFS-1129561). Adel Alshamrani is
supported by King Abdul Aziz University, Jeddah, Saudi
Arabia.

8.

REFERENCES

[1] Openflow switch specification v 1.3.1.
https://www.opennetworking.org/.
[2] Mininet Virtual Network https://www.mininet.org/,
2015.

58

MCC-OSGi: An OSGi-based Mobile Cloud Service
Model
Fatiha Houacine, Samia Bouzefrane

Li Li
Wuhan University
Wuhan, China
lli@whu.edu.cn

Conservatoire National des Arts et Métiers - CNAM
Paris, France
houcin_f@auditeur.cnam.fr, samia.bouzefrane@cnam.fr
Abstract—In this article, a new mobile Cloud service model is
presented. It offers a dynamic and efficient remote access to
information services and resources for mobile devices. Mobile
Cloud computing has been evolved as a distributed service model,
where individual mobile users are Cloud service providers.
Compared to traditional Internet-centric Cloud service models,
the complexity of mobile service management in a dynamic and
distributed service environment is increased dramatically. To
address this challenge, we propose to establish an OSGi-based
mobile Cloud service model – MCC-OSGi – that uses OSGi
Bundles as the basic mobile Cloud service building components.
The proposed solution supports OSGi bundles running on both
mobile devices and Cloud-side virtual machine OS platforms, and
the bundles can be transferred and run on different platforms
without compatibility issues. The presented solution is achieved:
1) by incorporating OSGi into Android software development
platform, 2) by setting up a Remote-OSGi on the Cloud and on
mobile devices, and 3) by defining three service architecture
models. The presented solution is validated through a
demonstrative
application
with
relevant
performance
measurements.
Keywords— OSGi, Service Oriented Architecture, Mobile
Cloud Computing, Android.

I. INTRODUCTION
In recent developments of mobile Cloud computing [1] [2],
a new service-oriented framework is presented to involve
mobile devices as Cloud service providers to offer Cloud-based
sensing services. For example, a mobile device can sense its
surrounding information through various embedded and
connected sensors, such as wireless communication channel
status, neighboring nodes information, environmental
information (e.g., air quality), personal information (e.g.,
medical and health information using bio sensors), etc.
Running mobile applications on a traditional Internet-based
Cloud framework, i.e., running executable binary codes in both
mobile devices and Cloud, the application development
approach is rigid in that the sensing capability and Cloud
offloading operations cannot be easily reused and
reprogrammed by various Cloud-based services. Moreover, the
application development overhead of traditional approaches is
higher than the service oriented approaches.
For example, a mobile device can provide various sensing
services that can be used as a building block for various
purposes without a pre-configuration in a traditional clientserver type of application framework. The provided sensing
services can be called by any services through a service

Dijiang Huang
Arizona State University
Phoenix, USA
dijiang@asu.edu

management framework without even knowing for what the
sensing services will be used. This feature can greatly improve
the reusability of the sensing service and reduce the application
developments overhead tremendously incurred by the
traditional client-server approaches.
To achieve the described mobile application-running
scenarios, service oriented approach is a natural choice to
support mobile Cloud software development and service
provisioning. In this context, Service-oriented Architecture
(SOA) [5, 9] is viewed as a suitable paradigm to guarantee
more control, re-use and reliability of the software. It has
proved to offer flexibility, scalability and reusability, due to the
independency, interoperability and loose coupling of the
services. Most of existing SOA solutions have been
implemented in the enterprise environment. SOA for mobile
applications is still in its infant stage.
In this research, we propose a Mobile Cloud Computing –
OSGi (MCC-OSGi), where each mobile device is considered as
a mobile service provider in the Cloud. MCC-OSGi is
established based on OSGi (Open Services Gateway initiative
[4]) framework and demonstrated on the Android platform that
can offload or compose remote services on the Cloud. The
presented approach provides dynamic OSGi-based class
loading, versioning management, and dynamic bundle
reconfiguration without restarting Android applications. The
main research goal of this paper is to establish an MCC-OSGi
middleware that supports the Java-based services modules (i.e.,
bundles in OSGi terminologies) running on both mobile and
Cloud OS platforms. To this end, we have developed the MCCOSGi by incorporating OSGi into Android software
development platform that interacts with Remote-OSGi on the
Cloud. The main contributions of this research are:
•

The establishment of an OSGi-based SOA architecture in
the mobile Cloud computing environment by integrating
R-OSGi bundles that support services discovery, selection
and deployment of bundles.

•

The integration of OSGi framework into Android mobile
devices so that the MCC-OSGi bundles can run in Java
Running Environment (JRE) without compatibility issues
on both Android based mobile devices and Cloud virtual
machines.

•

The performance evaluation shows that the presented
solution is lightweight and suitable for mobile Cloud
services.

In the following sections, the paper is organized as follows:
Section 2 discusses the related work; Section 3 describes the
overall MCC-OSGi architecture and the models established on
Android platform. In Section 4, three possible MCC-OSGi
service models are presented to deal with heterogeneous
interactions between bytecode-based devices and Dalvik code
devices. We underline distinct service architectures that are
suitable respectively for sensing mobiles devices, Cloud
offloading, or device-to-device communication. To
demonstrate the feasibility of the OSGi based Cloud
architecture, Section 5 presents an application example based
on OSGi and the corresponding performance measurements.
Finally, Section 6 concludes this paper.
II. RELATED WORK
Mobile Cloud Computing [1][3][6][8] has become a novel
computing model that integrates Cloud computing, wireless
communication infrastructures, mobile devices, etc. In a
mobile Cloud computing environment, on one hand, mobile
applications and services on mobile devices have been
augmented by accessing to unlimited computing power and
storage space; while on the other hand, lightweight computing
devices extend Cloud services into the mobile sensing domain.
Previous work has been done on either side, but does not
consider both sides in a comprehensive approach.
Chun et al. [6] proposed an architecture that can distribute
components of an application automatically and dynamically
between a mobile and the Cloud, where cloned replica of the
smartphone’s software is running. Instantiating devices’ replica
in the Cloud is determined based on the cost policies trying to
optimize execution time.
Zhang et al. [7] developed a reference framework for
partitioning a single application into elastic components with
dynamic configuration of execution. The components are
called weblets that can be launched on the mobile or in the
Cloud, depending on the configuration of the application and
the device hardware capabilities. The weblets are implemented
using C# and are accessed using HTTP protocol.
Giurgui et al. [15] developed an application middleware
named AlfredO, to distribute different layers of an application
between the device and the server. AlfredO is based on OSGi
and allows developers to decompose and distribute the
presentational and logic tiers between a mobile device and a
server.
Huerta-Canepa and Lee [10] presented a framework to
create virtual mobile Cloud computing providers. This
framework mimics a traditional Cloud provider using nearby
mobile devices and allows avoiding a connection to an
infrastructure-based Cloud provider while maintaining the
main benefits of offloading. Mobile devices in this ad-hoc
computing Cloud serve as a Cloud computing provider by
exposing their computing resources to other devices so that
they may execute tasks collaboratively. The Hyrax platform
[13] derived from Hadoop supports Cloud computing on
Android smartphones. Hyrax allows client applications to
conveniently utilize data and execute computing jobs on

networks of smartphones and heterogeneous networks of
phones and servers.
In the context of Cloud computing, the OSGi Alliance in
[19] investigates the way to use OSGi for Cloud-based
applications. Schmidt et al. [20] presented OSGi for the Cloud
(OSGi4C), a solution that combines OSGi and P2P overlay
called JXTA. The authors addressed the bundle process
selection issue when several choices are possible. Thanks to a
P2P based mechanism, remote available bundles are detected
and evaluation mechanisms permit a dynamic selection.
Rellermeyer et al. in [14, 16] took advantage of the
concepts developed for centralized module management, such
as dynamic loading and unloading of modules, and showed
how they can be used to support the development and
deployment of distributed applications by integrating R-OSGi
as a plugin within Eclipse IDE.
In [17], the authors outlined a Distributed OSGi (DOSGi)
architecture for sharing electronic health records using public
and private Clouds, which overcomes some of the security
issues inherent in Cloud systems. Research in [18] proposed to
use OSGi as the architecture foundation of a client agent and
use a peer-to-peer infrastructure to provide, share, and load
OSGi bundles at runtime.
Our previous work presented in [22] implemented a
middleware solution that incorporates OSGi into Android
software development platform that builds the service model
for Android-based mobile applications. Compared to the
related works, in this article, we extend the work in [22] and
provide three service architectures between mobile devices and
the Cloud. Unlike the work in [15] in which experimentations
are implemented on Nokia phones that have a compatible Java,
Android platforms used in this paper provide a Dalvik VM that
is incompatible with OSGi Java VM. Hence, one of the issues
addressed in this paper is to incorporate OSGi within Android
mobiles platforms.
III. DESCRIPTION OF MCC-OSGI
In this section, we first introduce the OSGi Framework,
before presenting the global view of the proposed OSGi-based
architecture for mobile Cloud computing, where mobiles are
Android platforms. Then, we discuss how to integrate OSGi
within Android platforms and set up R-OSGi in order to
establish the presented three MCC-OSGi service models.
A. OSGi Framework
OSGi is the acronym of “Open Service Gateway initiative”,
which is a Java development and running platform, based on
modular decoupled components and pluggable dynamic service
models [11]. As OSGi was originally designed for embedded
systems, the framework provides a lightweight and scalable
solution. Based on Java, the OSGi platform offers a portable
and secure execution environment.
OSGi platform consists of an OSGi framework attached to
standard services. The framework offers a service facility,
where a service can be added, removed or updated at any time.

It manages the bundle dependencies and their versions using a
class loader associated with each bundle. Considered as a
deployment unit, a bundle is a Jar file that contains a compiled
code, resources as well as meta-data. The meta-data is stored in
a configuration file called Manifest.mf, which contains all the
information related to the bundle such as the bundle name, the
version, the provider, the required dependencies, the packages,
etc. In particular, the Export-Package entry gives the list of the
services provided by a bundle, i.e., the services that can be
shared with other bundles. Similarly, the Import-Package entry
lists the required bundles. The OSGi framework also provides a
service management system that can be used to register and
share services across the bundles and decouple service
providers from service consumers.
In addition, to allow remote access, R-OSGi is a standard
OSGi bundle proposed in [14] to facilitate distribution of any
OSGi implementation (e.g., Equinox Eclipse, Knopflerfish,
Apache Felix, Concierge, etc.). Using R-OSGi, each service
provider has to register the service provided as a remote
service. The service is accessed through a service caller in a
transparent manner. For each remote service, a proxy bundle is
generated dynamically on the client side (e.g., proxyGenerator
[25]) that propagates the method invocation of the service to
the remote platform.
The research issue to be addressed in this paper is how to
establish a component-based middleware using OSGi in a
mobile Cloud environment while guaranteeing SOA features
such as, modularity and reusability capabilities, versioning
management and dynamic bundle configuration where remote
access is transparent for mobile users.

Figure 1. MCC-OSGi in MobiCloud.

To address this issue, we propose a distributed service
architecture based on OSGi. We implement it in MobiCloud
[1] system that is a Cloud computing that provides Virtual
Machines (VMs) serving for dedicated mobile devices. Each
mobile device interacts with its dedicated VM located in
MobiCloud VM-pool, where the OSGi framework and their
communication is supported by the signaling and
communication service. To address the inter-OSGi framework
signaling and communication issues, MCC-OSGi adopts ROSGi based solution that is used as a communication service
between different OSGi frameworks. We aim, through the
MCC-OSGi architecture, to design a distributed service

interaction while allowing a mobile device sensing for Cloud
purposes, Cloud offloading for mobile devices, or device-todevice service communication. To meet our objective, we
incorporate OSGi within Android application platform that
supports bundle offloading and mobile sensing service
composition.
B. An OSGi-based SOA for Android Platforms
The presented solutions use a component-based software
design concept to implement the service-component model
with SOA features such as dynamic class loading, version
management, and dynamic bundle configuration avoiding the
Android platform to restart when changing service
compositions. In fact, we have developed a middleware to
launch Felix [23] (a compact implementation of OSGi on
Android devices) and to manage the life cycle of bundles that
are used by Android applications. Unlike EZdroid project [21],
our solution does not require the recompilation of the
application during bundle updates and provides administrative
functions using the OSGi platform. Compared to the solution
provided by Wu et al. in [12], where an OSGi-based
architecture for a smart-home environment is established
through common web services, our solution is purely based on
OSGi bundles.
As shown in Figure 1, the access to Felix is based on our
developed middleware called AndroLix [22] that provides
inter-OSGi communication through the Android Interface
Definition Language (AIDL) [24] that provides descriptions
containing different methods that are implemented by this set
of OSGi bundles. The proposed AndroLix middleware allows
the management of bundles’ life cycle, and calls bundles
through the AndroLix AIDL, as shown in Figure 2. The
AndroLix methods that have been implemented are presented
as follows:
•

install(): installs a bundle from a specified location and
returns a unique bundle ID.

•

uninstall (): uninstalls a bundle with a specific ID. If the
Bundle is in a Resolved or Installed state, it is directly
uninstalled. If it is in Active state, it is stopped before
being uninstalled.

•

getBundleId(): returns the bundle ID.

•

startBundle(): starts a bundle after checking the
availability of the bundle ID and the bundle status. The
bundle is started if it is in Installed or Resolved state (i.e.,
the bundle's code dependencies are resolved).

•

stopBundle(): stops a bundle after checking the
availability of the bundle ID and the bundle status. The
bundle is stopped if it is in Active state.

•

getBundlesContainer(): retrieves the symbolic name, the
bundle ID and the status (Installed, Resolved, Active) of all
the bundles present in the bundle container.

•

startFelixFramework(): defines a persistent set of
properties (Felix Framework cache directory, Felix
Framework and Android packages to be loaded, etc.) and

starts the Felix Framework. This method is called when
creating AndroLix Service.
•

install_uninstall(): checks a package dependency of a
bundle at a start-up or a stop of the bundle.

•

Call() : allows a dynamic class-loading of classes to deal
with different services associated with distinct contracts.
By calling the methods of the AndroLix middleware
implemented as an Android service, any Android application is
able to interact with Felix platform and its bundles.
AndoLix allows Android applications to take advantage of
the facilities offered by OSGi such as dynamic bundles update
and version management, but it focuses only on local running
context. In a distributed and highly dynamic environment such
as MobiCloud, the service providers and the consumers can be
physically separated and the services can be remotely invoked.
This introduces additional challenges as those related to the
remote interactions and network limitations due to the
movements of mobile devices. MobiCloud addresses this issue
by providing on demand resources and services in a scalable
way, in which OSGi bundles in the Cloud VM pool can be
instantly deployed and removed within a large set of distributed
nodes.
In the following sub-section, we will describe how to
extend the use of OSGi bundles from the local execution
environment to a distributed MobiCloud environment so that
the mobile Cloud architecture is based entirely on OSGi service
model.

Figure 2. Remote access using OSGi.

IV. MCC-OSGI ARCHITECTURE MODELS
Based on the fact that OSGi framework is integrated within
Android mobile platforms and the inter-connection between
OSGi frameworks is resolved, we have identified three service
architecture models depending on whether the service provider
is the mobile platform or the Cloud.
A. The Android platform as a Service Provider and the Cloud
as a Client.

C. A Remote OSGi-based SOA for Mobile Cloud services
To allow interactions between Android platform bundles
and the Cloud services, we set up R-OSGi on the Cloud side
and we integrated within Android platforms R-OSGi as a proxy
bundle service. Hence, the OSGi bundle is considered as a
Cloud service’s deployment unit. The Cloud provider exports
the services that can be managed in a distributed and
autonomous fashion by the OSGi bundles management system.
A service is set up as a remote service by specifying it with the
following service properties:
service.exported.interfaces, and
service.exported.configs.

The first property determines which service interfaces are
to be exported in a remote manner, using the following method:
props.put ("service.exported.interfaces", "*"); and the second
property used as the first parameter of the following method
specifies how those interfaces can be made remote through the
method:
props.put("service.exported.configs","org.apache.ws");

As shown in Figure 2, the client bundle performs a remote
connection to the service through the R-OSGi bundle that calls
the remote service and checks its existence before starting the
application execution. The service client framework takes care
of importing the remote service by establishing a local proxy
endpoint, which is an instantiation of the R-OSGi bundle, and
connecting it to the remote endpoint.

Figure 3. Android as a SP and the Cloud as a Client.

As illustrated in Figure 3, when the mobile platform acts as
a Service Provider (SP) vis-à-vis the Cloud, the remote clients
are executed on the Cloud. The execution bytecode on the
client side does not need a DEX service adaptation that is
required by the Android platform and only OSGi bundles are
converted to .dex files in order to be executed in the DVM as a
Dalvik code. We have then to add the Dalvik classes of the Jar
file to make it executable on Android platforms. The service
model defined here is suitable for mobile Cloud context where
mobile devices provide sensing services to the Cloud.
B. The Android platform as a Client and the Cloud as a
Service Provider
As shown in Figure 4, the second situation is a little more
complex because when calling a service, the client gets the
interface description of the service in the form of a bytecode.
The client parses it and creates a bundle proxy bytecode that

has to be run on the Android platform. As Android applications
are composed of Dalvik codes, we change the original R-OSGi
bundles and add patches to transform dynamically the Java
bytecode to a Dalvik bytecode based on the following
approaches:

C. Android platforms as both Service Provider and Client.

Figure 5. Each entity is an SP and a Client.

Figure 4. Android as a Client and the Cloud as a Service Provider.

a) Step1: Usually R-OSGi uses the ASM library to
parse bytecode and creates the proxy object. In our case,
we have added the Dalvik classes of the Jar file to make
R-OSGi executable on Android platforms.
b) Step2: As the object created via ASM is always
a bytecode, we have to convert it into a Dalvik code. We
thus add a dexification service that we can integrate as a
bundle in the container or directly in R-OSGi (see Figure
4).
Here is the source code for dexification.
import com.android.dx.command.dexer.Main;
public class DexServiceImpl implements DexService {
public byte[] createDexedJarFromFile(String filename) {
byte[] dexed = Main.createDexJar(filename);
return dexed; }
}

c) Step3: Finally, we have to integrate the
DexService in the R-OSGi creation process. For this
purpose, we need to patch R-OSGi in order to invoke the
dexification service when creating the bundle proxy. This
dexification process has been facilitated thanks to the
development project of [25]. After all these modifications
are performed, the R-OSGi bundle can be executed on
the Android mobile device to access remote services.
The service model described here allows mobile devices to
outsource their computation to the Cloud, by executing services
hosted on the Cloud.

As shown in Figure 5, the R-OSGi bundle patched with the
dexification process is necessary only on the client side.
This model can be used in a device-to-device architecture,
where each mobile device can be a service provider as well
as a service consumer. In addition, MCC-OSGi adopts an
XMPP (Extensible Messaging and Presence Protocol)
based solution, in which an XMPP server is used as a
discovering service between different OSGi devices.
V. PERFORMANCE EVALUATION
In order to test the presented OSGi-based service models
and to evaluate the impact of the implemented middleware in
terms of execution time and memory consumption, we
developed a demonstrative service example established in
MobiCloud, a mobile Cloud computing designed by Arizona
State University [1], and we conducted performance
measurements, as described in the following sections.
A. MCC-OSGi Service example
To illustrate the use of MCC-OSGi remote services hosted
on a Cloud, we developed a service example that runs on Near
Field Communication (NFC) cell phones running Android
Nexus S with respect to the first service model presented in
Section 4. The client side service that reads a word from an
RFID tag must find this word in a dictionary service through a
call to a local bundle. If this dictionary does not exist locally on
the Android cell phone, a remote OSGi service in the Cloud is
called to perform the treatment, allowing an outsourcing
computation.
MobiCloud system provides VMs serving for dedicated
mobile phone users. Each mobile phone with integrated OSGi
framework interacts with its dedicated VM located in
MobiCloud VM pool. We set up Felix on a MobiCloud VM
and installed R-OSGi modules within this VM. R-OSGi
remains accessible via the public Internet URL
http://MobiCloud.asu.edu with the port number 9237 as in
Figure 6.

client and the service provider are hosted on the same
framework or not.
a) Case 1: The client and the provider of the remote
bundle are hosted on the same hardware, and share the same
OSGi framework. Our objective in this part is to show the
performance limits of the mobile devices because of their
resource constraints. The measurements are undertaken on a
Samsung Galaxy Tab mobile phone that uses a 2.2 version of
Android, with Cortex 1.0 GHz processor.

Figure 6. MobiCloud configuration.

As depicted in Figure 7, the mobile side service begins
reading the information from the RFID tag (Sector 1, bloc 0),
then retrieves the word, displays it on the phone screen and
tries to establish a connection with the local OSGi container
service to access to the dictionary. The local container itself
transfers the call to the remote container that processes the
information on the Cloud and returns a result to the mobile
phone.

Figure 8. Felix starting time when increasing the number of bundles.

First, we start Felix on the mobile device and we measure
the starting time when increasing the number of bundles as
depicted in Figure 8. We notice that this time may reach two
seconds if Felix handles up to 30 bundles. Even if this time
seems to be important, Felix is started once when starting the
Android platform.

Figure 7. The application example.

The MCC-OSGi service example that is described here is
used as a basis for the evaluations described in the following
sections.
B. Performance Analysis
In the MobiCloud environment, performance evaluations
are conducted by accessing a benchmark of the MCC-OSGi
components, e.g., on the mobile devices settings, and on the
networks capabilities (Wi-Fi, 3G, etc). In this section we
evaluate the performances of the remote service invocation
regarding our new architecture models. To highlight the benefit
of our proposed solution in terms of performance, we
developed a test case using the previously described service
example and run a set of experiments on it.
1) Execution time: To perform tests on the R-OSGi based
Cloud, two cases are considered depending on whether the

Figure 9. Execution times with bundles variation.

We also measure the execution time of three methods:
Start(), Stop() and Update() to respectively start, stop and
update bundles as in Figure 9. When increasing the number of
bundles, the execution time of the three methods seems to vary
independently of the number of bundles. However, when
increasing the level of dependencies, the execution time of the
methods Start() and Stop() increases linearly with the number
of dependency levels (see Figure 10). A dependency level
corresponds to a bundle that depends on another. In fact, when
a bundle is started, its dependencies are resolved first. In the
same manner, when a bundle is stopped, its dependencies are
freed.

TABLE I. REMOTE BUNDLE INVOCATION.

(without R-OSGi)

Case2: remote
invocation (with ROSGi)

Start bundle

150 ms

185 ms

Stop bundle

45 ms

57 ms

Update bundle

90 ms

95 ms

Action

Case1: Local
invocation

*Average bundle size 13940(bytes)
Figure 10. Execution times with dependencies variation.

Based on the above presented performance evaluations, we
show that the methods that manage the bundles life cycle
depend only on the number of the bundle dependencies for
each bundle.
b) Case 2: The client runs on the Tab mobile phone and
the provider of the remote bundle is hosted on a Cloud, so that
the communication is done through a network access (Wi-Fi
and GRE over Internet).

2) Memory consumption: The consumed memory
obviously depends on the number of local bundles launched
and their size. Since the execution of remote bundles is done
on Cloud provider nodes, the growth of the remote bundles
does not affect linearly the Android memory consumption.
Input-Output performance and network communication
resources are most sensitive to the growth of the number of
remote bundles. Figure 12 shows the resource consumption in
terms of memory consumed on the Galaxy tablet, with local
bundles and remote ones accessed through WiFi.

Figure 12. Memory consuming.

VI. CONCLUSION
Figure 11. Remote bundle invocation.

We observed in this part, the connection establishment and
the remote bundle invocation delays. Figure 11 shows a
significant delay of connection, which is about 1077ms. This
delay is introduced because in addition to establishing the
network connection and dependency resolution, the end point
R-OSGi proxy is created between nodes. By default, Felix
stores all of its persistent state in the Felix-cache directory. This
is shown, in the second iteration of Figure 11, where the
invocation time is significantly reduced, given the parameters
already cached.
Additionally, Table 1 compares the execution time of the
same types of bundles while these bundles are called locally or
remotely from the mobile device. We can conclude from this
table that launching a bundle on a Cloud does not take a
significant execution time.

In this article, we identified in R-OSGi platform an
excellent support for dynamic services invocation on Platform
as a Service (PaaS) mobile Cloud, thanks to the transport
abstraction through OSGi remote services and dependency
management using the OSGi framework capabilities.
We illustrate the use of remote OSGi in Cloud context
within Android platform. Then we explain how OSGi can
considerably improve the Cloud services by optimizing the
remote services invocation. We have shown the performance
evaluations of our approach through an application example
used as a proof-of-concept in heterogeneous support
environment. For future work, we will investigate the security
issues in three main axes:
•

Securing the mobile OSGi clients: by controlling the
remote service invocations in a distributed Cloud context.
Research issues such as service authentication,
authorization, validation, and revocation will be studied.

•

Securing the Cloud providers: from malicious service
invokers, by performing common policies negotiation
mechanisms between the Provider and the Client of the
remote services, (e.g., encryption parameters, MobiCloud
service authentication, etc.).

•

We have only mentioned the signaling and communication
service based on XMPP service briefly in this article. We
will follow SOA features for MobiCloud such as service
publishing, discovery, dynamic composition, and
revocation in future work.
We also aim to extend the OSGi based MobiCloud to
multiple distributed Cloud service sites to perform scalable and
performing evaluation of our distributed service interaction
mechanisms.
ACKNOWLEDGMENT
The research of Dijiang Huang of this research is sponsored
by ONR YIP award and NSF grant DUE-0942453, CNS1029546, and HP Innovation Research Program (IRP).
REFERENCES
[1] D. Huang, X. Zhang, M. Kang, and J. Luo, MobiCloud:
Building Secure Mobile Cloud Framework for Mobile
Computing and Communication. In Proceedings of the 5th IEEE
International Symposium on Service-Oriented System
Engineering (SOSE), pp. 27-34, 2010.
[2]

X. Li, H. Zhang and Y. Zhang, Deploying Mobile Computation
in Cloud Service , Lecture Notes in Computer Science, Vol.
5931, Cloud Computing, pp. 301-311, 2009.

[3] M. Satyanarayanan, P. Bahl, R. C´aceres, and N. Davies, The
Case for VM-Based Cloudlets in Mobile Computing, IEEE
Pervasive Computing, vol. 8, no. 4, pp. 14–23, Oct. 2009.
[4] OSGi: http://www.OSGi.org/Specifications/HomePage
[5] D. Thanh, I. Jorstad, A Service-Oriented Architecture
Framework for Mobile Services, In Proceedings of the
Advanced
Industrial
Conference
on
Telecommunications/Service Assurance with Partial and
Intermittent
Resources
Conference/E-Learning
on
Telecommunications Workshop, pp. 65 – 70, 2005.
[6] B. G. Chun, S. Ihm, P. Maniatis, M. Naik, and A. Patti.
CloneCloud: Elastic execution between mobile device and
Cloud. In Proceedings of the sixth conference on Computer
systems, pp. 301–314. ACM, 2011.
[7] X. Zhang, S. Jeong, A. Kunjithapatham, and Simon Gibbs,
Towards an Elastic Application Model for Augmenting
Computing Capabilities of Mobile Platforms, In Proceedings of
The Third International ICST Conference on MOBILe Wireless
MiddleWARE, Operating Systems, and Applications, Chicago,
IL, USA, pp. 161-174, 2010.
[8] E. Cuervo, A. Balasubramanian, D.-k. Cho, A. Wolman, S.
Saroiu, R. Chandra, and P. Bahl, MAUI: Making Smartphones
Last Longer with Code Offload, in Proceedings of the 8th
international conference on Mobile systems, applications, and
services (ACM MobiSys ’10). San Francisco, CA, USA: ACM,
pp. 49–62, 2010.
[9] Y. Natchetoi, V. Kaufman, and A. Shapiro, Service-Oriented
Architecture for Mobile Applications, In Proceedings of the 1st

international workshop on Software architectures and mobility
(SAM '08), pp. 27-32, 2008.
[10] G. Huerta-Canepa and D. Lee, A Virtual Cloud Computing
Provider for Mobile Devices, In Proceedings of the 1st ACM
Workshop on Mobile Cloud Computing & Services Social
Networks and Beyond (MCS ’10). San Francisco, CA, USA:
ACM, pp. 1–5, 2010.
[11] OSGi in Depth, Alexandre de Castro Alves, Manning
Publications Editor, Dec. 2011, 325 pages, ISBN 193518217X,
9781935182177.
[12] C. Wu, C. Liao, and L. Fu, Service-oriented smart-home
architecture based on OSGi and mobile-agent technology, IEEE
Transactions on Systems, Man, and Cybernetics, Part C,
Applications and Reviews, vol. 37, no. 2, pp. 193–205, Mar.
2007.
[13] E. E. Marinelli, Hyrax: Cloud Computing on Mobile Devices
using MapReduce, Master Thesis, Carnegie Mellon University,
2009.
[14] J. S. Rellermeyer, G. Alonso, and T. Roscoe. R-OSGi:
Distributed Applications Through Software Modularization. In
R. Cerqueira and R. H. Campbell (eds.), Middleware ’07,
LNCS? Vol. 4834, pp.1-20, Springer, Heidelberg, 2007.
[15] I. Giurgiu, O. Riva, D. Juric, I. Krivulev, and G. Alonso,
“Calling the Cloud: Enabling Mobile Phones as Interfaces to
Cloud Applications,” J.M. Bacon and B.F. Cooper (Eds.),
Middleware 2009, LNCS 5896, pp. 83-102, 2009.
[16] J. S. Rellermeyer, G. Alonso, T. Roscoe: Building, Deploying,
and Monitoring Distributed Applications with Eclipse and ROSGi. In: Fifth Eclipse Technology eXchange (ETX) Workshop
(in conjunction with OOPSLA 2007), Montreal, Canada, pp. 5054, Octerber, 2007.
[17] S. Mohammed, D. Servos, J. Fiaidhi, Developing a secure
distributed OSGi Cloud computing infrastructure for sharing
health records , In Autonomous and Intelligent Systems Lecture
Notes in Computer Science, Vol. 6752/2011, pp.241-252, 2011.
[18] C. Hang and C. Can, Research and Application of Distributed
OSGi for Cloud Computing, In Proceedings of International
Conference
on
Computational Intelligence and Software Engineering (CiSE),
pp.1-5, Wuhan, China, dec. 2010.
[19] http://www.OSGi.org/wiki/uploads/Design/rfp-0133Cloud_Computing.pdf
[20] H. Schmidt, J. Elsholz, V. Nikolov, F. J. Hauck, R. Kapitza,
OSGi4C: enabling OSGi for the Cloud”, In Proceedings of the
Fourth International Conference on COMmunication System
softWAre and middleware (COMSWARE’09, pp. 15:1 - 15:12,
Dublin, June 2009.
[21] EZdroit project : http://www.ezdroid.com/.
[22] S. Bouzefrane, D. Huang and P. Paradinas, An OSGi-based
Service Oriented Architecture for Android Software
Development Platforms, In Proceedings of 23rd International
Conf. on Systems and Software Engineering and their
Applications (ICSSEA’2011), pp. 1-10, Paris, Nov. 2011.
[23] http://felix.apache.org/site/index.html
[24] http://developer.android.com/guide/components/aidl.html
[25] Temat project http://OSGi-at-android.wikidot.com/start

MTD 2015: Second ACM Workshop on Moving Target
Defense
1

George Cybenko1 and Dijiang Huang2

Dartmouth College, USA; 2Arizona State University, USA
george.cybenko@dartmouth.edu, dijiang.huang@asu.edu
submissions on original research in the broad area of MTD, with
possible topics such as those listed below. Since MTD research is
still in its nascent stage, the list should only be used as a
reference. We welcome all works that fall under the broad scope
of moving target defense, including research that shows negative
results. Below are examples of appropriate topics for MTD 2015:

ABSTRACT
The second ACM workshop on cloud data management is held in
Denver, Colorado, USA on October 12, 2015 and co-located with
the ACM 22nd Conference on Computer and Communications
Security (CCS). The main idea of moving-target defense (MTD)
is to impose an asymmetric disadvantage on attackers by making
systems dynamic and therefore harder to explore and predict. This
workshop seeks to bring together researchers from academia,
government, and industry to report on the latest research efforts
on moving-target defense, and to have productive discussion and
constructive debate on this topic. We have constructed an exciting
program of 12 referred papers and two invited keynote talks that
will give participants a comprehensive view of emerging research.



Categories and Subject Descriptors
A. General Literature



General Terms
Security, Design

Keywords
Moving Target Defense, Security metrics, Cybersecuriy




1. INTRODUCTION
The static nature of current computing systems has made them
easy to attack and harder to defend. Adversaries have an
asymmetric advantage in that they have the time to study a
system, identify its vulnerabilities, and choose the time and place
of attack to gain the maximum benefit. The idea of moving-target
defense (MTD) is to impose the same asymmetric disadvantage
on attackers by making systems dynamic and therefore harder to
explore and predict. With a constantly changing system and its
ever adapting attack surface, attackers will have to deal with a
great deal of uncertainty just like defenders do today. The
ultimate goal of MTD is to increase the attacker's workload so as
to level the cybersecurity playing field for both defenders and
attackers - hopefully even tilting it in favor of the defender.

MTD Techniques
o System randomization
o Artificial diversity and system diversification
o Bio-inspired MTDs
o Dynamic network configuration
o Cloud-based and Large-scale MTDs (using multiple
techniques)
o Autonomous technologies for MTD
o Dynamic compilation
o Moving targets in software coding, application APIs
and virtualization
MTD Modeling and Analysis
o Analytical models for MTDs
o Quantitative models and effective measurement of
MTDs
o Theoretic study on modeling trade-offs of using MTD
approaches
o Control and game theory aspects of deploying MTDs
Human, social, and psychology aspects of MTD
Other related MTD areas

3. WORKSHOP OBJECTIVE
This workshop seeks to bring together researchers from academia,
government, and industry to report on the latest research efforts
on moving-target defense, and to have productive discussion and
constructive debate on this topic. It also seeks to bring together
researchers and practitioners from diverse research fields:
computer systems, networking, software, modeling, and
evaluation, etc. to maximize security performance and reduce the
implementation cost.
Security is one of the most important research areas. Even though
increasing research interests are focused in this area, people still
need a forum to exchange their ideas and results in the emerging
research area such as MTD. This workshop aims to provide such a
forum. This workshop also aims to reflect top research progress in
the attach countermeasure area.

2. SCOPE
The theme of the MTD’2015 is to address the challenges of
effective defense in a dynamic changing environment. We solicit
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full
citation on the first page. Copyrights for third-party components of this work must
be honored. For all other uses, contact the Owner/Author. Copyright is held by the
owner/author(s).
CCS'15, October 12–16, 2015, Denver, Colorado, USA.
ACM 978-1-4503-3832-5/15/10.
DOI: http://dx.doi.org/10.1145/2810103.2812623

4. WORKSHOP PROGRAM FORMAT
The workshop is a one-day workshop. We have invited two
keynotes, in which Michael Franz from University of California
Irvine (UCI) will talk about software code diversity to counter
attacks, and Hamed Okhravi from MIT Lincoln laboratory will
talk about how to evaluate the effectiveness, benefits, and

1709

Hasan Cam (US Army Research Laboratory, USA)
Marco Carvalho (Florida Institute of Technology, USA)
Scott DeLoach (Kansas State University, USA)
Yuval Elovici (Ben-Gurion University of the Negev, Israel)
Rob Erbacher (US Army Research Laboratory, USA)
Michael Franz (University of California, Irvine, USA)
Robert Gray (BAE Systems)
Jason Hamlet (Sandia National Laboratories, USA)
Sushil Jajodia (George Mason University, USA)
Myong Kang (US Naval Research Laboratory, USA)
Angelos Keromytis (Columbia University, USA)
Christopher Lamb (Sandia National Laboratories, USA)
Jason Li (Intelligent Automation, Inc. (IAI), USA)
Peng Liu (Penn State University, USA)
Tom Longstaff (John Hopkins University, USA)
Lisa Marvel (US Army Research Laboratory, USA)
Patrick McDaniel (Penn State University, USA)
Prasant Mohapatra (University of California, Davis, USA)
Sanjai Narain (Applied Communication Sciences)
Hamed Okhravi (MIT Lincoln Laboratory, USA)
Xinming Ou (Kansas State University, USA)
Radha Poovendran (University of Washington, USA)
Kui Ren (University at Buffalo, USA)
Kun Sun (College of William and Mary, USA)
Vipin Swarup (MITRE, USA)
Jason Syversen (Siege Technologies)
Cliff Wang (Army Research Office, USA)
Additional reviewers:
George Argyros, Alexandru G Bardas, Pinyao Guo, Jon
Kirsch, Damien Octeau, Theofilos Petsios, Luan Pham,
Marios Pomonis, Eric Vandenberg, Sridhar Venkatesan,
Robert Walls, Jun Xu

weakness of moving target techniques. We also accept eight
regular research papers and four short research papers to be
presented in the workshop. The presentations will be grouped
based on topics.
Ample time for discussion and networking has been allocated
during breaks and lunchtime. Moreover, the speakers are
encouraged to leave enough time after their presentations for
questions and discussion.

5. CONCLUSIONS
MTD presents many challenges, including problems of
intrusiveness to existing services, balance between security
strength and efficiency, effective evaluation models, general
MTD framework, and other issues. Other issues such as
deployment cost and usability studies are also important. The
MTD workshop provides a forum for researchers and practitioners
to exchange ideas and progress in moving target defense. We
have constructed an exciting program of refereed papers and
invited talks that will give participants a comprehensive overview
of emerging research in this exciting area.

6. WORKSHOP ORGANIZERS
PC Chairs:
George Cybenko (Dartmouth College, USA)
Dijiang Huang (Arizona State University, USA)
Steering Committee:
George Cybenko (Dartmouth College, USA)
Dijiang Huang (Arizona State University, USA)
Sushil Jajodia (George Mason University, USA)
Hamed Okhravi (MIT, Lincoln Lab, USA)
Xinming Ou (Kansas State University, USA)
Kun Sun (College of William and Mary, USA)
Publicity Chair:
Massimiliano Albanese (George Mason University, USA)
Web Chair
Sandeep Pisharody (Arizona State University, USA)

8. TPC Members and Reviewers
We would like to thank all authors who submitted contributions
and the program committee members and additional reviewers for
their excellent work to review the papers. We also thank the
publicity chair to distribute the CFP to various forum and mailing
lists. We thank the web chair to setup the workshop website and
establish the review system. The steering committee also provided
useful suggestions to make the workshop running smoothly.
Finally, we are very grateful for the invited keynote speakers for
accepting our invitations and their presentations in the workshop.

7. TPC Members and Reviewers
Program Committee:
Gail-Joon Ahn (Arizona State University, USA)
Ehab Al-Shaer (University of North Carolina, Charlotte,
USA)
Massimiliano Albanese (George Mason University, USA)

1710

Computer Networks 63 (2014) 128–146

Contents lists available at ScienceDirect

Computer Networks
journal homepage: www.elsevier.com/locate/comnet

SeRViTR: A framework, implementation, and a testbed for a
trustworthy future Internet
Shingo Ata a, Dijiang Huang b, Xuan Liu c, Akira Wada a, Tianyi Xing a, Parikshit Juluri c,
Chun-Jen Chung b, Yasuhiro Sato d, Deep Medhi c,e,⇑
a

Graduate School of Engineering, Osaka City University, Osaka, Japan
School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA
c
Department of Computer Science and Electrical Engineering, University of Missouri–Kansas City, Kansas City, MO, USA
d
Faculty of Maritime Safety Technology, Japan Coast Guard Academy, Kure, Japan
e
Department of Computer Science and Engineering, Indian Institute of Technology–Guwahati, Guwahati, India
b

a r t i c l e

i n f o

Article history:
Received 11 December 2012
Received in revised form 21 November 2013
Accepted 26 December 2013
Available online 3 January 2014
Keywords:
Future internet
Internet trustworthiness
Architecture
Prototype
Geo-distributed networks
Network virtualization

a b s t r a c t
A ﬂexible, scalable, and robust framework that enables ﬁne-grained ﬂow control under
ﬁxed or dynamic policies while addressing trustworthiness as a built-in network level
functionality is a desirable goal of the future Internet. Furthermore, the level of trustworthiness may possibly be different from one network to another. It is also desirable to provide user-centric or service-centric routing capabilities to achieve service-oriented trafﬁc
controls as well as trust and policy management for security. Addressing these aspects,
we present the SeRViTR (Secure and Resilient Virtual Trust Routing) framework. In particular, we discuss the goal and scope of SeRViTR, its implementation details, and a testbed
that enables us to demonstrate SeRViTR. We have designed protocols and mechanisms
for policy and trust management for SeRViTR and show a validation on the functional
implementation of several SeRViTR components to illustrate virtual domains and trust
level changes between virtual domains that are achieved under SeRViTR protocols. Going
from implementation to testbed, we demonstrate SeRViTR in a virtual network provisioning infrastructure called the Geo-distributed Programmable Layer-2 Networking Environment (G-PLaNE) that connects three institutions spanning the US and Japan.
Ó 2014 Elsevier B.V. All rights reserved.

1. Introduction
An important factor that has led to the success of the
current Internet is its ﬂexible routing functionality. However, with the rapid growth of the Internet, many issues
have risen. One area of interest is trustworthiness, especially at the architectural level. For instance, the current

⇑ Corresponding author at: University of Missouri–Kansas City, Kansas
City, MO, USA. Tel.: +1 816 235 2006.
E-mail addresses: ata@info.eng.osaka-cu.ac.jp (S. Ata), dijiang.huang@
asu.edu (D. Huang), Xuan.Liu@umkc.edu (X. Liu), wada@n.info.eng.
osaka-cu.ac.jp (A. Wada), tianyi.xing@asu.edu (T. Xing), pjuluri@mail.
umkc.edu (P. Juluri), cchung20@asu.edu (C.-J. Chung), sato@jcga.ac.jp
(Y. Sato), dmedhi@umkc.edu (D. Medhi).
1389-1286/$ - see front matter Ó 2014 Elsevier B.V. All rights reserved.
http://dx.doi.org/10.1016/j.bjp.2013.12.028

Internet has a limited capability on trustworthiness at the
network layer level. For example, a secure tunnel (e.g., IPSec [29,30]) at the network layer can be established to exchange information, or access control lists that are used for
ﬁltering trafﬁc from unreliable networks by adding network preﬁxes to their blacklist. An approach such as IPSec
is a point-to-point approach, rather than being a networkwide holistic architectural solution. From a routing
standpoint, the current Internet provides a simple and network-centric packet forwarding function by only referring
to the destination address of the packet where packets are
forwarded in the shortest-path manner. However, in the
future Internet, it is strongly desirable to have user- or service-centric routing capabilities to achieve service-oriented trafﬁc controls. Additionally, in the future Internet,

S. Ata et al. / Computer Networks 63 (2014) 128–146

to handle various network services’ ﬂexibilities and
dynamics, routing will be required to be more ﬂexible
and have ﬁne-grained ﬂow controls based on a policy
while addressing trustworthiness.
Current routing policies provide a functionality on limiting trafﬁc to control what may be allowed. Border Gateway Protocol (BGP) made policy decisions at the AS level
so that the AS has the control on redistributing routing
information. Another protocol called Inter-Domain Routing
Protocol (IDRP) [32] supports access restriction through
policies to deny particular trafﬁc transitions. Both BGP
and IDRP use path-vector routing, while Inter-Domain Policy Routing (IDPR) [44,43] uses link-state routing to distribute routing policies over managed domains. Here, the
managed domains refer to any collection of contiguous networks [34] including gateways, links, and hosts whose intra-domain routing manner and service restrictions are
controlled by a single administrator. IDPR aims to enforce
policies to direct trafﬁc under the users’ service requirements, such as bandwidth, acceptable latency, and the
paths to avoid. Although those routing policies can provide
network resources respecting users’ requirements or restrict trafﬁc to some certain path, a more standard and rigorous access control framework at the edges of a routing
domain is needed to ensure that the trafﬁc could be
trusted.
Policy-based management on the routing framework
that provides secure routing is a signiﬁcant plus on realizing trustworthiness in a virtualized network environment.
Having security and trust speciﬁcation policies enforces access control at the domain level to ﬁlter out anomaly trafﬁc
so that more secure and better services can be guaranteed
from the users’ perspective. An adaptive policy-based routing management framework is able to select a managed
domain with a proper trust level to direct transit trafﬁc
by reviewing the historical behavior of the trafﬁc and the
users’ service requirements. Note that the trafﬁc behavior
refers to the impact on the network performance.
Thus, a ﬂexible, scalable, and robust routing framework
that enables ﬁne-grained ﬂow control under ﬁxed or dynamic policies while addressing trustworthiness is a desirable goal. Furthermore, the level of trustworthiness may
possibly be different from one network to another, which
is also important to allow coexistence. To support ﬂexible
trafﬁc control according to various service or user requirements, diversiﬁcation of routing functionality is also desirable. For this, the network should have virtualization and
slicing capabilities according to control policies (for example, for trustworthiness) in place, but that may change
dynamically. Delivery of critical trafﬁc in a secure manner
by using an isolated slice from other trafﬁc and which is
controlled independently should be possible. In addition,
the integrated routing framework should support both
user- or service-centric trafﬁc controls and provide secured
communication with differentiated security requirements.
These need to also warrant that the network programmability is a desirable functionality.
Considering the above needs, we present the SeRViTR
(Secure and Resilient Virtual Trust Routing) approach. This
comprehensive paper is built on our earlier conference and
workshop papers [27,33,49]. SeRViTR encompasses three

129

aspects: (1) a framework for a future secure Internet that
addresses trustworthiness at the network level, (2) a discussion on how this is implemented, and (3) a geo-distributed testbed that connects three universities between the
US and Japan where this functionality is being tested. The
core framework builds on the notion of a Virtual Trusted
Routing and Provisioning Domain (VTRouPD) concept, at
both the network level and the service level. A VTRouPD
is constructed by a collection of networking resources
including routers and switches based on virtualization
techniques. Within one or spanning multiple VTRouPDs,
we can further create user-centric virtual routing domains
that are denoted as lVTRouPDs.
The paper is organized as follows. We ﬁrst describe related works in Section 2. We present the scope and the goal
of SeRViTR in Section 3. Our design model of SeRViTR with
descriptions on detailed operations of key components is
presented in Section 4 and Section 5. We next discuss the
geo-distributed programmable Layer-2 network environment for the SeRViTR experiment deployment in Section 6
and Section 7. In Section 8, we will brieﬂy introduce the
next phase on improving SeRViTR features. We conclude
this paper with future research topics in Section 9.

2. Related work
Research on the future Internet has been active for
years. There are several projects exploring the future Internet infrastructure to provide a large scale programmable
networking testbed. GENI [18,46], Global Environment for
Network Innovations, is a program exploring the future
global networking infrastructure in the United States,
where different types of resource provisioning platforms
resides. GENI platforms such as PlanetLab [6], ProtoGENI
[7], and OpenFlow Networks [35] have different concentrations in terms of provisioning resources, network architecture, programmable networks, and so on. For example,
ProtoGENI has integrated a large group of resources available from the world to provide resources with network
programmability and sensing features. All GENI-related
projects [19,20,39,42,17,45,36] are summarized in Table 1.
In particular, DETERLab [17] is a public Emulab-based cyber security research testbed, which supports trafﬁc generation, attack generation, and data analysis capabilities
[41]; whereas, Seattle [20] has an efﬁcient design that
can easily make spare nodes join their available resource
pool to be further utilized to provide Python based
experiments.
In Europe, FIRE [2] program is an initiative on the Future Internet architecture design. OneLab [4] is a GENI-like
testbed that supports research on the future Internet, as
well as the federation between networking research testbeds, in order to establish the international relationship
with the future Internet researches in other countries
around the world. It is known that GENI has deployed
large-scale OpenFlow Networks in the US, and OFELIA
[3,25] is the ﬁrst large-scale programmable OpenFlow Network research environment in Europe. It supports network
virtualization capability, new controller testing and customization. Another related effort is Bonﬁre [1].

130

S. Ata et al. / Computer Networks 63 (2014) 128–146

Table 1
Comparison table of GENI projects.
Project

Major resource

Programmable
networks

Extension
simplicity

Security

PlanetLab [6]
ProtoGENI [7]
OpenFlow Networks [35]
GENICloud [19]
OFELIA [3,25]
Seattle
DETERlab [17]

Fedora VM
PC and VM
OF Switch
Physical node
Physical node
Experimenter Software
PC

No
Yes
Yes
No
No
No
Yes

Difﬁcult
Difﬁcult
DD
NA
NA
Easy
NA

Access Control (PKI)
Access Control (PKI)
Transport Layer Security

GpENI [45,36]

Fedora VM

Yes

DD

Set proper operation mode for different
threaten level of security experiments; ABAC
Access Control (PKI)

DD: Dedicated Device, NA: Not Allowed, PKI: Public Key Infrastructure, ABAC: Attribute Based Access Control.

Network virtualization has been actively involved in the
future Internet research for several years. A recent survey
[23] states network virtualization may occur at four different layers: the physical layer, link layer, network layer, and
application layer. For example, PlanetLab [6] is an application-layer virtualization, whereas VINI [10] and VNET [11]
are network and link-layer virtualizations, respectively. In
[22], a customized VINI framework for network virtualization in GpENI [45,36] has been presented. With virtualization techniques, various new services arise such as
network management and resource management. A programmable hardware platform to construct virtual data
planes that focus on hardware implementation can be
found in [15]. VROOM [47] (Virtual ROuters On the Move)
is a recent network management primitive that avoids
unnecessary changes to the logical topology by allowing
(virtual) routers to freely move from one physical node
to another. The work presented in [28] focuses on the
accountability in a virtualized hosting environment. [37]
introduces a policy-based resource management function
into a virtual network environment based on a two-phase
resource distributive model. Ref. [21] is an early work on
trust/admission control in software-deﬁned networks.
3. SeRViTR: The goal and the scope
SeRViTR address an architectural approach with a builtin trustworthy network level functionality. While there
have been a number of approaches on testbed and new
architecture for the future Internet as highlighted in Section 2, there is none that addresses this scope. As we brieﬂy
discussed in the Introduction, an approach such as IPSec is
not an architectural solution; it only provides a tunnel level functionality for encrypted information if viewed from
an architectural perspective.
Fundamentally, if we wish to think about whether a
unit of information is trustworthy, we can go to the packet
level, which serves as the atomic unit of communication.
At the packet level, an elementary sanity check can be performed such as through the checksum function. On the
other hand, trying to do a check on each packet that enters
a router to see whether it is trustworthy (analogous to
checksum checking) is not a pragmatic choice due to the
high packet processing cost for checking trustworthiness;
in addition, there are additional systems functionalities
needed if we have to push different trustworthy levels to

all routers much like a routing protocol does in pushing
routing table information to the routers. This then raises
the issue of how and where we can fundamentally inject
trustworthiness. Certainly, another possible place is at
the ﬂow level on a ﬂow by ﬂow basis. This is still not a
complete architectural solution as this is not being addressed at the network level. Thus, we propose to build
trustworthiness at the network level where different networks (both physical or virtual) may have different levels
of trustworthiness. Note that this may, in turn, force some
ﬂow level functionality but not the other way around.
Using this basic premise, we set out to design SeRViTR.
To brieﬂy summarize, our goal is to ﬁrst build multiple
virtualized routing domains through a comprehensive approach by using logical virtual routers to partition the
physical networking environment into multiple virtual
networks while having trustworthiness as an intrinsic
property. Second, we aim to provide a secure inter/intrarouting domain that ensures safe end-to-end services.
Therefore, we provide a ﬁne-grained virtualization for
user-centric networking services by allowing to set security policies. Third, we design a mechanism to dynamically
negotiate trust levels between domains so that it is possible to differentiate applications or services behaving
abnormally. We discuss how these aspects come together
as a framework and are implemented in our SeRViTR approach. We also present G-PLaNE, consisting of multiple
clusters that are geographically distributed, and serves as
the testbed platform for SeRViTR. As a proof of concept
testbed, we have been able to create a Layer-2 virtualization among multiple virtual domains and across geo-distributed clusters to achieve intra and inter-domain
communications in the SeRViTR framework by using the
OpenFlow switch and XEN.
To further elaborate, trustworthiness is a fundamental
architectural requirement in SeRViTR. We posit that trustworthiness is needed to be realized for a trustable future
Internet as the needs and the requirements may vary based
on different viewpoints from end users, to network operators, or to service providers. Consider the following:
 From the viewpoint of users, trustworthiness of communication is based on the degree to which users can trust
a communication peer. Generally, trustworthiness is
often related to the importance of the information to
be communicated. For example, none of the end users

131

S. Ata et al. / Computer Networks 63 (2014) 128–146

may like a situation where their private information is
delivered over the untrusted network. To achieve this,
the network should be isolated based on the degree of
trustworthiness, and the communications in the lower
trustworthiness network should be more restricted.
 From the viewpoint of the network, trustworthiness of
the network is determined by the condition in which
routing in the network is secured and safe. That is,
any routing information (e.g., routing table exchanges,
signaling trafﬁc, MIB) must be conﬁdential, secured,
and protected.
 From the viewpoint of service providers, trustworthiness
of services is a situation where the service is protected,
secured, and exclusive of anonymous users. Not only
users but also the paths to users, might need to be managed by a service provider.
To realize the above stated diverse needs in regard to
trustworthiness, adding a special routing layer is not sufﬁcient. A network should have the capability to be sliced,
isolated from other networks, managed by an integrated
security policy, and have a secure routing protocol along
with ﬂexible trafﬁc engineering. Our aim with SeRViTR is
to present a proof-of-concept model to achieve these goals
and to demonstrate it through a testbed.

4. SeRViTR: Overview, models, and speciﬁcation
The SeRviTR framework is designed on the conceptual
model presented in Fig. 1, in order to realize the Virtual
Trust Routing and Provisioning Domain (VTRouPD) and construct user-centric VTRouPD as so-called lVTRouPD. In
this section, we ﬁrst introduce the conceptual model of
the VTRouPD and the lVTRouPD, and then we describe
the SeRViTR framework design to achieve a trusted routing
procedure in a virtualized routing environment.

4.1. VTRouPD conceptual model
The entire network can be divided into multiple routing/provisioning domains, and we refer to every such domain as a Virtual Trust Routing and Provisioning Domain
(VTRouPD). Fig. 1 presents a conceptual model design on
the VTRouPD. In each VTRouPD, we refer to routers or
switches as a generic Routing Service Node (RSN), which
can host one more multiple Router Instances residing in different user-centric routing domains. A Node Manager (NM)
is responsible for managing the Router Instances’ loading
and unloading in the RSN.
For a trustable environment, Trust Management Service
is the trust authority for the system. It handles the cryptographic key and the parameters’ distribution and revocation. It also provides identity search and federation
services for RSNs within different administrative domains,
as well as policy checking and enforcement functions to
provide a uniﬁed trust management system. The Resource
and Application Manager (RAM) is the resource manager directed by the VTRouPD manager and TMS to construct
VTRouPDs. Furthermore, from a system’s perspective,
trafﬁc management and network resource management
components are necessary for monitoring and managing
a network. Thus, we add two more components when
designing the SeRViTR framework, which are Flow Controller and Trafﬁc Monitor. We will discuss SeRViTR components in detail in the next subsection.

4.2. VTRouPD and

lVTRouPD

To establish VTRouPDs, we require network routers to
be programmable, i.e., we should be able to create multiple
virtual routers on the same physical router, and each virtual router is responsible for a particular virtual domain.
We consider two levels of approaches to deploy the virtual

Content-awareness risk management/Intrusion detection and response.
Isolation: resource, information flow, services, software, and applications
Mobile routing: provide a reliable and survivable automatic routing platform for future trustworthy
network routing.

Routing Services Provisioning
RSN

RSN

RSN

RSN

NM

NM

NM

NM

Trust
Management
Service (TMS)

VTRouPD i
VTRouPD j
VTRouPD k

Virtualization
Resource/Application
Manager (RAM)

Programmable
Router

Network Router Cloud

Virtual Trust
Routing and
Provisioning
Domain
(VTRouPD)
Manager

Notation:
RSN: Routing Service Node
Direct link or control
Indirect link or control

Fig. 1. SeRViTR: The conceptual view.

132

S. Ata et al. / Computer Networks 63 (2014) 128–146

routers. At the ﬁrst level, we create independent virtual
router images, where each virtual router has its own protocol stack and independent IP addresses associated with virtualized interfaces. In this way, trafﬁc can be differentiated
at the IP layer through routing functions. For example, the
routing table in each virtual router can mark the next hop.
However, there is a certain roadblock since the router’s
hardware conﬁguration restricts the number of virtual routers on each router. This restriction usually makes it
impractical to support a large number of virtual routers
running on the same router that further restricts the number of supported virtual domains. Second, it is difﬁcult to
allow inter-VTRouPDs trafﬁc when services provided by
two VTRouPDs are highly correlated and may need to
merge partial trafﬁc from two VTRouPDs. Thus, the approach using the entire routing function virtualization is
only appropriate for network-centric virtualization.
To address the restriction of network-centric routing
virtualization, we introduce a ﬁne-grained routing virtualization at the second level that can take care of the users’
service level demands. To this end, a complementary concept, virtual trust routing and provisioning sub-domain
(noted as lVTRouPD) is introduced. A VTRouPD may contain multiple lVTRouPDs. In other words, a lVTRouPD is
a sub-domain consisting of a collection of virtual routers
under a certain routing policy, and it can be constructed
either within a single VTRouPD or by spanning multiple
VTRouPDs. To explain the latter case, we deﬁne a
lVTRouPD as l, and there are two VTRouPDs, V 1 and V 2 ,
where both V 1 and V 2 have a set of virtual sub-domains.
A spanning lVTRouPD means the l does not belongs to
either V 1 or V 2 , but l belongs to V 1 [ V 2 . In general, an
administrative domain consists of a number of VTRouPDs,
V 1 ; . . . ; V n . Each VTRouPD has a different number of virtual
sub-domains V im , where i 2 ½1; n, and m is used to differentiate the virtual sub-domains by the policies. A spanning
lVTRouPD can be represented as a collection of virtual
sub-domains under a certain policy over these n
VTRouPDs, fV 1j ; V 2j ; . . . ; V nj g, where j 2 ½1; m.
Compared with VTRouPDs, the boundary of lVTRouPDs
is not established through virtualizing router functions; instead, we perform virtualization of lVTRouPDs through
the following techniques:
 Use of cryptographic packet marking techniques to
allow each virtual router to recognize the trafﬁc ﬂows
for different lVTRouPDs.
 Invocation of efﬁcient secure group communication
solutions to isolate trafﬁc ﬂows that belong to different
lVTRouPDs. This approach provides us a ﬁne-grained
trafﬁc management and ﬁltering capability to identify
malicious trafﬁc and reduce the impact to other services
when the malicious trafﬁc ﬂows are blocked. Moreover,
through secure group-based communication, we can
further merge or diverge trafﬁc belonging to different
lVTRouPDs
through
superor
sub-group
communications.
 Use of an efﬁcient security data access control solution
that provides trust party veriﬁcation, trafﬁc access control, and data privacy protection for lVTRouPDs. This

capability allows us to provide versatile user-centric
network routing services with assured data access policy enforcement and privacy protection.
4.3. Realizing VTRouPD in SeRViTR
The conceptual VTRouPD model discussed above is proposed from the perspective of a high-level design. In order
to realize the concept described in the VTRouPD model, we
designed a comprehensive architecture called Secure and
Resilient Virtual Trust Routing (SeRViTR) that crystallizes
the components deﬁned in the VTRouPD model. For this,
we designed functional components at the implementation
level to realize the roles of both TMS and the VTRouPD
Manager. We also deﬁne the exchange messages for communication between these functional components (see
the Appendix A). Table 2 presents the VTRouPD components and their roles in the SeRViTR framework, and
Table 4 summarizes terminologies for the key ﬁelds
deﬁned in the message types. These notations will be used
through the rest of this paper. It should be noted that to
realize VTRouPD, there are two additional components
needed in SeRViTR; they are: (1) the ﬂow controller and
(2) the trafﬁc monitor.
A Routing Service Node (RSN) is a physical programmable router within the VTRouPD, and it is in charge of forwarding packets to a speciﬁc Virtual Domain. A Routing
Service Node forwards packets to the next or Flow Controller
by modifying the ForwardingID denoted in the routing
table.
4.4. SeRViTR components
In this part, we illustrate the role of other SeRViTR components, and the interactive relation between one another.
Table 2 shows the roles of conceptual VTRouPD elements
in the design of the SeRViTR framework, as shown in Fig. 2.
4.4.1. Trust Management Service (TMS)
Trust Management Service is a key service in SeRViTR.
We accomplish Trust Management Service through three
functional components: Policy Manager, Authentication
Manager, and Trust Level Regulator.
A Policy Manager is associated with each VTRouPD. It
maintains three tables: the Rule-set Table, the Trust-level
Table, and the Virtual Domain Table. The role of the Policy
Manager is many-fold, which is depicted in Fig. 3:.
 It enforces policies that are assigned by the
Administrator.
 It is in charge of policy management. We use XACML
(eXtensible Access Control Markup Language)[12] to
describe the rules, and each rule is identiﬁed by hFlowID, Trusti. In order to ensure security, we use a unique
16-bit integer to identify the Trust based on the policy.
 It announces the request for the creation or deletion of
Virtual Domains to the VTRouPD Manager. When a new
TrustID is obtained, the Policy Manager generates a
request and sends it to the VTRouPD Manager through
the Virtual Domain Management Message (Fig. 13(a)).

S. Ata et al. / Computer Networks 63 (2014) 128–146

133

Table 2
VTRouPD components with role descriptions.
VTRouPD
Component

Role in SeRViTR

Description

VTRouPD

Managed domain

Physical topology and virtual domain used as the scope of policy which administrator inputs

lVTRouPD

Virtual domain
(intra)
Virtual domain
(spanning)

The sub-domain which consists of virtual routers under a particular routing policy in a single VTRouPD

Authentication
server
Policy manager
Trust level
regulator

Generating and distributing authentication information to Policy manager

VTRouPD manager

Domain
controller

Creating

Routing service
node

Virtual router

Physical routers where virtual router instances can be created on physical machines

Resource
application
manager

Resource
management

Assign network resources to

Flow controller
Trafﬁc monitor

Redirect ﬂows to different virtual domains based on the policies
Monitor the network for any suspicious trafﬁc

Trust management
service

The sub-domain spanning multiple VTRouPDs consists of virtual routers under a particular policy, i.e., if l
is a lVTrouPD, and V 1 and V 2 and two VTRouPDs that l spans, then l # V 1 [ V 2 ; l  V 1 ; l  V 2

Invoking lVTRouPD creation/deletion by providing policy management
Trust level negotiation between multiple VTRouPDs

lVTRouPDs based on the policy

lVTrouPDs

Fig. 2. SeRViTR: Architectural overview.

 It sends a Flow Table Update Message (Fig. 13(b)) to the
Flow Controller that manages the ﬂow table, informing
how incoming packets (ﬂows) should be processed at
the Flow Controller.
 It plays a role in negotiating the trust level between
managed domains. To do so, it creates an OutboundDomainID, and communicates with the Trust Level Regulator about the Outbound Domain ID Notiﬁcation.
The Trust Level Regulator behaves as a trust gateway in
each VTRouPD through which the trust level is established,
changed, and updated between two VTRouPDs. It relays
the Outbound Domain ID notiﬁcation that is sent from the
Policy Manager to other VTRouPD’s Trust Level Regulators.
The Authentication Server is responsible for the generation and distribution of authentication keys, and it man-

ages the HostID and Secret where the HostID indicates an
IP address or a user name, and Secret is the password or
certiﬁcate.

4.4.2. VTRouPD Manager
A VTRouPD Manager manages the information of physical routers within the VTRouPD and it is responsible for the
creation or deletion of the VirtualDomainID, as well as resource management in terms of resource information from
the Routing Service Nodes. The VTRouPD Manager maintains
a Virtual Domain Management Table that stores information
of the Virtual Domains, the RSNIDs, and the Resource Information. In order to create Virtual Domains, the VTRouPD
Manager assigns a VirtualDomainID and inserts it into the
Virtual Domain Management Table. Similarly, in order to

134

S. Ata et al. / Computer Networks 63 (2014) 128–146

Fig. 3. Operations of policy manager.

delete a Virtual Domain, the VTRouPD Manager deltes the
entry from the Virtual Domain Management Table.
For the resource management, the VTRouPD Manager
obtains resource information such as bandwidth from the
Routing Service Node. The VTRouPD Manager sends the Routing Table Update Message (Fig. 13(c)) to the Routing Service
Node to update its routing table. Particularly, the ForwardingID is set as the Layer-2 ID in our implementation.
4.4.3. Flow Controller and Trafﬁc Monitor
The Flow Controller is a component in SeRViTR that is
placed at the edge of the VTRouPD. A Flow Controller forwards ﬂows to the appropriate Virtual Domains based on
a given policy. For any outgoing packet, the ForwardingID
is removed from a data packet; while for any incoming
packet, a ForwardingID is attached according to the Flow
Table. Also, a Flow Controller encrypts the incoming packet
and decrypts the outgoing packet according to the ﬂow table. The Flow Controller updates the ﬂow table based on the
Flow Table Update Message.
The Trafﬁc Monitor is used to monitor anomaly behaviors of the ﬂows at the ingress routers. If anomaly trafﬁc
is detected, it communicates the ﬂow information to the
Trust Level Regulator. We assume that there is a separate
engine for identifying anomaly trafﬁc.

the routing function alone, virtualization cannot fully meet
the requirement of merging trafﬁc from two Virtual Domains at the edge of one VTRouPD and send it to another.
To address these issues, a ﬂexible and lightweight virtual
routing policy management and enforcement mechanism
is required. On the other hand, the trust management is
managed independently in different VTRouPDs. Hence, different administrative domains can have different compositions of VTRouPDs. To federate trust management among
VTRouPDs created by different administrative domains,
we need to construct a trust negotiation system to address
the incurred inconsistency and incompatibility issues.
The second critical trust management issue is how to
initiate trust among routers (and virtual routers). To address this, a reputation based approach can be used. Trust
Management Service, which involves the Trust Level Regulator and the Policy Manager, can collect feedback from
the system to rank the trust of a router, Virtual Domain,
and the VTRouPD, and in turn, they can calculate trust
ranking and provide a recommended trust level for the corresponding party at the initial trust level. The trust level
can be measured using metrics such as the percentage of
good trafﬁc transited, the reliability of the routing system,
trust levels of ingress and egress neighboring domains.
5.2. Trust Management Service sequence diagram

5. Policy and trust management in SeRViTR
We now present the enabling techniques to establish
VTRouPDs with a systematic approach. We start with a
description of the challenges in the policy and trust management, and we then discuss our approach.
5.1. Challenges for policy and trust management
There are limits on creating virtual routers on a physical
programmable router (refer to Section 4.2). When using

Considering the above challenges, we present sequence
diagrams for a number of situations of VTRouPD Trust
Management Services.
5.2.1. Policy setting
Policy setting involves a series of steps that includes
creating Virtual Domains and updating routing tables and
ﬂow tables. The sequence diagram for policy setting is
shown in Fig. 4. As we can see from this ﬁgure, the Administrator inputs a policy and on receiving it, the Policy

S. Ata et al. / Computer Networks 63 (2014) 128–146

Manager assigns a FlowID and unique TrustID. As we mentioned earlier, once the Policy Manager sets the TrustID and
there is no VirtualDomainID that corresponds to the TrustID
in the Virtual Domain Table at the Policy Manager, it generates and sends a request to create a Virtual Domain to the
VTRouPD Manager through the Virtual Domain Management
Message. In turn, the VTRouPD Manager will assign the VirtualDomainID that is used for updating the Virtual Domain
Management Table and sends Routing Table Update Messages to the Routing Service Nodes. The Routing Service Node
replies with an Update Complete Notiﬁcation and the
VTRouPD Manager sends a response back to the Policy Manager. Next, the Policy Manager sends the Flow Table Update
Message to the Flow Controller that responds with an
Update Complete Notiﬁcation to indicate that it has already
updated the routing policies. Finally, the Policy Manager
notiﬁes the Administrator that the policy setting is
completed.
5.2.2. Outbound trust level notiﬁcation
Two VTRouPDs can negotiate trust levels through their
own Trust Level Regulators. The sequence diagram for outbound trust level notiﬁcation is shown in Fig. 5. In this
case, the Policy Manager ﬁrst creates the OutboundDomainID list, and then notiﬁes the Trust Level Regulator with
the OutboundDomainID list. In turn, the Trust Level Regulator is responsible for communication with another Trust
Level Regulator associated with a corresponding NotifyDomainID. Once this is received by the other Trust Level
Regulator, it ﬁrst veriﬁes the validation. If the NotifyDomainID is acceptable, the Trust Level Regulator communicates
with its own Policy Manager about the NotifyDomainID, so
that data communication is possible between these two
VTRouPDs based on the established level of trust.
5.2.3. Trust level change notiﬁcation
Periodically, there is a requirement to communicate a
trust level change within a Managed Domain in regard to

135

communication with another VTRouPD. The sequence diagram for such a change is shown in Fig. 6. In this case,
when the other VTRouPD’s Trust Level Regulator is aware
of the trust level change, it communicates the change to
the ﬁrst VTRouPD’s Trust Level Regulator. Then, internally,
this change is notiﬁed to its Policy Manager, which in turn,
informs its Trafﬁc Monitor to request detecting these
changes.
6. SeRViTR functionality implementation
SeRViTR introduces a mechanism to forward ﬂows to
the corresponding lVTRouPD according to their trust level,
and the lVTRouPD creation based on the trust level is the
critical part in the SeRViTR functionality deployment. In
this section, we discuss its implementation on the Policy
Manager, VTRouPD Manager, Flow Controller, and Routing
Service Node, followed by a multiple domain scenario.
6.1. Implementation platform
The SeRViTR implementation is OpenFlow based. The
VTRouPD Manager is based on NOX 0.9.1 on an Ubuntu
10.10 platform where each function is implemented in
C++. As we described before in Section 7.3, we chose to
use an Openﬂow switch over NetFPGA to achieve better
performance in terms of handling packets. The Flow Controller and Routing Service Nodes are implemented using
NetFPGA 2.1.3_full on CentOS 5.3 where the OpenFlow
Switch was installed. As we mentioned earlier, the Flow
Controller assigns a different ForwardingID to the ﬂows
according to their trust level. When a Virtual Domain is created, the Flow Controller will update its ﬂow table and the
Routing Service Node updates its routing table, so that the
end systems can communicate with one another.
We have implemented four SeRViTR components, and
Fig. 7 presents the work ﬂows between these components.
The entire process involves six procedures:

Fig. 4. Policy setting.

136

S. Ata et al. / Computer Networks 63 (2014) 128–146

Fig. 5. Outbound trust level notiﬁcation.

Fig. 6. Trust level change notiﬁcation.

(1) Start the four SeRViTR components: VTRouPD Manager, Routing Service Node, Policy Manager and Flow
Controller, successively. Note that since we have
not implemented the Trust Level Regulator yet, we
presume that the Policy Manager already knew the
change of trust level when it created the virtual
domains. In our implementation, the Routing Service
Node (step 1.b) and Policy Manager (step 1.c) are
started after the VTRouPD Manager (step 1.a), and
the Flow Controller (step 1.d) is started after the Policy Manager and under the Policy Manager’s control.
(2) Interconnect the four components (Steps 2.a–2.d)
and Host Registration. Note that the step ‘‘Host Registration’’ is not presented in Fig. 7, but it is necessary for the following procedures. Before two hosts
setup communications, they have to register at the
Policy Manager within their own VTRouPDs, respectively. According to the type of communication
between these two hosts, the Policy Manager determines the trust level for them, in terms of TrustID.
(3) The Policy Manager sends the Virtual Domain Management Message. When the Policy Manager receives
the host registration information, it will generate the
TrustID and FlowID (step 4). Then it looks up the

Virtual Domain Table that maps the TrustID into the
corresponding VirtualDomainID. Fig. 7 shows two
implementation ﬂows after step 4, which are represented in red1 and green, respectively. The red ﬂow
path indicates a shorter ﬂow path to trigger a ﬂow
table update, which requires the Virtual Domain Table
to have the TrustID already mapped to a VirtualDomainID. If the TrustID does not exist in the trust table, the
Policy Manager will then send the Virtual Domain Management Message to the VTRouPD Manager to request
the VirtualDomainID, as shown in steps 5–6 in the
longer ﬂow path that is represented in green. The
longer path is a normal process for a new ﬂow that
arrives at the domain, because there is no priori TrustID-VirtualDomainID mapping pre-created. The next
procedure is only for the normal process.
(4) The VTRouPD Manager creates the Routing
Table Update Message. As soon as the VTRouPD Manager heard messages from the Routing Service Nodes,
it decides members for each virtual domain, as shown

1
For interpretation of color in Fig. 7, the reader is referred to the web
version of this article.

S. Ata et al. / Computer Networks 63 (2014) 128–146

137

Fig. 7. Workﬂows between policy manager, ﬂow controller, VTRouPD manager and routing service node.

by step 7 (7-a & 7-b) with both red and green paths.
When the VTRouPD Manager has decided the VirtualDomainID, it will send a Routing Table Update Message to all the Routing Service Nodes in the VTRouPD
to request a routing table update (steps 8 11). At
the same time, the VTRouPD Manager also sends the
new created VirtualDomainID to the Policy Manager
(steps 12–13).
(5) The Policy Manager sends the Flow Table Management
Message. Once the Policy Manager receives the newly
assigned VirtualDomainID from the VTRouPD Manager, it will ﬁrst update its Virtual Domain Table,
and then sends a Flow Table Management Message
to the Flow Controller to update the ﬂow table.
(6) The ﬂow table and routing table get updated.
6.2. Testing and validation
We setup a connection between two end-hosts that reside in two different VTRouPDs as shown in Fig. 8. In this
scenario, our goal is to validate the work ﬂows between
the four components we have discussed above. With each
VTRouPD setup, there are two Flow Controllers, at the ingress and egress points, respectively; a VTRouPD Manager
is connected to three Routing Service Nodes; a Policy Manager
is connected to both Flow Controllers and the VTRouPD Manager. We considered two different types of applications: SSH
and HTTP, where the HTTP ﬂow is set to the lowest trust level and the SSH ﬂow is assigned at the highest trust level.

In VTRouPD A, before sending out SSH and HTTP packets, the end-host PC1 needs to register at the Policy Manager PM1 with the information about the type of ﬂows.
For example, providing the port numbers (i.e., SSH: 22,
HTTP: 80). Based on the application type, PM1 uses predetermined policy rule hFlowID, Trusti to generate TrustIDs
for both types of applications. By querying its Virtual Domain Table hTrustID; VirtualDomainIDi, PM1 will decide the
VirtualDomainID and request the Flow Controller FC1 and
FC2 to update their ﬂow tables. Note that the VirtualDomainID can be used as the ForwardingID attached to the packet
sent from the Flow Controller (i.e., packet with ForwardingID 11, 12, 13 sent by FC1 in VTRouPD A).
In VTRouPD B, the end-host PC2 has to register at Policy
Manager PM2. The two Flow Controllers FC3 and FC4 will
update their ﬂow tables via the same procedure. Once
the VirtualDomainID has been determined for each application, the VTRouPD Managers will request all Routing Service
Nodes to update their routing tables.
The second validation is the degradation of the trust level when anomaly trafﬁc is detected in the ﬂow. In our current experimental setup, we assume that there is anomaly
trafﬁc mixed in the SSH ﬂow that is detected in VTRouPD A.
Because we have not implemented the Trust Level Regulator
yet, we manually change the TrustID for the application at
PM2, and in turn, the ﬂow tables at FC3 and FC4 are updated. Then, when receiving new SSH packets from
VTRouPD A, FC3 attaches a different ForwardingID and
forwards the packets to a different Virtual Domain that is

138

S. Ata et al. / Computer Networks 63 (2014) 128–146

Fig. 8. SeRViTR: Multiple-domain scenario.

under a lower trust level. The degraded SSH ﬂow is represented as a dotted arrow in Fig. 8.

6.3. Flow table size
In this section, we discuss the size of the ﬂow table at
the Flow Controller, in terms of the number of entries in
the table. Fig. 9 gives a few typical entries in a ﬂow table.
It shows that there are two entries for the ARP protocol,
and the rest of the entries are for the end-to-end communication. The ﬁrst two entries in Fig. 9 give an overview on
the basic elements in the complete ﬂow table entries. In
our design, we append one more parameter to a standard
ﬂow table entry; this parameter has two optional values:
‘‘mod_ForwardingID_vid’’ and ‘‘strip_ForwardingID’’.
When a Flow Controller receives a packet from outside of a
VTRouPD, the ‘‘mod_ForwardingID_vid’’ option is used in
the ﬂow entry with the ForwardingID tag that will be attached to the packet, indicating the Virtual Domain to
where the packet has been forwarded. When a Flow Controller forwards a packet out of the VTRouPD, the
‘‘strip_ForwardingID’’ is attached to the ﬂow entry
indicating that the ForwardingID tag is removed from the

packet. For each host that has registered at the Policy Manager, two ﬂow entries will be created in the ﬂow table for
each ﬂow under a particular trust level; here, ‘‘two’’ refers
to bi-directional communication.
Table 3 summarizes the parameters that affect the size
of a ﬂow table at the Flow Controller. The total number of
entries in a ﬂow table is

nARP þ nmod þ nstrip ¼ narp þ nhost  2  nflow þ ntrust

7. SeRViTR testbed: G-PLaNE
So far, we discussed SeRViTR components’ implementation from the functional perspective, and our next goal was
to deploy the SeRViTR testbed onto a real geo-distributed
environment. To support the SeRViTR testbed, we designed
the Geo-distributed Programmable Layer-2 Networking
Environment (G-PLaNE).
G-PLaNE is established for constructing the SeRViTR
system for the following reasons: (1) it is Geo-distributed
so that multiple virtual domains can be supported; (2) its
model is infrastructure-as-a-service so that lower level resources can be provided to enable the SeRViTR function

cookie=0, duration_sec=4s, duration_nsec=416000000s, table_id=0, priority=32768, n_packets=4294967295,
n_bytes=4294967295, idle_timeout=0, hard_timeout=0,tcp, in_port=3, dl_vlan=0x001f, tp_src=0, tp_dst=22,
actions=output:1, strip_vlan
cookie=0, duration_sec=4s, duration_nsec=423000000s, table_id=0, priority=32768, n_packets=4294967295,
n_bytes=4294967295, idle_timeout=0, hard_timeout=0, tcp,in_port=1, nw_src=172.16.1.103, tp_src=0,
tp_dst=22, actions=output:3, mod_vlan_vid:31
cookie=0, duration_sec=2515s, duration_nsec=567000000s, table_id=0, priority=32768,
n_packets=4294967295, n_bytes=4294967295, idle_timeout=0, hard_timeout=0, arp,in_port=3, dl_vlan=0x0014,
tp_src=0,tp_dst=0, actions=output:1, strip_vlan
cookie=0, duration_sec=2515s, duration_nsec=583000000s, table_id=0, priority=32768,
n_packets=4294967295, n_bytes=4294967295, idle_timeout=0, hard_timeout=0, arp,in_port=1, tp_src=0,
tp_dst=0, actions=output:3,mod_vlan_vid:20
Fig. 9. An example of ﬂow table at the Flow Controller.

S. Ata et al. / Computer Networks 63 (2014) 128–146

7.1.1. System components
We partition the G-PLaNE system into a number of
components as follows:

Table 3
Parameters determines the ﬂow table size.
Parameter

Description

narp
nhost
ntrust
nflow

The
The
The
The

number
number
number
number

of
of
of
of

139

ARP ﬂow entries, constant value = 2
hosts registered at the Policy Manager
TrustID has been created
ﬂows under different trust levels

with more capability; and (3) it has a network programmability feature so that the system built on top of it can be
developed with an additional network programming
capability.
The G-PLaNE currently involves three geographically
distributed sites. They are Osaka City University (OCU) in
Japan, Arizona State University (ASU) and the University
of Missouri–Kansas City (UMKC) in the United States. Thus,
the SeRViTR testbed environment consists of three
VTRouPDs, one located at each site, respectively. A Trust Level Regulator among these domains will communicate to
establish the appropriate trust levels. We started with
building the experimental environment and implementing
SeRViTR components concurrently. On the one hand, we
are building tunnels among these three sites, and we have
built GRE tunnels through OpenFlow Switches. On the
other hand, we implemented the VTRouPD Manager, the
Flow Controller, and the Routing Service Nodes in a twoVTRouPD environment over two sites.
7.1. Geo-distributed Programmable Layer-2 Networking
Environment (G-PLaNE)
G-PLaNE is designed to provide networking, computing,
and storage capabilities for terminals that usually have
limited resources and capabilities. The system component
and architecture can be seen in Fig. 10. We present here
a brief description on related components for constructing
SeRViTR; for example, components such as storage are not
discussed as this is not directly relevant to SeRViTR.

 Computing Component: Computing capability is the
major provisioning service that the majority of resource
provisioning platforms provide. We use Xen [38] to
maximally utilize the resource pool (physical XenServers) by creating multiple virtual machines (VMs). With
virtualization and programmability enabled, G-PLaNE
can provide logically separate resources for end users
in terms of a general routing suite, an OpenFlow
switch/router, and controllers. A resource pool always
has at least one physical node, known as the master.
Other physical nodes join the existing pool and are
described as slaves. Only the master node exposes an
administration interface and forwards commands to
individual slaves as necessary.
 Administrative Component: We also introduce dedicated management and monitoring servers to
administrate the VMs and network resources in the
resource pool and monitor network trafﬁc within and
across domains. NetFlow [24] and sFlow [9] are both
enabled to inspect Layer-2 and Layer-3 networking as
well as host performance (i.e., CPU and memory utilization). There is also a set of internal functional servers
serving different administrative purposes, i.e., Web
server, DHCP, DNS, Authentication Server, DB server,
and VPN.
7.1.2. Network architecture
In the system component discussion above, virtual
machines (VMs) are critical when deploying a testbed on
G-PLaNE, because they can be deployed into various functional components. In this section, we describe how these
VMs communicate with each other in a intra/inter-cluster
environment with the network architecture design. Details
on how we use VMs in the SeRViTR project will be discussed later in Section 7.3.

Fig. 10. G-PLaNE architecture design.

140

S. Ata et al. / Computer Networks 63 (2014) 128–146

In the G-PLaNE system, the data plane and the control
plane are isolated. The management network (Control
Plane) is for management and control trafﬁc (i.e., the trafﬁc
of the service request, downloading applications from our
repository and so on). On the other hand, the data network
is for data trafﬁc among different VMs, or different terminals via VMs. From Fig. 10, there are 4 networks in each
cluster. The incoming and outgoing trafﬁc switches isolate
the trafﬁc going out of or coming into the G-PLaNE domain.
With this design, we can easily control the privilege of resources accessing the Internet, which enhances the security of the resource network environment.
The communications between VMs go through the data
network. The data network switch is a managed switch
with VLAN support that enables different VMs being in different virtual domains. Additionally, the G-PLaNE management network connects the internal NetFlow and sFlow
monitoring systems to dynamically monitor the network
performance by an administrator. Not only is VM-to-VM
communication in one physical cluster considered, but also
those VMs located at different clusters are considered. For
this reason, the OpenFlow switch [35] has been introduced
to establish the inter-domain data link. To increase efﬁciency and security, each G-PLaNE server is installed with
Open vSwitch [5] with which the trafﬁc between two
VMs in the same physical server does not need to go
through the physical data network switch so that it is
exposed in public. The detail of this dual switch design is
further explained in Section 7.2.
7.1.3. Network programmability
Both the OpenFlow switch (OFS) and Open vSwitch
(OVS) are OpenFlow-based switches. In OpenFlow architecture, a controller executes all control tasks of the
switches and also those used for deploying new networking frameworks, such as new routing protocols or optimized cross layer packet-switching algorithms. With
these features, a programable network is established to
provide network programmability for Cloud providers. It
is feasible to develop a tenant-based policy or protocol to
control both internal OVS and external OFS in a virtual networking environment. There are several OFS controllers

available following the OpenFlow standard, such as Onix
[31], SNAC [13], and NOX [26]. OFS, as well as the controllers, can be easily deployed on VMs since they are software-based.
With the dynamic resource provisioning mechanism
supported, users are able to request a dedicated private
virtual OpenFlow network upon G-PLaNE and develop
their own network topology and control mechanism. A virtual network is created from several templates including
the software based OpenFlow switch and different controllers pre-installed in the VM. A user can easily turn the
claimed general virtual network into an OpenFlow-based
programmable virtual network by enabling some pre-installed functions. Besides this OpenFlow based switch/control model, there are also all-in-one routing suites; for
example, the Quagga Routing Suite [8] can be deployed
into the virtual network upon which users can develop
their research and experiments.
7.2. Virtual network construction
We chose a geo-distributed architecture to support resource provisioning over multiple clusters. The resource
network can be created by different conﬁgurations due to
different requirements: (1) a single physical server, (2)
multiple servers within one cluster (servers in the same
cluster are connected through a Layer-2 physical switch),
and (3) multiple servers belonging to different clusters.
7.2.1. Intra-cluster network creation
Intra-Cluster means there is always a native Layer-2
connection among all resources within the same cluster.
To create a virtual network within the same cluster, VLAN
technology is deployed. As we previously mentioned, it is
inefﬁcient to forward packets through the managed switch
from one VM to another one in the same physical resource
provisioning server. Therefore, each XenServer has an
internal Open vSwitch enabled to handle trafﬁc inside
the physical server as shown in Fig. 11.
Open vSwitch is designed to enable massive network
automation through programmatic extensions, while still
supporting standard management interfaces and protocols

Fig. 11. Intra- & inter-domain network architecture.

S. Ata et al. / Computer Networks 63 (2014) 128–146

(e.g., NetFlow, sFlow, RSPAN, ERSPAN, CLI, LACP, 802.1ag).
Open vSwitch can operate as a software-based switch running within the hypervisor (Xen Dom 0) in which many
security control functions can be implemented. With Open
vSwitch enabled, a packet sent from one VM to another one
within the same physical server does not need to be exposed out of the physical box. When a virtual network is
created within the same cluster but across different physical servers, a packet sent from one VM to another one on a
different server should go through the physically managed
switch by enabling trunk ports. The virtual network containing multiple VMs in different physical servers is simply
created by assigning the same VLAN ID so that it is virtually isolated from other resources.
7.2.2. Inter-cluster network creation
To enable provisioning of a virtual network across clusters in G-PLaNE, we establish Layer-2 GRE tunnels among
three sites. After a Layer-2 tunnel is established, VLAN can
function well upon a Layer-2 tunnel since it is a 2.5 layer
technology, strictly speaking. Although there are some options to establish the Layer-2 tunnel, we chose the OpenFlow solution since it is user-centric and can be easily
extended due to its programmability. OpenFlow is an open
standard that enables researchers to run experimental protocols. In a classical router or switch, the fast packet forwarding (data path) and the high level routing decisions
(control path) occur on the same device. An OpenFlow
switch separates these two functions. The data path portion
still resides on the switch, while high-level routing decisions are moved to a separate controller, typically a standard server. The OpenFlow switch and controller
communicate via the OpenFlow protocol, which deﬁnes
messages, such as packet-received, send-packet-out, modify-forwarding-table, and get-stats. The data path of an
OpenFlow switch presents a clean ﬂow table abstraction;
each ﬂow table entry contains a set of packet ﬁelds to
match, and an action (such as send-out-port, modify-ﬁeld,
or drop).

141

7.3. Deploying SeRViTR on the G-PLaNE
SeRViTR is deployed in a virtual networking environment that is supported by the G-PLaNE. The lVTRouPD is
a vital constituent part in the SeRViTR architecture and it
requires isolation as well as scalability when constructing
virtual networks. With the G-PLaNE system data network
switch, which is VLAN supported, VMs can be grouped into
different Virtual domains by tagging VLAN IDs, and the ones
which have been used can be queried through the database
of the G-PLaNE system. Fig. 11 shows a high level Virtual
Domain creation by grouping VMs into distinct VLANs. Particularly, consider Cluster A at ASU in Fig. 12 where one
XenServer is reserved from the resource pool for creating
SeRViTR functional managers. Regarding the virtual routers, we may also choose to reserve XenServers from the resource pool and customize an arbitrary number of VMs as
dedicated virtual routers by deploying a routing suite (i.e.,
OpenFlow switch, Quagga, and so on) on it. As a second option, we can directly use a physical OpenFlow Switch upon
a dedicated OpenFlow enabled switch or NetFPGA and use
VLAN tags to achieve isolation between Virtual Domains.
We ﬁrst deployed a single VTRouPD connecting three
sites, ASU, UMKC, and OCU on top of the G-PLaNE. OCU manages the control units, namely, Policy Manager and Domain
Controller, while ASU and UMKC deploy one Flow Controller
and one Routing Service Node at each site, respectively.
The G-PLaNE allows the clusters to be scalable. Therefore, we were able to construct multiple VTRouPDs over
geo-distributed locations. For example, take the SeRViTR
clusters at ASU and UMKC presented in Fig. 12; here, two
VTRouPDs were created. Within the cluster at each site,
the G-PLaNE resource pool contains physical XenServers
where VMs are created. Recall that all VMs can be created
and deployed as any form of functional entity; thus, we can
customize VMs as dedicated SeRViTR functional components as well as virtual routers. Particularly, VTRouPD Managers, and Policy Managers are implemented on VMs
created on one XenServer from the resource pool. In our

Fig. 12. SeRViTR inter-domain deployment on G-PLaNE: Two VTRouPD clusters at ASU and UMKC.

142

S. Ata et al. / Computer Networks 63 (2014) 128–146

deployment, the Flow Controllers and the Routing Service
Nodes are implemented on physical OpenFlow Switches
upon NetFPGA.
To establish a geo-distributed multi-domain infrastructure for SeRViTR, we established a Layer-2 GRE tunnel
using G-PLaNE, so that any two sites have either a direct
or an indirect Layer-2 connection. An OpenFlow Switch
was deployed to establish the tunnel. It uses the OpenFlow
protocol and also supports various controllers that speak
OpenFlow protocol. In this case, a Layer-2 GRE tunnel
was chosen so that any Layer-2 above technology, i.e.,
VLAN, is enabled upon this Layer-2 tunnel. The real entity
being tunneled is the virtual bridge that can be attached to
any VIF (Virtual Interface) or PIF (Physical Interface). This
means that both the physical XenServer or the virtual machine are actually in this tunnel. Using this ﬂexible mechanism to establish the tunnel also guarantees the easiness
of future extensions by using OpenFlow protocol. We also
tested the delay among all sites over the GRE tunnel. The
average latency from UMKC to OCU (Japan) is 219 ms,
the average latency from UMKC to ASU is 59 ms, and the
average latency from OCU to ASU is 278 ms.
8. Discussion and future work
So far, we presented SeRViTR, starting from its stope,
the framework to the international testbed that we have
deployed as a proof-of-concept. We are currently exploring
additional features to improve SeRViTR. In this section, we
brieﬂy discuss our ongoing work on the extended policy
and trust management functionalities at the Policy Manager, because policy and trust management are the core
features of the SeRViTR framework.
Note that policy-based management is not new to computer networking research. A common real-world application of policy-based management is the ﬁrewall rules, for
security authorization. With ﬁrewall rules, packets are able
to be ﬁltered out based on the source or destination IP addresses and port numbers. Role-Based Access Control
(RBAC) [40] Speciﬁcation is a policy model proposed to deﬁne permission according to the roles instead of individual
people [16]. The Attribute-Based Access Control (ABAC)
[48] proposed by DETERlab adds the attribute concept to
the RBAC framework, and its goal is to provide a novel federation framework instead of using the Public Key Infrastructure. In [16], the authors also described a number of security
and trust speciﬁcations for access control models and various languages that are used for access-control policy speciﬁcations including Logic-Based Language and Role-based
Security Languages. A security policy can also be described
in the form of an XML speciﬁcation, such as using XACML.
SeRViTR is designed to provide a user-centric secure
routing domain, so users’ requests on the network resources and trust management should be taken into consideration. Therefore, when designing the new features,
we added new input information known as Accounting Status and AccountID. These two terms are used to identify
how much a user will pay to request network resources
(i.e., bandwidth) for his/her lVTRouPD. On the other hand,
Policy Manager will also make a judgement on the behavior
of this user’s lVTRouPD to determine whether it is safe to

keep at the same trust level. Thus, we deﬁne Behavior Pattern as a type of ﬂow, application, or alert.
Based on the discussion above, we plan to extend the
current protocols in SeRViTR to support the added functions to the Policy Manager. We divide the role of Policy
Manager into three parts: Host and Flow Management,
Behavior Management, and Resource Management.
 At the input boundary, with Host and Flow Management,
the Policy Manager will receive the HOSTID and
Accounting Information and calculate the Trust and
Bandwidth request for the corresponding ﬂow. At the
output boundary, the Policy Manager will send an Flow
Table Update Message to the Flow Controller to update
the Flow Table. Meanwhile, it will also send an Outbound
DomainID Notiﬁcation to the Trust Level Regulator.
 Behavior Management is an important function since
there is a need to periodically update trust level between
VTRouPDs. The Policy Manager will receive Behavior
Notiﬁcation and Trust Level Change Notiﬁcation and make
the judgement on the behavior pattern. Here, the behavior pattern refers to the type of ﬂow, application or alert.
According to the judgement, the Policy Management will
make a decision whether there is a need to adjust the
trust level between two VTRouPDs. Together with the
Outbound DomainID Notiﬁcation, it will send the Trust
Level Change Notiﬁcation to the Trust Level Regulator.
 Resource Management refers to making requests to
assign the bandwidth for a lVTRouPD. This function is
being combined with our current implementation with
lVTRouPD creation.
9. Conclusion
In this paper, we presented the design of the SeRViTR
framework for the future Internet according to the idea
of the VTRouPD from our earlier work. We introduced
the role and responsibility of VTRouPD components in
the SeRViTR architecture. Speciﬁcally, we illustrated the
VTRouPD Trust Management Service that is able to setup
trust levels for different virtual domains within a VTRouPD,
and we negotiated the trustworthiness levels of the ﬂows
between VTRouPDs. Moreover, we designed a geo-distributed resource provisioning system called G-PLaNE to support virtual network creation between international
research platforms. The G-PLaNE system is discussed in
terms of system components, network architectures, and
so on. Virtual network creation, as a major service provided
by G-PLaNE, is explained from two perspectives, an
intra-domain virtual network and an inter-domain virtual
network. We deployed SeRViTR architecture on the
G-PLaNE system to achieve Layer-2 tunneling between
the US and Japan sites, and we validated the virtual domain
creation according to the trust levels. From our basic result
of implementation, we have been able to create ﬂow-level
lVTRouPDs under different trust levels and migrate the
ﬂow to the lVTRouPD under a lower trust level given that
the anomaly trafﬁc is detected in the ﬂow. In our future
work, we will consummate the functionalities of the Policy
Manager, by extending the current SeRViTR protocols, to
better support user-centric secure routing domains.

143

S. Ata et al. / Computer Networks 63 (2014) 128–146

Acknowledgments
This work has been supported by a US–Japan collaborative project grant with US NSF Grants CNS-1029562 and
CNS-1029546, and Japan NICT International Collaborative
Research Grant. It is also partially supported by Ofﬁce of
Naval Research’s (ONR) Young Investigator Program (YIP)
grant and an HP IRP grant.
Appendix A

Table 4
Terms used in the message types.
Term

Description

VirtualDomainID

The identiﬁer for identifying the Virtual
Domain
The identiﬁer for identifying the Routing
Service Node
The identiﬁer for identifying ﬂow
The identiﬁer for kinds of processes
Trustworthiness of ﬂow
The identiﬁer for identifying Trust
The identiﬁer used for communication
between different VTRouPDs

RSNID
FlowID
ActionID
Trust
TrustID
OutboundDomainID

A.1. SeRViTR message types
The Trust Management Service (TMS) takes three different roles: Authentication Server, Policy Manager, and Trust
Level Regulator, which are discussed in Section 4.4. In
Fig. 2, the Policy Manager communicates with every other
individual SeRViTR component. In order to implement policy management, we created four message types with their
packet formats. They are the main information exchanged
between the Policy Manager and other SeRViTR components when setting up routing policies or negotiating trust
levels between VTRouPDs.

Table 5
Flow ID: Information content.
Input port (8)
Layer-2 ID (16)
IP ToS (8)
Source IP Address (32)
Source MAC Address (48)
Source Port Number (16)

Ethernet frame type (16)
Layer-2 Priority (8)
Protocol Number (8)
Destination IP Address (32)
Destination MAC Address (48)
Destination Port Number (16)

A.2. Virtual Domain Management Message
The Virtual Domain Management Message is exchanged
between the Policy Manager and VTRouPD Manager to manage Virtual Domains. The packet format for the Virtual Domain Management message is shown in Fig. 13(a). It has a
ﬁeld to indicate the action (Create (C)/Modify (M)/Delete
(D)/Reply (R)) to be taken by the Virtual Domain along with
the list of the Routing Service Node’s identiﬁers and the VirtualDomainID. Any resource to be assigned to the Virtual
Domain is also indicated.
A.3. Flow Table Update Message
A Flow Table Update Message is for communication between the Policy Manager and Flow Controller to update
the ﬂow table at the Flow Controller. The packet format
for the Flow Table Update message is shown in Fig. 13(b).
It carries the TrustID and ActionID, along with the FlowID.
In particular, the FlowID is the identiﬁer of the input ﬂow
and the ActionID speciﬁes the action that can be the Attach/Strap/Modify ForwardingID or Encrypt/Decrypt ﬂows.
Here, in order to identify packets associated with a ﬂow,
marked by FlowID, we use OpenFlow Switch Speciﬁcation
v1.1 [14], in which we deﬁne a 256-bit ﬁeld for FlowID.
The information content of FlowID is shown in Table 5.

Fig. 13. Message type and corresponding packet format.

A.5. Outbound Domain ID Notiﬁcation
A.4. Routing Table Update Message
A Routing Table Update Message is communicated between the VTRouPD Manager and Routing Service Nodes
for routing table updates. The packet format for a Routing
Table Update message is shown in Fig. 13(c). It carries the
ActionID along with an input/output port and Forwarding
ID for input and output packets.

The Outbound Domain ID Notiﬁcation is exchanged between the Policy Manager and Trust Level Regulator for trust
negotiation among VTRouPDs. The packet format for Outbound Domain ID Notiﬁcation is shown in Fig. 13(d). It has
a ﬁeld to indicate any priority for an OutboundDomainID,
along with the OutboundDomainID and ForwardingID for input and output packets.

144

S. Ata et al. / Computer Networks 63 (2014) 128–146

References
[1] Bonﬁre <http://www.bonﬁre-project.eu/>.
[2] FIRE: Future Internet Research Experiment <http://cordis.europa.eu/
fp7/ict/ﬁre/>.
[3] OFELIA: OpenFlow in Europe: Linking Infrastructure and
Applications <http://www.fp7-ofelia.eu/>.
[4] OneLab <http://www.onelab.eu/index.php/about.html>.
[5] Open vswitch <http://openvswitch.org/>.
[6] PlanetLab <http://www.planet-lab.org/>.
[7] Protogeni <http://www.protogeni.net/>.
[8] Quagga Routing Suit <http://quagga.net/>.
[9] sFlow <http://www.sﬂow.org/>.
[10] VINI: Virtual Network Infrastructure <http://vini-veritas.net/>.
[11] Virtuoso: Resource Management and Prediction for Distributed
Computing using Virtual Machines <http://virtuoso.cs.northwestern.
edu/>.
[12] eXtensible Access Control Markup Language (XACML) Version 2.0,
December 2004 <http://docs.oasis-open.org/xacml/access_controlxacml-2_0-core-spec-cd-04.pdf>.
[13] The SNAC OpenFlow controller, 2010 <http://snacsource.org/>.
[14] Open Flow Switch Speciﬁcation, Feburary 2011 <http://
www.openﬂow.org/documents/openﬂow-spec-v1.1.0.pdf>.
[15] M.B. Anwer, N. Feamster, Building a fast, virtualized data plane with
programmable hardware, in: Proceedings of the 1st ACM Workshop
on Virtualized Infrastructure Systems and Architectures, VISA ’09,
ACM, New York, NY, USA, 2009, pp. 1–8.
[16] A.K. Bandara, N. Damianou, E.C. Lupu, M. Sloman, Policy based
management, in: J. Bergstra, M. Burgess (Eds.), Handbook of
Network and System Administration, Elsevier, 2008, pp. 507–564.
[17] T. Benzel, R. Braden, D. Kim, C. Neuman, Design, deployment, and use
of the deter testbed, in: Proceedings of the DETER Community
Workshop on Cyber-Security and Test, August 2007.
[18] M. Berman, J.S. Chase, L. Landweber, A. Nakao, M. Ott, D.
Raychaudhuri, R. Ricci, I. Seskar, GENI: a federated testbed for
innovative network experiments, Comput. Netw. 61 (2014) 5–23.
[19] R. Campbell, I. Gupta, M. Heath, S. Ko, M. Kozuch, M. Kunze, T. Kwan,
K. Lai, H. Y. Lee, M. Lyons, D. Milojicic, D.O. Hallaron, Y. C. Soh. Open
cirrus: cloud computing testbed: federated data centers for open
source systems and services research, in: Proceedings of the USENIX
Hotcloud, June 2009.
[20] J. Cappos, I. Beschastnikh, A. Krishnamurthy, T. Anderson, Seattle: a
platform for educational cloud computing, in: The 40th Technical
Symposium of the ACM Special Interest Group for Computer Science
Education (SIGCSE), 2009.
[21] M. Casado, M.J. Freedman, J. Pettit, J. Luo, N. McKeown, S. Shenker,
Ethane: taking control of the enterprise, in: Proceedings of the ACM
SIGCOMM Conference (SIGCOMM ’07), Kyoto, Japan, August 2007.
[22] R. Cherukuri, X. Liu, A. Bavier, J. Sterbenz, D. Medhi, Network
virtualization in GpENI: framework, implementation and integration
experience, in: Proceedings of 3rd IEEE/IFIP International Workshop
on Management of the Future Internet (ManFI’2011), Dublin,
Ireland, May 2011, pp. 1212–1219.
[23] N.M.K. Chowdhury, R. Boutaba, A survey of network virtualization,
Comput. Netw. 54 (2010) 862–876.
[24] B. Claise, G. Sadasivan, V. Valluri, M. Djernaes, Cisco systems
NetFlow services export version 9, IETF RFC 3954 (2004). <http://
www.ietf.org/rfc/rfc3954.txt>.
[25] M. Suñé, L. Bergesio, H. Woesner, T. Rothe, A. Köpsel, D. Colle, B.
Puype, D. Simeonidou, R. Nejabati, M. Channegowda, M. Kind, T.
Dietz, A. Autenrieth, V. Kotronis, E. Salvadori, S. Salsano, M. Körner,
S. Sharma, Design and implementation of the OFELIA FP7 facility:
the European OpenFlow testbed, Comp. Netw. (2013). ISBN: 13891286.
[26] N. Gude, T. Koponen, J. Pettit, B. Pfaff, M. Casado, N. McKeown, S.
Shenkes, NOX: towards an operating system for networks, in: ACM
SIGCOMM Computer Communication Review, July 2008.
[27] D. Huang, S. Ata, D. Medhi, Establishing secure virtual trust routing
and provisioning domains for future Internet, in: Proceedings of IEEE
GLOBECOM Next Generation Networking Symposium, Miami, FL,
2010.
[28] E. Keller, R.B. Lee, J. Rexford, Accountability in hosted virtual
networks, in: Proceedings of the 1st ACM Workshop on Virtualized
Infrastructure Systems and Architectures, VISA ’09, ACM, New York,
NY, USA, 2009, pp. 29–36.

[29] S. Kent, R. Atkinson, IP authentication header, in: IETF RFC 2402,
1998.
[30] S. Kent, R. Atkinson, IP encapsulating security payload (ESP), IETF
RFC 2406, 1998.
[31] T. Koponen, M. Casado, N. Gude, J. Stribling, P. L, M. Zhu, R. Ramanathan,
Y. Iwata, H. Inouye, T. Hama, S. Shenker, Onix: a distributed control
platform for large-scale production networks, 2010.
[32] C. Kunzinger, Protocol for the exchange of inter-domain routing
information among intermediate systems to support forwarding of
iso 8473, Technical report, IETF working draft ISO 10747, 1994.
[33] X. Liu, A. Wada, T. Xing, P. Juluri, Y. Sato, S. Ata, D. Huang, D. Medhi,
SeRViTR: a framework for trust and policy management for a secure
Internet and its proof-of-concept implementation, in: Proceedings of
4th IEEE/IFIP International Workshop on Management of the Future
Internet (ManFI’2012), Maui, Hawaii, April 2012, pp. 1159–1166.
[34] B. Lundy, G. Xie, Network policy languages: a survey and a new
approach, Network 15 (2001) 10–21.
[35] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson, J.
Rexford, S. Shenker, J. Turner, Openﬂow: enabling innovation in
campus networks, in: ACM SIGCOMM Computer Communication
Review April 2008.
[36] D. Medhi, B. Ramamurthy, C. Scoglio, J.P. Rohrer, E.K. Çetinkaya, R.
Cherukuri, X. Liu, P. Angu, A. Bavier, C. Bufﬁngton, J.P.G. Sterbenz,
The GpENI testbed: network infrastructure, implementation
experience, and experimentation, Comp. Netw. 61 (2014) 51–74.
[37] T. Miyamura, S. Kamamura, K. Shiomoto, Policy-based resource
management in virtual network environment, in: Network and
Service Management (CNSM), 2010, pp. 282–285.
[38] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R.
Neugebauer, I. Pratt, A. Warﬁeldh, Xen and the art of virtualization,
in: Proceedings of the Nineteenth ACM Symposium on Operating
Systems Principles (SOSP), 2003.
[39] D. Raychaudhuri, I. Seskar, M. Ott, S. Ganu, K. Ramachandran, H.
Kremo, R. Siracusa, H. Liu, M. Singh. Overview of the orbit radio grid
testbed for evaluation of next-generation wireless network
protocols, in: Proceedings of the IEEE Wireless Communications
and Networking Conference (WCNC), 2005.
[40] R.S. Sandhu, E.J. Coyne, H.L. Feinstein, C.E. Youman, Role-based
access control model, Computer 29 (1996) 38–47.
[41] S. Schwab, B. Wilson, C. Ko, A. Hussain, Seer: a security
experimentation environment for deter, in: Proceedings of the
DETER Community Workshop on Cyber Security Experimentation
and Test,
2007. <http://static.usenix.org/event/deter07/tech/
full_papers/schwab/schwab.pdf>.
[42] H. Soroush, N. Banerjee, A. Balasubramanian, M.D. Corner, B.N.
Levine, B. Lynn, Dome: a diverse outdoor mobile testbed, in:
Workshop on Hot Topics of Planet-Scale Mobility Measurements
(HotPlanet), June 2009.
[43] M. Steenstrup, An architecture for inter-domain policy routing,
Technical report, IETF Network Working Group RFC 1478, 1993.
[44] M. Steenstrup, Inter-domain policy routing protocol speciﬁcation:
Version 1, Technical report, IETF Network Working Group RFC 1479,
1993.
[45] J. Sterbenz, D. Medhi, B. Ramamurthy, C. Scoglio, D. Hutchison, B.
Plattner, T. Anjali, A. Scott, C. Bufﬁngton, G. Monaco, D. Gruenbacher,
R. McMullen, J. Rohrer, J. Sherrell, P. Angu, R. Cherukuri, H. Qian, N.
Tare, The Great Plains Environment for Network Innovation (GpENI):
a programmable testbed for future Internet architecture research, in:
Proceedings of 6th International Conference on Testbeds and
Research Infrastructures for the Development of Networks &
Communities (TridentCom), Berlin, Germany, May 2010, pp. 428–441.
[46] The Global Environment for Network Innovations (GENI) <http://
groups.geni.net>.
[47] Y. Wang, E. Keller, B. Biskeborn, J. van der Merwe, J. Rexford, Virtual
routers on the move: live router migration as a networkmanagement primitive, SIGCOMM Comput. Commun. Rev. 38
(2008) 231–242.
[48] W. Winsborough, Automated trust negotiation technology with
attribute-based access control, in: Proceedings of DARPA
Information Survivability Conference and Exposition, 2003.
[49] T. Xing, X. Liu, C.-J. Chung, A. Wada, S. Ata, D. Huang, D. Medhi.
Constructing virtual networking environment in a Geo-distributed
Programmable Layer-2 Networking Environment (G-PLaNE), in: IEEE
5th International Workshop on the Network of the Future
(FutureNet-V), Ottawa, Canada, June 2012.

S. Ata et al. / Computer Networks 63 (2014) 128–146

145

Shingo Ata received M.E. and Ph.D. degrees in
Informatics and Mathematical Science from
Osaka University, Japan in 1998 and 2000,
respectively. From 2003 to 2006, he was a
Lecturer in the Graduate School of Engineering at Osaka City University, and an Associate
Professor from 2006 to 2013. Currently, he is a
Professor at the Graduate School of Engineering at Osaka City University. His research
works include networking architecture,
design of communication protocols, and performance modeling on communication networks.

Tianyi Xing is currently a Ph.D. student in the
School of Computing Informatics and Decision
Systems Engineering (CIDSE) at Arizona State
University. He received his B.E. degree in
Telecommunications Engineering from Xidian
University and his M.E. degree in Electronic
Engineering from Beijing University of Posts &
Telecommunications in 2007 and 2010,
respectively. He worked in Microsoft Research
Asia as a research intern from July to
December in 2009. His research interests are
software deﬁned networks, mobile cloud
computing, and network security.

Dijiang Huang received his B.S. degree from
Beijing University of Posts and Telecommunications, China 1995. He received his M.S.,
and Ph.D. degrees from the University of
Missouri–Kansas City, in 2001 and 2004,
respectively. He is currently an associate
professor of Computer Science in the School of
Computing, Informatics, and Decision Systems Engineering at Arizona State University.
His current research interests are computer
networking, security, and privacy. He is an
associate editor of Journal of Network and
System Management and an editor of IEEE Communications Surveys and
Tutorials. He is the recipient of the ONR Young Investigator Award.

Parikshit Juluri is a Ph.D. student at the
University of Missouri–Kansas City (UMKC),
USA. He received his M.S. in Electrical Engineering from UMKC in 2008. His research
interests include network measurement and
management, measurement of QoE of online
video based services, network design, optimization, and performance.

Xuan Liu is a Ph.D. student at the University
of Missouri–Kansas City. She received her B.S.
in Communication Engineering from China
University of Geosciences (CUG) in June 2007
and her M.S. in Computer Science from the
University of Missouri–Kansas City in
December 2010. Her research interests
include network virtualization, information
centric networking, computer networking
modeling and optimization.

Akira Wada received his B.E. in Information
and Communication Engineering and his M.E.
in Physical Electronics and Informatics from
Osaka City University, Osaka, Japan, in 2011
and 2013, respectively. He is currently a Ph.D.
student at the Graduate School of Engineering, Osaka City University, Japan. His research
interests are in network security, softwaredeﬁned networks and the future Internet. He
is a student member of the IEEE.

Chun-Jen Chung received his M.S. degree in
computer science from New York University.
He is working toward the Ph.D. degree in the
School of Computing, Informatics, and Decision Systems Engineering (CIDSE) at Arizona
State University. Prior to that, he worked as a
software developer at Microsoft and Oracle
for several years. His current research interests include computer and network security,
cloud system security, security in the software
deﬁned networking, and trusted computing in
mobile devices and cloud computing.

Yasuhiro Sato received his B.E., M.E., and
Ph.D. degrees in Information and Communication Engineering from Osaka City University, Osaka, Japan, in 2004, 2006, and 2009,
respectively. From 2009 to 2013, he was a
Lecturer in the Faculty of Maritime Safety
Technology at Japan Coast Guard Academy.
Since 2013, he has been an Associate Professor
in the Faculty of Maritime Safety Technology
at Japan Coast Guard Academy. His research
work is in the area of modeling and evaluation
of network performance. He is a member of
IEEE.

146

S. Ata et al. / Computer Networks 63 (2014) 128–146

Deep Medhi is a Curators’ Professor in the
Department of Computer Science & Electrical
Engineering at the University of MissouriKansas City, USA, and a honorary professor in
the Department of Computer Science & Engineering at the Indian Institute of Technology–
Guwahati, India. He received B.Sc. in Mathematics from Cotton College, Gauhati University, India, M.Sc. in Mathematics from the
University of Delhi, India, and his Ph.D. in
Computer Sciences from the University of
Wisconsin–Madison, USA. Prior to joining
UMKC in 1989, he was a member of the technical staff at AT&T Bell
Laboratories. He served as an invited visiting professor at the Technical
University of Denmark, a visiting research fellow at Lund Institute of

Technology, Sweden, and State University of Campinas, Brazil. As a Fulbright Senior Specialist, he was a visitor at Bilkent University, Turkey, and
Kurukshetra University, India. He is the Editor-in-Chief of Springer’s
Journal of Network and Systems Management, and is on the editorial board
of IEEE/ACM Transactions on Networking, IEEE Transactions on Network and
Service Management, and IEEE Communications Surveys & Tutorials. He has
published over 125 papers, and is co-author of the books, Routing, Flow,
and Capacity Design in Communication and Computer Networks (2004) and
Network Routing: Algorithms, Protocols, and Architectures (2007), both
published by Morgan Kaufmann Publishers, an imprint of Elsevier
Science. His research interests are multi-layer networking, network
virtualization, data center optimization, and network routing, design,
and survivability. His research has been funded by NSF, DARPA,
and industries.

