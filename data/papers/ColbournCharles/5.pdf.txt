Des. Codes Cryptogr. (2015) 77:479­491 DOI 10.1007/s10623-015-0084-4

Optimal low-power coding for error correction and crosstalk avoidance in on-chip data buses
Yeow Meng Chee1 · Charles J. Colbourn2 · Alan Chi Hung Ling3 · Hui Zhang1 · Xiande Zhang1

Received: 30 October 2014 / Revised: 12 April 2015 / Accepted: 16 April 2015 / Published online: 8 May 2015 © Springer Science+Business Media New York 2015

Abstract Coupled switched capacitance causes crosstalk in ultra deep submicron/nanometer VLSI fabrication, which leads to power dissipation, delay faults, and logical malfunctions. We present the first memoryless transition bus-encoding technique for power minimization, errorcorrection, and elimination of crosstalk simultaneously. To accomplish this, we generalize balanced sampling plans avoiding adjacent units, which are widely used in the statistical design of experiments. Optimal or asymptotically optimal constant weight codes eliminating each kind of crosstalk are constructed. Keywords Constant weight codes · Packing sampling plan avoiding adjacent units · Crosstalk avoidance · Low power code · Packing by triples · Balanced sampling plan Mathematics Subject Classification 94B25 · 05B40 · 05B07 · 62K10

This is one of several papers published in Designs, Codes and Cryptography comprising the "Special Issue on Cryptography, Codes, Designs and Finite Fields: In Memory of Scott A. Vanstone".

B

Charles J. Colbourn charles.colbourn@asu.edu Yeow Meng Chee ymchee@ntu.edu.sg Alan Chi Hung Ling aling@emba.uvm.edu Hui Zhang huizhang@ntu.edu.sg Xiande Zhang xiandezhang@ntu.edu.sg

1

Division of Mathematical Sciences, School of Physical and Mathematical Sciences, Nanyang Technological University, Singapore 637371, Singapore School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ 85287, USA Department of Computer Science, University of Vermont, Burlington, VT 05405, USA

2

3

123

480

Y. M. Chee et al.

1 Introduction
The ever-decreasing feature size of VLSI fabrication process has led to many challenges in VLSI circuit design. One of the most important issues concerns the characteristics of onchip wires [11]. The wires' cross-sectional areas and spacings have fallen dramatically with the move into the ultra deep submicron/nanometer (UDSM) regime. This has increased the resistance and capacitance of wires. To help reduce resistance, wires today are taller than they are wide, and they are poised to grow even taller as technology continues to scale. The resulting growth of side-to-side capacitance between long parallel wires causes coupled switch capacitance to dominate the wire-to-substrate capacitance in UDSM circuits by several orders of magnitude [21]. Coupled switched capacitance in turn leads to crosstalks, which result in power dissipation, delay faults, and logical malfunctions. The problem of eliminating or minimising crosstalks is considered the biggest signal integrity challenge for long on-chip buses implemented in UDSM CMOS technology [12]. The worst crosstalk couplings have been classified into four types [6,12], as described in Table 1. The coupled switched capacitance resulting from type-1, -2, -3, and -4 crosstalks is in the ratio of 1:2:3:4. Hence, it is particularly important to avoid crosstalks of higher types. Type-1 crosstalks cannot be avoided in any useful communication channel. However, type-1 crosstalks give rise to power dissipation and must be limited, because low power is a critical design objective in recent years. Another factor that has emerged as a new challenge for VLSI circuit designers is UDSM noise, caused by high-leakage transistors, power-grid fluctuations, ground bounce, IR drops, clock jitter, and electromagnetic radiation. The effects of such noise are difficult to predict or prevent. For example, noise in radiation-hardened circuits for satellite communication systems is random and does not correlate with particular switching patterns on the buses. A further source of faults is manufacturing defects. In nanotechnology, circuits are manufactured with a significant proportion of faults, and occasional errors may be unavoidable. Hence, preventive techniques are insufficient, and active error correction is required. Various researchers have proposed coding techniques to encode data on a bus for crosstalk avoidance [6,17,28], for low power dissipation [3,15,19,22,26], and for error correction [1,8]. Coding schemes that simultaneously satisfy two of these three criteria have also been investigated: · crosstalk avoidance and low power dissipation [12,27]; · crosstalk avoidance and error correction [14]; and · low power dissipation and error correction [2,16,18].

Table 1 Types of worst crosstalk couplings Type-1 Type-2 001  110 011  100 Center wire in opposite transition to an adjacent wire. The other wire in same transition as center wire Type-3 001  010 010  100 011  101 101  110 Center wire in opposite transition to an adjacent wire. The other wire maintains previous state Type-4

0  1 Single wire undergoes transition. Adjacent wires maintain previous states

010  101 All three adjacent wires undergo opposite transitions

123

Optimal low-power coding for crosstalk avoidance

481

Despite many efforts, the only families of optimal codes known are those for low power dissipation [3]. Many of the results on the comparative performance of existing codes are based on simulations rather than rigorous mathematical analysis. In this paper, we begin the study of codes for UDSM buses that simultaneously provide for low power dissipation, crosstalk avoidance, and error correction. In particular, we exhibit the first infinite families of such codes that are provably optimal. The paper is organized as follows. Section 2 establishes necessary terminology and gives a mathematical formulation of the problem of designing low-power codes that avoid crosstalks and correct errors. In Sect. 3, we present the relation of codes of each type with packing sampling plans avoiding adjacent units. In Sect. 4, we focus on optimal solutions for k = 3 for all positive integer n . In Sect. 5, the sizes of optimal codes of all types with small lengths are determined by computer search, and brief conclusion is given.

2 Background
2.1 Coding framework
A coding framework for data buses was introduced by Ramprasad et al. [15]. A bus interconnecting two embedded systems on a systems-on-chip (SoC) platform can be modelled generically as in Fig. 1. The source encoder (decoder) compresses (decompresses) the input data so that the number of bits required in the representation of the source is minimised. While the source encoder removes redundancy, the channel encoder adds redundancy to combat errors that may arise due to noise in the bus. Ramprasad et al. [15] considered various combinations of source-channel encoder-decoder pairs and presented simulation results for their power dissipation. Their approach is what is known as joint source-channel coding in the information theory literature. Shannon's information separation theorem [20] states that reliable transmission can be accomplished by separate source and channel coding, where the source encoder and decoder need not take into account the channel statistics and the channel encoder and decoder need not take into account the source statistics. This applies, however, only for point-to-point transmissions and for infinite sequence length. The first condition (point-to-point transmission) holds for a UDSM bus but the second requirement for infinite sequence length is clearly undesirable for bus coding, because it could give rise to circuits of unbounded delay. Moreover, joint source-channel coding is useful only when we know the statistics of the source and channel. In the absence of such statistics, one can only fall back on optimising the source and channel separately. Indeed, Ramprasad et al. [15] considered coding schemes and simulations on certain source data with better understood statistics (for example, pop music, classical music, video, and speech).

noisy channel
source encoder channel encoder channel decoder source decoder

transmitter
Fig. 1 Framework for systems-on-chip

receiver

123

482

Y. M. Chee et al.

In many systems, the behaviour of source data is hard to predict and so the joint sourcechannel coding approach loses its power. Many researchers have therefore fallen back on addressing the source coding and channel coding problems separately. This is also the approach taken in this paper. We focus on designing optimal channel coding schemes for the scenario where the source statistics are unknown.

2.2 Codes
The Hamming n -space is the set H(n ) = {0, 1}n , endowed with the (Hamming) distance dH (·, ·) defined as follows: for u, v  H(n ), dH (u, v) is the number of positions where u and v differ. The (Hamming) weight of a vector u  H(n ) is the number of positions in u with nonzero value, and is denoted wH (u). The i th component of u is denoted ui . The support of a vector u  H(n ), denoted supp(u), is the set {i : ui = 1}. A (binary) code of length n is a subset C  H(n ). C is said to be of constant weight w if wH (u) = w for all u  C . The elements of a code are called codewords and the size of a code is the number of codewords it contains. The support of C is supp(C ) = {supp(u) : u  C }. The minimum distance of C is dmin (C ) = min{dH (u, v) : u, v  C and u = v}. A constant-weight code of length n , minimum distance d , and weight w is denoted as an (n , d , w) code. A code that is capable of correcting any occurrence of e or fewer symbol errors is said to be e-error-correcting. A code C is e-error-correcting if and only if dmin (C )  2e + 1 [9].

2.3 Set systems and graphs
For integers i < j , the set {i , i + 1, . . . , j } is abbreviated as [i , j ]. We further abbreviate [1, j ] to [ j ]. For a finite set X and k  | X |, we define 2 X = { B : B  X }, and X k = { B  X : | B | = k }.

A set system is a pair S = ( X , B), where X is a finite set of points and B  2 X . The elements of B are called blocks. The order of S is the number of points, | X |, and the size of S is the number of blocks, |B|. A set system ( X , B) is said to be k -uniform if B  X k .A graph is a 2-uniform set system and it is common to refer to the points and blocks of a graph as vertices and edges, respectively. A path of length n is an alternating sequence of vertices and edges W = v0 , e1 , v1 , e2 , . . . , en , vn , such that all the vertices vi , i  [0, n ] and edges ei , i  [n ] are all distinct from one another, except possibly the first and last vertices. A cycle is a path in which the first and last vertices are the same. Let ( X , B) be a set system of order n . The incidence vector of a block B  B is the vector ( B )  H(n ) such that 1, if i  B ( B )i = 0, otherwise. There is a natural correspondence between the Hamming n -space and the complete set system ( X , 2 X ): the positions of vectors in H(n ) correspond to points in X , a vector u  H(n ) corresponds to the block supp(u), and dH (u, v) = |(supp(u) \ supp(v))  (supp(v) \ supp(u))|. From this, it follows that there is a bijection between the set of all codes of length n and the set of all set systems of order n . An (n , k , )-packing is a k -uniform set system ( X , B) with | X | = n such that every element of X 2 is contained in at most  blocks of B . Let D (n , k , ) denote the largest size among all (n , k , )-packings. The leave graph of ( X , B) is the multigraph ( X , E ), where E

123

Optimal low-power coding for crosstalk avoidance

483

contains each e  X 2 exactly  - d (e) times, where d (e) is the number of blocks containing e. When  = 1, we omit  in the notation; in this case, the leave is a simple graph. When the leave contains no edges, the packing is a balanced incomplete block design. The balanced sampling plan avoiding adjacent units (BSA) was introduced to design sampling plans that exclude contiguous units in statistical experiments [10,25]; for more recent work, see [7,29]. In statistical applications, in a circular or linear order of the elements, elements that are "close" do not appear together, while those more distant all appear the same number of times together. A (circular) BSA (n , k ; ) is an (n , k , )-packing ( X , B) with X = Zn whose leave graph consists of all the edges {i , j } with i - j  ±1, . . . , ± (mod n ), and every other pair appears in  blocks. A (linear) LBSA (n , k ; ) is an (n , k , )-packing ( X , B) with X = [0, n - 1] whose leave graph consists of all the edges {i , j } with 0  i < j < n for which j - i   , and every other pair appears in  blocks. We employ these only when  = 1, and so omit  in the notation. We generalize circular and linear BSAs (with  = 1) to a packing sampling plan avoiding adjacent units (PSA). A (circular) CPSA(n , k ; ) is an (n , k )-packing ( X , B) with X = Zn whose leave graph contains all the edges {i , j } with i - j  ±1, . . . , ± (mod n ), and every other pair appears in at most one block. A (linear) LPSA(n , k ; ) is an (n , k )-packing ( X , B) with X = [0, n - 1] whose leave graph contains all the edges {i , j } with 0  i < j < n for which j - i   , and every other pair appears in at most one block. (In this case, every CPSA(n , k ; ) is an LPSA(n , k ; ) but the converse need not hold.) Let B (n , k ; ) denote the largest size of any LPSA(n , k ; ); the LPSA is optimal if its size is B (n , k ; ). Similarly, let B  (n , k ; ) denote the largest size of any CPSA(n , k ; ); the CPSA is optimal if its size is B  (n , k ; ). Let U (n , k ; ) =
2
 -1 i =0 n - -i -1 k -1

+(n -2) k

n -2 -1 k -1

.

Lemma 2.1 B (n , k ; )  U (n , k ; ). Proof For an LPSA(n , k ; ) constructed on [0, n - 1], for each i  [0,  - 1], the points i  -i -1 and n - 1 - i appear in at most n -k blocks, and all the other points appear in at most -1
n -2 -1 k -1

blocks. Then k B (n , k ; )  2

 -1 i =0

n - -i -1 k -1

+ (n - 2)

n -2 -1 k -1

.

When  = 1, we omit it in the notation. If there is an (n , k )-packing with leave graph containing a path of length n - 1, we can always relabel the points to get an LPSA(n , k ). Corollary 2.2 B (n , k ) 
2
n -2 k -1

+(n -2) k

n -3 k -1

.

Theorem 4.1 shows that when k = 3, this inequality is tight.

2.4 Problem formulation
Limited weight codes have been widely exploited for the case of on-chip communication to achieve crosstalk coupling elimination and energy efficiency [12,23]. We consider an n bit parallel bus in a single metal layer, for which we want memoryless codes to weaken crosstalk, reduce power consumption, and correct errors. We use constant weight codes with small weight to achieve low power similarly by reducing the node switching activity, that is, reducing the total number of transitions occurring between the newly arrived data and the present data on the bus.

123

484

Y. M. Chee et al.

Assume an n -bit bus, consisting of signals b0 , b1 , b2 , . . . , bn -1 . Consider a group of three wires in an on-chip bus, which are driven by signals bi -1 , bi and bi +1 . The delay and energy consumption are primarily affected by transition patterns based on the bus signals bi -1 , bi and bi +1 as the crosstalk patterns in Table 1. The selection of codeword does not depend on previous history, so the environment is memoryless. Consequently coding must address the possibility that any two codewords can appear one after the other. Therefore to avoid crosstalk and correct errors, we are interested in constant weight codes of length n , weight w and minimum distance d  3 satisfying the condition that there do not exist three consecutive coordinates i - 1, i , i + 1 such that the crosstalk couplings of type-2 (or -3, -4) occur in any two different codewords. We denote such a code avoiding crosstalk of each type as an (n , d , w)-II (or -III, -IV) code. The maximum size of these codes are denoted as A I I (n , d , w) (or A I I I (n , d , w), A I V (n , d , w)), and any code achieving this size is optimal. When S  { I I , I I I , I V }, the maximum size of a code that is simultaneously an (n , d , w)- S code for each S  S is denoted by AS (n , d , w). When d = 2w , the following results are straightforward. Lemma 2.3 For all positive integers n and w ,
n ; (i) A I I (n , 2w, w) = A I V (n , 2w, w) = w n I I I (ii) A (n , 2w, w) = w when w = 1; A I I I (n , 2, 1) = n +1 2

.

n is an upper bound on the size of the desired code in each case. Proof The quantity s = w We construct codes of size s as follows. The code with support

{{i , s + i , 2s + i , . . . , (w - 1)s + i } : i  [0, s - 1]} is an optimal (n , 2w, w)-II code. The code with support {{wi , 1 + wi , . . . , (w - 1) + wi } : i  [0, s - 1]} is an optimal (n , 2w, w)-IV code, and an optimal (n , 2w, w)-III code when w = 1. When 1 w = 1, the code with support {{2i } : i  [0, n - 2 ]} is an optimal (n , 2, 1)-III code. Next we show there is close connection between (n , 2k - 2, k ) codes of each type and optimal LPSA(n , k )s. Hence, optimal codes are constructed based on the construction of optimal LPSA(n , k )s.

3 Codes and LPSA(n, k; )s
In this section, we establish connections between optimal LPSA(n , k ; )s and the codes of each type. We begin with optimal (n , 2k - 2, k )-II codes for sufficiently large n . Theorem 3.1 Let k  3. Then A I I (n , 2k - 2, k )  B (n , k ). Further, if B (n , k ) = U (n , k ) and n  3k 2 + 2k - 3, then A I I (n , 2k - 2, k ) = B (n , k ). Proof Whenever ( X , B) is an LPSA(n , k ), the code with support B is an (n , 2k - 2, k )-II code. Now suppose that ( X , B) is an optimal LPSA(n , k ) of size U (n , k ). We prove that U (n , k ) is the largest possible size of an (n , 2k - 2, k )-II code. Assume that D is an (n , 2k - 2, k )-II code of size M . Partition the code into three parts as follows. The first part A contains all codewords with at least one segment "11". Because n > k , for each codeword in A, there always exist three adjacent coordinates such that "110" or "011"

123

Optimal low-power coding for crosstalk avoidance

485

appears in these coordinates. Let S = {i : u  A, s.t.,u has "110 in coordinates i - 2, i - 1, i , or "011" in coordinates i , i + 1, i + 2}, and let s = | S |. For each i  S , there exist at most two codewords in A that have "110" in i - 2, i - 1, i or "011" in i , i + 1, i + 2. Hence | A|  2 s . The second part T  D \ A contains all codewords with "1" in at least one coordinate in S . Without loss of generality, if there exists a codeword in A with "110" in the coordinates i - 2, i - 1, i for some i , then the codewords in T with "1" in i must have segment "101" in these coordinates to avoid type-2 crosstalk. Because dmin (D) = 2k - 2, there is only one such codeword. So for each i  S , there is at most one codeword in T with "1" in i . Hence |T |  s . Finally, let C = D \ (A  T ). Then M = |A| + |T | + |C |. Because each codeword in C has "0" in all coordinates in S , we can shorten C to a code C by deleting all coordinates in S . Then C is an (n - s , 2k - 2, k ) code, and supp(C ) is an (n - s , k )-packing. The shortening process partitions the coordinates of C into at most s + 1 classes, separated in C by the coordinates deleted to form C . No codeword of C has "11" in consecutive coordinates of any single class. Let x be the number of isolated coordinates in this partition, and m be the number of classes with at least two coordinates; then x + m  s + 1. We now estimate the size of C using the packing. s -1 s -2 s -3 Let a0 = n - , a1 = n - , a2 = n - . Then we have: k -1 k -1 k -1 | C | = |C |  x · a0 + 2m · a1 + (n - s - 2m - x ) · a2 . k    

Because x - y - 1  x - y  x - y , we have:   x n -s -1 - n -s -3 + 2m n -s -2 - n -s -3 + (n - s ) n -s -3  k -1 k -1 k -1 k -1 k -1 M  3s +  k   2 1 n -s -3  x   k -1 + 1 + 2m k -1 + 1 + (n - s ) k -1   3s +  k      2(s + 1) + (n - s ) n -s -3   2 x + 2m + (n - s ) n -s -3      k -1 k -1   3s +  .  3s +  k k Let F (s ) = 3s +
2(s +1)+(n -s ) k
n -s -3 k -1

. We claim that because n  3k 2 + 2k - 3,
n -s -3 k -1

U (n , k )  maxs [1,n ] F (s ). Because F (s ) = 3s +
2(s +2)+(n -s -1) k
n -s -4 k -1

2(s +1)+(n -s ) k
n -s -4 k -1

and F (s + 1) = 3(s + 1) +
n -s -4 k -1

, we have

-2

k

-3  F (s )- F (s +1)  n - 2k - s . k-1

+n -s -2 k

-2. Further, we have: n - 3k 2 - 1 - s k (k - 1)  F (s ) - F (s + 1) 

So when s  n - 3k 2 - 1, F (s ) - F (s + 1)  0, i.e., F (s ) is decreasing; and when s  n - 2k , F (s ) - F (s + 1)  0, i.e., F (s ) is increasing. When s  [n - 3k 2 , n - 2k - 1],

123

486

Y. M. Chee et al.

F (s )  F (1); because the verification is tedious, we omit it here. We therefore only need to compare F (1) and F (n ) to find the maximum value of F (s ).    4 + (n - 1) n -4  2  k -1   - 3n - 2(n + 1)  (n - 1)(n - 3k - 1) . F (1) - F (n ) = 3 +  k k k (k - 1)

Because n  3k 2 + 2k - 3  3k 2 + 1, F (1)  F (n ) and maxs [1,n ] F (s ) = F (1).    2 n -2 + (n - 2) n -3 - 4 - (n - 1) n -4   k -1 k -1 k -1  -3 U (n , k ) - F (1)   k    n -2 + (n - 1) n -3 - 4 - (n - 1) n -4   k -1 k -1 k -1  -3  k    n -2 - 4  2  k -1   - 3  n - 3k - 2 k + 3  0 .  k k (k - 1)

Hence U (n , k )  maxs [1,n ] F (s ). For (n , 2k - 2, k )-III codes and (n , 2k - 2, k )-IV codes, we establish lower bounds. Lemma 3.2 1. A I I I (n , 2k - 2, k )  A I I , I I I , I V (n , 2k - 2, k )  D ( n -1 2. A I I I (n , 4, 3)  A I I , I I I , I V (n , 4, 3)  B ( n 2 , 3) + 2 . n I I I I I , I I I , I V  3. A (n , 4, 3)  A (n , 4, 3)  B ( 2 , 3) + n 2 .
n 2

, k ).

Proof For the first inequality, take an ( n 2 , k )-packing ( X , B ), and construct a code C of n length n 2 by taking supp(C ) = B . View C as an |B | × 2 array. When n  1 (mod 2), we add one column of all zeroes between every two consecutive columns of C , and when n  0 (mod 2) we add one further column of all zeroes after C to get an (n , 2k - 2, k )-III code. The verification is straightforward, because every second column is all zeroes. The construction for the second is similar. Apply the same inflation to an LPSA n 2 ,3 of size B n 2 , 3 to obtain a code C1 . In every codeword of C1 , two 1s are separated by three (or more) coordinates, and different codewords cannot have 1s in adjacent coordinates. Now 1 form code C2 , consisting of all codewords with support {2i , 2i + 1, 2i + 2} for 0  i < n - 2 . No prohibited situation arises from 000 or 111 in three consecutive coordinates of a codeword. In consecutive coordinates in which two codewords of C2 are neither 000 nor 111, the two codewords contain 011 and 110, which is permitted. So we consider one codeword from 1 C1 and one from C2 . The coordinates with indices in {2i + 1 : 0  i < n - 2 } appear in only one codeword, which is {2i , 2i + 1, 2i + 2}. So in the consecutive coordinates in which two such codewords are neither 000 nor 111, and are not equal, the two codewords contain {001, 100}, {010, 011}, or {010, 110}. All are permitted. The bound in the third case is equal to that in the second unless n is even and B  n 2 ,3 = B n C and C as in the second case; one further , 3 . When both occur, use a CPSA to form 1 2 2 codeword can be added with support {0, n - 2, n - 1}.

123

Optimal low-power coding for crosstalk avoidance

487

Lemma 3.3 A I V (n , 2k - 2, k )  B (n , k ). Proof Take an LPSA(n , k ) ( X , B) of size B (n , k ). Apply to the points in [0, n - 1] the permutation i  2i , if i < n /2 , and i  2i - 2 n /2 + 1, if i  n /2 , to get ( X , B ). The code C with supp(C ) = B is an (n , 2k - 2, k )-IV code. We give another construction for an (n , 2k - 2, k )-IV code from an optimal LPSA(n , k ; k - 1). When k = 3, this construction gives a better lower bound than Lemma 3.3. Lemma 3.4 Let k  3. 1. A I I , I V (n , 2k - 2, k )  B (n , k ; k - 1), 2. A I V (n , 2k - 2, k )  B (n , k ; k - 1) + 3. A I V (n , 2k - 2, k )  B  (n , k ; k - 1) +
n -1 k -1 n k -1

, and .

-1 Proof Let s = n k -1 , and ( X , B ) be an LPSA(n , k ; k - 1) of size B (n , k ; k - 1). Then the code C with supp(C ) = { B : B  B} is an (n , 2k - 2, k )-II code and an (n , 2k - 2, k )-IV code. Further, the code C with supp(C ) = { B : B  B}{{(k -1)i , (k -1)i +1, . . . , (k -1)i +k -1} : i  [0, s - 1]} is an (n , 2k - 2, k )-IV code. When n  0 (mod k - 1), statement (3) is implied by statement (2). So suppose that n  0 (mod k - 1). Using instead a CPSA(n , k ; k - 1) of size B  (n , k ; k - 1), adjoin the block {(k - 1)s , (k - 1)s + 1, . . . , (k - 1)s + k - 2, 0}.

Lemma 3.5 A I I , I V (n , 4, 3)  U (n , 3; 2) when n  13. Proof Computational results reported in Table 2 show that A I I , I V (13, 4, 3) = U (13, 3; 2) = 16, A I I , I V (14, 4, 3) = U (14, 3; 2) = 20, A I I , I V (15, 4, 3) = U (15, 3; 2) = 25, and
Table 2 Sizes of optimal codes for n  20 n D (n , 3) B (n , 3) B  (n , 3) B (n , 3; 2) B  (n , 3; 2) A I I .(n , 4, 3) A I I I (n , 4, 3) A I V (n , 4, 3) A I I , I I I (n , 4, 3) A I I , I V (n , 4, 3) A I I I , I V (n , 4, 3) A I I , I I I , I V (n , 4, 3) 3 1 0 0 0 0 1 1 1 1 1 1 1 4 1 0 0 0 0 1 1 1 1 1 1 1 5 2 1 0 0 0 2 2 2 2 2 2 2 6 4 2 2 0 0 4 3 4 3 4 3 3 7 7 4 3 1 0 5 4 6 3 4 4 3 8 8 6 5 2 0 6 5 7 4 4 5 4 9 12 9 9 4 3 9 6 10 5 7 6 5 10 13 10 10 6 5 10 7 12 6 8 7 6 11 17 14 13 9 8 14 8 15 7 12 8 7 12 20 16 16 12 12 16 9 19 8 13 9 8 13 26 21 20 16 15 21 10 23 10 16 10 10 14 28 24 23 20 18 15 35 30 30 25 25 16 37 32 32 28 26 17 44 39 38 34 34 18 48 42 42 37 36 19 57 50 49 45 43 20 60 54 53 48 46

24
11

30
13

32
14

39
17

42
18

50
19

54
21

26
11 20 11 11

32
13 25 13 13

35
13 28 14 13

42
17 34 17 17

45
18 37 18 18

54
19 45 19 19

57
20 48 21 20

Lower bounds and exact values

123

488

Y. M. Chee et al.

A I I , I V (16, 4, 3) = U (16, 3; 2) = 32. Suppose to the contrary that A I I , I V (n , 4, 3) > U (n , 3; 2) for some n  17, and let n be the smallest such value. When n  17 we have U (n , 3; 2)  U (n - 1, 3; 2) + 3 and U (n , 3; 2)  U (n - 3, 3; 2) + 4. (See Table 2 for small values.) Let ( X , B) be the support of an (n , 4, 3)-{II,IV} code of size A I I , I V (n , 4, 3). Some triple of B covers a pair of the form {a , b}  {{i , i + 1}, {i , i + 2}} because it is not an LPSA(n , 3; 2). Case 1 Some element appears in at most one triple. Suppose that element i appears in no triple. Shorten the code by deleting coordinate i and delete the triples (if any) containing pairs {i - 1, i + 1}, {i - 2, i + 1}, and {i - 1, i + 2}. The result is a type II and IV code, so the given code has at most A I I , I V (n - 1, 4, 3) + 3 triples, a contradiction. Suppose now that element i appears in exactly one triple T . Then if i  {0, n - 1}, delete coordinate i and triple T to get a contradiction. If i  {1, n - 2}, delete coordinate i and delete triple T , along with triples containing {0, 2} and {0, 3} when i = 1 or {n - 4, n - 1} and {n - 3, n - 1}, to get a contradiction. So 2  i  n -3. If T contains neither i -1 nor i +1, then no triple contains both i - 1 and i + 1, because the code is type IV. Shorten by deleting coordinate i and delete triple T and the triples (if any) containing pairs {i - 2, i + 1} and {i - 1, i + 2}, yielding a contradiction. Otherwise, without loss of generality T also contains i - 1 but does not contain i + 1. But then if some triple T contains i - 2 and i + 1, it cannot contain i . If T does not also contain i - 1, then we have T  {i - 1, i , i + 1} = {i - 1, i } and T  {i - 1, i , i + 1} = {i + 1}, which cannot happen in a type II code. So T = {i - 2, i , i + 1}. Hence there are at most two triples among those containing pairs {i - 1, i + 1}, {i - 2, i + 1}, and {i - 1, i + 2}, so shorten as before. Case 2 Some triple T satisfies |T  {i , i + 1, i + 2}| = 2 for some 0  i  n - 3. Suppose that {a , b} = T  {i , i + 1, i + 2} and let {c} = {i , i + 1, i + 2} \ {a , b}. There can be no triple containing c but neither a nor b, because the code is type II and type IV. So c is in exactly two triples, T that contains a and T that contains b; only T contains both a and b. Applying the same argument to T and T , a and b each appear in exactly two triples. So there are only three triples (T , T , and T ) that contain a , b, or c. Shorten by deleting coordinate i + 1 and the triples T , T , and T to obtain a contradiction. Case 3 No triple T satisfies |T  {i , i + 1, i + 2}| = 2 for any 0  i  n - 3. If a triple T satisfies |T  {i , i + 1, i + 2}| = 3 for some 0  i  n - 3, equivalently it satisfies |T  {i + 1, i + 2, i + 3}| = 2 for some 0  i  n - 4 or |T  {i - 1, i , i + 1}| = 2 for some 1  i  n - 3. Apply Case 2. Otherwise every triple T satisfies |T  {i , i + 1, i + 2}|  1 for 0  i  n - 3. But then ( X , B) is an LPSA(n , 3; 2) and hence we have at most B (n , 3; 2)  U (n , 3; 2) triples, the final contradiction.

4 Optimal packing sampling plans
By Corollary 2.2, we have the upper bound:
n -2 2

U (n , 3) =

2

+ (n - 2) 3

n -3 2

 2 n -4n +4  ,  6    n 2 -3n , 6 = n2 - 4n   6 ,   2  n -3n -4 ,
6

if n  2 (mod 6), if n  3 (mod 6), if n  0, 4 (mod 6), if n  1, 5 (mod 6).

Theorem 4.1 B (n , 3) = U (n , 3) for all n  0.

123

Optimal low-power coding for crosstalk avoidance

489

(n -1) -4(n -1)+4 3n 3 blocks, we get an LPSA(n - 1, 3) of size n - - n- by removing 6 2 = 6 the point n - 1 and all blocks containing it, which is optimal. When n  1, 5 (mod 6), Colbourn and Rosa [4] showed there exists an (n , 3)-packing of 2 n +2 size n -3 , whose leave graph consists of a cycle of length n - 1 and one isolated point. 6 Assume n - 1 is the isolated point. Remove the block {x , n - 2, n - 1} for some x  [0, n - 3]; 3 the result is an optimal LPSA(n , 3). Now, n - 1 appears in n - 2 blocks. Removing n - 1 and all blocks containing it from the optimal LPSA(n , 3) constructed above, we obtain an 2 (n -1)2 -4(n -1) n -4 3 LPSA(n - 1, 3) of size n -3 - n- , which is optimal. 6 2 = 6 n -3 2
2 2

Proof When n  3 (mod 6), Colbourn and Rosa [4] (and Colbourn and Ling [5]) construct 2 3n a BSA(n , 3) of size n - 6 , which is an optimal LPSA(n , 3). Because each point appears in

Theorem 4.2 1. B  (n , 3) = U (n , 3) when n  0, 3, 4 (mod 6). 2. B  (n , 3) = U (n , 3) - 1 when n  1, 2, 5 (mod 6).
-3) blocks when n  Proof The constructions in Theorem 4.1 yield a CPSA(n , 3) with n (n6 n (n -4) 3 (mod 6) and with 6 blocks when n  0, 4 (mod 6). A CPSA(n , 3) can have at most n n -3 blocks, which equals U (n , 3) when n  0, 3, 4 (mod 6), so these are optimal. 3 2 n -3 When n  2 (mod 6), n = U (n , 3) - 1 so B  (n , 3)  U (n , 3) - 1. When 3 2

n  1, 5 (mod 6), if there were a CPSA(n , 3) with U (n , 3) =
n (n -1) 2 3(n 2 -3n -4)

n 2 -3n -4 6

codewords, then the

- = n + 2. The leave must be an number of edges in the leave graph is 6 n -cycle with two additional edges, but every vertex in the leave must have even degree, which cannot occur. So B  (n , 3)  U (n , 3) - 1. To establish equality when n  1, 2, 5 (mod 6), remove the block {0, n - 1, x } from an LPSA(n , 3) from Theorem 4.1. Lemma 4.3 B  (n , 3; 2) = B (n , 3; 2) = U (n , 3; 2) whenever n  3, 5 (mod 6) and n  15. B  (n , 3; 2) + 2 = B (n , 3; 2) = U (n , 3; 2) whenever n  2, 4 (mod 6) and n  14. Proof Zhang and Chang [30] establish that whenever n  15 and n  3, 5 (mod 6), there is a -5) BSA(n , 3; 2) having n (n6 blocks; this is also an optimal CPSA(n , 3; 2) and LPSA(n , 3; 2). Now suppose that n  14 and n  2, 4 (mod 6). When n  2 (mod 6), writing n = 6t + 2, U (6t + 2, 3; 2) = (2t )(3t - 1). Delete element 6t + 2 from a BSA(6t + 3, 3; 2) with (2t + 1)(3t - 1) blocks, removing 3t - 1 blocks to obtain an LPSA(6t + 2, 3; 2), which is therefore optimal. When n  4 (mod 6), writing n = 6t + 4, U (6t + 4, 3; 2) = t (6t + 2). Delete element 6t + 4 from a BSA(6t + 5, 3; 2) with t (6t + 5) blocks, removing 3t blocks to obtain an LPSA(6t + 4, 3; 2), which is therefore optimal. Remove the blocks {0, n - 2, x }, {1, n - 1, y } for some x and y from the optimal LPSA(n , 3; 2) constructed above to obtain an optimal CPSA(n , 3; 2) when n  2, 4 (mod 6). For n = 6t , U (6t , 3) = 6t (t - 1) + 1, and
6t +1 3 6t -4 2 6t 3 6t -5 2

= 6t (t - 1). For n = 6t + 1,

U (6t +1, 3) = t (6t -3), and = t (6t -3)-1. However, if a CPSA(6t +1, 3; 2) were to have t (6t - 3) - 1 blocks, its leave must have 2(6t + 1) + 1 edges and every such graph with minimum degree 4 has two vertices of degree 5. Because all vertices in the leave must have even degree, no CPSA(6t + 1, 3; 2) can exist with more than t (6t - 3) - 2 blocks. We provide bounds to apply when n  0, 1 (mod 6). Lemma 4.4 B (2n , 3; 2)  4 B (n , 3), and B (2n + 1, 3; 2)  4 B (n , 3) + n - 2. In addition, B  (2n , 3; 2)  4 B  (n , 3), and B  (2n + 1, 3; 2)  4 B  (n , 3) + n - 3.

123

490

Y. M. Chee et al.

Proof Start with an LPSA(n , 3) on [0, n - 1]. We form an LPSA(2n , 3; 2) on [0, 2n - 1]. For each block {a , b, c} in the LPSA, form four blocks {{2a + , 2b + , 2c +  } : , ,   {0, 1},  +  +   0 (mod 2)}. The verification is straightforward. To form an LPSA(2n + 1, 3) on [0, 2n ], adjoin {{2i , 2i + 3, 2n } : 0  i  n - 3}. The construction for CPSAs is the same, except that one does not adjoin {0, 3, 2n }.

5 Conclusion
Applying Theorem 3.1 with the results in Theorem 4.1, we have optimal (n , 4, 3)-II codes for all n  30. By computer search (using cliquer [13] and hill-climbing (a variant of [24])), we determined the sizes of optimal LPSA(n , 3; )s, CPSA(n , 3; )s, and (n , 4, 3) codes of lengths n  20. The sizes are listed in Table 2 and corresponding optimal codes are available from the authors; those in slanted font are lower bounds from Theorem 3.1 and Lemma 3.4. In this paper, we present the first memoryless transition bus-encoding technique for power minimization, error-correcting and elimination of crosstalk simultaneously. We establish the connection between codes avoiding crosstalk of each type with packing sampling plans avoiding adjacent units. Optimal codes of each type are constructed.

References
1. Bertozzi D., Benini L., de Micheli G.: Low power error resilient encoding for on-chip data buses. In: DATE'02: Proceedings of the Conference on Design. Automation and Test in Europe, pp. 102­109. IEEE Computer Society, Washington, DC (2002). 2. Bertozzi D. Benini L., Ricco B.: Energy-efficient and reliable low-swing signaling for on-chip buses based on redundant coding. In: ISCAS'02: Proceedings of the IEEE International Symposium on Circuits and Systems, vol. 1, pp. 93­96. IEEE Press, Piscataway, NJ (2002). 3. Chee Y.M., Colbourn C.J., Ling A.C.H.: Optimal memoryless encoding for low power off-chip data buses. In: ICCAD'06: Proceedings of the 2006 IEEE/ACM International Conference on Computer-Aided Design, pp. 369­374. ACM Press, New York (2006). 4. Colbourn C.J., Rosa A.: Quadratic leaves of maximal partial triple systems. Graphs Comb. 2(4), 317­337 (1986). 5. Colbourn C.J., Ling A.C.H.: A class of partial triple systems with applications in survey sampling. Commun. Stat. Theory Methods 27(4), 1009­1018 (1998). 6. Duan C., Tirumala A., Khatri S.P.: Analysis and avoidance of crosstalk in on-chip buses. In: Hot Interconnects'01: Proceedings of the 9th Annual Symposium on High-Performance Interconnects, pp. 133­138. IEEE, Piscataway (2001). 7. Dukes P.J., Ling A.C.H.: Existence of balanced sampling plans avoiding cyclic distances. Metrika 70, 131­140 (2009). 8. Favalli M., Metra C.: Bus crosstalk fault-detection capabilities of error-detecting codes for on-line testing. IEEE Trans. Very Large Scale Integr. Syst. 7, 392­396 (1999). 9. Hamming R.W.: Error detecting and error correcting codes. Bell Syst. Tech. J. 29(2), 147­160 (1950). 10. Hedayat A.S., Rao C.R., Stufken J.: Sampling plans excluding contiguous units. J. Stat. Plan. Inference 19(2), 159­170 (1988). 11. Ho R.: On-chip wires: Scaling and efficiency, Ph.D. dissertation, Department of Electrical Engineering, Stanford University, Palo Alto, CA (2003). 12. Khan Z., Arslan T., Erdogan A.T.: A dual low-power and crosstalk immune encoding scheme for systemon-chip buses. In: PATMOS'04: Proceedings of the 14th International Workshop on Power and Timing Modeling, Optimization and Simulation. Lecture Notes in Computer Science, vol. 3254, pp. 585­592. Springer, Berlin (2004). 13. Niskanen S., Östergård P.R.J.: Cliquer User's Guide, Version 1.0, Communications Laboratory, Helsinki University of Technology, Espoo. Tech. Rep. T48, (2003). 14. Patel K.N., Markov I.L.: Error-correction and crosstalk avoidance in DSM busses. IEEE Trans. Very Large Scale Integr. Syst. 12(10), 1076­1080 (2004).

123

Optimal low-power coding for crosstalk avoidance

491

15. Ramprasad S., Shanbhag N.R., Hajj I.N.: A coding framework for low-power address and data busses. IEEE Trans. Very Large Scale Integr. (VLSI) Syst. 7, 212­221 (1999). 16. Rossi D., van Dijk E.S., Kleihorst R.P., Nieuwland A.K., Metra C.: Coding scheme for low energy consumption fault-tolerant bus. In: IOLTW'02: Proceedings of the Eighth IEEE International On-Line Testing Workshop, pp. 8­12. IEEE Computer Society, Washington, DC (2002). 17. Rossi D., Cavallotti S., Metra C.: Error correcting codes for crosstalk effect minimization. In: DFT'03: Proceedings of the 18th IEEE International Symposium on Defect and Fault-Tolerance in VLSI Systems, pp. 257­266. IEEE Computer Society, Washington, DC (2003). 18. Rossi D., van Dijk E.S., Kleihorst R.P., Nieuwland, A.K., Metra, C.: Power consumption of fault tolerant codes: the active elements. In IOLTW'03: Proceedings of the Ninth IEEE International On-line Testing Workshop, pp. 61­67. IEEE Computer Society, Washington, DC (2003). 19. Samala N.K., Radhakrishnan D., Izadi B.: A novel deep sub-micron bus coding for low energy. In: ESA'04: Proceedings of the International Conference on Embedded Systems and Applications, pp. 25­30. CSREA Press, Leuven (2004). 20. Shannon C.E.: A mathematical theory of communications, Bell Syst. Tech. J. 27(3), 379­423, 623­656 (1948). 21. Sotiriadis P.P., Chandrakasan A.: Bus energy minimization by transition pattern coding (TPC) in deep sub-micron technologies. In: ICCAD'00--Proceedings of the 2000 IEEE/ACM International Conference on Computer-Aided Design, pp. 322­327. IEEE, Piscataway, NJ (2000). 22. Stan M.R., Burleson W.P.: Bus-invert coding for low-power I/O. IEEE Trans. Very Large Scale Integr. Syst. 3(1), 49­58 (1995). 23. Stan M.R., Burleson W.P.: Coding a terminated bus for low power. In: Great Lakes Symposium VLSI, pp. 70­73, Buffalo, NY (1995). 24. Stinson D.R.: Hill-climbing algorithms for the construction of combinatorial designs. In: Algorithms in Combinatorial Design Theory. Annals of Discrete Mathematics, vol. 26, pp. 321­334. Elsevier, NorthHolland (1985). 25. Stufken J.: Combinatorial and statistical aspects of sampling plans to avoid the selection of adjacent units. J. Comb. Inf. Syst. Sci. 18(1­2), 149­160 (1993). 26. Su C.L., Tsui C.Y., Despain A.M.: Saving power in the control path of embedded processors. IEEE Des. Comput. 11, 24­30 (1994). 27. Subrahmanya P., Manimegalai R., Kamakoti V., Mutyam M.: A bus encoding technique for power and cross-talk minimization. In: VLSI Design 2004: 17th International Conference on VLSI Design, pp. 443­448. IEEE Computer Society, Xi'an (2004). 28. Victor B., Keutzer K.: Bus encoding to prevent crosstalk delay. In: ICCAD'01--Proceedings of the 2001 IEEE/ACM International Conference on Computer-Aided Design, pp. 57­63. IEEE, Piscataway, NJ (2001). 29. Wright J.H., Stufken J.: New balanced sampling plans excluding adjacent units. J. Stat. Plan. Inference 138, 3326­3335 (2008). 30. Zhang J., Chang Y.X.: The spectrum of BSA(v, 3, ; ) with  = 2, 3. J. Comb. Des. 15, 61­76 (2007).

123

