Des. Codes Cryptogr. (2015) 77:479–491
DOI 10.1007/s10623-015-0084-4

Optimal low-power coding for error correction
and crosstalk avoidance in on-chip data buses
Yeow Meng Chee1 · Charles J. Colbourn2 ·
Alan Chi Hung Ling3 · Hui Zhang1 · Xiande Zhang1

Received: 30 October 2014 / Revised: 12 April 2015 / Accepted: 16 April 2015 /
Published online: 8 May 2015
© Springer Science+Business Media New York 2015

Abstract Coupled switched capacitance causes crosstalk in ultra deep submicron/nanometer
VLSI fabrication, which leads to power dissipation, delay faults, and logical malfunctions. We
present the first memoryless transition bus-encoding technique for power minimization, errorcorrection, and elimination of crosstalk simultaneously. To accomplish this, we generalize
balanced sampling plans avoiding adjacent units, which are widely used in the statistical
design of experiments. Optimal or asymptotically optimal constant weight codes eliminating
each kind of crosstalk are constructed.
Keywords Constant weight codes · Packing sampling plan avoiding adjacent units ·
Crosstalk avoidance · Low power code · Packing by triples · Balanced sampling plan
Mathematics Subject Classification

94B25 · 05B40 · 05B07 · 62K10

This is one of several papers published in Designs, Codes and Cryptography comprising the “Special Issue
on Cryptography, Codes, Designs and Finite Fields: In Memory of Scott A. Vanstone”.

B

Charles J. Colbourn
charles.colbourn@asu.edu
Yeow Meng Chee
ymchee@ntu.edu.sg
Alan Chi Hung Ling
aling@emba.uvm.edu
Hui Zhang
huizhang@ntu.edu.sg
Xiande Zhang
xiandezhang@ntu.edu.sg

1

Division of Mathematical Sciences, School of Physical and Mathematical Sciences,
Nanyang Technological University, Singapore 637371, Singapore

2

School of Computing, Informatics, and Decision Systems Engineering,
Arizona State University, Tempe, AZ 85287, USA

3

Department of Computer Science, University of Vermont, Burlington, VT 05405, USA

123

480

Y. M. Chee et al.

1 Introduction
The ever-decreasing feature size of VLSI fabrication process has led to many challenges in
VLSI circuit design. One of the most important issues concerns the characteristics of onchip wires [11]. The wires’ cross-sectional areas and spacings have fallen dramatically with
the move into the ultra deep submicron/nanometer (UDSM) regime. This has increased the
resistance and capacitance of wires. To help reduce resistance, wires today are taller than
they are wide, and they are poised to grow even taller as technology continues to scale.
The resulting growth of side-to-side capacitance between long parallel wires causes coupled
switch capacitance to dominate the wire-to-substrate capacitance in UDSM circuits by several
orders of magnitude [21]. Coupled switched capacitance in turn leads to crosstalks, which
result in power dissipation, delay faults, and logical malfunctions. The problem of eliminating
or minimising crosstalks is considered the biggest signal integrity challenge for long on-chip
buses implemented in UDSM CMOS technology [12].
The worst crosstalk couplings have been classified into four types [6,12], as described in
Table 1. The coupled switched capacitance resulting from type-1, -2, -3, and -4 crosstalks is
in the ratio of 1:2:3:4. Hence, it is particularly important to avoid crosstalks of higher types.
Type-1 crosstalks cannot be avoided in any useful communication channel. However, type-1
crosstalks give rise to power dissipation and must be limited, because low power is a critical
design objective in recent years.
Another factor that has emerged as a new challenge for VLSI circuit designers is UDSM
noise, caused by high-leakage transistors, power-grid fluctuations, ground bounce, IR drops,
clock jitter, and electromagnetic radiation. The effects of such noise are difficult to predict
or prevent. For example, noise in radiation-hardened circuits for satellite communication
systems is random and does not correlate with particular switching patterns on the buses.
A further source of faults is manufacturing defects. In nanotechnology, circuits are manufactured with a significant proportion of faults, and occasional errors may be unavoidable.
Hence, preventive techniques are insufficient, and active error correction is required.
Various researchers have proposed coding techniques to encode data on a bus for crosstalk
avoidance [6,17,28], for low power dissipation [3,15,19,22,26], and for error correction
[1,8]. Coding schemes that simultaneously satisfy two of these three criteria have also been
investigated:
• crosstalk avoidance and low power dissipation [12,27];
• crosstalk avoidance and error correction [14]; and
• low power dissipation and error correction [2,16,18].

Table 1 Types of worst crosstalk couplings
Type-1

Type-2

Type-3

Type-4

0 ←→ 1

001 ←→ 110
011 ←→ 100

001 ←→ 010
010 ←→ 100
011 ←→ 101
101 ←→ 110

010 ←→ 101

Single wire undergoes
transition. Adjacent
wires maintain previous states

Center wire in opposite
transition to an adjacent wire.
The other wire in same transition as center wire

Center wire in opposite
transition to an adjacent
wire. The other wire maintains previous state

123

All three adjacent
wires undergo opposite transitions

Optimal low-power coding for crosstalk avoidance

481

Despite many efforts, the only families of optimal codes known are those for low power
dissipation [3]. Many of the results on the comparative performance of existing codes are
based on simulations rather than rigorous mathematical analysis.
In this paper, we begin the study of codes for UDSM buses that simultaneously provide
for low power dissipation, crosstalk avoidance, and error correction. In particular, we exhibit
the first infinite families of such codes that are provably optimal.
The paper is organized as follows. Section 2 establishes necessary terminology and gives a
mathematical formulation of the problem of designing low-power codes that avoid crosstalks
and correct errors. In Sect. 3, we present the relation of codes of each type with packing
sampling plans avoiding adjacent units. In Sect. 4, we focus on optimal solutions for k = 3
for all positive integer n. In Sect. 5, the sizes of optimal codes of all types with small lengths
are determined by computer search, and brief conclusion is given.

2 Background
2.1 Coding framework
A coding framework for data buses was introduced by Ramprasad et al. [15]. A bus interconnecting two embedded systems on a systems-on-chip (SoC) platform can be modelled
generically as in Fig. 1. The source encoder (decoder) compresses (decompresses) the input
data so that the number of bits required in the representation of the source is minimised. While
the source encoder removes redundancy, the channel encoder adds redundancy to combat
errors that may arise due to noise in the bus.
Ramprasad et al. [15] considered various combinations of source-channel encoder-decoder
pairs and presented simulation results for their power dissipation. Their approach is what
is known as joint source-channel coding in the information theory literature. Shannon’s
information separation theorem [20] states that reliable transmission can be accomplished
by separate source and channel coding, where the source encoder and decoder need not take
into account the channel statistics and the channel encoder and decoder need not take into
account the source statistics. This applies, however, only for point-to-point transmissions
and for infinite sequence length. The first condition (point-to-point transmission) holds for
a UDSM bus but the second requirement for infinite sequence length is clearly undesirable
for bus coding, because it could give rise to circuits of unbounded delay. Moreover, joint
source-channel coding is useful only when we know the statistics of the source and channel.
In the absence of such statistics, one can only fall back on optimising the source and channel
separately. Indeed, Ramprasad et al. [15] considered coding schemes and simulations on
certain source data with better understood statistics (for example, pop music, classical music,
video, and speech).

noisy channel
source
encoder

channel
encoder

transmitter

channel
decoder

source
decoder

receiver

Fig. 1 Framework for systems-on-chip

123

482

Y. M. Chee et al.

In many systems, the behaviour of source data is hard to predict and so the joint sourcechannel coding approach loses its power. Many researchers have therefore fallen back on
addressing the source coding and channel coding problems separately. This is also the
approach taken in this paper. We focus on designing optimal channel coding schemes for the
scenario where the source statistics are unknown.

2.2 Codes
The Hamming n-space is the set H(n) = {0, 1}n , endowed with the (Hamming) distance
dH (·, ·) defined as follows: for u, v ∈ H(n), dH (u, v) is the number of positions where u and
v differ. The (Hamming) weight of a vector u ∈ H(n) is the number of positions in u with
nonzero value, and is denoted wH (u). The ith component of u is denoted ui . The support of
a vector u ∈ H(n), denoted supp(u), is the set {i : ui = 1}.
A (binary) code of length n is a subset C ⊆ H(n). C is said to be of constant weight w if
wH (u) = w for all u ∈ C . The elements of a code are called codewords and the size of a code
is the number of codewords it contains. The support of C is supp(C ) = {supp(u) : u ∈ C }. The
minimum distance of C is dmin (C ) = min{dH (u, v) : u, v ∈ C and u  = v}. A constant-weight
code of length n, minimum distance d, and weight w is denoted as an (n, d, w) code.
A code that is capable of correcting any occurrence of e or fewer symbol errors is said to
be e-error-correcting. A code C is e-error-correcting if and only if dmin (C ) ≥ 2e + 1 [9].

2.3 Set systems and graphs
For integers i < j, the set {i, i + 1, . . . , j} is abbreviated as [i, j]. We further abbreviate
[1, j] to [ j]. For a finite set X and k ≤ |X |, we define
 
X
X
2 = {B : B ⊆ X }, and
= {B ⊆ X : |B| = k}.
k
A set system is a pair S = (X, B), where X is a finite set of points and B ⊆ 2 X . The
elements of B are called blocks. The order of S is the number of points, |X |, and the size
 of
S is the number of blocks, |B|. A set system (X, B) is said to be k-uniform if B ⊆ Xk . A
graph is a 2-uniform set system and it is common to refer to the points and blocks of a graph
as vertices and edges, respectively. A path of length n is an alternating sequence of vertices
and edges W = v0 , e1 , v1 , e2 , . . . , en , vn , such that all the vertices vi , i ∈ [0, n] and edges
ei , i ∈ [n] are all distinct from one another, except possibly the first and last vertices. A cycle
is a path in which the first and last vertices are the same.
Let (X, B) be a set system of order n. The incidence vector of a block B ∈ B is the vector
ι(B) ∈ H(n) such that

1, if i ∈ B
ι(B)i =
0, otherwise.
There is a natural correspondence between the Hamming n-space and the complete set system
(X, 2 X ): the positions of vectors in H(n) correspond to points in X , a vector u ∈ H(n)
corresponds to the block supp(u), and dH (u, v) = |(supp(u)\supp(v))∪(supp(v)\supp(u))|.
From this, it follows that there is a bijection between the set of all codes of length n and the
set of all set systems of order n.
An (n, k,
is a k-uniform set system (X, B) with |X | = n such that every

 λ)-packing
element of X2 is contained in at most λ blocks of B. Let D(n, k, λ) denote the largest size
among all (n, k, λ)-packings. The leave graph of (X, B) is the multigraph (X, E), where E

123

Optimal low-power coding for crosstalk avoidance

483

 
contains each e ∈ X2 exactly λ − d(e) times, where d(e) is the number of blocks containing
e. When λ = 1, we omit λ in the notation; in this case, the leave is a simple graph. When the
leave contains no edges, the packing is a balanced incomplete block design.
The balanced sampling plan avoiding adjacent units (BSA) was introduced to design
sampling plans that exclude contiguous units in statistical experiments [10,25]; for more
recent work, see [7,29]. In statistical applications, in a circular or linear order of the elements,
elements that are “close” do not appear together, while those more distant all appear the same
number of times together. A (circular) BSAλ (n, k; α) is an (n, k, λ)-packing (X, B) with X =
Zn whose leave graph consists of all the edges {i, j} with i − j ≡ ±1, . . . , ±α (mod n), and
every other pair appears in λ blocks. A (linear) LBSAλ (n, k; α) is an (n, k, λ)-packing (X, B)
with X = [0, n − 1] whose leave graph consists of all the edges {i, j} with 0 ≤ i < j < n
for which j − i ≤ α, and every other pair appears in λ blocks. We employ these only when
λ = 1, and so omit λ in the notation.
We generalize circular and linear BSAs (with λ = 1) to a packing sampling plan avoiding
adjacent units (PSA). A (circular) CPSA(n, k; α) is an (n, k)-packing (X, B) with X = Zn
whose leave graph contains all the edges {i, j} with i − j ≡ ±1, . . . , ±α (mod n), and every
other pair appears in at most one block. A (linear) LPSA(n, k; α) is an (n, k)-packing (X, B)
with X = [0, n − 1] whose leave graph contains all the edges {i, j} with 0 ≤ i < j < n
for which j − i ≤ α, and every other pair appears in at most one block. (In this case, every
CPSA(n, k; α) is an LPSA(n, k; α) but the converse need not hold.) Let B(n, k; α) denote
the largest size of any LPSA(n, k; α); the LPSA is optimal if its size is B(n, k; α). Similarly,
let B ◦ (n, k; α) denote the largest size of any CPSA(n, k; α); the CPSA is optimal if its size
is B ◦ (n, k; α).

	


	


Let U (n, k; α) =

2

α−1
i=0

n−α−i−1
k−1

+(n−2α)

n−2α−1
k−1

k

.

Lemma 2.1 B(n, k; α) ≤ U (n, k; α).
Proof For an LPSA(n, k; α) constructed
on
	

 [0, n − 1], for each i ∈ [0, α − 1], the points i
n−α−i−1
and n − 1 − i appear in at most
blocks, and all the other points appear in at most
k−1
	


	


α−1 	 n−α−i−1 

n−2α−1
blocks. Then k B(n, k; α) ≤ 2 i=0
+ (n − 2α) n−2α−1
.


k−1
k−1
k−1
When α = 1, we omit it in the notation. If there is an (n, k)-packing with leave graph
containing a path of length n − 1, we can always relabel the points to get an LPSA(n, k).
 	 

	


Corollary 2.2 B(n, k) ≤

2

n−2
k−1

+(n−2)
k

n−3
k−1

.

Theorem 4.1 shows that when k = 3, this inequality is tight.

2.4 Problem formulation
Limited weight codes have been widely exploited for the case of on-chip communication
to achieve crosstalk coupling elimination and energy efficiency [12,23]. We consider an nbit parallel bus in a single metal layer, for which we want memoryless codes to weaken
crosstalk, reduce power consumption, and correct errors. We use constant weight codes with
small weight to achieve low power similarly by reducing the node switching activity, that is,
reducing the total number of transitions occurring between the newly arrived data and the
present data on the bus.

123

484

Y. M. Chee et al.

Assume an n-bit bus, consisting of signals b0 , b1 , b2 , . . . , bn−1 . Consider a group of three
wires in an on-chip bus, which are driven by signals bi−1 , bi and bi+1 . The delay and energy
consumption are primarily affected by transition patterns based on the bus signals bi−1 , bi
and bi+1 as the crosstalk patterns in Table 1.
The selection of codeword does not depend on previous history, so the environment is
memoryless. Consequently coding must address the possibility that any two codewords can
appear one after the other. Therefore to avoid crosstalk and correct errors, we are interested
in constant weight codes of length n, weight w and minimum distance d ≥ 3 satisfying the
condition that there do not exist three consecutive coordinates i − 1, i, i + 1 such that the
crosstalk couplings of type-2 (or -3, -4) occur in any two different codewords.
We denote such a code avoiding crosstalk of each type as an (n, d, w)-II (or -III, -IV)
code. The maximum size of these codes are denoted as A I I (n, d, w) (or A I I I (n, d, w),
A I V (n, d, w)), and any code achieving this size is optimal. When S ⊆ {I I, I I I, I V }, the
maximum size of a code that is simultaneously an (n, d, w)-S code for each S ∈ S is denoted
by AS (n, d, w).
When d = 2w, the following results are straightforward.
Lemma 2.3 For all positive integers n and w,
 
(i) A I I (n, 2w, w) = A I V (n, 2w, w) = wn ;




(ii) A I I I (n, 2w, w) = wn when w  = 1; A I I I (n, 2, 1) = n+1
2 .
 
Proof The quantity s = wn is an upper bound on the size of the desired code in each case.
We construct codes of size s as follows. The code with support
{{i, s + i, 2s + i, . . . , (w − 1)s + i} : i ∈ [0, s − 1]}
is an optimal (n, 2w, w)-II code. The code with support
{{wi, 1 + wi, . . . , (w − 1) + wi} : i ∈ [0, s − 1]}
is an optimal (n, 2w, w)-IV code, and an optimal

(n, 2w, w)-III code when w  = 1. When
w = 1, the code with support {{2i} : i ∈ [0, n−1


2 ]} is an optimal (n, 2, 1)-III code.
Next we show there is close connection between (n, 2k − 2, k) codes of each type and
optimal LPSA(n, k)s. Hence, optimal codes are constructed based on the construction of
optimal LPSA(n, k)s.

3 Codes and LPSA(n, k; α)s
In this section, we establish connections between optimal LPSA(n, k; α)s and the codes of
each type. We begin with optimal (n, 2k − 2, k)-II codes for sufficiently large n.
Theorem 3.1 Let k ≥ 3. Then A I I (n, 2k − 2, k) ≥ B(n, k). Further, if B(n, k) = U (n, k)
and n ≥ 3k 2 + 2k − 3, then A I I (n, 2k − 2, k) = B(n, k).
Proof Whenever (X, B) is an LPSA(n, k), the code with support B is an (n, 2k−2, k)-II code.
Now suppose that (X, B) is an optimal LPSA(n, k) of size U (n, k). We prove that U (n, k)
is the largest possible size of an (n, 2k − 2, k)-II code. Assume that D is an (n, 2k − 2, k)-II
code of size M. Partition the code into three parts as follows.
The first part A contains all codewords with at least one segment “11”. Because n > k, for
each codeword in A, there always exist three adjacent coordinates such that “110” or “011”

123

Optimal low-power coding for crosstalk avoidance

485

appears in these coordinates. Let S = {i : ∃u ∈ A, s.t.,u has “110 in coordinates i − 2, i −
1, i, or “011” in coordinates i, i + 1, i + 2}, and let s = |S|. For each i ∈ S, there exist at
most two codewords in A that have “110” in i − 2, i − 1, i or “011” in i, i + 1, i + 2. Hence
|A| ≤ 2s.
The second part T ⊆ D \ A contains all codewords with “1” in at least one coordinate in
S. Without loss of generality, if there exists a codeword in A with “110” in the coordinates
i − 2, i − 1, i for some i, then the codewords in T with “1” in i must have segment “101”
in these coordinates to avoid type-2 crosstalk. Because dmin (D) = 2k − 2, there is only one
such codeword. So for each i ∈ S, there is at most one codeword in T with “1” in i. Hence
|T | ≤ s.
Finally, let C = D \ (A ∪ T ). Then M = |A| + |T | + |C |. Because each codeword in C
has “0” in all coordinates in S, we can shorten C to a code C  by deleting all coordinates in
S. Then C  is an (n − s, 2k − 2, k) code, and supp(C  ) is an (n − s, k)-packing.
The shortening process partitions the coordinates of C  into at most s +1 classes, separated
in C by the coordinates deleted to form C  . No codeword of C  has “11” in consecutive
coordinates of any single class. Let x be the number of isolated coordinates in this partition,
and m be the number of classes with at least two coordinates; then x + m ≤ s + 1. We now
estimate the 	
size of C
 using the




	 packing.
	
n−s−2
n−s−3
Let a0 = n−s−1
,
a
,
a
. Then we have:
=
=
1
2
k−1
k−1
k−1


x · a0 + 2m · a1 + (n − s − 2m − x) · a2

| C | = |C | ≤
.
k
Because x − y − 1 ≤ x − y ≤ x − y, we have:

 	


	

 	


	

⎥
⎢ 	
⎢ x n−s−1 − n−s−3 +2m n−s−2 − n−s−3 + (n − s) n−s−3 ⎥
⎥
⎢
k−1
k−1
k−1
k−1
k−1
⎦
M ≤ 3s + ⎣
k



	



	

⎥
⎢ 	
2
1
n−s−3 ⎥
⎢x
+
1
+
2m
+
1
+
(n
−
s)
⎢
⎥
k−1
k−1
k−1
⎦
≤ 3s + ⎣
k
	
	

⎥

⎥
⎢
⎢
⎢ 2(s + 1) + (n − s) n−s−3 ⎥
⎢ 2x + 2m + (n − s) n−s−3 ⎥
⎢
⎢
⎥
⎥
k−1
k−1
⎦ ≤ 3s + ⎣
⎦.
≤ 3s + ⎣
k
k

Let F(s) = 3s +

	
2(s+1)+(n−s)

Because F(s) = 3s +


	
2(s+2)+(n−s−1)
k

n−s−4
k−1




. We claim that because n ≥ 3k 2 + 2k − 3,

k

U (n, k) ≥ maxs∈[1,n] F(s).


n−s−3
k−1



	
2(s+1)+(n−s)

, we have

	

n−s−3
k−1

k
n−s−4
k−1

k




−2






and F(s + 1) = 3(s + 1) +
	




−3 ≤ F(s)−F(s+1) ≤

n−s−4
k−1

+n−s−2

k

−2. Further, we have:




n − 2k − s
n − 3k 2 − 1 − s
≤ F(s) − F(s + 1) ≤
.
k(k − 1)
k−1
So when s ≤ n − 3k 2 − 1, F(s) − F(s + 1) ≥ 0, i.e., F(s) is decreasing; and when
s ≥ n − 2k, F(s) − F(s + 1) ≤ 0, i.e., F(s) is increasing. When s ∈ [n − 3k 2 , n − 2k − 1],

123

486

Y. M. Chee et al.

F(s) ≤ F(1); because the verification is tedious, we omit it here. We therefore only need to
compare F(1) and F(n) to find the maximum value of F(s).
	

⎥
⎢
⎢ 4+(n − 1) n−4 ⎥

 

2
⎢
k−1 ⎥
⎦ − 3n − 2(n +1) ≥ (n − 1)(n − 3k − 1) .
F(1) − F(n) = 3+ ⎣
k
k
k(k − 1)

Because n ≥ 3k 2 + 2k − 3 ≥ 3k 2 + 1, F(1) ≥ F(n) and maxs∈[1,n] F(s) = F(1).


	


	

⎥
⎢ 	
⎢ 2 n−2 + (n − 2) n−3 − 4 − (n − 1) n−4 ⎥
⎢ k−1
k−1
k−1 ⎥
⎦−3
U (n, k) − F(1) ≥ ⎣
k


	


	

⎥
⎢	
⎢ n−2 + (n − 1) n−3 − 4 − (n − 1) n−4 ⎥
⎢ k−1
k−1
k−1 ⎥
⎦−3
≥⎣
k


⎢	
⎥
⎢ n−2 − 4 ⎥


2
⎢ k−1
⎥
⎦ − 3 ≥ n − 3k − 2k + 3 ≥ 0.
≥⎣
k
k(k − 1)

Hence U (n, k) ≥ maxs∈[1,n] F(s).




For (n, 2k − 2, k)-III codes and (n, 2k − 2, k)-IV codes, we establish lower bounds.
 
Lemma 3.2 1. A I I I (n, 2k − 2, k) ≥ A I I,I I I,I V (n, 2k − 2, k) ≥ D( n2 , k).


2. A I I I (n, 4, 3) ≥ A I I,I I I,I V (n, 4, 3) ≥ B( n2 , 3) +  n−1
2 .
 
3. A I I I (n, 4, 3) ≥ A I I,I I I,I V (n, 4, 3) ≥ B ◦ ( n2 , 3) +  n2 .
n
Proof For
 n the first inequality, take an ( 2 , k)-packing (X,
 B), and construct a code C of
length 2 by taking supp(C ) = B. View C as an |B| × n2 array. When n ≡ 1 (mod 2),
we add one column of all zeroes between every two consecutive columns of C , and when
n ≡ 0 (mod 2) we add one further column of all zeroes after C to get an (n, 2k − 2, k)-III
code. The verification is straightforward, because every second column is all zeroes.
  
The construction for the second is similar. Apply the same inflation to an LPSA n2 , 3
  
of size B n2 , 3 to obtain a code C1 . In every codeword of C1 , two 1s are separated by three
(or more) coordinates, and different codewords cannot have 1s in adjacent coordinates. Now
form code C2 , consisting of all codewords with support {2i, 2i +1, 2i +2} for 0 ≤ i <  n−1
2 .
No prohibited situation arises from 000 or 111 in three consecutive coordinates of a codeword.
In consecutive coordinates in which two codewords of C2 are neither 000 nor 111, the two
codewords contain 011 and 110, which is permitted. So we consider one codeword from
C1 and one from C2 . The coordinates with indices in {2i + 1 : 0 ≤ i <  n−1
2 } appear in
only one codeword, which is {2i, 2i + 1, 2i + 2}. So in the consecutive coordinates in which
two such codewords are neither 000 nor 111, and are not equal, the two codewords contain
{001, 100}, {010, 011}, or {010, 110}. All are permitted.
 n 
◦
2 ,3 =
 The
 n bound
 in the third case is equal to that in the second unless n is even and B
B 2 , 3 . When both occur, use a CPSA to form C1 and C2 as in the second case; one further
codeword can be added with support {0, n − 2, n − 1}.



123

Optimal low-power coding for crosstalk avoidance

487

Lemma 3.3 A I V (n, 2k − 2, k) ≥ B(n, k).
Proof Take an LPSA(n, k) (X, B) of size B(n, k). Apply to the points in [0, n − 1] the
permutation

i → 2i, if i < n/2, and
i → 2i − 2n/2 + 1, if i ≥ n/2,
to get (X, B ). The code C  with supp(C  ) = B is an (n, 2k − 2, k)-IV code.




We give another construction for an (n, 2k−2, k)-IV code from an optimal LPSA(n, k; k−
1). When k = 3, this construction gives a better lower bound than Lemma 3.3.
Lemma 3.4 Let k ≥ 3.
1. A I I,I V (n, 2k − 2, k) ≥ B(n, k; k − 1),	


2. A I V (n, 2k − 2, k) ≥ B(n, k; k − 1) + n−1
, and
	k−1 

n
I
V
◦
3. A (n, 2k − 2, k) ≥ B (n, k; k − 1) + k−1 .


	
Proof Let s = n−1
k−1 , and (X, B ) be an LPSA(n, k; k − 1) of size B(n, k; k − 1). Then the
code C with supp(C ) = {B : B ∈ B} is an (n, 2k −2, k)-II code and an (n, 2k −2, k)-IV code.
Further, the code C with supp(C ) = {B : B ∈ B}∪{{(k−1)i, (k−1)i +1, . . . , (k−1)i +k−1} :
i ∈ [0, s −1]} is an (n, 2k −2, k)-IV code. When n  ≡ 0 (mod k − 1), statement (3) is implied
by statement (2). So suppose that n ≡ 0 (mod k − 1). Using instead a CPSA(n, k; k − 1) of
size B ◦ (n, k; k − 1), adjoin the block {(k − 1)s, (k − 1)s + 1, . . . , (k − 1)s + k − 2, 0}. 

Lemma 3.5 A I I,I V (n, 4, 3) ≤ U (n, 3; 2) when n ≥ 13.
Proof Computational results reported in Table 2 show that A I I,I V (13, 4, 3) = U (13, 3; 2) =
16, A I I,I V (14, 4, 3) = U (14, 3; 2) = 20, A I I,I V (15, 4, 3) = U (15, 3; 2) = 25, and
Table 2 Sizes of optimal codes for n ≤ 20
n

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

D (n, 3)

1

1

2

4

7

8

12

13

17

20

26

28

35

37

44

48

57

60

B (n, 3)

0

0

1

2

4

6

9

10

14

16

21

24

30

32

39

42

50

54

B ◦ (n, 3)

0

0

0

2

3

5

9

10

13

16

20

23

30

32

38

42

49

53

B (n, 3; 2)

0

0

0

0

1

2

4

6

9

12

16

20

25

28

34

37

45

48

B ◦ (n, 3; 2)

0

0

0

0

0

0

3

5

8

12

15

18

25

26

34

36

43

46

A I I .(n, 4, 3)

1

1

2

4

5

6

9

10

14

16

21

24

30

32

39

42

50

54

A I I I (n, 4, 3)

1

1

2

3

4

5

6

7

8

9

10

11

13

14

17

18

19

21

A I V (n, 4, 3)

1

1

2

4

6

7

10

12

15

19

23

26

32

35

42

45

54

57

A I I,I I I (n, 4, 3)

1

1

2

3

3

4

5

6

7

8

10

11

13

13

17

18

19

20

A I I,I V (n, 4, 3)

1

1

2

4

4

4

7

8

12

13

16

20

25

28

34

37

45

48

A I I I,I V (n, 4, 3)

1

1

2

3

4

5

6

7

8

9

10

11

13

14

17

18

19

21

A I I,I I I,I V (n, 4, 3)

1

1

2

3

3

4

5

6

7

8

10

11

13

13

17

18

19

20

Lower bounds and exact values

123

488

Y. M. Chee et al.

A I I,I V (16, 4, 3) = U (16, 3; 2) = 32. Suppose to the contrary that A I I,I V (n, 4, 3) >
U (n, 3; 2) for some n ≥ 17, and let n be the smallest such value. When n ≥ 17 we have
U (n, 3; 2) ≥ U (n − 1, 3; 2) + 3 and U (n, 3; 2) ≥ U (n − 3, 3; 2) + 4. (See Table 2 for small
values.)
Let (X, B) be the support of an (n, 4, 3)-{II,IV} code of size A I I,I V (n, 4, 3). Some triple
of B covers a pair of the form {a, b} ∈ {{i, i +1}, {i, i +2}} because it is not an LPSA(n, 3; 2).
Case 1 Some element appears in at most one triple. Suppose that element i appears in no
triple. Shorten the code by deleting coordinate i and delete the triples (if any) containing
pairs {i − 1, i + 1}, {i − 2, i + 1}, and {i − 1, i + 2}. The result is a type II and IV code, so
the given code has at most A I I,I V (n − 1, 4, 3) + 3 triples, a contradiction. Suppose now that
element i appears in exactly one triple T . Then if i ∈ {0, n − 1}, delete coordinate i and triple
T to get a contradiction. If i ∈ {1, n − 2}, delete coordinate i and delete triple T , along with
triples containing {0, 2} and {0, 3} when i = 1 or {n − 4, n − 1} and {n − 3, n − 1}, to get a
contradiction. So 2 ≤ i ≤ n−3. If T contains neither i −1 nor i +1, then no triple contains both
i −1 and i +1, because the code is type IV. Shorten by deleting coordinate i and delete triple T
and the triples (if any) containing pairs {i −2, i +1} and {i −1, i +2}, yielding a contradiction.
Otherwise, without loss of generality T also contains i − 1 but does not contain i + 1. But
then if some triple T  contains i − 2 and i + 1, it cannot contain i. If T  does not also contain
i − 1, then we have T ∩ {i − 1, i, i + 1} = {i − 1, i} and T  ∩ {i − 1, i, i + 1} = {i + 1},
which cannot happen in a type II code. So T  = {i − 2, i, i + 1}. Hence there are at most
two triples among those containing pairs {i − 1, i + 1}, {i − 2, i + 1}, and {i − 1, i + 2}, so
shorten as before.
Case 2 Some triple T satisfies |T ∩ {i, i + 1, i + 2}| = 2 for some 0 ≤ i ≤ n − 3. Suppose
that {a, b} = T ∩ {i, i + 1, i + 2} and let {c} = {i, i + 1, i + 2} \ {a, b}. There can be no triple
containing c but neither a nor b, because the code is type II and type IV. So c is in exactly two
triples, T  that contains a and T  that contains b; only T contains both a and b. Applying the
same argument to T  and T  , a and b each appear in exactly two triples. So there are only
three triples (T , T  , and T  ) that contain a, b, or c. Shorten by deleting coordinate i + 1 and
the triples T , T  , and T  to obtain a contradiction.
Case 3 No triple T satisfies |T ∩ {i, i + 1, i + 2}| = 2 for any 0 ≤ i ≤ n − 3. If a triple
T satisfies |T ∩ {i, i + 1, i + 2}| = 3 for some 0 ≤ i ≤ n − 3, equivalently it satisfies
|T ∩ {i + 1, i + 2, i + 3}| = 2 for some 0 ≤ i ≤ n − 4 or |T ∩ {i − 1, i, i + 1}| = 2 for some
1 ≤ i ≤ n − 3. Apply Case 2. Otherwise every triple T satisfies |T ∩ {i, i + 1, i + 2}| ≤ 1 for
0 ≤ i ≤ n − 3. But then (X, B) is an LPSA(n, 3; 2) and hence we have at most B(n, 3; 2) ≤
U (n, 3; 2) triples, the final contradiction.



4 Optimal packing sampling plans
By Corollary 2.2, we have the upper bound:

⎧ 2
n −4n+4
⎪
,
⎪
6
⎪
 




⎪
2 −3n
n−2
n−3
⎨
n
2 2 + (n − 2) 2
6 ,
U (n, 3) =
= n 2 −4n
⎪
3
⎪ 6 ,
⎪
⎪
⎩ n 2 −3n−4 ,
6

Theorem 4.1 B(n, 3) = U (n, 3) for all n ≥ 0.

123

if n ≡ 2 (mod 6),
if n ≡ 3 (mod 6),
if n ≡ 0, 4 (mod 6),
if n ≡ 1, 5 (mod 6).

Optimal low-power coding for crosstalk avoidance

489

Proof When n ≡ 3 (mod 6), Colbourn and Rosa [4] (and Colbourn and Ling [5]) construct
2
a BSA(n, 3) of size n −3n
6 , which is an optimal LPSA(n, 3). Because each point appears in

(n−1) −4(n−1)+4
blocks, we get an LPSA(n − 1, 3) of size n −3n
− n−3
by removing
6
2 =
6
the point n − 1 and all blocks containing it, which is optimal.
When n ≡ 1, 5 (mod 6), Colbourn and Rosa [4] showed there exists an (n, 3)-packing of
2
size n −3n+2
, whose leave graph consists of a cycle of length n − 1 and one isolated point.
6
Assume n −1 is the isolated point. Remove the block {x, n −2, n −1} for some x ∈ [0, n −3];
the result is an optimal LPSA(n, 3). Now, n − 1 appears in n−3
2 blocks. Removing n − 1
and all blocks containing it from the optimal LPSA(n, 3) constructed above, we obtain an
2
(n−1)2 −4(n−1)
LPSA(n − 1, 3) of size n −3n−4
− n−3
, which is optimal.


6
2 =
6
2

2

n−3
2

Theorem 4.2 1. B ◦ (n, 3) = U (n, 3) when n ≡ 0, 3, 4 (mod 6).
2. B ◦ (n, 3) = U (n, 3) − 1 when n ≡ 1, 2, 5 (mod 6).
blocks when n ≡
Proof The constructions in Theorem 4.1 yield a CPSA(n, 3) with n(n−3)
6
blocks
when
n
≡
0,
4
(mod
6).
A
CPSA(n,
3)
can have at most
3 (mod 6) and with n(n−4)
6
 n  n−3 
blocks,
which
equals
U
(n,
3)
when
n
≡
0,
3,
4
(mod
6),
so
these
are optimal.
3
2
 n  n−3 
◦
When n ≡ 2 (mod 6), 3 2
= U (n, 3) − 1 so B (n, 3) ≤ U (n, 3) − 1. When
n ≡ 1, 5 (mod 6), if there were a CPSA(n, 3) with U (n, 3) =
n(n−1)
2

3(n 2 −3n−4)

n 2 −3n−4
6

codewords, then the

−
= n + 2. The leave must be an
number of edges in the leave graph is
6
n-cycle with two additional edges, but every vertex in the leave must have even degree, which
cannot occur. So B ◦ (n, 3) ≤ U (n, 3) − 1. To establish equality when n ≡ 1, 2, 5 (mod 6),
remove the block {0, n − 1, x} from an LPSA(n, 3) from Theorem 4.1.


Lemma 4.3 B ◦ (n, 3; 2) = B(n, 3; 2) = U (n, 3; 2) whenever n ≡ 3, 5 (mod 6) and n ≥
15. B ◦ (n, 3; 2) + 2 = B(n, 3; 2) = U (n, 3; 2) whenever n ≡ 2, 4 (mod 6) and n ≥ 14.
Proof Zhang and Chang [30] establish that whenever n ≥ 15 and n ≡ 3, 5 (mod 6), there is a
BSA(n, 3; 2) having n(n−5)
blocks; this is also an optimal CPSA(n, 3; 2) and LPSA(n, 3; 2).
6
Now suppose that n ≥ 14 and n ≡ 2, 4 (mod 6). When n ≡ 2 (mod 6), writing n = 6t + 2,
U (6t + 2, 3; 2) = (2t)(3t − 1). Delete element 6t + 2 from a BSA(6t + 3, 3; 2) with
(2t + 1)(3t − 1) blocks, removing 3t − 1 blocks to obtain an LPSA(6t + 2, 3; 2), which is
therefore optimal. When n ≡ 4 (mod 6), writing n = 6t + 4, U (6t + 4, 3; 2) = t (6t + 2).
Delete element 6t + 4 from a BSA(6t + 5, 3; 2) with t (6t + 5) blocks, removing 3t blocks to
obtain an LPSA(6t + 4, 3; 2), which is therefore optimal. Remove the blocks {0, n − 2, x},
{1, n − 1, y} for some x and y from the optimal LPSA(n, 3; 2) constructed above to obtain
an optimal CPSA(n, 3; 2) when n ≡ 2, 4 (mod 6).


	 	



For n = 6t, U (6t, 3) = 6t (t − 1) + 1, and 6t3 6t−5
= 6t (t − 1). For n = 6t + 1,
2
 6t+1  6t−4 
U (6t +1, 3) = t (6t −3), and 3
= t (6t −3)−1. However, if a CPSA(6t +1, 3; 2)
2
were to have t (6t − 3) − 1 blocks, its leave must have 2(6t + 1) + 1 edges and every such
graph with minimum degree 4 has two vertices of degree 5. Because all vertices in the leave
must have even degree, no CPSA(6t + 1, 3; 2) can exist with more than t (6t − 3) − 2 blocks.
We provide bounds to apply when n ≡ 0, 1 (mod 6).
Lemma 4.4 B(2n, 3; 2) ≥ 4B(n, 3), and B(2n + 1, 3; 2) ≥ 4B(n, 3) + n − 2. In addition,
B ◦ (2n, 3; 2) ≥ 4B ◦ (n, 3), and B ◦ (2n + 1, 3; 2) ≥ 4B ◦ (n, 3) + n − 3.

123

490

Y. M. Chee et al.

Proof Start with an LPSA(n, 3) on [0, n − 1]. We form an LPSA(2n, 3; 2) on [0, 2n − 1].
For each block {a, b, c} in the LPSA, form four blocks {{2a + α, 2b + β, 2c + γ } : α, β, γ ∈
{0, 1}, α + β + γ ≡ 0 (mod 2)}. The verification is straightforward. To form an LPSA(2n +
1, 3) on [0, 2n], adjoin {{2i, 2i + 3, 2n} : 0 ≤ i ≤ n − 3}.
The construction for CPSAs is the same, except that one does not adjoin {0, 3, 2n}.



5 Conclusion
Applying Theorem 3.1 with the results in Theorem 4.1, we have optimal (n, 4, 3)-II codes for
all n ≥ 30. By computer search (using cliquer [13] and hill-climbing (a variant of [24])),
we determined the sizes of optimal LPSA(n, 3; α)s, CPSA(n, 3; α)s, and (n, 4, 3) codes of
lengths n ≤ 20. The sizes are listed in Table 2 and corresponding optimal codes are available
from the authors; those in slanted font are lower bounds from Theorem 3.1 and Lemma 3.4.
In this paper, we present the first memoryless transition bus-encoding technique for power
minimization, error-correcting and elimination of crosstalk simultaneously. We establish the
connection between codes avoiding crosstalk of each type with packing sampling plans
avoiding adjacent units. Optimal codes of each type are constructed.

References
1. Bertozzi D., Benini L., de Micheli G.: Low power error resilient encoding for on-chip data buses. In:
DATE’02: Proceedings of the Conference on Design. Automation and Test in Europe, pp. 102–109. IEEE
Computer Society, Washington, DC (2002).
2. Bertozzi D. Benini L., Ricco B.: Energy-efficient and reliable low-swing signaling for on-chip buses
based on redundant coding. In: ISCAS’02: Proceedings of the IEEE International Symposium on Circuits
and Systems, vol. 1, pp. 93–96. IEEE Press, Piscataway, NJ (2002).
3. Chee Y.M., Colbourn C.J., Ling A.C.H.: Optimal memoryless encoding for low power off-chip data
buses. In: ICCAD’06: Proceedings of the 2006 IEEE/ACM International Conference on Computer-Aided
Design, pp. 369–374. ACM Press, New York (2006).
4. Colbourn C.J., Rosa A.: Quadratic leaves of maximal partial triple systems. Graphs Comb. 2(4), 317–337
(1986).
5. Colbourn C.J., Ling A.C.H.: A class of partial triple systems with applications in survey sampling.
Commun. Stat. Theory Methods 27(4), 1009–1018 (1998).
6. Duan C., Tirumala A., Khatri S.P.: Analysis and avoidance of crosstalk in on-chip buses. In: Hot Interconnects’01: Proceedings of the 9th Annual Symposium on High-Performance Interconnects, pp. 133–138.
IEEE, Piscataway (2001).
7. Dukes P.J., Ling A.C.H.: Existence of balanced sampling plans avoiding cyclic distances. Metrika 70,
131–140 (2009).
8. Favalli M., Metra C.: Bus crosstalk fault-detection capabilities of error-detecting codes for on-line testing.
IEEE Trans. Very Large Scale Integr. Syst. 7, 392–396 (1999).
9. Hamming R.W.: Error detecting and error correcting codes. Bell Syst. Tech. J. 29(2), 147–160 (1950).
10. Hedayat A.S., Rao C.R., Stufken J.: Sampling plans excluding contiguous units. J. Stat. Plan. Inference
19(2), 159–170 (1988).
11. Ho R.: On-chip wires: Scaling and efficiency, Ph.D. dissertation, Department of Electrical Engineering,
Stanford University, Palo Alto, CA (2003).
12. Khan Z., Arslan T., Erdogan A.T.: A dual low-power and crosstalk immune encoding scheme for systemon-chip buses. In: PATMOS’04: Proceedings of the 14th International Workshop on Power and Timing
Modeling, Optimization and Simulation. Lecture Notes in Computer Science, vol. 3254, pp. 585–592.
Springer, Berlin (2004).
13. Niskanen S., Östergård P.R.J.: Cliquer User’s Guide, Version 1.0, Communications Laboratory, Helsinki
University of Technology, Espoo. Tech. Rep. T48, (2003).
14. Patel K.N., Markov I.L.: Error-correction and crosstalk avoidance in DSM busses. IEEE Trans. Very
Large Scale Integr. Syst. 12(10), 1076–1080 (2004).

123

Optimal low-power coding for crosstalk avoidance

491

15. Ramprasad S., Shanbhag N.R., Hajj I.N.: A coding framework for low-power address and data busses.
IEEE Trans. Very Large Scale Integr. (VLSI) Syst. 7, 212–221 (1999).
16. Rossi D., van Dijk E.S., Kleihorst R.P., Nieuwland A.K., Metra C.: Coding scheme for low energy
consumption fault-tolerant bus. In: IOLTW’02: Proceedings of the Eighth IEEE International On-Line
Testing Workshop, pp. 8–12. IEEE Computer Society, Washington, DC (2002).
17. Rossi D., Cavallotti S., Metra C.: Error correcting codes for crosstalk effect minimization. In: DFT’03:
Proceedings of the 18th IEEE International Symposium on Defect and Fault-Tolerance in VLSI Systems,
pp. 257–266. IEEE Computer Society, Washington, DC (2003).
18. Rossi D., van Dijk E.S., Kleihorst R.P., Nieuwland, A.K., Metra, C.: Power consumption of fault tolerant
codes: the active elements. In IOLTW’03: Proceedings of the Ninth IEEE International On-line Testing
Workshop, pp. 61–67. IEEE Computer Society, Washington, DC (2003).
19. Samala N.K., Radhakrishnan D., Izadi B.: A novel deep sub-micron bus coding for low energy. In: ESA’04:
Proceedings of the International Conference on Embedded Systems and Applications, pp. 25–30. CSREA
Press, Leuven (2004).
20. Shannon C.E.: A mathematical theory of communications, Bell Syst. Tech. J. 27(3), 379–423, 623–656
(1948).
21. Sotiriadis P.P., Chandrakasan A.: Bus energy minimization by transition pattern coding (TPC) in deep
sub-micron technologies. In: ICCAD’00—Proceedings of the 2000 IEEE/ACM International Conference
on Computer-Aided Design, pp. 322–327. IEEE, Piscataway, NJ (2000).
22. Stan M.R., Burleson W.P.: Bus-invert coding for low-power I/O. IEEE Trans. Very Large Scale Integr.
Syst. 3(1), 49–58 (1995).
23. Stan M.R., Burleson W.P.: Coding a terminated bus for low power. In: Great Lakes Symposium VLSI,
pp. 70–73, Buffalo, NY (1995).
24. Stinson D.R.: Hill-climbing algorithms for the construction of combinatorial designs. In: Algorithms in
Combinatorial Design Theory. Annals of Discrete Mathematics, vol. 26, pp. 321–334. Elsevier, NorthHolland (1985).
25. Stufken J.: Combinatorial and statistical aspects of sampling plans to avoid the selection of adjacent units.
J. Comb. Inf. Syst. Sci. 18(1–2), 149–160 (1993).
26. Su C.L., Tsui C.Y., Despain A.M.: Saving power in the control path of embedded processors. IEEE Des.
Comput. 11, 24–30 (1994).
27. Subrahmanya P., Manimegalai R., Kamakoti V., Mutyam M.: A bus encoding technique for power and
cross-talk minimization. In: VLSI Design 2004: 17th International Conference on VLSI Design, pp.
443–448. IEEE Computer Society, Xi’an (2004).
28. Victor B., Keutzer K.: Bus encoding to prevent crosstalk delay. In: ICCAD’01—Proceedings of the
2001 IEEE/ACM International Conference on Computer-Aided Design, pp. 57–63. IEEE, Piscataway,
NJ (2001).
29. Wright J.H., Stufken J.: New balanced sampling plans excluding adjacent units. J. Stat. Plan. Inference
138, 3326–3335 (2008).
30. Zhang J., Chang Y.X.: The spectrum of BSA(v, 3, λ; α) with α = 2, 3. J. Comb. Des. 15, 61–76 (2007).

123

