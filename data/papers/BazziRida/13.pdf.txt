Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Storage capacity of labeled graphs
Dana Angluin1 James Aspnes1 Rida A. Bazzi2
Jiang Chen3 David Eisenstat4 Goran Konjevod2
1 Department
2 Department

of Computer Science, Yale University

of Computer Science and Engineering, Arizona State University
3 Google

4 Department

of Computer Science, Brown University

September 22, 2010
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Capacity of labeled graphs
Effect of graph structure
Information-theoretic vs effective capacity

The basic picture

Network of n anonymous
finite-state machines.
Graph structure is fixed.
State of each machine
⇒ one label per node.
How much information can
we store?

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Capacity of labeled graphs
Effect of graph structure
Information-theoretic vs effective capacity

Structure of the graph matters!

Lots of symmetries:
⇒ can’t tell nodes with
the same label apart
⇒ O(log n) bits are
enough to describe the
state.

Few symmetries:
⇒ most nodes are
distinguishable
⇒ Θ(n) bits are needed
to describe the state.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Capacity of labeled graphs
Effect of graph structure
Information-theoretic vs effective capacity

Information-theoretic vs effective capacity

Information-theoretic capacity =
log (number of distinguishable labelings) = how much space a
program running outside the network can get.
Effective capacity = how much space a program running
inside the network can get.
Information-theoretic capacity ≥ effective capacity.
When are they equal?

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph Turing machines
Effective capacity

Graph Turing machines
Graph Turing machine is like a
regular Turing machine with the
tape replaced by a graph.
Finite-state controller sees
label on current node and
set of labels on adjacent
nodes (without
multiplicities!)
No sense of direction:
controller moves by
choosing a label.
If more than one neighbor
has that label, adversary
chooses which to move to.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph Turing machines
Effective capacity

Graph Turing machines
Graph Turing machine is like a
regular Turing machine with the
tape replaced by a graph.
Finite-state controller sees
label on current node and
set of labels on adjacent
nodes (without
multiplicities!)
No sense of direction:
controller moves by
choosing a label.
If more than one neighbor
has that label, adversary
chooses which to move to.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph Turing machines
Effective capacity

Graph Turing machines
Graph Turing machine is like a
regular Turing machine with the
tape replaced by a graph.
Finite-state controller sees
label on current node and
set of labels on adjacent
nodes (without
multiplicities!)
No sense of direction:
controller moves by
choosing a label.
If more than one neighbor
has that label, adversary
chooses which to move to.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph Turing machines
Effective capacity

Graph Turing machines: formal version
Input: Graph G and initial vertex v0 .
Specification: Tuple (Σ, Q, q0 , δ) where
Σ is the label set,
Q is the state space for the controller,
q0 is the initial state, and
δ : Q × Σ × P(Σ) → (Q ∪ {qaccept , qreject }) × Σ × Σ is the
transition function.

Transitions:
Let δ(q, `(v ), {`(v 0 )|(v , v 0 ) ∈ E }) = (q 0 , s, t).
q ← q0.
`(v ) ← s.
Move controller to some v 0 where `(v 0 ) = t.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph Turing machines
Effective capacity

Effective capacity
Idea: Measure capacity by size of the largest ordinary Turing
machine we can simulate.
Problem: Not well-defined for a single graph (can put as
much storage as we like in the controller).
Effective capacity is defined for classes of graphs G.
A class G has effective capacity f (G ) if:
For any standard Turing machine M,
There is a graph Turing machine M 0 , such that
For any graph G in G and vertex v0 of G ,
M 0 (G , v0 ) simulates M running on a blank tape with f (G )
cells.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Tool: graph traversal
Subroutine allows controller to visit every node in the graph.
Basic idea: use depth-first
search, storing stack in
graph itself.
But stack may get tangled
up.
Solution: Assign a layer
number mod 3 to each node
using breadth-first search.
(Itkis and Levin, 1994).
DFS now only considers
children in next layer.
Total time is O(n).
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Graph traversal
Counting in unary

Every graph has effective capacity Ω(log n)
Count from 0 to n by storing values in unary, with one bit per
node.
Each of these operations takes one graph traversal:
c ← c/2
Change every other 1 to a 0.
c ←c −1
Find a 1 and change it to 0.
c ←c +1
Find a 0 and change it to 1.
?

c=0

Traverse the graph looking for a 1.
?

c mod 2 = 0 Sum up all bits mod 2.
Doubling can be accomplished in quadratic time by repeatedly
adding 2 to a second counter.
This gives an O(log n)-bit counter in any graph.
⇒ (Minsky, 1967) Any graph can simulate an O(log n)-space
Turing machine.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Capacity of lines is Θ(n)

Use a mod-3 slope to orient the line.
Now we have an ordinary Turing machine.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Capacity of trees

Information-theoretic capacity
varies from
Θ(log n) for stars, to
Θ(n) for lines.
We’d like to get the same values
for effective capacity.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Information-theoretic capacity
Recursively ranking a rooted tree:
Group subtrees into
isomorphism classes.
Convert each subtree
labeling into a number: this
gives a multiset for each
equivalence class.
Multisets + root → rank for
whole tree.
Information-theoretic capacity =
log(number of possible ranks) =
log2 (31200) ≈ 14.93.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Extracting the information-theoretic capacity
Increment operation:
Find lowest-valued
subtree in rightmost
isomorphism class that is
not maxed out.
Increment it.
Reset less-significant
subtrees to zero.

All of this can be done using
finite-state controller plus
previous tricks for storing
stacks in tree etc.
Other counter operations are
similar.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Extracting the information-theoretic capacity
Increment operation:
Find lowest-valued
subtree in rightmost
isomorphism class that is
not maxed out.
Increment it.
Reset less-significant
subtrees to zero.

All of this can be done using
finite-state controller plus
previous tricks for storing
stacks in tree etc.
Other counter operations are
similar.
SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Capacity of random graphs is Θ(n)
Problem: Can’t tell nodes
apart.
Solution: Assign random
labels.
Sort nodes by degree and
neighborhood labeling and
use them as TM tape.
Works for Gn,p model where
edge probability p is
polynomial in n.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Lines
Trees
Random graphs

Capacity of random graphs is Θ(n)
Problem: Can’t tell nodes
apart.
Solution: Assign random
labels.
Sort nodes by degree and
neighborhood labeling and
use them as TM tape.
Works for Gn,p model where
edge probability p is
polynomial in n.

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Open problems
More information

Conclusions and open problems
We extract full information-theoretic
capacity from:
Highly-symmetric graphs.
Trees.
Random graphs with polynomial
edge probabilities.

Observation: GRAPH ISOMORPHISM
is not hard on these graphs.
What about:
Random geometric graphs?
Planar graphs?

SSS 2010

Storage capacity of labeled graphs

Introduction
Graph Turing machines
Graph traversal and applications
Higher-capacity graphs
Conclusions

Open problems
More information

Warning!

Proceedings version omits many details.
Full paper (and these slides) available at:
www.cs.yale.edu/homes/aspnes/graph-capacity.html

SSS 2010

Storage capacity of labeled graphs

