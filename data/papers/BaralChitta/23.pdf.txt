Reasoning About the Beliefs of Agents in
Multi-Agent Domains in the Presence of State
Constraints: The Action Language mAL
Chitta Baral1 , Gregory Gelfond1 , Enrico Pontelli2 , and Tran Cao Son2
1

2

Arizona State University, Tempe, AZ 85281
New Mexico State University, Las Cruces, NM 88011

Abstract. Reasoning about actions forms the basis of many tasks such
as prediction, planning, and diagnosis in a dynamic domain. Within the
reasoning about actions community, a broad class of languages called
action languages has been developed together with a methodology for
their use in representing dynamic domains. With a few notable exceptions,
the focus of these efforts has largely centered around single-agent systems. Agents rarely operate in a vacuum however, and almost in parallel,
substantial work has been done within the dynamic epistemic logic community towards understanding how the actions of an agent may affect the
knowledge and/or beliefs of his fellows. What is less understood by both
communities is how to represent and reason about both the direct and
indirect effects of both ontic and epistemic actions within a multi-agent
setting. This paper presents a new action language, mAL, which brings
together techniques developed in both communities for reasoning about
dynamic multi-agent domains involving both ontic and epistemic actions,
as well as the indirect effects that such actions may have on the domain.

1

Introduction

Reasoning about actions and change has been one of the cornerstones of artificial
intelligence research ever since McCarthy’s description of the “advice taker
system” [16]. Since that time, a considerable body of work on a broad class of
languages called action languages together with a corresponding methodology
for their use has been developed [1,10,11]. A distinguishing characteristic of
such languages is their simple syntax and semantics which allow for concise and
natural representations of huge transition systems, and elegant solutions to the
frame problem [3,5,10,15]. With a few notable exceptions, [5,14], the focus of
such languages has been on representing an agent’s knowledge concerning sensing
and ontic actions (i.e., those which primarily affect the physical environment).
Agents rarely operate in isolation, often exchanging information, and consequently
almost in parallel, substantial work has been done within the Dynamic Epistemic
Logic (DEL) community towards understanding epistemic actions (i.e., those
which primarily affect the knowledge or beliefs of other agents) [2,8,7] and, to
a lesser extent ontic actions [6]. What is less understood by both communities

is how to represent and reason about both the direct and indirect effects of
both classes of actions in a multi-agent setting. In this paper we present a
new action language, mAL, which brings together techniques developed in both
communities for reasoning about dynamic multi-agent domains involving both
ontic and epistemic actions. Unlike prior works of both the action language [4],
and dynamic epistemic logic communities [6], mAL allows for the representation
of complex dependencies between fluents and provides a robust solution to the
ramification problem [17,12,13]. In addition, it is capable of representing domains
involving collaboration between agents for both ontic and epistemic actions.

Example 1 (A Multi-Agent “Lin’s Briefcase Domain”). Let us consider a multiagent variant of the “Lin’s Briefcase Domain” [13]: Three agents, A, B, and C, are
together in a room with a locked briefcase which contains a coin. The briefcase is
locked by two independent latches, each of which may be flipped open (or closed)
by an agent. Once both latches are open, the briefcase is unlocked and an agent
may peek inside to determine which face of the coin is showing. Suppose that
the briefcase is locked, and that this fact, together with the fact that none of the
agents knows which face of the coin is showing is common knowledge amongst
them. Furthermore, let us suppose that all of the agents are paying attention to
their surroundings, and that this is common knowledge as well. Lastly, let us
suppose that the coin is actually showing heads. How could agent A determine
the face of the coin while keeping B aware of his activities but leaving C in the
dark? One way could be as follows: A distracts C, causing him to look away;
once this is done, he flips open both latches, thereby unlocking the briefcase; and
finally A peeks inside.
Note that the domain in Ex. 1 contains both ontic (e.g., flipping the latches)
and epistemic (e.g., peeking into the briefcase) actions. In addition, the actions of
signaling/distracting an agent and flipping the latches have two classes of indirect
effects: those affecting the frames of reference (or degrees of awareness) that
agents have with respect to subsequent action occurrences, and those affecting
the physical properties of the domain. As an example of the former, once C is
distracted, he will be unaware of A’s subsequent activities. As an example of the
latter, flipping a latch open when its counterpart is as well, causes the briefcase
to become unlocked.
While the languages of action and update models developed within the DEL
community [2,6] provide an elegant means for deriving the direct effects of
both ontic and epistemic actions, they fall short when it comes to solving the
ramification problem, and consequently are unable to represent domains such as
the one presented in Ex. 1. Furthermore, their graphical nature and unification of
the distinct notions of an action and action occurrence, renders them inadequate
from a knowledge representation standpoint due to their lack of elaboration
tolerance. As we hope to show in this paper, both difficulties are overcome by
mAL.

2

The Action Language mAL

The action language mAL incorporates elements from the action languages AL
[11,9] and mA+ [4], adding to mA+ the ability to describe various dependencies
between fluents by the inclusion of state constraints.
2.1

Syntax

Theories of mAL are defined over a multi-agent domain D with a signature
Σ = (AG, F, A) where AG, F, and A, are finite, disjoint, non-empty sets of
symbols respectively defining the names of the agents within the domain, the
properties of the domain (or fluents), and the elementary actions which the
agents may perform. mAL supports two broad classes of actions: ontic and
epistemic actions, the former describing actions which affect the properties of the
domain represented by fluents, and the latter describing actions which primarily
affect the agents’ beliefs. Epistemic actions are further broken into two categories:
sensing and communication. Sensing actions represent actions which an agent
may perform in order to learn the value of a fluent, while communication actions
are used to represent actions which communicate information between agents.
Ontic properties of the domain are represented by fluents, while the various
epistemic properties are represented by modal formulae:
Definition 1 (Modal Formula [8]). Let D be a multi-agent domain with the
signature Σ = (AG, F, A). The set of modal formulae over Σ is defined as
follows:
– f ∈ F is a formula
– if ϕ is a formula, then ¬ϕ is a formula
– if ϕ1 and ϕ2 are formulae, then ϕ1 ∧ ϕ2 , ϕ1 ∨ ϕ2 , ϕ1 → ϕ2 , and ϕ1 ≡ ϕ2 are
formulae
– if α ∈ AG and ϕ is a formula, then Bα ϕ is a formula
– if γ ⊆ AG and ϕ is a formula, then Eγ ϕ and Cγ ϕ are formulae
As the modality of discourse is that of belief, we adopt the following readings of
modal formulae: Bα ϕ, is understood to mean that “agent α believes ϕ”; formulae
of the form Eγ ϕ denote that “every member of γ believes ϕ”, while those of the
form Cγ ϕ are read as “every member of γ believes ϕ, and every member of γ
believes that every member of γ believes ϕ, ad infinitum, (i.e. ϕ is a commonly
held belief amongst the agents of γ).”
The direct effects of ontic actions are described by dynamic causal laws which
are statements of the form:
a causes λ if φ
(1)
where a is an action, λ is a fluent literal, and φ is a conjunction of fluent literals.
Laws of this form are read as: “performing the action a in a state which satisfies
φ causes λ to be true.” If φ is a tautology, then we simply write the following:
a causes λ

(2)

Sensing actions are described by sensing axioms which have the form:
a determines f

(3)

where a is the name of an action, and f is a fluent. Statements of this form are
understood to mean: “if an agent performs the action a, he will learn the value of
the fluent f .” Communication actions are described by communication axioms
which have the form:
a communicates ϕ
(4)
where a is the name of an action, and ϕ is a modal formula. In mAL only truthful
announcements are allowed.
The constructs (1)–(4) only describe the direct effects of their respective
actions. In general, an agent’s actions may indirectly affect the knowledge/beliefs
of his fellows, as well as the values of various fluents. As in mA+, indirect effects
of the first form are determined by the frames of reference (or levels of awareness)
that the agents have with respect to the action. In general, for any given action
occurrence we divide the agents of the domain into three groups: those who are
fully aware of both the action occurrence and its effects; those who are aware
of the occurrence but not the full consequences of the action; and those agents
who are oblivious as to what has transpired. Frames of reference are dynamic in
nature and are described by perspective axioms which are statements of the form:
X observes a if φ

(5)

X aware of a if φ

(6)

where X is a set of agent names, a is an action, and φ is a modal formula.
Perspective axioms of the first form (called observation axioms) define the set of
agents who are fully aware of both the action occurrence and its effects. Those
of the second form (called awareness axioms) define the set of agents who are
aware of the occurrence, but only partially of its effects. By default, we assume
that all other agents within the domain are oblivious. As with dynamic causal
laws, if φ is a tautology, we adopt the following shorthand:
X observes a

(7)

X aware of a

(8)

The inclusion of observation axioms allows us to make explicit the assumption
that agents are aware of the actions they perform. In mAL, the only assumptions
made regarding the frames of reference of the agents are that those who are fully
aware of an action occurrence and its effects, as well as those who are aware only
of the occurrence, know the frames of reference of all of the agents within the
domain.
Unlike mA+, mAL includes state constraints which are statements of the
form:
λ if φ
(9)

where λ is a fluent literal and φ is a conjunction of fluent literals. Statements of
this form are read as: “if φ is true in a state, then λ must also be true in that
state.” State constraints are used to represent dependencies between fluents and
provide a powerful means for representing indirect effects of the second form.
Lastly, executability conditions, which are statements of the form:
impossible a if φ

(10)

where a is an action and φ is a modal formula, are used to describe when actions
may not be performed.
Definition 2 (Action Description of mAL). An action description, ∆, in
mAL is a collection of statements of the form (1)–(10).
Now that the syntax has been introduced, we present a detailed axiomatization
of the multi-agent variant of the Lin’s Briefcase Domain from Ex. 1.
Example 2 (Axiomatization of the Multi-Agent “Lin’s Briefcase Domain”). Let λ
be a variable ranging over the set {l1 , l2 } representing the latches governing the
briefcase. Similarly, let α, α1 , and α2 , be variables ranging over the set of agents
in our domain. We begin our representation by adopting the following domain
signature Σ = (AG, F, A) where:
AG = {A, B, C}
F = {open(λ), locked, heads, attentive(α)}
A = {f lip(α, λ), peek(α), signal(α1 , α2 ), distract(α1 , α2 )}
The direct effects of the action f lip(α, λ) are represented via the following pair
of dynamic causal laws:
f lip(α, λ) causes open(λ) if ¬open(λ)

(11)

f lip(α, λ) causes ¬open(λ) if open(λ)

(12)

The following state constraint models the indirect effects of the action, f lip(α, λ),
namely that the briefcase is unlocked once both latches are open.
¬locked if open(l1 ) ∧ open(l2 )

(13)

The agent directly performing the action f lip(α, λ), as well as any attentive
agents are considered to be fully aware of the action occurrence and of its full
effects. This information may be encoded by the following pair of perspective
axioms:
{α} observes f lip(α, λ)

(14)

{α2 } observes f lip(α1 , λ) if attentive(α2 )

(15)

The action, peek(α), is an epistemic action — in particular, it is a sensing action.
Consequently its direct effects are represented by the following sensing axiom:
peek(α) determines heads

(16)

The fact that an agent may not peek into a locked briefcase is represented by
the following executability condition:
impossible peek(α) if locked

(17)

Unlike the action f lip(α, λ), only the agent who is peeking is fully aware of the
occurrence and its full effects. Agents who are attentive, are only partially aware
of the action’s effects. This is represented by the following perspective axioms:
{α} observes peek(α)

(18)

{α2 } aware of peek(α1 ) if attentive(α2 )

(19)

Lastly, the actions signal(α1 , α2 ) and distract(α1 , α2 ) are represented in a similar
fashion:

2.2

signal(α1 , α2 ) causes attentive(α2 )

(20)

{α1 , α2 } observes signal(α1 , α2 )

(21)

{α} observes signal(α1 , α2 ) if attentive(α)

(22)

distract(α1 , α2 ) causes ¬attentive(α2 )

(23)

{α1 , α2 } observes distract(α1 , α2 )

(24)

{α} observes distract(α1 , α2 ) if attentive(α)

(25)

Semantics

Before we discuss the semantics of our language, we must first introduce the
notions of a Kripke structure and Kripke world.
Definition 3 (Kripke Structure [8]). Let D be a multi-agent domain with
signature, Σ = (AG, F, A), where AG = {α1 , . . . , αn }. A Kripke structure, M ,
is a tuple of the form (Ω, π, Rα1 , . . . , Rαn ) where:
– Ω is a nonempty set of possible worlds
– π is an interpretation function which for each ω ∈ Ω gives an interpretation,
π(ω) : F 7→ {true, f alse}
– each Rαi is a binary relation on Ω called an accessibility relation for agent
αi
Possible worlds and their respective interpretations describe potential physical
configurations of the domain, while the accessibility relations represent its various
epistemic properties. Intuitively, the pair (ωσ , ωτ ) ∈ Rαi represents the property
that from within possible world ωσ , agent αi cannot distinguish between ωσ and
ωτ .
Definition 4 (Kripke World [8]). A Kripke world is a pair, (M, ω), where
M is a Kripke structure, and ω is a possible world of M .

For a given Kripke world, (M, ω), ω denotes which possible world of M
corresponds to the real physical state of the world as known to an impartial
external observer.
Having defined the notions of a Kripke structure and a Kripke world, we can
now define the semantics of modal logic.
Definition 5 (Entailment Relation for Modal Formulae). Let (M, ωσ ) be
a Kripke world in a multi-agent domain, D, with the signature Σ = (AG, F, A).
–
–
–
–
–

(M, ωσ ) |= f where f ∈ F iff M.π(ωσ )(f ) = >
(M, ωσ ) |= ¬ϕ iff (M, ωσ ) 6|= ϕ
(M, ωσ ) |= ϕ1 ∧ ϕ2 iff (M, ωσ ) |= ϕ1 and (M, ωσ ) |= ϕ2
(M, ωσ ) |= ϕ1 ∨ ϕ2 iff (M, ωσ ) |= ϕ1 or (M, ωσ ) |= ϕ2
(M, ωσ ) |= Bα ϕ iff (M, ωτ ) |= ϕ for all ωτ such that (ωσ , ωτ ) ∈ M.Rα

Let E0γ ϕ be equivalent to ϕ and let Ek+1
ϕ be Eγ Ekγ ϕ.
γ
– (M, ωσ ) |= Eγ ϕ iff (M, ωσ ) |= Bα ϕ for each α ∈ γ
– (M, ωσ ) |= Cγ ϕ iff (M, ωσ ) |= Ekγ ϕ for k = 1, 2, 3, . . .
As is the case with other action languages, an action description of mAL
defines a transition diagram whose nodes correspond to states of the domain
— which we model as Kripke worlds — and whose arcs are labeled by actions.
Within a particular state, the possible worlds comprising the underlying Kripke
world correspond to complete consistent sets of fluent literals closed under the
state constraints of the action description.
Example 3 (Initial State of the Multi-Agent “Lin’s Briefcase Domain”). The
initial state, σ0 , of the domain from Ex. 1 corresponds to the Kripke world,
(M0 , ω1 ), shown in Fig. 1. σ0 consists of two possible worlds, ω1 and ω2 , where:
– M0 .π(ω1 ) = {heads, attentive(A), attentive(B), attentive(C), ¬open(l1 ),
¬open(l2 ), locked}
– M0 .π(ω2 ) = {¬heads, attentive(A), attentive(B), attentive(C), ¬open(l1 ),
¬open(l2 ), locked}
A graphical convention that we adopt in this work is to present Kripke structures/worlds as directed graphs whose nodes are drawn as circles with unbroken
lines. The possible world(s) designated as pertaining to the real state of the world
are marked by a double circle.
The semantics of mAL is defined via a transition function, Φ∆ (σ, a), which
when applied to a state, σ, and an action occurrence, a, yields the corresponding
successor state(s). The approach taken in this paper combines methods used in
defining the semantics of AL [9], with an approach based on that of [6]. The key
intuition behind our semantics is that reasoning about the effects of an action is
a two-step process: an agent first reasons about how his fellows may perceive his
action, thereby establishing an epistemic configuration for the successor state;
and then reasons about how his action may actually play out.

A, B, C

ω1

A, B, C

(a)

A, B, C

A, B, C

ω2

ω1

A, B, C

A, B, C

ω2

(b)

Fig. 1. The initial state, σ0 , of the Multi-Agent Lin’s Briefcase Domain. 1(a) shows the
underlying Kripke structure of σ0 , while 1(b) corresponds to σ0 itself.

Frames of Reference In order to reason about how his fellows will perceive his
actions, an agent must reason about their respective frames of reference; hence
the inclusion of perspective axioms, which allow one to dynamically specify the
levels of awareness that the agents have with respect to an action occurrence.
It must be emphasized, that frames of reference are thought of as attributes of
an action that differ from one action occurrence to another. This is in marked
contrast with the approach of [2,6], in which different frames of references yield
very different actions.
Definition 6 (Frames of Reference). Let ∆ be an action description of mAL,
σ = (M, ω) be a state of the transition diagram defined by ∆, and a be an action.
The various frames of reference of the agents are defined as follows:
– the set of agents who are fully aware of a, denoted by f (σ, a), is {α ∈ AG |
[α observes a if φ] ∈ ∆ ∧ (M, ω) |= φ}
– the set of agents who are partially aware of a, denoted by p(σ, a), is {α ∈
AG | [α aware of a if φ] ∈ ∆ ∧ (M, ω) |= φ}
– the set of agents who are oblivious of a, denoted by o(σ, a), is AG \ f (σ, a) ∪
p(σ, a)
Update Schema/Instantiations On a semantic level, an action occurrence is
represented by an update schema 3 , which may be thought of as a Kripke structure
capturing how the agents in a domain perceive various action occurrences. Rather
than possible worlds, an action occurrence is described by a number of scenarios,
each of which is associated with a necessary precondition. What the agents believe
about the scenarios is described by their respective accessibility relations. This
leads to the following definition:
Definition 7 (Update Schema). Let L denote the set of all modal formulae that may be defined over the multi-agent domain, D, with signature Σ =
(AG = {α1 , . . . , αn }, F, A). An update schema, U , is a tuple of the form
(Sc , Rα1 , . . . , Rαn , pre) where:
3

Update schema/instantiations are analogous to the certain structures described in
[2,6], but have been renamed to reflect different intuitions behind their use.

– Sc is a finite, non-empty set of scenarios
– each Rαi is a binary relation on ε called an accessibility relation for agent αi
– pre : Sc 7→ L assigns a precondition function to each scenario
An update schema only describes the beliefs of the agents with regards to
a particular action occurrence. As with Kripke structures, they do not describe
which scenario actually took place. To accomodate this additional information,
update schema are instantiated by specifying which scenario actually occurred.
Definition 8 (Update Instantiation). An update instantiation is a pair,
(U, ε), where U is an update schema, and ε is a scenario of U .
In the context of mAL, we define three particular update instantiations, for
ontic, sensing, and communication actions respectively: υo (σ, a), υs (σ, a), and
υc (σ, a).
The intuition behind υo (σ, a) is relatively straightforward: the agents are
either aware of the action occurrence or are oblivious. In addition, we make the
assumption that those agents who are aware of the action occurrences know
which agents are oblivious.
Definition 9 (Ontic Instantiation). The function υo (σ, a) yields the set of
update instantiations represented by the pair (U, Γ ) where U is defined as follows:
– U.Sc = {εp , εi }
– U.Rα = {(εp , εp ), (εi , εi )} for each agent in f (σ, a)
– U.Rα = {(εp , εi ), (εi , εi )} for each agent in o(σ, a)
Let Ψ = {φ | [impossible a if φ] ∈ ∆}.
W
– U.pre(εp ) = ¬( Ψ )
– U.pre(εi ) = >
and Γ = {εp }.
υs (σ, a) is based on the following intuition: the real value of f is revealed to
those agents who are performing the action, causing it to become a commonly
held belief amongst them; agents who observe the action learn that the value
of f has been revealed to those agents who were directly involved in it; and the
beliefs of oblivious agents remain unchanged.
Definition 10 (Sensing Instantiation). The function υs (σ, a) yields the set
of update instantiations represented by the pair (U, Γ ) where U is defined as
follows:
–
–
–
–

U.Sc = {εp , εn , εi }
U.Rα = {(εp , εp ), (εn , εn ), (εi , εi )} for each agent in f (σ, a)
U.Rα = {(εp , εp ), (εn , εn ), (εi , εi ), (εp , εn ), (εn , εp )} for each agent in p(σ, a)
U.Rα = {(εp , εi ), (εn , εi ), (εi , εi )} for each agent in o(σ, a)

Let f be the fluent determined by the sensing axiom for the action a, and let
Ψ = {φ | [impossible a if φ] ∈ ∆}.
W
– U.pre(εp ) = f ∧ ¬( Ψ )
W
– U.pre(εn ) = ¬f ∧ ¬( Ψ )
– U.pre(εi ) = >
and Γ = {εp , εn }.
The intuition behind υc (σ, a) similar to that of sensing actions: ϕ becomes a
commonly held belief amongst those agents who receive/hear the message; agents
who observe the action learn that the value of ϕ has been revealed to those agents
who heard it (they are however unaware of the truth of ϕ); and lastly, the beliefs
of oblivious agents are unchanged.
Definition 11 (Communication Instantiation). The function υc (σ, a) yields
the set of update instantiations represented by the pair (U, Γ ) where U is defined
as follows:
–
–
–
–

U.Sc = {εp , εn , εi }
U.Rα = {(εp , εp ), (εn , εn ), (εi , εi )} for each agent in f (σ, a)
U.Rα = {(εp , εp ), (εn , εn ), (εi , εi ), (εp , εn ), (εn , εp )} for each agent in p(σ, a)
U.Rα = {(εp , εi ), (εn , εi ), (εi , εi )} for each agent in o(σ, a)

Let ϕ be the formula specified by the communication axiom for the action a, and
let Ψ = {φ | [impossible a if φ] ∈ ∆}.
W
– U.pre(εp ) = ϕ ∧ ¬( Ψ )
W
– U.pre(εn ) = ¬ϕ ∧ ¬( Ψ )
– U.pre(εi ) = >
and Γ = {εp }.
Example 4 (Update Instantiations for the Action distract(A, C)). Consider an
action occurrence distract(A, C). Suppose that agent B is oblivious of the action
occurrence. In this case, the corresponding ontic instantiation, is shown in
Fig. 2(a). Now consider an occurrence of the action distract(A, C), where all
of the agents are fully aware of the action occurrence. This yields a different
ontic instantiation, shown in Fig. 2(b). Here we adopt the graphical convention
of presenting update schema/instantiations as directed graphs whose nodes are
drawn as rounded rectangles with solid lines. Once again, it bears emphasizing
that the action, distract(A, C), is the same in both instances. Only the attributes
corresponding to the agents’ frames of reference (which are represented by the
respective arcs) differ.

A, C

εp

B

(a)

A, B, C

A, B, C

εi

εp

(b)

Fig. 2. 2(a) shows the ontic instantiation for an occurrence of the action distract(A, C)
with A and C fully aware of the occurrence, and agent B oblivious. 2(b) show the ontic
instantiation of the same action with all agents fully aware of the occurrence.

Epistemic Configurations When reasoning about the effects of an action, an
agent first establishes what is called an epistemic configuration of the successor
state. This is done by the application of what we term an epistemic update to a
state, and the update instantiation of action occurrence in question.
An epistemic configuration defines the general graphical structure of the
successor state. Consequently it is similar to a Kripke structure, but does not
include the interpretation function. This intuition leads to the following pair of
definitions:
Definition 12 (Epistemic Schema). Let D be a multi-agent domain with
signature Σ = (AG = {α1 , . . . , αn }, F, A). An epistemic schema, E, is a tuple of
the form (S, Rα1 , . . . , Rαn ) where:
– S is a nonempty set of situations
– each Rαi is a binary relation on S called an accessibility relation for agent
αi
Definition 13 (Epistemic Configuration). An epistemic configuration is a
pair, (E, s), where E is an epistemic schema, and s is a situation of E.
In order to obtain the epistemic configuration of the successor state, we apply
an operation that we call the epistemic update operation, which when applied to
a state and an update instantiation, defines an epistemic configuration for the
successor state.
Definition 14 (Epistemic Update Operation). Given a state, σ = (M, ω),
and an update instantiation υ = (U, ε), such that σ |= U.pre(ε), Eu(σ, υ) defines
the epistemic configuration EC = (E, (ω, ε)) where:
– E.S = {(ωj , εj ) | ωj ∈ M.Ω, εj ∈ U.Sc , (M, ωj ) |= U.pre(εj )}
– E.Rα = {((ωj , εj ), (ωk , εk )) | (ωj , ωk ) ∈ M.Rα , (εj , εk ) ∈ U.Rα }
Example 5 (Applying the Epistemic Update). Recall from Ex. 1 that A first
distracts C. The action distract(A, C) is an ontic action which directly affects
the fluent attentive(C) as specified by the dynamic causal law (23). Perspective
axioms (24) and (25), together with the fact that the agents are initially attentive,

give f (σ0 , distract(A, C)) = {A, B, C} and o(σ0 , distract(A, C)) = ∅ as the
agents’ frames of reference. υo (σ0 , distract(A, C))) is shown in Fig. 3(a) and the
epistemic configuration of the successor state resulting from the occurrence of the
action distract(A, C) is given by Eu(σ0 , υo (σ0 , distract(A, C))), and is shown in
Fig. 3(b). For epistemic configurations, we adopt the convention of presenting
them as directed graphs whose nodes are drawn as dashed circles (the dashed
lines help express the notion that the scenarios are later expanded into possible
worlds). Those scenarios which correspond to potential real possible worlds are
marked by a double dashed line.

A, B, C

A, B, C

εp

(ω1,εp)

(a)

A, B, C

A, B, C

(ω2,εp)

(b)

Fig. 3. 3(a) shows the update instantiation for an occurrence of the action distract(A, C)
in σ0 , while Fig. 3(b) shows the epistemic configuration of the successor state resulting
from that action occurrence.

From Epistemic Configurations to States The epistemic update only describes how an agent reasons about how his actions are perceived by his fellows.
In order to obtain the full successor state, he must then reason about how his
actions may actually play out. This is accomplished by abstracting away the
presence of other agents, turning the problem into one concerning the effects of
an action in a single-agent domain. This is done by applying what we term an
ontic update operation to the epistemic configuration. Prior to defining the ontic
update, we must first describe how to relate an epistemic configuration to the
framework for reasoning about the effects of an action from the perspective of
AL.
Definition 15 (AL(σ, ω)). Let ∆ be an action description of mAL and σ be
a state of the transition diagram defined by ∆. Each possible world, ω of σ
corresponds to a complete consistent set of fluent literals, AL(σ, ω), defined as
follows:
{f | σ.ω.π(f ) = >} ∪ {¬f | σ.ω.π(f ) = ⊥}
Intuitively, an epistemic configuration describes the basic structure of the
successor state. Each situation s = (ω, ε) in an epistemic configuration may be
read as “scenario ε transpires in the possible world ω”, and corresponds to possibly
multiple possible worlds in the successor state. The possible worlds of the sucessor
state within the multi-agent transition diagram are obtained by applying the
McCain-Turner equation [15] to the possible worlds defined by AL(σ, ω).

Definition 16 (Scenario Expansion). Let σ be a state of the transition diagram defined by ∆, υ be an update instantiation corresponding to the occurrence
of an action, a in σ, EC be an epistemic configuration defined by Eu(σ, υ), and
s = (ω, ε) be a situation of EC . The expansion of the situation s consistent with
the state, σ, (denoted by C(σ, s)), is defined as follows:
– if ε = εi , then C(σ, s) = {AL(σ, ω)}, otherwise
– C(σ, s) = {τ (s) | τ (s) = Cn∆ (E(AL(σ, ω), a) ∪ (AL(σ, ω) ∩ τ (s)))}
The expansion of the entire epistemic configuration, C(σ, EC ), is defined in a
straightforward fashion as well:
[
C(σ, EC ) =
C(σ, s) for each s ∈ EC .S
Having defined this basic framework, we may now define the ontic update
operation.
Definition 17 (Ontic Update). Let ∆ be an action description of mAL, σ be
a state of the transition diagram defined by ∆, and EC = (E, ω) be an epistemic
configuration. Ou∆ (σ, EC ) defines a set of Kripke worlds (M 0 , RW ) where:
–
–
–
–
–

M 0 .Ω is the set of new symbols of the form ωτi (s) for each τi (s) ∈ C(σ, EC )
M 0 .π(ωτi (s) )(f ) = > if f ∈ τi (s)
M 0 .π(ωτi (s) )(f ) = ⊥ if ¬f ∈ τi (s)
M 0 .Rα = {(ωτi (s1 ) , ωτj (s2 ) ) | ωτi (s1 ) , ωτj (s2 ) ∈ M 0 .Ω, and (s1 , s2 ) ∈ EC .Rα }
RW = {ωτi (s) | τi (s) ∈ C(σ, ω)}

Example 6 (Applying the Ontic Update). Let EC 0 denote the epistemic configuration from Ex. 5. Application of the ontic update operation, Ou∆ (σ0 , EC 0 ),
gives us the successor state, σ1 = (M1 , ω3 ), depicted in Fig. 4. The Kripke

A, B, C

A, B, C

ω3

A, B, C

ω4

Fig. 4. Successor state, σ1 , resulting from the application of Ou∆ (σ0 , EC 0 ).

structure, M1 , shown in Fig. 4 consists of two possible worlds, ω3 = ωτ ((ω1 ,εp )) ,
and ω4 = ωτ ((ω2 ,εp )) where:
– M1 .π(ω3 ) = {heads, locked, ¬open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}
– M1 .π(ω4 ) = {¬heads, locked, ¬open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}

The Transition Function As was mentioned previously, the transition function
is based on the following intuition: an agent first reasons about how his action is
perceived, and then reasons about how it may actually play out. This intuition
is realized in the definition of our transition function, Φ∆ (σ, a).
Definition 18. Let ∆ be an action description of mAL, σ be a state of the
transition diagram defined by ∆, and a be an action. The successor state(s)
obtained by performing the action a in the state σ are defined as follows:


Ou∆ (σ, Eu(σ, υo (σ, a)) ontic action
Φ∆ (σ, a) = Ou∆ (σ, Eu(σ, υs (σ, a)) sensing action


Ou∆ (σ, Eu(σ, υc (σ, a)) otherwise
2.3

Properties of the Language

The syntax and semantics of mAL may be of interest in and of themselves, but
of particular interest is the fact that mAL satisfies certain useful properties
- namely that it correctly captures certain intuitions concerning the effects of
various types of actions. Space constraints preclude us from including the proofs
of the subsequent theorems, which we leave to a future journal paper (the paper
is currently in development and will cover mAL in greater detail, including
application of the languages towards modeling collaboration amongst agents for
both ontic and epistemic actions).
Theorem 1. Let ∆ be an action description of mAL; σ = (Mσ , ωσ ) be a state
of the transition diagram defined by ∆; a be an ontic action; and σ 0 = (Mτ , ωτ ) ∈
Φ∆ (σ, a). It holds that:
1. for every agent α ∈ f (σ, a) and dynamic causal law [a causes λ if φ] in ∆, if
(Mσ , ωσ ) |= Bα φ then (Mτ , ωτ ) |= Bα λ
2. for every agent α ∈ f (σ, a) and state constraint [λ if φ] in ∆, (Mσ , ωσ ) |=
Bα (φ → λ)
3. for each agent α ∈ o(σ, a) and literal, λ, (Mτ , ωτ ) |= Bα λ if and only if
(Mσ , ωσ ) |= Bα λ
Theorem 2. Let ∆ be an action description of mAL; σ = (Mσ , ωσ ) be a state
of the transition diagram defined by ∆; a be a sensing action described by the
axiom [a determines f ] in ∆; and σ 0 = (Mτ , ωτ ) ∈ Φ∆ (σ, a). It holds that:
1. (Mτ , ωτ ) |= Cf (σ,a) λ if and only if (Mσ , ωσ ) |= λ where λ ∈ {f, ¬f }
2. (Mτ , ωτ ) |= Cp(σ,a) (Cf (σ,a) f ∨ Cf (σ,a) ¬f )
3. for each agent α ∈ o(σ, a) and literal, λ, (Mτ , ωτ ) |= Bα λ if and only if
(Mσ , ωσ ) |= Bα λ
Theorem 3. Let ∆ be an action description of mAL; σ = (Mσ , ωσ ) be a state
of the transition diagram defined by ∆; a be a communication action described
by the axiom [a communicates ϕ] in ∆; and σ 0 = (Mτ , ωτ ) ∈ Φ∆ (σ, a). It holds
that:

1. (Mτ , ωτ ) |= Cf (σ,a) ϕ
2. (Mτ , ωτ ) |= Cp(σ,a) (Cf (σ,a) ϕ ∨ Cf (σ,a) ¬ϕ)
3. for each agent α ∈ o(σ, a) and literal, λ, (Mτ , ωτ ) |= Bα λ if and only if
(Mσ , ωσ ) |= Bα λ

3

Temporal Projection in mAL

Recall that in Ex. 1 we presented the following
sequence of actions by which A might achieve his
goal: A distracts C, causing him to look away;
ω5
ω6
A, B
once this is done, he then flips open both latches
C
C
on the briefcase, thereby unlocking it; and finally
C
C
A peeks inside. Space considerations preclude us
from examining the entire trajectory, and conseω7
ω8
A, B, C
quently we will only show in detail how to obtain the successor state resulting from A flipping
A, B, C
A, B, C
open the second latch (represented by the action
Fig. 5: Successor state, σ2 , re- f lip(A, l2 )).
sulting from the action sequence Let σ2 , shown in Fig. 5, be the state of the trandistract(A, C), f lip(A, l1 ).
sition diagram resulting from the sequence of actions: distract(A, C), f lip(A, l1 ).
σ2 consists of four possible worlds4 , ω5 , ω6 , ω7 , and ω8 where:
A, B

A, B

– M2 .π(ω5 ) = {heads, locked, open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}
– M2 .π(ω6 ) = {¬heads, locked, open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}
– M2 .π(ω7 ) = {heads, locked, ¬open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}
– M2 .π(ω8 ) = {¬heads, locked, ¬open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}
Like its predecessor, f lip(A, l2 ), is an ontic action, affecting only the values of the fluents of our possible worlds. Consequently, our intuition informs
us that the structure of the successor state should essentially be unchanged.
σ2 and observation axioms (14) and (14) give f (σ2 , f lip(A, l2 )) = {A, B} and
o(σ2 , f lip(A, l2 )) = {C} as the agents’ frames of reference. Being an ontic action,
the epistemic configuration, EC 2 , of the successor state resulting from f lip(A, l2 )
is given by Eu(σ2 , υo (σ2 , f lip(A, l2 ))) and is shown in Fig. 6(a). As we can see,
EC 2 is structurally similar to σ2 , confirming our aforementioned intuition.
According to the dynamic causal law (11), f lip(A, l2 ) causes open(l2 ). Furthermore, the state constraint (13), informs us that as a consequence of both
l1 and l2 being open, the briefcase itself should become unlocked (i.e., ¬locked
must now be true). The expansions of the scenarios in EC 2 , that are consistent
with σ2 :
4

The labels of the possible worlds have been abbreviated for legibility purposes.

– C(σ2 , (ω5 , εp )) = {{heads, ¬locked, open(l1 ), open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}}
– C(σ2 , (ω6 , εp )) = {{¬heads, ¬locked, open(l1 ), open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}}
– C(σ2 , (ω7 , εi )) = {{heads, locked, ¬open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}}
– C(σ2 , (ω8 , εi )) = {{¬heads, locked, ¬open(l1 ), ¬open(l2 ), attentive(A),
attentive(B), ¬attentive(C)}}
confirm our intuition.
Let ω9 = ωτ ((ω5 ,εp )) , ω10 = ωτ ((ω6 ,εp )) , ω11 = ωτ ((ω7 ,εi )) , and ω12 = ωτ ((ω8 ,εi )) .
Application of the ontic update operation to σ2 and EC 2 , Ou∆ (σ2 , EC 2 ), yields
the successor state, σ3 , shown in Fig. 6(b). Careful examination of σ3 shows
that it entails a number of modal formulae, among which is C{A,B} ¬locked –
indicating that it is a commonly held belief amongst A and B that the briefcase
is unlocked. In addition, σ3 entails C{A,B} ¬BC BA ¬locked, as well as other
formulae illustrating that C is oblivious of all of the events that transpired since
he was distracted, and that this is a commonly held belief amongst A and B.

A, B

(ω5,εp)

A, B

A, B

(ω6,εp)

ω9

C

C

(ω8,εi)

ω11

A, B, C

A, B, C

C

C
C

(ω7,εi)

A, B

A, B, C

A, B, C

A, B

C

C

(a)

ω10

A, B

C

A, B, C

ω12

A, B, C

(b)

Fig. 6. 6(a) shows the epistemic configuration, EC 2 , resulting from an occurrence of
f lip(A, l2 ) in σ2 , while 6(b) shows the resulting successor state, σ3 .

4

Conclusions and Future Work

In this paper we presented a new multi-agent action language mAL, which
extends the language of mA+ [4] with state constraints from the language AL
[9]. The language’s application was presented in the context of representing and
performing temporal projection in the context of a multi-agent variant of the
Lin’s Briefcase Domain [13], which heretofore could not be represented in either
mA+ or the update model approaches of [2] and [6]. Future work includes a

thorough analysis of the language’s theoretical properties and formulation of
the planning and diagnosis problems within a multi-agent context. Additional
extensions to the language such as non-deterministic sensing actions, and false
communication are under consideration as well.

References
1. Balduccini, M., Gelfond, M.: The AAA Architecture: An Overview. In: AAAI Spring
Symposium 2008 on Architectures for Intelligent Theory-Based Agents (2008)
2. Baltag, A., Moss, L.S.: Logics for Epistemic Programs. Synthese 139(2), 165–224
(2004)
3. Baral, C.: Reasoning About Actions: Non-deterministic Effects, Constraints, and
Qualification. In: Proceedings of the 14th International Joint Conferences on Artificial Intelligence 95. pp. 2017–2023. IJCAI ’95, Morgan Kaufmann (1995)
4. Baral, C., Gelfond, G., Son, T.C., Pontelli, E.: An Action Language for Reasoning
about Beliefs in Multi-Agent Domains. In: Proceedings of the 14th International
Workshop on Non-Monotonic Reasoning (2012)
5. Baral, C., Gelfond, M.: Reasoning about effects of concurrent actions. Journal of
Logic Programming 31, 85–117 (1997)
6. van Benthem, J., van Eijck, J., Kooi, B.: Logics of communication and change.
Information and Computation 204(11), 1620–1662 (2006)
7. van Ditmarsch, H., van der Hoek, W., Kooi, B.: Dynamic Epistemic Logic. Springer
(2008)
8. Fagin, R., Halpern, J.Y., Moses, Y., Vardi, M.Y.: Reasoning About Knowledge.
MIT Press (1995)
9. Gelfond, M.: Handbook of Knowledge Representation – Chapter 7: Answer Sets.
Elsevier (2007)
10. Gelfond, M., Lifschitz, V.: Representing Action and Change by Logic Programs.
Journal of Logic Programming 17, 301–322 (1993)
11. Gelfond, M., Lifschitz, V.: Action Languages. Electronic Transactions on AI 3
(1998)
12. Lifschitz, V. (ed.): Formalizing Common Sense – Papers by John McCarthy. Ablex
Publishing Corporation (1990)
13. Lin, F.: Embracing Causality in Specifying the Indirect Effects of Actions. In:
Proceedings of the 14th International Joint Conferences on Artificial Intelligence.
IJCAI ’95, Morgan Kaufmann (1995)
14. Lin, F., Shoham, Y.: Provably correct theories of action. Journal of the ACM 42(2),
293–320 (1995)
15. McCain, N., Turner, H.: A Causal Theory of Ramifications and Qualifications. In:
Proceedings of the 14th International Joint Conferences on Artificial Intelligence.
IJCAI ’95, Morgan Kaufmann (1995)
16. McCarthy, J.: Programs with common sense. In: Semantic Information Processing.
pp. 403–418. MIT Press (1959)
17. McCarthy, J.: Mathematical Logic in Artificial Intelligence. Daedalus 117(1), 297–
311 (1988)

