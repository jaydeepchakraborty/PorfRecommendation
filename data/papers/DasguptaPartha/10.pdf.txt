Fair Resource Allocation for Heterogeneous Tasks
Koyel Mukherjee, Partha Dutta, Gurulingesh Raravi, Thangaraj Balasubramaniam, Koustuv Dasgupta, Atul Singh Xerox Research Center India, Bangalore, India 560105 Email: {Koyel.Mukherjee, Partha.Dutta, Gurulingesh.Raravi}@xerox.com {Rajasubramaniam.T, Koustuv.Dasgupta, Atul.Singh}@xerox.com

Abstract--We consider the problem of fair allocation of resources to tasks where a resource has to be assigned to at most one task entirely without any fractional allocation. The system is heterogeneous in the sense that the cost may vary across resources, and different tasks may have different resource demand. Due to heterogeneity of resource costs, the cost of allocation for a task in isolation, without any other competing task, may differ significantly from its allocation cost when the task is allocated along with other tasks. In this context, we consider the problem of allocating resources to tasks, while ensuring that the cost is distributed fairly across the tasks, namely, the ratio of allocation cost of a task to its isolation cost is minimized over all tasks. We show that this fair resource allocation problem is strongly NP-Hard even when resources are of unit size by a reduction from 3-partition. Our main results are a 2+ O( ) approximation LP rounding based algorithm for the problem when resources are of unit capacity, and a near-optimal greedy algorithm for a more restricted version. The above fair allocation problem arises in various context, such as, allocating computing resources for reservation requests from clients in a data center, allocating resources to computing tasks in grid computing, or allocating personnel for projects in service delivery organizations. Keywords-Resource allocation, Approximation algorithm, LP rounding, Greedy algorithm

I. I NTRODUCTION In this work we consider a heterogeneous system where each resource has an associated cost and a capacity (or size), and a resource can be allocated entirely to at most one task, without any fractional allocation. Every task has a demand (or capacity requirement) and we would like to minimize the resource allocation cost for meeting this demand. In isolation, i.e., when there is exactly one task in the system, an ideal allocation would select a set of resources that would meet the task's demand while minimizing its total cost. This case of a task in isolation is identical to the minimization knapsack problem [6], a known NP-Hard problem, and we call the corresponding minimum cost of a task, its isolation cost. However, in presence of multiple tasks, due to heterogeneity of resources, the resource allocation

cost for a task may significantly differ from its isolation cost. In this scenario, we would like to minimize the cost for multiple tasks in a manner that is fair across tasks. In particular, when multiple tasks are present, we want to allocate the resources in a way that minimizes over all tasks, the ratio of the allocation cost of each task to its isolation cost. Fair resource allocation is one of the core problems in parallel and distributed computing which arises in multiple settings, as illustrated next. Consider a multitenant data center where multiple tenants request to reserve certain computing capacity over the set of available (physical or virtual) machines. Here the tasks are the reservation requests with their respective demands, and the resources are the machines, each with its computing capacity and cost. We would like to ensure a resource allocation that is fair across tenants, in terms of the costs of resources allocated. From a tenant's point of view, such a fair allocation is preferable than the case where the data center operator tries to minimize the total cost over all resources. A similar problem can be seen in a geographically distributed grid computing environment in which different users request computing resource reservations, where the resource costs can be the monetary cost, or the cost of network communication. Finally, the problem of allocating personnel to project in large service delivery organizations, such that any increase in project cost, due to the presence of other tasks, is fairly distributed, can also be modeled as the above fair resource allocation problem. A. Problem Definition and System Model We study the following problem. Given a set of tasks where each task has a certain resource requirement (also called demand), and a set of resources where each resource has a certain resource supply (also called capacity or size of the resource) and a cost, find a fair allocation of tasks to resources such that the resource requirements of all the tasks are met and each resource is allocated entirely to at most one task. The fairness is

defined with respect to the ratio of the cost of a task when allocated along with other tasks, to the optimal cost of the task, when allocated in isolation (i.e., when other tasks are not present). Our goal is to minimize the maximum of this ratio across all tasks. Henceforth, we refer to this problem as the fair allocation problem. Formally, we are given a set of tasks P , and we have access to a set of resources E . Each task j is characterized by its resource requirement denoted by Dj . Each resource i is characterized by two parameters: a resource supply si and a cost ci . Upon allocating a resource i to a task j , the task incurs a cost of ci and its resource requirement is reduced by si . In order for a task j to successfully execute, it must be ensured that the total size of resources allocated to it is at least Dj . We require all assignments to be integral (0 or 1), i.e., each resource must be entirely assigned to a task and hence cannot be fractionally assigned to multiple tasks. We denote by Ij the isolation cost of a task j , that is the cost that the task would incur if this is the only task that needs to be allocated resources and no other tasks were present in the system. We denote by Cj the cost incurred by the task j when resources are allocated to it along with other tasks in the system; we refer to this cost as the actual cost of the task. The problem objective i is to minimize  = maxiP C Ii . B. Related Work Fairness of resource allocation has been well-studied both from a theoretical and practical point of view. Fair sharing of network resources (such as a wired network links and wireless spectrum) has been extensively studied, and various indices and algorithms for fairness have been developed, such as [5], [7]. More recent work on sharing of system resources has focused on sharing resources in data centers [4], [9], and on a variant of max-min fairness. Our work differs from these [4], [5], [7], [9] in following two ways. Firstly, we consider a system where there are sufficient resources to satisfy requirements of all tasks, but the cost of the resources may vary, which in turn results in increase in cost of task in presence of other tasks. Most earlier work considers a system where the number of resources is limited and may not be able to fully satisfy the demands of all tasks. With the rapid increase in the computing capacity of data centers, our assumption of a large number of available resources from one or more data centers, albeit with different (rental) costs, is increasingly becoming more relevant. Secondly, we give a provable fairness guarantee for tasks, where fairness is quantified by the ratio of actual cost of a task to its isolation cost, which has not been investigated earlier. 2

The combinatorial optimization problem studied in this paper is a mixed packing and covering problem [11], where we need to cover the demand of task using resources subject to packing the selected resources within a certain cost budget. Young [11] studies the fractional version of the problem, which is not NP-hard, and provides efficient sequential and parallel algorithms for the problem. Chakaravarthy et al. [2] study a version of mixed packing and covering problems, where they solve a knapsack cover problem subject to cardinality constraints, and then extend it to multiple matroid constraints. In terms of the resource allocation problem that we study in this paper, the work of Chakaravarthy et al. [2] can be used to find the minimum cost resource allocation for one task, such that the total size of the resources allocated meets the total resource requirement of the task, and the number of resources allocated is at most a pre-specified number. This is slightly different compared to our problem where we try to ensure fairness of resource allocation costs across multiple tasks, such that the total resource requirement of every task is met. Escoffier et al. [3] study some multi-agent optimization problems where the goal is to maximize the satisfaction of the least satisfied agent, where the satisfaction of an agent is defined as the ratio between his utility for the given solution and his maximum possible utility. For some NP-hard problems, assuming a feasible solution exists, they give polynomial algorithms with approximation factors dependent on the number of agents and/or on other problem parameters. Though the objective of the problem studied is quite similar to ours, the underlying problem we study is different, and we provide constant approximations, not dependent on the problem size. Moreover, our techniques are fundamentally different from Escoffier et al. [3]. Online algorithms for the fractional mixed packing and covering problem are investigated by Azar et al. [1], where the packing constraints are known offline, while the covering constraints get revealed online. Their objective is to minimize the maximum multiplicative factor by which any constraint is getting violated, while meeting all the covering constraints. They give a polylogarithmic competitive ratio, and a nearly tight lower bound for the fractional problem. In contrast, we study an integral, offline version of the above problem, for which we give constant approximations. C. Our Contributions This paper makes the following contributions. 1) We first show that the fair allocation problem is NP-Hard in the strong sense even when the resources are of unit size.

2) We formulate the fair allocation problem as a mixed packing and covering problem and give a 2 + O( ) approximation algorithm, based on LP rounding when resources are unit sized. 3) We further show that the LP considered has an integrality gap of 2, hence the bound of 2 + O( ) is essentially tight for this LP. 4) Finally, for a restricted version of the problem, we give a near-optimal greedy algorithm. We would like to note that, although we assume that resources cannot be fractionally allocated to a task, it is straightforward to extend our methods to a setup where a resource can be allocated in multiples of a certain given 1 fraction k , by creating k copies of the resource each 1 with k of the cost and size of the original resource. D. Organization of the Paper The rest of the paper is organized as follows. In Section II, we show that the fair allocation problem is strongly NP-hard even for unit size resources. Then we formulate the problem as an integer linear program and show that a naive relaxation has an unbounded integrality gap in Section III, for unit sizes. We also show that when resources have arbitrary sizes and costs, any trivial modifications of the LP considered will still result in an unbounded integrality gap. Hence, we focus on the unit size resource problem the next section onwards. We give a 2 + O( ) approximate LP rounding algorithm for this problem in Section IV, following which we show that the LP considered has an integrality gap of 2 in Section V which essentially shows that our bound is tight. In Section VI, we present a greedy algorithm, that in a restricted scenario, achieves near optimal performance and finally Section VII concludes the paper. II. NP- HARDNESS In this section, we show that the problem of fair resource allocation to multiple tasks, is strongly NPhard even when the resources are of unit size and have different costs and the tasks are all identical in the sense that the resource requirement of each task is same. The reduction is from 3-Partition. Theorem 1: The feasibility problem of the fair resource allocation to multiple tasks is strongly NP-hard. Proof: Consider an instance of the 3-partition problem. There are n = 3m integers {ai |i  [1, . . . , n]} such that the sum of the integers i[1,...,n] ai = mB , B and each integer ai is strictly between B 4 and 2 , i.e., B B 4 < ai < 2 . The feasibility question is whether there exists a partition of the n integers into m partitions such that the sum of the integers in each partition is exactly equal to B . Note that this would require every partition 3

Minimize  subject to the following constraints: I1. j  P iE xi,j × ci   × Ij I2. j  P iE xi,j × si  Dj I3. i  E j P xi,j  1 I4. xi,j  {0, 1} i  E , j  P Fig. 1. An integer linear program for the fair allocation problem.

to have exactly 3 integers. Now, let us define a fair resource allocation problem, where we have m tasks, each requiring 3 units of resource. We create n = 3m resources, each of unit size, where the cost of each resource is ci = ai . Let us order the integers in the 3partition instance in non-decreasing order of their sizes. Let the sum of the 3 smallest integers be I . The isolation cost of every task is therefore equal to I . The feasibility question we ask is whether  = B I is feasible. If there exists a feasible solution to the 3-partition instance, that implies that  = B I is feasible, since this corresponds to 3 units of resources per task, and the cost incurred by every task is B . At the same time, if there exists a feasible  = B I for the fair resource allocation problem, then this implies that the 3-partition instance is feasible. Every task has received 3 resources, and the cost incurred by every task must be  I = B I I = B . Since we have allocated every resource, the total sum of the costs incurred by all m tasks is mB , hence no task can cost < B , as that would make another task cost > B , which cannot happen,  being feasible. As a result, this requires every task to cost exactly B . Therefore, the resource allocations to the m tasks corresponds to feasible m partitions of the integers in 3-partition, where the sum of the integers in every partition is exactly B . III. ILP FORMULATION , LP RELAXATION AND I NTEGRALITY GAP In this section, we formulate the problem as Integer Linear Program (ILP), then relax it to a Linear Program (LP) and show that the problem in the generic case where resources may have different costs and sizes has an unbounded integrality gap. Recall that the aim is to find an allocation of resources to tasks that minimizes the ratio of actual cost of allocation to the isolation cost, for all tasks. Formally, C we want to minimize  , where  = maxj P Ijj . This is subject to fulfilling the resource requirement Dj for all tasks j  P . We formulate this problem as an ILP, shown in Figure 1. In the formulation given in Figure 1,  represents an upper bound on the ratio of Cj to Ij across all tasks j  P , and since we are minimizing it,  is the smallest possible value for the required objective, i.e., C min maxj P Ijj , that can be achieved by any integral allocation. In the formulation , the inequality I 1 ensures that the cost incurred by a task j due to resource

allocation is at most Cj = Ij , inequality I 2 ensures that the total resource allocated to a task is no less than its resource requirement Dj , inequality I 3 ensures that no resource must be over allocated, and finally I 4 ensures that every resource must be integrally allocated to a task, if at all. A naive linear relaxation of this ILP formulation would relax I 4 to xi,j  0. However, such a relaxation has an unbounded integrality gap as illustrated next. Consider m tasks, each with a resource requirement of Dj = 1, and m resources of which m - 1 resources have a cost 1 and one resource has a cost m. All resources are of unit-size, i.e., si = 1. Any integral allocation would have to allocate the high cost resource to one of the tasks, hence incurring a  = m. However, the linear program 1 would allocate m of each resource to each task. This will meet the resource requirement of every task since 1 m· m = 1, while the cost incurred by every task is 1 -1 1 m m + mm = 2- m . Therefore, the integrality gap is m m  2- 1 > 2   as m  . m To overcome this, we use the parametric pruning technique, similar to the seminal work of Lenstra et al. [8]. We guess the optimal value of  , and solve a feasibility linear program. (Later in the section, we show that  can be guessed in a logarithmic number of iterations.) For each guess of  , we solve the feasibility linear program shown in Figure 2, where in order to avoid giving an unfair advantage to the linear program, we allow the LP to assign a resource i to a task j , only if ci   × Ij .
C1. C2. C3. C4.
iE|ci Ij iE|ci Ij j P xi,j xi,j  0

C1. C2. C3. C4.

iE|ci Ij  si Dj iE|ci Ij  si Dj j P xi,j  1

xi,j × ci  Ij xi,j × si  Dj

xi,j  0

j  P j  P i  E i  E , j  P

Fig. 3. Further restricted LP relaxation (still with an unbounded integrality gap for arbitrary sizes.

xi,j × ci  Ij xi,j × si  Dj 1

j  P j  P i  E i  E , j  P

Fig. 2.

An LP relaxation of ILP shown in Figure 1.

However, if the resources are of arbitrary sizes, then the linear program shown in Figure 2 still has an unbounded gap1 . Further, simple parametric pruning along the size dimension, specifically, allowing the LP to allocate a resource i to a task j , only if si  Dj , still cannot remove the gap. Consider the LP shown in Figure 3. This LP still has an unbounded integrality gap, and trivial modification of this LP cannot remove this gap. We show this with an example. Consider m tasks where each task has a resource requirement of m. Let there
1 Consider a system with 2 tasks, each with a resource requirement of Dj = 1, and 2 resources of which resource 1 has a size = 2 and a cost 1, and resource 2 has a size 1 and a cost L 1. It can be seen that the isolation cost of both tasks is 1. Any integral allocation would have to allocate the high cost resource to one of the tasks, resulting in a  = L. However, the linear program would return a feasible solution 1 for  = 1, by allocating fraction 2 of resource 1 to both tasks.

be 2m - 1 resources of which m - 1 resources have a cost of m and a size of m, and m resources have a cost of m and a size of 1. Any integral feasible solution would have to assign the m - 1 resources of size m to m - 1 tasks and the remaining m resources of unit size to another task. The task receiving the m unit size resources incurs a cost of m2 , whereas the isolation cost of every task is m, which means any integral solution would incur a  of m. Since the isolation cost of every task is m, and the resource requirement of every task is m, and further since i, j : si  Di , every resource is feasible to be allocated to every task by the LP, for every   1. A feasible LP solution therefore, allocates each of the m - 1 resources of size m to each of the 1 m tasks to an extent of m , and one unit size resource integrally to each task. The total resource received by 1 + 1 = m. The total every task is therefore (m - 1)m m 1 cost incurred by every task is (m - 1)m m + m = 2m - 1. Therefore, the LP will return a feasible solution for a -1  = 2m < 2, whereas any integral solution will incur m a  of m, giving an integrality gap of m 2  , as m  . Note that if we try to modify the LP by restricting the allocation of resources which have a large ratio of cost to size, compared to the ratio of isolation cost to the resource requirement of a task, may render the LP infeasible, when a feasible solution exists, or suboptimal. Hence, in the rest of the paper, we will only consider the case where all resources are of unit size, but may have different costs. Guessing  : We next show that we can guess a near optimal  in a logarithmic number of iterations. The minimum value of  is given by min = 1. For every guess of  , we allow a resource i to be allocated to a task j , only if ci  Ij , i.e., ci  Cj . Without loss of generality, we assume that the minimum cost of any resource is 1, since the costs are rational numbers, and can always be made integral by scaling the problem. Similarly, we assume that the sizes of the resources are 1, and the resource requirement for every task Dj is integral. Observation 2: The maximum value of  is max = cmax , where cmax = maxiE ci . Proof: Suppose that the resource requirement of a task j with the highest value of  is Dj . In the worst case, the task is allocated those resources that have the highest cost, hence Cj  Dj × cmax . However, the isola4

tion cost of the task can be expressed as Ij  Dj , since minimum cost of any resource is  1. Therefore, the D ×c maximum value of  is given by   j Djmax = cmax . With that, we can do a binary search for  in the range [min, max ] = [1, cmax ], using a resolution of and guess the optimal  in log2 ( cmax ) iterations. The next theorem shows that a near optimal value of  can be found by such a method. Theorem 3: Let OP T -IN T be the objective function value for an integral optimal solution (where the optimality is with respect to the fairness objective). Let OP T -LP be the smallest  for which the linear program LP is feasible. Then OP T -LP  OP T -IN T + . Proof: Let the smallest  for which the LP is feasible be OP T -LP . By definition of OP T -LP and by the property of binary search it must hold that for OP T -LP - , the LP must have been infeasible. Therefore, there exists no feasible resource allocation satisfying the specified constraints in the LP, such that the cost for every task j is  (OP T -LP - ) Ij and allocation is  Dj , and every resource is allocated to unity. This implies that in any feasible (integral or otherwise) allocation of resources satisfying the resource requirement Dj for every task j , there must exist a task j such that Cj > (OP T -LP - ) Ij . Since any the optimal integral allocation is a feasible allocation (satisfying the LP constraints), this implies that there exists a task j in the optimal integral allocation, such that the cost incurred by j is Cj > (OP T -LP - ) Ij , C therefore, OP T -IN T  I j > (OP T -LP - ). This j completes the proof. In the remainder of the paper, we assume that the resources are of unit size. Note that, with unit-sized resources, the isolation cost Ij of a task j , with demand Dj , is simply the sum of the cost of Dj lowest cost resources. We also assume that there are sufficient resources in the system to satisfy the demand of all tasks simultaneously, but possibly with different allocation costs. IV. LP ROUNDING A LGORITHM In this section, we present a polynomial LP rounding algorithm with a 2 + O( ) approximation to the fair resource allocation problem. The factor is due to the binary search performed over the space of  with a resolution . We later (in Section V) show that for unit size resources, even the LP has an integrality gap approaching 2, hence our rounding algorithm is essentially tight. The rounding proceeds as follows. First, we convert a feasible LP solution to another feasible solution where 5

every resource, if allocated, is allocated up to unity. In other words, no resource has an overall fractional allocation. Once we have done this conversion, we essentially have a perfect fractional matching, where every resource is allocated to unity, and every task's resource requirement is exactly satisfied, while the cost of every task j is  Ij . Now, we convert this to an integral, feasible, perfect matching, such that the total cost of the resources allocated to every task j is at most twice Ij , where the LP was feasible for  . This procedure is described in detail in Section IV-A. We now show how to convert a feasible LP solution to a perfect fractional matching, where every resource is allocated to unity, and every task's resource requirement is exactly satisfied, while the cost of every task j is  Ij . Lemma 4: Let LP -OP T be the smallest value for which the LP is feasible. Then there exists a feasible LP solution  for the same value of  , in which any resource that has a non-zero allocation, is allocated to an extent of 1; formally, if i  E , j  P such that xij > 0 then it holds that j P xij = 1. Proof: Informally, the proof is based on the following reasoning. A more formal proof follows the informal discussion. Depending on whether one or more resources are fractionally allocated, we need to consider two cases. If there exists one resource i that is fractionally allocated (i.e., xi = j P xi,j < 1) then in a feasible solution, some tasks must be over-allocated. This is because (i) total resource requirement D = j P Dj of tasks is integral since individual resource requests Dj of each task are integral, and (ii) resources are unit size, (iii) only one resource is fractionally assigned, therefore, any feasible solution must have assigned  D resources to unity. Hence, there must be over-allocation of resources and this over allocation sums to xi which can be eliminated by readjusting the resource allocation of tasks without violating the feasibility of the solution thereby making all the resource allocations integral. If there exists multiple resources that are fractionally assigned then considering a pair of such resources at a time and by readjusting their resource allocations (decreasing one of the fractional allocation and increasing the other fractional allocation) systematically converts at least one of the fractional resource allocations into an integral allocation without violating the feasibility of the solution. Repeating this process either eliminates all the fractional allocations or leaves one fractional allocation in which case we can use the procedure described for the first case. A formal proof follows now. We prove the claim by contradiction. Suppose that the claim is not true. Then

we need to consider two cases. Case 1: A single resource has an allocation xi = j P xi,j < 1. We have already argued that at least D resources must have been allocated to unity, otherwise, the total resource requirement of D cannot be met. For every task j for which resource i has a non-zero allocation to, we first reduce xi,j by kE xk,j - Dj , without any loss of feasibility. Now, let P be the set of tasks for which resource i has a non-zero allocation after this modification. All the tasks in P are now exactly satisfied in terms of their resource requirements, i.e., k xk,j = Dj j  P . Let us consider two scenarios depending on the cost ci of the fractional resource i. Scenario 1.a. First consider the scenario, where all of the resources allocated to unity, cost at most ci . Since k ,j P xk,j > j P Dj , there must exist a task j , where k xk,j > Dj . Let the highest cost resource allocated to task j be i . Since ci  ci and resource i has a non-zero allocation to task j , resource i is feasible to be allocated to j . Now, we decrease the allocation of resource i to task j by  = min xi ,j , xi,j , kE xk,j - Dj > 0 and increase the allocation of resource i to task j by  , and decrease the allocation of resource i allocation to task j by  . The resultant allocation is still feasible in terms of resource requirements to all tasks, and the cost of every task is at most the cost of the earlier allocation. Since by definition,  > 0, we have decremented xi,j . As long as xi,j > 0, there is always a task j that has been over allocated, and we repeat the above transformations, till we have removed the allocation of resource i to task j , or, xi,j = 0. If xi > 0, then there must exist another task p to which resource i has a non-zero allocation. We repeat the above steps for resource i and task p. We continue till we have removed the allocation of i to every project, without violating feasibility, and removing the fractional resource. This takes a polynomial number of transformations. Scenario 1.b. Now consider the scenario where there exists a resource that has been allocated to unity and whose cost is greater than ci . From the set of resources allocated to unity, let k be the highest cost resource. Clearly, ck > ci . Now consider a task j to which resource k is allocated. Increase the allocation of resource i to task j by  = min (xk,j , 1 - xi ), while decreasing allocation of resource k to task j by  . In the process, we have not violated feasibility since the resource requirement is still met every where, every resource is allocated at most to unity, and the costs of the tasks after this transformation is at most what they were earlier. After this transformation, if we have made resource i allocated up to unity, then resource k 6

becomes the new fractionally allocated resource having the highest cost of any non-zero allocated resource, and hence we can now apply the procedure of Scenario 1.a to reduce its allocation to 0. Otherwise, i.e., if resource i is not allocated to unity then xk,j = 0. Note that, even after this transformation, xk > 0 since  < 1. Therefore, there must exist another task j where resource k has a non-zero allocation. We repeat the above process, till we make resource i allocated to unity. This will always be possible since resource k is allocated to unity, and 1 - xi < 1. Now, resource k becomes the new fractionally allocated resource, and it costs the most among all the resources allocated, hence this reduces to Scenario 1.a. We repeat the transformations outlined in Scenario 1.a, till we reduce xk to 0. Case 2: More than one resource has an allocation < 1. Let us consider a pair of resources (i, i ) both of which are fractionally allocated. Without loss of generality, let ci  ci . Suppose xi + xi  1. In this case, for every task j that resource i has a non-zero allocation to, we make xi,j = xi ,j and reduce xi ,j to 0. In this way, we have reduced the number of resources with fractional allocation by at least 1. We repeat this for every pair of fractional resources, till we are left with at most one fractional resource. Then we perform the transformations described in Case 1. Now, suppose xi + xi > 1. Again, we repeat the above procedure for every task that resource i has a non-zero allocation to, till we come across a task, where xi ,j > 1 - xi , where xi refers to the current fractional allocation of resource i after the above transformations. In this case, we set xi,j = 1 - xi , and xi ,j = xi ,j - xi,j . Now, we have again reduced the number of fractional resources by 1. We repeat the above described procedures for every pair, till we are left with at most one fractional resource, which corresponds to Case 1. This completes the proof. We now describe the rounding algorithm. A. Description of the LP Rounding Algorithm The solution  is a set of connected components in a bipartite graph, with one vertex partition V1 = {i  E| j P xi,j > 0} being the set of resources with non-zero allocation. In fact, after the polynomial transformation described in Lemma 4, V1 = {i  E| j P xi,j = 1}. The other partition V2 is the set of tasks P . We have already argued that we have a perfect fractional matching in this bipartite graph, which we will now convert to a perfect integral matching, without violating the cost constraints too much. From  , we first remove all the edges that are integral, allocating the corresponding resource to the corresponding task, without any loss in feasibility. Let V1 = E be

  1    

2   
  

3   
  

the set of resources who are yet unallocated and V2 = P be the set of tasks, that have still not been fully allocated, after removing the integral edges. Since all the resource requirements are integral, and all resources are allocated to unity, the total number of resource available is no less than the total resource requirement over all tasks, i.e., |V1 |  pV Dp , i.e., we still have a perfect fractional 2 matching. We order the resource vertices in non-increasing order of their costs, and assume henceforth that they are numbered accordingly, namely e1 , e2 , . . . , e|V1 | , where ce1  ce2  . . . ce|V | . The tasks are ordered in 1 any arbitrary order, p1 , p2 , . . . , p|V2 | . Now, we use a procedure, which is somewhat inspired by the analysis of the generalized assignment problem, in the seminal work of Shmoys and Tardos [10] to transform the current fractional matching to an integral matching. The algorithm proceeds as follows. Start with the highest cost resource and allocate it integrally to any task that it has a non-zero allocation to. Now, adjust the allocation of the resources to maintain feasibility. Then, proceed to completely allocate this task. Once done, pick the next highest cost resource, that is not yet integrally allocated and repeat the procedure. We describe this in detail in the following paragraphs. Let pj be a task where resource e1 has a nonzero allocation, in other words, (e1 , pj ) is an edge in this connected component. We allocate resource e1 to resource pj integrally (i.e., xe1 ,pj = 1), and remove e1 from the set V1 . Now, we find the lowest resource index ei such that ek |k{1,...,i} xek ,pj  1, and ek |k{1,...,i-1} xek ,pj < 1. We remove the edge xei ,pj and split the node i into two nodes i1 and i2 , and add two edges xei1 ,pj = ek |k{1,...,i} xek ,pj - 1, and xei2 ,pj = xei ,pj - xei1 ,pj . We have made xe1 ,pj = 1. Therefore to maintain feasibility, we have to make xe1 ,pq = 0 pq  P , q = j . Note that all the resources ek , 1 < k  i, have costs  ce1 , and hence are feasible to be allocated to any task that resource e1 was allocated to. Now, consider a task j to which resource e1 had a nonzero allocation. We know that all of the resources ek , 2  k  i are feasible to be allocated to j . Hence, we add an edge from resource e2 to task j of value xe2 ,j = min (xe2 ,j , xe1 ,j ) to j and decrement xe2 ,j by xe2 ,j . Now, if xe2 ,j = xe1 ,j , we consider the next task j that resource e1 had an allocation to, and repeat the above process, with e2 if xe2 ,j > 0. Otherwise, if xe2 ,j = 0, and xe2 ,j < xe1 ,j , we pick e3 do the same procedure. We continue till either we have removed all the edges (ek , pj ) for all 1  k < i and xei1 ,pj , or we have have removed all edges xe1 ,pq for all q = j , in a 7

1 1

2

3 3  
 

1

2  
 

1

2

3 1  2    

Fig. 4.

Illustration of one iteration of the LP rounding algorithm.

polynomial number of transformations (O(|V1 | + |V2 |)). Note that xei1 ,pj + ek |k{2,...,i} xek ,pj = 1 - xe1 ,pj , therefore, both the events will happen simultaneously, after which we have a feasible solution, where every resource in V1 is allocated up to unity and every task in V2 is fully allocated. If task pj had only one resource requirement, then we have allocated task pj integrally, while not violating the cost constraint of pj , as ce1  Cj . Otherwise, if Dj > 1, then we still have unmet resource requirement in task pj . Now, we find the lowest resource index u > 1, that has a non-zero allocation to task pj , i.e., xeu ,pj > 0 and repeat the above. If xei2 ,pj > 0, then u = i, otherwise, u > i. We allocate resource u integrally to task pj , remove the resource from V1 , and repeat the above procedure. We continue till pj is allocated Dj integral resources. Once task pj is fully allocated integrally, we remove it from V2 , and find the next highest cost resource es remaining in V1 . Let pr be a task that es has a non-zero allocation to. We perform the same transformations on resource es and task pr and continue, till both V1 =  and V2 = . Figure 4 provides an example for one iteration of the rounding algorithm. Observe that we allocate only one resource integrally to a task at a time, and adequately remove some assignments to maintain feasibility of total allocation of any resource, and resource allocation of any task. Since, initially |V1 |  pk V2 Dpk , and we are not violating the size constraints on resource allocations at any iteration, we will always find a resource to allocate to a task yet unsatisfied, that is, if V2 = , that implies V1 = . Not only that, at any iteration, when we change the allocations, we maintain feasibility in terms of the assignment restrictions on the resources; in other words, we allow a resource to be allocated to a task, only if the cost of the resource is at most the total cost

allowed for the task. Moreover, at any iteration, when we are processing the resources allocated to a task q , we are removing Dq vertices from V1 and 1 vertex from V2 . Therefore, in at most |V1 | iterations, we will have allocated every resource and and every task integrally. B. Cost Incurred due to Rounding Algorithm In this section, we argue that the resultant integral allocation will be at most 2Cj for every task j . Note that the first resource e1 that is allocated to any task pj has a non-zero allocation to pj , hence, ce1  Cj . Let the next resource to be allocated be eu , where u > 1. Also, let i be the lowest index such that ek |1ki xek ,pj  1. Note that, u  i. According to the procedure outlined earlier, we must have added two vertices i1 and i2 to the graph, in place of i, and replaced the edge xei ,pj by xei1 ,pj and xei2 ,pj , such that ek |1k<i xek ,pj + xei1 ,pj = 1, and xei2 ,pj = xei ,pj - xei1 ,pj . In this case, C1 = ek |1k<i cek xek ,pj + cei xei1 ,pj . Clearly, C1  cei ek |1k<i xek ,pj + cei xei1 ,pj = cei as ek |1k<i xek ,pj + xei1 ,pj = 1. Therefore, cei  C1 , hence we charge its cost to C1 at no additional cost. Similarly, let the next resource to be integrally allocated to j is ev , v > u. This means ek |ukv xek ,pj > 1, and let ew be the lowest index such that ek |ukw xek ,pj  1. Note that v  w . Again, following the same of procedure of adding two vertices (say w1 and w2 ) and replacing the edges as described above, we obtain cew  C2 and hence we charge its cost to C2 at no additional cost where C2 = ek |uk<w cek xek ,pj + cew xew1 ,pj The total cost Cj = C1 + C2 + . . . CDj , where Ci s are defined above, and we have charged the cost of the k th resource allocated to pj , to Ck-1 , where k  {2, . . . , Dj }, therefore, the total cost of these resources is  Cj . The first resource to be allocated has a cost ce1  Cj . Therefore, the cost of the total integral allocation to task pj is at most 2Cj . We repeat the above argument for every task. C. Approximation Ratio of LP Rounding Algorithm Theorem 5: Given a  for which a feasible LP solution exists, there exists a polynomial time algorithm that gives an integral feasible resource allocation to all tasks, such that the cost of any task pj , is at most 2Ij , where Ij is its isolation cost. Proof: The proof follows from the discussion in Sections IV-A and IV-B. Theorem 6: There exists a polynomial 2 + O( ) approximation algorithm to the integral fair resource allocation problem. Proof: From Theorem 5, we know that given a  , for which a feasible LP solution exists, we can find 8

an integral feasible solution, where every task costs at most 2Cj = 2Ij . From Theorem 3, we know that the lowest value for which the LP is feasible is, LP -OP T  OP T -IN T + , and it can be found in at most log cmax iterations, for any fixed > 0. Hence the resultant value of  incurred by our algorithm is  2LP -OP T  2OP T -IN T + 2 . This proves the theorem. V. I NTEGRALITY G AP FOR U NIT S IZE R ESOURCES In this section we show that the LP has an integrality gap approaching 2. Theorem 7: The LP has an integrality gap  2, hence the LP rounding algorithm of Section IV is tight. Proof: Consider an instance with m tasks, each with a resource requirement of m. Let there be m2 resources of which m2 - 1 resources are of cost 1 and another resource is of cost m. Any feasibly integral solution would have to allocate the resource of cost m to one of the tasks thereby incurring a cost of 2m-1. However, the isolation cost I of every task is m. Therefore, any inte-1 1 gral feasible solution would incur a   2m = 2- m . m For the LP, every resource is feasible to be allocated to every task for every   1, since the isolation cost of every task is m and the resource requirement of every 1 . A feasible LP task is m. Let us consider  = 1 + m solution would allocate to every task, m2 - m unit cost resources integrally, m - 1 unit cost resources to an 1 1 extent of m , and m of the resource of cost m. With such an allocation, every task receives a resource allocation of m units, and every resource is allocated up to 1. Note that the overall number of resources allocated is m2 -m+m-1+1 = m2 . The cost incurred by every task 1 1 1 +m m = m+1- m < m+1, which is (m-1)+(m-1) m m+1 is feasible since  = m . Therefore, the integrality gap 2- 1 is at least 1+ m 1  2, when m  . Hence the proof.
m

VI. G REEDY ALGORITHM In this section, we consider a restricted version of the problem, where the costs of the resources, though arbitrary, vary smoothly across resources. The resources are unit sized as in the previous sections. We give a greedy algorithm which will give a near optimal fairness in resource allocation, when all the tasks have the same resource requirement. We first define some notations. Definition 8: A set of resources are called homogenous, if, when ordered in non-increasing order of their costs, the difference in costs between two consecutive resources is very small,  for some small fixed > 0. In other words, assuming the resources are numbered according to their position in the sorted order, for any i  {1, . . . , |E|}, ci+1 - ci  . We assume that ci  1.

Definition 9: A set of tasks are called identical in terms of their resource requirements, if their resource requirements are identical. In other words, for every pair of tasks j, j  P , Dj = Dj = D, where D  1. In this version of the problem, we assume the resources are homogeneous and give a greedy algorithm which allocates resources to the tasks in iterations, till every task is fully allocated its total resource requirement. In every iteration, the task to allocate a resource is chosen according to a rule which is a function of the total resource requirement of the task, remaining resource requirement and the cost incurred so far by the task due to allocated resources. To the chosen task, the algorithm allocates the next available resource in the sorted order. The choosing rule is as follows: pick the task j with the largest value of f (j ), i.e., j = arg maxkP f (k ), D +C where f (j ) is defined as: f (j ) = j Dj j , where Dj is the total resource requirement of task j , Dj is the remaining resource requirement or current deficit, Cj is the current cost incurred by j by the resources already allocated. Note that the isolation cost of a task depends on the total resource requirement of the task, and is higher for tasks with high resource requirements. The intuition behind choosing this function is that we want to favor the tasks that have already incurred a high cost relative to the total resource requirement (hence, the isolation cost), and also the tasks for which the remaining resource requirement is high relative to the total resource requirement. By favoring a task, we mean allocating it lower cost resources. This is done to balance the ratio of actual costs to isolation costs across resources. The value of  is chosen so that the greedy algorithm behaves in a certain manner to ensure fairness of cost across tasks. 1 . Specifically,  = iE ci The pseudo-code of the greedy algorithm is presented in Algorithm 1. We will prove that when the resources are homogeneous and tasks are identical, the greedy algorithm will give a near optimal fairness ratio. Let us denote the number of tasks |P| = n, in the following analysis for notational ease, and the resource requirement of each as D. Since we have n tasks, each requiring D resources, the greedy algorithm will require nD iterations. Let us define the set of consecutive n iterations [kn + 1, kn + 2, . . . , (k + 1)n] as the k th block iteration. Clearly we have D block iterations. We next prove that the greedy algorithm will allocate resources to the tasks in an alternating round-robin manner, such that in the ith block iteration, where i  {1, . . . , D}, every task will be allocated exactly one resource. Lemma 10: Every task is allocated a resource in every 9

Algorithm 1: Greedy algorithm for fair resource allocation.
Input : P : set of tasks; Dj : total resource requirement in task j  P Dj : current resource deficit in task j  P (initially set to the original resource requirement of j ; Cj : current cost incurred by task j  P (initially set to 0); E : set of resources; ci : cost of a resource i  E Output: xij : assignment of resources to tasks. Set Dj  Dj and Cj  0, j  P . Sort all resources in E such that ci  ci+1 i  {1, . . . , |E| - 1} Set xi,j  0, i  E , j  P . Set i  1; while P =  do Choose the task j , such that
k k j = arg maxkP Dk Set xi,j  1 and allocate resource i to task j . Set Dj  Dj - 1 and Cj  Cj + ci Set i  i + 1. if Dj = 0 then P  P \ j. end

1 2 3 4 5

D +C

6 7 8 9 10 11

end

block iteration (in other words, consecutive n iterations). Proof: Let us consider the first block iteration. Suppose a task j is not allocated at all in block iteration 1. Since a block iteration consists of n rounds, this implies that some task j is was allocated  2 resources in this iteration. Consider the round in the first block iteration, when j was chosen for a second allocation. According to the choosing rule, therefore, j = arg maxkP f (k ), Dj +Cj Dj +Cj  . But Dj = D which implies D D whereas Dj = D - 1, Cj = 0 and Cj = c, where c is the cost of the resource allocated to j . Clearly, D +C Dj +Cj 1 = 1. On the other hand, j D j = 1 - D + D c 1 < 1 . This gives a contradiction. Therefore, D kE ck every task gets an allocation in the first block iteration. Now, let us assume by induction hypothesis that this holds for the first i block iterations, where i < D. Now, all tasks have have i unit resources. If a task j does not get an allocation in the iteration i + 1, then this implies that some task j is was allocated  2 resources in this iteration. Consider the round in the i + 1 block iteration, when j was chosen for a second allocation. Since j = Dj +Cj Dj +Cj arg maxkP f (k ),  . Note that D D Dj = D - (i + 1), whereas Dj = D - i. Because of our choice of , 
Dj D

Also, =1 1 - i+1 D . Therefore, f (j ) - f (j ) < 0. This gives a contradiction. Hence, we have proved inductively the statement of the lemma. Observation 11: When all tasks have received the same number of resources, the next task to be allocated a resource is the task that has incurred the highest cost

Cj 1 D < D , therefore, Dj i -D , whereas D =



Cj D

-

Cj D

<

1 D.

so far. This follows from the function used by greedy as the choosing rule. Lemma 12: At the end of every block iteration i, the cost incurred by any task j , Cj is at most Ci,OP T + 1 n , where Ci,OP T = n e{1,...,i·n} ce is the optimal fair allocation cost when all the tasks are identical, each with a resource requirement of i, and the resources are homogeneous. Proof: At the end of any block iteration i, let the costs incurred by tasks be Cj j  [1, . . . , n]. Since any optimal solution would allocate the first i · n resources from the sorted list to the n tasks, the total cost incurred across all tasks in the greedy solution till iteration i is the same as that of any optimal solution. Therefore, 1 Ci,OP T = n j [1,...,n] Cj . Let Cmin,i denote the lowest cost incurred by any task at the end of block iteration i and Cmax,i denote the highest cost incurred by any task. Clearly, Ci,OP T  Cmin,i by definition. We will prove by induction that for any pair of tasks (j, j ). at the end of block iteration i, |Cj - Cj |  n . At the end of block iteration 1, Cmin,1 = c1 , and Cmax,1 = cn  c1 + n , (where cp is the cost of the pth resource in the sorted order), by our assumption of homogeneous resources. Hence, the base case holds. Now, we assume by induction hypothesis, that the above holds for all block iterations {1, . . . , i - 1}. In the block iteration i, according to Observation 11 and Lemma 10, the task with the highest cost is allocated first, followed by the next highest cost, and so on, till the lowest cost task gets allocated last. Suppose at the end of block iteration i, Cj,i  Cj ,i , where Cj,i denotes the cost incurred by j at the end of iteration i, hence j will allocated before j . But from induction hypothesis, Cj,i  Cj ,i + n . Therefore, Cj,i+1 - Cj ,i+1  c - c + n , where c is the cost of the resource allocated to j in block iteration i + 1, and c is the cost of the resource allocated to j in block iteration i +1. Note that c  c due to the sorted order and from Observation 11. Therefore, Cj,i+1 - Cj ,i+1  n . At the same time, Cj ,i+1 - Cj,i+1 = Cj ,i + c - Cj,i - c  c - c , since Cj ,i  Cj,i . But we know from homogeneous property of resources. c - c  n , therefore, Cj,i+1 - Cj ,i+1  n . This holds for any pair of resources (j, j ). This completes the proof by induction. We have proved that for any pair of tasks (j, j ). at the end of block iteration i, |Cj - Cj |  n . Therefore, Cmax,i  Cmin,i + n  Ci,OP T + n . Theorem 13: For homogeneous resources and identical tasks, the greedy algorithm gives a 1 + approximation to the fair resource allocation problem. 10

Proof: Let Cmax,D be the highest cost incurred by any task at the end of nD iterations, and COP T be the optimal fair allocation cost. For any optimal solution, T OP T = COP where I is the isolation cost of any I resource. From Lemma 12, Cmax,D  COP T + n . T +n Therefore, the resultant greedy  COP I . Hence, greedy n  1 + . We know that C = nDcavg OP T OP T COP T where cavg the average cost of the first nD resources.  n Therefore, OP  1 + nDc < 1 + , since D  1 avg T and cavg  c1  1. VII. C ONCLUDING R EMARKS This paper studied the problem of fair allocation of resources with heterogeneous costs to tasks with heterogeneous resource requirements. We show that the problem is strongly NP-Hard even with unit sized resources, and present an LP rounding approximation algorithm for this version of the problem and a near-optimal greedy algorithm for a special case in which costs of resources do not differ much and resource requirements of tasks are identical. As part of future work, we plan to study the problem where resources have limited heterogeneity in costs, as well as, the online version of the problem. R EFERENCES
[1] Yossi Azar, Umang Bhaskar, Lisa Fleischer, and Debmalya Panigrahi. Online mixed packing and covering. In Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 85­100, 2013. [2] Venkatesan T Chakaravarthy, Anamitra Roy Choudhury, Sivaramakrishnan R Natarajan, and Sambuddha Roy. Knapsack cover subject to a matroid constraint. In LIPIcs-Leibniz International Proceedings in Informatics, volume 24. Schloss DagstuhlLeibniz-Zentrum fuer Informatik, 2013. [3] Bruno Escoffier, Laurent Gourv` es, and J´ er^ ome Monnot. Fair solutions for some multiagent optimization problems. Autonomous agents and multi-agent systems, 26(2):184­201, 2013. [4] Ali Ghodsi, Matei Zaharia, Scott Shenker, and Ion Stoica. Choosy: max-min fair sharing for datacenter jobs with constraints. In Proceedings of the 8th ACM European Conference on Computer Systems (EuroSys), pages 365­378, 2013. [5] Raj Jain, Dah-Ming Chiu, and W Hawe. A quantitative measure of fairness and discrimination for resource allocation in shared computer systems. Technical Report TR-301, DEC, 1984. [6] Hans Kellerer, Ulrich Pferschy, and David Pisinger. Knapsack problems. Springer, 2004. [7] H. J. Kushner and P. A. Whiting. Convergence of proportionalfair sharing algorithms under general conditions. IEEE Transactions on Wireless Communications, 3(4):1250­1259, 2004. ´ Tardos. Approximation [8] J. K. Lenstra, D. B. Shmoys, and E. algorithms for scheduling unrelated parallel machines. Math. Program., 46(3):259­271, 1990. [9] Alan Shieh, Srikanth Kandula, Albert G. Greenberg, Changhoon Kim, and Bikas Saha. Sharing the data center network. In NSDI, 2011. ´ [10] David B. Shmoys and Eva Tardos. An approximation algorithm for the generalized assignment problem. Math. Program., 62(3):461­474, 1993. [11] Neal E. Young. Sequential and parallel algorithms for mixed packing and covering. In Proceedings of the 42nd IEEE Symposium on Foundations of Computer Science (FOCS), pages 538­ 546, 2001.

