Fair Resource Allocation for Heterogeneous
Tasks
Koyel Mukherjee, Partha Dutta, Gurulingesh Raravi, Thangaraj Balasubramaniam, Koustuv Dasgupta, Atul Singh
Xerox Research Center India, Bangalore, India 560105
Email: {Koyel.Mukherjee, Partha.Dutta, Gurulingesh.Raravi}@xerox.com
{Rajasubramaniam.T, Koustuv.Dasgupta, Atul.Singh}@xerox.com

Abstract—We consider the problem of fair allocation of
resources to tasks where a resource has to be assigned to
at most one task entirely without any fractional allocation.
The system is heterogeneous in the sense that the cost
may vary across resources, and different tasks may have
different resource demand. Due to heterogeneity of resource
costs, the cost of allocation for a task in isolation, without
any other competing task, may differ significantly from
its allocation cost when the task is allocated along with
other tasks. In this context, we consider the problem of
allocating resources to tasks, while ensuring that the cost
is distributed fairly across the tasks, namely, the ratio of
allocation cost of a task to its isolation cost is minimized
over all tasks. We show that this fair resource allocation
problem is strongly NP-Hard even when resources are of
unit size by a reduction from 3-partition. Our main results
are a 2+O() approximation LP rounding based algorithm
for the problem when resources are of unit capacity, and
a near-optimal greedy algorithm for a more restricted
version.
The above fair allocation problem arises in various context, such as, allocating computing resources for reservation
requests from clients in a data center, allocating resources
to computing tasks in grid computing, or allocating personnel for projects in service delivery organizations.
Keywords-Resource allocation, Approximation algorithm,
LP rounding, Greedy algorithm

I. I NTRODUCTION
In this work we consider a heterogeneous system
where each resource has an associated cost and a capacity (or size), and a resource can be allocated entirely
to at most one task, without any fractional allocation.
Every task has a demand (or capacity requirement) and
we would like to minimize the resource allocation cost
for meeting this demand. In isolation, i.e., when there
is exactly one task in the system, an ideal allocation
would select a set of resources that would meet the
task’s demand while minimizing its total cost. This case
of a task in isolation is identical to the minimization
knapsack problem [6], a known NP-Hard problem, and
we call the corresponding minimum cost of a task, its
isolation cost. However, in presence of multiple tasks,
due to heterogeneity of resources, the resource allocation

cost for a task may significantly differ from its isolation
cost. In this scenario, we would like to minimize the cost
for multiple tasks in a manner that is fair across tasks.
In particular, when multiple tasks are present, we want
to allocate the resources in a way that minimizes over
all tasks, the ratio of the allocation cost of each task to
its isolation cost.
Fair resource allocation is one of the core problems
in parallel and distributed computing which arises in
multiple settings, as illustrated next. Consider a multitenant data center where multiple tenants request to reserve certain computing capacity over the set of available
(physical or virtual) machines. Here the tasks are the
reservation requests with their respective demands, and
the resources are the machines, each with its computing
capacity and cost. We would like to ensure a resource
allocation that is fair across tenants, in terms of the
costs of resources allocated. From a tenant’s point of
view, such a fair allocation is preferable than the case
where the data center operator tries to minimize the
total cost over all resources. A similar problem can
be seen in a geographically distributed grid computing
environment in which different users request computing
resource reservations, where the resource costs can be
the monetary cost, or the cost of network communication. Finally, the problem of allocating personnel to
project in large service delivery organizations, such that
any increase in project cost, due to the presence of other
tasks, is fairly distributed, can also be modeled as the
above fair resource allocation problem.
A. Problem Definition and System Model
We study the following problem. Given a set of tasks
where each task has a certain resource requirement
(also called demand), and a set of resources where
each resource has a certain resource supply (also called
capacity or size of the resource) and a cost, find a fair
allocation of tasks to resources such that the resource
requirements of all the tasks are met and each resource
is allocated entirely to at most one task. The fairness is

defined with respect to the ratio of the cost of a task
when allocated along with other tasks, to the optimal
cost of the task, when allocated in isolation (i.e., when
other tasks are not present). Our goal is to minimize the
maximum of this ratio across all tasks. Henceforth, we
refer to this problem as the fair allocation problem.
Formally, we are given a set of tasks P, and we
have access to a set of resources E. Each task j is
characterized by its resource requirement denoted by
Dj . Each resource i is characterized by two parameters:
a resource supply si and a cost ci . Upon allocating a
resource i to a task j, the task incurs a cost of ci and
its resource requirement is reduced by si . In order for
a task j to successfully execute, it must be ensured that
the total size of resources allocated to it is at least Dj .
We require all assignments to be integral (0 or 1), i.e.,
each resource must be entirely assigned to a task and
hence cannot be fractionally assigned to multiple tasks.
We denote by Ij the isolation cost of a task j, that is
the cost that the task would incur if this is the only task
that needs to be allocated resources and no other tasks
were present in the system. We denote by Cj the cost
incurred by the task j when resources are allocated to
it along with other tasks in the system; we refer to this
cost as the actual cost of the task. The problem objective
is to minimize γ = maxi∈P CIii .

The combinatorial optimization problem studied in
this paper is a mixed packing and covering problem [11],
where we need to cover the demand of task using resources subject to packing the selected resources within
a certain cost budget. Young [11] studies the fractional
version of the problem, which is not NP-hard, and
provides efficient sequential and parallel algorithms for
the problem. Chakaravarthy et al. [2] study a version
of mixed packing and covering problems, where they
solve a knapsack cover problem subject to cardinality
constraints, and then extend it to multiple matroid constraints. In terms of the resource allocation problem that
we study in this paper, the work of Chakaravarthy et
al. [2] can be used to find the minimum cost resource
allocation for one task, such that the total size of the
resources allocated meets the total resource requirement
of the task, and the number of resources allocated is
at most a pre-specified number. This is slightly different
compared to our problem where we try to ensure fairness
of resource allocation costs across multiple tasks, such
that the total resource requirement of every task is met.
Escoffier et al. [3] study some multi-agent optimization
problems where the goal is to maximize the satisfaction
of the least satisfied agent, where the satisfaction of an
agent is defined as the ratio between his utility for the
given solution and his maximum possible utility. For
some NP-hard problems, assuming a feasible solution
exists, they give polynomial algorithms with approximation factors dependent on the number of agents and/or on
other problem parameters. Though the objective of the
problem studied is quite similar to ours, the underlying
problem we study is different, and we provide constant
approximations, not dependent on the problem size.
Moreover, our techniques are fundamentally different
from Escoffier et al. [3].
Online algorithms for the fractional mixed packing
and covering problem are investigated by Azar et al. [1],
where the packing constraints are known offline, while
the covering constraints get revealed online. Their objective is to minimize the maximum multiplicative factor by
which any constraint is getting violated, while meeting
all the covering constraints. They give a polylogarithmic
competitive ratio, and a nearly tight lower bound for
the fractional problem. In contrast, we study an integral,
offline version of the above problem, for which we give
constant approximations.

B. Related Work
Fairness of resource allocation has been well-studied
both from a theoretical and practical point of view. Fair
sharing of network resources (such as a wired network
links and wireless spectrum) has been extensively studied, and various indices and algorithms for fairness have
been developed, such as [5], [7]. More recent work
on sharing of system resources has focused on sharing
resources in data centers [4], [9], and on a variant of
max-min fairness. Our work differs from these [4], [5],
[7], [9] in following two ways. Firstly, we consider a
system where there are sufficient resources to satisfy
requirements of all tasks, but the cost of the resources
may vary, which in turn results in increase in cost of task
in presence of other tasks. Most earlier work considers
a system where the number of resources is limited and
may not be able to fully satisfy the demands of all tasks.
With the rapid increase in the computing capacity of data
centers, our assumption of a large number of available
resources from one or more data centers, albeit with
different (rental) costs, is increasingly becoming more
relevant. Secondly, we give a provable fairness guarantee
for tasks, where fairness is quantified by the ratio of
actual cost of a task to its isolation cost, which has not
been investigated earlier.

C. Our Contributions
This paper makes the following contributions.
1) We first show that the fair allocation problem
is NP-Hard in the strong sense even when the
resources are of unit size.
2

Minimize γ subject to the following constraints:
P
I1.
∀j ∈ P
Pi∈E xi,j × ci ≤ γ × Ij
I2.
∀j ∈ P
Pi∈E xi,j × si ≥ Dj
I3.
∀i ∈ E
j∈P xi,j ≤ 1
I4.
xi,j ∈ {0, 1}
∀i ∈ E, j ∈ P

2) We formulate the fair allocation problem as a
mixed packing and covering problem and give a
2 + O() approximation algorithm, based on LP
rounding when resources are unit sized.
3) We further show that the LP considered has an
integrality gap of 2, hence the bound of 2 + O()
is essentially tight for this LP.
4) Finally, for a restricted version of the problem, we
give a near-optimal greedy algorithm.
We would like to note that, although we assume that
resources cannot be fractionally allocated to a task, it is
straightforward to extend our methods to a setup where a
resource can be allocated in multiples of a certain given
fraction k1 , by creating k copies of the resource each
with k1 of the cost and size of the original resource.

Fig. 1.

An integer linear program for the fair allocation problem.

to have exactly 3 integers. Now, let us define a fair
resource allocation problem, where we have m tasks,
each requiring 3 units of resource. We create n = 3m
resources, each of unit size, where the cost of each
resource is ci = ai . Let us order the integers in the 3partition instance in non-decreasing order of their sizes.
Let the sum of the 3 smallest integers be I. The isolation
cost of every task is therefore equal to I. The feasibility
question we ask is whether γ = BI is feasible. If there
exists a feasible solution to the 3-partition instance, that
implies that γ = BI is feasible, since this corresponds
to 3 units of resources per task, and the cost incurred
by every task is B. At the same time, if there exists a
feasible γ = BI for the fair resource allocation problem,
then this implies that the 3-partition instance is feasible.
Every task has received 3 resources, and the cost incurred
by every task must be ≤ γI = BI I = B. Since we
have allocated every resource, the total sum of the costs
incurred by all m tasks is mB, hence no task can cost
< B, as that would make another task cost > B, which
cannot happen, γ being feasible. As a result, this requires
every task to cost exactly B. Therefore, the resource
allocations to the m tasks corresponds to feasible m
partitions of the integers in 3-partition, where the sum
of the integers in every partition is exactly B.

D. Organization of the Paper
The rest of the paper is organized as follows. In
Section II, we show that the fair allocation problem is
strongly NP-hard even for unit size resources. Then we
formulate the problem as an integer linear program and
show that a naive relaxation has an unbounded integrality
gap in Section III, for unit sizes. We also show that
when resources have arbitrary sizes and costs, any trivial
modifications of the LP considered will still result in an
unbounded integrality gap. Hence, we focus on the unit
size resource problem the next section onwards. We give
a 2 + O() approximate LP rounding algorithm for this
problem in Section IV, following which we show that
the LP considered has an integrality gap of 2 in Section
V which essentially shows that our bound is tight. In
Section VI, we present a greedy algorithm, that in a
restricted scenario, achieves near optimal performance
and finally Section VII concludes the paper.

III. ILP FORMULATION , LP RELAXATION AND
I NTEGRALITY GAP
In this section, we formulate the problem as Integer
Linear Program (ILP), then relax it to a Linear Program
(LP) and show that the problem in the generic case
where resources may have different costs and sizes has
an unbounded integrality gap.
Recall that the aim is to find an allocation of resources
to tasks that minimizes the ratio of actual cost of
allocation to the isolation cost, for all tasks. Formally,
C
we want to minimize γ, where γ = maxj∈P Ijj . This
is subject to fulfilling the resource requirement Dj for
all tasks j ∈ P. We formulate this problem as an ILP,
shown in Figure 1.
In the formulation given in Figure 1, γ represents
an upper bound on the ratio of Cj to Ij across all
tasks j ∈ P, and since we are minimizing it, γ is the
smallest possible value for the required objective, i.e.,
C
min maxj∈P Ijj , that can be achieved by any integral
allocation. In the formulation , the inequality I1 ensures
that the cost incurred by a task j due to resource

II. NP- HARDNESS
In this section, we show that the problem of fair
resource allocation to multiple tasks, is strongly NPhard even when the resources are of unit size and have
different costs and the tasks are all identical in the sense
that the resource requirement of each task is same. The
reduction is from 3-Partition.
Theorem 1: The feasibility problem of the fair resource allocation to multiple tasks is strongly NP-hard.
Proof: Consider an instance of the 3-partition problem. There are n = 3m integersP{ai |i ∈ [1, . . . , n]}
such that the sum of the integers i∈[1,...,n] ai = mB,
and each integer ai is strictly between B4 and B2 , i.e.,
B
B
4 < ai < 2 . The feasibility question is whether there
exists a partition of the n integers into m partitions such
that the sum of the integers in each partition is exactly
equal to B. Note that this would require every partition
3

C1.
C2.
C3.
C4.

allocation is at most Cj = γIj , inequality I2 ensures that
the total resource allocated to a task is no less than its
resource requirement Dj , inequality I3 ensures that no
resource must be over allocated, and finally I4 ensures
that every resource must be integrally allocated to a task,
if at all.
A naive linear relaxation of this ILP formulation
would relax I4 to xi,j ≥ 0. However, such a relaxation
has an unbounded integrality gap as illustrated next.
Consider m tasks, each with a resource requirement of
Dj = 1, and m resources of which m−1 resources have
a cost 1 and one resource has a cost m. All resources are
of unit-size, i.e., si = 1. Any integral allocation would
have to allocate the high cost resource to one of the tasks,
hence incurring a γ = m. However, the linear program
1
would allocate m
of each resource to each task. This
will meet the resource requirement of every task since
1
m· m
= 1, while the cost incurred by every task is
1
1
m m + m−1
m = 2 − m . Therefore, the integrality gap is
m
m
≥ 2− 1 > 2 → ∞ as m → ∞.
m
To overcome this, we use the parametric pruning
technique, similar to the seminal work of Lenstra et
al. [8]. We guess the optimal value of γ, and solve
a feasibility linear program. (Later in the section, we
show that γ can be guessed in a logarithmic number of
iterations.) For each guess of γ, we solve the feasibility
linear program shown in Figure 2, where in order to
avoid giving an unfair advantage to the linear program,
we allow the LP to assign a resource i to a task j, only
if ci ≤ γ × Ij .
C1.
C2.
C3.
C4.

P
x × ci ≤ γIj
Pi∈E|ci ≤γIj i,j
xi,j × si ≥ Dj
i∈E|c
≤γI
i
j
P
j∈P xi,j ≤ 1
xi,j ≥ 0
Fig. 2.

P
Pi∈E|ci ≤γIj ∧
Pi∈E|ci ≤γIj ∧
j∈P xi,j ≤ 1
xi,j ≥ 0

si ≤Dj
si ≤Dj

xi,j × ci ≤ γIj
xi,j × si ≥ Dj

∀j ∈ P
∀j ∈ P
∀i ∈ E
∀i ∈ E, j ∈ P

Fig. 3. Further restricted LP relaxation (still with an unbounded
integrality gap for arbitrary sizes.

be 2m − 1 resources of which m − 1 resources have
a cost of m and a size of m, and m resources have a
cost of m and a size of 1. Any integral feasible solution
would have to assign the m − 1 resources of size m
to m − 1 tasks and the remaining m resources of unit
size to another task. The task receiving the m unit size
resources incurs a cost of m2 , whereas the isolation cost
of every task is m, which means any integral solution
would incur a γ of m. Since the isolation cost of every
task is m, and the resource requirement of every task
is m, and further since ∀i, j : si ≤ Di , every resource
is feasible to be allocated to every task by the LP, for
every γ ≥ 1. A feasible LP solution therefore, allocates
each of the m − 1 resources of size m to each of the
1
m tasks to an extent of m
, and one unit size resource
integrally to each task. The total resource received by
1
+ 1 = m. The total
every task is therefore (m − 1)m m
1
cost incurred by every task is (m−1)m m
+m = 2m−1.
Therefore, the LP will return a feasible solution for a
γ = 2m−1
< 2, whereas any integral solution will incur
m
a γ of m, giving an integrality gap of m
2 → ∞, as
m → ∞. Note that if we try to modify the LP by
restricting the allocation of resources which have a large
ratio of cost to size, compared to the ratio of isolation
cost to the resource requirement of a task, may render
the LP infeasible, when a feasible solution exists, or
suboptimal. Hence, in the rest of the paper, we will only
consider the case where all resources are of unit size,
but may have different costs.
Guessing γ: We next show that we can guess a near
optimal γ in a logarithmic number of iterations. The
minimum value of γ is given by γmin = 1. For every
guess of γ, we allow a resource i to be allocated to a
task j, only if ci ≤ γIj , i.e., ci ≤ Cj .
Without loss of generality, we assume that the minimum cost of any resource is 1, since the costs are rational
numbers, and can always be made integral by scaling
the problem. Similarly, we assume that the sizes of the
resources are 1, and the resource requirement for every
task Dj is integral.
Observation 2: The maximum value of γ is γmax =
cmax , where cmax = maxi∈E ci .
Proof: Suppose that the resource requirement of a
task τj with the highest value of γ is Dj . In the worst
case, the task is allocated those resources that have the
highest cost, hence Cj ≤ Dj ×cmax . However, the isola-

∀j ∈ P
∀j ∈ P
∀i ∈ E
∀i ∈ E, j ∈ P

An LP relaxation of ILP shown in Figure 1.

However, if the resources are of arbitrary sizes, then
the linear program shown in Figure 2 still has an
unbounded gap1 .
Further, simple parametric pruning along the size
dimension, specifically, allowing the LP to allocate a
resource i to a task j, only if si ≤ Dj , still cannot
remove the gap. Consider the LP shown in Figure 3. This
LP still has an unbounded integrality gap, and trivial
modification of this LP cannot remove this gap. We
show this with an example. Consider m tasks where
each task has a resource requirement of m. Let there
1 Consider a system with 2 tasks, each with a resource requirement
of Dj = 1, and 2 resources of which resource 1 has a size = 2 and a
cost 1, and resource 2 has a size 1 and a cost L  1. It can be seen
that the isolation cost of both tasks is 1. Any integral allocation would
have to allocate the high cost resource to one of the tasks, resulting in
a γ = L. However, the linear program would return a feasible solution
for γ = 1, by allocating fraction 21 of resource 1 to both tasks.

4

tion cost of the task can be expressed as Ij ≥ Dj , since
minimum cost of any resource is ≥ 1. Therefore, the
D ×c
maximum value of γ is given by γ ≤ j Djmax = cmax .

every resource, if allocated, is allocated up to unity.
In other words, no resource has an overall fractional
allocation. Once we have done this conversion, we essentially have a perfect fractional matching, where every
resource is allocated to unity, and every task’s resource
requirement is exactly satisfied, while the cost of every
task j is ≤ γIj . Now, we convert this to an integral,
feasible, perfect matching, such that the total cost of
the resources allocated to every task j is at most twice
γIj , where the LP was feasible for γ. This procedure is
described in detail in Section IV-A.
We now show how to convert a feasible LP solution
to a perfect fractional matching, where every resource is
allocated to unity, and every task’s resource requirement
is exactly satisfied, while the cost of every task j is
≤ γIj .
Lemma 4: Let γLP −OP T be the smallest value for
which the LP is feasible. Then there exists a feasible LP
solution σ for the same value of γ, in which any resource
that has a non-zero allocation, is allocated to an extent
of 1; formally,
Pif ∃i ∈ E, ∃j ∈ P such that xij > 0 then
it holds that j∈P xij = 1.
Proof: Informally, the proof is based on the following reasoning. A more formal proof follows the informal
discussion. Depending on whether one or more resources
are fractionally allocated, we need to consider two cases.
If there exists one
P resource i that is fractionally
allocated (i.e., xi = j∈P xi,j < 1) then in a feasible
solution, some tasks must be over-allocated.PThis is
because (i) total resource requirement D =
j∈P Dj
of tasks is integral since individual resource requests
Dj of each task are integral, and (ii) resources are
unit size, (iii) only one resource is fractionally assigned,
therefore, any feasible solution must have assigned ≥ D
resources to unity. Hence, there must be over-allocation
of resources and this over allocation sums to xi which
can be eliminated by readjusting the resource allocation
of tasks without violating the feasibility of the solution
thereby making all the resource allocations integral.
If there exists multiple resources that are fractionally
assigned then considering a pair of such resources at a
time and by readjusting their resource allocations (decreasing one of the fractional allocation and increasing
the other fractional allocation) systematically converts
at least one of the fractional resource allocations into an
integral allocation without violating the feasibility of the
solution. Repeating this process either eliminates all the
fractional allocations or leaves one fractional allocation
in which case we can use the procedure described for
the first case.
A formal proof follows now. We prove the claim by
contradiction. Suppose that the claim is not true. Then

With that, we can do a binary search for γ in the
range [γmin, γmax ] = [1, cmax ], using a resolution of 
and guess the optimal γ in log2 ( cmax
 ) iterations.
The next theorem shows that a near optimal value of
γ can be found by such a method.
Theorem 3: Let γOP T −IN T be the objective function
value for an integral optimal solution (where the optimality is with respect to the fairness objective). Let
γOP T −LP be the smallest γ for which the linear program
LP is feasible. Then γOP T −LP ≤ γOP T −IN T + .
Proof: Let the smallest γ for which the LP is
feasible be γOP T −LP . By definition of γOP T −LP and
by the property of binary search it must hold that
for γOP T −LP − , the LP must have been infeasible.
Therefore, there exists no feasible resource allocation
satisfying the specified constraints in the LP, such that
the cost for every task j is ≤ (γOP T −LP − ) Ij and
allocation is ≥ Dj , and every resource is allocated
to unity. This implies that in any feasible (integral or
otherwise) allocation of resources satisfying the resource
requirement Dj for every task j, there must exist a task
j 0 such that Cj 0 > (γOP T −LP − ) Ij 0 . Since any the
optimal integral allocation is a feasible allocation (satisfying the LP constraints), this implies that there exists
a task j 00 in the optimal integral allocation, such that
the cost incurred by j 00 is Cj 00 > (γOP T −LP − ) Ij 0 ,
C 00
therefore, γOP T −IN T ≥ I j00 > (γOP T −LP − ). This
j
completes the proof.
In the remainder of the paper, we assume that the
resources are of unit size. Note that, with unit-sized
resources, the isolation cost Ij of a task j, with demand
Dj , is simply the sum of the cost of Dj lowest cost
resources. We also assume that there are sufficient resources in the system to satisfy the demand of all tasks
simultaneously, but possibly with different allocation
costs.
IV. LP ROUNDING A LGORITHM
In this section, we present a polynomial LP rounding
algorithm with a 2 + O() approximation to the fair
resource allocation problem. The  factor is due to the
binary search performed over the space of γ with a
resolution . We later (in Section V) show that for unit
size resources, even the LP has an integrality gap approaching 2, hence our rounding algorithm is essentially
tight.
The rounding proceeds as follows. First, we convert a
feasible LP solution to another feasible solution where
5

becomes the new fractionally allocated resource having
the highest cost of any non-zero allocated resource, and
hence we can now apply the procedure of Scenario 1.a
to reduce its allocation to 0. Otherwise, i.e., if resource
i is not allocated to unity then xk,j 0 = 0. Note that, even
after this transformation, xk > 0 since δ < 1. Therefore,
there must exist another task j 00 where resource k has
a non-zero allocation. We repeat the above process,
till we make resource i allocated to unity. This will
always be possible since resource k is allocated to unity,
and 1 − xi < 1. Now, resource k becomes the new
fractionally allocated resource, and it costs the most
among all the resources allocated, hence this reduces to
Scenario 1.a. We repeat the transformations outlined in
Scenario 1.a, till we reduce xk to 0.
Case 2: More than one resource has an allocation
< 1. Let us consider a pair of resources (i, i0 ) both
of which are fractionally allocated. Without loss of
generality, let ci ≤ ci0 . Suppose xi + xi0 ≤ 1. In this
case, for every task j that resource i0 has a non-zero
allocation to, we make xi,j = xi0 ,j and reduce xi0 ,j to
0. In this way, we have reduced the number of resources
with fractional allocation by at least 1. We repeat this
for every pair of fractional resources, till we are left
with at most one fractional resource. Then we perform
the transformations described in Case 1. Now, suppose
xi + xi0 > 1. Again, we repeat the above procedure
for every task that resource i0 has a non-zero allocation
to, till we come across a task, where xi0 ,j > 1 − xi ,
where xi refers to the current fractional allocation of
resource i after the above transformations. In this case,
we set xi,j = 1 − xi , and xi0 ,j = xi0 ,j − xi,j . Now, we
have again reduced the number of fractional resources by
1. We repeat the above described procedures for every
pair, till we are left with at most one fractional resource,
which corresponds to Case 1.
This completes the proof.
We now describe the rounding algorithm.

we need to consider two cases.
PCase 1: A single resource has an allocation xi =
j∈P xi,j < 1. We have already argued that at least D
resources must have been allocated to unity, otherwise,
the total resource requirement of D cannot be met.
For every task j for which resource P
i has a non-zero
allocation to, we first reduce xi,j by k∈E xk,j − Dj ,
without any loss of feasibility. Now, let P 0 be the set of
tasks for which resource i has a non-zero allocation after
this modification. All the tasks in P 0 are now exactly
satisfied
in terms of their resource requirements, i.e.,
P
0
x
k∈i k,j = Dj ∀j ∈ P . Let us consider two scenarios
depending on the cost ci of the fractional resource i.
Scenario 1.a. First consider the scenario, where all
of the P
resources allocated
P to unity, cost at most ci .
Since
x
>
k,j
k∈i,j∈P
j∈P Dj , there must exist a
P
task j 0 , where k∈i xk,j 0 > Dj 0 . Let the highest cost
resource allocated to task j 0 be i0 . Since ci ≥ ci0
and resource i has a non-zero allocation to task j,
resource i0 is feasible to be allocated to j. Now, we
decrease the allocation
of resource i0 to task j 0 by δ =
P
0
0
min xi ,j , xi,j , k∈E xk,j 0 − Dj 0 > 0 and increase
the allocation of resource i0 to task j by δ, and decrease
the allocation of resource i allocation to task j by δ. The
resultant allocation is still feasible in terms of resource
requirements to all tasks, and the cost of every task
is at most the cost of the earlier allocation. Since by
definition, δ > 0, we have decremented xi,j . As long as
xi,j > 0, there is always a task j 00 that has been over
allocated, and we repeat the above transformations, till
we have removed the allocation of resource i to task j,
or, xi,j = 0. If xi > 0, then there must exist another
task p to which resource i has a non-zero allocation.
We repeat the above steps for resource i and task p.
We continue till we have removed the allocation of i to
every project, without violating feasibility, and removing
the fractional resource. This takes a polynomial number
of transformations.
Scenario 1.b. Now consider the scenario where there
exists a resource that has been allocated to unity and
whose cost is greater than ci . From the set of resources
allocated to unity, let k be the highest cost resource.
Clearly, ck > ci . Now consider a task j 0 to which
resource k is allocated. Increase the allocation of resource i to task j 0 by δ = min (xk,j 0 , 1 − xi ), while
decreasing allocation of resource k to task j 0 by δ. In
the process, we have not violated feasibility since the
resource requirement is still met every where, every
resource is allocated at most to unity, and the costs
of the tasks after this transformation is at most what
they were earlier. After this transformation, if we have
made resource i allocated up to unity, then resource k

A. Description of the LP Rounding Algorithm
The solution σ is a set of connected components
in a bipartite
P graph, with one vertex partition V1 =
{i ∈ E| j∈P xi,j > 0} being the set of resources
with non-zero allocation. In fact, after the polynomial
transformation
described in Lemma 4, V1 = {i ∈
P
E| j∈P xi,j = 1}. The other partition V2 is the set of
tasks P. We have already argued that we have a perfect
fractional matching in this bipartite graph, which we
will now convert to a perfect integral matching, without
violating the cost constraints too much.
From σ, we first remove all the edges that are integral,
allocating the corresponding resource to the corresponding task, without any loss in feasibility. Let V10 = E 0 be
6

the set of resources who are yet unallocated and V20 = P 0
be the set of tasks, that have still not been fully allocated,
after removing the integral edges. Since all the resource
requirements are integral, and all resources are allocated
to unity, the total number of resource available is no less
than thePtotal resource requirement over all tasks, i.e.,
|V10 | ≥ p∈V 0 Dp , i.e., we still have a perfect fractional
2
matching.
We order the resource vertices in non-increasing order
of their costs, and assume henceforth that they are
numbered accordingly, namely e1 , e2 , . . . , e|V10 | , where
ce1 ≥ ce2 ≥ . . . ce|V 0 | . The tasks are ordered in
1
any arbitrary order, p1 , p2 , . . . , p|V20 | . Now, we use a
procedure, which is somewhat inspired by the analysis
of the generalized assignment problem, in the seminal
work of Shmoys and Tardos [10] to transform the
current fractional matching to an integral matching. The
algorithm proceeds as follows. Start with the highest cost
resource and allocate it integrally to any task that it has
a non-zero allocation to. Now, adjust the allocation of
the resources to maintain feasibility. Then, proceed to
completely allocate this task. Once done, pick the next
highest cost resource, that is not yet integrally allocated
and repeat the procedure. We describe this in detail in
the following paragraphs.
Let pj be a task where resource e1 has a nonzero allocation, in other words, (e1 , pj ) is an edge
in this connected component. We allocate resource e1
to resource pj integrally (i.e., xe1 ,pj = 1), and remove e1 from the set V10 . P
Now, we find the lowest
resource
index
e
such
that
i
ek |k∈{1,...,i} xek ,pj ≥ 1,
P
and ek |k∈{1,...,i−1} xek ,pj < 1. We remove the edge
xei ,pj and split the node iP
into two nodes i1 and i2 , and
add two edges xei1 ,pj = ek |k∈{1,...,i} xek ,pj − 1, and
xei2 ,pj = xei ,pj − xei1 ,pj .
We have made xe1 ,pj = 1. Therefore to maintain
feasibility, we have to make xe1 ,pq = 0 ∀pq ∈ P 0 , q 6= j.
Note that all the resources ek , 1 < k ≤ i, have
costs ≤ ce1 , and hence are feasible to be allocated
to any task that resource e1 was allocated to. Now,
consider a task j 0 to which resource e1 had a nonzero allocation. We know that all of the resources
ek , 2 ≤ k ≤ i are feasible to be allocated to j 0 . Hence,
we add an edge from resource e2 to task j 0 of value
xe2 ,j 0 = min (xe2 ,j , xe1 ,j 0 ) to j 0 and decrement xe2 ,j
by xe2 ,j 0 . Now, if xe2 ,j 0 = xe1 ,j 0 , we consider the next
task j 00 that resource e1 had an allocation to, and repeat
the above process, with e2 if xe2 ,j > 0. Otherwise, if
xe2 ,j = 0, and xe2 ,j 0 < xe1 ,j 0 , we pick e3 do the same
procedure. We continue till either we have removed all
the edges (ek , pj ) for all 1 ≤ k < i and xei1 ,pj , or we
have have removed all edges xe1 ,pq for all q 6= j, in a

𝑒1
𝑝1

𝟒

𝟐

𝑒2

1

𝑒1

𝑝3 𝟏 𝟏 𝟏

𝑝2 𝟏 𝟏 𝟏

𝑝1 𝟏𝟐 𝟏𝟒 𝟏𝟒

𝟒

𝟒

𝟖

𝑒3
𝑝3 𝟏 𝟑

𝑝2 𝟑 𝟏
𝟒

𝑒2

𝟖

𝟖

𝟒

𝟖

𝑒3
𝑐𝑒1 ≥ 𝑐𝑒2 ≥ ⋯ ≥ 𝑐𝑒𝑛

Fig. 4.

Illustration of one iteration of the LP rounding algorithm.

0
0
polynomial number of
Ptransformations (O(|V1 | + |V2 |)).
Note that xei1 ,pj + ek |k∈{2,...,i} xek ,pj = 1 − xe1 ,pj ,
therefore, both the events will happen simultaneously,
after which we have a feasible solution, where every
resource in V10 is allocated up to unity and every task in
V20 is fully allocated. If task pj had only one resource
requirement, then we have allocated task pj integrally,
while not violating the cost constraint of pj , as ce1 ≤ Cj .
Otherwise, if Dj > 1, then we still have unmet resource
requirement in task pj .
Now, we find the lowest resource index u > 1, that
has a non-zero allocation to task pj , i.e., xeu ,pj > 0
and repeat the above. If xei2 ,pj > 0, then u = i,
otherwise, u > i. We allocate resource u integrally to
task pj , remove the resource from V10 , and repeat the
above procedure. We continue till pj is allocated Dj
integral resources.
Once task pj is fully allocated integrally, we remove
it from V20 , and find the next highest cost resource es
remaining in V10 . Let pr be a task that es has a non-zero
allocation to. We perform the same transformations on
resource es and task pr and continue, till both V10 =
∅ and V20 = ∅. Figure 4 provides an example for one
iteration of the rounding algorithm.
Observe that we allocate only one resource integrally
to a task at a time, and adequately remove some
assignments to maintain feasibility of total allocation
of any resource, and resource
allocation of any task.
P
Since, initially |V1 |0 ≥
pk ∈V20 Dpk , and we are not
violating the size constraints on resource allocations at
any iteration, we will always find a resource to allocate
to a task yet unsatisfied, that is, if V2 6= ∅, that implies
V1 6= ∅. Not only that, at any iteration, when we change
the allocations, we maintain feasibility in terms of the
assignment restrictions on the resources; in other words,
we allow a resource to be allocated to a task, only
if the cost of the resource is at most the total cost

7

allowed for the task. Moreover, at any iteration, when
we are processing the resources allocated to a task q,
we are removing Dq vertices from V10 and 1 vertex from
V20 . Therefore, in at most |V1 | iterations, we will have
allocated every resource and and every task integrally.

an integral feasible solution, where every task costs
at most 2Cj = 2γIj . From Theorem 3, we know
that the lowest value for which the LP is feasible is,
γLP −OP T ≤ γOP
 T −IN T + , and it can be found in at
most log cmax
iterations, for any fixed  > 0. Hence

the resultant value of γ incurred by our algorithm is
≤ 2γLP −OP T ≤ 2γOP T −IN T + 2. This proves the
theorem.

B. Cost Incurred due to Rounding Algorithm
In this section, we argue that the resultant integral
allocation will be at most 2Cj for every task j. Note
that the first resource e1 that is allocated to any task pj
has a non-zero allocation to pj , hence, ce1 ≤ Cj . Let the
next resource to be allocated be eP
u , where u > 1. Also,
let i be the lowest index such that ek |1≤k≤i xek ,pj ≥ 1.
Note that, u ≥ i. According to the procedure outlined
earlier, we must have added two vertices i1 and i2 to
the graph, in place of i, and replaced
P the edge xei ,pj
by xei1 ,pj and xei2 ,pj , such that
ek |1≤k<i xek ,pj +
xei1 ,pj = 1,Pand xei2 ,pj = xei ,pj − xei1 ,pj . In this
case, C1 = P ek |1≤k<i cek xek ,pj + cei xei1 ,pj . Clearly,
C
P1 ≥ cei ek |1≤k<i xek ,pj + cei xei1 ,pj = cei as
ek |1≤k<i xek ,pj + xei1 ,pj = 1. Therefore, cei ≤ C1 ,
hence we charge its cost to C1 at no additional cost.
Similarly, let the next resource to
Pbe integrally allocated to j is ev , v > u. This means ek |u≤k≤v xek ,pj >
1, and let ew be the lowest index such that
P
ek |u≤k≤w xek ,pj ≥ 1. Note that v ≥ w. Again, following the same of procedure of adding two vertices (say w1
and w2 ) and replacing the edges as described above, we
obtain cew ≤ C2 and hence we P
charge its cost to C2 at
no additional cost where C2 = ek |u≤k<w cek xek ,pj +
cew xew1 ,pj
The total cost Cj = C1 + C2 + . . . CDj , where
Ci s are defined above, and we have charged the cost
of the k th resource allocated to pj , to Ck−1 , where
k ∈ {2, . . . , Dj }, therefore, the total cost of these
resources is ≤ Cj . The first resource to be allocated has
a cost ce1 ≤ Cj . Therefore, the cost of the total integral
allocation to task pj is at most 2Cj . We repeat the above
argument for every task.

V. I NTEGRALITY G AP FOR U NIT S IZE R ESOURCES
In this section we show that the LP has an integrality
gap approaching 2.
Theorem 7: The LP has an integrality gap → 2, hence
the LP rounding algorithm of Section IV is tight.
Proof: Consider an instance with m tasks, each with
a resource requirement of m. Let there be m2 resources
of which m2 − 1 resources are of cost 1 and another
resource is of cost m. Any feasibly integral solution
would have to allocate the resource of cost m to one of
the tasks thereby incurring a cost of 2m−1. However, the
isolation cost I of every task is m. Therefore, any inte1
gral feasible solution would incur a γ ≥ 2m−1
= 2− m
.
m
For the LP, every resource is feasible to be allocated to
every task for every γ ≥ 1, since the isolation cost of
every task is m and the resource requirement of every
1
. A feasible LP
task is m. Let us consider γ = 1 + m
solution would allocate to every task, m2 − m unit cost
resources integrally, m − 1 unit cost resources to an
1
1
extent of m
, and m
of the resource of cost m. With such
an allocation, every task receives a resource allocation
of m units, and every resource is allocated up to 1.
Note that the overall number of resources allocated is
m2 −m+m−1+1 = m2 . The cost incurred by every task
1
1
1
+m m
= m+1− m
< m+1, which
is (m−1)+(m−1) m
m+1
is feasible since γ = m . Therefore, the integrality gap
2− 1
is at least 1+ m1 → 2, when m → ∞. Hence the proof.
m

VI. G REEDY ALGORITHM
In this section, we consider a restricted version of
the problem, where the costs of the resources, though
arbitrary, vary smoothly across resources. The resources
are unit sized as in the previous sections. We give a
greedy algorithm which will give a near optimal fairness
in resource allocation, when all the tasks have the same
resource requirement. We first define some notations.
Definition 8: A set of resources are called homogenous, if, when ordered in non-increasing order of their
costs, the difference in costs between two consecutive
resources is very small, ≤  for some small fixed  > 0.
In other words, assuming the resources are numbered
according to their position in the sorted order, for any
i ∈ {1, . . . , |E|}, ci+1 − ci ≤ . We assume that ci ≥ 1.

C. Approximation Ratio of LP Rounding Algorithm
Theorem 5: Given a γ for which a feasible LP solution exists, there exists a polynomial time algorithm that
gives an integral feasible resource allocation to all tasks,
such that the cost of any task pj , is at most 2γIj , where
Ij is its isolation cost.
Proof: The proof follows from the discussion in
Sections IV-A and IV-B.
Theorem 6: There exists a polynomial 2 + O() approximation algorithm to the integral fair resource allocation problem.
Proof: From Theorem 5, we know that given a γ,
for which a feasible LP solution exists, we can find
8

Definition 9: A set of tasks are called identical in
terms of their resource requirements, if their resource
requirements are identical. In other words, for every pair
of tasks j, j 0 ∈ P, Dj = Dj 0 = D, where D ≥ 1.
In this version of the problem, we assume the resources are homogeneous and give a greedy algorithm
which allocates resources to the tasks in iterations, till
every task is fully allocated its total resource requirement. In every iteration, the task to allocate a resource is
chosen according to a rule which is a function of the total
resource requirement of the task, remaining resource
requirement and the cost incurred so far by the task due
to allocated resources. To the chosen task, the algorithm
allocates the next available resource in the sorted order.
The choosing rule is as follows: pick the task j with
the largest value of f (j), i.e., j = arg maxk∈P f (k),
D 0 +αC 0
where f (j) is defined as: f (j) = j Dj j , where Dj
is the total resource requirement of task j, Dj0 is the
remaining resource requirement or current deficit, Cj0 is
the current cost incurred by j by the resources already
allocated. Note that the isolation cost of a task depends
on the total resource requirement of the task, and is
higher for tasks with high resource requirements. The
intuition behind choosing this function is that we want
to favor the tasks that have already incurred a high cost
relative to the total resource requirement (hence, the
isolation cost), and also the tasks for which the remaining
resource requirement is high relative to the total resource
requirement. By favoring a task, we mean allocating it
lower cost resources. This is done to balance the ratio of
actual costs to isolation costs across resources. The value
of α is chosen so that the greedy algorithm behaves in
a certain manner to ensure fairness of cost across tasks.
Specifically, α = P 1 ci .
i∈E
The pseudo-code of the greedy algorithm is presented
in Algorithm 1.
We will prove that when the resources are homogeneous and tasks are identical, the greedy algorithm will
give a near optimal fairness ratio.
Let us denote the number of tasks |P| = n, in the
following analysis for notational ease, and the resource
requirement of each as D. Since we have n tasks, each
requiring D resources, the greedy algorithm will require
nD iterations. Let us define the set of consecutive n
iterations [kn + 1, kn + 2, . . . , (k + 1)n] as the k th block
iteration. Clearly we have D block iterations.
We next prove that the greedy algorithm will allocate
resources to the tasks in an alternating round-robin
manner, such that in the ith block iteration, where
i ∈ {1, . . . , D}, every task will be allocated exactly one
resource.
Lemma 10: Every task is allocated a resource in every

Algorithm 1: Greedy algorithm for fair resource
allocation.

1
2
3
4
5

Input : P: set of tasks; Dj : total resource requirement in
task j ∈ P Dj0 : current resource deficit in task
j ∈ P (initially set to the original resource requirement
of j; Cj : current cost incurred by task j ∈ P
(initially set to 0); E: set of resources; ci : cost of
a resource i ∈ E
Output: xij : assignment of resources to tasks.
Set Dj0 ← Dj and Cj0 ← 0, ∀j ∈ P.
Sort all resources in E such that
ci ≤ ci+1 ∀i ∈ {1, . . . , |E| − 1}
Set xi,j ← 0, ∀i ∈ E, j ∈ P.
Set i ← 1; while P 6= ∅ do
Choose the task j,such that 
D 0 +αC 0

k
k
j = arg maxk∈P
Dk
Set xi,j ← 1 and allocate resource i to task j.
Set Dj0 ← Dj0 − 1 and Cj0 ← Cj0 + ci
Set i ← i + 1. if Dj0 = 0 then
P ← P \ j.
end

6
7
8
9
10
11

end

block iteration (in other words, consecutive n iterations).
Proof: Let us consider the first block iteration. Suppose a task j is not allocated at all in block iteration 1.
Since a block iteration consists of n rounds, this implies
that some task j 0 is was allocated ≥ 2 resources in this
iteration. Consider the round in the first block iteration,
when j 0 was chosen for a second allocation. According
0
to the choosing rule, therefore,
  j 0 = arg
maxk∈P f (k),
Dj0 0 +αCj0 0
Dj +αCj0
≥
. But Dj0 = D
which implies
D
D
whereas Dj0 0 = D − 1, Cj0 = 0 and Cj0 0 = c, where
c is the cost of the resource allocated
to j 0 . Clearly,
Dj0 0 +αCj0 0
Dj0 +αCj0
1
= 1. On the other hand,
=1− D
+
D
D
1 P c
<
1.
This
gives
a
contradiction.
Therefore,
D
k∈E ck
every task gets an allocation in the first block iteration.
Now, let us assume by induction hypothesis that this
holds for the first i block iterations, where i < D. Now,
all tasks have have i unit resources. If a task j does not
get an allocation in the iteration i + 1, then this implies
that some task j 0 is was allocated ≥ 2 resources in this
iteration. Consider the round in the i + 1 block iteration,
when j 0 was chosen
a second
allocation.
Since j 0 =
 Dfor
 0
0
0 
0 
+αC
D
+αC
j0
j
j
j0
arg maxk∈P f (k),
≥
. Note that
D
D
Dj0 0 = D − (i + 1), whereas Dj0 = D − i. Because of our
Cj0 0
1
D < D , therefore,
D0 0
− Di , whereas Dj =

choice of α, α
D0

α

Cj0 0
Cj0 0
1
D − α D < D.
− i+1
D . Therefore,

Also, Dj = 1
1
f (j 0 ) − f (j) < 0. This gives a contradiction. Hence, we
have proved inductively the statement of the lemma.
Observation 11: When all tasks have received the
same number of resources, the next task to be allocated
a resource is the task that has incurred the highest cost
9

Proof: Let Cmax,D be the highest cost incurred by
any task at the end of nD iterations, and COP T be the
optimal fair allocation cost. For any optimal solution,
T
γOP T = COP
where I is the isolation cost of any
I
resource. From Lemma 12, Cmax,D ≤ COP T + n.
Therefore, the resultant γgreedy ≤ COP IT +n . Hence,
γgreedy
n
γOP T ≤ 1 + COP T . We know that COP T = nDcavg
where cavg the average cost of the first nD resources.
γ
n
Therefore, γOP
≤ 1 + nDc
< 1 + , since D ≥ 1
avg
T
and cavg ≥ c1 ≥ 1.

so far.
This follows from the function used by greedy as the
choosing rule.
Lemma 12: At the end of every block iteration i, the
0
cost incurred by any task
Pj, Cj is at most Ci,OP T +
1
n, where Ci,OP T = n e∈{1,...,i·n} ce is the optimal
fair allocation cost when all the tasks are identical, each
with a resource requirement of i, and the resources are
homogeneous.
Proof: At the end of any block iteration i, let the
costs incurred by tasks be Cj0 j ∈ [1, . . . , n]. Since any
optimal solution would allocate the first i · n resources
from the sorted list to the n tasks, the total cost incurred
across all tasks in the greedy solution till iteration i is
the same as that
P of any optimal solution. Therefore,
Ci,OP T = n1 j∈[1,...,n] Cj0 . Let Cmin,i denote the
lowest cost incurred by any task at the end of block
iteration i and Cmax,i denote the highest cost incurred
by any task. Clearly, Ci,OP T ≥ Cmin,i by definition.
We will prove by induction that for any pair of tasks
(j, j 0 ). at the end of block iteration i, |Cj0 − Cj0 0 | ≤ n.
At the end of block iteration 1, Cmin,1 = c1 , and
Cmax,1 = cn ≤ c1 + n, (where cp is the cost of the
pth resource in the sorted order), by our assumption
of homogeneous resources. Hence, the base case holds.
Now, we assume by induction hypothesis, that the above
holds for all block iterations {1, . . . , i − 1}. In the block
iteration i, according to Observation 11 and Lemma
10, the task with the highest cost is allocated first,
followed by the next highest cost, and so on, till the
lowest cost task gets allocated last. Suppose at the end
0
0
of block iteration i, Cj,i
≥ Cj0 0 ,i , where Cj,i
denotes
the cost incurred by j at the end of iteration i, hence j
will allocated before j 0 . But from induction hypothesis,
0
0
Cj,i
≤ Cj0 0 ,i + n. Therefore, Cj,i+1
− Cj0 0 ,i+1 ≤
0
00
0
c −c +n, where c is the cost of the resource allocated
to j in block iteration i + 1, and c00 is the cost of the
resource allocated to j 00 in block iteration i+1. Note that
c0 ≤ c00 due to the sorted order and from Observation
0
11. Therefore, Cj,i+1
− Cj0 0 ,i+1 ≤ n. At the same time,
0
0
0
0
Cj 0 ,i+1 − Cj,i+1 = Cj 0 ,i + c00 − Cj,i
− c0 ≤ c00 − c0 , since
0
0
Cj 0 ,i ≤ Cj,i . But we know from homogeneous property
0
of resources. c00 − c0 ≤ n, therefore, Cj,i+1
− Cj0 0 ,i+1 ≤
n. This holds for any pair of resources (j, j 0 ). This
completes the proof by induction.
We have proved that for any pair of tasks (j, j 0 ). at
the end of block iteration i, |Cj0 − Cj0 0 | ≤ n. Therefore,
Cmax,i ≤ Cmin,i + n ≤ Ci,OP T + n.
Theorem 13: For homogeneous resources and identical tasks, the greedy algorithm gives a 1 +  approximation to the fair resource allocation problem.

VII. C ONCLUDING R EMARKS
This paper studied the problem of fair allocation of
resources with heterogeneous costs to tasks with heterogeneous resource requirements. We show that the problem is strongly NP-Hard even with unit sized resources,
and present an LP rounding approximation algorithm for
this version of the problem and a near-optimal greedy
algorithm for a special case in which costs of resources
do not differ much and resource requirements of tasks
are identical. As part of future work, we plan to study
the problem where resources have limited heterogeneity
in costs, as well as, the online version of the problem.
R EFERENCES
[1] Yossi Azar, Umang Bhaskar, Lisa Fleischer, and Debmalya
Panigrahi. Online mixed packing and covering. In Proceedings of
the 24th Annual ACM-SIAM Symposium on Discrete Algorithms
(SODA), pages 85–100, 2013.
[2] Venkatesan T Chakaravarthy, Anamitra Roy Choudhury, Sivaramakrishnan R Natarajan, and Sambuddha Roy. Knapsack cover
subject to a matroid constraint. In LIPIcs-Leibniz International Proceedings in Informatics, volume 24. Schloss DagstuhlLeibniz-Zentrum fuer Informatik, 2013.
[3] Bruno Escoffier, Laurent Gourvès, and Jérôme Monnot. Fair solutions for some multiagent optimization problems. Autonomous
agents and multi-agent systems, 26(2):184–201, 2013.
[4] Ali Ghodsi, Matei Zaharia, Scott Shenker, and Ion Stoica.
Choosy: max-min fair sharing for datacenter jobs with constraints. In Proceedings of the 8th ACM European Conference
on Computer Systems (EuroSys), pages 365–378, 2013.
[5] Raj Jain, Dah-Ming Chiu, and W Hawe. A quantitative measure
of fairness and discrimination for resource allocation in shared
computer systems. Technical Report TR-301, DEC, 1984.
[6] Hans Kellerer, Ulrich Pferschy, and David Pisinger. Knapsack
problems. Springer, 2004.
[7] H. J. Kushner and P. A. Whiting. Convergence of proportionalfair sharing algorithms under general conditions. IEEE Transactions on Wireless Communications, 3(4):1250–1259, 2004.
[8] J. K. Lenstra, D. B. Shmoys, and É. Tardos. Approximation
algorithms for scheduling unrelated parallel machines. Math.
Program., 46(3):259–271, 1990.
[9] Alan Shieh, Srikanth Kandula, Albert G. Greenberg, Changhoon
Kim, and Bikas Saha. Sharing the data center network. In NSDI,
2011.
[10] David B. Shmoys and Éva Tardos. An approximation algorithm for the generalized assignment problem. Math. Program.,
62(3):461–474, 1993.
[11] Neal E. Young. Sequential and parallel algorithms for mixed
packing and covering. In Proceedings of the 42nd IEEE Symposium on Foundations of Computer Science (FOCS), pages 538–
546, 2001.

10

