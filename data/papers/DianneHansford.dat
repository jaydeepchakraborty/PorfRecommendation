Invited Paper

Digital 3D Facial Reconstruction of George
Washington
Anshuman Razdan∗
Jeﬀ Schwartz†
Matthew Tocheri‡
Dianne Hansford§
ABSTRACT
PRISM is a focal point of interdisciplinary research in geometric modeling, computer graphics and
visualization at Arizona State University. Many projects in the last ten years have involved laser
scanning, geometric modeling and feature extraction from such data as archaeological vessels, bones,
human faces, etc. This paper gives a brief overview of a recently completed project on the 3D reconstruction of George Washington (GW). The project brought together forensic anthropologists,
digital artists and computer scientists in the 3D digital reconstruction of GW at 57, 45 and 19 including detailed heads and bodies. Although many other scanning projects such as the Michelangelo
project have successfully captured ﬁne details via laser scanning, our project took it a step further,
i.e. to predict what that individual (in the sculpture) might have looked like both in later and
earlier years, speciﬁcally the process to account for reverse aging. Our base data was GWs face
mask at Morgan Library and Hudons bust of GW at Mount Vernon, both done when GW was 53.
Additionally, we scanned the statue at the Capitol in Richmond, VA; various dentures, and other
items. Other measurements came from clothing and even portraits of GW. The digital GWs were
then milled in high density foam for a studio to complete the work. These will be unveiled at the
opening of the new education center at Mt Vernon in fall 2006.

1. INTRODUCTION
In the spring of 2002 Jeﬀ Schwartz (JHS), forensic anthropologist at the University of Pittsburgh,
was approached by Laura Fisher of the Allegheny Conference to consider reconstructing George
Washington at the age of 22, when he was an oﬃcer in the British army during the French and
Indian War. After learning that he would not be able to study Washington’s skeletal remains - and
to the complete set of dentures with which Washington had purportedly been buried, he pursued
other approaches to attempting this reconstruction of our founding father. To this end, he discovered
that he could have access to various three-dimensional realizations of Washington such as a life mask,
bust, and statue, etc., documented and provenanced clothing, portraits for which Washington sat,
and diaries, letters, and other documentary evidence.
From the beginning, it was clear that the nature of the secondary evidence - both three- and
two-dimensional - would require digital manipulation, not only in scanning and digitally comparing
representations, but also in attempting to reconstruct the skeletal understructure of Washington’s
∗
Research

Professor, The Decision Theater, Arizona State University, MC 8409, Tempe AZ 85287, razdan@asu.edu
of Anthropology and History and Philosophy of Science, 3302 WWPH University of Pittsburgh,
Pittsburgh, PA 15260, jhs@pitt.edu
‡
Graduate Assistant PRISM, InCISE, Arizona State University, MC 8609, Tempe AZ 85287-8609,
matt.tocheri@asu.edu
§
Research Scientist, PRISM, InCISE, Arizona State University, MC 8609, Tempe AZ 85287-8609, dianne.hansford@asu.edu
†
Departments

Three-Dimensional Image Capture and Applications VII, edited by Brian D. Corner, Peng Li, Matthew Tocheri,
Proc. of SPIE-IS&T Electronic Imaging, SPIE Vol. 6056, 60560I, © 2006 SPIE-IS&T · 0277-786X/06/$15

SPIE-IS&T/ Vol. 6056 60560I-1
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

face at the age of 53 as the foundation from which to de-age him in the reverse of the hypothesized
sequence in which he lost teeth and the bone in which they had been anchored. Thus, in addition
to recognizing the need to engage experts in the portraiture, clothing, and sculpture of the 18th
century, it was realized that a project of this nature would require a collaborative eﬀort between
JHS and PRISM.
By new year, the emphasis of Fisher’s program had changed. However, this change coincided
with the executive director of Mount Vernon Gardens and Estate moving ahead with plans for a new
education center that would feature three life-size ﬁgures of Washington at three important ages: 19
years, when, as a surveyor, he learned how to ”read” the land; 45 years, when, as commander-in-chief
of the revolutionary army, he and his troops were bivouacked at Valley Forge; and 57 years, when
he took the oath as the ﬁrst president. Mount Vernon invited a proposal and ultimately accepted
the idea of the project.
PRISM or Partnership for Research In Spatial Modeling¶ was established in 1996 as an interdisciplinary center at Arizona State University (ASU). The focus of the center is to conduct research in
geometric modeling, computer graphics and visualization in collaboration with other domain scientists. PRISM has a variety of laser scanning equipment and has developed expertise in commercial
software and where necessary developed an array of in house software and algorithms. This project
nicely ﬁt the research paradigm at PRISM. The collaborative team was lead by Jeﬀ Schwartz who
was the senior anthropologist on the team and laid down the requirements and oversaw the reconstruction eﬀort. At PRISM, the team consisted of Anshuman Razdan, Dianne Hansford and Gerald
Farin (computer scientists), Mathew Tocheri (Ph.D. student in Anthropology), Dan Collins (School
of Fine Arts), Gene Cooper (3D artists) and Scott Van Note and Jeremy Hansen (graduate students
in School of Fine Arts and Computer Science, respectively). The goal for this project at PRISM
was to scan the artifacts, process and reﬁne the data, create software tools necessary for tweaking
the shape as determined by the anthropologist and digitally sculpt bodies where necessary. For this
paper we will focus on the face reconstruction part only.
The rest of the paper is organized in three main sections that deal with the 3D scanning eﬀort,
methodology for reconstruction and volume deformation tool that was developed to achieve the
geometric manipulation of the 3D data.

2. 3D SCANNING
The ﬁrst few months of the project were devoted to scanning various artifacts in diﬀerent parts of
the country, followed by careful data processing and stitching to generate 3D images which were
then used by the anthropologists to derive the face geometries at the appropriate ages.
The ﬁrst step of the George Washington reconstruction eﬀort involved acquiring 3D data that best
represented the ﬁrst president’s physical characteristics. As direct access to Washington’s physical
remains was not possible, other evidence was carefully selected based on the potential 3D information
that would be provided to the reconstruction eﬀort. A plaster mask of the ﬁrst president’s face was
the most important piece of evidence with respect to Washington’s facial features and underlying
bony structure. The mask is an actual mold of Washington’s face, taken when he was 53 years old by
the French sculptor, Jean Antoine Houdon. Currently, it is housed at the Morgan Library Museum
in New York. Thirteen laser scans were taken from various angles to capture the 3D structure of the
mask. Originally, Houdon used the plaster mask along with measurements he took of Washington
to sculpt a bust as well as a life-sized statue. The bust is now part of the Mount Vernon estate while
the statue is displayed in the state capital of Virginia in Richmond. The bust provided 3D data on
Washington’s head and neck while the statue provided 3D data on body proportions. Approximately
120 laser scans were taken of the bust and well over 500 scans were taken of the statue. Figure 2
shows the scanning process of Houdon’s bust at Mount Vernon.
¶

prism.asu.edu

SPIE-IS&T/ Vol. 6056 60560I-2
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

Figure 1. Houdon bust of GW being scanned at Mount Vernon.

With 3D information about Washington’s face, head, and body provided by the three aforementioned objects, evidence pertaining to his teeth and jaws was still required. A total of four sets of
dentures (2 real, 2 replicas) were laser scanned to provide this information. The ﬁrst set, housed
at the Mount Vernon estate, consists of upper and lower jaw components. This set of dentures
was composed largely of metal which complicated the scanning process because of the reﬂectivity
of the surface. The remaining sets of dentures, housed at the National Museum of Dentistry in
Baltimore, scanned more successfully. In particular, the resulting 3D model of a replica of the lower
jaw denture from the Morgan Library Museum became vital to the reconstruction eﬀort as it is a
denture that Washington likely wore for a signiﬁcant time of his later life. In general, well over
100 laser scans were taken on each set of dentures. In all cases, the research team traveled to the
location of the object and laser scanning was completed on site under direct supervision of curatorial
staﬀ. The conditions for laser scanning were not always ideal and the team made adjustments as
necessary to capture as much of the vital 3D information as was possible given the circumstances.
All sets of dentures were scanned using the Cyberware Model 15 laser scanner whereas the life mask,
bust, and statue were scanned using the LDI 100/200 laser scanners. Several additional items were
also scanned (e.g., Corcoran mask, Mount Vernon medallion, etc.); however, these items did not
contribute signiﬁcantly to the reconstruction eﬀort as their ’true’ 3D relationship to Washington is
suspect.
All the scanned data was pieced together using Raindrop-Geomagic software and the resulting
data type was triangle meshes. The triangle mesh representation is the most common output of
laser scanners and geometry software processing software. An example is shown in Figure 2 to give
readers an idea of the detail. This posed another problem of editing and manipulating the geometry.

SPIE-IS&T/ Vol. 6056 60560I-3
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

:iTjri

Figure 2. Scanning detail (wirefrmae over shaded) around nose of the Houdon’s bust of GW.

This was tackled by developing a tool described in the volume deformation section.

3. METHODOLOGY
Facial reconstruction is fairly common in the forensic sciences. However it is limited to creating 2D
sketches and most of the time limited to forward aging. In other words the forensic artist/scientist
tries to predict what the victim or criminal looks like today based on a photograph and other evidence from the past. It is also the case that the forensic scientists will try to create a face based
on other evidence such as a partial or complete skull. Many projects have been undertaken to
scan important historic artifacts during the last ten years. One of the major undertakings was
started in 1997 by the Stanford group to scan Michelangelo’s David. Named ”The Digial Michelangelo Project”, links to the project and many publications can be seen at the Stanford web site
http://graphics.stanford.edu/projects/mich/. Our project goals were diﬀerent. Although scanning
of the historic artifacts was an important element of the project, it was just the starting point. Our
goal was to use this information to create 3D reconstructions by de-aging i.e. going backwards in time
(for the case of 19 and 45 year old). Below we present our methodology behind the reconstruction
project.

SPIE-IS&T/ Vol. 6056 60560I-4
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

Figure 3. 3D comparison of the Morgan life mask and the Houdon’s bust scaled by 9% to accomodate
shrinking of the terracota material during ﬁring. Light green to light blue range of colors shows high
simmilarity between the two.

SPIE-IS&T/ Vol. 6056 60560I-5
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

As would turn out to be the case with many of the ”truths” about Washington or Washington
representations, the ﬁrst of these to fall was the oft-repeated story that Washington had not worn
dentures when the mold for the life mask was cast in plaster. As was noted from photographs, and
was later conﬁrmed when digitally superimposing the 3D scan of the life mask with the 3D scan
of the bust (Figure 3), there had to have been structure behind Washington’s lips or the weight of
the plaster would have notably depressed them into his oral cavity. Another result of this digital
comparison was that the life mask and face of the bust were so similar metrically that it seemed
eminently reasonable to use the bust in its entirety as a reasonable representation of the man’s head
in general.
The second sources of information that was needed in order to pursue the aging and especially the
de-aging of Washington were his dentures. The only available complete set consisting of associated
uppers and lowers are those in the collections of Mount Vernon. Diﬀering from dentures typical
of the 18th century in that lead rather than ivory or bone was the substrate in which teeth (in
this case animal incisors in the upper and various human teeth in the lower plate) were fastened,
they were also unusual in that the non-dental surfaces of both plates were essentially ﬂat, rather
than grooved to embrace toothless gums. Nevertheless, until scans of other dentures were acquired,
the scan of the Mount Vernon dentures was used initially as a guide for digitally whittling to ﬁt
a scanned mandible of a French and Indian War soldier that approximated the width of what was
determined from the digital bust and life mask Washington’s mandible had been. Since the Mount
Vernon denture possessed a hole to receive Washington’s last tooth - a left lower left second - the
appropriate tooth was left in the digitally altered mandible and adjusted to height of the teeth in
the lead plate. After an exact replica of the surviving lower plate of the dentures Joseph Greenwood
made in 1789 for Washington was scanned, the digitally manipulated mandible was further adjusted
to ﬁt the groove along this plate’s underside. When the senior anthropologist was satisﬁed with
the alveolar curve of the digital mandible, the 3D data was placed in the bust in order to adjust
the angle of the chin, which, in virtually all representations of Washington as an older individual,
is obliquely slanted down from left to right. Having thus reconstructed a reasonable facsimile of
Washington’s mandible at the age of 57 (which he would have been in 1789), the ﬁt was ﬁne tuned
by adjusting known average skin depths for older individuals at crucial point along the lower jaw.
Reconstructing the upper jaw was less straightforward. When initially inquired about the 1795
Greenwood dentures, Scott Swank, curator at the National Museum of Dentistry, noted that although
the original had been stolen from the Smithsonian in the 1980s and only the lower recovered, there
was a replica. Upon seeing the replica, it was immediately obvious to the anthropologist that it did
not capture the shape and size of the original, much less its details. Fortunately, Swank was able
to provide a photograph that portrayed both the original and the replica. As such, it was realized,
once scanned, we could use the replica upper and lower as a scale by which to calibrate the size of
the original. Subsequently, the photograph was scanned and the images of the original and replica
upper superimposed in order to achieve a curvature that could be used to remodel the scanned
upper jaw of the soldier whose mandible had been used. When the toothless digital maxilla seemed
satisfactorily modiﬁed, it was placed into the digital bust and skin depth adjusted accordingly. This
then provided the bony infrastructure for Washington’s face at the age of 57.
In order to achieve the face of the 45 year old, we looked at Charles Wilson Peale’s portraits
of Washington at the ages of 40 and 47, which visually represented an individual who lower face
was longer from nose to chin, and whose chin was rounded symmetrical. Given Washington’s selfproclaimed proclivity for cracking walnut shells with his teeth, and the common loss of posterior
teeth prior to front teeth, the longer lower face could be explained by the retention of anterior teeth.
In order to test the visual observation, prints of both portraits were scanned and relevant facial
features digitized. The two scans were then compared and, indeed, they were similar in length of the
lower face and symmetry of the chin. The two-dimensional scans of the portraits were superimposed
over the bust, which was oriented in the position of the pose. Upon aligning facial features, it was

SPIE-IS&T/ Vol. 6056 60560I-6
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

indeed the case the 40 and 47 year old faces were longer from nose to chin, and the face of the bust
was adjusted accordingly, including rounding up the inferior margin of the chin. The digital mandible
and maxilla were then placed into this remodeled face and adjusted to it, using average skin depth
measurements. The angle of the mandible was left essentially unaltered from its amorphous shape
in the bust and portraits in accordance with the hypothesis of posterior tooth loss and concomitant
bone loss. The ﬂesh around the neck was also tightened up a bit.
Having thus lengthened the lower face, the reconstruction of the lower jaw of the 19 year old
required manipulating the back of the mandible to assume the right-angled look a pre-tooth loss
jaw of a young individual would have had. In turn, the inferior margin of the body of the mandible
had to become more horizontal and it and the angle made more prominent. Since cartilage grows
throughout one’s lifetime the tip of the nose and its alar cartilages as well as the earlobe were shrunk
(exposed below the hair in the life mask). Hypothesizing that Washington might have continued to
acquire the somewhat more pronounced supraorbital and glabellar regions seen in the older adults,
the anthropologist required that these regions be ﬂattened. A younger appearance was also achieved
by removing wrinkles and adding a bit to the cheeks, which would have lost fat with age. The skin of
the neck was tightened further. It was also decided to ﬁll in the pock mark under the left zygomatic
arch that is seen in older representations of Washington and which could have resulted from the
bout of smallpox he suﬀered when he traveled to Barbados with his brother later that year.
Figure 4 shows the three facial reconstructions.

(a) GW at 19

(b) GW at 45

(c) GW at 57

Figure 4. Final results of facial reconstruction of George Washington.

4. VOLUME DEFORMATION TOOL
An important tool that needed to be developed for tweaking the face data as required by the anthropologists was based on the idea of deformation of B-spline volumes. Altering the shape of a triangle
mesh by moving individual vertices is not practical. A better method, called volume deformations,
allows for aesthetically and functionally pleasing changes to areas of a mesh. Operations such as
bending and stretching are performed with respect to a 3D control grid surrounding the mesh. The
method presented here is based on B-spline volumes, which are introduced in Section 4.1. Bézier1
was the ﬁrst to use this technique. Sederberg and Parry4 popularized this technique with a computer
graphics approach. A collection of work on deformations and morphing can be found in.3

4.1. B-spline Volumes
The fundamentals of B-spline curves and surfaces may be found in.2 To introduce notation, we
review that a B-spline curve is deﬁned by its degree n, the number of polynomial segments l, and

SPIE-IS&T/ Vol. 6056 60560I-7
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

Figure 5. A cubic B-spline curve with four segments.

its knot vector (u0 , . . . , um−1 ) where m = 2n + l − 1. A B-spline curve will have control points
d0 , . . . dp−1 , where p = l + n, and such a curve is illustrated in Figure 5. A point x on the B-spline
curve corresponding to u in the knot vector is deﬁned as
x(u) =

p


di Nin (u),

i=0

where Nin are the B-spline basis functions of degree n over the given knot sequence.
The parameters u are normally restricted to lie within the domain knots, un−1 , . . . , um−n+1 .
The Greville abscissae are moving averages of the knots, gi = n1 (ui + . . . ui+n−1 ). For each Greville
abscissa, there is a corresponding B-spline control point. In Figure 5, the knot vector has full
multiplicity at the ends, causing the curve to interpolate to the end control points.
A B-spline volume is deﬁned similarly to a curve, however now we have u-, v-, and w-parametric
directions. Thus we specify degrees nu , nv , nw , the number of segments lu , lv , lw , and the knot vectors
u = (u0 , . . . , umu ), v = (v0 , . . . , vmv ), w = (w0 , . . . , wmw ). As before, the number of knots is related
to the degree and number of segments,
mu = nu + lu + 1,

mv = nv + lv + 1,

mw = nw + lw + 1.

The control points di,j,k form a control net, and the number of control points, pu , pv , pw , corresponding to each parametric direction is as for the curve example, related to the number of knots
and segments.
The shape of this control net plays a role in deﬁning the shape of the volume deﬁned by the
B-spline. A point x on the B-spline volume is deﬁned as
x(u, v, w) =

pu
pw 
pv 

k=0 j=0 i=0

di,j,k Ninu (u)Njnv (v)Nknw (w)

(1)

For our purposes, we will restrict ourselves to knot sequences with full multiplicity at the ends.
Figure 6 illustrates a control net. (The mesh inside will be explained in Section 4.2.) The B-spline
volume is tri-cubic and there are three segments in each parametric direction.
If we consider the knot vectors u, v, w embedded in an orthogonal system originating at the
origin and coinciding with the x-, y-, and z-axes, then we can construct a B-spline control net at
the points corresponding to the Greville abscissae. Call this special net the control lattice, although

SPIE-IS&T/ Vol. 6056 60560I-8
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

Figure 6. Example of placement of a mesh within a control lattice. The control net is tri-cubic with three
segments in each parametric direction.

--S

Figure 7. Deformation of the mesh by applying the taper operation to the B-spline control net.

it is not entirely regular. B-spline volume deformations exploit the linearity property of B-splines,
namely that each point in the control lattice can be expressed as
⎡ ⎤
pu
pw 
pv 
u

⎣v ⎦ =
di,j,k Ninu (u)Njnv (v)Nknw (w).
(2)
w
k=0 j=0 i=0

4.2. B-spline Volume Deformation
Figure 6 illustrates a mesh embedded in a control lattice. Because of the relationship between the
control points and the knots in the special control lattice, for each vertex in the mesh, we can ﬁnd its
corresponding (u, v, w). As we know from the linear precision property (2), evaluating the B-spline
volume at these parameters would result in the identical mesh.
Now, distort the control lattice of di,j,k into d̂i,j,k , as is illustrated in Figure 7. The mesh is
distorted as well. Again, each vertex of the mesh is assigned a (u, v, w) parameter triplet based on
its position in the control lattice, however now (1) is evaluated using the distorted control points.
We found the following operations for distorting a control lattice useful.
• Translate: move sets of control points (row, column, or cross section) by a speciﬁed amount.

SPIE-IS&T/ Vol. 6056 60560I-9
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

Figure 8. The deformation box is yellow. Multiple operations have been performed, and the next operation
will only change those control points within the deformation box.

• Scale: deﬁne a local coordinate system within the lattice to help deﬁne the scale.
• Rotate about a line: deﬁne a line about which the control points will rotate.
• Bend about a plane: deﬁne a plane which separates the control net. This is similar to the
operation ’rotate about a line’ except that the rotation angle for points on one side of the
plane is opposite in sign to the rotation angle for points on the other side.
• Taper one or more cross sections: variable scaling of the cross sections of control points creates
a taper eﬀect. This operation is illustrated in Figure 7.
How the lattice should be deformed and the type of user interface available are the driving forces
behind the design of these operations.

4.3. Local Control
B-spline volumes provide a certain amount of local control. However, this might not be enough. The
operations deﬁned above are easy to specify, but they might modify more control points than desired.
One way to work around this problem is to add the concept of a deformation box. Illustrated in
Figure 8, this box allows us to identify the control points that we would like to modify. Operations
will only modify points within the deformation box. Thus we can keep the simple user interface for
implementing the operations, and add a control for specifying the extents of this box. The default
deformation box would hold the entire control lattice. A user can scale and move this box as desired.
Figure 9 shows how the jaw could be modiﬁed with the 3D mesh of the face providing a refrence
frame.

5. SUMMARY
We presented a brief report on scanning, methodology for reverse aging and B-spline volume deformation tool to accomplish the digital 3D reconstruction of George Washington’s face. Based on the
evidence derived from 3D artifacts as well as portraiture the over all result achieved seem reasonable.
However, since we do not have access to GW’s remains, the best forensic reconstruction cannot be
compared and validated. The reverse aging process is the ﬁrst we know of. The project required
strong collaboration between the anthropologists, computer scientists and digital artists.

SPIE-IS&T/ Vol. 6056 60560I-10
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

Figure 9. An example of how volume deformation tool was used. The jaw was deformed with the 3D scan
of the face from Houdon’s bust as a reference.

ACKNOWLEDGMENTS
The authors are grateful to Mount Vernon for commissioning the project. Special thanks are due
to Ms. Ann Bay, Director of the Education Center, the curator and the collections departmentment
staﬀ at Mount Vernon. We would also like to thank many organizations, collections, curators and
scores of other people responsible in making our visits to scan various artifacts associated with the
project less stressful and as eﬃcient as one could imagine. Last but not the least we would like to
thank Prof. Gerald Farin, Prof. Dan Collins, Gene Cooper and graduate students Scott Van Note
and Jeremy ”Goose” Hansen for spending long hours working on details that were required to make
this project successful.

REFERENCES
1. P. Bézier,General distortion of an ensemble of biparametric patches, Computer Aided Design,
10(2):116-120, 1978.
2. G. Farin and D. Hansford, The Essentials of CAGD, AK Peters, 2000.
3. J. Gomes, L. Darsa, B. Costa, L. Velho, editors, Warping and Morphing of Graphical
Objects, Morgan Kaufmann, 1999.
4. T. Sederberg and S. Parry, Free-form deformation of solid geometric models, SIGGRAPH Proceedings, Computer Graphics, 20(4):151-160, 1986.

SPIE-IS&T/ Vol. 6056 60560I-11
Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/10/2017 Terms of Use: http://spiedigitallibrary.org/ss/termsofuse.aspx

DINUS: Double Insertion, Nonuniform, Stationary
Subdivision Surfaces
KERSTIN MÜLLER, CHRISTOPH FÜNFZIG, and LARS REUSCHE
Technical University Kaiserslautern
DIANNE HANSFORD and GERALD FARIN
Arizona State University
and
HANS HAGEN
Technical University Kaiserslautern

The Double Insertion, Nonuniform, Stationary subdivision surface (DINUS) generalizes both the nonuniform, bicubic spline surface and the Catmull-Clark
subdivision surface. DINUS allows arbitrary knot intervals on the edges, allows incorporation of special features, and provides limit point as well as limit
normal rules. It is the first subdivision scheme that gives the user all this flexibility and at the same time all essential limit information, which is important
for applications in modeling and adaptive rendering. DINUS is also amenable to analysis techniques for stationary schemes. We implemented DINUS as an
Autodesk Maya plugin to show several modeling and rendering examples.
Categories and Subject Descriptors: I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Curve, Surface, solid, and object
representation

25

General Terms: Theory
Additional Key Words and Phrases: Catmull-Clark subdivision surfaces, NURBS, subdivision surfaces
ACM Reference Format:
Müller, K., Fünfzig, C., Reusche, L., Hansford, D., Farin, G., and Hagen, H. 2010. DINUS: Double insertion, nonuniform, stationary subdivision surfaces.
ACM Trans. Graph. 29, 3, Article 25 (June 2010), 21 pages. DOI = 10.1145/1805964.1805969 http://doi.acm.org/10.1145/1805964.1805969

1.

INTRODUCTION

Nonuniform subdivision surfaces combine the strength of spline surfaces and subdivision surfaces into one, new surface type. Tensorproduct spline surfaces are forced to a strict n × m topology of
patches. Subdivision surfaces generalize the uniform tensor-product
spline surfaces and allow for surface patches having arbitrary valence vertices and arbitrary valence faces. Extended subdivision
surfaces [Müller et al. 2006] are a blend between binary subdivision
for nonuniform, bicubic spline regions (single knot insertion) and
the Catmull-Clark scheme for patches having an irregular point.
Their systematic approach allows for limit point rules in regular
and irregular control points. Despite limit point rules, the subdivision scheme is still nonstationary in general. In this article, we
propose a stationary subdivision scheme which generalizes both
nonuniform, bicubic spline surfaces and Catmull-Clark subdivision
surfaces. Our new subdivision scheme is based on double knot in-

sertion. In contrast to all other nonuniform subdivision schemes,
it is a stationary scheme. Limit point rules and limit normal rules
are available and the surface is amenable to analysis techniques for
stationary schemes.

1.1 Related Work
The combination of NURBS and subdivision surfaces into one surface type has received a lot of attention recently. For spline curves
and tensor-product spline surfaces, binary subdivision is knot insertion in the middle of knot intervals. In Farin [2002], an algorithm
due to Boehm is given for inserting a single, arbitrary knot. Several
papers aim at such an algorithm for simultaneously inserting into all
knot intervals of a nonuniform, arbitrary degree curve. The LaneRiesenfeld algorithm [Lane and Riesenfeld 1980] does midway
knot insertion for uniform, degree n B-spline curves as a sequence
of one refinement and n smoothing steps. The resulting scheme has

Authors’ addresses: K. Müller, Technical University Kaiserslautern, Postfach 3049, 67653 Kaiserslautern, Germany; email: kerstin.mueller@gmx.org;
C. Fünfzig, L. Reusche, Technical University Kaiserslautern, Postfach 3049, 67653 Kaiserslautern, Germany; email: {c.fuenfzig, l.reusche}@gmx.de;
D. Hansford, G. Farin, Arizona State University; email: {dianne.hansford, gerald.farin}@asu.edu; H. Hagen, Technical University Kaiserslautern, Postfach
3049, 67653 Kaiserslautern, Germany; email: hagen@informatik.uni-kl.de.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made
or distributed for profit or commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation.
Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to
post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be
requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org.
c 2010 ACM 0730-0301/2010/06-ART25 $10.00 DOI 10.1145/1805964.1805969 http://doi.acm.org/10.1145/1805964.1805969

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:2

•

K. Müller et al.

the smallest support among all other subdivision schemes of the
same continuity. Schaefer and Goldman [2009] give a midway knot
insertion algorithm similar to Lane-Riesenfeld for nonuniform and
arbitrary degree B-splines.
Cashman et al. propose a refinement scheme for regular topology
and arbitrary degree in Cashman et al. [2007]. Based on this scheme,
they present in Cashman et al. [2009] a method that, in the case of
uneven degree, works with meshes of face valence four and vertices
of arbitrary valences. For even degree, it works with meshes of
arbitrary face valences and vertices of valence four. Unfortunately,
they do not consider fully arbitrary knot intervals on opposing edges
and special features.
Two approaches extend bicubic NURBS and Catmull-Clark surfaces to allow for arbitrary knot intervals on opposing edges of the
quadrangle control mesh. NURSS of Sederberg et al. [1998] are
fully general in the choice of knot intervals but result in a nonstationary subdivision scheme. Limit point rules are not known
for this scheme to date. In Sederberg et al. [2003] they restrict
the knot intervals to be equal on opposing edges to get back to a
stationary subdivision scheme. As a separate technique, they introduce T-joints on control meshes to achieve C 0 , C 1 , or C 2 continuous surfaces. This is especially suitable for putting together
different NURBS patches [Sederberg et al. 2003] and saving control points in the resulting surface [Sederberg et al. 2004]. Extended Subdivision Surfaces (ESubs) [Müller et al. 2006] also merge
bicubic NURBS and Catmull-Clark rules into one scheme. Different knot intervals are possible on opposing edges of a control
mesh face. The subdivision rules are modified so that the control points converge to the limit points known from NURBS or
Catmull-Clark.
Ternary subdivision is similarly possible by insertion of two knots
in a knot interval. As there are additional control points available,
ternary subdivision schemes are interesting for shape optimization.
Loop [2002] for triangle meshes and Ni et al. [2007] for quadrangle
meshes use ternary subdivision for surface tuning at irregular points.
They yield surfaces with bounded curvature and the convex hull
property. For our work, the ternary subdivision makes our scheme
stationary also in the nonuniform case with arbitrary knot intervals
by sufficiently separating the different knot intervals.

1.2

Contribution

This article introduces a new subdivision scheme as a blend between ternary subdivision for nonuniform, bicubic spline regions
and a ternary subdivision derived from Catmull-Clark around irregular points. The scheme allows us to sufficiently separate different
knot intervals so that it is stationary also in the nonuniform case
with arbitrary knot intervals. Consequently, limit point rules and
limit normal rules are available for this scheme. The benefits are in
modeling with adaptive tessellations of enhanced NURBS surfaces,
with generating offset surfaces, and in rendering, for example, with
continuous displacement mapping of surfaces.

1.3

Overview

In Section 2, we give the surface construction and start with
introducing some notation and preliminaries in Section 2.1. In
Section 2.2, single knot insertion (SINU) for the first subdivision
step is presented. Then the derivation of rules for double knot insertion (DINUS) follows, where we start with curves and then extend
to surfaces. An important problem is how to assign knots to the
edges after a subdivision step. The special features are discussed in
Section 2.4 and the properties are given in Section 3. In Section 4,
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

SINU Subdivision

DINUS Subdivision

new SINU Vertex Point
new SINU Face Point
new SINU Edge Point

new DINUS Vertex Point
new DINUS Face Point
new DINUS Edge Point

Fig. 1. Base mesh M 0 (left), first subdivision step with SINU rules provides
mesh M 1 (middle), a further subdivision step, done with DINUS rules,
results in mesh M 2 (right).

we show applications of the new scheme in modeling and rendering.
Finally, Section 5 gives conclusions and future work.

2.

SURFACE CONSTRUCTION

To construct our surface, we start from a base mesh M 0 of arbitrary
topology. In a first step, we subdivide the mesh using a method
based on single knot insertion per knot interval, which we call
SINU. During this refinement step, we compute for each edge, face,
and vertex of M 0 a new point and connect the new points similar
to the Catmull-Clark scheme (see Figure 1 middle). The resulting
mesh M 1 is a quadrangle mesh with the number of faces totaling the
sum of the face valences in the base mesh. The number of vertices
with valence not equal to 4 increases by the number of nonvalence
4 faces.
We take the quadrangle mesh M 1 as the input mesh for further subdivision steps with a subdivision method based on double
knot insertion per knot interval, which is named DINUS. Using
the quadrangle mesh M 1 instead of M 0 as the input mesh for a
DINUS subdivision surface reduces the number of cases to be handled in the DINUS rules. DINUS subdivision generates for each
edge two new points, for each face four new points and for each
vertex one new vertex point. The new points are connected as described in Figure 1, right, that is, each face is divided into nine
new faces and the new mesh M i+1 after the refinement step i has
9i · (number of faces in M 1 ) new faces. The number of irregular
vertices remains constant for all DINUS subdivision steps, whereas
the number of regular vertices grows exponentially.
SINU and DINUS generate local knot interval vectors for each
control point of the mesh M i . Via these local knot interval vectors,
local Bézier control points around each control vertex of M i can
be computed. These Bézier control points are used to get the new
face, edge, and vertex points for the binary as well as for the ternary
subdivision scheme.
To emphasize, we do the initial SINU step only to transform the
mesh with arbitrary topology into a quadrangle mesh. The SINU
subdivision rules are based on midway knot insertion alike ESubs
[Müller et al. 2006]. The face and edge rules of ESubs and SINU
have a similar structure, and for faces with valence four, the face
rules are even identical. The ESubs vertex rule in the valence four
case comprises the limit point rule to achieve the ESubs limit point.
In contrast, the SINU vertex rule is derived directly from NURBS
and extended to vertices with arbitrary valences. Limit points and
normals of the DINUS surface can be evaluated after the initial
SINU or any following DINUS step.

•

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces
Pj−1

Pj+3

d j−1

d j−2
d j+2

Pj−1

Pj+3

d j−1

d j+3
d j+2

dj
Pj

d j+1
B0j

Pj+2 Pj
d j−1
dj

d j+1

25:3

B1j

B3j+1
B3j

dj

B2j

Pj+1

=

B0j+1

d j+1

dj

B1j+1

B j+1
d j+1 2

Pj+2
d j+2

Pj+1
knot interval vector
d j−2

d j−1

dj

d j+1

d j+2 d j+3
j

j

j

j

Fig. 2. Section of a nonuniform cubic B-spline curve with a section of its knot interval vector presented with its Bézier segments. B0 , B1 , B2 , B3 are the
j +1
j +1
j +1
j +1
Bézier control points corresponding to knot interval dj (marked in blue), likewise, B0 , B1 , B2 , B3 are the Bézier control points of knot interval dj +1
(marked in red).

2.1

Preliminaries

Before we present our new subdivision surface in detail, we introduce the notation, give some definitions, and summarize the
necessary subdivision and limit rules for cubic B-spline curves as
well as bicubic B-spline surfaces.
We use the notation for curves, surfaces, and knot intervals presented in Sederberg et al. [2003] and Müller et al. [2006]. Points
and vectors are denoted by capital letters. Scalars, for example, knot
intervals, are named with lower case letters. Figures 1 to 26 as well
as 28 are schematical drawings to explain the method, they do not
show the exact position of the subdivided and limit points. Also,
the nonuniform knot interval vectors are displayed as uniform ones
mainly to simplify the drawing (Figures 2, 3, 11, 18).
2.1.1 Bézier and B-Spline Curves. Our construction is based
on nonuniform, cubic B-spline curves, surfaces, and their Bézier
segments. Figure 2 shows a section of such a curve with its knot
interval vector. The knot intervals of the knot interval vector, which
indicate the parameter domain of a specific Bézier segment, can be
assigned to the edges of the B-spline control polygon (see Figure 2,
left). To compute the Bézier control points around a vertex, we need
the points in its 1-neighborhood and its local knot interval vector. In
Figure 2, for vertex Pj +1 we get the 1-neighborhood Pj , Pj +1 , Pj +2
and local knot interval vector Kj +1 = {dj −1 , dj , dj +1 , dj +2 } collected from the edges Pj −1 Pj , Pj Pj +1 , Pj +1 Pj +2 , Pj +2 Pj +3 . To
calculate the Bézier control points on the edge Pj +1 Pj +2 (see
Figure 2, right), we need the local knot intervals of the edge Pj Pj +1
and its neighbors Pj +1 Pj +2 , Pj +2 Pj +3 . The three knot intervals
{dj , dj +1 , dj +2 } are assigned to the edge Pj +1 Pj +2 as its knot interval triple. The knot intervals {dj −1 , dj , dj +1 } are the knot interval
triple of the edge Pj Pj +1 and they are necessary to get the Bézier
control points on the edge Pj Pj +1 . The Bézier control points around
vertex Pj +1 can now be determined by
dj +1 + dj +2
dj
· Pj +1 +
· Pj +2
dj + dj +1 + dj +2
dj + dj +1 + dj +2
dj +1
dj −1 + dj
j
B2 =
· Pj +
· Pj +1
dj −1 + dj + dj +1
dj −1 + dj + dj +1
dj +1
dj
j +1
j
j +1
B0 =
· B2 +
· B1 .
(1)
dj + dj +1
dj + dj +1
j +1

B1

=

An infinite control polygon refinement via binary or ternary subj +1
division by knot insertion (see Figures 11, 18) provides B0 as
the limit point of Pj +1 . The direction of the limit tangent is defined
j +1
j
by B1 − B2 . We call the procedures to compute the limit point
Lj and the direction of the limit tangent Tj of a vertex Pj by its
1-neighborhood Pj −1 , Pj , Pj +1 and its local knot interval vector
(2)
Lj = limitCurveVertex(Pj −1 , Pj , Pj +1 , dj −2 , . . . , dj +1 )
Tj = tangentCurveVertex(Pj −1 , Pj , Pj +1 , dj −2 , . . . , dj +1 ). (3)
2.1.2 Bézier and B-Spline Surfaces. We can use the same approach for a bicubic NURBS surface with its two knot interval
vectors. The knot intervals of the horizontal knot interval vector are
assigned to each row. Likewise, the knot intervals of the vertical
knot vector are assigned to each column (see Figure 3, left). The
local knot interval vectors of a vertex can be determined by collecting the knot intervals from the edges in the horizontal and the
vertical direction. In Figure 3, for vertex Pi,j we obtain the horizonh
tal knot interval vector Ki,j
= {ei−2 , ei−1 , ei , ei+1 } and the vertical
v
= {dj −2 , dj −1 , dj , dj +1 } by scanning the
knot interval vector Ki,j
edges in the horizontal and the vertical direction (scanned edges
are marked in blue). We complete the local knot interval triple of
an edge by collecting the edges before and after it with its knot
intervals. In Figure 3, the knot interval triple of the edge Pi−1,j Pi,j
is {ei−2 , ei−1 , ei }.
The Bézier segment of the knot intervals dj , ei is a bicubic Bézier
patch (marked red in Figure 3) that is assigned to face Fi,j of the
control mesh. The Bézier control points around vertex Pi,j (see
the grey and red cubes in the blue marked field of Figure 3, right)
are denoted by Ii+,j + , Ii+,j − , Ii−,j − , Ii−,j + , where the indices +−
indicate the quadrant relative to the point Pi,j . They can be computed
by its 1-neighborhood Pa,b with a = i − 1, . . . , i + 1, b = j −
h
v
, Ki,j
. For our
1, . . . , j + 1, and its two knot interval vectors Ki,j
method, we need the Bézier control point Ii+,j + (see Figure 3, right)
Ii+,j + = ((ei + ei+1 ) · (dj + dj +1 ) · Pi,j
+(ei + ei+1 ) · dj −1 · Pi,j +1 + ei−1 · dj −1 · Pi+1,j +1
+ei−1 · (dj + dj +1 ) · Pi+1,j )/((ei+1 + ei + ei−1 )
(4)
·(dj −1 + dj + dj +1 )).
In a similar way the Bézier control points Ii+,j − , Ii−,j − , Ii−,j + of face
Fi,j −1 , Fi−1,j −1 , Fi−1,j can be calculated. Now, we can determine
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:4

•

K. Müller et al.
d j+1
Pi−1, j+1

d j+1
Pi, j+1

ei−2

ei−1

ei

dj

d j+1
dj

Pi−1, j
ei−2

d j−1

Face Fi−1, j

Pi−1, j−1
ei−2

ei

ei−1

Pi, j−1 ei

d j−2

d j−2
ei−2 ei−1

Pi−1, j
ei−2

Face Fi−1, j

Pi+1, j+1

Li j Face Fi, j

Ii−, j−

Pi+1, j−1
ei+1

Ii+, j+

ei−1 Pi j

d j−1

Face Fi, j−1

dj

Ii−, j+

Pi+1, j
ei+1

d j−1
Face Fi−1, j−1

Pi, j+1

dj

Face Fi, j

ei−1 Pi, j

d j+1
Pi−1, j+1

ei+1

dj

d j−1

d j−2

d j+1
Pi+1, j+1

ei

Pi+1, j
ei+1

d j−1 Ii+, j−

Face Fi−1, j−1

Pi−1, j−1

Face Fi, j−1

Pi, j−1

d j−2

Pi+1, j−1

d j−2

ei ei+1

Fig. 3. Section of a bicubic NURBS surface with sections of its two knot interval vectors (left). For face Fi,j , the dedicated Bézier control points are marked
in red, the Bézier control points of the faces Fi,j −1 , Fi−1,j −1 , Fi−1,j are shown in grey. The local knot interval vector of Pi,j is defined by the knot intervals
on the horizontal and vertical blue edges (right). To compute the Bézier control points around vertex Pi,j (marked in blue), the vertices in the 1-neighborhood
of Pi,j and the local knot interval vector of Pi,j are necessary.
b4

0)
b3
a1

a2

1)

F
a3

F

E2
a4

E3

P0
b2

E1
P0
E4

2) K0h :

E2

E3
P0
E4

F

3) K0v :

E1

E3

E2

F
E1

P0
E4

b1
Fig. 4. Regular case: (0) Knot intervals for the two knot interval vectors K0h and K0v of vertex P0 . (1) Labeling of the edges around P0 . (2) Required knot
interval triples for K0h : Knot interval triple of edge E3 {a1 , a2 , a3 } and edge E1 {a2 , a3 , a4 } provides knot interval vector K0h = {a1 , a2 , a3 , a4 }. (3) Required
knot interval triples for K0v : Knot interval triple of edge E4 {b1 , b2 , b3 } and edge E2 {b2 , b3 , b4 } provides knot interval vector K0v = {b1 , b2 , b3 , b4 }.

the Bézier control point Li,j by
Li,j =

ei · dj −1 · Ii−,j + + ei−1 · dj −1 · Ii+,j + + ei−1 · dj · Ii+,j − + ei · dj · Ii−,j −
(ei−1 + ei ) · (dj −1 + dj ).

(5)
An infinite binary or ternary subdivision by knot insertion results in
a refined control mesh where the refined control point Pi,j converges
to Li,j . The directions of the two limit tangents can be computed
by
ei · Ii−,j + + ei−1 · Ii+,j +
− Li,j ,
ei−1 + ei
dj −1 · Ii+,j + + dj · Ii+,j −
=
− Li,j ,
dj −1 + dj

T 1i,j =
T 2i,j

(6)

so that the limit normal results in
Ni,j = T 1i,j × T 2i,j .

(7)

We denote by
Li,j = limitPoint(Pi−1,j −1 , . . . , Pi,j , . . . , Pi+1,j +1 ,
ei−2 , . . . , ei+1 , dj −2 , . . . , dj +1 )

(8)

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

Ni,j = limitNormal(Pi−1,j −1 , . . . , Pi,j , . . . , Pi+1,j +1 ,
ei−2 , . . . , ei+1 , dj −2 , . . . , dj +1 )

(9)

the procedures to compute the limit point Li,j and the limit normal
Ni,j of a vertex Pi,j with its 1-neighborhood Pa,b , a = i −1, . . . , i +
1, b = j − 1, . . . , j + 1, and its two local knot interval vectors
h
v
= {ei−2 , ei−1 , ei , ei+1 }, Ki,j
= {dj −2 , dj −1 , dj , dj +1 }.
Ki,j
2.1.3 Knot Interval Vectors and Knot Interval Triples for All
Cases. To determine the knot interval vectors, we distinguish between the regular and the irregular case. The control mesh of a
NURBS surface has a regular topology with regular vertices and
faces. More precisely, a vertex V of a mesh is regular, if it has
valence four in the interior of the mesh and valence three or two
at the border. A face is regular if it has valence four. A mesh with
regular faces and vertices has a regular topology. For the regular
case, that means we have a regular vertex and a regular topology in
its 1-neighborhood without sharp edges or borders, we get the two
knot interval vectors of the vertex as described in Section 2.1.1 and
2.1.2 (see also Figure 4).
In the irregular case, we compute the knot interval vectors per
vertex and per face. The method extends the regular case; that means
it also provides the regular knot interval vectors for the regular case.

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces
0)

a)

b)

E2

T12 (1):

E1
P1

E3
P2

P1

E4

P2

E3

P2

c)

E1

P2
E2

P2
E4

E4
E3

P1

E1
P1

b)
E1

P2
E2

E3

E4

E4

E1

E2
E1

P1

a)
E4

P1

E3

E4

0)
T12 (3):

E2
E1

25:5

c)

E2

E3

•

E4
E3

P1

E1

P2
E2

E3

P1

P2
E2

Fig. 5. Examples for T1,2 (1) and T1,2 (3): (0) Notation. (a) through (c) are related to the cases (a) through (c) to get T1,2 (k), k = 1, 3: (a) Two sharp edges
(including E1 ): E1 and E2 are sharp, take the knot interval of E2 as T1,2 (k). (b) Two sharp edges (without E1 ) or three sharp edges: E1 , E2 , E3 are sharp, take
the knot interval of E1 as T1,2 (k). (c) Otherwise take the knot interval of E3 as T1,2 (k).

0)

a)

b)

E2

Ei

E2

E1

T1,2 (1):
P1

E1
P2

P1

E1
P2

P1

En

0)

a)

b)

Em

T1,2 (3):

Ei

E1

P1

Em
E1

E1
P2

P2
En

P1

E2

P2

P1

P2
E2

Fig. 6. Examples for T1,2 (1) and T1,2 (3): (0) Notation. (a) through (b) are related to the cases (a) through (b) to get T1,2 (k), k = 1, 3: (a) Two sharp edges
(including E1 ): E1 and Ei are sharp, take the knot interval of Ei as T1,2 (k). (b) Otherwise take the knot interval of E1 as T1,2 (k).

The idea is that sharp edge lines and irregular topology are integrated
in a natural way, for example, during collection of the knot intervals
for the knot interval vectors we stay on sharp edge lines. We also do
not cross sharp edges, instead we complement the missing entries
in the knot interval vectors in a suitable manner.
Before we give all the details, we introduce the knot interval
triples of an edge for the arbitrary case, which we need for the knot
interval vectors.
We use the following notation to determine the knot interval
vectors and knot interval triples: For the knot interval vectors of
a given vertex P0 and a face F in the arbitrary case, we label the
incident edges of P0 counterclockwise around P0 in such a way that
for the horizontal knot interval vector, the edges denoted by E1 and
E2 are edges of face F (see Figures 7 and 8, top). For the vertical
knot interval vector, we rotate the labeling of the horizontal knot
interval vector in counterclockwise direction by one (see Figures 7
and 8, bottom). For the knot interval triple of an edge Pi Pj looking
at vertex Pi , we label the incident edges of Pi counterclockwise
around Pi starting with edge Pi Pj (bold marked in Figures 5 and
6). Additionally, red edges are sharp edges or borders. The green
tag on an edge indicates its knot interval, and three blobs on an
edge indicate its knot interval triple. Figures 5 through 8 illustrate
an example for each case and do not show the complete variety.

2.1.3.1 Knot Interval Triples for All Cases. To obtain a
unique and unambiguous notation for the knot interval triples in the

arbitrary case with arbitrary topology, we use directed edges for
the definition. That means we distinguish between the knot interval
triple of P1 P2 and P2 P1 : If T1,2 = {t1 , t2 , t3 } is the knot interval
triple of P1 P2 then T2,1 = {t3 , t2 , t1 } is also the knot interval triple
of P2 P1 received by exchanging the first and last entry T2,1 =
{T1,2 (3), T1,2 (2), T1,2 (1)}.
We consider an edge P1 P2 in direction P1 to P2 and its knot
interval triple T1,2 = {t1 , t2 , t3 } consisting of three knot intervals,
which we collect as follows.
T1,2 (2): The entry in the middle t2 = T1,2 (2) is the knot interval of
the edge P1 P2 .
T1,2 (k): The first entry t1 = T1,2 (1) depends on the valence of
vertex P1 as well as on the presence of sharp edges or borders. Similarly, the last entry t3 = T1,2 (3), depends on the valence of vertex P3 and the existence of sharp edges or borders
respectively.
(1) For the first entry k = 1, if P1 has valence 4, and for the third
entry k = 3, if P2 has valence 4 (see Figure 5 for notation), we
take the following knot intervals.
(a) If the two edges E1 and Ei , i ∈ {2, 3, 4}, are sharp/border:
Take the knot interval of the edge Ei as T1,2 (k).
(b) If the two edges Ei , Ej , i, j = 1 are sharp/border or three
edges are sharp/border: Take the knot interval of the edge
E1 , that means in the case k = 1, we have the same first
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:6

•

K. Müller et al.
P2

0)

E2
h :
K0,F

E3
P3

E3
P1

P3

P1

0)
E2
P2

E1
E4

P0
E3
P3

E2
P4

P2

P3

P1
E2

P4

E3
P1

P0
E3
P3

E1

E1
E2
P4

P1

P1

E4

P2

F

P0
E4
P4

c)

F

E1

E4
P0
E3
P3

P0
E4
P4

b)

F

E2

E1

P3

P1

a)

E1
v :
K0,F

E3
P1

P2

c)

F

E2

E1
P0
E4
P4

P2

b)

F

E2

E1
P0
E4
P4

P2

a)

F

P2

F
E4

P0
E3
P3

P4

h
v (see bottom row) for vertex P has valence 4: (0) Notation. (a) through (c) are
Fig. 7. Examples for the knot interval vectors K0,F
(see top row) and K0,F
0
related to the cases: (a) Two sharp edges (including E1 ): E1 and E4 are sharp, take the knot interval triples T4,0 , T0,1 of E1 and E4 . The resulting knot interval
vector is {T4,0 (1), T4,0 (2), T0,1 (2), T0,1 (3)}. (b) Two sharp edges (without E1 ) or three sharp edges: E2 , E3 are sharp, take the knot interval triple T0,1 of E1
and get {T0,1 (1), T0,1 (1), T0,1 (2), T0,1 (3)}. (c) Otherwise take the knot interval triples T3,0 , T0,1 of E3 and E1 , obtain {T3,0 (1), T3,0 (2), T0,1 (2), T0,1 (3)}.

P2

0)
P3 E2
E3
P0

h :
K0,F

v :
K0,F

E2

F

P0
Pi

Pn

P1
P2 E1
E2
P0
Pn−1

P1

P2 E1
E2
P0

F
Pn
P0

Pi

P1
E1

En

Ei

Pn

P1

b)

Pn
En

F

En

E1

F

E1

Ei

a)

En−1

P3 E2
E3
P0

F
P1

E1

P2

b)

P1
En

0)

P2

a)

Pn−1

F
Pn
En
En−1

h
v
Fig. 8. Examples for the knot interval vectors K0,F
(see top row) and K0,F
(see bottom row), valence of vertex P0 = 4: (0) Notation. (a) through (b) are
related to the cases: (a) Two sharp edges (including E1 ): E1 and Ei are sharp, take the knot interval triples Ti,0 , T0,1 of Ei and E1 , get the knot interval vector
{Ti,0 (1), Ti,0 (2), T0,1 (2), T0,1 (3)}. (b) Otherwise take the knot interval triple T0,1 of E1 and obtain {T0,1 (1), T0,1 (1), T0,1 (2), T0,1 (3)}.

and middle entry, and in the case k = 3, we obtain the
same entry in the last and middle place. Hence, we get
T1,2 (k) = T1,2 (2).
(c) For all other cases: Take the knot interval of the edge E3
as T1,2 (k).

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

h5
P2

P5
a2
Border or sharp edge

(2) If P1 in the case k = 1, and P2 in the case k = 3, has valence
unequal to 4 (see Figure 6 for notation), take the following
knot intervals:
(a) If the two edges E1 and Ei , i ∈ {2, . . . , valence(P1 )}
for k = 1, and i ∈ {2, . . . , valence(P2 )} for k = 3, are
sharp/border:
Take the knot interval of the edge Ei as T1,2 (k).
(b) For all other cases: Take the knot interval of the edge E1 .
That means for k = 1 we have the same first and middle
entry, and for k = 3 we get the same last and middle
entry. Thus, T1,2 (k) = T1,2 (2).
2.1.3.2 Knot Interval Vectors for All Cases. To get the
h
v
two knot interval vectors K0,F
= {a1 , a2 , a3 , a4 } and K0,F
=
{b1 , b2 , b3 , b4 } for a vertex P0 and a face F (see Figure 4 for the
regular case), we use the notation in Figures 7 and 8: By using the
notation for the horizontal knot interval vector (see Figure 7 and

b4

h4

h1
P6

h2

a3

P7
h3

b3

d3

g3

P1

e2 P0

e3 P3

b2

d2

g2

P9

c2 P4

c3 P8

b1

d1

g1

e4

c4

Fig. 9. Base mesh with arbitrary topology, arbitrary knot intervals, border,
and sharp edges.

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces
y · b5

b5
d
b
d b
a
g
d

e

b

f

y · b4

b4

f

e

b

a
a
d a
e
f
g
c
c
c
c
e
f
g

a1

a2

a3

a4

a1

a2

x · a3
b2

y · b2

b1

y · b1

d4
a3

e3 = a3
e1 e2

a4

a5

d3 = b3

b3

x · a4 x · a5

25:7

d5

b4
a5

y · b3

b3
x · a1 x · a2

b5

•

e4

b2

d2

b1

d1

e5

Fig. 10. Quadrangle mesh with regular, that means NURBS-like, knot interval structure (left). Nonaugmented face (yellow, middle). Augmented face (orange,
right). The opposing vertical and horizontal knot interval vectors must have the same ratio if it is not an augmented face.

8, top), we get the horizontal knot interval vector, and similarly, by
using the notation for the vertical knot interval vector (see Figure 7
and 8, bottom), we obtain the vertical knot interval vector of vertex
P0 and face F .
(1) If P0 has valence 4 (see Figure 7 for notation):
(a) If the two edges E1 and Ei , i ∈ {2, 3, 4}, are
sharp/border:
take the knot interval triples Ti,0 and T0,1 of the edges
Ei and E1 , set:
{Ti,0 (1), Ti,0 (2), T0,1 (2), T0,1 (3)}.
(b) If the two edges Ei , Ej , i, j = 1 are sharp/border or
three edges are sharp/border:
take the knot interval triple T0,1 of the edge E1 , set:
{T0,1 (1), T0,1 (1), T0,1 (2), T0,1 (3)}.
(c) For all other cases, they are treated like the regular
case:
take the knot interval triples T3,0 and T0,1 of the edges
E3 and E1 , set:
{T3,0 (1), T3,0 (2), T0,1 (2), T0,1 (3)}.
(2) If P0 has valence unequal to 4 (see Figure 8 for
notation):
(a) If the edges E1 and Ei , i ∈ {2, . . . , valence(P1 )}, are
sharp/border:
take the knot interval triples Ti,0 and T0,1 of the edges
Ei and E1 , set:
{Ti,0 (1), Ti,0 (2), T0,1 (2), T0,1 (3)}.
(b) For all other cases:
take the knot interval triple T0,1 of the edge E1 , set:
{T0,1 (1), T0,1 (1), T0,1 (2), T0,1 (3)}.
As an example (see Figure 9), consider the local horizontal and the
local vertical knot interval vector of vertex P0 and face F defined
by the vertices P0 , P3 , P7 , P6 , P2 .
v
= {d1 , d2 , d3 , d3 },
K0,F

h
K0,F
= {e2 , e2 , e3 , e4 }

(10)

h
we need the knot interval triples
For the knot interval vector K0,F
T1,0 , T0,3 of the edges P1 P0 and P0 P3 . In the same manner, the knot
interval triples T4,0 , T0,2 of the edges P4 P0 and P0 P2 are necessary
v
. Vertex P2 has irregular valence, that
for the knot interval vector K0,F
means the knot interval triple T0,2 of the edge P0 P2 is {d2 , d3 , d3 }.
v
Therefore, the last entry of the vertical knot interval vector K0,F
gets the knot interval d3 . Because edge P1 P0 is terminated at vertex
P1 by a sharp edge or border, the first entry of the knot interval triple
T1,0 of the edge P1 P0 is substituted by e2 and we get {e2 , e2 , e3 }.
h
Thus, the first entry of the horizontal knot interval vector K0,F
is
replaced by e2 .

Please remember that we assign the knot interval vectors per
vertex and per face: In our example, vertex P2 of face F2 deh
=
fined by P2 ,P0 ,P3 ,P7 ,P6 , has the knot interval vectors K2,F
2
v
{d3 , d3 , d3 , d2 } and K2,F
=
{a
,
a
,
a
,
a
}.
The
knot
interval
3
3
3
3
2
triples T2,0 , T2,6 of the edges P2 P0 and P2 P6 are {d3 , d3 , d2 } and
{a3 , a3 , a3 }. In comparison, the knot interval vectors of vertex P2
h
and face F3 defined by P5 ,P1 ,P0 ,P2 are K2,F
= {a2 , a2 , a2 , a2 } and
3
v
K2,F3 = {d3 , d3 , d3 , d2 }.
After the definition of the knot interval vectors, we have a closer
look at the internal structure of the knot intervals.
A quadrangle mesh with a regular, that means bicubic NURBSlike, knot interval structure has equal knot intervals on opposite
sides of a face. A knot interval vector {a, b, c, d} is uniform if
a = b = c = d. In the same way, a knot interval triple {a, b, c} of
an edge is uniform if a = b = c. A face is called augmented if the
knot intervals on opposing edges of the face are different and the
horizontal as well as vertical knot interval vectors of the face do not
have the same ratio (see Figure 10 and Müller et al. [2006]).
In the next two sections we introduce our new subdivision surface that can deal with arbitrary two-manifold topology, augmented
faces, and special features.

2.2 SINU Subdivision
Firstly, we carry out one subdivision step with the SINU subdivision
rules, which are based on midway knot insertion. We start with the
subdivision rules for a curve. These rules are needed for special
features on the surface. After that, we develop the subdivision rules
for the surface and have a look at the knot intervals on the new and
subdivided edges.
2.2.1 Curve Scheme. Via midway knot insertion we obtain for
each edge and for each vertex a new edge and a new vertex point
(see also Sederberg et al. [1998], and Müller et al. [2006]). In the
example of Figure 11 we get the new edge point Ej by the Bézier
j
j
control points B1 and B2 (see also Figure 2).
Ej =
j

1  j
j
· B1 + B2
2

(11)

j

B1 and B2 are computed (see Eq. (1)) by the edge Pj Pj +1 , and its
knot interval triple {dj −1 , dj , dj +1 }. The new vertex point Vj +1 can
now be computed by


dj +1 · Ej + dj · Ej +1
1
(12)
+ Pj +1 ,
Vj +1 = ·
2
dj + dj +1
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

•

25:8

K. Müller et al.
Pj−1

Pj+3

Pj−1

d j−1

d j+2

d j−1

Pj

Pj+2 Pj
Ej

B1j

dj

E j+1
V j+1

B2j

B1j+1

Pj+3
d j+2

Vj

V j+2
Ej

B2j+1
d j+1

Pj+2

E j+1
V j+1

dj

Pj+1

d j+1

Pj+1
knot interval vector
d j−1

dj

d j+1

d j+2

Fig. 11. Subdivision step of a nonuniform cubic B-spline curve via midway knot insertion.

b4

h5

Border or sharp edge

a2

h4

and, let T0,1L = {b0 , b1 , b2 } be the knot interval triple of the edge
P0 P1L . Then, I can be calculated by

h1

I =

h2

a3

h3
b3

d3

e2
b2

e3
d2

c2
b1

g3

g2

c4
g1

Fig. 12. SINU base mesh with arbitrary topology, arbitrary knot intervals,
border, and sharp edges. Around each vertex, the (pseudo) Bézier control
points are depicted.

2.2.2 Surface Scheme. The SINU subdivision surface must
deal with arbitrary face valence, arbitrary vertex valence, arbitrary
knot intervals on the edges, and special feature tags. Figure 12
shows an example for a SINU base mesh.
To compute the new face, edge, and vertex points we collect
the knot interval vectors and knot interval triples as described in
Section 2.1.3.
For the new face point, we must determine the Bézier control
points I for all vertices of the considered face firstly. Because we
deal with irregular face valences, we must extend the computation
of I for the regular face of valence four (Eq. (4)) to an arbitrary face
valence (see Figure 13 for notation). To compute the Bézier control
point I of a vertex P0 and a face F we need two vertices P1L and P2L
of F in clockwise direction starting from P0 , as well as two vertices
P1R and P2R of F in counterclockwise direction starting from P0 .
Also, the knot interval triples of the edges P0 P1R and P0 P1L are
necessary (see also Section 2.1.3 for the knot interval triples): Let
T0,1R = {a0 , a1 , a2 } be the knot interval triple of the edge P0 P1R
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

+P2R

+a0 ·(b1 +b2 )·P1R

(13)
for all face valences (see Figure 13).
Having all Bézier control points Ii of the considered face F (see
Figure 14, left), the new face point can then be calculated for all
cases by

e4

c3
d1

P

(a1 +a2 )·(b1 +b2 )·P0 +(a1 +a2 )·b0 ·P1L +a0 ·b0 · 2L 2
(a2 +a1 +a0 )·(b0 +b1 +b2 )

F =

n
1 
·
Ii .
n i=1

(14)

For the new edge point E (see Figure 14, right), we need the two
new face points Fl and Fr of the two faces adjacent to the considered
edge, the knot intervals of the green marked edges a1 , a2 , b1 , b2 as
well as the knot interval triple T1,2 = {c1 , c2 , c3 } of the edge P1 P2 ,
and the midpoint of the edge.
We get the midpoint of the edge P1 P2 by its knot interval triple
and its endpoints
M=

(c2 /2 + c3 ) · P1 + (c1 + c2 /2) · P2
.
c1 + c2 + c3

(15)

The new edge point can now be computed for all cases by (for
notation see Figure 14, right)


1
· (a2 + b2 ) · Fl + 12 · (a1 + b1 ) · Fr
1
2
E= ·
+ M . (16)
1
2
· (a1 + a2 + b1 + b2 )
2
For the computation of the new vertex point, we distinguish
between regular and irregular vertex points. For the regular vertex
point, we use the refinement rule for bicubic NURBS surfaces (see
Figure 15, left)
V =



ei · dj −1 · Fi−1,j + ei−1 · dj −1 · Fi,j + ei−1 · dj · Fi,j −1 + ei · dj · Fi−1,j −1
(ei−1 + ei ) · (dj −1 + dj )

ei · Mi− 12 ,j + ei−1 · Mi+ 12 ,j
dj −1 · Mi,j + 12 + dj · Mi,j − 12
+
+
+ P0
ei−1 + ei
dj −1 + dj
1
·
4

(17)
whereby Mi+ 1 ,j is a midpoint of the edge Pi,j Pi+1,j in horizontal
2

direction, and Mi,j + 1 is a midpoint of the edge Pi,j Pi,j +1 in vertical
2
direction.
To get the new irregular vertex point V with valence k (see
Figure 15, right), we calculate the midpoints Mi (Eq. (15)) of the
incident edges P0 Pi , i = 1, . . . , k via its knot interval triples T0,i

•

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces

25:9

P2L = P2R
P2L

P1L = P2R

P2R
P1L

P1L

I

P1R
P0

P1R

I

P1R = P2L

I

P0

P0

Fig. 13. Computation of the (pseudo) Bézier control points I illustrated for arbitrary face valences (left), valence four (middle), and valence three (right).

P2

P1
I2

I1

I3
P3

to all incident edges of P as new knot intervals. With this regularization step, the knot intervals are averaged to achieve uniform knot
intervals around irregular vertices. It reduces the number of cases
for DINUS considerably.

b2

Pn
Fl

In
F

P2

b1

I4
P4

a1

E

M

Fr

2.3 DINUS Subdivision
P1

a2

Fig. 14. SINU subdivision: New face point (left) and new edge point
(right).

and the points Pi , i = 0, . . . , k firstly. With these midpoints Mi , the
neighboring new face points Fi , the points on the incident edges Pi ,
and the old vertex point, we can compute the new vertex point


k
k
1 
3
2 
+ 2 ·
Fi + 2 ·
Mi .
V = P0 · 1 −
k
k i=1
k i=1

(18)

It is easy to see that the SINU subdivision rules (Eqs. (14), (16),
(17), and (18)) reduce to the Catmull-Clark rules in the case of
uniform knot intervals. Also, if we have NURBS-like knot intervals
and regular topology, the SINU subdivision rules (Eqs. (14), (16),
and (17)) are identical to the NURBS subdivision rules.
We do not need limit point and normal rules for SINU because
we only do one initial subdivision step with SINU and continue
with the DINUS rules after that.
So, with these SINU subdivision rules, we perform a first subdivison step on the base mesh M 0 to obtain a quadrangle mesh
M 1 for further treatment with the DINUS rules. Before the DINUS
rules can be applied on the mesh M 1 , the knot intervals need to be
assigned to the new and subdivided edges.
2.2.3 Knot Interval Assignment. We assign knot intervals to
the new and subdivided edges in two steps as described in
Figures 16 and 17.
In a first step, we do the same knot interval assignment as ESubs [Müller et al. 2006] and NURSS [Sederberg et al. 1998] (see
Figure 17 middle). For the new edges, the knot intervals on opposing edges are averaged (see Figure 16, left). After this assignment,
we perform a regularization step of knot intervals on the incident
edges around all irregular vertices (see Figure 16, right).
Let P be an irregular vertex with valence k, and ai , i = 1, . . . , k
are the knot intervals on the incident edges of P . We assign
av =

k
1
ai
k i=1

The DINUS rules must now deal with a mesh M 1 generated by
the SINU subdivision rules. M 1 has quad faces only, irregular and
regular vertices, as well as tags for special features. Each face has at
most one irregular vertex due to the SINU subdivision step. Around
each irregular vertex, the knot intervals on its incident edges are
equal. The DINUS rules must still cope with augmented faces that
have irregular as well as regular vertices.
The rules for DINUS subdivision are based on double knot insertion. We start with the rules for curve subdivision that we also
need for special features. Afterwards, we introduce the subdivision
surface rules, the limit point as well as the limit normal rules.
2.3.1 Curve Scheme. Via ternary subdivision of the knot intervals (i.e., double knot insertion per knot interval), we get two new
edge points for each edge and one new vertex point for each vertex.
j
j +1
In Figure 18, the new edge points E2 , E1 , and the new vertex
j
j
point Vj +1 can be computed by the Bézier control points B1 , B2 ,
j
j +1
j +1
j +1
B3 = B0 , B1 , B2 (see also Figure 2) via the knot interval
vector of Pj +1 , and the vertices in its 1-neighborhood Pj , Pj +1 ,
Pj +2 .
j

1 
j
j
j
(19)
· 2 · B3 + 5 · B2 + 2 · B1
9




j
j
j +1
j +1
dj +1 · (B1 + 2 · B2 ) + dj · (2 · B1 + B2 )
1 2
·
=
+ Pj +1
3 3
dj + dj +1

E2 =
Vj +1

(20)
j +1
The rule for the new edge point E1 can be obtained from the
j
rule of E2 via symmetry. We denote by
j

E2 = subdivDINUS CurveEdge(Pj +2 , Pj +1 , Pj , dj +2 , . . . , dj −1 )
(21)
j

the procedures to compute the new edge point E2 on the edge
Pj +1 Pj next to Pj +1 .
Also, we denote by
Vj +1 = subdivDINUS CurveVertex(Pj , Pj +1 , Pj +2 , dj −1 , . . . , dj +2 )
(22)
the procedure to calculate the new vertex point Vj +1 of
Pj +1 .
The knot interval vector of Pj +1 {dj −1 , . . . , dj +2 } and its 1neighborhood Pj , Pj +1 , Pj +2 are required as input parameters for
the new vertex and new edge point.
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:10

•

K. Müller et al.

d j+1
Pi−1, j+1

Pi, j+1
Fi−1, j

M4

F3

2

Mi− 1 , j

Mi+ 1 , j

V

2

ei−2

P4

Fi, j
Mi, j+ 1

dj
Pi−1, j

Pi+1 j+1

ei−1 Pi, j
Fi−1, j−1
d j−1

Pk

Pi+1, j

2

ei
Fi, j−1

Mk

ei+1

Fk

Mi, j− 1
Pi+1, j−1

F1

M2

P1

Pi, j−1

P3

F2

M1

2

Pi−1, j−1

M3

P0 V

P2

d j−2
Fig. 15. SINU subdivision: New vertex point for a regular vertex (left) and for an irregular vertex (right).

1)

c

2)

c

b

ak

a1
a2

a+c
2

b

b

F

a3

a

a

av
P
av
av

av

P
a4

av

Regularization for
DINUS Subdivision

SINU Subdivision

Fig. 16. (1) For the new edges obtained by the first SINU subdivision step, we average the knot intervals on the opposing edges. (2) In a second step, an
averaging of the knot intervals around irregular points is done.

e
f

e

f

m

d

e

l g

g
a

a

c
b

h

k
j

q

t
r

o

s

q

e+b
2

i

b

e+c
2

a+c
2

o

SINU Subdivision

d m

c
k

b

o

f

e

c l g

d+b
2

i+ j
b+o 2 b+o
2
2
i+ j
2

r

avV

d

d+a
2

a

h
i

i

avV
V
avV

n

n

a

j

i
t

s

r

F

avF

avF
a

h
i

j

avF

b

c l

avF
avF

c
k

b

i+ j
b+o 2 b+o
2
2
i+ j
2

o

d m

o

j
j
s

Regularization for DINUS Subdivision

Fig. 17. Knot interval assignment after the first SINU subdivision step (middle). An averaging of the knot intervals around irregular points is added:
avF = (a + b + c + d + e)/5, avV = (e + d + n)/3.

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces
Pj−1

Pj+3

Pj−1

d j−1

d j+2

Pj
B1j

dj

B3j

B2j

=

B0j+1
V j+1

E1j+1
B1j+1

d j+2

Vj
E1j

B2j+1
d j+1

E2j

j+1
V j+1 E1

dj

Pj+1

25:11

Pj+3

d j−1
Pj+2 Pj

E2j

•

V j+2
E2j+1

Pj+2

d j+1
Pj+1

knot interval vector
d j−1

dj

d j+1

d j+2

Fig. 18. Subdivision step of a nonuniform cubic B-spline curve via double knot insertion per knot interval.
e4

e3
d1

d2

P1

d3
d3

d3

P0
d3

e2

d3

e1
Fig. 19. DINUS subdivision step: each edge gets two new edge points,
each face obtains four new face points, and the old vertex is replaced by a
new vertex point.

2.3.2 Surface Scheme. During one subdivision step, the ternary
subdivision scheme DINUS provides us with two new edge points
for each edge, four new face points for each face, and one new
vertex point for each vertex (see Figure 19). To perform a DINUS subdivision step, we collect the local knot interval vectors and
the 1-neighborhood of each vertex and compute the surrounding
new edge, new face, and new vertex points. For point P0 with
valence k = 5 in Figure 19, we calculate k new face points
(green cubes in the red polygon around P0 ) and the k new edge
points (green rhombuses in the red polygon around P0 ) as well
as the new vertex point of P0 (green circle next to P0 ) based on
the knot interval vectors of P0 and its 1-neighborhood. After the
computation of the new points, we connect them as depicted in
Figure 19.
For the computation of the new DINUS face, edge, and vertex
points, we must consider two cases: We distinguish between the
computation of the new face, edge, and vertex points around a
regular and an irregular vertex in the control mesh.

Subdivision rules in the regular case. In the case the vertex Pi,j is regular, (see Figure 20, left) we collect the two loh
= {ei−2 , ei−1 , ei , ei+1 },
cal knot interval vectors of Pi,j , Ki,j
v
Ki,j
= {dj −2 , dj −1 , dj , dj +1 }, and its 1-neighborhood Px,y , x =
i − 1, . . . , i + 1, y = j − 1, . . . , j + 1. The local mesh consisting of Px,y , x = i − 1, . . . , i + 1, y = j − 1, . . . , j + 1 is
treated as a bicubic, nonuniform B-spline surface patch with the loh
v
cal knot interval vectors Ki,j
and Ki,j
. A local ternary division of the

knot intervals ei−1 , ei horizontally, and dj −1 , dj vertically, provides
the new edge and face points as well as the new vertex point for
Pi,j .
Hence, the new regular face and edge point can be calculated
by subdividing the horizontal curve sections Pi−1,j +1 Pi,j +1 Pi+1,j +1 ,
Pi−1,j Pi,j Pi+1,j , Pi−1,j −1 Pi,j −1 Pi+1,j −1 with the procedure subdivDINUS CurveEdge according to the knot interval vector
h
={ei−2 ,ei−1 ,ei , ei+1 } (see Figure 20, left). We denote the
Ki,j
resulting points by Hy , y = j − 1, . . . , j + 1. They are rev
={dj −2 ,dj −1 ,dj ,dj +1 } and
fined using the knot interval Ki,j
the method subdivDINUS CurveEdge for the new face point
and subdivDINUS CurveVertex for the new edge point (see
Figure 20, middle). Similarly for the new vertex point, we subdivide the horizontal curve sections with subdivDINUS CurveVertex
h
. We denote the resulting
using the knot interval vector Ki,j
points by Qy , y = j − 1, . . . , j + 1, and refine them with
subdivDINUS CurveVertex according to the knot interval vector
v
of Ki,j
(see Figure 20, middle).
Using a tensor product with uniform knot intervals, we get the
weights for the new face, edge, and vertex points for a regular
topology as depicted in Figure 21. These masks are also part of the
ternary Catmull-Clark for regular topolgy, which we use in the next
section.

Subdivision rules in the irregular case. To determine the
new subdivided points around an irregular vertex, we have a look
at its knot intervals firstly. The knot intervals on the incident edges
are equal because of the preceeding SINU subdivision step. That
means, after one further DINUS subdivision step, the knot interval
triples on the incident edges of the irregular vertex are uniform. Also
the knot interval vectors of the irregular vertex are uniform. We use
uniform knot interval vectors always at irregular vertices for the
computation of the new vertex point and the surrounding new face
and edge points. As required for the properties of DINUS, uniform
knot interval vectors should provide a Catmull-Clark surface locally.
To determine the ternary Catmull-Clark rules for a new face and
edge point around the irregular vertex as well as the rule for the
irregular vertex itself, we proceed as sketched in Figures 22 and
23. We already have the ternary rules for a new face, edge, and
vertex rules for regular topology (see Figure 21), and we make
these assumptions:
(1) A binary Catmull-Clark step and a ternary subdivision step
afterwards produces the same mesh as a ternary subdivision
step followed by a binary Catmull-Clark step.
(2) In the limit, the binary Catmull-Clark subdivision and
the ternary Catmull-Clark subdivision provide the same
surface.
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:12

•

K. Müller et al.

Pi−1, j+1

d j+1 Pi, j+1

Pi+1, j+1

Pi−1, j+1 Pi, j+1 Pi+1, j+1
Q j+1 H j+1
Pi, j
Pi+1, j

dj
Pi−1, j
ei−2

Pi−1, j−1

ei−1
d j−1

Pi, j
ei

d j−2 Pi, j−1

Pi+1, j
ei+1

Pi−1, j+1
Q j+1

Pi−1, j

Qj Hj
Pi−1, j−1 Pi, j−1 Pi+1, j−1

Pi+1, j−1

V

Qj
Q j−1

Q j−1 H j−1

d j+1 Pi, j+1

H j+1
F
E

Hj
H j−1

Pi−1, j
ei−2

Pi−1, j−1

dj
Pi, j V
ei−1
d j−1

Pi+1, j+1

F
Pi+1, j

E
ei

ei+1

d j−2 Pi, j−1

Pi+1, j−1

Fig. 20. DINUS subdivision: New face, edge, and vertex point around a regular vertex.

(a)new face point F

(b) new edge point E

160
729

10
729

100
729

4
729

160
729

19
729

10
729

4
729

(c) new vertex point V

64
729

40
729

16
729

190
729

76
729

40
729

16
729

76
729

16
729

V

76
729

76
729

16
729

F
256
729

16
729

16
729

1
729

304
729

E

64
729

361
729

Fig. 21. Weights for the regular new face, new edge, and new vertex point with uniform knot intervals.

DI N U S
P9

P8

P7

CC

P6
F3

F2
TB

P0
P2k−1

P2k

P2

P1
P9

F0

P5

P8

P3

P4

P7

P6

F1

T B = BT

BT
P0

P5

P2k−1

P2k

P1

P2

P3

P4
CC

D IN U S

Fig. 22. Comparison of the weights for TB and BT provides the new face rule for DINUS. Top: A DINUS subdivision step followed by a Catmull-Clark step
provides the face point TB. The yellow points are the yet unknown new face, edge, and vertex points of the DINUS. Bottom: A Catmull-Clark subdivision
followed by a DINUS subdivision step. All rules are known and point BT can be expressed by weights of P0 , . . . , P2k .

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces
To obtain the new face as well as the new edge rule in the irregular
case, we use the first assumption. In Figure 22 top, P0 is an irregular
vertex and P0 P5 P6 P7 is a neighboring face of P0 . We subdivide the
face with the DINUS rules, where the rules for the regular case
determine the red points.
We apply the rule with the yet unknown weights for the new face
point F0 . Then we do a further binary subdivision step (see Figure
22 right) to obtain the point TB. We solve for the weights of TB
for the points P0 , . . . , P2k of the base mesh. They include the yet
unknown weights for the face rule.
We can get the same point TB = BT by using the first assumption
again: We do a binary Catmull-Clark step on face P0 P5 P6 P7 , for
which we know all the rules. Then we continue with the DINUS
rules, which require in this case the regular rules only. A comparison
of the weights of BT and of T B for the points P0 , . . . , P2k of the
base mesh provides the new face rule.
We now have the new face rule available, and we can find the
new edge rule for DINUS by proceeding similarly, as sketched in
Figure 23.
For the new vertex rule, we use the second assumption. We can
compute the new face and edge points around the irregular point
with known rules now. The new vertex point is obtained by the
vertex rule, for which we need to determine the weights. We apply
the binary Catmull-Clark limit point rule to the points P0 , . . . , P2k
of the base mesh and to the 1-ring of subdivided points. For both
limit points, we compute the weights for the points P0 , . . . , P2k of
the base mesh. A comparison of the weights provides the new vertex
point rule.
The resulting DINUS rules for the new face, edge, and vertex
points around a vertex with valence k are (see Figure 24):

F0 =
F1 =
F2 =
F3 =
F4 =
Fγ =
Fβ =

1
729
1
729
1
729
1
729
1
729
1
729
1
729

· (220 + 64 · α)
· (154 + 64 · β)
· (99 + 64 · γ )
· (9 + 64 · γ )
· (10 + 64 · β)
· (64 · γ )
· (64 · β)

E0 =
E1 =
E2 =
E3 =
E4 =
E5 =
Eβ =
Eγ =

Vα = 1 −

1
729
1
729
1
729
1
729
1
729
1
729
1
729
1
729

·
·
·
·
·
·
·
·

8
3
8
3
8
3
8
3
8
3
8
3
8
3
8
3



· 68 · α + 75 + 34


· 68 · β + 17 + 58


· 68 · β + 64 + 78


· 68 · γ + 13 + 15
16


· 68 · γ + 167


· 68 · β + 38
· (68 · β)
· (68 · γ )

βL
γL
· k · E0 −
· k · F0
αL
αL

βL
· ( F0 + 2 · ( F 1 + F4 )
αL
+ (k − 4) · Fβ − 4 · (2 · (E3 + E4 ) + (k − 4) · Eγ ))
βL
=
· (E0 + 2 · (E3 + E4 )
αL
1
+ (k − 4) · Eγ − · (2 · (F1 + F4 ) + (k − 4) · Fβ ))
4
(23)

Vβ =
Vγ

whereby α, β, γ are the Catmull-Clark weights for a new vertex
with valence k and αL , βL , γL are the Catmull-Clark weights for
the limit point of a vertex with valence k [Catmull and Clark 1978;
Zorin and Schröder 1999]. Note that the weights of the vertex rules
Vα , Vβ , Vγ are always positive. The minus in their equations

•

25:13

results from the derivation and the negative terms disappear when
inserting all terms.
For the limit point and normal rule, we again make a distinction
between regular and irregular vertices.

Limit rules for regular vertices. The limit point of a regular vertex Pi,j (see Figure 20) is the limit point of a local bicubic,
nonuniform B-spline surface defined by the two knot interval vectors of Pi,j and its 1-neighborhood Px,y , x = i − 1, . . . , i + 1,
y = j − 1, . . . , j + 1. This is true because the subdivided points in
the 1-neighborhood of Pi,j are built by the subdivision rules of the
local bicubic, nonuniform B-spline surface. Therefore, for a regular
vertex Pi,j with its 1-neighborhood Px,y , x = i − 1, . . . , i + 1, y =
j − 1, . . . , j + 1 and its knot interval vectors {ei−2 , ei−1 , ei , ei+1 },
{dj −2 , dj −1 , dj , dj +1 }, we can get the limit point and limit normal
via the procedures
limitPoint(Pi,j , Pi−1,j −1 , . . . , Pi+1,j +1 , dj −2 , . . . , dj +1 ,
ei−2 , . . . , ei+1 ) and
limitNormal(Pi,j , Pi−1,j −1 , . . . , Pi+1,j +1 , dj −2 , . . . , dj +1 ,
ei−2 , . . . , ei+1 )
of Section 2.1 (Eqs. (5) and (7)).

Limit rules for irregular vertices. At the irregular vertex, the
limit point is defined by the Catmull-Clark limit point rule because
the subdivided points in the 1-neighborhood of the irregular vertex are generated by the Catmull-Clark subdivision rules. Hence,
we get the limit point of an irregular vertex P0 with valence k
	
g
g
by L = αL P0 + ki=1 βL · Pib + γL · Pi , where Pi are the verb
tices of the incident edges to P0 , Pi are the vertices in the 1-ring
of P0 , nonincident to P0 , and αL , βL , γL are the weights for the
limit point of a Catmull-Clark point with valence k. The limit surface normals can also be computed via the limit normal rule of
	k
g
T1
· Pib + γiT 1 · Pi ,
the Catmull-Clark surface by T1 =
i=1 βi
	k
g
T2
T2 =
· Pib + γiT 2 · Pi , whereby βiT 1 , βiT 2 , γiT 1 , γiT 2
i=1 βi
are the Catmull-Clark weights for the two limit tangents, and
N = T1 × T2 .
It is easy to verify that the DINUS rules (see Section 2.3.2) reduce
to the Catmull-Clark rules in the case of uniform knot intervals. If we
use NURBS-like knot intervals and regular topology, the DINUS
rules (see Section 2.3.2) are identical to the NURBS subdivision
rules and we obtain a NURBS surface.
2.3.3 Knot Interval Assignment. We need to assign knot intervals to the subdivided and new edges. In comparison to the initial
SINU subdivision step, we use a ternary subdivision and divide the
knot intervals into equal thirds instead of equal halves. The resulting
knot intervals are depicted in Figure 26. After the first subdivision
step, the knot intervals of a vertex do not change and stay constant
in further subdivision steps.

2.4 Special Features
For DINUS subdivision surfaces, two kinds of special features are
available. Via special feature rules, for example, sharp edges, corner,
and darts can be generated in the same way as proposed for CatmullClark subdivision surfaces [Hoppe et al. 1994; Biermann et al.
2001]. Because arbitrary knot intervals are possible with DINUS,
we can change the appearance of the sharp edges in detail (see
Figure 27). Further on, special features can be obtained by zero
knot intervals as proposed in Sederberg et al. [1998].
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

•

25:14

K. Müller et al.
DINUS
P9

P8

P5

P2k−1

P2k

P2

P1

P6

P7

P0

CC

TB

P3

P4

P7

P6

T B = BT
P9

P8

P0

P5

P2k−1

P2k

P1

P2

P3

BT

P4
CC

DINUS

Fig. 23. Comparison of the weights for TB and BT provides the new edge rule for DINUS. Top: A DINUS subdivision step followed by a Catmull-Clark step
provides the edge point TB. The yellow points are the yet unknown new edge and vertex points of the DINUS. Bottom: A Catmull-Clark subdivision followed
by a DINUS subdivision step. All rules are known and point BT can be expressed by weights of points P0 , . . . , P2k of the base mesh.

Fig. 24. DINUS subdivision: Masks for a new face point (left), new edge point (middle), and new vertex point (right) around an irregular vertex.

d
d
avV
V
avV

avV
e

f
g

a

avF

i
i
r

avF

avF
a

h

F

b

avF

c l

a
a

b

c
k

b

o

c

d m

avF

i+ j
b+o 2 b+o
2
2
i+ j
2

o

a

a

d

d

2a+c
a+2c
3
3
b+2d
b+2d
b+2d
3
3
3
a+2c
2a+c
3
3
2b+d
2b+d
2b+d
3
3
3
a+2c
2a+c
3
3

b

b

c
c
c

b

DINUS Subdivision

j

Fig. 26. DINUS knot interval assignment.

j
s

DINUS Subdivision
Fig. 25. After the initial SINUS step we continue with DINUS subdivision.
The knot interval assignment is done as demonstrated in Figure 26.
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

3.

SURFACE PROPERTIES

Considering the structure of the DINUS surface after the initial
SINU step, it is easy to prove that the subdivided points converge
to their calculated limit points via the limit point rules. Because

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces

•

25:15

Fig. 27. Some simple DINUS special features: sharp edge via special feature rule, sharp edge via zero knot intervals, conical, sharp edges with nonuniform
knot intervals on the edge and at the end of the edge.

d

a

d

c

a

c

b

b

(depth 0)

(depth 1)

d

a

d

c

a

b
(depth 2)

d

c

a

b
(depth 3)

c

b
(depth 4)

Fig. 28. Augmented face in depth n = 0, 1, 2, 3, 4. Depth 2 is the first refinement level where we obtain uniform knot interval vectors (green circles, filled
with yellow). During further subdivision steps, the number of uniform knot interval vectors increases and the sequence of resulting B-spline patches (marked
in yellow) converges towards the border of the augmented face.

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:16

•

K. Müller et al.

(a)

(b)

(c)

(d)

Fig. 29. Local surface modifications of the uniform surface (a) due to creases (b) and augmented faces ((c) and (d)). Part (c) shows the knot interval values
used. Reflection lines illustrate the surface smoothness and its stretch and contract under nonuniform knot intervals and augmented faces.

Fig. 30. Highly curved polygonal base mesh, modified by several knot interval changes (left), and application of creases (right).

locally we deal with a bicubic, nonuniform B-spline surface in a
regular vertex, and with a Catmull-Clark surface in an irregular
vertex, respectively, we can see that their 1-neighborhood is built
by the same rules, which also indicates that we get the calculated
limit point by infinite subdivision. Due to this fact, we can also use
the limit normal rules for the bicubic, nonuniform B-spline surface
in the case of a regular vertex and the Catmull-Clark normal rules
for the irregular vertices.
Using an arbitrary topology with uniform knot intervals results
in a Catmull-Clark surface. Therefore, in this case, we get the same
continuity as Catmull-Clark surfaces, that is, C 1 continuity at the
irregular points and C 2 continuity elsewhere. In particular, the surface properties around an irregular point are the same as for the
Catmull-Clark surface. For a detailed analysis of this behavior, we
refer the reader to Karciauskas et al. [2004]. An approach for surface
tuning at an irregular point during ternary subdivision is described
in Ni et al. [2007].
In the case we have a mesh with a regular topolgy and regular
(i.e., NURBS-like) knot intervals, we obtain a bicubic, nonuniform B-spline surface with our subdivision scheme. With a bicubic,
nonuniform B-spline configuration, we have C 2 continuity for our
surface in this case.

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

Fig. 31. Spikes created with augmented faces (vertical knot intervals 5,
left), with control points moved to a single point (middle), and with triangular
faces (right).

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces

•

25:17

Fig. 32. Torus mesh with uniform knot intervals (left image), and with knot intervals changed on a row and on a column.

Fig. 33. By face extrusion irregular vertices are introduced, and the knot intervals on the same edges are changed like above. Note that this introduces
augmented faces, which are neither available with NURBS nor with Catmull-Clark.

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:18

•

K. Müller et al.

Fig. 34. Merging of five NURBS patches with different knot intervals on opposing edges. The assigned knot intervals are written on rows and columns next
to the transition region labeled in yellow.

The DINUS surface offers the possibility to use arbitrary knot
intervals with the special case of augmented faces. If we have an
augmented face, we can observe that the pattern of the knot interval
vectors in the interior of the augmented face with increasing subdivision depth is similar to the ones of NURSS and ESubs [Sederberg
et al. 2003] and [Müller et al. 2006]; see Figure 28. In the limit,
we will get uniform knot interval vectors in the interior of the augmented face, which implies that we get a uniform B-spline surface
in the interior of the augmented face. A proof of surface continuity
at the border of augmented faces is more involved and part of our
further work.
To visually assess surface behavior under knot interval modifications, we have generated reflection lines for a set of different
knot interval and crease settings. Figure 29 shows a bottle model
which has large faces and consequently deforms largely under knot
interval changes. Note especially the behavior of the surface at augmented faces. Under these conditions, the surface changes vastly in
some areas but smoothness is maintained.

4.

SURFACE EXAMPLES

The DINUS surface is very flexible in creating and reusing model
data as it combines polygonal and NURBS modeling. Starting with
a cube or a plane, complex models can be generated by a sequence
of polygonal modeling operations, like extrude or split face. Any
polygonal mesh can be taken as input, similar to Catmull-Clark.
Using just uniform knot intervals, the resulting surface surface are
identical to the Catmull-Clark surface. Figure 30 shows a polygonal mesh with uniform knot intervals originating from a polygonal
model. With editing the knot intervals on edges, local model modifications like stretch and contract can be achieved. Especially, it
is possible to set different knot intervals on opposing edges of a
face.
In Figure 31, we show the effect of augmented faces, control
points bunched together, and triangular faces in comparison. The
modeler can choose among these possibilities and set the knot intervals in the case of augmented faces in order to achieve the desired
appearance. As described in Section 2.4, special feature rules from
Catmull-Clark can be transferred to the DINUS surface. In this
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

way, sharp edges are available by setting knot intervals on edges
to zero or by using a crease rule. Figure 27 shows a comparison
of both alternatives. Note that the special feature rules fully interoperate with different knot intervals and irregular points so that
no side conditions on knot intervals or special features have to be
maintained.
Using a quadrangle mesh with grid topology and the same knot
intervals on rows and columns respectively, DINUS surface are
identical to bicubic NURBS surfaces and all methods from NURBS
design are available. Figure 32 shows a NURBS torus mesh with
uniform knot intervals and knot intervals changed on a row and on
a column, which are all of the possibilities available with NURBS.
With DINUS irregular vertices can be introduced like with the
Catmull-Clark scheme. In Figure 33, several valence 5 vertices
occur incident to the extruded face. Changing knot intervals on the
same edges like before but after the extrusion, introduces augmented
faces. In such a modeling sequence, augmented faces occur easily
and are hard to avoid.
As further application, NURBS surfaces with the same number
of control points but different knot intervals can be merged into one
surface with augmented faces. Figure 34 shows an example where
five NURBS patches with different knot intervals on opposing edges
are merged together. The resulting DINUS surface has augmented
faces along the seams.
Limit points and limit point rules are necessary for several problems in modeling and rendering. We want to show
only some representatives. The DINUS surface allows to compute limit points on the surface with exact limit normals.
Figure 35 gives a side-by-side comparison of a spiky teapot model
rendered without and with limit points/limit normals. Note the
model’s appearance is shrinking with control points alone, and
shading artifacts occur from normals computed on the polygonal
mesh.
The availability of limit normals allows for the computation of
high-quality offset surface meshes from a DINUS surface. Although
it might not be possible to represent the offset surface exactly with
bicubic surface patches, a faithful approximation can be obtained
with the resulting offset mesh. In Figure 36 an offset mesh is shown
which has been computed for the cactus model with complete variety of surface modifications.

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces

•

25:19

Fig. 35. Spiky teapot model at depths 0, 1 (after SINU step), 2 (after one DINU step). The images in the left column use control points, the images in the
right column use limit points and limit normals.

Fig. 36. Cactus model with uniform knot intervals (left) and with a variety of augmented faces and sharp edges (middle). Mesh offsets can be generated using
the exact limit normals (right).

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

25:20

•

K. Müller et al.

Fig. 37. Left: Catmull-Clark surface with sharp edges (end of the left limb). Right: In a next step, the green edges and the sharp edges are set to one, the red
edges get the denoted values. Using the ESubs rules, the resulting surface shows some shape enhancements.

Fig. 38. Comparison of an ESubs surface (left) and a DINUS surface (right): Augmented faces have a larger effect using ESubs rules, however, the resulting
DINUS surface has a smoother appearance.

5.

CONCLUSION

In this article, we present a nonuniform subdivision surface with
limit point and limit normal rules. Both Catmull-Clark and bicubic,
nonuniform B-spline surfaces can be represented with this surface
type. Moreover, the flexibility of arbitrary knot intervals on the edges
allows further modeling options, especially in combination with the
Catmull-Clark special feature rules. After the first subdivision step,
the scheme is stationary and amenable to analysis techniques for
stationary schemes.
Our scheme combines two subdivision methods: Firstly, the base
mesh is subdivided using a nonuniform binary method to get a
quadrangle mesh and to average the knot intervals on the incident
edges around an irregular vertex. The further subdivision steps are
done with our ternary subdivision scheme. Both methods determine
for each control point local knot interval vectors. These local knot
interval vectors are used to compute local Bézier control points
around the vertices. Via these Bézier control points, the new face,
ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

edge and vertex points can be calculated. The ternary subdivision
makes our scheme stationary after the first subdivision step. It also
makes it possible that we can have limit point and normal rules even
with augmented faces.
This flexibility gives us the freedom to put several NURBS
patches together with the constraint that they have an equal number of control points on the border curve. It is part of our further
work to deal with an unequal number of control points at the border
curve.
In comparison to NURSS [Sederberg et al. 1998], the DINUS
surfaces offer limit point and limit normal rules and are stationary,
even with augmented faces. NURCC [Sederberg et al. 2003] are
stationary, and they have the same rules as NURSS, but they lost
the flexibility to use augmented faces. Limit point and limit normal rules are also not presented. T-splines [Sederberg et al. 2003,
2004] are a combination of NURBS and Catmull-Clark with a main
focus on NURBS as a parametric surface. They cannot deal with
augmented faces but offer nice possibilities to put NURBS patches

DINUS: Double Insertion, Nonuniform, Stationary Subdivision Surfaces
with a different number of control points at the border curve together. ESubs [Müller et al. 2006] are related to DINUS, they offer
already limit point rules but are nonstationary. Because of the binary and nonstationary scheme, they cannot provide limit normal
rules.
REFERENCES
BIERMANN, H., MARTIN, I. M., ZORIN, D., AND BERNARDINI, F. 2001.
Sharp features on multiresolution subdivision surfaces. In Proceedings
of the Pacific Graphics Conference. 61–77.
CASHMAN, T. J., DODGSON, N. A., AND SABIN, M. A. 2007. Non-uniform
B-spline subdivision using refine and smooth. In IMA Conference on the
Mathematics of Surfaces, R. R. Martin, M. A. Sabin, and J. R. Winkler,
Eds. Lecture Notes in Computer Science, vol. 4647. Springer, 121–137.
CASHMAN, T. J., DODGSON, N. A., AND SABIN, M. A. 2009. A symmetric,
non-uniform, refine and smooth subdivision algorithm for general degree
B-splines. Comput.-Aided Geom. Des. 26 1, 94–104.
CATMULL, E. AND CLARK, J. 1978.
Recursively generated B-spline
surfaces on arbitrary topological meshes. Comput.-Aided Des. 10,
350–355.
FARIN, G. 2002.
Curves and Surfaces for CAGD, 5th ed. Morgan
Kaufmann Publishers.
HOPPE, H., DEROSE, T., DUCHAMP, T., HALSTEAD, H., JIN, H., MCDONALD, J.,
SCHWEITZER, J., AND STUETZLE, W. 1994. Piecewise smooth surface
reconstruction. In Proceedings of SIGGRAPH Conference. 295–302.
KARCIAUSKAS, K., PETERS, J., AND REIF, U. 2004. Shape characterization
of subdivision surfaces: Case studies. Comput.-Aided Geom. Des. 21, 6,
601–614.

•

25:21

LANE, J. AND RIESENFELD, R. 1980. A theoretical development for the
computer generation and display of piecewise polynomial surfaces. IEEE
Trans. Pattern Anal. Mach. Intell. 2, 1, 35–46.
LOOP, C. 2002.
Smooth ternary subdivision of triangle meshes. In
Proceedings of the Conference on Curves and Surfaces Fitting: SaintMalo. 295–302.
MÜLLER, K., REUSCHE, L., AND FELLNER, D. 2006. Extended subdivision
surfaces: Building a bridge between NURBS and Catmull-Clark surfaces.
ACM Trans. Graph. 25, 2, 268–292.
NI, T., NASRI, A. H., AND PETERS, J. 2007.
Ternary subdivision
for quadrilateral meshes. Comput.-Aided Geom. Des. 24, 6, 361–
370.
SCHAEFER, S. AND GOLDMAN, R. 2009.
Non-uniform subdivision
for B-splines of arbitrary degree. Comput.-Aided Geom. Des. 26, 1,
75–81.
SEDERBERG, T. W., CARDON, D. L., ZHENG, J., AND LYCHE, T. 2004. TSpline simplification and local refinement. In Proceedings of SIGGRAPH
Conference. 276–283.
SEDERBERG, T. W., SEWELL, D., AND SABIN, M. 1998. Non-uniform recursive subdivision surfaces. In Proceedings of SIGGRAPH Conference.
387–394.
SEDERBERG, T. W., ZHENG, J., BAKENOV, A., AND NASRI, A. 2003. TSplines and T-NURCCs. In Proceedings of SIGGRAPH Conference.
477–484.
ZORIN, D. AND SCHRÖDER, P. 1999. Subdivision for modeling and animation. In ACM SIGGRAPH 1999 Course Notes.
Received November 2008; revised February 2010; accepted April 2010

ACM Transactions on Graphics, Vol. 29, No. 3, Article 25, Publication date: June 2010.

Surface Interrogation Methods for Haptic Rendering of Virtual Objects
Anusha Sridaran, Dianne Hansford, Kanav Kahol, Sethuraman Panchanathan
School of Computing and Informatics
Arizona State University, Tempe, Arizona
Email: {Anusha.Sridaran, Dianne.Hansford, kanav, panch}@asu.edu
Abstract
The process which enables virtual objects to
mimic their real world counterparts is known as
realistic rendering in haptics. Realistic sensations
could relate to any spatial feature like shape or
texture. We have proposed a system here that aims at
utilizing the shape information of a surface effectively
to aid in object recognition through a haptic interface.
This paper describes some surface interrogation
techniques namely isophotes, contours and Gaussian
curvature to assist in haptic rendering by drawing the
user’s attention to certain features on a surface that
cannot be perceived by realistic means. The
effectiveness of these tools, based on their behavior in
an external environment, has also been compared. The
main goal of this paper is to demonstrate that
perception of virtual surfaces can be enhanced by
providing haptic feedbacks parameterized according
to geometric features identified by surface
interrogation.

1. Introduction
Surface interrogation is defined as the analysis of
surfaces with the intent of detecting shape
imperfections and features [1, 3, 9]. It has its
foundation in the CAD/CAM industry where it is
desired to put models of high quality into production
[2].
In the context of haptic rendering of surfaces, we
have defined a parameterization of a surface as its
classification into regions of identical characteristics,
such as geometric features. Surface interrogation
techniques enable such a parameterization which can
be utilized for generating homogenous haptic
sensations for regions with identical characteristics. In
other words, a “perceptual parameterization” of a
surface from a haptics perspective is defined. By
perceptual parameterization we mean that regions of

Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)
0-7695-2738-8/07 $20.00 © 2007

identical surface characteristics will be perceived
haptically in a similar manner by a user. Surface
segmentation algorithms such as the watershed
method of Mangan and Whitaker [11] and range
image classification [13] partition a surface into
meaningful patches based on the curvature.
The system we propose aims at the integration of
interrogation techniques with haptic-exploration to
communicate the local and global shape of an object in
the virtual world. Some such tools are isophotes,
reflection-lines, crest-lines, focal surfaces and
curvature characteristics of a surface [1].
The interrogation techniques presented here can
be classified either into an extrinsic or an intrinsic
category. Tools which are independent of the surface
orientation in three-dimensional (3D) space are
intrinsic interrogation tools, while those which are
dependent on the surface orientation are extrinsic
tools. Further study and experimentation also indicate,
that in our implementation of this proposed system,
the intrinsic tool namely the Gaussian curvature
provided a better channel for communicating shape
information haptically than the extrinsic tools used
within the context of the single point contact namely
the Phantom haptic interface. We have presented here
three surface interrogation algorithms that were used
for rendering virtual surfaces in a haptic environment
in an effective manner. This is followed by a
description of the experiment conducted and the
results and discussions based on the experiment.

2. Surface Interrogation Algorithms
We define a 3D surface in its parametric form

[

]T

given by, x = x(u, v ) = x (u , v), y (u, v ), z (u , v)
as a map of a real plane [9]. In our experiments, we
will
present
the
surface
over
a
sub-

[ ]T œ

[u 0 , u1 ] × [v0 , v1 ] . The
surface normal at (u , v) is n(u , v) , and it is assumed

domain u = u, v
to be unit length.

For the purpose of rendering, the surface is
evaluated at points on a uniform grid in the subdomain. A triangulation is formed from the grid
structure, and the surface points are the vertices of the
triangles.

Section 1, and thus we classify contours as an extrinsic
tool for surface interrogation.
A simple representation of a contour of a surface
is

z (u , v) = c ,

2.1 Isophotes
An infinite point light source is represented by a
unit length “light vector” l . The locus of points on a
surface whose normals form a constant angle α with
the light vector, are called isophotes.

where c is a constant.

n(u , v) ⋅ l = c ,
where c = cos (α). Hence, they can be called
equipotent “lines” on a surface or patterns of equal
light intensity [1]. Isophotes are an extrinsic surface
interrogation tool. Fig. 1 illustrates isophotes on a
sinusoidal surface.

Fig. 2. Contours on a parametric surface of a
cone

[

x = x(u, v) = u , v, (u 2 + v 2 ) / 5

Fig. 1. Isophotes on a sinusoidal surface

x = x(u, v ) = [u , v, sin u ]

T

[

]T

Light vector l = 0,0,1 ; c=1.
In our experiments, we manually chose a light
direction for each surface so as to accentuate the
defining features of the surface. It can be inferred that
every point on the surface would belong to an “αangle class” of isophote. We chose α=0, and thus the
isophote is formed by a set of points whose normal
make identical angles with the light vector within a
specified tolerance.

2.2 Contours
Contours can be used to represent surface
topography. Contour lines are formed by a set of
points on a surface that have an equal elevation.
Families of contour lines together can convey shape
information. When defined with respect to a global
coordinate system rather than a local coordinate
system, the contour pattern formed on a surface is
dependent on the surface’s orientation, as discussed in

Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)
0-7695-2738-8/07 $20.00 © 2007

]

T

The number of contour levels required to best
describe the surface was determined on a trial and
error basis for all the test-surfaces used in our system.
The contour lines were thus formed by surface points
on those levels within small depth-tolerances. The
number of levels and tolerance parameters were
however also made dynamic and could be varied
during run-time to view a different set of contour lines
on the surface.
Each of the vertices that belong to the contour and
isophote family was rendered as a small sphere on the
surface with a gravity-well. Gravity-wells are used to
attract the haptic device to a point location when the
device is within the point’s radius of influence [10]. In
our case, the probe gets attracted to the center of the
sphere. A user navigating over the surface would
hence be attracted towards these patterns formed on
the surface. Our hypothesis is that such an attraction
can convey information about the overall shape of the
surface to the user as these isolines formed on the
surface are dependent on the surface shape.

2.3 Curvature
Another important characterization of surfaces is
curvature, which gives a measure of deviation from
flatness. We used Gaussian curvature, κ , for haptic
exploration of virtual objects. Gaussian curvature is an
intrinsic characteristic of a surface.

At a point x(u , v) on the surface, a normal
section is the intersection of the surface with a plane
through the point and containing n(u , v) . In each
normal section, we may calculate the curvature of the
planar curve at x(u , v) . Over all normal sections, the
maximum and minimum curvature values are the
principle curvatures, k1 and k2, respectively. Gaussian
curvature is the product of the principal curvatures,
κ = k1 k2. Equivalently,

κ = ( LN − M 2 ) /( EG − F 2 )
where E, F and G are the coefficients of the first
fundamental form. L, M and N are the coefficients of
the second fundamental form [9]. They are defined as

E = E (u , v) = x u .x u
F = F (u , v) = x u .x v
G = G (u, v ) = x v .x v

L = L(u , v ) = n ⋅ x uu
M = M (u, v ) = n ⋅ x uv
N = N (u , v ) = n ⋅ x vv

where x u and x v are the first partial derivatives of
the surface with respect to u and v,
respectively. x uu , x uv and x vv are the second and
mixed partial derivatives of the surface [9]. We
assume x(u , v) is twice differentiable.
The sign of κ can be used to categorize regions
of a surface as parabolic ( κ = 0), elliptic ( κ > 0) and
hyperbolic ( κ < 0). We further this categorization by
separating planes from the other parabolic surfaces.
In our system, each region is associated with a
different haptic feedback. For instance, a planar region
is rendered as a perfectly smooth surface with
negligible friction and damping characteristics. Static
and dynamic frictions are referred to as stick-slip
friction. This form of friction is used to oppose lateral
motion along the surface. The moment a contact is
made with the surface, the static friction plays the
dominant role in opposing motion along the surface.
This state is known as stick as there is no relative
motion. The moment the user applies enough force to
overcome the resistance and enable movement, the
state changes to slip. In this state, dynamic friction is
dominant and this force resists relative motion on the
surface [10]. A region of positive curvature is rendered
with high static friction properties and hence makes
those regions of a surface highly sticky. A region of
negative curvature is rendered with high static and
dynamic friction hence makes navigation across those
domains difficult due to high stick and slip conditions
making the surface rough. A parabolic region is one

Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)
0-7695-2738-8/07 $20.00 © 2007

which is not flat but still has zero Gaussian curvature.
In order to distinguish it from planar regions it is
rendered with stiffness parameters which are identical
to plane surfaces along with damping constraints.
Ideally, damping effects are used to reduce the
vibrations caused during the opposition offered to the
motion. The damping effects are proportional to the
velocity of motion [10].
The rendering process based on the above
parameterization would make exploration with a
haptic interface less constrained on flat regions unlike
the regions associated with non-zero Gaussian
curvatures due to the haptic material constraints.
Ideally, such a perceptual parameterization of a
surface is based on the fact that a person would find it
easier to navigate across a route which is flat than a
curved one.
The design of our experiments is based on the fact
that a user would have to explore a surface
completely, before gathering its shape information.
Such an exploration using a single point device in an
exocentric frame may not be sufficient to provide the
adequate feedbacks necessary to recognize the surface
in future. The process can however be made more
flexible by changing the feedbacks associated with a
surface according to its intrinsic properties such as
Gaussian curvature.
A paraboloid and a hyperboloid could feel the
same when felt using a single point contact device like
the Sensable’s Phantom. This is because the Phantom
provides an exocentric reference frame to its user
which in haptics has been shown to limit shape
perception [6]. The distinction is made sharper by
associating them with differential haptic parameters
instead. In our system we make use of analytical
surfaces which are represented over a sub-domain.
Another interesting aspect to be noted here is that
small variations in the coupled effects of the input
domain definition and parametric coefficients defining
a surface could render the look and feel of two
different surfaces as highly similar. An ellipsoid and a
paraboloid visualized in Fig. 3(a) and 3(b) when
rendered over a particular domain as in Fig. 4(a) and
4(b) they might appear and feel identical.

Fig. 3(a). Ellipsoid

Fig. 3(b). Paraboloid

(Fig. 3(a) and 3(b) courtesy of
wolfram.mathworld.com)

Fig. 4(a). Ellipsoid evaluated over a sub-domain

Fig. 4(b). Paraboloid evaluated over a subdomain
During realistic haptic rendering, the surfaces in
Fig. 4(a) and Fig. 4(b) would feel identical when
oriented in the same manner. This can however be
avoided with a haptic parameterization of the surfaces.
The feedback given is based on the relative intrinsic
curvature value at each point on the surface which
would always remain a constant irrespective of the
surface orientation in the haptic workspace or the
variations in the input domain. Moreover, the
perceptual differences between the surfaces are
accentuated by haptic parameterization.

3. Methods
Some observations were made during the
implementation and preliminary testing which could
be put forth for further study and analysis. The system
was developed with the intention of using the
methodology provided by surface interrogation tools
to render virtual objects in an intuitive manner. A
rendered surface was analyzed in four different modes
in the haptic and graphic environment: a normal mode
with no special haptic properties like friction or
damping effects, with isophote details, with contour
details and with intrinsic Gaussian curvature based
haptic feedbacks. The user’s perception of an object
surface tended to vary across each of the modes. The
perception of shape details was found to be minimal in
the case of rendering with extrinsic interrogation tools,
namely isophotes and contours. Perception was higher
for surfaces rendered in a normal mode. Perception
was the best for haptic rendering based the intrinsic
interrogation tool.
Hence, an experiment was designed to test our
hypothesis of haptic perception of surfaces based on
curvature characteristics alone. The goal of the
experiment was to determine whether a user
undergoing the test is able to correctly identify a

Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)
0-7695-2738-8/07 $20.00 © 2007

surface rendered via haptic rendering algorithms. The
surface rendered was chosen randomly from our
database of surfaces. The subject was made to become
familiar with all our surfaces during the training phase
before the start of testing.
Also, the testing and training phases were carriedout over two different modes of rendering. The first
mode was a normal mode of rendering where no
specialized haptic constraints were rendered for the
surface during the haptic exploration process. The
second mode of rendering involves specifications of
haptic properties over the surface based on Gaussian
curvature attributes. Our goal was to firstly determine
the accuracy achieved in the surface recognition by the
users in the two different rendering modes for the
surfaces in our database, which was later followed by
a comparison of user’s perception in the two haptic
modes.
For the experiment, we made use of regions of
surfaces defined over domains rendered in a manner
that their complete shape was not revealed to the user.
Simple models that were generated and fed into the
system were,
Planar Surface: plane, Қ = 0
Parabolic Surface: Cylinder and Cone: Қ = 0.
Elliptic Surface: Paraboloid, Ellipsoid , Sphere: Қ > 0
Hyperbolic Surface: Elliptic Hyperboloid, Simplesaddle, Monkey–saddle: Қ < 0.
After choosing an appropriate sub-domain for all
the models, the tessellation details namely the vertex
and the polygonal representation of each surface
model were extracted into a file for rendering purpose.
The Gaussian curvature at each vertex was precomputed. The specific surface coefficients were
chosen in order to have reduced variations in the
visual appearance of the models while rendering. This
was because our motive was to determine if haptic
parameterization of surfaces based on their
characteristics enables better perception than a
conventional haptic rendering algorithm. The surfaces
rendered to the user were haptically parameterized
according to their Gaussian curvature in the rendering
environment. Each of these models has a homogenous
Gaussian curvature sign. The subjects were guided to
the center of the surface before the start of exploration
with the Phantom and a haptic snap effect was
provided for the surfaces to guide the user to stay in
the vicinity of the surface throughout. This reduces the
exploration costs that would be incurred when the
user’s uncertainty about an object being explored is
larger [12].

3.1 Experiment

The experiment was conducted with eight sighted
and two blind individuals. The details that were
collected from the blind individuals were their age
group, visual abilities and the age at which they
ascertained their present visual abilities. Individuals
who were sighted or had partial visual capabilities
were blind-folded in order to maintain consistency
among all the participants.
A set of eight surfaces was used for an experiment
with one user. For each training session, the user was
presented with only four of those surfaces with one
chosen from each of the Gaussian curvature categories
listed. Sufficient time (two minutes) was given to the
user to explore the surfaces and become familiar with
them. In the testing session, one surface out of the
four was randomly rendered and the user was asked to
identify the surface. This process was repeated for
each of the four surfaces.
There were four such training and testing phases
where the user was presented with the same set of four
surfaces. This was carried out with the intention of
determining whether the surface identification
accuracy improved with more learning. This is a
standard methodology used in psychology for
measuring learning of new stimuli [14].
The fifth phase of the experiment involved
random generation of a surface from the set of eight
surfaces that were initially chosen for that experiment.
The first task given to the user was to determine
whether the surface rendered was an old surface (one
of the four) or a new surface. If identified as an old
surface, the user was further requested to recognize
which of the four old surfaces was rendered. The
process was repeated eight times for all the surfaces
chosen for the experiment. Oldness ratings help
estimate a user’s ability to remember past felt stimulus
and transfer the knowledge to other domains like
object recognition in this case. Intuitively a higher
oldness rating for a method of presentation suggests
better discriminability of stimuli and hence higher
efficacy of perception and memory.
The entire experiment took place twice, once for
algorithm A which involved haptic rendering of
surfaces without any perceptual parameterizations and
once for algorithm B which involved perceptual
parameterization of surfaces based on their curvatures.

4. Results and Discussion
Fig. 5 shows learning rates. As the results
indicate, algorithm A did not lead to effective learning
of stimuli and recognizing these stimuli. On the other
hand, perceptual parameterization of surfaces led to a
substantial increase in recognition accuracies and
learning rates. The results clearly suggest the

Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)
0-7695-2738-8/07 $20.00 © 2007

superiority of surface interrogation methods in
improving haptic rendering of curvatures.
Fig. 6 shows the oldness ratings. As mentioned
before, oldness ratings are an indicator of how well
users can transfer previous experiences into new
contexts and discriminate between previous
experiences and new ones.

Algorithm A

Algorithm B

Fig. 5. Learning rates and recognition accuracy
It can be inferred from Fig. 6 that perceptual
parameterization leads to an increase in oldness
ratings. This suggests superiority in providing better
haptic perception of virtual surfaces.

Algorithm A

Algorithm B

Fig. 6. Oldness ratings
The extrinsic features, namely the isophotes and
contours, when rendered as gravity-wells of chosen
radius proportional to the surface mesh, were found to
be obtrusive during surface exploration. In the case of
more complex models, the contours and isophotes
were perceived as sporadic points over the surface
rather than patterns indicating shape. Hence the
system did not work very well with a haptic device
having a single point contact but it would be an
interesting experience to try making them work with
multi-point contact rendering.

5. Conclusion
In this paper, we presented an approach for
coupling surface interrogation methods with haptic
rendering for
increased
perception.
Haptic
identification is made more efficient with homogenous
sensations over regions of significant contact area
rather than characteristic lines on the surface such as
isophotes or contours. Thus we coined the term
perceptual parameterization for associating haptic
feedback to surface characteristics over regions on a
surface. Gaussian curvature proved to be an effective
intrinsic tool in a haptic environment.
There is limited ability of the haptic modality to
perceive shape element through a single point contact
device as the Phantom. Psychology of haptics
indicates the preference of human beings to explore
objects in an egocentric reference frame [6]. The
presented haptic rendering system of using isophotes
and contours as interrogation tools can be enhanced
further by inducing a dual contact mode for haptic
exploration. The first contact point can be used as a
reference and the second point of contact can be used
for exploring the extrinsic features on the surface. Our
hypothesis is that perception will increase when a user
is provided with a reference frame during exploration.
An indication of improved performance in surface
recognition through such a system can be very
beneficial and lay the foundation for experimenting
with other interrogation features like crest-lines for
shape exploration in haptics modality.
As mentioned in Section 1, surface interrogation
techniques are used in the car design industry where
the physical prototypes need to be tested before being
put into production. Incorporation of the sense of
touch with the interrogation process as in the current
system shows an incredible promise in adding a
greater level of certainty for product validation.

Acknowledgements
This research was supported by the National Science
Foundation (NSF), SGER: Incorporation of a
psychological basis of haptics in the design of
assistive haptic user interfaces, Grant No 0554698.

References
[1] H.Hagen, S.Hahmann, T. Schreiber, Y.Nakajima,
B.Wordenweber and P.Hollemann-Grundstedt., ‘’Surface
Interrogation Algorithms’’, IEEE, Computer Graphics and
Applications, Sep 1992, vol. 12, pp. 53-60.

Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)
0-7695-2738-8/07 $20.00 © 2007

[2] S.Hahmann, “Visualization techniques for surface
analysis’’, published in Visualization techniques for surface
analysis, in C.Bajaj (ed): Advanced Visualization
Techniques, John Wiley, (1999).
[3] N.M. Patrikalakis and T.Maekawa, "Shape Interrogation
for Computer Aided Design and Manufacturing", Structural
and Multidisciplinary Optimization Springer-Verlag, Berlin,
Heidelberg, New York, December 2002, vol. 2.
[4] W.R.Provancher, M.R.Cutkosky, K.J.Kuchenbecker and
G.Niemeyer, “Contact Location Display for Haptic
Perception of Curvature and Object Motion’’, International
Journal of Robotics Research, Sep 2005, vol. 24, pp. 691702.
[5] V.S.Chib, J.S.Patton, K.M.Lynch and F.A.Mussa-Ivaldi,
‘‘Effect of Stiffness and curvature in Haptic Identification of
Surfaces’’, Haptic Interface for Virtual Environment and
Teleoperator Systems, WHC, First-Joint Eurohaptics
Conferences and Symposium, , March 2005, pp. 126-131.
[6] K.Kahol, “Distal Object Perception through Haptic user
Interfaces”, PhD Dissertation, Arizona State University,
May 2006.
[7] H. Theisel,‘‘On geometric continuity of isophotes’’,
Proceedings of Chamonix 1996, A. Le Mehaute, C. Rabut,
and L. L. Schumaker (eds.), Vanderbilt University Press,
Nashville, TN, 1997, pp. 1-8.
[8] H.Theisel, ‘‘Are isophotes and reflection lines the
same?’’, Computer aided geometric design, 2001,
vol. 18, pp. 711-722 (9 ref.).
[9] G.Farin, ‘‘Curves and Surfaces for CAGD: A Practical
Guide, 5th edition’’, published by Morgan-Kaufmann, 2002.
[10] ‘‘3D TouchTM SDK OpenHapticsTM TOOLKIT
Version’’, Programmer’s Guide, Sensable Technologies.
[11] A.P.Mangan and R.T.Whitaker, “Partitioning 3D
Surface Meshes Using Watershed Segmentation”, IEEE
Transactions on Visualization and Computer Graphics,
1999, vol. 5, pp. 308-21.
[12] S.Caselli, C.Magnanini, F.Zanichelli and E.Caraffi,
“Efficient exploration and recognition of complex objects
based on haptic perception”, Robotics and Automation,
Proceedings, IEEE International Conference, MN, April
1996, vol. 4, pp. 3508–13.
[13] J.Bohm and C.Brenner, “Curvature based range image
classification for object recognition”, Proceedings of SPIE The International Society for Optical Engineering, 2000,
vol. 4197, p 211-220.
[14] S.R.Zaki and D.Homa, “Concepts and transformational
knowledge”, Cognitive Psychology, 1999, vol. 39, pp. 69115.

Computing 79, 211–223 (2007)
DOI 10.1007/s00607-006-0199-6
Printed in The Netherlands

Anamorphic 3D geometry
D. Hansford and D. Collins, Tempe, AZ
Received January 13, 2006; revised April 17, 2006
Published online: March 7, 2007
© Springer-Verlag 2007
Abstract
An anamorphic image appears distorted from all but a few viewpoints. They have been studied by artists
and architects since the early ﬁfteenth century. Computer graphics opens the door to anamorphic 3D
geometry. We are not bound by physical reality nor a static canvas. Here we describe a simple method
for achieving anamorphoses of 3D objects by utilizing a variation of a simple projective map that is
well-known in the computer graphics literature. The novelty of this work is the creation of anamorphic
3D digital models, resulting in a tool for artists and architects.
AMS Subject Classiﬁcations: 68U07, 68U05, 51N15.
Keywords: Anamorphosis, projective map, volume deformation.

1. Introduction
An anamorphic image appears distorted from all but a few viewpoints. The term
comes from Greek ana-, again and morphe-, shape. Figure 1 illustrates an early
example of an anamorph (short for anamorphosis) in the painting “The Ambassadors” by Hans Holbein the Younger (1536). At the feet of the ambassadors is
an unrecognizable object contrasting the rest of the painting which is composed of
clearly and precisely rendered elements. This object is a skull, illustrated in a corrected form in the right part of the ﬁgure. It can be seen by moving close to the wall
at the right side of the picture plane.1
One could argue that anamorphs were ﬁrst constructed in Roman times as “accelerated” and “decelerated” perspective, whereby structures such as columns were
built with non-standard dimensions in order to appear farther or nearer from an
observer than they were in reality. Greek and Roman artists used the technique of
tromp-l’oeil2 (deceive the eye) to make the viewer believe they are seeing something
three-dimensional when in reality the work is only two-dimensional.
1

Kent [13] offers a “true” restoration created using a digital camera and a poster reproduction of the painting. Baltrusaitis [2] dedicates a chapter to this painting.
2 Although the term did not appear until the 17th century.

212

D. Hansford and D. Collins

Fig. 1. “The Ambassadors” by Hans Holbein the Younger was painted in 1536. The ﬁgure ﬂoating in the
foreground of the painting is an anamorphic projection of a skull. The “corrected” image of the skull,
shown on the right, can be seen by moving close to the wall at the right side of the picture plane

The curious effects of anamorphs as they are known today, were ﬁrst understood and
explored by Leonardo Da Vinci who included anamorphic drawings of a child’s head
in his Codex Atlanticus (ca. 1485). The appearance of anamorphs as a consciously
applied technique in the history of art is nearly simultaneous with the restoration
of the study of perspective in the Renaissance period (early 15th century) by artists
and architects such as F. Brunelleschi and L. Alberti [2], [7], [12].
In the seventeenth century, S. de Caus and J.-F. Niceron, most notably, dedicated
themselves to the study of perspective which included anamorphs. Figure 2, created by Niceron (1638), illustrates the method for creating an anamorph. This is an
application of the construzione legittima, a trapezoidal checkerboard, going back to
Alberti and da Vinci. The original image is placed in a regular grid. A base edge for
a trapezoidal grid is selected with the same partition as the corresponding edge in
the regular grid. A ﬁnite horizon line is selected. On this line there are two points
of interest: one (principal or eye point) at which the horizontal lines in the regular
grid converge and one at which one set of diagonal lines converge. This determines
the partition of the trapezoidal grid to which the image can be transferred [2].
The study of perspective, its application and place in mathematics, continued through
the centuries. For example, in the nineteenth century, La Gournerie [14] studied geometric distortions of architectual plans and Staudigl [19] studied the correspondence
of orthographic and perspective projections from special viewpoints.

Anamorphic 3D geometry

213

Fig. 2. Demonstration of the method of creating an anamorph by J.-F. Niceron 1638. See [2]

Anamorphs are categorized into two groups. Optical anamorphs can be seen from a
speciﬁc point of view without any sort of apparatus. (This is the sort we will be concerned with here.) Catoptric or mirrored anamorphs require a mirror of some kind,
often cylindrical or conical. A wealth of information on the various anamorphic
techniques may be found in Kent [13] and Hunt et al. [11]. Noteworthy is Beever
[3], who is known for vivid and captivating anamorphic pavement drawings. We are
all familiar with road markings such as bike symbols or arrows that are drawn to
compensate for forshortening observed by an approaching driver [13].3 Additional
insights into anamorphs may be found in Andersen [1], Baltrusaitis [2], Clarici [6],
Collins [7], Gardner [9], Hunt et al. [11], Kemp [12], Leeman [15], and Walker [21].
Figure 3 illustrates one of Collins’ “real” experiments with anamorphs. A mask
of George Washington was scanned, and then the 3D digital model was deformed
by moving groups of vertices, so as to create an (approximate) anamorph. This
tedious process led the authors to look for an easier way to deﬁne anamorphs for
3D geometry.
3D computer graphics opens new doors to anamorphs. We are not bound by physical reality nor a static canvas. Here we describe a simple method for achieving
anamorphs of 3D objects by utilizing a simple projective map (collineation), wellknown in the computer graphics literature [8], [18], [20], that takes a frustum to
an “orthographic box”. The method presented here is equivalent to the methods
employed by Niceron and his contemporaries. The novelty of this work is the creation of anamorphic 3D digital models, and the realization that a commonly known
map can be used to create anamorphs for 3D digital models. Additionally, we present an analytic tool for artists and architects. We plan to pursue more anamorphic projects with Kreysler and Associates (see Fig. 3), a company that specializes
3 These markings are linearly stretched, and as we see from Fig. 2, an anamorph is a
rational linear operation.

214

D. Hansford and D. Collins

Fig. 3. Anamorph of George Washington. A mask was scanned, and then the 3D digital model was
deformed so as to create an (approximate) anamorphic version, seen on the left from an undistorted
viewpoint. On the right is a side-view of the anamorphic mask. It was created in foam by Kreysler and
Associates, http://www.kreysler.com/projects/George Washington/georgewashington.htm

in architectural facades. In addition, this method is a contribution to the many
volume deformation tools in computer graphics and geometric modeling literature
[4], [10], [17].
The development of anamorphic 3D geometry proceeds as follows. Section 2 introduces elements of the graphics pipeline. We contend that an understanding of this
pipeline facilitates an understanding of the classical method for creating anamorphs.
We observe that a common, well-known element of the pipeline can be used to create
interesting, anamophic deformations of 3D objects. Section 3 derives this element,
a projective map known as a collineation. Section 4 develops and outlines the technique. A demonstration of the method is provided in Sect. 5. In Sect. 6, we present
conclusions and ideas for future work.

2. The graphics pipeline and projective maps
The graphics pipeline consists of several coordinate transformations designed for
optimization of the algorithms applied to a primitive traveling down the pipeline
[20]. The ﬁrst such transformation is to place the geometry in eye coordinates: consider your eye positioned at the origin, looking at your object positioned on the
−z-axis. The next step is to deﬁne a viewing volume around your geometry which
will determine what is displayed. Geometry outside of the viewing volume will be
clipped (eliminated). The projection method that we choose plays a role in the speciﬁcation of this viewing volume.
Orthographic and perspective projections, illustrated in Fig. 4, are the methods
most often used in computer graphics. At the end of the pipeline, the object will be
projected into a view plane in front of your eye. An orthographic projection projects
all vertices in a direction perpendicular to the view plane. A perspective projection

Anamorphic 3D geometry

215

Fig. 4. Left: an orthographic projection. Vertices are projected perpendicular to the view plane. Right:
a perspective projection. Vertices are projected into the view plane through the center of projection,
resulting in foreshortening

Mp

Mo

Fig. 5. With a perspective projection, the transformation from eye to clip coordinates involves two mappings. First Mp maps the frustum to a box sharing the dimensions of the view plane and z-depth of the
frustum. Next this box is mapped to a cube with edge length two, centered at the origin

projects a vertex along a line deﬁned by that vertex and the eye, or center of projection
(cop). Thus the viewing volume takes the form of a box for an orthographic projection and a frustum (truncated pyramid) for a perspective projection.
Clipping against a frustum is more difﬁcult than clipping against a box. Therefore,
a projective map Mp is constructed to map the points in the frustum to a box [5].
This map is special in that “relative” z-depths are preserved,4 but changed so that
an orthographic projection will produce a perspective image. Not only does this
facilitate clipping, but also the z-buffer algorithm for hidden surface removal. The
viewing volume (now a box) is mapped via an afﬁne map Mo to a normalized box
centered at the origin for the purpose of simplify the clipping algorithm. Figure 5
illustrates.

4

A more precise deﬁnition of this statement follows in (2).

216

D. Hansford and D. Collins

y

Θ

h

-z

cop
n
f

Fig. 6. The perspective projection frustum is deﬁned by the parameters θ, n, f, h and the width of the
view (near) plane

3. The projective map: frustum to box
The frustum is illustrated in Fig. 6. The center of projection is at the origin. The
angle θ is called the ﬁeld of view. The distance from the eye to the near (or view)
plane is n and the distance from the eye to the far plane is f .5 The height of the
near plane is denoted by h. The parameters, θ, h, n, are dependent, and they are
related by
h/2
.
n
The width w of the view plane completes the frustum’s deﬁnition.
tan(θ/2) =

(1)

Homogeneous coordinates serve the purpose of expressing afﬁne and projective
maps in a convenient matrix representation [16]. An afﬁne point and corresponding
homogeneous point have coordinates


 
px · w
px
py · w 

and
p̄ = 
p = py 
 pz · w  ,
pz
w
respectively.
Projective maps preserve the cross ratio, cr, of four collinear points, and this fact
may be used to derive the map Mp . We will use the following deﬁnition. Suppose
a, b, c, d ∈ IE 1 , then
cr(a, b, c, d) =

ratio(a, b, d)
,
ratio(a, c, d)

where

ratio(a, b, d) =

vol(a, b)
,
vol(b, d)

and “vol” refers to one-dimensional signed volume [8].
5 Since the eye is placed at the origin, n and f will be referred to as both −z−values and
distances.

Anamorphic 3D geometry

217

To map a point p ∈ IE 3 in the frustum to a point b ∈ IE 3 in the corresponding
orthographic box, we ﬁrst examine the action of the map in the z-coordinate. The
projective map sends the center of projection to inﬁnity, and points in the near and
far planes should remain there, respectively. Thus, pz in the frustum is mapped to
bz in the box by satisfying the following equality:
cr(cop, n, pz , f ) = cr(−∞, n, bz , f ).

(2)

As illustrated in Fig. 7, determining the x- and y-coordinates is simply a matter
of observing that the point must live on the line perpendicular to the near plane,
through the point of projection. Employing the rule of similar triangles, the corresponding afﬁne point is



px n/pz
.
py n/pz
b=
n + f − f n/pz

(3)

The left most graph in Fig. 8 illustrates the action of this map in the z-coordinate.
Points on the near and far planes remain in their respective planes, although the
x- and y-values are scaled in the far plane. In fact, the scaling in x and y is a function of z (the distance from the eye). As illustrated in Fig. 5, points in the frustum
will be mapped to points in the box sharing the same dimensions as the frustum’s
near plane and z-extents.

Fig. 7. Action of the projective map: The line through a point’s position after perspective division and
perpendicular to the near plane determines its new x-and y-coordinates. The z-coordinate is determined
by (3). Except for at the near and far plane, points move away from the eye

218

D. Hansford and D. Collins

In matrix form, the projective map Mp takes the form [20], [18]:


1 0
0
0
0 1
0
0 

Mp = 
 0 0 (n + f )/n −f  .
0 0
1/n
0
This map transforms collinear points to collinear points, and it transforms coplanar
points to coplanar points, and thus it is also known as a collineation [8]. For this
particular construction, the inverse exists, namely


1 0 0
0
0 1 0
0 

Mp−1 = 
(4)
0 0 0
n ,
f +n
0 0 −1
f
f
and it too is a collineation.

4. Anamorphs
In the spirit of Fig. 2 (Niceron), creating an anamorph amounts to applying Mp−1
given in (4). Now we want to take points, b, in a box to points, p, in a frustum.
Our goal is to create the most dramatic “distortions”. One option is to choose the
ﬁeld of view to be large. Also, we allow the near and far planes of the frustum to
move, which requires a slight reformulation of Mp . The cross ratio condition in (2)
becomes
cr(cop, np , pz , fp ) = cr(−∞, n, bz , f ),

(5)

where the frustum’s near and far plane distances are np and fp , respectively.
The new expression for b is


px n/pz
,
py n/pz
b=
rnp + f − rnp fp /pz

where

r=

f −n
.
fp − n p

(6)

The action of this map is similar to that of (3) in that the near and far planes of the
frustum are mapped to the near and far planes of the box.
By simply solving for p in (6), we have the anamorph operation. First establish the
new z-value
rnp fp
pz =
,
(7)
rnp + f − bz
and then set the x- and y-values in the frustum:
by pz
bx pz
and py =
.
n
n
Figure 8 illustrates the z-coordinate action of the map.
px =

(8)

Anamorphic 3D geometry
pz

pz

219
pz

fp

fp

fp
np

np
np
n

f

bz

n

f

bz

n

f

bz

Fig. 8. The rational linear function from (7) illustrates the correspondence between the z-coordinates of
points in a box to points in a frustum. Left: np = n and fp = f . Middle: np < n and fp > f . Right:
np > n and fp < f

A procedure for creating anamorphic 3D geometry is as follows. Given is a 3D object
deﬁned by vertices bi .
(1) Deﬁne a box, such as a bounding box, around the vertices bi .
(2) Choose one face of this box. The center of projection will be placed in front of
this face, and this face will serve as the near plane. Let the distance from this
near plane to the opposing face be d.
(3) Specify a ﬁeld-of-view angle, θ, thereby determining the near distance n from (1).
(4) Assign the far distance of the box: f = n + d.
(5) Input a near and far distance np and fp , respectively, for the frustum. (It is
convenient to input these relative to n and f so it is not necessary to generate
actual values.)
(6) Transform the vertices to eye coordinates.
(7) Apply (7) and then (8) to each vertex of the model.
(8) (Optional) Return the vertices to their original coordinate frame.
This procedure eliminates concern for singularities as long 0 < θ < 180◦ .

5. Demonstration
First we demonstrate our tool on the George Washington (GW) data set, which was
the motivation for this work in the ﬁrst place. In the top row of Fig. 9 is the original
data set, and in the bottom row is the anamorphic data set. On the left, we choose
a viewpoint (close to the projection center) where GW looks the same in both data
sets. The original data set is displayed with an orthographic projection and the anamorphic data set is displayed with a perspective projection.6 In the right-bottom
6 This idea is not new; La Gournerie [14], and Staudigl [19] studied the correspondence
between orthographic and perspective images from certain viewpoints.

220

D. Hansford and D. Collins

Fig. 9. Anamorphic George Washington: top row illustrates the original data set and the bottom row
illustrates the anamorphic data set with θ = 100◦ , np = n, and fp = 4f

ﬁgure, we can see the anamorph with a ﬁeld of view θ = 100◦ , np = n, and fp = 4f .
In the right part of the ﬁgure, both images are created with an orthographic projection. In the left part of the ﬁgure, we are actually seeing GW from the backside, as
is made clear by the location of the frustum in the bottom-right ﬁgure.7
To make the bottom-left ﬁgure appear identical to the top-left ﬁgure as shaded
images, one must use the original data set’s normals for the anamorphic data set.
And we have done this to further the illusion! Of course the wireframe models look
identical, and so we have included them in the rendering. The bottom-right ﬁgure
is rendered with its true normals.
7

Due to zooming-in on the geometry, parts of the frustum have been clipped.

Anamorphic 3D geometry

221

The layout of Fig. 10 follows the same format as Fig. 9. The anamorph has been
constructed with θ = 80◦ , np = n/2, and fp = 3f . Because the frustum’s near
plane is closer to the eye than the box’s near plane, the teapot is pushed toward the
eye, and the handle distortion is accentuated. This same behavior is illustrated in
Fig. 11 where the eye has been placed on the opposite side of the teapot, θ = 80◦ ,
np = n/4, and fp = f . The middle plot in Fig. 8 shows that the conﬁguration of
near planes used in these teapot examples causes a slow movement of z (away from
the eye) close to the frustum’s near plane.
A few comments on the anamorph procedure’s parameters are in order. Making the
ﬁeld of view small (e.g., θ = 1◦ ) in the procedure in Sect. 4 results in a large near
distance n. In the resulting anamorph with np = n and fp = f , there is nearly no
change in the data since the frustum has nearly the same shape as the box. On the
other hand, large ﬁeld of views result in more distortion. It should be clear that the
orientation of the box has a signiﬁcant impact on the resulting anamorph. In Fig. 9,
we see that the tool would be improved with the addition of adaptive meshing for
smoothing the deformed model.

Fig. 10. Anamorphic teapot: top row illustrates the original data set and the bottom row illustrates the
anamorphic data set with θ = 80◦ , np = n/2, and fp = 3f

222

D. Hansford and D. Collins

Fig. 11. Anamorphic teapot: A spout for reaching across the table! The parameters for the anamorphic
data set include θ = 80◦ , np = n/4, and fp = f . The rectangle is the orthographic box

6. Conclusions
We have presented a tool for creating anamorphic 3D geometry. We have remarked
that this tool, a collineation, was already familiar to those in computer graphics and
mathematics. The novelty here is that we have applied this to 3D triangle meshes.
We plan to use this tool for building anamorphic sculptures similar to that in Fig. 3.
Additionally, this tool is a contribution to the many volume deformation tools in
computer graphics literature [4], [10], [17].
Future work on anamorphs of 3D models will include investigating what can be
done with conical and cylindrical anamorphs in combination with their respective
reﬂecting surface and a ray tracing rendering. Anamorphic texture mapping might
be interesting to persue also. Other collineations could be explored.

References
[1] Andersen, K.: The mathematical treatment of anamorphoses from Piero della Francesca to Niceron. History of Mathematics: States of the Art, Flores quadrivii. Studies in Honor of Christoph J.
Scriba (J. W. Dauben et al., eds.), pp. 3–28. New York 1996.
[2] Baltrusaitis, J.: Anamorphic art. Cambridge: Chadwyck-Healy 1977.
[3] Beever, J.: Pavement drawings. http://users.skynet.be/j.beever/pave.htm.
[4] Bézier, P.: General distortions of an ensemble of biparametric patches. Comput. Aided Design 10(2),
116–120 (1978).
[5] Blinn, J. F.: A trip down the graphics pipeline: the homogeneous perspective transform. IEEE
Comput. Graphics Appl. 13(3), 75–80 (1993).
[6] Clarici, F.: The grand illusion: some considerations of perspective, illusionism, and tromp-l’oeil.
Art News Annual XXIII, 1954.
[7] Collins, D.: Anamorphosis and the eccentric observer. Leonardo J. 25(1 and 2). Berkeley: Pergamon
Press 1992 (also available at http://www.asu.edu/cfa/art/people/faculty/collins/Anamorph.html).
[8] Farin, G.: NURB curve and surfaces. From projective geometry to practical use, 2nd ed. A. K.
Peters 1995.
[9] Gardner, M.: Mathematical games. Scientiﬁc American 232(1), 1975.

Anamorphic 3D geometry

223

[10] Gomes, J., Darsa, L., Costa, B., Velho, L. (eds.): Warping and morphing of graphical objects.
Morgan Kaufmann 1999.
[11] Hunt, J. L., Nickel, B. G., Gigault, C.: Anamorphic images. Amer. J. Physics 68(3), March 2000.
[12] Kemp, M.: The science of art. Optic themes in western art from Brunelleschi to Seurat. New Haven
and London: Yale University Press 1990.
[13] Kent, P.: Art of anamorphosis. http://www.anamorphosis.com, January 2003.
[14] de La Gournerie, J.: Traité de perspective linéaire contenant les tracés pour les tableaux plans et
courbes, les bas-reliefs et les décorations théatrales, avec une théorie des effets de persecptive. Paris:
Dalmont et Dunod, 1859.
[15] Leeman, F.: Hidden images: games of perception, anamorphic art, illusion. New York: Abrams
1976.
[16] Riesenfeld, R. F.: Homogeneous coordinates and projective planes in computer graphics. IEEE
Computer Graphics and Applications, 1(1), January 1981.
[17] Sederberg, T., Parry, S.: Free-form deformation of solid geometric models. SIGGRAPH Proc.
Computer Graphics 20(4), 151–160 (1986).
[18] Shirley, P.: Fundamentals of computer graphics. A. K. Peters 2002.
[19] Staudigl, R.: Über die Identitäte von Constructionen in perspectivischer, schiefer und orthogonaler
Projection. 329G, S.A.W., 64, pp. 490–494, K23c:2–122, 1871.
[20] Shreiner, D., Woo, M., Neider, J., Davis, T.: OpenGL programming guide, 4th edition. Addison
Wesley 2004.
[21] Walker, J.: The amateur scientist. Scientiﬁc American 245(1), 1981.
D. Hansford and D. Collins
Partnership for Research in Spatial Modeling (PRISM)
Arizona State University
Tempe, AZ 85287-8809, USA
e-mails: {dianne.hansford, dan.collins}@asu.edu

PNG1 Triangles for Tangent Plane Continuous Surfaces on the GPU
1, 2‡

Christoph Fünfzig

Kerstin Müller
1

2

1, 2§

Keywords: PN triangles, Bézier surfaces, Geometry shader, GPUbased tessellation
Index Terms:
I.3.5 [Computing Methodologies]: Computer Graphics—Surface Representation, Spline, I.3.1 [Computing
Methodologies]: Computer Graphics—Graphics Processors
I NTRODUCTION

Graphics hardware is improving at a fast pace. In real-time rendering the visual appearance of triangle models is augmented by
special per-pixel techniques using textures. With coarse triangle
models it is inherently difficult to improve the geometric appearance at silhouettes. This is the case because shading has only a
small influence there, and the geometry must be refined efficiently.
Until recently, only the vertex shader was available to displace the
vertices. As the bandwidth between CPU and GPU is restricted, the
main problem is how to communicate the mesh and displacement
data efficiently to the GPU. In the geometry shader released with
the Direct3D 10 API, there is the possibility to generate new primitives using a restricted input mesh. There is fixed-size neighborhood information available consisting of the triangle and its three
edge neighbor triangles, see Figure 1, right. In this paper, our task
c.fuenfzig@gmx.de
kerstin.mueller@gmx.org
¶ e-mail: dianne.hansford@asu.edu
 e-mail: gerald.farin@asu.edu
§ e-mail:

1

Gerald Farin

PRISM Lab, Arizona State University, Tempe, USA

Improving the visual appearance of coarse triangle meshes is usually done with graphics hardware with per-pixel shading techniques. Improving the appearance at silhouettes is inherently hard,
as shading has only a small influence there and the geometry must
be corrected. With the new geometry shader stage released with
DirectX 10, the functionality to generate new primitives from an
input primitive is available. Also the shader can access a restricted
primitive neighborhood. In this paper, we present a curved surface
patch that can deal with this restricted data available in the geometry shader. A surface patch is defined over a triangle with its vertex
normals and the three edge neighbor triangles. Compared to PN
triangles, which define a curved patch using just the triangle with
its vertex normals, our surface patch is G1 continuous with its three
neighboring patches. The patch is obtained by blending two cubic Bézier patches for each triangle edge. In this way, our surface
is especially suitable for efficient, high-quality tessellation on the
GPU.
We show the construction of the surface and how to add special
features such as creases. Thus, the appearance of the surface patch
can be fine-tuned easily. The surface patch is easy to integrate into
existing polygonal modeling and rendering environments. We give
R
some examples using Autodesk Maya.

‡ e-mail:

1¶

Computer Graphics and Visualization, University Kaiserslautern, Germany

A BSTRACT

1

Dianne Hansford

is to construct a G1 continuous surface patch defined by exactly this
restricted input mesh. The resulting surface should be
• reasonable smooth,
• on edges the smoothness should be taggable so that special
features are available similar to creases on subdivision surfaces,
• a surface patch should be suitable and efficient for GPU rendering with the new geometry shader stage.
To meet these requirements, we construct two cubic triangular
Bézier patches for each edge of a triangle. These two cubic triangular Bézier patches generate a G1 join across their edge. To
get the final G1 surface, we blend the resulting triangular Bézier
patches together such that G1 continuity is not destroyed. We start
with related work for this problem in Section 2. Section 3 describes
our construction of the PNG1 surface. After a short overview of the
method, we summarize some results on cubic Bézier triangles and
their G1 continuity (Section 3.1). Then we apply a G1 construction
on each side of the triangle. Section 3.2 contains also the derivation of the blending functions and the overall surface evaluation.
For improved surface lighting, Section 3.3 contains two options to
get normals: original normals derived from the PNG1 patches and
modified normals by interpolation. Special features are presented
in Section 3.4. The properties and applications (Section 3.5) of
PNG1 surfaces on GPUs are explained afterwards. We show visual
R and give additional details on the
results using Autodesk Maya
implementation (Section 4). Finally, we close with conclusions and
possible further work (Section 5).
2 R ELATED W ORK
For modeling of curved surfaces there exists a zoo of different surface types. Parametric surfaces such as Bézier and B-Spline surfaces are defined by a control mesh [7]. Also surfaces resulting

Figure 1: On the left, the required neighborhood (light gray) for
the tessellation of the gray marked face using the Loop subdivision scheme. On the right, the neighborhood (light gray) of the gray
marked face on the GPU (GL TRIANGLES ADJACENCY EXT).

from subdivision of a base mesh are available. For a prominent
example, the Loop subdivision surface [14] works with a triangle
base mesh and generates an approximating, C2 continuous surface
except at the irregular points where it is only C1 . For a refinement step, the complete 1-neighborhood of a triangle is required as

shown in Figure 1, left. We define the restricted neighborhood as
the light gray triangles with its vertex normals in Figure 1, right.
The problem of mesh refinement consists of two sub-problems.
Firstly, the defining data for a surface patch has to be transferred to
the computation unit. Secondly, it remains to tessellate the surface
patch at a sufficient resolution to show all the surface details. In
principle, this can be done with a fixed tessellation or with adaptive
patterns resulting from vertex depth tags. The process of mesh refinement has been covered by Adaptive Refinement Patterns (ARP)
in general [2], and has been specially solved for NURBS and their
complex trimming [10]. These approaches choose a sufficiently fine
tessellation (already stored on the GPU) and displace it within the
vertex shader stage. Some adaptivity is achieved by precomputing
all possible fitting tessellations corresponding to the resolutions at
the edges.
Defining Patch Data
As mechanisms to transfer data to the GPU, vertex attributes and
recently also uniform buffer objects are available. These can be
combined to transfer all defining data for a surface patch. GPGPU
techniques for encoding the mesh connectivity and mesh geometry into textures [21, 4] have been proposed to make larger neighborhoods available in the vertex and fragment shader stages of the
GPU. The variety of schemes possible in this way is very broad but
the resulting algorithms are inherently multi-pass and still require
considerable preparation on the CPU after changes of the mesh connectivity. For subdivision surfaces (Loop, Butterfly), an approximation of a limit triangle by a quadratic surface patch interpolating
in the triangle corner and mid-edge vertices, has been proposed in
[3]. After one subdivision step on the CPU into four limit triangles
using the 1-neighborhood, the 1-neighborhood is no longer necessary to do the local approximation by quadratic surface patches in
a PN-like fashion [22]. Again there is a complex CPU preparation process involved. Unfortunately, this quadratic approximation
destroys the C1 continuity of the subdivision surface. A similar approach was proposed for the adaptive tessellation of Catmull-Clark
surfaces [15]. The Catmull-Clark surface is approximated by bicubic surface patches defined by 16 control points. In this way, it
can be evaluated on current GPUs. A variable-size hardware vertex cache has been proposed in [13] to make the 1-neighborhood
available in future GPU designs.
Tessellation
Besides using precomputed tessellation patterns in a patch-by-patch
rendering, the geometry shader released with the Direct3D 10 API
[1] can generate new triangles or triangle-strip primitives and, even
more important, offers new primitives for patch definition. The
complete neighborhood of a triangle is also not available but the
edge triangle neighbors can be accessed inside a new primitive consisting of six vertices (Figure 1). In [2], the current restriction to
generate not more than 1024 varying floats is pointed out. With
vertex coordinates and vertex color/vertex normal there are 8 floats
per vertex so that 126 triangles can be emitted in one triangle strip.
It is worthwhile to note that the new input primitives can be batched
efficiently, i.e., large batches of these primitives can be issued in one
API call. This is a considerable improvement over a patch-by-patch
setup each time a surface patch is rendered.
Parametric surfaces like curved PN triangles [22] can deal with
the restricted neighborhood information. A PN triangle is generated by a single triangle and its vertex normals. The construction
uses a cubic Bézier patch that is only C0 in general. To give the
impression of a smooth surface, the normals are computed separately from the surface via a smart normal interpolation method.
Figure 2 shows an example of PN triangles. Because PN triangles
are simple to evaluate, they found their way into graphics hardware (TruForm rendering) [9]. Mann and Davidchuk presented a

(b)

(a)

Figure 2: Comparison PNG1 (a) and PN (b). The C0 continuity of
the PN patch is clearly visible at the silhouette. The PNG1 patches
present a G1 surface with a smooth silhouette.

more sophisticated construction in [6, 17] that has G1 continuity
and uses only the restricted neighborhood. They generate a hybrid
Bézier patch that blends the interior as well as the boundary control points. The construction makes use of a planar scattered data
interpolation scheme proposed in [8]. Unfortunately, they do not
offer special features for their surface type. Our surface patch is
similar in spirit but our construction only uses a sufficient condition
for cubic Bézier triangles to be C1 continuous across an edge. By
controlled violation of this condition, we can easily create special
features like sharp edges.
In [16], parametric surface interpolation is surveyed, and the
paper compares local and global methods. From the local methods, the one by Shirman and Sequin [20] constructs three quartic triangular Bézier surfaces per patch similarly to the method of
Chiyokura and Kimura [5]. Further on, they present Nielson’s side
vertex method [18] with rational blending of three cubic triangular
Bézier surfaces. They state that with global methods the remaining
free parameters can be chosen much better compared to the heuristic choices in the local methods. For our application though, global
methods are not an option due to their preparation requirements.
Later, Hahmann and Bonneau [11] presented an interesting local
method using the 4-split instead of the Clough-Tocher-split in the
previous methods. They define four quintic patches leaving three
free Bézier control points. Unfortunately, the use of the complete
1-neighboorhood and the computation of 63 control points makes
this nice method unsuitable for the GPU.
3 PNG1 T RIANGLE PATCHES
In general, it is not possible to build a G1 join between two neighboring cubic Bézier triangles if only the middle control point of
both Bézier patches is variable. This is also the case if the control
points adjacent to the corner points share the same tangent plane
(see [19] for more details and an example). Therefore, we construct
for each edge of the triangle, a surface based on two cubic Bézier
patches that has the G1 join to its edge-neighbor. The resulting three
surfaces from the three sides are blended together conveniently to
maintain the G1 property on all three boundaries. That way, we
obtain a kind of a cubic Bézier patch whereby its control points are
replaced by control functions. Similar to the method in [22], to alleviate the effect of the curvature discontinuity that is not eliminated
by a G1 surface, we smooth the normals via a quadratic interpolation. The resulting surface looks smoother and gives us the desired
appearance. To enhance the variety of modeling options, special
features are used. Special features reduce the continuity locally on
the surface to allow for, e.g., sharp edges. They were introduced for
subdivision surfaces firstly but they are also available for PNG1.
3.1 Cubic Bézier Triangles
A Bézier triangle is defined by
B(u, v, w) =

n! i j k
u v w bi jk
i!
i+ j+k=n j!k!

∑

(1)

where bi jk are the control points of the Bézier triangle and w =
1 − u − v [7]. For n = 3 we get a cubic Bézier triangle (see Figure 3,
left, and Appendix A). The normals of the surface can be computed
by
N(u, v, w) = Du B(u, v, w) × Dv B(u, v, w)

(2)

where
u = [1, 0, −1]
v = [0, 1, −1]
We obtain a C1 join between two adjacent Bézier triangles, if the
quadrangles pi qi ri qi+1 , where i = 0, . . . , n − 1, are coplanar and
all quadrangles are similar [7] (see Figure 3). We will use this condition for the construction of our PNG1 patch to ensure a C1 join
to its adjacent triangles. In this way, we achieve a surface that is at
least G1 everywhere.
b003
b102
b201
b300

b012
b111

b210

q3

p2
q2

p1
p0

b021
b120

b030

q1

q0

r2

r1

r0

Figure 3: Left: Control points of a cubic Bézier patch. Right: C1 join
of two cubic Bézier patches.

3.2 Construction of a PNG1 Triangle Patch
We use the notation described in Figure 4 and start with building
the surface corresponding to the edge P1 P2 . The surfaces for the
edges P2 P3 and P3 P1 can be generated similarly.
N31

N3

N23

P3

P31

P23
N2

N1
P1

N12

u w
v

P2

P12
Figure 4: Notation for the input mesh for a PNG1 patch (left) and the
resulting shape (gray marked, right). The parameter space and the
barycentric coordinates are illustrated in the middle.

Consider the tangent plane of P1 defined by the point P1 and its
normal N1 (see Figure 5). We project the points P2 , P3 , and P12 in
the direction of N1 into the tangent plane of P1 . To preserve the edge
length in the projection, we scale the vector proj(Pi ) − P1 until it has
the same length as Pi − P1 for i = 2, 3, 12. The result of this projection and scaling are two adjacent triangles in the tangent plane as
illustrated in Figure 5, right. Subdivision of these two triangles by
factor 1/3 provides for each triangle the three red colored similar
subtriangles. They form three similar quadrangles that are coplanar. The same procedure can be done with the tangent plane of P2
defined by point P2 and its normal N2 : P1 , P12 , and P3 are projected
into the tangent plane of P2 and a scaling is done to maintain the

original edge length. The subdivision of the two projected triangles
in the tangent plane of P2 results also in three similar quadrangles.
For the construction of the PNG1 patch (see Figure 6, top)
we need the triangle adjacent to P1 in the tangent plane of P1
(P1 bP1:210 bP1:201 , red marked) and also the triangle adjacent to
P2 in the tangent plane of P2 (bP2:120 P2 bP2:021 , blue marked). An
affine transformation of the red triangle from tangent plane P1 into
the tangent plane of P2 provides the point bP1:021 (see Figure 6, bottom). In an analogous manner, point bP2:201 is computed by transferring the blue triangle from tangent plane P2 into tangent plane
P1 .
For the middle control points, we generate a plane defined by
e1 = bP2:120 − bP1:210
e2 = (NT + NT 12 ) ×e1
N12 =e1 ×e2

(3)
(4)
(5)

where NT is the normal of the triangle plane P1 , P2 , P3 , and NT 12
denotes the normal of P1 , P12 , P2 (see Figure 7). A transfer of the
red triangle from the tangent plane of P1 and a transfer of the blue
triangle from the tangent plane of P2 provides the points b12:P1:111
and b12:P2:111 . Constructed in this way, the resulting red and blue
triangles respectively are similar to each other. With the same procedure for the adjacent triangle P2 P1 P12 we get coplanar similar
quadrangles which results in the G1 property.
Applying the described construction also to the edges P2 P3 and
P3 P1 , provides the points as illustrated in Figure 8, top. The red
control points were created via the tangent plane of P1 , the blue
ones are constructed using the tangent plane of P2 , and the green
control points are generated by the tangent plane of P3 . Now we
map the calculated control points to a control function (see Figure
8, bottom). The indexing of the control point bPl:i jk results from its
creation by tangent plane of Pl , l = 1, 2, 3 and its correspondence to
control function i jk, where i jk is the standard indexing for Bézier
triangles. We use control functions instead of control points to get
the form of a cubic Bézier patch:
S(u, v, w) =

n! i j k
u v w bi jk (u, v, w)
i!
i+ j+k=3 j!k!

∑

(6)

where b300 (u, v, w) = b300 , b030 (u, v, w) = b030 , and b003 (u, v, w) =
b003 are the triangle vertices. The control functions bi jk (u, v, w)
blend the assigned control points and deliver for each parameter
(u, v, w) a suitable control point.
To specify the blending functions bi jk (u, v, w) we look at the side
P1 P2 firstly. To get a G1 join across P1 P2 , the following conditions
are sufficient on the border curve v = 0:
1. On the border curve, we are required to use only the control
point constructed from this edge
b210 (u, v, w) |v=0 = bP1:210 and b120 (u, v, w) |v=0 = bP2:120
2. Likewise, the derivatives of b210 (u, v, w) and b120 (u, v, w)
should be zero on this edge:
Du b210 (u, v, w) |v=0 = 0, Dv b210 (u, v, w) |v=0 = 0
Du b120 (u, v, w) |v=0 = 0, Dv b120 (u, v, w) |v=0 = 0
3. For the remaining control points affecting the continuity
on this side, we need to blend between bP1:201 and bP2:201 ,
bP1:021 and bP2:021 , b12:P1:111 and b12:P2:111 for u from 0 to
1, w from 1 to 0.

P3

Property 1 and 3 follow directly from the construction of these
points. Property 2 results from the surface derivatives on the side
v = 0. See Appendix B for the surface derivatives Du S(u, v, w),
Dv S(u, v, w) in terms of the derivatives of the control point functions. Analoguous conditions apply to the edges P2 P3 and P3 P1 .

b12:P1:111

NT
b12:P2:111

Ne12
bP1:210

bP2:120

P1
N1

P2
NT 12

Tangent Plane of P1
P3

P12
1/3

N1

N1

1/3

P1

Figure 7: Construction of the middle plane by the two adjacent triangle normals and bP2:120 − bP1:210 . The red and blue triangles from the
tangent planes of P1 and P2 are transferred into the middle plane to
compute the points b12:P1:111 , b12:P2:111 .

2/3

1/3
P1

P2
N1

b003
= P3

P12

Figure 5: Left: Normal projection of P2 , P3 , P12 onto the tangent plane
of P1 . The length of the vectors proj(P2 ) − P1 , proj(P3 ) − P1 , proj(P12 ) −
P1 is scaled to equal the original length P2 −P1 , P3 −P1 , P12 −P1 . Right:
A subdivision of the two projected triangles by factor 1/3 provides for
each triangle the three red colored similar subtriangles.

edge P3 P1 :

edge P2 P3 :

bP3:012

bP3:102

bP1:201

bP3:120

bP1:012

bP2:102

b31:P3:111

b23:P3:111

b31:P1:111

b23:P2:111

bP3:210

bP1:201
P1
=b300

1/3

bP2:021

1/3

bP1:210
1/3

bP2:120
2/3

2/3
1/3

1/3

b300
= P1

bP3:120

bP1:210
bP1:201

P2
=b030

b003
= P3

bP2:120
edge P1 P2 :
bP2:201
b12:P2:111 bP2:021
b12:P1:111 bP1:021

b030
= P2

1/3

Tangent Plane of P1

b300
= P1

Tangent Plane of P2

bP1:210

bP2:120

b030
= P2

Grouping of the control points:
bP1:201

bP2:201

bP1:021 bP2:021

bP1:210
b300

1/3

b003

bP2:120
2/3

2/3

1/3

b030

b102 (u, v, w)
Figure 6: Affine transformation of the two red triangles from tangent
plane P1 into the tangent plane of P2 . Likewise, make an affine transformation of the two blue triangles from tangent plane P2 into the tangent plane of P1 . The resulting red and blue quadrangles respectively
are coplanar and similar.

b201 (u, v, w)

b300

b012 (u, v, w)

b111 (u, v, w)

b210 (u, v, w)

b021 (u, v, w)

b120 (u, v, w)

b030

Figure 8: Top: Construction of a G1 patch for each side provides the
points illustrated. Bottom: These points are schematically grouped
together. A control function blends the points.

We designed the blending functions to fulfill all the properties
1–3 for all edges of the triangle:
b201 (u, v, w) =
b102 (u, v, w) =

1
u2 + (1 − u)2
1
u2 + (1 − u)2



(1 − u)2 bP1:201 + u2 bP2:201


(1 − u)2 bP3:102 + u2 bP2:102



1
2
2
(1
−
w)
b
+
w
b
P3:012
P1:012
w2 + (1 − w)2


1
2
2
b
+
w
b
b021 (u, v, w) = 2
(1
−
w)
P2:021
P1:021
w + (1 − w)2


1
2
2
(1
−
v)
b
+
v
b
b120 (u, v, w) = 2
P2:120
P3:120
v + (1 − v)2


1
(1 − v)2 bP1:210 + v2 bP3:210
b210 (u, v, w) = 2
2
v + (1 − v)
b012 (u, v, w) =

e2 = NT ×e1
To emphasize the sharp edge, the points bP2:201 , b12:P1:111 ,
b12:P2:111 , bP1:021 can be moved by κ NT . Models with special features are presented in Figures 10 and 12, right.

The inner function b111 (u, v, w) must deal with six control points,
two from each side, so Nielson’s blending function [18] occurs also
in our blending function for the inner control point:
b111 (u, v, w) =
 (1 − u)wb

uw
12:P1:111 + u(1 − w)b12:P2:111
+
uv + uw + vw
w + u − 2uw
 (1 − v)ub

uv
23:P2:111 + (1 − u)vb23:P3:111
+
uv + uw + vw
u + v − 2uv
 (1 − w)vb

vw
31:P3:111 + (1 − v)wb31:P1:111
uv + uw + vw
w + v − 2vw
3.3 PNG1 Normals
The normals of our surface can be computed directly (see also Appendix B) by
N(u, v, w) = Du S(u, v, w) × Dv S(u, v, w)

(7)

However, we deal with a G1 surface and therefore, it happens that
we do not get the desired smooth appearance, visible especially in
reflections. Thus, for a kind of normal smoothing, we use a method
similar to the one presented in [22] by Vlachos et al.
We get the smoothed normals via a quadratic Bézier triangle
patch
NS (u, v, w) =

3.4 Special Features for PNG1 Triangle Patch
In addition to smooth surfaces, sharp edges are desired for advanced
modeling applications. Loop and Catmull Clark subdivision surfaces offer nice kinds of special features (e.g., [12]) which should
also be available for our PNG1 surface similarly.
From a user’s point of view, sharp edges are obtained by setting
sharpness values κ on designated edges of the base mesh. To generate a sharp edge with PNG1 patches, we use the same construction
process as described in Section 3.2 with a minor change: If we have
a sharp edge, e.g., on the side P1 P2 , the regular computation of e2
(see Equation 4) is substituted by

2! i j k
u v w ni jk
i!
i+ j+k=2 j!k!

∑

= u2 n020 + v2 n002 + w2 n200 +
2wu n110 + 2uv n011 + 2wv n101
where (see Figure 4 for notation) n020 = N2 = N(1, 0, 0), n002 =
N3 = N(0, 1, 0), n200 = N1 = N(0, 0, 1), and
1
1
1
n110 = 2N( , 0, ) − (N1 + N2 )
2
2
2
1
1 1
n011 = 2N( , , 0) − (N2 + N3 )
2 2
2
1
1 1
n101 = 2N(0, , ) − (N3 + N1 )
2 2
2
In this way, we obtain the original surface normals in the middle of
the boundary curves as well as on the corners. With these normals,
the surface appearance gives us the impression that it is smoother
because curvature discontinuities are alleviated.

3.5 Properties and Applications for PNG1 Patches
From the construction of the PNG1 patch, it follows that the surface is at least G1 at the border and G2 in the interior of the patch.
The surface patches are reasonably smooth even when a silhouette
is observed, which is an additional advantage over PN triangles.
Special features as known from Loop subdivision surfaces can be
implemented for PNG1 patches. The appearance of the sharp edges
for PNG1 differ from the ones of Loop because we deal with an
interpolating method instead of an approximating one.
The G1 surface above has been designed for the restricted neighborhood directly available, for example, in the geometry shader
stage of modern GPUs. The application only needs to keep track
of the edge neighbors on triangles, which is of constant size per
triangle and can be maintained easily. This enables vertex attribute
and index data to be processed in large batches similar to standard
triangle models. The geometry shader can then carry out the evaluation of the parametric surface with formulas given in Appendix
A. Using a uniform tessellation, we step through the barycentric
parameter domain in rows of constant w and generate a triangle
strip per row. Each emitted vertex can have a lighted color computed in the geometry shader or a normal for per-pixel lighting in
the fragment shader. In each case, this requires 8 float varyings per
vertex. Using l points per triangle side, this requires l triangle strips
of lengths (2l + 1), . . . , 3, defining (2l − 1), . . . , 3, 1 triangles. So a
vertex sequence of length (2l + 1) + . . . + 3 = (l + 1)l + l = l 2 + 2l
defines (2l − 1) + . . . + 3 + 1 = (l + 1)l − l = l 2 triangles.
4 R ESULTS
We have implemented the PNG1 patches as a MPxHwShaderNode
R The Polygons part of Autodesk Maya
R
within Autodesk Maya.
is a classic polygonal modeller, and lots of low-level and high-level
functions are available for surface creation. Without sharpness tags
for creases, the PNG1 triangles are defined by ordinary triangle
models so that it is not necessary to touch the underlying database.
Even sharpness tags can be integrated easily, either directly by a
new vertex-face attribute or by using a component of the vertexface color.
For assessing the surface shape, we rendered some simple polyhedral shapes with Phong shading in comparison to the PN patches.
Figure 9 and Figure 11 (left) show the PNG1 and the PN surface,
Figure 9 presents also the triangle model with its normals. The PN
patches usually look good in the inside due to surface lighting generated by a smooth normal field but at the silhouettes, kinks caused
by the C0 continuous surface are clearly visible and cannot be covered up with normal interpolation.
We have used the interpolated normals described in Section 3.3.
They can largely improve the surface lighting in comparison to the
original normals, so that the G1 continuous surface gets lighted with

Figure 9: Cone of valence 6 from above. Triangle model with symmetrical normals (left), PNG1 patches (middle) and PN patches (right).

Figure 10: Smooth tetrahedron and tetrahedron with special features. Triangle model with centroid normals (left), PNG1 patches (middle), and
PNG1 patches with creased bottom triangle of sharpness value κ = −0.1 (right).

an enhanced smooth normal field, which interpolates the exact normals at the triangle corners and edge mid-points.
On the tetrahedron (Figure 10) and the spaceship model (Figure
12, right), we show the effect of sharp edges on the elsewhere G1
continuous surface.
More complex models are presented in Figure 11. The head
model was previously used in the paper on PN triangles [22]. It
can be seen that the shape of the PNG1 patches is more curved and
smoother especially at the silhouettes. The appearance away from
silhouettes is good with both due to the interpolated normals.
Figure 13 shows the Loop surface on a bunny base mesh in
comparison to the PNG1 surface. For the PNG1 surface, we used
the base mesh of same topology but with points/normals computed
by Loop limit rules. Using these normals, both schemes generate
nearly the same shape. Small differences occur in the ear and eye
regions. Using normals averaged from the incident face normals,
shows some more differences, especially at the ear and the tail.
We want to report on the performance of the uniform tessellation
in a geometry shader writing out the vertex and normal coordinates
as vertex attributes required for per-pixel lighting. The uniform
tessellation can generate 100 triangles with a vertex sequence of
length l 2 + 2l = 120 < 1024/8 = 128 in l = 10 triangle strips per
patch. This bound results from 1024 varying floats available on a
NVidia Geforce G8800 GTX used by 8 varying floats per vertex.
With this resolution, we achieve the following framerates for the
PN head model (200 triangles): 214 frames per second (fps) using

the PN shader, and 93 fps using the PNG1 shader. With depth l =
9, we achieve 258 fps using the PN shader, 112.5 fps using the
PNG1 shader and with depth l = 8, 316.5 fps using the PN shader,
138.5 fps using the PNG1 shader. For a model of typical size 1084
triangles, we observe 42 fps using the PN shader, and 14 fps using
the PNG1 shader. With depth l = 9, we achieve 50 fps using the PN
shader, 16.5 fps using the PNG1 shader and with depth l = 8, 61.8
fps using the PN shader, 20 fps using the PNG1 shader. Note that
OpenGL vertex arrays were used for issueing the vertex and index
data in these benchmarks.
5

C ONCLUSION

AND

F URTHER W ORK

In this paper, we present an enhancement of PN patches by generating at least G1 continuous surfaces from triangle models and
their normals, called PNG1 patches. PNG1 patches are based on
cubic Bézier triangles and use rational blending functions. This
new curved surface significantly improves the appearance of silhouettes on shaded surface tessellations. Compared to subdivision
surfaces like Loop surfaces, the new surface just uses the triangle’s
edge neighbors in its construction, which is of constant size, six
points and six normals. In terms of surface quality such a scheme
is inferior to the Loop scheme but generates nice G1 surfaces. The
appearance of shading can be further and separately improved by
normal interpolation of the corner and mid-edge normals.
The PNG1 patches are suitable for direct rendering in the geometry shader stage of modern GPUs and its restricted triangle neigh-

(a)

(b)

Figure 11: Comparison PNG1 (a), PN (b) for the head model (200 triangles), originally used in the PN paper [22]. Further PNG1 example of a
Dove model (832 triangles).

Figure 12: PNG1 Examples. Spaceship model (460 triangles, left), PNG1 model (middle), and PNG1 model with creases of value κ = −0.2
(right).

Figure 13: Loop surface on bunny mesh (910 triangles, left), PNG1 surface on base mesh of same topology and Loop limit points/normals
(middle), and with Loop limit points but normals computed by averaging incident face normals (right).

borhood available with GL TRIANGLES ADJACENCY EXT.
They do not require any precomputation step on the CPU and are
easy to implement. The geometry shader with drivers for current
hardware is restricted to 1024 varying floats. We expect that this
will improve with upcoming drivers and the next hardware update
cycle. For fine tessellations, it is also possible to use the tessellation approach proposed in [2] using vertex buffer objects with
predefined tessellation patterns and surface evaluation in the vertex
shader.
As further work, we want to allow arbitrary sharp edges inde-

pendent of the input mesh. This makes feature creation with PNG1
triangles even more flexible as the triangle mesh does not need to
be changed.
ACKNOWLEDGEMENTS
We would like to thank the German Research Council (DFG) for
the support of one author by a postdoc scholarship. We thank Jörg
Peters for providing us with the head model originally used in the
PN triangles paper. Further thanks go to Mo Li for the flying se-

quence, we used in the movie, and for help with some Autodesk
R questions. We would like to thank Volker Settgast for the
Maya
animated knight model and Torsten Techmann for providing us with
the bunny model with Loop limit points/normals. Last but not least,
we thank the artist Maurizio (http://www.abyssalplains-music.info)
for the permission to use his track Orange River in our movie.

A

P OINT AND DERIVATIVE
T RIANGLES

EVALUATION FOR CUBIC

B ÉZIER

B(u, v, w) = u3 b030 + v3 b003 + w3 b300 + 3u2 wb120 +
3u2 vb021 + 3v2 wb102 + 3v2 ub012 +
3w2 ub210 + 3w2 vb201 + 6wuvb111

R EFERENCES
[1] D. Blythe. The Direct3D 10 system. In SIGGRAPH ’06: ACM SIGGRAPH 2006 Papers, pages 724–734, New York, NY, USA, 2006.
ACM Press.
[2] T. Boubekeur and C. Schlick. A Flexible Kernel for Adaptive Mesh
Refinement on GPU. Computer Graphics Forum, 2007.
[3] T. Boubekeur and C. Schlick. QAS: Real-time Quadratic Approximation of Subdivision Surfaces. In Proceedings of Pacific Graphics
2007, November 2007.
[4] M. Bunnell. Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping. In GPU Gems II. Addison-Wesley, 2005.
[5] H. Chiyokura and F. Kimura. Design of Solids with free-form Surfaces. In SIGGRAPH ’83: Proceedings of the 10th annual conference on Computer graphics and interactive techniques, pages 289–
298, New York, NY, USA, 1983. ACM Press.
[6] M. Davidchuk and S. Mann. A Parameteric Hybrid Triangular Bézier
Patch. In M. Daehlen, T. Lyche, and L. Schumaker, editors, Mathematical Methods for Curves and Surfaces 2, pages 335–342, 1998.
[7] G. Farin. Curves and Surfaces for CAGD. Morgan Kaufmann Publishers, 2002.
[8] T. Foley and K. Opitz. Hybrid cubic Bézier Triangle Patches. In T. Lyche and L. Schumaker, editors, Mathematical Methods in Computer
Aided Geometric Design 2, pages 275–286. Academic Press, 1992.
[9] D. Ginsburg and A. Vlachos.
ATI TruForm Rendering.
http://ati.amd.com/developer/truform faq.html, 2001.
[10] M. Guthe, A. Balázs, and R. Klein. GPU-based Trimming and Tessellation of NURBS and T-Spline Surfaces. ACM Trans. Graph.,
24(3):1016–1023, 2005.
[11] S. Hahmann and G.-P. Bonneau. Triangular G1 interpolation by
4-splitting domain triangles. Computer Aided Geometric Design,
17(8):731–757, 2000.
[12] H. Hoppe, T. DeRose, T. Duchamp, H. Halstead, H. Jin, J. McDonald,
J. Schweitzer, and W. Stuetzle. Piecewise Smooth Surface Reconstruction. In Proceedings of SIGGRAPH 1994, pages 295–302, 1994.
[13] M. Kazakov. Catmull-Clark Subdivision for Geometry Shaders. In
AFRIGRAPH ’07: Proceedings of the 5th international conference
on Computer graphics, virtual reality, visualisation and interaction in
Africa, pages 77–84, New York, NY, USA, 2007. ACM.
[14] C. Loop. Smooth Subdivision Surfaces Based on Triangles. Master’s
thesis, University of Utah, 1987.
[15] C. Loop and S. Schaefer. Approximating Catmull-Clark Subdivision
Surfaces with Bicubic Patches. Technical Report MSR-TR-2007-44,
Microsoft Research, Apr 2007.
[16] M. Lounsbery, S. Mann, and T. DeRose. Parametric Surface Interpolation. IEEE Comput. Graph. Appl., 12(5):45–52, 1992.
[17] S. Mann. An Improved Parametric Side–Vertex Triangle Mesh Interpolant. In Graphics Interface, pages 35–42, 1998.
[18] G. M. Nielson. A Transfinite, Visually Continuous, Triangular Interpolant. In Geometric Modeling: Algorithms and New Trends, pages
235–245. SIAM, 1987.
[19] B. R. Piper. Visually Smooth Interpolation with Triangular Bézier
Patches. In Geometric Modeling: Algorithms and New Trends, pages
221–233. SIAM, 1987.
[20] L. Shirman and C. Sequin. Local Surface Interpolation with Bézier
Patches. CADG, 4:279–295, 1987.
[21] L.-J. Shiue, I. Jones, and J. Peters. A Realtime GPU Subdivision Kernel. In SIGGRAPH ’05: ACM SIGGRAPH 2005 Papers, pages 1010–
1015, New York, NY, USA, 2005. ACM Press.
[22] A. Vlachos, J. Peters, C. Boyd, and J. L. Mitchell. Curved PN Triangles. In SI3D ’01: Proceedings of the 2001 symposium on Interactive
3D graphics, pages 159–166. ACM Press, 2001.

Du B(u, v, w) = 3u2 b030 − 3w2 b300 + (6uw − 3u2 )b120 +
6uvb021 − 3v2 b102 + 3v2 b012 +
(3w2 − 6wu)b210 − 6wvb201 +
(6wv − 6uv)b111
Dv B(u, v, w) = 3v2 b003 − 3w2 b300 − 3u2 b120 +
3u2 b021 + (6vw − 3v2 )b102 + 6vub012
− 6wub210 + (3w2 − 6wv)b201 +
(6wu − 6uv)b111
B

P OINT

AND
PATCHES

DERIVATIVE

EVALUATION

FOR

PNG1

S(u, v, w) =
u3 b030 (u, v, w) + v3 b003 (u, v, w) + w3 b300 (u, v, w) +
3u2 wb120 (u, v, w) + 3u2 vb021 (u, v, w) + 3v2 wb102 (u, v, w) +
3v2 ub012 (u, v, w) + 3w2 ub210 (u, v, w) + 3w2 vb201 (u, v, w) +
6wuvb111 (u, v, w)
Du S(u, v, w) =
−3 b300 w2 + 3b030 u2 + 3 (Du b210 (u, v, w)) w2 u
−6b210 (u, v, w) wu + 3b210 (u, v, w) w2
+3 (Du b120 (u, v, w)) wu2 − 3b120 (u, v, w) u2
+6b120 (u, v, w) wu + 3 (Du b201 (u, v, w)) w2 v
−6b201 (u, v, w) wv + 3 (Du b021 (u, v, w)) u2 v
+6b021 (u, v, w) uv + 3 (Du b102 (u, v, w)) wv2
−3b102 (u, v, w) v2 + 3 (Du b012 (u, v, w)) uv2
+3b012 (u, v, w) v2 + 6 (Du b111 (u, v, w)) wuv
−6b111 (u, v, w) uv + 6b111 (u, v, w) wv
Dv S(u, v, w) =
−3b300 w2 + 3b003 v2 + 3 (Dv b210 (u, v, w)) w2 u
−6b210 (u, v, w) wu + 3 (Dv b120 (u, v, w)) wu2
−3b120 (u, v, w) u2 + 3 (Dv b201 (u, v, w)) w2 v
−6b201 (u, v, w) wv + 3b201 (u, v, w) w2
+3 (Dv b021 (u, v, w)) u2 v + 3b021 (u, v, w) u2
+3 (Dv b102 (u, v, w)) wv2 − 3b102 (u, v, w) v2
+6b102 (u, v, w) wv + 3 (Dv b012 (u, v, w)) uv2
+6b012 (u, v, w) uv + 6 (Dv b111 (u, v, w)) wuv
−6b111 (u, v, w) uv + 6b111 (u, v, w) wu

