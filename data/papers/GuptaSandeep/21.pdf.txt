arXiv:1103.1109v4 [cs.DS] 2 Aug 2016

Fully dynamic maximal matching in O(log n) update time
Surender Baswana
Department of CSE,
I.I.T. Kanpur, India

Manoj Gupta
Department of CSE,
I.I.T. Delhi, India

sbaswana@cse.iitk.ac.in

gmanoj@cse.iitd.ernet.in

Sandeep Sen
Department of CSE,
I.I.T. Delhi, India
ssen@cse.iitd.ernet.in

August 3, 2016

Abstract
We present an algorithm for maintaining a maximal matching in a graph under addition and deletion
of edges. Our algorithm is randomized and it takes expected amortized O(log n) time for each edge
update where n is the number of vertices in the graph. Moreover, for any sequence of t edge updates,
the total time taken by the algorithm is O(t log n + n log2 n) with high probability.

Note: The previous version of this result appeared in SIAM J. Comp., 44(1): 88-113, 2015. However, the
analysis presented there for the algorithm was erroneous. This version rectifies this deficiency without any
changes in the algorithm while preserving the performance bounds of the original algorithm.

1

1

Introduction

Let G = (V, E) be an undirected graph on n = |V | vertices and m = |E| edges. A matching in G is a
set of edges M ⊆ E such that no two edges in M share any vertex. The study of matchings satisfying
various properties has remained the focus of graph theory for decades [21]. It is due to the elegant structure
of matching that it also appears in various combinatorial optimization problems [11, 20]. A few well studied
matching problems are maximum cardinality matching [10, 17, 22, 23], maximum weight matching [12,
18], minimum cost matching (chapter 7, [19]), stable matching [13], popular matching [2]. Among these
problems, the maximum cardinality matching problem has been studied most extensively. A matching M
is of maximum cardinality if the number of edges in M is maximum. A maximum cardinality matching
(MCM) is also referred to as a maximum matching. A matching is said to be a maximal matching if it
cannot be strictly contained in any other matching. It is well known that a maximal matching guarantees
a 2-approximation of the maximum matching. Though it is quite easy to compute a maximal matching in
O(m + n) time, designing an efficient algorithm for maximum matching has remained a very challenging
√
problem for researchers [10, 22]. The fastest algorithm, till date, for maximum matching runs in O(m n)
time and is due to Micali and Vazirani [22]. In this paper, we address the problem of maintaining a maximal
matching in a dynamic graph.
Most of the graph applications in real life deal with graphs that are not static, viz., the graph changes
over time caused by deletion and insertion of edges. This has motivated researchers to design efficient
algorithms for various graph problems in dynamic environment. An algorithmic graph problem is modeled
in the dynamic environment as follows. There is an online sequence of insertion and deletion of edges and
the goal is to update the solution of the graph problem after each edge update. A trivial way to achieve this
is to run the best static algorithm for this problem after each edge update; clearly this approach is wasteful.
The aim of a dynamic graph algorithm is to maintain some clever data structure for the underlying problem
such that the time taken to update the solution is much smaller than that of the best static algorithm. There
exist many efficient dynamic algorithms for various fundamental problems in graphs [6, 16, 27, 28, 30].
Baswana, Gupta and Sen [5] had presented a fully dynamic algorithm for maximal matching which
achieved O(log n) expected amortized time per edge insertion or deletion. Moreover, for any sequence of
t edge updates, the total time taken by the algorithm is O(t log n + n log2 n) with high probability. Their
algorithm improved an earlier result of Onak and Rubinfeld [25] who presented a randomized algorithm
for maintaining a c-approximate (for some unspecified large constant c) matching in a dynamic graph with
O(log2 n) expected amortized time for each edge update.
This algorithm also implied a similar result for maintaining a two approximate vertex cover. It is also
used as a basis for maintaining approximate maximum weight matching in a dynamic graph [3].
Unfortunately, the analysis given in [5] has a crucial flaw, viz., the statement of Lemma 4.10 [5] is
not true in general. Although the bound on the update time was critically dependent on Lemma 4.10, we
have presented an alternate proof of the claimed update time based on an interesting property of the original
algorithm that was not reported earlier. For completeness, we have presented the full details of the algorithm
of [5] and the new corrected analysis in this paper. This property is interesting in its own right and may have
other useful applications of the algorithm.

2 An overview
Let M denote a matching of the given graph at any moment. Every edge of M is called a matched edge and
an edge in E\M is called an unmatched edge. For an edge (u, v) ∈ M , we define u to be the mate of v and
vice versa. For a vertex x, if there is an edge incident to it in the matching M , then x is a matched vertex;
otherwise it is free or unmatched.

2

In order to maintain a maximal matching, it suffices to ensure that there is no edge (u, v) in the graph
such that both u and v are free with respect to the matching M . From this observation, an obvious approach
will be to maintain the information for each vertex whether it is matched or free at any stage. When an edge
(u, v) is inserted, add (u, v) to the matching if u and v are free. For a case when an unmatched edge (u, v) is
deleted, no action is required. Otherwise, for both u and v we search their neighborhoods for any free vertex
and update the matching accordingly. It follows that each update takes O(1) computation time except when
it involves deletion of a matched edge; in this case the computation time is of the order of the sum of the
degrees of the two vertices. So this trivial algorithm is quite efficient for small degree vertices, but could be
expensive for large degree vertices. An alternate approach to handling deletion of a matched edge is to use
a simple randomized technique - a vertex u is matched with a randomly chosen neighbor v. Following the
standard adversarial model, it can be observed that an expected deg(u)/2 edges incident to u will be deleted
before
 deleting the
 matched edge (u, v). So the expected amortized cost per edge deletion for u is roughly
deg(u)+deg(v)
O
. If deg(v) < deg(u), this cost is O(1); but if deg(v) ≫ deg(u), then it can be as bad
deg(u)/2
as the trivial algorithm. We combine the idea of choosing a random mate and the trivial algorithm suitably
√
as follows. We first present a fully dynamic algorithm which achieves expected amortized O( n) time per
update. We introduce a notion of ownership of edges in which we assign an edge to that endpoint which has
higher degree. We maintain a partition of the set of vertices into two levels : 0 and 1. Level 0 consists of
vertices which own fewer edges than an appropriate threshold and we handle the updates in level 0 using the
trivial algorithm. Level 1 consists of vertices (and their mates) which own larger number of edges and we
use the idea of random mate to handle their updates. In particular, a vertex chooses a random mate from its
set of owned edges which ensures that it selects a neighbor having a lower degree.
√
A careful analysis of the O( n) update time algorithm suggests that a finer partition of vertices may
help in achieving a better update time. This leads to our final algorithm which achieves expected amortized
O(log n) time per update. More specifically, our algorithm maintains an invariant that can be informally
summarized as follows.
Each vertex tries to rise to a level higher than its current level, if, upon reaching that level, there are
sufficiently large number of edges incident on it from lower levels. Once a vertex reaches a new level, it
selects a random edge from this set and makes it matched.
Note that we say that ”a vertex rises” to indicate that the vertex moves to a higher level and ”a vertex
falls” to indicate that the vertex moves to a lower level. A vertex may also fall to a lower level if the number
of edges incident to it decreases. But a vertex only uses its neighborhood information to decide whether to
move to higher or lower level. Overall, the vertices use their local information to reach a global equilibrium
state in which after each update each vertex is at the right level having no incentive to either move above or
below its current level.

2.1 Organization of the paper
For a gentle exposition of the ideas and techniques, we first describe a simple but less efficient fully dynamic
algorithm for maximal matching in Section 4. We present our final fully dynamic algorithm which achieves
expected amortized O(log n) time per update in Section 5. In Section 6, we illustrate an example of a
dynamic graph that establishes the tightness of the approximation factor guaranteed by our algorithm. In
the following section, we describe notations and elementary results from the probability theory that we shall
use.

3

3 Preliminaries
We shall use M to denote the matching maintained by our algorithm at any stage. Our algorithms maintain a
partition of the set of vertices among various levels. We shall use LEVEL (u) to denote the level of a vertex u.
We define LEVEL (u, v) for an edge (u, v) as max(LEVEL (u), LEVEL (v)). Our algorithms will ensure that
both the endpoints of each matched edge in M are present at the same level. So the matching M maintained
by our algorithms will be a set of tuples as follows.
M = {(u, v, ℓ) | u is matched with v at level ℓ}
The analysis of our algorithms will use a basic result about asymmetric random walk as follows.
Asymmetric random walk on a line
Consider a particle performing a discrete random walk on a line. In each step, it moves one unit to the right
with probability p or to the left with probability q = 1 − p. Each move is independent of the moves made in
the past. The following lemma holds if p > q.
Lemma 3.1 Suppose the random walk starts at location ℓ units to the right of the origin. Then the proba ℓ
bility that it ever reaches origin within L steps for any given L is less than pq .

The proof of Lemma 3.1 is sketched in Appendix. During the analysis of algorithms, we shall use the
terminology very high probability for those events whose probability is 1 − nc for some positive constant c.

√
4 Fully dynamic algorithm with expected amortized O( n) time per update
The algorithm maintains a partition of the set of vertices into two levels - 0 and 1. We now introduce the
concept of ownership of the edges. Each edge present in the graph will be owned by one or both of its
endpoints as follows. If both the endpoints of an edge are at level 0, then it is owned by both of them.
Otherwise it will be owned by exactly that endpoint which lies at higher level. If both the endpoints are
at level 1, the tie will be broken suitably by the algorithm. As the algorithm proceeds, the vertices will
make transition from one level to another and the ownership of edges will also change accordingly. Let Ou
denote the set of edges owned by u at any moment of time. Each vertex u ∈ V will keep the set Ou in
a dynamic hash table [26] so that each search or deletion operation on Ou can be performed in worst case
O(1) time and each insertion operation can be performed in expected O(1) time. This hash table is also
suitably augmented with a linked list storing Ou so that we can retrieve all edges of set Ou in O(|Ou |) time.
The algorithm maintains the following three invariants after each update.
1. Every vertex at level 1 is matched. Every free vertex at level 0 has all its neighbors matched.
√
2. Every vertex at level 0 owns less than n edges at any moment of time.
3. Both the endpoints of every matched edge are at the same level.
The first invariant implies that the matching M maintained is maximal at each stage. A vertex u is
said to be a dirty vertex at a moment if at least one of its invariants does not hold. In order to restore
the invariants, each dirty vertex might make transition to some new level and do some processing. This
processing involves owning or disowning some edges depending upon whether the level of the vertex has
risen or fallen. Thereafter, the vertex will execute RANDOM - SETTLE or NAIVE - SETTLE to settle down at
its new level. The pseudocode of our algorithms for handling insertion and deletion of an edge is given in
Figure 1 and Figure 2.
4

Handling insertion of an edge
Let (u, v) be the edge being inserted. If either u or v are at level 1, there is no violation of any invariant. So
the only processing that needs to be done is to assign (u, v) to Ou if LEVEL (u) = 1, and to Ov otherwise.
This takes O(1) time. However, if both u and v are at level 0, then we execute HANDLING - INSERTION
procedure which does the following (see Figure 1).
Procedure
1
2
3
4
5
6
7
8
9
10

H A N D L I N G - I N S E R T I O N (u, v)

Ou ← Ou ∪ {(u, v)};
Ov ← Ov ∪ {(u, v)};
if u and v are FREE then M ← M ∪ {(u, v)};
if |Ov | > |Ou | then swap(u, v);
√
if |Ou | = n then
foreach (u, w) ∈ Ou do
delete (u, w) from Ow ;

x ← RANDOM - SETTLE (u);
if x 6= NULL then NAIVE - SETTLE(x);
if w was previous mate of u then NAIVE - SETTLE(w);

Procedure R A N D O M - S E T T L E (u): Finds a random edge (u, y) from the edges owned by u and
returns the previous mate of y
1
2
3
4
5
6

7
8

Let (u, y) be a uniformly randomly selected edge from Ou ;
foreach (y, w) ∈ Oy do
delete (y, w) from Ow ;
if y is matched then
x ← MATE (y);
M ← M\{(x, y)}
else
x ← NULL ;

M ← M ∪ {(u, y)};
← 1; LEVEL (y) ← 1;
return x;

9 LEVEL (u)
10

Procedure
1
2
3
4

N A I V E - S E T T L E (u)

: Finds a free vertex adjacent to u deterministically

for each (u, x) ∈ Ou do
if x is free then
M ← M ∪ {(u, x)};
Break;
Figure 1: Procedure for handling insertion of an edge (u, v) where LEVEL (u) =

LEVEL (v)

= 0.

Both u and v become the owner of the edge (u, v). If u and v are free, then the insertion of (u, v) has
violated the first invariant for u as well as v. We restore it by adding (u, v) to M. Note that the insertion
of (u, v) also leads to increase of |Ou | and |Ov | by one. We process that vertex from {u, v} which owns
√
larger number of edges; let u be that vertex. If |Ou | = n, then Invariant 2 has got violated. We execute
RANDOM - SETTLE (u); as a result, u moves to level 1 and gets matched to some vertex, say y, selected
5

randomly uniformly from Ou . Vertex y moves to level 1 to satisfy Invariant 3. If w and x were respectively
the earlier mates of u and y at level 0, then the matching of u with y has rendered w and x free. So to restore
Invariant 1, we execute NAIVE - SETTLE(w) and NAIVE - SETTLE(x). This finishes the processing of insertion
of (u, v). Note that when u rises to level 1, |Ov | remains unchanged. Since all the invariants for v were
satisfied before the current edge update, it follows that the second invariant for v still remains valid.
Handling deletion of an edge
Let (u, v) be an edge that is deleted. If (u, v) ∈
/ M, all the invariants are still valid. So let us consider the
nontrivial case when (u, v) ∈ M. In this case, the deletion of (u, v) has made u and v free. Therefore,
potentially the first invariant might have got violated for u and v, making them dirty. We do the following
processing in this case.
If edge (u, v) was at level 0, then following the deletion of (u, v), vertex u executes NAIVE - SETTLE(u),
and then vertex v executes NAIVE - SETTLE(v). This restores the first invariant and the vertices u and v are
clean again. If edge (u, v) was at level 1, then u is processed using the procedure shown in Figure 2 which
does the following (v is processed similarly).
Procedure H A N D L I N G - D E L E T I O N (u,v)
1 foreach (u, w) ∈ Ou and LEVEL (w) = 1 do
2
move (u, w) from Ou to Ow ;
√
3 if |Ou | ≥
n then
4
x ← RANDOM - SETTLE (u);
5
if x 6= NULL then NAIVE - SETTLE(x);
else
6
LEVEL (u) ← 0;
7
foreach (u, w) ∈ Ou and LEVEL (w) = 0 do
8
add (u, w) to Ow ;
9
10
11
12
13

NAIVE - SETTLE(u);

foreach (u, w) ∈ Ou do
√
if |Ow | = n then
x ← RANDOM - SETTLE (w);
if x 6= NULL then NAIVE - SETTLE(x);

Figure 2: Procedure for processing u when (u, v) ∈ M is deleted and LEVEL (u)=LEVEL (v)=1.
First, u disowns all its edges whose other endpoint is at level 1. If |Ou | is still greater than or equal to
√
n, then u stays at level 1 and executes RANDOM - SETTLE(u). If |Ou | is less than n, u moves to level 0
and executes NAIVE - SETTLE(u). Note that the transition of u from level 1 to 0 leads to an increase in the
number of edges owned by each of its neighbors at level 0. The second invariant for each such neighbor, say
√
w, may get violated if |Ow | = n, making w dirty. So we scan each neighbor of u sequentially and for each
√
dirty neighbor w (that is, |Ow | = n), we execute RANDOM - SETTLE(w) to restore the second invariant.
This finishes the processing of deletion of (u, v).
It can be observed that, unlike insertion of an edge, the deletion of an edge may lead to creation of a
large number of dirty vertices. This may happen if the deleted edge is a matched edge at level 1 and at least
one of its endpoints move to level 0.

√

6

4.1 Analysis of the algorithm
While processing the sequence of insertions and deletions of edges, an edge may become matched or unmatched at different update steps. We analyze the algorithm using the concept of epochs, which we explain
as follows.
Definition 4.1 At any time t, let (u, v) be any edge in M. Then the epoch defined by (u, v) at time t is the
maximal continuous time period containing t during which it remains in M. An epoch is said to belong to
level 0 or 1 depending upon the level of the matched edge that defines the epoch.
The entire life span of an edge (u, v) consists of a sequence of epochs of (u, v) separated by the continuous periods when (u, v) is unmatched. It follows from the algorithm that any edge update that does
not change the matching is processed in O(1) time. An edge update that changes the matching results
in the start of new epoch(s) or the termination of some existing epoch(s). For the sake of analysis, we
will redistribute the computation performed at any update step t among the epochs that are created or terminated at step t. More specifically, let epoch of (u1 , v1 ), (u2 , v2 ), . . . , (ul , vl ) be created and epochs of
(w1 , x1 ), (w2 , x2 ), . . . , (wk , xk ) be terminated at step t. We will redistribute total computation performed at
step t in such a way that:
Pl
Total computation performed at step t =
computation associated with the start of epoch (ui , vi ) +
Pi=1
k
i=1 computation associated with the termination of epoch (wi , xi )
Now, we shall analyze the computation involved in each procedure of our algorithm and distribute it
suitably among various epochs.
1.

NAIVE - SETTLE (u)
Observe that whenever the procedure NAIVE - SETTLE(u) is carried out, u is present at level 0, and
√
hence |Ou | < n. The procedure NAIVE - SETTLE(u) searches for a free neighbor of u by scanning
√
Ou . Hence, the time complexity of NAIVE - SETTLE(u) is O(|Ou |) = O( n). Furthermore, this
procedure is called whenever u loses its mate, say v. So we can associate the computation cost of
NAIVE - SETTLE (u) with the termination of the previous epoch (u, v).

2.

RANDOM - SETTLE (u)

3.

√
Observe that whenever RANDOM - SETTLE(u) is invoked, u owns at least n edges incident from level
√
0, and hence |Ou | ≥ n. During RANDOM - SETTLE(u), u finds a random mate from level 0. This
is done by selecting a random number r ∈ [1, |Ou |], and then picking the r th edge, say (u, y), from
the linked list storing Ou . This takes O(|Ou |) time. Vertex u then pulls y to level 1 to satisfy the
third invariant. In this process, y becomes the sole owner of all those edges whose other endpoint is
√
at level 0 (line 2,3). Since y was the owner of at most n edges, the total computation time involved
√
in performing this step is O( n). Other steps in RANDOM - SETTLE can be executed in O(1) time.
√
√
Hence the total computation time is O(|Ou | + n) which is O(|Ou |) since |Ou | ≥ n. We associate
this computation time with the start of the epoch (u, y) that gets created at level 1.
HANDLING - INSERTION (u, v)

√
This procedure takes O(1) time unless one of the endpoints of (u, v) starts owning n edges. In
that case, the procedure invokes RANDOM - SETTLE (line 8) and NAIVE - SETTLE (line 9,10). We have
already distributed the time taken in these procedures to the respective epochs that get created. Excluding these tasks, the only computation performed in this procedure is in the FOR loop. The purpose
√
of this loop is to make u the sole owner of all its edges incident from level 0. Since u owns n edges
√
from level 0, the total computation time involved in performing this step is O( n). We associate this
computation time with the start of the epoch created by u at level 1.
7

4.

HANDLING - DELETION (u, v)
Procedure HANDLING - DELETION(u, v) is carried out when the matched edge (u, v) at level 1 gets
deleted. In addition to invoking RANDOM - SETTLE and NAIVE - SETTLE procedures whose computation cost is already assigned to respective epochs, this procedure scans the list Ou at most twice.
Notice that |Ou | can be Θ(n). We associate this computation time of O(n) with the termination of
the epoch (u, v).

Excluding the updates that cause the start and termination of an epoch of (u, v), every other edge update
on u and v during the epoch is handled in just O(1) time. Therefore, we shall focus only on the amount
of computation associated with the start and termination of an epoch. Let us now analyze the computation
time associated with the epoch at level 0 and level 1.
• Epoch at level 0
As discussed above, it is only the procedure NAIVE - SETTLE whose computation time is associated
√
with an epoch at level 0. This procedure takes O( n) time. Hence the computation time associated
√
with an epoch at level 0 is O( n).
• Epoch at level 1
Consider an epoch at level 1. There are two ways in which this epoch gets created at level 1:
– In HANDLING - INSERTION
An epoch of (u, v) can be created during the procedure HANDLING - INSERTION(u, v). In this
case, the computation time associated with the start of the epoch of (u, v) is the computation
time incurred in executing the procedure HANDLING - INSERTION and the procedure RANDOM SETTLE which it invokes. It follows from the above discussion that the computation cost associ√
√
√
ated with the epoch (u, v) is O( n + |Ou |) which is O( n) since |Ou | = n when we invoke
HANDLING - INSERTION (u, v).
– In HANDLING - DELETION
Procedure HANDLING - DELETION(u, v) invokes RANDOM - SETTLE at lines 4 and 12 to create
new epochs at level 1. The execution of RANDOM - SETTLE at line 4 creates a new epoch for u
and its computation time O(|Ou |), which can be Θ(n), gets associated with the start of the new
epoch created by u. The execution of RANDOM - SETTLE at line 12 creates a new epoch for some
√
vertex w which is some neighbor of u. Note that |Ow | = n. Its computation time, which is
√
O( n), is associated with the start of the epoch at level 1 created by w.
Now let us calculate the computation cost associated with an epoch, say of an edge (u, v), at level 1
when it terminates. It follows from the discussion above that the only computation time associated
with the termination of epoch (u, v) is the computation time of HANDLING - DELETION (excluding the
time spent in procedures RANDOM - SETTLE and NAIVE - SETTLE that are already associated with the
start of their respective epochs). This cost is at most O(n).
From our analysis given above, it follows that the amount of computation time associated with an epoch
√
at level 0 is O( n) and the computation time associated with an epoch at level 1 is O(n).
An epoch of (u, v) may either terminate (if (u, v) is removed from the matching) or remain alive, i.e.,
(u, v) remain in the matching after the end of all the updates. An epoch of (u, v), ends because of exactly
one of the following causes.
(i) if (u, v) is deleted from the graph.
8

epoch of (u, v)
epoch of (u, v)

LEVEL

1
natural epoch

:

epoch of (u, w)
:

induced epoch

epoch of (v, x)

Time

LEVEL

0

epoch of (u, w)
epoch of (v, x)

Figure 3: Epochs at level 0 and 1; the creation of an epoch at level 1 can terminate at most two epochs at
level 0.
(ii) u (or v) get matched to some other vertex leaving its current mate free.
An epoch will be called a natural epoch if it terminates due to cause (i); otherwise it will be called an
induced epoch. Induced epoch can terminate prematurely since, unlike natural epoch, the matched edge is
not actually deleted from the graph when an induced epoch terminates.
It follows from the algorithm described above that every epoch at level 1 is a natural epoch whereas
an epoch at level 0 can be natural or induced depending on the cause of its termination. Furthermore,
each induced epoch at level 0 can be associated with a natural epoch at level 1 whose creation led to the
termination of the former. In fact, there can be at most two induced epochs at level 0 which can be associated
with an epoch at level 1. It can be explained as follows (see Figure 3).
Consider an epoch at level 1 associated with an edge, say (u, v). Suppose it was created by vertex u. If
u was already matched at level 0, let w 6= v be its mate. Similarly, if v was also matched already, let x 6= u
be its current mate at level 0. So matching u to v terminates the epoch of (u, w) as well as the epoch of edge
(v, x) at level 0. We charge the overall cost of these two epochs to the epoch of (u, v). We have seen that
√
the computational cost associated with an epoch at level 0 is O( n). So the overall computation charged to
√
an epoch of (u, v) at level 1 is O(n + 2 n) which is O(n).
Lemma 4.1 The computation charged to a natural epoch at level 1 is O(n) and the computation charged
√
to a natural epoch at level 0 is O( n).
In order to analyze our algorithm, we just need to get a bound on the computation charged to all natural
epochs that get terminated during a sequence of updates or are alive at the end of the all the updates. Let
us first analyze the computation cost charged to all those epochs which are alive at the end of t updates.
Consider an epoch of edge (u, v) that is alive at the end of t updates. If this epoch is at level 0, the computation cost associated with the start of this epoch is O(1). If this epoch is at level 1, then the computation
√
time associated with the start of this epoch is O(|Ou |) and notice that |Ou | ≥ n. Note that there can be at
√
most two induced epochs at level 0 whose computation time, which is O( n), is also charged to the epoch
of (u, v). Hence the computation charged to the live epoch of (u, v) is O(|Ou |). Observe that, at any given
moment of time, Ou ∩ Ow = ∅ for any two vertices u, w presentP
at level 1. Hence the computation time
charged to all live epochs at the end of t updates is of the order of u |Ou | ≤ 2t = O(t). So all we need is
to analyse the computation charged to all natural epochs that get terminated during the sequence of updates.
Let t be the total number of updates. Each natural epoch at level 0 which gets terminated can be assigned
uniquely to the deletion of its matched edge. Hence it follows from Lemma 4.1 that the computation charged
√
to all natural epochs terminated at level 0 during t updates is O(t n). We shall now analyze the number of
epochs terminated at level 1. Our analysis will crucially exploit the following lemma.

9

Lemma 4.2 Suppose vertex v creates an epoch at level 1 during an update in the graph. and let Ovinit be
the set of edges that v owned at the time of the creation of this epoch. Then, for any arbitrary sequence D
of edge deletions of Ovinit , and for any (v, w) ∈ Ovinit
Pr[MATE (v) = w | D] =

1
|Ovinit |

We first carry out the analysis for the high probability bound on the total update time taken by our algorithm.
Thereafter we carry out the analysis for the expected value of the total update time.

4.2 High probability bound on the total update time
The key idea of randomization is that once a vretex v creates an epoch at level 1, there should be many edge
deletions from Ovinit before the matched edge of v is deleted. In order to quanitfy this key idea, we introduce
the following definition that categorizes an epoch as good or bad.
Definition 4.2 An epoch is said to be bad if it gets terminated naturally with in the deletion of the first 1/3
edges that it owned at the time of its creation. An epoch is said to be good if it is not bad.
It follows from Definition 4.2 that a good epoch undergoes many edge deletions before getting terminated.
So only the bad epochs are problematic. Now using Lemma 4.2, we establish an upper bound on the
probability of an epoch to be bad.
Lemma 4.3 Suppose vertex v creates an epoch at level 1 during the kth update for some k ≤ t. Then this
epoch is going to be bad with probability 1/3 irrespective of the future updates in the graph and the random
bits picked during their processing.
Proof: Consider any sequence of updates in the graph following the creation of this epoch. This sequence
defines the sequence D of edge deletions of Ovinit . The termination of this epoch is fully determined by the
mate that v picked and this sequence D. This epoch will be bad if the mate of v is among the endpoints of
the first 1/3 edges in this sequence. Then, Lemma 4.2 implies that the mate of v is equally likely to be the
endpoint of any edge in this sequence. So the probability of the epoch to be bad is 1/3 1 .

For the time complexity analysis, we will show that the number of bad epochs may exceed the number
of good epochs by at most O(log n) with very high probability. Notice that the number of epochs created
at level 1 is itself a random variable whose value may depend upon the updates in the graph as well as the
random bits picked during their processing. However, as shown by Lemma 4.3, each newly created epoch
at level 1 will be bad with probability 1/3 irrespective of the past epochs. The number of epochs created at
level 1 during any t updates is trivially O(nt). Therefore, the sequence of epochs at level 1 can be seen as an
instance of the asymmetric random walk as follows. The walk starts at location 2 log2 n to the right of the
origin. Each step of the walk is one unit to the right of the current location with probability 2/3 or one unit
to the left with probability 1/3 independent of the past moves. We need to find the probability that the walk
ever reaches the origin during any time in the algorithm. It follows from Lemma 3.1 that the probability of
this event is less than 1/n2 . So the following lemma holds immediately.
Lemma 4.4 During any sequence of t updates, the number of bad epoch at level 1 can exceed the number
of good epochs by 2 log2 n with probability at most 1/n2 .
1

The analysis assumed that each edge from Ovinit is going to be deleted sometime in future. If not, place all such edges
arbitrarily at the end of the sequence D. In this case, the probability of the epoch to be bad will be even less than 1/3.

10

As stated in Lemma 4.1, each epoch at level 1 has a computation cost of O(n) charged to it. Let t be the
total number of updates in the graph. For each epoch at level 1, the number of owned edges at the time of
√
√
its creation is at least n. As a result the number of good epochs during t updates is bounded by 4t/ n
√
deterministically. So the computation cost of good epochs at level 1 is bounded by O(t n). Lemma 4.4
implies that the computation cost of all bad epochs at level 1 can exceed the computation cost of all good
epochs at most by cn log n amount for some constant c with probability ≥ 1 − 1/n2 . So overall the cost of
√
all epochs at level 1 is bounded by O((t n + n log n) with high probability. The computation cost of all
√
epochs at level 0 is bounded deterministically by O(t n). Hence the total computation time taken by our
√
algorithm for any sequence of t updates is O(t n + n log n) with high probability.

4.3 Expected value of the total update time
Let Xv,i,k be a random variable which is 1 if v creates an epoch at level i at update step k, otherwise it is 0.
We denote this epoch as EPOCH(v, i, k). Let Zv,i,k denote the number of edges from Ovinit that are deleted
during the epoch. (If EPOCH(v, i, k) is not created, Zv,i,k is defined
P as 0). Since each edge deletion at level
1 is uniquely associated to the epoch that owned it. Therefore, v,k Zv,1,k ≤ t. Hence,
X
v,k

E[Zv,1,k ] ≤ t

(1)

We shall now derive a bound on the expected value of Zv,1,k in an alternate way.
√
Lemma 4.5 E[Zv,1,k ] ≥ n/2 · Pr[Xv,1,k = 1].
Proof: We shall first find the expectation of Zv,1,k conditioned on the event that v creates an epoch at
level 1 during kth update. That is, we shall find E[Zv,1,k |Xv,1,k = 1]. Let Ovinit be the set of edges
owned by v at the moment of creation of EPOCH(v, 1, k), and let D be the deletion sequence associated
with Ovinit . It follows from Lemma 4.2 that the matched egde of v is distributed uniformly over Ovinit . So
√
√
E[Zv,1,k |Xv,1,k = 1] = |Ovinit |/2 ≥ n/2 since |Ovinit | for an epoch at level 1 is at least n. Using
conditional expectation, we get
√
E[Zv,1,k ] = E[Zv,1,k |Xv,1,k = 1] · Pr[Xv,1,k = 1] ≥ n/2 · Pr[Xv,1,k = 1]

Notice that the computation cost of an epoch at level 1 is at most cn for some constant c. So the expected
value of the computation cost associated with all natural epochs that get terminated at level 1 during t
updates is
X
√ X√
n/2 · Pr[Xv,1,k = 1]
cn · Pr[Xv,1,k = 1] = 2c n
v,k

v,k

√ X
≤ 2c n
E[Zv,1,k ]
√
≤ 2c nt

using Lemma 4.5

v,k

using Equation 1

We can thus conclude with the following theorem.
Theorem 4.1 Starting with a graph on n vertices and no edges, we can maintain maximal matching for any
√
√
sequence of t updates in O(t n) time in expectation and O(t n + n log n) with high probability.

11

√
4.4 On improving the update time beyond O( n)
In order to extend our 2-LEVEL algorithm for getting a better update time, it is worth exploring the reason
√
underlying O( n) update time guaranteed by our 2-LEVEL algorithm. For this purpose, let us examine the
second invariant more carefully. Let α(n) be the threshold for the maximum number of edges that a vertex
at level 0 can own. Consider an epoch at level 1 associated with some edge, say (u, v). The computation
associated with this epoch is of the order of the number of edges u and v own which can be Θ(n) in the
worst case. However, the expected duration of the epoch is of the order of the minimum number of edges u
can own at the time of its creation, i.e., Θ(α(n)). Therefore, the expected amortized computation per edge
deletion for an epoch at level 1 is O(n/α(n)). Balancing this with the α(n) update time at level 0, yields
√
α(n) = n.
In order to improve the running time of our algorithm, we need to decrease the ratio between the maximum and the minimum number of edges a vertex can own during an epoch at any level. It is this ratio that
determines the expected amortized time of an epoch. This insight motivates us for having a finer partition of
vertices – the number of levels should be increased to O(log n) instead of just 2. When a vertex creates an
epoch at level i, it will own at least 2i edges, and during the epoch it will be allowed to own at most 2i+1 − 1
edges. As soon as it owns 2i+1 edges, it should migrate to higher level. Notice that the ratio of maximum to
√
minimum edges owned by a vertex during an epoch gets reduced from n to a constant.
We pursue the approach sketched above combined with some additional techniques in the following
section. This leads to a fully dynamic algorithm for maximal matching which achieves expected amortized
O(log n) update time per edge insertion or deletion.

5 Fully dynamic algorithm with expected amortized O(log n) time per update
This algorithm maintain a partition of vertices among various levels. We describe the difference in this
partition vis-a-vis 2-LEVEL algorithm.
1. The fully dynamic algorithm maintains a partition of vertices among ⌊log4 n⌋ + 2 levels. The levels
are numbered from −1 to L0 = ⌊log4 n⌋. During the algorithm, when a vertex moves to level i, it
owns at least 4i edges. So a vantage point is needed for a vertex that does not own any edge. As a
result, we introduce a level -1 that contains all the vertices that do not own any edge.
2. We use the notion of ownership of edges which is slightly different from the one used in the 2-LEVEL
algorithm. In the 2-LEVEL algorithm, at level 0, both the endpoints of the edge are the owner of the
edge. Here, at every level, each edge is owned by exactly one of its endpoints. If the endpoints of the
edge are at different levels, the edge is owned by the endpoint that lies at the higher level. If the two
endpoints are at the same level, then the tie is broken appropriately by the algorithm.
Like the 2-LEVEL algorithm, each vertex u will maintain a dynamic hash table storing the edges Ou
owned by it. In addition, the generalized fully dynamic algorithm will maintain the following data structure
for each vertex u. For each i ≥ LEVEL (u), let Eui be the set of all those edges incident on u from vertices at
level i that are not owned by u. The set Eui will be maintained in a dynamic hash table. However, the onus
of maintaining Eui will not be on u. For any edge (u, v) ∈ Eui , v will be responsible for the maintenance of
(u, v) in Eui since (u, v) ∈ Ov . For example, suppose vertex v moves to level j. If j > LEVEL (u), then v
will remove (u, v) from Eui and insert it to Euj . Otherwise ( (j ≤ LEVEL (u)), v will remove (u, v) from Eui
and insert it to Ou .

12

3
2
v

1
0

x

−

1

Figure 4: A snapshot of the algorithm on K9 : all vertices are matched( thick edges) except vertex x at level
−1. φv (2) = 4 < 42 and φv (3) = 6 < 43 , so v cannot rise to a higher level.

5.1 Invariants and a basic subroutine used by the algorithm
As can be seen from the 2-level algorithm, it is advantageous for a vertex to get settled at a higher level once
it owns a large number of edges. Pushing this idea still further, our fully dynamic algorithm will allow a
vertex to rise to a higher level if it can own sufficiently large number of edges after moving there. In order
to formally define this approach, we introduce an important notation here.
For a vertex v with LEVEL (v) = i,

P
|Ov | + i≤k<j |Evk | if j > i
φv (j) =
0
otherwise
In other words, for any vertex v at level i and any j > i, φv (j) denote the number of edges which v can
own if v rises to level j. Our algorithm will be based on the following key idea. If a vertex v has φv (j) ≥ 4j ,
then v would rise to the level j. In case, there are multiple levels to which v can rise, v will rise to the highest
such level. With this key idea, we now describe the three invariants which our algorithm will maintain.
1. Every vertex at level ≥ 0 is matched and every vertex at level −1 is free.
2. For each vertex v and for all j >

LEVEL (v),

φv (j) < 4j holds true.

3. Both the endpoints of a matched edge are at the same level.
It follows that the free vertices, if any, will be present at level −1 only. Any vertex v present at level −1 can
not have any neighbor at level −1. Otherwise, it would imply that φv (0) ≥ 1 = 40 , violating the second
invariant. Hence, every neighbor of a free vertex must be matched. This implies that the algorithm will
always maintain a maximal matching. Furthermore, the key idea of our algorithm is captured by the second
invariant – after processing every update there is no vertex which fulfills the criteria of rising. Figure 4
depicts a snapshot of the algorithm.
An edge update may lead to the violation of the invariants mentioned above and the algorithm basically
restores these invariants. This may involve rise or fall of vertices between levels. Notice that the second
invariant of a vertex is influenced by the rise and fall of its neighbors. We now state and prove two lemmas
which quantify this influence more precisely.
Lemma 5.1 The rise of a vertex v does not violate the second invariant for any of its neighbors.

13

Proof: Consider any neighbor u of v. Let LEVEL (u) = k. Since the second invariant holds true for u before
the rise of v, so φu (i) < 4i for all i > k. It suffices if we can show that φu (i) does not increase for any i
due to the rise of v. We show this as follows.
Let vertex v rise from level j to ℓ. If ℓ ≤ k, the edge (u, v) continues to be an element of Ou , and so
there is no change in φu (i) for any i. Let us consider the case when ℓ > k. The rise of v from j to ℓ causes
removal of (u, v) from Ou (or Euj if j ≥ k) and insertion to Euℓ . As a result φu (i) decreases by one for each
i in [max(j, k) + 1, ℓ], and remains unchanged for all other values of i.

Lemma 5.2 Suppose a vertex v falls from level j to j − 1. As a result, for any neighbor u of v, φu (i)
increases by at most 1 for i = j and remains unchanged for all other values of i.
Proof: Let LEVEL (u) = k. In case k ≥ j, there is no change in φu (i) for any i due to fall of v. So let us
consider the case j > k. In this case, the fall of v from level j to j − 1 leads to the insertion of (u, v) in
Euj−1 and deletion from Euj . Consequently, φu (i) increases by one only for i = j and remains unchanged for
all other values of i.

In order to detect any violation of the second invariant for a vertex v due to rise or fall of its neighbors,
we shall maintain {φv (i)|i ≤ L0 } in an array φv [] of size L0 + 2. The updates on this data structure during
the algorithm will involve the following two types of operations.
•

This operation decrements φv (i) by one for all i in interval I. This operation
will be executed when some neighbor of v rises. For example, suppose some neighbor of v rises from
level j to ℓ, then φv (i) decreases by one for all i in interval I = [max(j, LEVEL (v)) + 1, ℓ].

•

INCREMENT-φ(v, i): this operation increases φv (i) by one. This operation will be executed when
some neighbor of v falls from i to i − 1.

DECREMENT-φ(v, I):

It can be seen that a single DECREMENT-φ(v, I) operation takes O(|I|) time which is O(log n) in the worst
case. On the other hand any single INCREMENT-φ(v, i) operation takes O(1) time. However, since φv (i) is
0 initially and is non-negative always, we can conclude the following.
Lemma 5.3 The computation cost of all DECREMENT-φ() operations over all vertices is upper-bounded by
the computation cost of all INCREMENT-φ() operations over all vertices during the algorithm.
Observation 5.1 It follows from Lemma 5.3 that we just need to analyze the computation involving all
INCREMENT-φ() operations since the computation involved in DECREMENT-φ() operations is subsumed by
the former.
If any invariant of a vertex, say u, gets violated, it might rise or fall, though in some cases, it may still
remain at the same level. However, in all these cases, eventually the vertex u will execute the procedure,
GENERIC - RANDOM - SETTLE , shown in Figure 5. This procedure is essentially a generalized version of
RANDOM - SETTLE (u) which we used in the 2-level algorithm. GENERIC - RANDOM - SETTLE (u, i) starts with
moving u from its current level (LEVEL (u)) to level i. If level i is higher than the previous level of u, then
u performs the following tasks. For each edge (u, w) already owned by it, u informs w about its rise to
level i by updating Ewi . In addition u acquires the ownership of all the edges whose other endpoint lies at a
level ∈ [LEVEL (u), i − 1]. For each such edge (u, w) that is now owned by u, we perform DECREMENTφ(w, [LEVEL (w) + 1, i]) to reflect that the edge is now owned by vertex u which has moved to level i.
Henceforth, the procedure then resembles RANDOM - SETTLE. It finds a random edge (u, v) from Ou and
moves v to level i. The procedure returns the previous mate of v, if v was matched. We can thus state the
following lemma.
14

Lemma 5.4 Consider a vertex u that executes GENERIC - RANDOM - SETTLE(u, i) and selects a mate v.
Excluding the time spent in DECREMENT-φ operations, the computation time of this procedure is of the
order of |Ou | + |Ov | where Ou and Ov is the set of edges owned by u and v just at the end of the procedure.

Procedure G E N E R I C - R A N D O M - S E T T L E (u, i)
1 if LEVEL (u) < i then
2
for each (u, w) ∈ Ou do
LEVEL(u)
3
transfer (u, w) from Ew
to Ewi ;
4
DECREMENT-φ(w, [LEVEL (u) + 1, i]);
5
6
7
8
9
10
11
12
13
14
15

16
17
18
19
20
21
22
23
24
25
26
27
28

//u rises to level i
//u informs w about its rise

for each j = LEVEL (u) to i − 1 do
for each (u, w) ∈ Euj do
transfer (u, w) from Euj to Ewi ;
transfer (u, w) from Ow to Ou ;
DECREMENT-φ(w, [j + 1, i]);

//u gains ownership of some more edges

foreach j = LEVEL (u) + 1 to i do φu (j) ← 0;
← i;

LEVEL (u)

Let (u, v) be a uniformly randomly selected edge from Ou ;
if v is matched then
x ← MATE (v);
M ← M\{(v, x)};
else
x ← NULL ;
for each (v, w) ∈ Ov do
LEVEL(v)
transfer (v, w) from Ew
to Ewi ;
DECREMENT-φ(w, [LEVEL (v) + 1, i]);

//v informs w about its rise

for each j = LEVEL (v) to i − 1 do
for each (v, w) ∈ Evj do
transfer (v, w) from Evj to Ewi ;
transfer (v, w) from Ow to Ov ;
DECREMENT-φ(w, [j + 1, i]);

//v gains ownership of some more edges

M ← M ∪ {(u, v)};
foreach j = LEVEL (v) + 1 to i do φv (j) ← 0;
LEVEL (v) ← i ;
return x;

/*v rises to level i*/

Figure 5: Procedure used by a free vertex u to settle at LEVEL i.

5.2 Handling edge updates by the fully dynamic algorithm
Our fully dynamic algorithm will employ a generic procedure called PROCESS - FREE - VERTICES(). The
input to this procedure is a sequence S consisting of ordered pairs of the form (x, k) where x is a free
vertex at level k ≥ 0. Observe that the presence of free vertices at level ≥ 0 implies that matching M
15

is not necessarily maximal. In order to preserve maximality of matching, the procedure PROCESS - FREE VERTICES restores the invariants of each such free vertex till S becomes empty. We now describe our fully
dynamic algorithm.
Handling deletion of an edge
Consider deletion of an edge, say (u, v). For each j > max(LEVEL (u), LEVEL (v)), we decrement φu (j)
and φv (j) by one. If (u, v) is an unmatched edge, no invariant gets violated. So we only delete the edge
(u, v) from the data structures of u and v. Otherwise, let k = LEVEL (u) = LEVEL (v). We execute the
Procedure PROCESS - FREE - VERTICES(h(u, k), (v, k)i).
Handling insertion of an edge
Consider insertion of an edge, say (u, v). Without loss of generality, assume that initially u was at the same
LEVEL(u)
level as v or a higher level than v. So we add (u, v) to Ou and Ev
. For each j > max(LEVEL (u), LEVEL (v)),
we increment φu (j) and φv (j) by one. We check if the second invariant has got violated for either u or v.
This invariant may get violated for u (likewise for v) if there is any integer i > max(LEVEL (u), LEVEL (v)),
such that φu (i) has become 4i just after the insertion of edge (u, v). In case there are multiple such integers,
let imax be the largest such integer. To restore the invariant, u leaves its current mate, say w, and rises to level
imax . We execute GENERIC - RANDOM - SETTLE(u, imax ), and let x be the vertex returned by this procedure.
Let j and k be respectively the levels of w and x. Note that x and w are two free vertices now. We execute
PROCESS - FREE - VERTICES (h(x, k), (w, j)i).
If the insertion of edge (u, v) violates the second invariant for both u and v, we proceed as follows. Let
j be the highest level to which u can rise after the insertion of (u, v), that is, φu (j) = 4j . Similarly, let ℓ
be the highest level to which v may rise, that is, φv (ℓ) = 4ℓ . If j ≥ ℓ, we allow only u to rise to level j;
otherwise
edge (u, v) becomes an element of
P we allow only v to rise to ℓ. Note that after u moves to level j, P
Evj . So LEVEL(v)≤k<ℓ |Evk | decreases by 1. As a result, φv (ℓ) = |Ov | + LEVEL(v)≤k<ℓ |Evk | also decreases
by 1 and is now strictly less than 4ℓ ; thus the second invariant for v is also restored.
5.2.1

Description of Procedure PROCESS - FREE - VERTICES

The procedure receives a sequence S of ordered pairs (x, i) such that x is a free vertex at level i. It processes
the free vertices in a decreasing order of their levels starting from L0 . We give an overview of this processing
at level i. For a free vertex at level i, if it owns sufficiently large number of edges, then it settles at level i
and gets matched by selecting a random edge from the edges owned by it. Otherwise the vertex falls down
by one level. Notice that the fall of a vertex from level i to i − 1 may lead to rise of some of its neighbors
lying at level < i. However, as follows from Lemma 5.2, for each such vertex v, only φv (i) increases by
one and φv () value for all other levels remains unchanged. So the second invariant may get violated only for
φv (i). This implies that v will rise only to level i. After these rising vertices move to level i (by executing
GENERIC - RANDOM - SETTLE ), we move onto level i − 1 and proceed similarly. Overall, the entire process
can be seen as a wave of free vertices falling level by level. Eventually this wave of free vertices reaches
level −1 and fades away ensuring maximal matching. With this overview, we now describe the procedure
in more details and its complete pseudocode is given in Figure 6.
The procedure uses an array Q of size L0 + 2, where Q[i] is a pointer to a queue (initially empty)
corresponding to level i. For each ordered pair (x, k) ∈ S, it inserts x into queue Q[k]. The procedure
executes a FOR loop from L0 down to 0 where the ith iteration extracts and processes the vertices of queue
Q[i] one by one as follows. Let v be a vertex extracted from Q[i]. First we execute the function FALLING(v)
which does the following. v disowns all its edges whose other endpoint lies at level i. If v owns less than 4i
16

Procedure P R O C E S S - F R E E - V E R T I C E S (S)
1 for each (x, i) ∈ S do ENQUEUE(Q[i], x);
2 for i = L 0 to 0 do
3
while (Q[i] is not EMPTY) do
4
v ← DEQUEUE(Q[i]);
5
if FALLING(v) then
6
LEVEL (v) ← i − 1;
7
ENQUEUE(Q[i − 1], v);
9
8
for each (u, v) ∈ Ov do
10
transfer (u, v) from Eui to Eui−1 ;
11
INCREMENT-φ(u, i);
12
INCREMENT-φ(v, i);
13
if φu (i) ≥ 4i then
14
x ← GENERIC - RANDOM - SETTLE(u, i);
15
if x 6= NULL then
16
j ← LEVEL (x);
17
ENQUEUE(Q[j], x);

//v falls to i − 1

//u rises to i

18

19
20
21
22

else
x ← GENERIC - RANDOM - SETTLE(v, i);
if x 6= NULL then
j ← LEVEL (x);
ENQUEUE(Q[j], x);

Function F A L L I N G (v)
i ← LEVEL (v);
2 for each (u, v) ∈ Ov such that LEVEL(u) = i do
3
transfer (u, v) from Ov to Ou ;
4
transfer (u, v) from Eui to Evi ;

//v settles at level i

1

5

//v disowns all edges at level i

if |Ov | < 4i then return TRUE else return FALSE;

Figure 6: Procedure for processing free vertices given as a sequence S of ordered pairs (x, i) where x is a
free vertex at LEVEL i.

17

edges then v falls to level i − 1, otherwise v will continue to stay at level i. The processing of the free vertex
v for each of these two cases is done as follows.
1. v has to stay at level i.
v executes GENERIC - RANDOM - SETTLE and selects a random mate, say w, from level j < i (if w is
present in Q[j] then it is removed from it and is raised to level i). If x was the previous mate of w,
then x is a falling vertex. Vertex x gets added to Q[j]. This finishes the processing of v.
2. v has to fall.
In this case, v falls to level i − 1 and is inserted to Q[i − 1]. At this stage, Ov consists of neighbors
of v from level i − 1 or below. It follows from Lemma 5.2 that the fall of v from i to i − 1 leads to
increase in φu (i) by one for each neighbor u of v which is present at a level lower than i. Moreover,
φv (i), that was 0 initially, has to be set to |Ov |. So all the vertices of Ov are scanned, and for each
(u, v) ∈ Ov , we increment φu (i) and φv (i) by 1. In case φu (i) has become 4i , u has to rise to level i
and is processed as follows. u executes GENERIC - RANDOM - SETTLE(u, i) to selects a random mate,
say w, from level j < i. If w was in Q[j] then it is removed from it. If x was the previous mate of w,
then x is a falling vertex, and so it gets added to queue Q[j].
Remark 5.1 Notice a stark similarity between the above procedure for handling a free vertex and the procedure for handling a free vertex at level 1 in the 2-level algorithm.
In case 1, v remains at level i and w moves to the level i from some level j < i. This renders vertex x
(earlier mate of w) free and the first invariant of x is violated. So x is added to the queue at level j. The
processing of v does not change φu () for any neighbor u of v. Furthermore, the rise of w to level i does not
lead to violation of any invariant due to Lemma 5.1. In case 2, v falls to level i − 1 and as a result some
vertices may rise to level i. Each such rising vertex executes GENERIC - RANDOM - SETTLE. As in case 1,
the processing of these rising vertices may create some free vertices only at level < i. We can thus state the
following lemma.
Lemma 5.5 After ith iteration of the for loop of PROCESS - FREE - VERTICES, the free vertices are present
only in the queues at level < i, and for all vertices not belonging to these queues the three invariants holds.
Lemma 5.5 establishes that after termination of procedure PROCESS - FREE - VERTICES, there are no free
vertices at level ≥ 0 and all the invariants get restored globally.

5.3 Analysis of the algorithm
Processing the deletion or insertion of an edge (u, v) begins with decrementing or incrementing φu (i) and
φv (i) for each level j > max(LEVEL (u), LEVEL (v)). Since there are O(log n) levels, the computation
associated with this task over any sequence of t updates will be O(t log n). This task may be followed by
executing the procedure PROCESS - FREE - VERTICES that restores the invariants and updates the matching
accordingly. The updates in the matching can be seen as creation of new epochs and termination of some of
the existing epochs. Like 2-level algorithm, for the purpose of analysis, we visualize the entire algorithm as
a sequence of creation and termination of various epochs. Excluding the O(t log n) time for maintaining φ,
the total computation performed by the algorithm can be associated with all the epochs that get terminated
and those that remain alive at the end of the sequence of updates. Along exactly similar lines as in 2-level
algorithm, the computation associated with all the epochs that are alive at the end of t updates is O(t) only.
So we just need to focus on the epochs that get terminated and the computation associated with each of
them.

18

Let us first analyse the computation associated with an epoch of a matched edge (u, v). Suppose this
epoch got created by vertex v at level j. So v would have executed GENERIC - RANDOM - SETTLE and selected
u as a random mate from level < j. Note that v must be owning less than 4j+1 edges and u would be owning
at most 4j edges at that moment. This observation and Lemma 5.4 imply that the computation involved in the
creation of the epoch is O(4j ). Once the epoch is created, any update pertaining to u or v will be performed
in just O(1) time until the epoch gets terminated. Let us analyze the computation performed when the
epoch gets terminated. At this moment either one or both u and v become free vertices. If v becomes free, v
executes the following task (see procedure PROCESS - FREE - VERTICES in Figure 6): v scans all edges owned
by it, which is less than 4j+1 , and disowns those edges incident from vertices of level j. Thereafter, if v still
owns at least 4j edges, it settles at level j and creates a new epoch at level j. Otherwise, v keeps falling one
level at a time. For a single fall of v from level i to i − 1, the computation performed involves the following
tasks: scanning the edges owned by v, disowning those incident from vertices at level i, incrementing φw
values for each neighbor w of v lying at level less than i, and updating φv (i) to |Ov |. All this computation
is of the order of the number of edges v owns at level i which is less than 4i+1 . Eventually either v settles at
some level k ≥ 0 and becomes part
Pof a new epoch or it reaches level −1. The total computation performed
by v is, therefore, of the order of ji=k 4i+1 = O(4j ). This entire computation involving v (and u) in this
process is associated with the the epoch of (u, v). Hence we can state the following Lemma.
Lemma 5.6 For any i ≥ 0, the computation associated with an epoch at level i is O(4i ).
An epoch corresponding to edge (u, v) at level i could be terminated if the matched edge (u, v) gets
deleted. Such an epoch is called a natural epoch. However, this epoch could be terminated due to one of the
following reasons also.
• u (or v) get selected as a random mate by one of their neighbors present at LEVEL > i.
• u (or v) starts owning 4i+1 or more edges.
Each of the above factors render the epoch to be an induced epoch. For any level i > 0, the creation of an
epoch causes termination of at most two epochs at levels < i. It can be explained as follows: Consider an
epoch at level i associated with an edge, say (u, v). Suppose it was created by vertex u. If u was already
matched at some level j < i, let w 6= v be its mate. Similarly, if v was also matched already at some level
k < i, let x 6= u be its mate. So matching u to v terminates the epoch of (u, w) and (v, x) at level j and k
respectively. We can thus state the following lemma.
Lemma 5.7 Creation of an epoch at a level i may cause termination of at most 2 epochs at level < i.
5.3.1

Analysing an epoch

Consider an epoch created by a vertex v at level i. At the time of the creation of the epoch, let Ovinit be
the set of edges owned by v, and let w = MATE(v). This epoch may terminate much before the deletion
of (v, w). This happens when v or w moves to some level > i before the deletion of (v, w). In order to
analyse termination of an epoch, therefore, we associate an update sequence with it as follows. For each
edge (v, x) ∈ Ovinit , we consider the first time in future that x moves to some higher level 2 . The update
label associated with edge (v, x) is defined as
if x moves to a level > i before its deletion then it is classified as upward else it is deletion.
2

vertex x may move to level > i (and down) multiple times while the algorithm processes a sequence of updates. However, it
is only the first time (after the creation of the epoch) when x moves to a level > i that is relevant as far as the possibility of the
termination of the epoch by the upward movement of x is concerned.

19

Likewise, we also consider the first time in future that v moves to a level > i. If v never moves to any level
> i in future, we just append v at the end of all the updates associated with Ovinit . The update sequence U for
the epoch is the sequence of these updates on the edges of Ovinit and vertex v arranged in the chronological
order. Consider the following example. Suppose Ovinit has 10 edges and let the corresponding neighbors
of v be {w1 , . . . , w10 }. Let the updates in the chronological order be : the deletion of (v, w4 ), upward
movement of w1 , upward movement of w9 , the deletion of (v, w5 ), and so on. The corresponding update
sequence will be
•

↑

↑

•

•

•

↑

↑

•

↑

•

U : h w4 , w1 , w9 , w5 , w8 , w3 , w2 , v, w7 , w10 , w8 i
Observation 5.2 If the update associated with (the owner) v appears at ℓth location in U , then the epoch
will terminate on or before the ℓth update in U . Therefore, the updates at location > ℓ in U will have no
influence on the termination of the epoch.
Unlike the 2-level algorithm, the update sequence associated with an epoch is not uniquely defined by the
sequence of updates in the graph after the creation of the epoch. Rather, it also depends upon the current
matching as well as the random bits chosen by the algorithm while processing the updates. So there is
a probability distribution defined over all possible update sequences that depends upon these two factors.
Consequently, the analysis of an epoch in our final algorithm is more complex compared to the 2-level
algorithm. In particular, it is not obvious whether there is any dependence between the random mate picked
by a vertex while creating an epoch and the sequence of updates associated with the epoch. However, using
an interesting non-trivial property of our algorithm, we will establish that there is no dependence between
the two.
Lemma 5.8 Suppose a vertex v creates an epoch and let Ovinit be the set of its owned edges at the time of
the creation of this epoch. Then, for any update sequence U and for each (v, w) ∈ Ovinit ,
Pr[MATE (v) = w | U ] = Pr[MATE (v) = w] =

1
|Ovinit |

Lemma 5.8 can be seen as a generalization of Lemma 4.2 that we stated for our 2-level algorithm. Its proof
is given in Section 5.4. The analysis of our algorithm will be critically dependent on this lemma. Using this
lemma, we shall first establish a high probability bound on the total update time of the algorithm to process
a sequence of updates in the graph.
5.3.2

High probability bound on the total update time

Recall Definition 4.2 of a bad epoch. It can be observed from this definition that an induced epoch is always
a good epoch. Using Lemma 5.8, the lemma for the probability of a bad epoch extends seamlessly from
2-level algorithm to our final algorithm as follows.
Lemma 5.9 Suppose vertex v creates an epoch at level i while the algorithm processes kth update in the
graph. This epoch will be bad with probability at most 1/3 irrespective of the updates in the graph and the
random bits picked during their processing.
Proof: The termination of the epoch is completely determined by the mate that v picks and the update
sequence associated with this epoch. Consider any update sequence U associated with this epoch. It follows
from Lemma 5.8 that conditioned on U , the mate of v is equally likely to be the endpoint of any edge in
20

Ovinit . Now recall from Observation 5.2 that for the epoch to be terminated naturally, the mate of v must be
among the endpoints of the deleted edges that precede v in U . We distinguish between the following two
cases.
Case1. There are less than |Ovinit |/3 edge deletions preceding v in U .
The epoch will be bad only if the matched edge of v is one of these edge deletions preceding v in U .
Since the number of these edge deletions is less than |Ovinit |/3, so using Lemma 5.9 the probability
of the epoch to be bad is less than 1/3.
Case2. There are at least |Ovinit |/3 edge deletions preceding v in U .
The epoch will be bad if the matched edge of v is one of the first |Ovinit |/3 edge deletions in U . From
Lemma 5.8, the termination of the epoch is equiprobable for any of the Ovinit ’s, so the probability that
the epoch is bad in this case is exactly 1/3.
It follows that the epoch is going to be bad with probability 1/3 for each possible update sequence U associated with the epoch.

We will show that the number of bad epochs at a level i could exceed the number of good epochs at
level i by at most O(log n) with very high probability. Notice that the number of epochs created at level i
is itself a random variable. During any update, the number of epochs that will be created at level i depends
upon the past updates in the graph and the random bits picked during their processing. However, Lemma
5.9 implies that each newly created epoch at level i will be bad with probability at most 1/3 independent of
these events. Hence, the sequence of epochs at level i can be seen as an instance of the asymmetric random
walk as established in the analysis of the 2-level algorithm. So the bad epochs at any level i may exceed the
good epochs by 2 log 2 n with probability at most 1/n2 . There are O(log n) levels in the hierarchy. Hence
we get the following lemma using union bound.
Lemma 5.10 For every level i ≤ L0 , the number of bad epochs will not exceed the number of good epochs
by more than 2 log2 n with probability at least 1 − (log n)/n2 > 1 − 1/n.
Let us temporarily exclude the maximum surplus of O(log n) bad epochs at each level from our analysis.
Consequently, it follows from Lemma 5.10 that each bad epoch at a level can be mapped to a good epoch
at the same level in a unique manner - see Figure 7(i). Also the creation of each epoch at a level i + 1
can terminate at most two (induced) epochs at lower levels as stated in Lemma 5.7. Using this fact and
the mapping between the good and bad epochs at a level, we can construct a forest whose nodes will be
the epochs terminated across all levels during the algorithm. The intuition for defining this forest is that
eventually the computation cost of a bad epoch or an induced epoch will be charged to a good natural epoch.
Since a good natural epoch has sufficiently large number of edge deletions associated with it, these edge
deletions can be charged to pay for all the computation carried out by our algorithm.
With this intuition, we now provide the construction of the forest by defining parent of each epoch using
the following rules.
1. Parent of each induced epoch is the epoch at the higher level whose creation led to its termination.
2. Parent of a good epoch is itself (hence it is the root of its tree).
3. If a bad epoch is mapped to an induced epoch, then its parent is the same as the parent of the induced
epoch. Otherwise, it is the parent of itself (hence it is the root of its tree).

21

... ...

. . .a

...

b ...

...

c

g. . .

d. . .

g

i+1

a

i

b

A natural good epoch
An induced epoch
A bad epoch
c

d

(ii)

(i)

Figure 7: (i) Mapping between bad and good epochs at level i (ii) Assigning at most 4 epochs from lower
levels to an epoch.
It follows from rule 1 and 3 (the if part) that with an epoch at a level, at most 4 epochs from lower levels
can be associated. Hence each node in the forest will have at most four children. See Figure 7(ii). Moreover,
the root of each tree in the forest of epochs is either a bad epoch or a good natural epoch. Using Lemma
5.6, the computation cost C(i) associated with a tree of epochs whose root is at level i obeys the following
recurrence for some constant a.
C(i) = a4i + 4C(i − 1)

The solution of this recurrence is C(i) = O(i4i ). It follows from Lemma 5.10 and rule 3(Otherwise part)
that the trees rooted at good natural epochs at a level i are at least the number of trees rooted at bad epochs at
level i. Hence, it suffices to analyze the computation cost associated with all the tree rooted at good natural
epochs. Now for each good natural epoch at a level i, there are at least 4i /3 edge deletions associated
uniquely to it. This natural epoch will be charged for the computation cost C(i) = O(i4i ) associated with
the tree rooted at it. So if t is the total number of updates in the graph, then the computation cost associated
with all epochs
P in the forest is O(t log n). The computation cost associated with surplus bad epochs at all
levels is O( i i4i log n) = O(n log2 n). Hence with high probability the computation cost for processing
t edge updates by the algorithm is O(t log n + n log2 n). This also implies that the total expected update
time is O(t log n) for t = Ω(n log n). In the following subsection, we will establish O(t log n) bound on
the expected update time for all values of t.
5.3.3

Expected value of the total update time

During a sequence of t updates in the graph, various epochs get created by various vertices at various levels.
Let Xv,i,k be a random variable which is 1 if v creates an epoch at level i at update step k, otherwise it
is 0. We denote this epoch as EPOCH(v, i, k). Let Ovinit denote the edges that v owned at the time of the
creation of the epoch. Let Zv,i,k denote the number of edges from Ovinit that are deleted during the epoch.
(If EPOCH(v, i, k) is not created, Zv,i,k is defined as 0). The key role in bounding the expected running time
is played by a random variable Bv,i,k defined as follows:
(
(8Zv,i,k − 2 · 4i )Xv,i,k if EPOCH (v, i, k) is natural
(2)
Bv,i,k =
(4i+1 − 2 · 4i )Xv,i,k
if EPOCH (v, i, k) is induced
First observe that Bv,i,k = 0 if Xv,i,k = 0. Else (if Xv,i,k = 1), the random variable Bv,i,k can be seen
as credits associated with EPOCH(v, i, k) to be used for paying its computation cost. For a natural epoch, the
credits is defined in terms of the edges deleted during the epoch. So we define Bv,i,k to be 8Zv,i,k . However,
we need to discount for the two epochs at lower levels that may get terminated due to EPOCH(v, i, k). To
this end, from the term, we deduct 2 · 4i . Similarly, if EPOCH(v, i, k) is an induced epoch, then it gets 4i+1
credits from the epoch that destroyed it. But here again we need to discount for the two epochs at lower
22

i
i+1
levels that might be
P terminated by it. To this end, we again deduct 2 · 4 from 4 . The following lemma
gives a bound on Bv,i,k .

Lemma 5.11

P

v,i,k

Bv,i,k ≤ 8

P

v,i,k

Zv,i,k ≤ 8t, where t is the total number of updates in the graph.

Proof: We need to analyze the sum of Bv,i,k ’s for all those (i, v, k) values for which the EPOCH(i, v, k)
got created. If this epoch is an induced epoch, it can be associated with an epoch, say EPOCH(v ′ , i′ , k′ ), at
′
term in Bv′ ,i′ ,k′ cancels out
a higher level i′ > i whose creation destroyed it. Notice that the negative 4i P
the positive 4i+1 term in Bv,i,t . Hence, the contribution of induced epochs P
in v,i,k Bv,i,k is P
nullified and
all that remains is the sum of terms 8Zv,i,k for each natural epoch. Hence v,i,k Bv,i,k ≤ 8 v,i,k Zv,i,k .
An edge deletion
is associated with an epoch in a unique manner, so will contribute to exactly one Zv,i,k .
P
Therefore, v,i,k Zv,i,k is upper bounded by the total number of edges deleted.

P

Corollary 5.0.1

v,i,k

E[Bv,i,k ] ≤ 8t

Lemma 5.12 For all i, v, k, E[Bv,i,k ] ≥ Pr[Xv,i,k = 1] · 4i .
Proof: Since Xv,i,k is an indicator random variable, E[Bv,i,k ] = Pr[Xv,i,k = 1] E[Bv,i,k | Xv,i,k = 1]. We
will first estimate E[Bv,i,k | Xv,i,k = 1], that is, the expected value of Bv,i,k given that EPOCH(v, i, k) got
created.
Let (U , P ) be the probability space of all the update sequences associated with this epoch and let U ∈ U
be any update sequence. Suppose among the updates in U that precede the update associated with v, only
d are edge deletions. It follows from Lemma 5.8 that the matched edge of v is distributed uniformly over
Ovinit . So EPOCH(v, i, k) will be an induced epoch with probability (|Ovinit | − d)/|Ovinit | and in that case
B(v, i, k) will be 4i+1 − 2 · 4i . If the epoch is natural, it couldP
be due to any one of the d edge deletions
present in U . In that case the expected value of Bv,i,k will be 1/d dj=1 (8j −2·4i ) ≥ 4d−2·4i . Considering
the cases of induced and natural epoch together,
E[Bv,i,k | U ] =

d
4i+1 d − 4d2
|Ovinit | − d i+1
i
i
i
(4
−
2
·
4
)
+
(4d
−
2
·
4
)
=
2
·
4
−
|Ovinit |
|Ovinit |
|Ovinit |
4i · 4i
≥ 2 · 4i − init (for all values of d)
|Ov |

Therefore
E[Bv,i,k ] =

X

U ∈U

E[Bv,i,k | U ] · Pr[U ] ≥



4i · 4i
2 · 4 − init
|Ov |
i

Since |Ovinit | ≥ 4i , for level i, the result follows.

 X
4i · 4i
·
Pr[U ] = 2 · 4i − init
|Ov |
U ∈U



Let Wv,i,k be a random variable that corresponds to the value of the computation cost of EPOCH(v, i, k)
if the epoch is created and is 0 otherwise. Notice that the computation cost of an epoch at level i is c4i+1 for
some constant c. So, E[Wv,i,k ] = Pr[Xv,i,k = 1]c4i+1 . Therefore, using Lemma 5.12,
E[Wv,i,k ] ≤ 4cE[Bv,i,k ]

(3)

Using the above equation and Corollary 5.0.1, the total expected computation cost associated with all epochs
that get destroyed during the algorithm can be bounded by O(t) as follows.
X
X
E[Wv,i,k ] ≤
4cE[Bv,i,k ] ≤ 32ct = O(t)
v,i,k

v,i,k

23

Since for each update in the graph, we incur O(log n) time to update φ at various levels, there is an O(t log n)
overhead for t updates. We can thus conclude with the following theorem.
Theorem 5.1 Starting with a graph on n vertices and no edges, we can maintain a maximal matching for
any sequence of t updates in O(t log n) time in expectation and O(t log n + n log2 n) with high probability.

5.4 Proof of Lemma 5.8
Our algorithm use randomization to maintain maximal matching. After any given sequence of updates,
there is a set of possible maximal matchings that the algorithm may be maintaining and there is probability
distribution associated with these maximal matchings. So it is useful to think about the probability space of
these matchings as the algorithm proceeds while processing a sequence of updates.
We introduce some notations first. For any matching M maintained at any stage by our algorithm, let
Mi denote the matching at level i. Let M>i = ∪j>i Mj denote the matchings at all levels > i. Let Vi
denote the set of all the vertices belonging to levels in the range ∈ [−1, i]. We now extend the notations to
incorporate the updates in the graph. For any k ≥ 1, let G(k) denote the graph after a given sequence of k
updates and let M(k) denote the maximal matching of G(k) as maintained by our algorithm. Let M>i (k)
denote the matching at all levels > i after a given sequence of k updates.
After processing certain number of updates by the algorithm, suppose M and M ′ are any two matchings
′ . Consider any single update in the graph at this stage. In order to process it,
possible such that M>i = M>i
suppose we carry out two executions I and I ′ of our algorithm with the initial matching being M and M ′
respectively. That is, M(0) = M in the execution I and M(0) = M ′ in the execution I ′ . Our claim is
that the probability distribution of matching at levels > i will be identical at the end of both the executions.
More precisely, for any maximal matching µ(1) on a subset of vertices in graph G(1),
Pr[M>i (1) = µ(1)|M(0) = M ] = Pr[M>i (1) = µ(1)|M(0) = M ′ ]
In order to establish our claim, we shall crucially exploit the following lemma.
Lemma 5.13 For both the matchings M and M ′ , φv (j) is the same for each v ∈ V and j > i.
′ . This implies that for each level j > i the sets of vertices present are
Proof: It is given that M>i = M>i
identical in M and M ′ . Hence the set Vi of all the vertices present at levels ∈ [−1, i] is identical in M and
M ′ . Hence for any vertex v, and any level j > i, the set of all the neighbours of v at levels < j is identical;
notice that φv (j) is just the cardinality of this set. So it follows that φv (j) is the same for each vertex v and
each j > i.


We shall now establish our claim for the deletion of an edge e = (u, v). Establishing the claim for the
insertion of an edge is similar. Notice that our algorithm does not alter the matching if e is not a matched
edge. If e is a matched edge, a wave of free vertices originates from LEVEL (e) and propagates downward.
The following fact follows from our analysis in Section 5.2.1.
F 1. The algorithm won’t alter the matching at level >

LEVEL (e)

while processing the deletion of e.

F 2. The matching is updated in the decreasing order of levels, and once the updating of the matching at a
level is complete, the matching at that level will remain unchanged during the updates of the matching
at lower levels.

24

It follows from the description of M and M ′ that either LEVEL (e) is less than or equal to i in both the
matchings or LEVEL (e) is the same in M and M ′ . Let us first consider the (easier) case when LEVEL (e) ≤ i
in M as well as M ′ . It follows from Fact F 1 stated above that the only changes in matching M and M ′
will be at levels ≤ i. Hence the matching M>i (1) will be identical at the end of both the executions I
and I ′ . Let us now consider the more interesting case of LEVEL (e) > i. Both the executions I and I ′
invoke the procedure PROCESS - FREE - VERTICES(h(u, LEVEL (e)), (v, LEVEL (e))i) in this case. The reader
is recommended to revisit this procedure from Section 5.2.1 before proceeding further.
In order to establish our claim about I and I ′ , we shall establish the following. While the matching at
levels > i is being updated, for each step executed in I, the identical step can be executed in I ′ . Moreover,
if the step in I is executed with some probability, the step will be executed with the same probability in I ′
as well. In order to show this, let us analyse the first iteration of the procedure PROCESS - FREE - VERTICES.
Both I and I ′ will process u first. After disowning its edges from its present level, u owns the same set of
edges in both the executions. Thereafter, u will either stay at the same level or fall by one level. If u stays
at the same level, it chooses a random edge to get matched. The probability that any specific random edge
is picked by u is the same in both the executions. Let us consider the case that u falls by one level. For
each neighbour z of u, it follows from Lemma 5.13 that φℓ (z) is the same in the case of M and M ′ . Hence
the set of vertices rising to level ℓ are the same in both the executions. In addition, the set of edges that
each such vertex owns on rising to level j is also the same, hence, the probability that any specific random
mate is picked is the same in both the executions. So each update in M and M ′ is equally likely during the
processing of u. The reader may note that after each such identical update in M and M ′ , the matchings are
identical at each level > i. Hence, Lemma 5.13 holds again for the updated matchings.
Unlike the first iteration, a generic iteration of the procedure PROCESS - FREE - VERTICES may have free
vertices at levels ≤ LEVEL (e) that are kept in respective queues at these levels. Suppose in the beginning
of any such iteration of the procedure PROCESS - FREE - VERTICES there are two possible configurations such
that the matching as well as the queue storing the free vertices are identical at each level > i but differ at
levels ≤ i. Lemma 5.13 will hold for these configurations as well. Therefore, along exactly the same lines
as the first iteration analysed above, it can be shown that every update in the matching at level > i will be
carried out with the same probability during any generic iteration for any two configurations that match at
all levels > i.
Therefore, each sequence of updates in the matching is equally likely in both the executions I and I ′ till
the last free vertex at level i + 1 is processed. Henceforth, the two executions may differ. But as follows
from Fact F 2, it will affect only the matching at levels ≤ i and there won’t be any change in the matching
at higher levels.
This concludes our claim for a single update. This claim can be invoked appropriately for a sequence of
updates giving us the following theorem.
Theorem 5.2 Let M and M ′ be any two matchings possible by our algorithm at any time such that M>i =
′ . For any sequence of t update in the graph, suppose we carry out two executions I and I ′ of our
M>i
algorithm with the initial matching being M and M ′ respectively. The probability distribution of matching
at every level > i will be identical at the end of both the executions. That is,
Pr[M>i (t) = µ(t), . . . , M>i (1) = µ(1)|M(0) = M ] = Pr[M>i (t) = µ(t), . . . , M>i (1) = µ(1)|M(0) = M ′ ]
where µ(j), for 1 ≤ j ≤ t, is any maximal matching on a subset of vertices in the graph G(j).
For the proof of Theorem 5.2, we shall apply the argument for single update inductively and use the following lemma from elementary probability theory.
Lemma 5.14 Suppose A, B, C are three events defined over a probability space (Ω, P ). Then,
Pr[A ∩ B | C] = Pr[A | B ∩ C] · Pr[B | C]
25

Let us define events C as M(0) = M and C ′ as M(0) = M ′ . We have shown that Pr[M>i (1) =
µ(1) | C] = Pr[M>i (1) = µ(1) | C ′ ]. If we define event B as M>i (1) = µ(1) then by another application
of the arguments that we used for a single update,
Pr[M>i (2) = µ(2) | B, C] = Pr[M>i (2) = µ(2) | B, C ′ ]
Applying Lemma 5.14, we get
Pr[M>i (2) = µ(2), B | C] = Pr[M>i (2) = µ(2) | B, C] · Pr[B | C]
Since Pr[B | C] = Pr[B|C ′ ], it follows that
Pr[M>i (2) = µ(2), B | C] = Pr[M>i (2) = µ(2), B | C ′ ]
The above argument can be inductively applied for every subsequent update. This completes the proof of
Theorem 5.2
5.4.1

Connection to the analysis

We first state two lemmas from elementary probability theory that deal with the independence of events. For
the sake of completeness, the proof of these lemmas is given in Appendix.

The first lemma deals with conditional probability.
Lemma 5.15 Let A be an event and B1 , . . . , Bk be k mutually exclusive events defined over a probability
space (Ω, P ). If Pr[A | Bj ] = ρ for each 1 ≤ j ≤ k, then Pr[A | C] = ρ where event C = ∪j Bj .
The second lemma deals with independence of events. Let A and B be two events defined over a probability
space (Ω, P ). A is said to be independent of B if Pr[A | B] = Pr[A | B̄] = Pr[A]. Alternatively,
Pr[A ∩ B] = Pr[A] · Pr[B]. The notion of independence gets carried over from events to random variables
in a natural manner as follows.
Definition 5.1 An event A is said to be independent of a random variable X if for each x ∈ X, Pr[A | X =
x] = Pr[A].
Lemma 5.16 Suppose A is an event and X be a random variable defined over probability space (Ω, P ). If
A is independent of X, then for each x ∈ X,
Pr[X = x | A] = Pr[X = x]
Now we shall establish the connection of Theorem 5.2 to the anlysis of our algorithm. In particular, we shall
use this theorem to prove Lemma 5.8. Suppose a vertex v creates an epoch at level i while the algorithm
processes kth update in the graph for any k < t. We shall analyse the probability space of the future
matchings starting from the time just before the creation of this epoch.
While creating its epoch, v chooses its mate randomly uniformly out of Ovinit . Clearly, the change in the
matching at levels ≤ i will depend on the mate that v picks. Let M be the set of all possible matchings once
the algorithm completes the processing of the kth update. Now notice that all matchings from the set M are
identical at each level > i. So it follows from Theorem 5.2 that for any two matchings M, M ′ ∈ M,
26

Pr[M>i (t) = µ(t), . . . ,M>i (k + 1) = µ(k + 1) | M(k) = M ]
= Pr[M>i (t) = µ(t), . . . , M>i (k + 1) = µ(k + 1) | M(k) = M ′ ]
Let this conditional probability be ρ. For each (v, w) ∈ Ovinit , there may be several matchings in M in
which v is matched to w. By applying Lemma 5.15, the following equation holds for every (v, w) ∈ Ovinit ,
Pr[M>i (t) = µ(t), . . . , M>i (k + 1) = µ(k + 1) | MATE (v) = w] = ρ
Since this probability is the same for each (v, w) ∈ Ovinit , so using Definition 5.1, it follows that the
matchings at levels > i during any sequence of updates is independent of the mate that v picked during the
creation of its epoch. Now applying Lemma 5.16 we get the following lemma.
Lemma 5.17 Suppose a vertex v creates an epoch at level i while the algorithm processes kth update in the
graph. Consider any sequence of updates in the graph. The mate picked by v while creating the epoch is
independent of the sequence of matchings at levels > i computed by the algorithm while processing these
updates. That is, for any t > k, and any (v, w) ∈ Ovinit ,
Pr[MATE (v) = w|M>i (t) = µ(t), . . . , M>i (k + 1) = µ(k + 1)] = Pr[MATE (v) = w] =

1
|Ovinit |

Consider any given sequence of t updates in the graph. Subsequent to the time v creates an epoch at level
i during kth update, let µ = hµ(k + 1), . . . , µ(t)i be the sequence of matching at levels > i as computed by
the algorithm. Notice that the upward movement of v and each (v, w) ∈ Ovinit after the creation of epoch
is captured precisely by the corresponding update in the matching at level > i. Therefore, using µ we can
define the update sequence associated with the epoch as follows. Consider an edge (v, w) ∈ Ovinit and let ℓth
update in the graph be the deletion of (v, w). Let j < ℓ be the smallest integer such that w ∈ µj , that is, w
appears in the matching at level > i while processing of jth update in the graph, then the update associated
with (v, w) is the upward movement. If no such j exists, the update associated with (v, w) is its deletion.
Likewise, we define the update associated with v. The update sequence U for the epoch is the sequence of
these updates on v and the edges of Ovinit arranged in the chronological order.
For an update sequence U associated with an epoch, there may exist many sequences {µ1 , . . . , µq } such
that for each of them, the update sequence associated with the epoch is U . It follows from Lemma 5.17 that
the mate picked by v during its epoch is independent of each such sequence µr , 1 ≤ r ≤ q. Therefore, using
Lemma 5.15, the mate picked by v during its epoch is independent of U as well. Thus we have established
the validity of Lemma 5.8.

6 A tight example
We tested our algorithm on random graphs of various densities and found that the matching maintained is
very close to the maximum matching. This suggests that our algorithm might be able to maintain nearly
maximum matching for dynamic graphs appearing in various practical applications. However, it is not hard
to come up with an update sequence such that at the end of the sequence, the matching obtained by our
algorithm is strictly half the size of maximum matching. In other words, the approximation factor 2 for the
matching maintained by our algorithm is indeed tight. We present one such example as follows (see Figure
8).
Let G(V ∪ W, E) be a graph such that V = {v1 , v2 , . . . , vn } and W = {w1 , w2 , . . . , wn } for some
even number n. Consider the following update sequence. In the first phase, add edges between every pair
of vertices present in V . This results in a complete subgraph on vertices of V . The size of any maximal
27

Figure 8: An example where our algorithm gives a 2-approximation. The vertices on top are in V and form
a complete graph. The vertices at the bottom of the figure are in W .
matching on a complete graph of size n is n/2. After the first phase of updates ends, the size of matching
obtained by our algorithm is n/2. In the second phase, add edge (vi , wi ) for all i. Note that the degree of
each wi is one at the end of the updates. Let us now find the matching which our algorithm maintains. Let
(vi , vj ) be an edge in the matching after phase 1. Note that both these endpoints are at a level greater than
−1. A vertex in W is at level −1 as it does not have any adjacent edges after phase 1. When an edge (wi , vi )
is added, since vi is at a higher level than wi , vi becomes the owner of this edge. The second invariant of vi is
not violated after this edge insertion and nothing happens at this update step and wi still remains at level −1.
Using same reasoning, we can show that wj also remains at level −1 after the addition of edge (vj , wj ). So
matching maintained by the algorithm remains unchanged. It is easy to observe that the maximum matching
of the graph G now has size n which is twice the size of the matching maintained by our algorithm.

7 Postscript
We presented a fully dynamic randomized algorithm for maximal matching which achieves expected amortized O(log n) time per edge insertion or deletion. An interesting question is to explore how crucial randomization is for dynamic maximal matching.
Subsequent to an earlier version of this paper [5], Bhattacharya et al. [9] almost answered this question
in affirmative by designing a determinstic algorithm that maintains (2 + ǫ)-approximate matching in amortized O(poly(log n, 1/ǫ) update time. Another interesting question is to explore whether we can achieve
O(1) amortized update time. Very recently Solomon [29] answered this question in affirmative as well by
designing a randomized algorithm that takes O(t + n log n) update time with high probability to process
any sequence of t edge deletions. Though the basic building blocks of his algorithm are the same as ours,
the two algorithms are inherently different and so are their analysis.
In our algorithm, a vertex may rise to a higher level and create a new epoch even when its matched edge
is intact. But the algorithm of Solomon [29] of takes a lazy approach to maintain the hierarchy of vertices
wherein a vertex is processed only when it becomes absolutely necessary. Another crucial difference is the
following. Our algorithm maintains a function φv (j) for each vertex v and each level j. This function is used
to ensure an invariant that each vertex v is at the highest possible level ℓ such that the edges incident from
lower levels is at least 4ℓ . An important property guaranteed by this invariant is that the mate of a vertex
while creating an epoch is independent of the update sequence associated with the epoch. The analysis
of our algorithm crucially exploits this property. However, the explicit maintenance of φv (j) imposes an
overhead of Θ(log n) in the update time. In order to achieve O(1) update time, Solomon [29] gets rid of the

28

maintenance of φv (j) by taking a lazy approach and a couple of new ideas. As a result, unfortunately, the
property of our algorithm no longer holds for the algorithm of Solomon [29] - indeed there is dependence
between the update sequence associated with an epoch created by a vertex and the random mate picked by
it. Solomon [29] makes use of a new concept called uninterrupted duration of an epoch that bypasses the
need of our property for the analysis. His analysis can be adapted to our algorithm as well and can be viewed
as the correct counterpart of Lemma 4.10 in [5]. However, our new analysis has its own merits since it is
based on an insightful property of our algorithm which we believe is of its own independent interest and
importance.
Subsequent to the publication of the [5] there has been interesting progress in the area of dynamic
matching with approximation less than 2 [7, 8, 24, 14], and dynamic weighted matching [3, 4, 14].
One of the technical challenges in theoretical computer science is to prove lower bounds for algorithmic
problems. Recently there has been some progress on proving conditional lower bounds for dynamic graph
algorithms [1, 15]. In the light of the lower bound presented by Abboud and Williams [1] based on Ω(n2 )
hardness of the 3SUM problem, it would be an interesting and challenging problem to see if c-approximate
maximum matching for c < 2 can be maintained in o(n) update time.

8 Acknowledgment
The possibility of an error in Lemma 4.10 of [5] was pointed out by Sayan Bhattacharya and Divyarthi
Mohan. The second author would like to thank both of them for discussions on the proof of the expectation
bound and the definition of B(v, i, k). In [5], we used 2i as the threshold for raising a vertex to level i.
The possibility of increasing this threshold from 2i to bi for any constant b without any impact on the time
complexity was observed by Shay Solomon [29]. We are thankful to him for this observation.

References
[1] Amir Abboud and Virginia Vassilevska Williams. Popular conjectures imply strong lower bounds for
dynamic problems. CoRR, abs/1402.0054, 2014.
[2] David J. Abraham, Robert W. Irving, Telikepalli Kavitha, and Kurt Mehlhorn. Popular matchings.
SIAM J. Comput., 37(4):1030–1045, 2007.
[3] Abhash Anand, Surender Baswana, Manoj Gupta, and Sandeep Sen. Maintaining approximate maximum weighted matching in fully dynamic graphs. In FSTTCS, pages 257–266, 2012.
[4] Abhash Anand, Surender Baswana, Manoj Gupta, and Sandeep Sen. Maintaining approximate maximum weighted matching in fully dynamic graphs. CoRR, abs/1207.3976, 2012.
[5] Surender Baswana, Manoj Gupta, and Sandeep Sen. Fully dynamic maximal matching in O(log n)
update time. SIAM J. Comput. (preliminary version appeared in FOCS 2011), 44(1):88–113, 2015.
[6] Surender Baswana, Sumeet Khurana, and Soumojit Sarkar. Fully dynamic randomized algorithms for
graph spanners. ACM Transactions on Algorithms, 8(4):35, 2012.
[7] Aaron Bernstein and Cliff Stein. Fully dynamic matching in bipartite graphs. In Automata, Languages,
and Programming - 42nd International Colloquium, ICALP 2015, Kyoto, Japan, July 6-10, 2015,
Proceedings, Part I, pages 167–179, 2015.

29

[8] Aaron Bernstein and Cliff Stein. Faster fully dynamic matchings with small approximation ratios.
In Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, SODA
2016, Arlington, VA, USA, January 10-12, 2016, pages 692–711, 2016.
[9] Sayan Bhattacharya, Monika Henzinger, and Danupon Nanongkai. New deterministic approximation
algorithms for fully dynamic matching. In Proceedings of the 48th Annual ACM SIGACT Symposium
on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016, pages 398–411, 2016.
[10] J. Edmonds. Paths, trees, and flowers. Canadian Journal of Mathematics, 17:449467, 1965.
[11] J. Edmonds and E. L. Johnson. Matching, euler tours, and the chinese postman. Mathematical Programming, 5:88–124, 1973.
[12] Harold N. Gabow and Robert Endre Tarjan. Faster scaling algorithms for general graph-matching
problems. J. ACM, 38(4):815–853, 1991.
[13] D. Gale and L. S. Shapley. College admissions and the stability of marriage. American Mathematical
Monthly, 69:9–14, 1962.
[14] Manoj Gupta and Richard Peng. Fully dynamic $(1+)$-approximate matchings. In 54th Annual IEEE
Symposium on Foundations of Computer Science, 2013.
[15] Monika Henzinger, Sebastian Krinninger, Danupon Nanongkai, and Thatchaphol Saranurak. Unifying
and strengthening hardness for dynamic problems via the online matrix-vector multiplication conjecture. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, STOC
2015, Portland, OR, USA, June 14-17, 2015, pages 21–30, 2015.
[16] Jacob Holm, Kristian de Lichtenberg, and Mikkel Thorup. Poly-logarithmic deterministic fullydynamic algorithms for connectivity, minimum spanning tree, 2-edge, and biconnectivity. J. ACM,
48(4):723–760, 2001.
[17] John E. Hopcroft and Richard M. Karp. An n5/2 algorithm for maximum matchings in bipartite graphs.
SIAM J. Comput., 2(4):225–231, 1973.
[18] Chien-Chung Huang and Telikepalli Kavitha. Efficient algorithms for maximum weight matchings in
general graphs with small edge weights. In SODA, pages 1400–1412, 2012.
[19] Jon Kleinberg and Eva Tardos. Algorithm Design. Addison Wesley, 2005.
[20] E. Lawler. Combinatorial Optimization: Networks and Matroids. Holt, Rinehart & Winston, Newyork,
1976.
[21] L. Lovasz and M.D. Plummer. Matching Theory. AMS Chelsea Publishing, North-Holland, AmsterdamNew York, 1986.
p
[22] Silvio Micali and Vijay V. Vazirani. An O( (|V |)|E|) algorithm for finding maximum matching in
general graphs. In FOCS, pages 17–27, 1980.
[23] Marcin Mucha and Piotr Sankowski. Maximum matchings via gaussian elimination. In FOCS, pages
248–255, 2004.
[24] Ofer Neiman and Shay Solomon. Deterministic algorithms for fully dynamic maximal matching.
CoRR, abs/1207.1277, 2012.
30

[25] Krzysztof Onak and Ronitt Rubinfeld. Maintaining a large matching and a small vertex cover. In
STOC, pages 457–464, 2010.
[26] Rasmus Pagh and Flemming Friche Rodler. Cuckoo hashing. J. Algorithms, 51(2):122–144, 2004.
[27] Liam Roditty and Uri Zwick. Improved dynamic reachability algorithms for directed graphs. SIAM J.
Comput., 37(5):1455–1471, 2008.
[28] Liam Roditty and Uri Zwick. Dynamic approximate all-pairs shortest paths in undirected graphs. SIAM
J. Comput., 41(3):670–683, 2012.
[29] Shay Solomon. Fully dynamic maximal matching in constant update time. CoRR, abs/1604.08491,
2016.
[30] Mikkel Thorup. Fully-dynamic min-cut. Combinatorica, 27(1):91–127, 2007.

9 Appendix
Proof of Lemma 5.15
Proof:
Pr[A ∩ C] = Pr[A ∩ (∪i Bi )]
X
Pr[A ∩ Bi ]
=

since Bi ’s are mutually exclusive

i

=

X
i

= ρ·

Pr[A | Bi ] · Pr[Bi ]

X

using the definition of conditional probability

Pr[Bi ]

i

= ρ · Pr[∪i Bi ] = ρ · Pr[C]

since Bi ’s are mutually exclusive

Hence Pr[A | C] = Pr[A ∩ C]/Pr[C] = ρ.



Proof of Lemma 5.16
Proof: Since A is independent of X, so for each x ∈ X,
Pr[A ∩ X = x] = Pr[A] · Pr[X = x]

(4)

Hence
Pr[A ∩ X = x]
Pr[A]
Pr[A] · Pr[X = x]
=
Pr[A]
= Pr[X = x]

Pr[X = x|A] =

using Equation 4



31

Proof of Lemma 3.1
The asymmetric random walk problem can be seen as a special case of the famous Gambler’s ruin
problem described as follows.
Gambler’s ruin problem.
There are two players who play a game that goes in rounds. Initially Player 1 has a capital of c units
and Player 2 has a capital of c′ units. Player 1 wins a round with probability p and loses with probability
q = 1 − p independent of the previous rounds. The winner of a round takes away one unit of the capital
from the opponent. The game ends when the capital of one of the players becomes 0.
The following lemma is well-known in many text books on probability theory. A concise and self
contained proof is available at the link : examplehttp://faculty.washington.edu/fm1/394/Materials/Gambler.pdf.
Lemma 9.1 In the Gambler’s ruin problem with p > q, the probability that Player 1 gets ruined is
′

1 − (p/q)c
1 − (p/q)c+c′
Let us now put an additional restriction in the problem: the total number of rounds allowed in the game
is L for a given number L < c′ . Notice that with this restriction Player 2 will never be ruined. As a result
the game will be over when Player 1 gets ruined or when L rounds are over. The probability of Player 1
getting ruined in this restricted Gambler’s problem is strictly less than the probability of Player 1 getting
ruined in the original Gambler’s problem described above. This is because there is a non-zero probability
that Player 1 may be ruined after performing more than L steps, and the restricted Gambler’s problem rules
out this possibility. Hence, using Lemma 9.1, it follows that for the restricted version of the Gambler’s ruin
problem with p > q, the probability that Player 1 gets ruined is less than
′

1 − (p/q)c
<
1 − (p/q)c+c′

 c
q
p

The restricted version of the Gambler’s ruin problem can be formulated as an asymmetric random walk
problem: The walk starts at location c units to the right of the origin. In each step, the particle moves one
unit to the right with probability p or one unit to the left with probability q = 1 − p indepependent of the
past moves. The walk terminates upon reaching either the origin or when it has performed L step. This
completes the proof of Lemma 3.1.

32

