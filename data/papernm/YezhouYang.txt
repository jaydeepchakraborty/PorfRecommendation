http://dx.doi.org/10.1109/LRA.2017.2669363 || Unsupervised Linking of Visual Features to Textual Descriptions in Long Manipulation Activities.
http://dx.doi.org/10.1007/978-3-319-46487-9_49 || Reliable Attribute-Based Object Recognition Using High Predictive Value Classifiers.
http://dx.doi.org/10.1109/HUMANOIDS.2016.7803303 || Co-active learning to adapt humanoid movement for manipulation.
http://doi.acm.org/10.1145/2964284.2973791 || LightNet: A Versatile, Standalone Matlab-based Environment for Deep Learning.
http://arxiv.org/abs/1611.05896 || Answering Image Riddles using Vision and Reasoning through Probabilistic Soft Logic.
http://arxiv.org/abs/1610.00759 || Prediction of Manipulation Actions.
http://arxiv.org/abs/1609.03619 || Reliable Attribute-Based Object Recognition Using High Predictive Value Classifiers.
http://arxiv.org/abs/1609.03628 || Co-active Learning to Adapt Humanoid Movement for Manipulation.
http://arxiv.org/abs/1602.00032 || What Can I Do Around Here? Deep Functional Scene Understanding for Cognitive Robots.
http://arxiv.org/abs/1605.02766 || LightNet: A Versatile, Standalone Matlab-based Environment for Deep Learning.
http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9286 || Robot Learning Manipulation Action Plans by "Watching" Unconstrained Videos from the World Wide Web.
http://aclweb.org/anthology/P/P15/P15-1066.pdf || Learning the Semantics of Manipulation Action.
http://dx.doi.org/10.1109/CVPR.2015.7298637 || Grasp type revisited: A modern perspective on a classical feature for vision.
http://dx.doi.org/10.1109/ICRA.2015.7139371 || Learning the spatial semantics of manipulation actions through preposition grounding.
http://arxiv.org/abs/1511.03292 || From Images to Sentences through Scene Description Graphs using Commonsense Reasoning and Knowledge.
http://arxiv.org/abs/1512.01525 || Learning the Semantics of Manipulation Action.
http://arxiv.org/abs/1512.03460 || Neural Self Talk: Image Understanding via Continuous Questioning and Answering.
http://dx.doi.org/10.1016/j.ins.2013.09.036 || Low-level and high-level prior learning for visual saliency estimation.
http://dx.doi.org/10.1109/HUMANOIDS.2014.7041476 || Learning hand movements from markerless demonstrations for humanoid tasks.
http://dx.doi.org/10.1109/HUMANOIDS.2014.7041483 || Manipulation action tree bank: A knowledge resource for humanoids.
http://dx.doi.org/10.1016/j.neucom.2013.03.037 || Color-to-gray based on chance of happening preservation.
http://dx.doi.org/10.5244/C.27.79 || Action Attribute Detection from Sports Videos with Contextual Constraints.
http://dx.doi.org/10.1109/CVPR.2013.331 || Detection of Manipulation Action Consequences (MAC).
http://dx.doi.org/10.1109/ICRA.2013.6631179 || Robots with language: Multi-label visual recognition using NLP.
http://dx.doi.org/10.1109/IROS.2013.6697213 || Minimalist plans for interpreting manipulation actions.
http://dx.doi.org/10.1109/ICRA.2012.6224589 || Towards a Watson that sees: Language-guided action recognition for robots.
http://dx.doi.org/10.1109/IROS.2012.6385483 || Using a minimal action grammar for activity understanding in the real world.
http://www.aaai.org/ocs/index.php/WS/AAAIW11/paper/view/3921 || A Corpus-Guided Framework for Robotic Visual Perception.
http://www.aclweb.org/anthology/D11-1041 || Corpus-Guided Sentence Generation of Natural Images.
http://dx.doi.org/10.1109/ICCV.2011.6126320 || Active scene recognition with vision and language.
