(0, '0.278*"vehicl" + 0.270*"use" + 0.207*"can" + 0.202*"imag" + 0.193*"model" + 0.169*"method" + 0.157*"propos" + 0.155*"featur" + 0.154*"data" + 0.141*"learn" + 0.126*"inform" + 0.123*"ieee" + 0.118*"one" + 0.116*"train" + 0.116*"base" + 0.109*"fig" + 0.107*"system" + 0.103*"dataset" + 0.096*"approach" + 0.094*"cooper" + 0.092*"sentiment" + 0.090*"perform" + 0.090*"comput" + 0.089*"pp" + 0.085*"gener" + 0.082*"visual" + 0.081*"problem" + 0.079*"algorithm" + 0.079*"network" + 0.079*"map"')
(1, '0.532*"vehicl" + -0.186*"model" + 0.181*"cooper" + 0.172*"system" + -0.165*"learn" + 0.156*"fig" + -0.148*"featur" + -0.134*"imag" + -0.131*"train" + 0.130*"percept" + -0.127*"dataset" + 0.120*"map" + 0.117*"ego" + 0.116*"leader" + 0.112*"road" + 0.112*"drive" + -0.109*"sentiment" + -0.105*"network" + 0.099*"driver" + -0.095*"method" + 0.091*"lane" + -0.090*"data" + 0.085*"scan" + 0.081*"view" + 0.081*"see" + -0.076*"gener" + 0.076*"ieee" + 0.076*"merg" + 0.076*"sensor" + -0.076*"þ"')
(2, '-0.341*"network" + 0.334*"model" + -0.326*"dataset" + 0.231*"þ" + -0.219*"layer" + 0.197*"data" + 0.181*"method" + -0.178*"gener" + -0.172*"imag" + -0.134*"mnist" + 0.125*"skill" + -0.115*"featur" + 0.109*"hmm" + 0.101*"¼" + 0.096*"rel" + 0.093*"video" + 0.093*"propos" + -0.091*"learn" + -0.090*"class" + 0.089*"pair" + 0.088*"sequenc" + 0.081*"surgic" + 0.080*"improv" + 0.079*"problem" + 0.077*"motion" + 0.077*"eqn" + -0.075*"sentiment" + 0.074*"markov" + -0.073*"instanc" + 0.072*"rank"')
(3, '-0.407*"sentiment" + -0.353*"imag" + 0.273*"network" + 0.191*"learn" + 0.184*"dataset" + 0.183*"layer" + 0.171*"gener" + 0.169*"train" + -0.156*"visual" + -0.147*"featur" + -0.147*"uv" + -0.131*"inform" + 0.129*"þ" + -0.110*"predict" + 0.107*"mnist" + 0.098*"model" + -0.097*"social" + -0.096*"textual" + 0.090*"data" + -0.088*"u0" + -0.086*"analysi" + -0.078*"approach" + 0.076*"class" + -0.073*"matrix" + -0.071*"factor" + -0.070*"ut" + 0.069*"skill" + 0.069*"use" + -0.067*"2013" + 0.066*"also"')
(4, '-0.550*"answer" + -0.276*"question" + -0.243*"one" + -0.204*"best" + 0.185*"sentiment" + -0.178*"featur" + -0.166*"rank" + -0.145*"eqn" + 0.136*"imag" + -0.135*"interact" + -0.134*"predict" + 0.132*"method" + -0.120*"qualiti" + 0.117*"train" + -0.103*"j2" + -0.103*"j1" + 0.091*"visual" + 0.088*"þ" + 0.085*"video" + -0.080*"user" + -0.078*"w2" + -0.072*"differ" + -0.069*"hierarch" + 0.068*"dataset" + -0.068*"acm" + -0.067*"consid" + 0.067*"uv" + -0.061*"intern" + -0.061*"algorithm" + -0.056*"site"')
(5, '-0.413*"instanc" + 0.350*"sentiment" + -0.255*"imag" + 0.210*"network" + -0.195*"bag" + -0.187*"posit" + -0.180*"mil" + 0.153*"uv" + -0.140*"approach" + 0.132*"inform" + 0.126*"answer" + 0.123*"visual" + -0.110*"prototyp" + -0.106*"neg" + -0.101*"paramet" + -0.099*"enhanc" + 0.097*"textual" + -0.096*"dd" + -0.095*"space" + -0.093*"region" + 0.093*"layer" + 0.092*"analysi" + 0.090*"u0" + 0.090*"model" + 0.088*"social" + 0.073*"ut" + 0.065*"question" + 0.063*"vv" + 0.063*"vt" + 0.062*"media"')
(6, '-0.403*"imag" + 0.375*"instanc" + -0.248*"paramet" + -0.215*"enhanc" + 0.206*"posit" + 0.202*"sentiment" + 0.170*"bag" + 0.161*"mil" + 0.138*"neg" + 0.125*"label" + 0.123*"dataset" + -0.121*"qualiti" + -0.111*"version" + -0.106*"predict" + 0.101*"analysi" + 0.099*"prototyp" + -0.095*"approach" + 0.090*"method" + 0.087*"uv" + 0.086*"dd" + 0.082*"one" + -0.081*"iqa" + -0.078*"low" + -0.075*"set" + 0.068*"learn" + 0.068*"region" + -0.067*"structur" + 0.067*"multipl" + 0.063*"figur" + 0.062*"classif"')
(7, '-0.403*"video" + -0.354*"salienc" + -0.222*"detect" + -0.209*"frame" + -0.179*"propos" + -0.171*"abnorm" + -0.155*"object" + 0.141*"learn" + -0.119*"attent" + 0.116*"sentiment" + -0.114*"motion" + 0.113*"þ" + -0.110*"spatiotempor" + 0.107*"train" + 0.106*"instanc" + 0.094*"imag" + -0.092*"action" + -0.090*"region" + -0.090*"lstm" + -0.088*"tv" + -0.085*"two" + -0.084*"han" + -0.084*"tempor" + -0.083*"result" + -0.082*"dataset" + 0.080*"paramet" + 0.078*"data" + -0.076*"page" + -0.076*"move" + -0.074*"domain"')
(8, '0.307*"network" + -0.296*"attribut" + -0.230*"dataset" + -0.207*"featur" + -0.205*"select" + -0.196*"gener" + -0.185*"cluster" + -0.170*"class" + 0.165*"imag" + 0.160*"mentor" + 0.152*"neuron" + 0.140*"mente" + -0.133*"mnist" + 0.118*"instanc" + -0.103*"optim" + 0.098*"method" + 0.096*"answer" + -0.086*"group" + -0.082*"structur" + 0.082*"max" + 0.081*"video" + 0.080*"pool" + 0.079*"learn" + 0.078*"uv" + -0.077*"matrix" + -0.074*"tr" + 0.071*"inform" + 0.071*"space" + 0.070*"salienc" + 0.069*"19"')
(9, '0.269*"featur" + 0.259*"attribut" + 0.241*"network" + -0.239*"gener" + -0.194*"mnist" + -0.189*"imag" + 0.189*"select" + 0.166*"cluster" + 0.162*"learn" + -0.160*"dataset" + 0.152*"mentor" + 0.144*"neuron" + 0.133*"mente" + -0.130*"layer" + 0.118*"approach" + -0.111*"uv" + -0.108*"answer" + -0.098*"class" + -0.094*"di" + 0.087*"represent" + -0.085*"base" + 0.083*"pool" + 0.082*"matrix" + -0.081*"iqa" + -0.079*"qualiti" + 0.079*"max" + -0.074*"filter" + 0.074*"group" + 0.071*"weight" + 0.071*"optim"')
